uint64_t type metadata accessor for MLActionClassifier.DataSource(uint64_t a1)
{
  uint64_t result;

  result = type metadata singleton initialization cache for MLActionClassifier.DataSource;
  if (!type metadata singleton initialization cache for MLActionClassifier.DataSource) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLActionClassifier.DataSource);
  }
  return result;
}

uint64_t outlined init with copy of MLActionClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLActionClassifier.DataSource(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t specialized DataFrame.init<A>(expanding:keysColumnName:valuesColumnName:)(uint64_t a1, uint64_t a2, uint64_t *a3, void *a4, uint64_t a5)
{
  uint64_t v53 = a5;
  v54 = a4;
  v56 = a3;
  uint64_t v55 = a2;
  uint64_t v6 = a1;
  uint64_t v48 = v5;
  uint64_t v52 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v49 = *(void *)(v52 - 8);
  int64_t v7 = *(void *)(v49 + 64);
  v8 = alloca(v7);
  v9 = alloca(v7);
  v10 = alloca(v7);
  v11 = alloca(v7);
  v57[0] = _swiftEmptyArrayStorage;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  uint64_t v13 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [String] and conformance [A], &demangling cache variable for type metadata for [String], (uint64_t)&protocol conformance descriptor for [A]);
  v51 = &v43;
  Column.init<A>(name:contents:)(a2, v56, v57, &type metadata for String, v12, v13);
  v57[0] = _swiftEmptyArrayStorage;
  v56 = &v43;
  uint64_t v55 = v12;
  uint64_t v44 = v13;
  Column.init<A>(name:contents:)(v54, v53, v57, &type metadata for String, v12, v13);
  uint64_t v14 = 2;
  swift_bridgeObjectRetain_n(a1, 2);
  v15 = specialized _copyCollectionToContiguousArray<A>(_:)(a1);
  swift_bridgeObjectRelease(a1);
  v57[0] = v15;
  specialized MutableCollection<>.sort(by:)(v57);
  swift_bridgeObjectRelease(a1);
  uint64_t v16 = v57[0];
  uint64_t v45 = *(void *)(v57[0] + 16);
  if (v45)
  {
    uint64_t v50 = v57[0];
    uint64_t v47 = v57[0] + 32;
    uint64_t v17 = 0;
    uint64_t v46 = a1;
    do
    {
      uint64_t v18 = *(void *)(v47 + 16 * v17);
      uint64_t v19 = *(void *)(v47 + 16 * v17 + 8);
      uint64_t v20 = *(void *)(v6 + 16);
      swift_bridgeObjectRetain(v19);
      v21 = _swiftEmptyArrayStorage;
      if (v20)
      {
        swift_bridgeObjectRetain(v19);
        unint64_t v22 = specialized __RawDictionaryStorage.find<A>(_:)(v18, v19);
        v23 = _swiftEmptyArrayStorage;
        if (v24)
        {
          v23 = *(void **)(*(void *)(v6 + 56) + 8 * v22);
          swift_bridgeObjectRetain((_BYTE)v23);
        }
        swift_bridgeObjectRelease(v19);
        v21 = v23;
      }
      uint64_t v53 = v17;
      v54 = v21;
      uint64_t v25 = v21[2];
      if (v25)
      {
        v26 = (void *)static Array._allocateBufferUninitialized(minimumCapacity:)(v21[2]);
        v27 = v26;
        v26[2] = v25;
        v26[4] = v18;
        v26[5] = v19;
        if (v25 != 1)
        {
          v26[6] = v18;
          v28 = v26;
          v26[7] = v19;
          if (v25 != 2)
          {
            uint64_t v29 = v25 - 2;
            v30 = v26 + 9;
            do
            {
              *(v30 - 1) = v18;
              uint64_t *v30 = v19;
              swift_bridgeObjectRetain(v19);
              v30 += 2;
              --v29;
            }
            while (v29);
          }
          swift_bridgeObjectRetain(v19);
          v27 = v28;
        }
      }
      else
      {
        swift_bridgeObjectRelease(v19);
        v27 = _swiftEmptyArrayStorage;
      }
      uint64_t v17 = v53 + 1;
      v57[0] = v27;
      uint64_t v31 = v55;
      uint64_t v32 = v44;
      Column.append<A>(contentsOf:)(v57, v52, v55, v44);
      swift_bridgeObjectRelease((_BYTE)v27);
      char v33 = (char)v54;
      v57[0] = v54;
      uint64_t v14 = v52;
      Column.append<A>(contentsOf:)(v57, v52, v31, v32);
      swift_bridgeObjectRelease(v33);
      uint64_t v6 = v46;
    }
    while (v17 != v45);
    swift_bridgeObjectRelease(v46);
    uint64_t v34 = v50;
  }
  else
  {
    swift_bridgeObjectRelease(a1);
    uint64_t v34 = v16;
  }
  swift_release();
  DataFrame.init()(v34, v14, v35, v36);
  v37 = v51;
  DataFrame.append<A>(column:)(v51, &type metadata for String);
  v38 = v56;
  DataFrame.append<A>(column:)(v56, &type metadata for String);
  v39 = *(void (**)(uint64_t *, uint64_t))(v49 + 8);
  v40 = v38;
  uint64_t v41 = v52;
  v39(v40, v52);
  return ((uint64_t (*)(uint64_t *, uint64_t))v39)(v37, v41);
}

uint64_t MLActionClassifier.DataSource.keypointsWithAnnotations(targetFrameRate:)(__m128 a1)
{
  uint64_t v85 = v2;
  v91 = v3;
  v88 = (void *)a1.i64[0];
  v78 = v1;
  uint64_t v76 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v75 = *(void *)(v76 - 8);
  int64_t v4 = *(void *)(v75 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  v70 = (uint64_t *)&v68;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?)
                             - 8)
                 + 64);
  v8 = alloca(v7);
  v9 = alloca(v7);
  v69 = &v68;
  v86 = (void *)type metadata accessor for AnyColumn(0);
  v81 = (uint64_t *)*(v86 - 1);
  int64_t v10 = v81[8];
  v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  v71 = (uint64_t *)&v68;
  uint64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  v84 = (uint64_t *)&v68;
  uint64_t v15 = type metadata accessor for DataFrame(0);
  uint64_t v16 = *(void *)(v15 - 8);
  int64_t v17 = *(void *)(v16 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  v77 = (uint64_t *)&v68;
  uint64_t v20 = alloca(v17);
  v21 = alloca(v17);
  v90 = (uint64_t *)&v68;
  uint64_t v22 = type metadata accessor for MLActionClassifier.DataSource(0);
  int64_t v23 = *(void *)(*(void *)(v22 - 8) + 64);
  char v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  outlined init with copy of MLActionClassifier.DataSource((uint64_t)v91, (uint64_t)&v68);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v68, v22);
  if (EnumCaseMultiPayload != 5)
  {
    if (EnumCaseMultiPayload == 3)
    {
      char v27 = (char)v69;
      v81 = v70;
      v91 = v71;
      v84 = v72;
      v86 = v73;
      v28 = v74;
      uint64_t v29 = (void *)v75;
      uint64_t v92 = (uint64_t)v68;
      LOBYTE(v93) = v69 & 1;
      v90 = v68;
      outlined copy of Result<_DataTable, Error>((uint64_t)v68, (char)v69);
      v88 = v28;
      uint64_t v30 = v85;
      static MLActionClassifier.reformatKeypointsDataTable(table:featureColumn:)(&v92, (uint64_t)v28, v29, *(double *)a1.i64);
      if (v30)
      {
        outlined consume of Result<_DataTable, Error>(v92, v93);
        swift_bridgeObjectRelease((_BYTE)v91);
        swift_bridgeObjectRelease((_BYTE)v86);
        swift_bridgeObjectRelease((_BYTE)v29);
        return outlined consume of Result<_DataTable, Error>((uint64_t)v90, v27);
      }
      char v48 = (char)v86;
      static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)((uint64_t)&v92, (uint64_t)v81, v91, v88, v29, (uint64_t)v84, v86);
      swift_bridgeObjectRelease((_BYTE)v91);
      swift_bridgeObjectRelease(v48);
      swift_bridgeObjectRelease((_BYTE)v29);
      outlined consume of Result<_DataTable, Error>((uint64_t)v90, v27);
    }
    else
    {
      type metadata accessor for MLActionClassifier.FeatureExtractor();
      uint64_t v47 = v85;
      static MLActionClassifier.FeatureExtractor.extractFeatures(from:targetFrameRate:)((uint64_t)v91, (__m128)(unint64_t)v88);
      if (v47) {
        return outlined destroy of MLActionClassifier.DataSource((uint64_t)&v68);
      }
      uint64_t v92 = v82;
      LOBYTE(v93) = v83;
      outlined destroy of MLActionClassifier.DataSource((uint64_t)&v68);
    }
    goto LABEL_19;
  }
  uint64_t v31 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
  uint64_t v32 = v31[12];
  v73 = *(uint64_t **)((char *)&v68 + v32);
  v79 = *(uint64_t **)((char *)&v68 + v32 + 8);
  uint64_t v33 = v31[16];
  v72 = *(uint64_t **)((char *)&v68 + v33);
  v88 = *(uint64_t **)((char *)&v68 + v33 + 8);
  uint64_t v34 = v31[20];
  uint64_t v35 = v15;
  uint64_t v36 = *(uint64_t *)((char *)&v68 + v34);
  v37 = *(uint64_t **)((char *)&v68 + v34 + 8);
  uint64_t v89 = v35;
  uint64_t v87 = v16;
  (*(void (**)(uint64_t *, uint64_t **))(v16 + 32))(v90, &v68);
  uint64_t v38 = (uint64_t)v84;
  uint64_t v80 = v36;
  v91 = v37;
  v39 = v37;
  uint64_t v40 = (uint64_t)v90;
  DataFrame.subscript.getter(v36, v39);
  uint64_t v41 = (void *)AnyColumn.wrappedElementType.getter();
  v42 = (void (*)(uint64_t, void *))v81[1];
  v42(v38, v86);
  uint64_t v43 = v40;
  if (v41 != &type metadata for String) {
    goto LABEL_6;
  }
  v74 = (void (*)(void, void))v42;
  uint64_t v49 = v70;
  DataFrame.subscript.getter(v80, v91, &type metadata for String);
  uint64_t v50 = (uint64_t)v69;
  uint64_t v51 = v85;
  Column<A>.parseAsJSONArrays()();
  if (v51)
  {
    swift_errorRelease(v51);
    (*(void (**)(uint64_t *, uint64_t))(v75 + 8))(v49, v76);
    __swift_storeEnumTagSinglePayload(v50, 1, 1, (uint64_t)v86);
    uint64_t v52 = v50;
LABEL_14:
    uint64_t v45 = v89;
    uint64_t v85 = 0;
    outlined destroy of AnyColumn?(v52);
    uint64_t v46 = (uint64_t)v77;
    uint64_t v44 = v87;
    uint64_t v43 = (uint64_t)v90;
    goto LABEL_15;
  }
  (*(void (**)(uint64_t *, uint64_t))(v75 + 8))(v49, v76);
  uint64_t v53 = v50;
  uint64_t v52 = v50;
  v54 = v86;
  __swift_storeEnumTagSinglePayload(v53, 0, 1, (uint64_t)v86);
  if (__swift_getEnumTagSinglePayload(v52, 1, (uint64_t)v54) == 1) {
    goto LABEL_14;
  }
  v61 = v71;
  uint64_t v62 = v52;
  uint64_t v63 = (uint64_t)v81;
  ((void (*)(uint64_t *, uint64_t, void *))v81[4])(v71, v62, v54);
  (*(void (**)(uint64_t *, uint64_t *, void *))(v63 + 16))(v84, v61, v54);
  v64 = v91;
  swift_bridgeObjectRetain((_BYTE)v91);
  uint64_t v85 = 0;
  uint64_t v65 = (uint64_t)v90;
  DataFrame.subscript.setter(v84, v80, v64);
  v74(v61, v54);
  uint64_t v43 = v65;
LABEL_6:
  uint64_t v44 = v87;
  uint64_t v45 = v89;
  uint64_t v46 = (uint64_t)v77;
LABEL_15:
  *(double *)a1.i64 = (*(double (**)(uint64_t, uint64_t, uint64_t))(v44 + 16))(v46, v43, v45);
  uint64_t v55 = v85;
  MLDataTable.init(_:convertArraysToShapedArrays:)(v46, 0, a1);
  if (v55)
  {
    (*(void (**)(uint64_t, uint64_t))(v44 + 8))(v43, v45);
    swift_bridgeObjectRelease((_BYTE)v91);
    swift_bridgeObjectRelease((_BYTE)v88);
    return swift_bridgeObjectRelease((_BYTE)v79);
  }
  uint64_t v92 = v82;
  LOBYTE(v93) = v83;
  uint64_t v56 = v80;
  v57 = v91;
  static MLActionClassifier.reformatKeypointsDataTable(table:featureColumn:)(&v92, v80, v91, *(double *)a1.i64);
  char v58 = (char)v79;
  v59 = (void *)v56;
  LOBYTE(v56) = (_BYTE)v88;
  static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)((uint64_t)&v92, (uint64_t)v73, v79, v59, v57, (uint64_t)v72, v88);
  (*(void (**)(uint64_t *, uint64_t))(v87 + 8))(v90, v89);
  swift_bridgeObjectRelease(v58);
  swift_bridgeObjectRelease(v56);
  swift_bridgeObjectRelease((_BYTE)v57);
LABEL_19:
  v66 = v78;
  uint64_t result = v92;
  char v67 = v93;
  void *v78 = v92;
  *((unsigned char *)v66 + 8) = v67;
  return result;
}

uint64_t MLActionClassifier.DataSource.extractKeypoints(targetFrameRate:)(double a1)
{
  uint64_t v100 = v2;
  v105._uint64_t countAndFlagsBits = v3;
  double in = a1;
  uint64_t v91 = v1;
  uint64_t v88 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Data>);
  uint64_t v87 = *(void *)(v88 - 8);
  int64_t v4 = *(void *)(v87 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v92 = &v76;
  uint64_t v86 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v85 = *(void *)(v86 - 8);
  int64_t v7 = *(void *)(v85 + 64);
  v8 = alloca(v7);
  v9 = alloca(v7);
  v79 = &v76;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?)
                              - 8)
                  + 64);
  v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v80 = &v76;
  uint64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  v78 = &v76;
  v103 = (uint64_t *)type metadata accessor for AnyColumn(0);
  uint64_t v97 = *(v103 - 1);
  int64_t v15 = *(void *)(v97 + 64);
  uint64_t v16 = alloca(v15);
  int64_t v17 = alloca(v15);
  v94 = &v76;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  int v93 = &v76;
  uint64_t v20 = alloca(v15);
  v21 = alloca(v15);
  v84 = &v76;
  uint64_t v22 = type metadata accessor for DataFrame(0);
  uint64_t v23 = *(void *)(v22 - 8);
  int64_t v24 = *(void *)(v23 + 64);
  uint64_t v25 = alloca(v24);
  v26 = alloca(v24);
  v99 = &v76;
  uint64_t v27 = type metadata accessor for MLActionClassifier.DataSource(0);
  int64_t v28 = *(void *)(*(void *)(v27 - 8) + 64);
  uint64_t v29 = alloca(v28);
  uint64_t v30 = alloca(v28);
  outlined init with copy of MLActionClassifier.DataSource(v105._countAndFlagsBits, (uint64_t)&v76);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v76, v27);
  if (EnumCaseMultiPayload == 5)
  {
    v37 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
    uint64_t v38 = v37[12];
    uint64_t v82 = *(void **)((char *)&v76 + v38);
    v98 = *(void **)((char *)&v76 + v38 + 8);
    uint64_t v39 = v37[16];
    v81 = *(void **)((char *)&v76 + v39);
    uint64_t v89 = *(void **)((char *)&v76 + v39 + 8);
    uint64_t v40 = v37[20];
    v105._uint64_t countAndFlagsBits = *(uint64_t *)((char *)&v76 + v40);
    double v41 = *(double *)((char *)&v76 + v40 + 8);
    uint64_t v90 = v23;
    v42 = *(void (**)(uint64_t, uint64_t, uint64_t))(v23 + 32);
    uint64_t v95 = v22;
    char v83 = v42;
    v42((uint64_t)v99, (uint64_t)&v76, v22);
    uint64_t v43 = v84;
    double in = v41;
    DataFrame.subscript.getter(v105._countAndFlagsBits, *(void *)&v41);
    uint64_t v44 = (void *)AnyColumn.wrappedElementType.getter();
    uint64_t v45 = *(void (**)(uint64_t *, uint64_t *))(v97 + 8);
    v45(v43, v103);
    v96 = v45;
    if (v44 == &type metadata for String)
    {
      uint64_t v50 = v79;
      DataFrame.subscript.getter(v105._countAndFlagsBits, *(void *)&in, &type metadata for String);
      uint64_t v51 = (uint64_t)v78;
      uint64_t v52 = v100;
      Column<A>.parseAsJSONArrays()();
      if (v52)
      {
        swift_errorRelease(v52);
        (*(void (**)(uint64_t *, uint64_t))(v85 + 8))(v50, v86);
        __swift_storeEnumTagSinglePayload(v51, 1, 1, (uint64_t)v103);
        uint64_t v53 = v51;
      }
      else
      {
        uint64_t v100 = 0;
        (*(void (**)(uint64_t *, uint64_t))(v85 + 8))(v50, v86);
        uint64_t v53 = v51;
        uint64_t v58 = (uint64_t)v103;
        __swift_storeEnumTagSinglePayload(v51, 0, 1, (uint64_t)v103);
        if (__swift_getEnumTagSinglePayload(v51, 1, v58) != 1)
        {
          uint64_t v71 = v97;
          (*(void (**)(uint64_t *, uint64_t, uint64_t))(v97 + 32))(v93, v53, v58);
          v72 = v84;
          (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v71 + 16))(v84, v93, v58);
          double v73 = in;
          swift_bridgeObjectRetain(LOBYTE(in));
          v74 = v72;
          uint64_t countAndFlagsBits = v105._countAndFlagsBits;
          DataFrame.subscript.setter(v74, v105._countAndFlagsBits, *(void *)&v73);
          uint64_t v48 = countAndFlagsBits;
          double v47 = v73;
          v96(v93, v103);
          goto LABEL_21;
        }
      }
      double v47 = in;
      uint64_t v48 = v105._countAndFlagsBits;
      uint64_t v59 = v53;
    }
    else
    {
      DataFrame.subscript.getter(v105._countAndFlagsBits, *(void *)&in);
      uint64_t v46 = (void *)AnyColumn.wrappedElementType.getter();
      v96(v43, v103);
      if (v46 != &type metadata for Data)
      {
        double v47 = in;
        uint64_t v48 = v105._countAndFlagsBits;
LABEL_21:
        v64._uint64_t countAndFlagsBits = v48;
        *(double *)&v64._object = v47;
        uint64_t v65 = v48;
        uint64_t v66 = (uint64_t)v99;
        DataFrame.flattenNestedArrays(in:shape:)(v64, (Swift::OpaquePointer)&outlined read-only object #0 of MLActionClassifier.DataSource.extractKeypoints(targetFrameRate:));
        if (v67)
        {
          (*(void (**)(uint64_t, uint64_t))(v90 + 8))(v66, v95);
          swift_bridgeObjectRelease((_BYTE)v98);
          char v68 = (char)v89;
        }
        else
        {
          uint64_t v69 = v65;
          char v70 = (char)v89;
          static _VideoUtilities.renameFeatureColumns(dataFrame:sessionIdColumn:featureColumn:labelColumn:)(v66, (uint64_t)v82, v98, v69, *(void **)&v47, v81, v89);
          v83(v91, v66, v95);
          swift_bridgeObjectRelease((_BYTE)v98);
          char v68 = v70;
        }
        swift_bridgeObjectRelease(v68);
        char v36 = LOBYTE(v47);
        return swift_bridgeObjectRelease(v36);
      }
      DataFrame.subscript.getter(v105._countAndFlagsBits, *(void *)&in, &type metadata for Data);
      uint64_t v54 = (uint64_t)v80;
      uint64_t v55 = v100;
      Column<A>.parseAsJSONArrays()();
      if (v55)
      {
        swift_errorRelease(v55);
        (*(void (**)(uint64_t *, uint64_t))(v87 + 8))(v92, v88);
        __swift_storeEnumTagSinglePayload(v54, 1, 1, (uint64_t)v103);
        uint64_t v56 = v54;
        double v47 = in;
        uint64_t v48 = v105._countAndFlagsBits;
      }
      else
      {
        (*(void (**)(uint64_t *, uint64_t))(v87 + 8))(v92, v88);
        uint64_t v60 = v54;
        uint64_t v61 = v54;
        uint64_t v62 = (uint64_t)v103;
        __swift_storeEnumTagSinglePayload(v60, 0, 1, (uint64_t)v103);
        int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v61, 1, v62);
        uint64_t v56 = v61;
        double v47 = in;
        uint64_t v48 = v105._countAndFlagsBits;
        if (EnumTagSinglePayload != 1)
        {
          (*(void (**)(uint64_t *, uint64_t, uint64_t *))(v97 + 32))(v94, v56, v103);
          (*(void (**)(uint64_t *, uint64_t *, uint64_t *))(v97 + 16))(v43, v94, v103);
          swift_bridgeObjectRetain(LOBYTE(v47));
          DataFrame.subscript.setter(v43, v48, *(void *)&v47);
          uint64_t v48 = v105._countAndFlagsBits;
          double v47 = in;
          v96(v94, v103);
          goto LABEL_21;
        }
      }
      uint64_t v59 = v56;
    }
    outlined destroy of AnyColumn?(v59);
    goto LABEL_21;
  }
  if (EnumCaseMultiPayload == 3)
  {
    v99 = v78;
    v105._uint64_t countAndFlagsBits = (uint64_t)v79;
    v103 = v80;
    uint64_t v32 = v81;
    uint64_t v33 = v82;
    uint64_t v34 = v83;
    uint64_t v101 = v76;
    LOBYTE(v102) = v77;
    uint64_t v35 = v100;
    static MLActionClassifier.reformatKeypointsDataTable(table:featureColumn:)(&v101, (uint64_t)v82, v83, a1);
    if (!v35)
    {
      static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)((uint64_t)&v101, (uint64_t)v99, (void *)v105._countAndFlagsBits, v33, v34, (uint64_t)v103, v32);
      swift_bridgeObjectRelease((_BYTE)v34);
      swift_bridgeObjectRelease((_BYTE)v32);
      swift_bridgeObjectRelease(v105._countAndFlagsBits);
      uint64_t v76 = v101;
      char v77 = v102;
      return DataFrame.init(_:)((uint64_t)&v76);
    }
    outlined consume of Result<_DataTable, Error>(v101, v102);
    swift_bridgeObjectRelease(v105._countAndFlagsBits);
    swift_bridgeObjectRelease((_BYTE)v32);
    char v36 = (char)v34;
    return swift_bridgeObjectRelease(v36);
  }
  type metadata accessor for MLActionClassifier.FeatureExtractor();
  uint64_t v49 = v100;
  static MLActionClassifier.FeatureExtractor.extractFeatures(from:targetFrameRate:)(v105._countAndFlagsBits, (__m128)*(unint64_t *)&in);
  if (!v49)
  {
    uint64_t v76 = v101;
    char v77 = v102;
    DataFrame.init(_:)((uint64_t)&v76);
  }
  return outlined destroy of MLActionClassifier.DataSource((uint64_t)&v76);
}

uint64_t MLActionClassifier.DataSource.gatherAnnotatedFileNames()()
{
  uint64_t v97 = v1;
  uint64_t v95 = v0;
  v103 = (void *)type metadata accessor for DataFrame(0);
  uint64_t v98 = *(v103 - 1);
  int64_t v3 = *(void *)(v98 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v100 = (uint64_t *)&v91;
  uint64_t v6 = alloca(v3);
  int64_t v7 = alloca(v3);
  v104 = (uint64_t *)&v91;
  int v102 = (void *)type metadata accessor for UTType(0);
  uint64_t v8 = *(v102 - 1);
  int64_t v9 = *(void *)(v8 + 64);
  int64_t v10 = alloca(v9);
  v11 = alloca(v9);
  Swift::String v105 = (uint64_t *)&v91;
  uint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  v96 = (uint64_t *)&v91;
  v107 = (uint64_t *)type metadata accessor for URL(0);
  v108 = (void *)*(v107 - 1);
  int64_t v14 = v108[8];
  int64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v101 = (uint64_t *)&v91;
  int64_t v17 = alloca(v14);
  uint64_t v18 = alloca(v14);
  v106 = (uint64_t *)&v91;
  uint64_t v19 = alloca(v14);
  uint64_t v20 = alloca(v14);
  v99 = (uint64_t *)&v91;
  v21 = alloca(v14);
  uint64_t v22 = alloca(v14);
  v94 = (uint64_t *)&v91;
  uint64_t v23 = type metadata accessor for MLActionClassifier.DataSource(0);
  int64_t v24 = *(void *)(*(void *)(v23 - 8) + 64);
  uint64_t v25 = alloca(v24);
  v26 = alloca(v24);
  int v93 = (uint64_t *)v2;
  outlined init with copy of MLActionClassifier.DataSource(v2, (uint64_t)&v91);
  switch(swift_getEnumCaseMultiPayload(&v91, v23))
  {
    case 0u:
      uint64_t v27 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      int64_t v28 = (uint64_t **)((char *)&v91 + v27[12]);
      uint64_t v29 = v27[16];
      uint64_t v100 = *(uint64_t **)((char *)&v91 + v29);
      int v102 = *(uint64_t **)((char *)&v91 + v29 + 8);
      uint64_t v30 = v27[20];
      v104 = *(uint64_t **)((char *)&v91 + v30);
      Swift::String v105 = *(uint64_t **)((char *)&v91 + v30 + 8);
      uint64_t v31 = v27[24];
      uint64_t v98 = *(uint64_t *)((char *)&v91 + v31);
      v96 = *(uint64_t **)((char *)&v91 + v31 + 8);
      uint64_t v32 = v27[28];
      v99 = *(uint64_t **)((char *)&v91 + v32);
      v103 = *(uint64_t **)((char *)&v91 + v32 + 8);
      uint64_t v33 = (void (*)(uint64_t *, uint64_t **, uint64_t *))v108[4];
      uint64_t v34 = v107;
      v33(v106, &v91, v107);
      uint64_t v35 = (uint64_t)v101;
      char v36 = v34;
      v37 = v102;
      v33(v101, v28, v36);
      LOBYTE(v33) = (_BYTE)v96;
      uint64_t v38 = v35;
      LOBYTE(v35) = (_BYTE)v105;
      MLActionClassifier.DataSource.gatherAnnotatedFileNamesForDirectory(url:annotationFile:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v106, v38, (uint64_t)v100, v37, (uint64_t)v104, v105, v98, v96, (uint64_t)v99, v103);
      swift_bridgeObjectRelease(v35);
      swift_bridgeObjectRelease((_BYTE)v37);
      swift_bridgeObjectRelease((_BYTE)v33);
      swift_bridgeObjectRelease((_BYTE)v103);
      uint64_t v39 = (void (*)(uint64_t *, uint64_t *))v108[1];
      uint64_t v40 = v107;
      v39(v101, v107);
      return ((uint64_t (*)(uint64_t *, uint64_t *))v39)(v106, v40);
    case 1u:
      uint64_t v42 = (uint64_t)v99;
      ((void (*)(uint64_t *, uint64_t **, uint64_t *))v108[4])(v99, &v91, v107);
      uint64_t v43 = v105;
      static UTType.movie.getter();
      uint64_t v44 = v97;
      uint64_t v45 = static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)(v42, (uint64_t)v43);
      if (v44)
      {
        (*(void (**)(uint64_t *, void *))(v8 + 8))(v105, v102);
        uint64_t v46 = (uint64_t)v99;
        return ((uint64_t (*)(uint64_t, uint64_t *))v108[1])(v46, v107);
      }
      uint64_t v81 = (uint64_t)v45;
      (*(void (**)(uint64_t *, void *))(v8 + 8))(v105, v102);
      uint64_t v82 = specialized _NativeDictionary.mapValues<A>(_:)(v81);
      swift_bridgeObjectRelease(v81);
      uint64_t v83 = v95;
      specialized DataFrame.init<A>(expanding:keysColumnName:valuesColumnName:)((uint64_t)v82, 0x6C6562616CLL, (uint64_t *)0xE500000000000000, (void *)0x7461506F65646976, 0xE900000000000068);
      uint64_t v84 = (uint64_t)v99;
      goto LABEL_20;
    case 2u:
      uint64_t v47 = (uint64_t)v94;
      ((void (*)(uint64_t *, uint64_t **, uint64_t *))v108[4])(v94, &v91, v107);
      uint64_t v48 = v96;
      static UTType.movie.getter();
      uint64_t v49 = v97;
      uint64_t v50 = static _FileUtilities.collectFilesLabeledByFileName(at:type:)(v47, (uint64_t)v48);
      if (v49)
      {
        (*(void (**)(uint64_t *, void *))(v8 + 8))(v96, v102);
        uint64_t v46 = (uint64_t)v94;
        return ((uint64_t (*)(uint64_t, uint64_t *))v108[1])(v46, v107);
      }
      uint64_t v85 = v50;
      (*(void (**)(uint64_t *, void *))(v8 + 8))(v96, v102);
      uint64_t v86 = specialized _NativeDictionary.mapValues<A>(_:)(v85);
      swift_bridgeObjectRelease(v85);
      uint64_t v83 = v95;
      specialized DataFrame.init<A>(expanding:keysColumnName:valuesColumnName:)((uint64_t)v86, 0x6C6562616CLL, (uint64_t *)0xE500000000000000, (void *)0x7461506F65646976, 0xE900000000000068);
      uint64_t v84 = (uint64_t)v94;
LABEL_20:
      ((void (*)(uint64_t, uint64_t *))v108[1])(v84, v107);
      uint64_t v54 = v83;
      uint64_t v89 = 0;
      uint64_t v55 = (uint64_t)v103;
      return __swift_storeEnumTagSinglePayload(v54, v89, 1, v55);
    case 3u:
      char v51 = (char)v94;
      char v52 = (char)v96;
      char v53 = v98;
      outlined consume of Result<_DataTable, Error>((uint64_t)v91, v92);
      swift_bridgeObjectRelease(v53);
      swift_bridgeObjectRelease(v52);
      swift_bridgeObjectRelease(v51);
      uint64_t v54 = v95;
      uint64_t v55 = (uint64_t)v103;
      goto LABEL_13;
    case 4u:
      int v56 = v92;
      v99 = v93;
      v96 = v94;
      uint64_t v57 = v95;
      uint64_t v58 = v94;
      int v102 = v97;
      v108 = (void *)v98;
      uint64_t v100 = v93;
      v107 = v93;
      LOBYTE(v92) = v92 & 1;
      uint64_t v101 = v91;
      LODWORD(v105) = v56;
      outlined copy of Result<_DataTable, Error>((uint64_t)v91, v56);
      uint64_t v59 = v104;
      DataFrame.init(_:)((uint64_t)&v91);
      uint64_t v60 = (uint64_t)v59;
      uint64_t v61 = v96;
      uint64_t v62 = (uint64_t)v99;
      v94 = (uint64_t *)v57;
      uint64_t v63 = v57;
      v106 = v58;
      Swift::String v64 = (void (*)(void, void, void))v102;
      uint64_t v65 = v97;
      static _VideoUtilities.validateVideoInput(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(v60, (uint64_t)v99, v96, v63, v58, (uint64_t)v102, (uint64_t)v108, (uint64_t)v100, (uint64_t)v107);
      if (!v65)
      {
        static _VideoUtilities.renameVideoColumns(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v104, v62, v61, (uint64_t)v94, v106, (uint64_t)v64, v108, (uint64_t)v100, v107);
        outlined consume of Result<_DataTable, Error>((uint64_t)v101, (char)v105);
        swift_bridgeObjectRelease((_BYTE)v106);
        swift_bridgeObjectRelease((_BYTE)v61);
        swift_bridgeObjectRelease((_BYTE)v108);
        swift_bridgeObjectRelease((_BYTE)v107);
        uint64_t v87 = v95;
        uint64_t v88 = v103;
        (*(void (**)(uint64_t, uint64_t *, void *))(v98 + 32))(v95, v104, v103);
        uint64_t v54 = v87;
        uint64_t v89 = 0;
        uint64_t v55 = (uint64_t)v88;
        return __swift_storeEnumTagSinglePayload(v54, v89, 1, v55);
      }
      (*(void (**)(uint64_t *, void *))(v98 + 8))(v104, v103);
      outlined consume of Result<_DataTable, Error>((uint64_t)v101, (char)v105);
      swift_bridgeObjectRelease((_BYTE)v106);
      swift_bridgeObjectRelease((_BYTE)v61);
      swift_bridgeObjectRelease((_BYTE)v108);
      char v66 = (char)v107;
      return swift_bridgeObjectRelease(v66);
    case 5u:
      uint64_t v67 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      swift_bridgeObjectRelease(*(uint64_t **)((char *)&v91 + v67[12] + 8));
      swift_bridgeObjectRelease(*(uint64_t **)((char *)&v91 + v67[16] + 8));
      swift_bridgeObjectRelease(*(uint64_t **)((char *)&v91 + v67[20] + 8));
      char v68 = v103;
      (*(void (**)(uint64_t **, void *))(v98 + 8))(&v91, v103);
      uint64_t v54 = v95;
      uint64_t v55 = (uint64_t)v68;
LABEL_13:
      uint64_t v89 = 1;
      return __swift_storeEnumTagSinglePayload(v54, v89, 1, v55);
    case 6u:
      uint64_t v69 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      uint64_t v70 = v69[12];
      uint64_t v101 = *(uint64_t **)((char *)&v91 + v70);
      v107 = *(uint64_t **)((char *)&v91 + v70 + 8);
      uint64_t v71 = v69[16];
      Swift::String v105 = *(uint64_t **)((char *)&v91 + v71);
      v72 = *(uint64_t **)((char *)&v91 + v71 + 8);
      uint64_t v73 = v69[20];
      v99 = *(uint64_t **)((char *)&v91 + v73);
      v108 = *(uint64_t **)((char *)&v91 + v73 + 8);
      uint64_t v74 = v69[24];
      uint64_t v75 = *(void (**)(void, void, void))((char *)&v91 + v74);
      v106 = *(uint64_t **)((char *)&v91 + v74 + 8);
      uint64_t v76 = (uint64_t)v100;
      char v77 = v103;
      int v102 = *(void **)(v98 + 32);
      ((void (*)(uint64_t *, uint64_t **, void *))v102)(v100, &v91, v103);
      uint64_t v78 = v76;
      uint64_t v79 = (uint64_t)v99;
      v104 = v72;
      uint64_t v80 = v97;
      uint64_t v97 = v75;
      static _VideoUtilities.validateVideoInput(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(v78, (uint64_t)v101, v107, (uint64_t)v105, v72, (uint64_t)v99, (uint64_t)v108, (uint64_t)v75, (uint64_t)v106);
      if (v80)
      {
        (*(void (**)(uint64_t *, void *))(v98 + 8))(v100, v77);
        swift_bridgeObjectRelease((_BYTE)v107);
        swift_bridgeObjectRelease((_BYTE)v104);
        swift_bridgeObjectRelease((_BYTE)v106);
        char v66 = (char)v108;
        return swift_bridgeObjectRelease(v66);
      }
      else
      {
        static _VideoUtilities.renameVideoColumns(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v100, (uint64_t)v101, v107, (uint64_t)v105, v104, v79, v108, (uint64_t)v97, v106);
        swift_bridgeObjectRelease((_BYTE)v104);
        swift_bridgeObjectRelease((_BYTE)v107);
        swift_bridgeObjectRelease((_BYTE)v108);
        swift_bridgeObjectRelease((_BYTE)v106);
        uint64_t v90 = v95;
        ((void (*)(uint64_t, uint64_t *, void *))v102)(v95, v100, v77);
        uint64_t v54 = v90;
        uint64_t v89 = 0;
        uint64_t v55 = (uint64_t)v77;
        return __swift_storeEnumTagSinglePayload(v54, v89, 1, v55);
      }
  }
}

uint64_t MLActionClassifier.DataSource.gatherAnnotatedFileNamesForDirectory(url:annotationFile:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, uint64_t a5, void *a6, uint64_t a7, void *a8, uint64_t a9, void *a10)
{
  uint64_t v130 = v10;
  uint64_t v153 = a2;
  uint64_t v131 = v11;
  uint64_t v123 = a1;
  uint64_t v124 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v125 = *(void *)(v124 - 8);
  int64_t v16 = *(void *)(v125 + 64);
  int64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  v126 = v121;
  uint64_t v134 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  uint64_t v133 = *(void *)(v134 - 8);
  int64_t v19 = *(void *)(v133 + 64);
  uint64_t v20 = alloca(v19);
  v21 = alloca(v19);
  v138 = v121;
  uint64_t v127 = type metadata accessor for CSVType(0);
  uint64_t v129 = *(void *)(v127 - 8);
  int64_t v22 = *(void *)(v129 + 64);
  uint64_t v23 = alloca(v22);
  int64_t v24 = alloca(v22);
  v141 = v121;
  int64_t v25 = *(void *)(*(void *)(type metadata accessor for CSVReadingOptions(0) - 8) + 64);
  v26 = alloca(v25);
  uint64_t v27 = alloca(v25);
  v140 = v121;
  int64_t v28 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CSVType?)
                              - 8)
                  + 64);
  uint64_t v29 = alloca(v28);
  uint64_t v30 = alloca(v28);
  uint64_t v146 = (uint64_t)v121;
  int64_t v31 = *(void *)(*(void *)(type metadata accessor for JSONReadingOptions(0) - 8) + 64);
  uint64_t v32 = alloca(v31);
  uint64_t v33 = alloca(v31);
  v151 = v121;
  uint64_t v132 = type metadata accessor for URL(0);
  v144 = *(void **)(v132 - 8);
  int64_t v34 = v144[8];
  uint64_t v35 = alloca(v34);
  char v36 = alloca(v34);
  v152 = v121;
  v37 = alloca(v34);
  uint64_t v38 = alloca(v34);
  v150 = v121;
  int64_t v39 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for JSONType?)
                              - 8)
                  + 64);
  uint64_t v40 = alloca(v39);
  double v41 = alloca(v39);
  v122 = v121;
  uint64_t v145 = type metadata accessor for DataFrame(0);
  uint64_t v139 = *(void *)(v145 - 8);
  int64_t v42 = *(void *)(v139 + 64);
  uint64_t v43 = alloca(v42);
  uint64_t v44 = alloca(v42);
  v128 = v121;
  uint64_t v45 = alloca(v42);
  uint64_t v46 = alloca(v42);
  v137 = v121;
  uint64_t v47 = alloca(v42);
  uint64_t v48 = alloca(v42);
  v147 = v121;
  uint64_t v49 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t v50 = (void *)swift_allocObject(v49, 64, 7);
  v50[2] = 2;
  v50[3] = 4;
  uint64_t v143 = a3;
  v50[4] = a3;
  char v51 = v50;
  v50[5] = a4;
  uint64_t v136 = a5;
  v50[6] = a5;
  v50[7] = a6;
  v135 = a6;
  swift_bridgeObjectRetain((_BYTE)a4);
  swift_bridgeObjectRetain((_BYTE)a6);
  if (a8)
  {
    swift_bridgeObjectRetain((_BYTE)a8);
    unint64_t v52 = 3;
    char v51 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(1, 3, 1, (uint64_t)v51);
    v51[2] = 3;
    v51[8] = a7;
    v51[9] = a8;
  }
  else
  {
    unint64_t v52 = 2;
  }
  v148 = a4;
  if (a10)
  {
    v149 = v51;
    unint64_t v53 = v51[3];
    swift_bridgeObjectRetain((_BYTE)a10);
    if (v53 >> 1 <= v52) {
      char v51 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v53 >= 2, v52 + 1, 1, (uint64_t)v149);
    }
    else {
      char v51 = v149;
    }
    v51[2] = v52 + 1;
    uint64_t v54 = 2 * v52;
    v51[v54 + 4] = a9;
    v51[v54 + 5] = a10;
  }
  v149 = v51;
  uint64_t v55 = URL.pathExtension.getter();
  char v57 = v56;
  if (v55 == 1852797802 && v56 == 0xE400000000000000)
  {
    swift_bridgeObjectRelease(0);
LABEL_12:
    uint64_t v59 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, JSONType)>);
    uint64_t v60 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, JSONType));
    uint64_t v61 = *(void *)(v60 - 8);
    v141 = (char *)v60;
    uint64_t v146 = *(void *)(v61 + 72);
    uint64_t v62 = *(unsigned __int8 *)(v61 + 80);
    uint64_t v63 = ((int)v62 + 32) & ~*(unsigned __int8 *)(v61 + 80);
    uint64_t v64 = swift_allocObject(v59, v63 + 2 * v146, v62 | 7);
    *(void *)(v64 + 16) = 2;
    *(void *)(v64 + 24) = 4;
    v140 = (char *)(v63 + v64);
    uint64_t v65 = v63 + v64 + *(int *)(v60 + 48);
    *(void *)(v64 + v63) = v143;
    *(void *)(v64 + v63 + 8) = v148;
    LODWORD(v152) = enum case for JSONType.string(_:);
    uint64_t v66 = type metadata accessor for JSONType(0);
    uint64_t v67 = *(unsigned char **)(*(void *)(v66 - 8) + 104);
    ((void (*)(uint64_t, void, uint64_t))v67)(v65, v152, v66);
    uint64_t v68 = v146;
    uint64_t v69 = v140;
    uint64_t v70 = &v140[v146 + *((int *)v141 + 12)];
    *(void *)&v140[v146] = v136;
    LOBYTE(v65) = (_BYTE)v135;
    *(void *)&v69[v68 + 8] = v135;
    uint64_t v71 = v152;
    v152 = v67;
    ((void (*)(char *, uint64_t, uint64_t))v67)(v70, v71, v66);
    swift_bridgeObjectRetain((_BYTE)v148);
    swift_bridgeObjectRetain(v65);
    v142[0] = Dictionary.init(dictionaryLiteral:)(v64, &type metadata for String, v66, &protocol witness table for String);
    uint64_t v72 = (uint64_t)v122;
    if (a8)
    {
      ((void (*)(char *, void, uint64_t))v152)(v122, enum case for JSONType.double(_:), v66);
      __swift_storeEnumTagSinglePayload(v72, 0, 1, v66);
      swift_bridgeObjectRetain((_BYTE)a8);
      specialized Dictionary.subscript.setter(v72, a7, (uint64_t)a8);
    }
    uint64_t v73 = v152;
    if (a10)
    {
      ((void (*)(uint64_t, void, uint64_t))v152)(v72, enum case for JSONType.double(_:), v66);
      __swift_storeEnumTagSinglePayload(v72, 0, 1, v66);
      swift_bridgeObjectRetain((_BYTE)a10);
      specialized Dictionary.subscript.setter(v72, a9, (uint64_t)a10);
    }
    uint64_t v74 = v150;
    ((void (*)(char *, uint64_t, uint64_t, char *))v144[2])(v150, v153, v132, v73);
    uint64_t v153 = v142[0];
    uint64_t v75 = (uint64_t)v149;
    swift_bridgeObjectRetain((_BYTE)v149);
    uint64_t v76 = v151;
    JSONReadingOptions.init()();
    char v77 = v137;
    uint64_t v78 = v131;
    DataFrame.init(contentsOfJSONFile:columns:types:options:)(v74, v75, v153, v76);
    goto LABEL_22;
  }
  char v58 = _stringCompareWithSmolCheck(_:_:expecting:)(v55, v56, 1852797802, 0xE400000000000000, 0);
  swift_bridgeObjectRelease(v57);
  if (v58) {
    goto LABEL_12;
  }
  uint64_t v79 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, CSVType)>);
  uint64_t v80 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, CSVType));
  uint64_t v81 = *(void *)(v80 - 8);
  uint64_t v82 = v80;
  v150 = (char *)v80;
  v151 = *(char **)(v81 + 72);
  uint64_t v83 = *(unsigned __int8 *)(v81 + 80);
  uint64_t v84 = ((int)v83 + 32) & ~*(unsigned __int8 *)(v81 + 80);
  uint64_t v85 = swift_allocObject(v79, v84 + 2 * (void)v151, v83 | 7);
  *(void *)(v85 + 16) = 2;
  *(void *)(v85 + 24) = 4;
  uint64_t v86 = v85 + v84;
  uint64_t v87 = v85 + v84 + *(int *)(v82 + 48);
  *(void *)(v85 + v84) = v143;
  *(void *)(v85 + v84 + 8) = v148;
  LODWORD(v137) = enum case for CSVType.string(_:);
  uint64_t v88 = *(unsigned char **)(v129 + 104);
  uint64_t v89 = v127;
  ((void (*)(uint64_t, void, uint64_t))v88)(v87, enum case for CSVType.string(_:), v127);
  uint64_t v90 = v151;
  uint64_t v91 = &v151[*((int *)v150 + 12) + v86];
  *(void *)&v151[v86] = v136;
  char v92 = (char)v135;
  *(void *)&v90[v86 + 8] = v135;
  LOBYTE(v86) = v92;
  v151 = v88;
  ((void (*)(char *, void, uint64_t))v88)(v91, v137, v89);
  swift_bridgeObjectRetain((_BYTE)v148);
  swift_bridgeObjectRetain(v86);
  v142[0] = Dictionary.init(dictionaryLiteral:)(v85, &type metadata for String, v89, &protocol witness table for String);
  unsigned int v93 = enum case for CSVType.double(_:);
  if (a8)
  {
    uint64_t v94 = v146;
    ((void (*)(uint64_t, void, uint64_t))v151)(v146, enum case for CSVType.double(_:), v89);
    __swift_storeEnumTagSinglePayload(v94, 0, 1, v89);
    swift_bridgeObjectRetain((_BYTE)a8);
    specialized Dictionary.subscript.setter(v94, a7, (uint64_t)a8);
  }
  LODWORD(v150) = v93;
  uint64_t v95 = (uint64_t)v149;
  if (a10)
  {
    uint64_t v96 = v146;
    ((void (*)(uint64_t, void, uint64_t))v151)(v146, v150, v89);
    __swift_storeEnumTagSinglePayload(v96, 0, 1, v89);
    swift_bridgeObjectRetain((_BYTE)a10);
    specialized Dictionary.subscript.setter(v96, a9, (uint64_t)a10);
  }
  ((void (*)(char *, uint64_t, uint64_t))v144[2])(v152, v153, v132);
  uint64_t v153 = v142[0];
  swift_bridgeObjectRetain(v95);
  v144 = default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
  uint64_t v97 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 2 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
  uint64_t v98 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 3 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
  uint64_t v99 = v89;
  uint64_t v100 = v141;
  ((void (*)(char *, void, uint64_t))v151)(v141, v150, v99);
  uint64_t v101 = v95;
  int v102 = v140;
  v103 = v97;
  uint64_t v75 = v101;
  CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)(1, v144, v103, v98, v100, 1, 1, 0, 44, 0xE100000000000000, 92, 0xE100000000000000);
  char v77 = v128;
  uint64_t v78 = v131;
  DataFrame.init(contentsOfCSVFile:columns:rows:types:options:)(v152, v75, 0, 0, 1, v153, v102);
LABEL_22:
  if (v78) {
    return swift_bridgeObjectRelease(v75);
  }
  uint64_t v153 = 0;
  v152 = *(char **)(v139 + 32);
  ((void (*)(char *, char *, uint64_t))v152)(v147, v77, v145);
  Swift::String v105 = v126;
  DataFrame.subscript.getter(v143, v148, &type metadata for String);
  v142[0] = 0;
  v142[1] = 0xE000000000000000;
  uint64_t v106 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v107 = v124;
  OptionalColumnProtocol.filled(with:)(v142, v124, v106);
  (*(void (**)(char *, uint64_t))(v125 + 8))(v105, v107);
  v108 = alloca(24);
  v109 = alloca(32);
  uint64_t v110 = v153;
  v111 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lF11TabularData12FilledColumnVyAF0G0VySSGG_SSSgs5NeverOTg5((void (*)(void *))partial apply for closure #3 in MLObjectDetector.DataSource.gatherAnnotatedFileNames(), (uint64_t)v121);
  uint64_t v153 = v110;
  swift_bridgeObjectRelease((_BYTE)v149);
  v112 = v148;
  swift_bridgeObjectRetain((_BYTE)v148);
  v113 = v111;
  uint64_t v114 = v143;
  v115 = v112;
  DataFrame.subscript.setter(v113, v143, v112, &type metadata for String, &type metadata for String);
  uint64_t v116 = (uint64_t)v147;
  uint64_t v117 = v153;
  static _VideoUtilities.renameVideoColumns(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v147, v114, v115, v136, v135, a7, a8, a9, a10);
  (*(void (**)(char *, uint64_t))(v133 + 8))(v138, v134);
  if (v117) {
    return (*(uint64_t (**)(uint64_t, uint64_t))(v139 + 8))(v116, v145);
  }
  uint64_t v118 = v130;
  uint64_t v119 = v116;
  uint64_t v120 = v145;
  ((void (*)(uint64_t, uint64_t, uint64_t))v152)(v130, v119, v145);
  return __swift_storeEnumTagSinglePayload(v118, 0, 1, v120);
}

uint64_t MLActionClassifier.DataSource.stratifiedSplit(proportions:seed:labelColumn:)(void *a1, uint64_t a2, uint64_t a3, void *a4, __m128 a5)
{
  uint64_t v8 = v6;
  int64_t v34 = a4;
  v35._uint64_t countAndFlagsBits = a3;
  uint64_t v39 = a2;
  v35._object = a1;
  uint64_t v36 = v5;
  uint64_t v9 = type metadata accessor for MLActionClassifier.DataSource(0);
  int64_t v10 = *(void *)(*(void *)(v9 - 8) + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  outlined init with copy of MLActionClassifier.DataSource(v7, (uint64_t)&v32);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v32, v9);
  if (EnumCaseMultiPayload == 5)
  {
    int64_t v17 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
    uint64_t v18 = v17[12];
    *(void *)v37 = *(uint64_t *)((char *)&v32 + v18);
    *(void *)int64_t v42 = *(uint64_t *)((char *)&v32 + v18 + 8);
    swift_bridgeObjectRelease(*(uint64_t *)((char *)&v32 + v17[16] + 8));
    swift_bridgeObjectRelease(*(uint64_t *)((char *)&v32 + v17[20] + 8));
    uint64_t v19 = type metadata accessor for DataFrame(0);
    (*(void (**)(uint64_t *, uint64_t))(*(void *)(v19 - 8) + 8))(&v32, v19);
LABEL_5:
    MLActionClassifier.DataSource.keypointsWithAnnotations(targetFrameRate:)((__m128)0x403E000000000000uLL);
    if (v8) {
      return swift_bridgeObjectRelease(v42[0]);
    }
    uint64_t v21 = v39;
    if (v39 >= 0)
    {
      int64_t v22 = v40;
      uint64_t v33 = v40;
      LOBYTE(v38) = v41;
      uint64_t v23 = type metadata accessor for MersenneTwisterGenerator();
      swift_allocObject(v23, 136, 7);
      uint64_t v40 = MersenneTwisterGenerator.init(seed:)(v21);
      char v24 = v38;
      uint64_t v25 = (uint64_t)v22;
      LOBYTE(v22) = v42[0];
      v31._object = v34;
      v31._uint64_t countAndFlagsBits = v35._countAndFlagsBits;
      specialized stratifiedSplitBySequenceGenerator<A>(proportions:generator:dataTable:by:on:)((uint64_t)v35._object, (uint64_t)&v40, v25, v38, *(uint64_t *)v37, *(void **)v42, 30.0, v31);
      swift_bridgeObjectRelease((_BYTE)v22);
      swift_release();
      return outlined consume of Result<_DataTable, Error>((uint64_t)v33, v24);
    }
LABEL_13:
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, "Negative value is not representable", 35, 2, "Swift/Integers.swift", 20, 2, 3451, 1);
    BUG();
  }
  if (EnumCaseMultiPayload == 3)
  {
    uint64_t v38 = v32;
    *(void *)v37 = v34;
    *(void *)int64_t v42 = v35._countAndFlagsBits;
    char v14 = v32;
    char v15 = (char)v33;
    swift_bridgeObjectRelease(v36);
    char v16 = v14;
    uint64_t v8 = v6;
    swift_bridgeObjectRelease(v16);
    outlined consume of Result<_DataTable, Error>(v38, v15);
    goto LABEL_5;
  }
  MLActionClassifier.DataSource.videosWithAnnotations()(a5);
  if (v6) {
    return outlined destroy of MLActionClassifier.DataSource((uint64_t)&v32);
  }
  uint64_t v26 = v39;
  if (v39 < 0) {
    goto LABEL_13;
  }
  *(void *)int64_t v42 = v40;
  unsigned __int8 v27 = v41;
  uint64_t v28 = type metadata accessor for MersenneTwisterGenerator();
  swift_allocObject(v28, 136, 7);
  uint64_t v40 = MersenneTwisterGenerator.init(seed:)(v26);
  int v29 = v27;
  LODWORD(v39) = v27;
  uint64_t v30 = *(void **)v42;
  specialized stratifiedSplitGenerator<A>(proportions:generator:dataTable:on:)((uint64_t)v35._object, (uint64_t)&v40, *(void **)v42, v29, v35._countAndFlagsBits, v34, *(double *)a5.i64);
  swift_release();
  outlined consume of Result<_DataTable, Error>((uint64_t)v30, v39);
  return outlined destroy of MLActionClassifier.DataSource((uint64_t)&v32);
}

uint64_t outlined destroy of MLActionClassifier.DataSource(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLActionClassifier.DataSource(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t assignWithCopy for MLActionClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLActionClassifier.DataSource(a1);
    switch(swift_getEnumCaseMultiPayload(a2, a3))
    {
      case 0u:
        uint64_t v5 = type metadata accessor for URL(0);
        uint64_t v50 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16);
        v50(a1, a2, v5);
        uint64_t v6 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v50(a1 + v6[12], a2 + v6[12], v5);
        uint64_t v7 = v6[16];
        *(void *)(a1 + v7) = *(void *)(a2 + v7);
        uint64_t v8 = *(void *)(a2 + v7 + 8);
        *(void *)(a1 + v7 + 8) = v8;
        uint64_t v9 = v6[20];
        *(void *)(a1 + v9) = *(void *)(a2 + v9);
        uint64_t v51 = *(void *)(a2 + v9 + 8);
        *(void *)(a1 + v9 + 8) = v51;
        uint64_t v10 = v6[24];
        *(void *)(a1 + v10) = *(void *)(a2 + v10);
        uint64_t v11 = *(void *)(a2 + v10 + 8);
        *(void *)(a1 + v10 + 8) = v11;
        uint64_t v12 = v6[28];
        *(void *)(a1 + v12) = *(void *)(a2 + v12);
        uint64_t v13 = *(void *)(a2 + v12 + 8);
        *(void *)(a1 + v12 + 8) = v13;
        swift_bridgeObjectRetain(v8);
        swift_bridgeObjectRetain(v51);
        swift_bridgeObjectRetain(v11);
        swift_bridgeObjectRetain(v13);
        uint64_t v14 = a1;
        uint64_t v15 = a3;
        uint64_t v16 = 0;
        goto LABEL_11;
      case 1u:
        uint64_t v17 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v17 - 8) + 16))(a1, a2, v17);
        uint64_t v49 = 1;
        goto LABEL_10;
      case 2u:
        uint64_t v18 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v18 - 8) + 16))(a1, a2, v18);
        uint64_t v49 = 2;
        goto LABEL_10;
      case 3u:
        uint64_t v19 = *(void *)a2;
        char v20 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(void *)a2, v20);
        *(void *)a1 = v19;
        *(unsigned char *)(a1 + 8) = v20;
        *(void *)(a1 + 16) = *(void *)(a2 + 16);
        uint64_t v21 = *(void *)(a2 + 24);
        *(void *)(a1 + 24) = v21;
        *(void *)(a1 + 32) = *(void *)(a2 + 32);
        uint64_t v22 = *(void *)(a2 + 40);
        *(void *)(a1 + 40) = v22;
        *(void *)(a1 + 48) = *(void *)(a2 + 48);
        uint64_t v23 = *(void *)(a2 + 56);
        *(void *)(a1 + 56) = v23;
        swift_bridgeObjectRetain(v21);
        swift_bridgeObjectRetain(v22);
        swift_bridgeObjectRetain(v23);
        uint64_t v49 = 3;
        goto LABEL_10;
      case 4u:
        uint64_t v24 = *(void *)a2;
        char v25 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(void *)a2, v25);
        *(void *)a1 = v24;
        *(unsigned char *)(a1 + 8) = v25;
        *(void *)(a1 + 16) = *(void *)(a2 + 16);
        uint64_t v26 = *(void *)(a2 + 24);
        *(void *)(a1 + 24) = v26;
        *(void *)(a1 + 32) = *(void *)(a2 + 32);
        uint64_t v27 = *(void *)(a2 + 40);
        *(void *)(a1 + 40) = v27;
        *(void *)(a1 + 48) = *(void *)(a2 + 48);
        uint64_t v28 = *(void *)(a2 + 56);
        *(void *)(a1 + 56) = v28;
        *(void *)(a1 + 64) = *(void *)(a2 + 64);
        uint64_t v29 = *(void *)(a2 + 72);
        *(void *)(a1 + 72) = v29;
        swift_bridgeObjectRetain(v26);
        swift_bridgeObjectRetain(v27);
        swift_bridgeObjectRetain(v28);
        swift_bridgeObjectRetain(v29);
        uint64_t v49 = 4;
        goto LABEL_10;
      case 5u:
        uint64_t v30 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v30 - 8) + 16))(a1, a2, v30);
        Swift::String v31 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v32 = v31[12];
        *(void *)(a1 + v32) = *(void *)(a2 + v32);
        uint64_t v33 = *(void *)(a2 + v32 + 8);
        *(void *)(a1 + v32 + 8) = v33;
        uint64_t v34 = v31[16];
        *(void *)(a1 + v34) = *(void *)(a2 + v34);
        uint64_t v35 = *(void *)(a2 + v34 + 8);
        *(void *)(a1 + v34 + 8) = v35;
        uint64_t v36 = v31[20];
        *(void *)(a1 + v36) = *(void *)(a2 + v36);
        uint64_t v37 = *(void *)(a2 + v36 + 8);
        *(void *)(a1 + v36 + 8) = v37;
        swift_bridgeObjectRetain(v33);
        swift_bridgeObjectRetain(v35);
        swift_bridgeObjectRetain(v37);
        uint64_t v49 = 5;
        goto LABEL_10;
      case 6u:
        uint64_t v38 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v38 - 8) + 16))(a1, a2, v38);
        uint64_t v39 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        uint64_t v40 = v39[12];
        *(void *)(a1 + v40) = *(void *)(a2 + v40);
        uint64_t v41 = *(void *)(a2 + v40 + 8);
        *(void *)(a1 + v40 + 8) = v41;
        uint64_t v42 = v39[16];
        *(void *)(a1 + v42) = *(void *)(a2 + v42);
        uint64_t v43 = *(void *)(a2 + v42 + 8);
        *(void *)(a1 + v42 + 8) = v43;
        uint64_t v44 = v39[20];
        *(void *)(a1 + v44) = *(void *)(a2 + v44);
        uint64_t v45 = *(void *)(a2 + v44 + 8);
        *(void *)(a1 + v44 + 8) = v45;
        uint64_t v46 = v39[24];
        *(void *)(a1 + v46) = *(void *)(a2 + v46);
        uint64_t v47 = *(void *)(a2 + v46 + 8);
        *(void *)(a1 + v46 + 8) = v47;
        swift_bridgeObjectRetain(v41);
        swift_bridgeObjectRetain(v43);
        swift_bridgeObjectRetain(v45);
        swift_bridgeObjectRetain(v47);
        uint64_t v49 = 6;
LABEL_10:
        uint64_t v16 = v49;
        uint64_t v14 = a1;
        uint64_t v15 = a3;
LABEL_11:
        swift_storeEnumTagMultiPayload(v14, v15, v16);
        break;
    }
  }
  return a1;
}

char *assignWithTake for MLActionClassifier.DataSource(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActionClassifier.DataSource((uint64_t)__dst);
    switch(swift_getEnumCaseMultiPayload(__src, a3))
    {
      case 0u:
        uint64_t v4 = type metadata accessor for URL(0);
        uint64_t v16 = *(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 32);
        v16(__dst, __src, v4);
        uint64_t v5 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v16(&__dst[v5[12]], &__src[v5[12]], v4);
        *(_OWORD *)&__dst[v5[16]] = *(_OWORD *)&__src[v5[16]];
        *(_OWORD *)&__dst[v5[20]] = *(_OWORD *)&__src[v5[20]];
        *(_OWORD *)&__dst[v5[24]] = *(_OWORD *)&__src[v5[24]];
        *(_OWORD *)&__dst[v5[28]] = *(_OWORD *)&__src[v5[28]];
        uint64_t v6 = a3;
        uint64_t v7 = 0;
        goto LABEL_10;
      case 1u:
        uint64_t v8 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
        uint64_t v15 = 1;
        goto LABEL_9;
      case 2u:
        uint64_t v9 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
        uint64_t v15 = 2;
        goto LABEL_9;
      case 5u:
        uint64_t v10 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
        uint64_t v11 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        *(_OWORD *)&__dst[v11[12]] = *(_OWORD *)&__src[v11[12]];
        *(_OWORD *)&__dst[v11[16]] = *(_OWORD *)&__src[v11[16]];
        *(_OWORD *)&__dst[v11[20]] = *(_OWORD *)&__src[v11[20]];
        uint64_t v15 = 5;
        goto LABEL_9;
      case 6u:
        uint64_t v12 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
        uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        *(_OWORD *)&__dst[v13[12]] = *(_OWORD *)&__src[v13[12]];
        *(_OWORD *)&__dst[v13[16]] = *(_OWORD *)&__src[v13[16]];
        *(_OWORD *)&__dst[v13[20]] = *(_OWORD *)&__src[v13[20]];
        *(_OWORD *)&__dst[v13[24]] = *(_OWORD *)&__src[v13[24]];
        uint64_t v15 = 6;
LABEL_9:
        uint64_t v7 = v15;
        uint64_t v6 = a3;
LABEL_10:
        swift_storeEnumTagMultiPayload(__dst, v6, v7);
        break;
      default:
        memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
        break;
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLActionClassifier.DataSource(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for URL(319);
  uint64_t v2 = v1;
  if (v3 <= 0x3F)
  {
    uint64_t v21 = a1;
    uint64_t v4 = *(void *)(v1 - 8) + 64;
    uint64_t v13 = v4;
    uint64_t v14 = (void *)v4;
    uint64_t v15 = &unk_3519C0;
    uint64_t v16 = &unk_3519C0;
    uint64_t v17 = &unk_3519D8;
    uint64_t v18 = &unk_3519D8;
    swift_getTupleTypeLayout(v11, 0, 6);
    v20[0] = v11;
    v20[1] = v4;
    v20[2] = v4;
    v20[3] = &unk_3519F0;
    v20[4] = &unk_351A08;
    uint64_t v5 = type metadata accessor for DataFrame(319);
    uint64_t v2 = v5;
    if (v6 <= 0x3F)
    {
      uint64_t v13 = *(void *)(v5 - 8) + 64;
      uint64_t v7 = v13;
      uint64_t v14 = &unk_3519C0;
      uint64_t v15 = &unk_3519C0;
      uint64_t v16 = &unk_3519C0;
      uint64_t v2 = 0;
      swift_getTupleTypeLayout(v19, 0, 4);
      v20[5] = v19;
      uint64_t v13 = v7;
      uint64_t v14 = &unk_3519C0;
      uint64_t v15 = &unk_3519C0;
      uint64_t v16 = &unk_3519D8;
      uint64_t v17 = &unk_3519D8;
      swift_getTupleTypeLayout(v12, 0, 5);
      v20[6] = v12;
      swift_initEnumMetadataMultiPayload(v21, 256, 7, v20, v8, v9);
    }
  }
  return v2;
}

uint64_t BlobMetadata.dataType.getter()
{
  unsigned int v1 = *(_DWORD *)(v0 + 4);
  unsigned int v2 = 0x2010003u >> (8 * v1);
  BOOL v3 = v1 < 4;
  uint64_t result = 3;
  if (v3) {
    return v2;
  }
  return result;
}

uint64_t getEnumTagSinglePayload for BlobMetadata(uint64_t a1, int a2)
{
  uint64_t result = 0;
  if (a2)
  {
    if (*(unsigned char *)(a1 + 64)) {
      return (*(_DWORD *)a1 + 1);
    }
  }
  return result;
}

void storeEnumTagSinglePayload for BlobMetadata(uint64_t a1, int a2, int a3)
{
  if (!a2)
  {
    if (!a3) {
      return;
    }
    char v3 = 0;
    goto LABEL_6;
  }
  *(void *)(a1 + 56) = 0;
  *(_OWORD *)(a1 + 40) = 0;
  *(_OWORD *)(a1 + 24) = 0;
  *(_OWORD *)(a1 + 8) = 0;
  *(void *)a1 = (a2 - 1);
  char v3 = 1;
  if (a3) {
LABEL_6:
  }
    *(unsigned char *)(a1 + 64) = v3;
}

ValueMetadata *type metadata accessor for BlobMetadata()
{
  return &type metadata for BlobMetadata;
}

ValueMetadata *type metadata accessor for Header()
{
  return &type metadata for Header;
}

void storeEnumTagSinglePayload for Header(uint64_t a1, int a2, int a3)
{
}

uint64_t getEnumTagSinglePayload for Header(uint64_t a1, int a2)
{
  return getEnumTagSinglePayload for BlobMetadata(a1, a2);
}

uint64_t MLTextClassifier.ModelParameters.maxIterations.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLTextClassifier.ModelParameters(0) + 36));
}

uint64_t type metadata accessor for MLTextClassifier.ModelParameters(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLTextClassifier.ModelParameters;
  if (!type metadata singleton initialization cache for MLTextClassifier.ModelParameters) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLTextClassifier.ModelParameters);
  }
  return result;
}

uint64_t MLTextClassifier.ModelParameters.init(validation:algorithm:language:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v18 = a3;
  uint64_t v19 = a1;
  uint64_t v4 = v3;
  uint64_t v20 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  int64_t v5 = *(void *)(*(void *)(v20 - 8) + 64);
  unint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v8 = (int *)type metadata accessor for MLTextClassifier.ModelParameters(0);
  uint64_t v9 = v8[5];
  uint64_t v10 = (_OWORD *)(v4 + v8[6]);
  uint64_t v21 = v10;
  v10[1] = 0;
  _OWORD *v10 = 0;
  uint64_t v11 = v8[7];
  *(_OWORD *)(v4 + v11) = 0;
  *(_OWORD *)(v4 + v8[8]) = 0;
  uint64_t v12 = v8[9];
  *(void *)(v4 + v12) = 0;
  *(unsigned char *)(v4 + v12 + 8) = 1;
  outlined init with copy of MLTrainingSessionParameters(a2, v4, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  *(void *)(v4 + v9) = v18;
  uint64_t v13 = v19;
  outlined init with copy of MLTrainingSessionParameters(v19, (uint64_t)&v16, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
  *(_OWORD *)(v4 + v11) = 0;
  v17[3] = v20;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v17);
  outlined init with take of MLClassifierMetrics((uint64_t)&v16, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
  outlined assign with take of Any?((uint64_t)v17, (uint64_t)v21);
  outlined destroy of MLActivityClassifier.ModelParameters(a2, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  return outlined destroy of MLActivityClassifier.ModelParameters(v13, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
}

uint64_t MLTextClassifier.ModelParameters.validation.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  outlined init with copy of Any?(v1 + *(int *)(v3 + 24), (uint64_t)&v7);
  if (!v8) {
    BUG();
  }
  outlined init with take of Any(&v7, v6);
  uint64_t v4 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  return swift_dynamicCast(v2, v6, (char *)&type metadata for Any + 8, v4, 7);
}

uint64_t MLTextClassifier.ModelParameters.init(validationData:algorithm:language:textColumnValidationData:labelColumnValidationData:)(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, unint64_t a5, uint64_t a6, unint64_t a7)
{
  uint64_t v41 = a4;
  id v39 = a3;
  uint64_t v8 = v7;
  uint64_t v9 = a2;
  uint64_t v40 = a6;
  uint64_t v35 = *(void *)a1;
  char v11 = *(unsigned char *)(a1 + 8);
  uint64_t v12 = (int *)type metadata accessor for MLTextClassifier.ModelParameters(0);
  uint64_t v13 = v12[6];
  *(_OWORD *)(v8 + v13 + 16) = 0;
  *(_OWORD *)(v8 + v13) = 0;
  *(_OWORD *)(v8 + v12[7]) = 0;
  *(_OWORD *)(v8 + v12[8]) = 0;
  uint64_t v14 = v12[9];
  *(void *)(v8 + v14) = 0;
  uint64_t v36 = v8;
  *(unsigned char *)(v8 + v14 + 8) = 1;
  char v43 = v11;
  if (v11 != -1)
  {
    if (!a5)
    {
      uint64_t v42 = v13;
      uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
      uint64_t v16 = (void *)swift_allocObject(v15, 64, 7);
      char v17 = (char)v16;
      v16[2] = 1;
      v16[3] = 2;
      v16[7] = &type metadata for String;
      v16[4] = 0xD00000000000005CLL;
      v16[5] = "Missing event metric for key " + 0x8000000000000000;
      print(_:separator:terminator:)(v16, 32, 0xE100000000000000, 10, 0xE100000000000000);
      swift_bridgeObjectRelease(v17);
      uint64_t v13 = v42;
    }
    if (!a7)
    {
      uint64_t v42 = v13;
      uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
      uint64_t v19 = (void *)swift_allocObject(v18, 64, 7);
      char v20 = (char)v19;
      v19[2] = 1;
      v19[3] = 2;
      v19[7] = &type metadata for String;
      v19[4] = 0xD00000000000005ELL;
      v19[5] = "ified, default to use 'text'" + 0x8000000000000000;
      print(_:separator:terminator:)(v19, 32, 0xE100000000000000, 10, 0xE100000000000000);
      swift_bridgeObjectRelease(v20);
      uint64_t v13 = v42;
    }
  }
  unint64_t v34 = a5;
  uint64_t v42 = v36 + v13;
  uint64_t v21 = v12[5];
  outlined init with copy of MLTrainingSessionParameters(a2, v36, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  id v22 = v39;
  *(void *)(v36 + v21) = v39;
  uint64_t v23 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  v32[3] = v23;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v32);
  if (v43 == -1)
  {
    *(_OWORD *)boxed_opaque_existential_1 = 0;
    *((_WORD *)boxed_opaque_existential_1 + 8) = 256;
    swift_storeEnumTagMultiPayload(boxed_opaque_existential_1, v23, 0);
    v22;
  }
  else
  {
    uint64_t v38 = v23;
    uint64_t v37 = a2;
    uint64_t v25 = v35;
    v32[4] = v35;
    char v26 = v43 & 1;
    char v33 = v43 & 1;
    uint64_t v27 = v22;
    char v28 = v43;
    v27;
    if (MLDataTable.size.getter())
    {
      void *boxed_opaque_existential_1 = v25;
      *((unsigned char *)boxed_opaque_existential_1 + 8) = v26;
      boxed_opaque_existential_1[2] = 1954047348;
      boxed_opaque_existential_1[3] = 0xE400000000000000;
      boxed_opaque_existential_1[4] = 0x6C6562616CLL;
      boxed_opaque_existential_1[5] = 0xE500000000000000;
      swift_storeEnumTagMultiPayload(boxed_opaque_existential_1, v38, 1);
    }
    else
    {
      outlined consume of MLDataTable?(v25, v28);
      swift_storeEnumTagMultiPayload(boxed_opaque_existential_1, v38, 5);
    }
    uint64_t v9 = v37;
    id v22 = v39;
  }
  uint64_t v29 = v40;
  uint64_t v30 = v41;
  outlined assign with take of Any?((uint64_t)v32, v42);
  MLTextClassifier.ModelParameters.textColumnValidationData.setter(v30, v34);
  MLTextClassifier.ModelParameters.labelColumnValidationData.setter(v29, a7);

  return outlined destroy of MLActivityClassifier.ModelParameters(v9, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
}

id MLTextClassifier.ModelParameters.description.getter(uint64_t a1)
{
  v2._uint64_t countAndFlagsBits = MLTextClassifier.ModelAlgorithmType.description.getter(a1);
  char object = (char)v2._object;
  id v10 = (id)0xD000000000000010;
  char v11 = "than the trained model." + 0x8000000000000000;
  String.append(_:)(v2);
  swift_bridgeObjectRelease(object);
  swift_bridgeObjectRetain(("than the trained model." + 0x8000000000000000));
  v4._uint64_t countAndFlagsBits = 0x676175676E614C0ALL;
  v4._char object = (void *)0xEB00000000203A65;
  String.append(_:)(v4);
  swift_bridgeObjectRelease(("than the trained model." + 0x8000000000000000));
  id v10 = *(id *)(v1 + *(int *)(type metadata accessor for MLTextClassifier.ModelParameters(0) + 20));
  v10;
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NLLanguage?);
  id v10 = (id)String.init<A>(describing:)(&v10, v5);
  char v11 = v6;
  v4._uint64_t countAndFlagsBits = 10;
  v4._char object = (void *)0xE100000000000000;
  String.append(_:)(v4);
  uint64_t v7 = (uint64_t)v10;
  uint64_t v8 = v11;
  id v10 = (id)0xD000000000000010;
  char v11 = "than the trained model." + 0x8000000000000000;
  swift_bridgeObjectRetain(("than the trained model." + 0x8000000000000000));
  v4._uint64_t countAndFlagsBits = v7;
  v4._char object = v8;
  String.append(_:)(v4);
  swift_bridgeObjectRelease(("than the trained model." + 0x8000000000000000));
  swift_bridgeObjectRelease((_BYTE)v8);
  return v10;
}

uint64_t MLTextClassifier.ModelParameters.algorithm.getter()
{
  return outlined init with copy of MLTrainingSessionParameters(v1, v0, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
}

uint64_t MLTextClassifier.ModelParameters.algorithm.setter(uint64_t a1)
{
  return outlined assign with take of MLTextClassifier.ModelAlgorithmType(a1, v1);
}

void (*MLTextClassifier.ModelParameters.algorithm.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

void *MLTextClassifier.ModelParameters.language.getter()
{
  uint64_t v1 = *(void **)(v0 + *(int *)(type metadata accessor for MLTextClassifier.ModelParameters(0) + 20));
  v1;
  return v1;
}

void MLTextClassifier.ModelParameters.language.setter(uint64_t a1)
{
  uint64_t v2 = *(int *)(type metadata accessor for MLTextClassifier.ModelParameters(0) + 20);

  *(void *)(v1 + v2) = a1;
}

void (*MLTextClassifier.ModelParameters.language.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t key path setter for MLTextClassifier.ModelParameters.validation : MLTextClassifier.ModelParameters(uint64_t a1)
{
  v6[0] = v1;
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0) - 8)
                 + 64);
  uint64_t v3 = alloca(v2);
  Swift::String v4 = alloca(v2);
  outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v6, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
  return MLTextClassifier.ModelParameters.validation.setter((uint64_t)v6);
}

uint64_t MLTextClassifier.ModelParameters.validation.setter(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  uint64_t v3 = *(int *)(v2 + 28);
  swift_bridgeObjectRelease(*(void *)(v1 + v3 + 8));
  *(_OWORD *)(v1 + v3) = 0;
  v6[3] = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v6);
  outlined init with take of MLClassifierMetrics(a1, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
  return outlined assign with take of Any?((uint64_t)v6, v1 + *(int *)(v2 + 24));
}

void (*MLTextClassifier.ModelParameters.validation.modify(void *a1))(uint64_t a1, char a2)
{
  uint64_t v2 = malloc(0x58uLL);
  *a1 = v2;
  *((void *)v2 + 8) = v1;
  uint64_t v3 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  size_t v4 = *(void *)(*(void *)(v3 - 8) + 64);
  *((void *)v2 + 9) = malloc(v4);
  uint64_t v5 = malloc(v4);
  *((void *)v2 + 10) = v5;
  uint64_t v6 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  outlined init with copy of Any?(v1 + *(int *)(v6 + 24), (uint64_t)(v2 + 2));
  if (!*((void *)v2 + 7)) {
    BUG();
  }
  outlined init with take of Any(v2 + 2, v2);
  swift_dynamicCast(v5, v2, (char *)&type metadata for Any + 8, v3, 7);
  return MLTextClassifier.ModelParameters.validation.modify;
}

void MLTextClassifier.ModelParameters.validation.modify(uint64_t a1, char a2)
{
  uint64_t v2 = *(void **)a1;
  uint64_t v3 = *(void **)(*(void *)a1 + 80);
  size_t v4 = *(void **)(*(void *)a1 + 72);
  if (a2)
  {
    outlined init with copy of MLTrainingSessionParameters(*(void *)(*(void *)a1 + 80), (uint64_t)v4, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
    MLTextClassifier.ModelParameters.validation.setter((uint64_t)v4);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v3, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
  }
  else
  {
    MLTextClassifier.ModelParameters.validation.setter(*(void *)(*(void *)a1 + 80));
  }
  free(v3);
  free(v4);
  free(v2);
}

uint64_t key path getter for MLTextClassifier.ModelParameters.maxIterations : MLTextClassifier.ModelParameters()
{
  uint64_t v1 = v0;
  uint64_t result = MLTextClassifier.ModelParameters.maxIterations.getter();
  *(void *)uint64_t v1 = result;
  *(unsigned char *)(v1 + 8) = v3 & 1;
  return result;
}

uint64_t key path setter for MLTextClassifier.ModelParameters.maxIterations : MLTextClassifier.ModelParameters(uint64_t a1)
{
  return MLTextClassifier.ModelParameters.maxIterations.setter(*(void *)a1, *(unsigned char *)(a1 + 8));
}

uint64_t MLTextClassifier.ModelParameters.maxIterations.setter(uint64_t a1, char a2)
{
  uint64_t result = *(int *)(type metadata accessor for MLTextClassifier.ModelParameters(0) + 36);
  *(void *)(v2 + result) = a1;
  *(unsigned char *)(v2 + result + 8) = a2 & 1;
  return result;
}

uint64_t (*MLTextClassifier.ModelParameters.maxIterations.modify(uint64_t a1))(uint64_t a1)
{
  *(void *)(a1 + 16) = v1;
  uint64_t v2 = *(int *)(type metadata accessor for MLTextClassifier.ModelParameters(0) + 36);
  *(_DWORD *)(a1 + 12) = v2;
  uint64_t v3 = *(void *)(v1 + v2);
  LOBYTE(v2) = *(unsigned char *)(v1 + v2 + 8);
  *(void *)a1 = v3;
  *(unsigned char *)(a1 + 8) = v2;
  return MLTextClassifier.ModelParameters.maxIterations.modify;
}

uint64_t MLTextClassifier.ModelParameters.maxIterations.modify(uint64_t a1)
{
  uint64_t result = *(int *)(a1 + 12);
  uint64_t v2 = *(void *)(a1 + 16);
  char v3 = *(unsigned char *)(a1 + 8);
  *(void *)(v2 + result) = *(void *)a1;
  *(unsigned char *)(v2 + result + 8) = v3;
  return result;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> MLTextClassifier.ModelParameters.validateRevision()()
{
  uint64_t v1 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  int64_t v2 = *(void *)(*(void *)(v1 - 8) + 64);
  char v3 = alloca(v2);
  size_t v4 = alloca(v2);
  outlined init with copy of MLTrainingSessionParameters(v0, (uint64_t)&v22, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  if (swift_getEnumCaseMultiPayload(&v22, v1) > 1)
  {
    uint64_t v13 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLTextClassifier.FeatureExtractorType, revision: Int?))
                 + 48);
    if (!*((unsigned char *)&v22 + v13 + 8))
    {
      uint64_t v14 = *(uint64_t *)((char *)&v22 + v13);
      if (!NLPClassifierModelIsRevisionSupported(v14))
      {
        *(void *)&long long v23 = 0;
        *((void *)&v23 + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(29);
        swift_bridgeObjectRelease(BYTE8(v23));
        *(void *)&long long v23 = 0x6E6F697369766552;
        *((void *)&v23 + 1) = 0xE900000000000020;
        uint64_t v24 = v14;
        v15._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
        char object = (char)v15._object;
        String.append(_:)(v15);
        swift_bridgeObjectRelease(object);
        v17._char object = "und in the model." + 0x8000000000000000;
        v17._uint64_t countAndFlagsBits = 0xD000000000000012;
        String.append(_:)(v17);
        long long v25 = v23;
        v17._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v17._object, 0, 0);
        *(_OWORD *)uint64_t v18 = v25;
        *(_OWORD *)(v18 + 16) = 0;
        *(_OWORD *)(v18 + 32) = 0;
        *(unsigned char *)(v18 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v17._object, v18, v19, v20, v21);
      }
    }
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v22, type metadata accessor for MLTextClassifier.FeatureExtractorType);
  }
  else if (!(_BYTE)v23)
  {
    uint64_t v5 = v22;
    if (!NLPClassifierModelIsRevisionSupported(v22))
    {
      *(void *)&long long v23 = 0;
      *((void *)&v23 + 1) = 0xE000000000000000;
      _StringGuts.grow(_:)(29);
      swift_bridgeObjectRelease(BYTE8(v23));
      *(void *)&long long v23 = 0x6E6F697369766552;
      *((void *)&v23 + 1) = 0xE900000000000020;
      uint64_t v24 = v5;
      v6._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
      char v7 = (char)v6._object;
      String.append(_:)(v6);
      swift_bridgeObjectRelease(v7);
      v8._char object = "und in the model." + 0x8000000000000000;
      v8._uint64_t countAndFlagsBits = 0xD000000000000012;
      String.append(_:)(v8);
      long long v25 = v23;
      v8._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v8._object, 0, 0);
      *(_OWORD *)uint64_t v9 = v25;
      *(_OWORD *)(v9 + 16) = 0;
      *(_OWORD *)(v9 + 32) = 0;
      *(unsigned char *)(v9 + 48) = 0;
      swift_willThrow(&type metadata for MLCreateError, v8._object, v9, v10, v11, v12);
    }
  }
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> MLTextClassifier.ModelParameters.validateCustomEmbeddingURL()()
{
  *(void *)&long long v41 = v0;
  uint64_t v42 = (long long *)v1;
  uint64_t v40 = type metadata accessor for URL(0);
  uint64_t v39 = *(void *)(v40 - 8);
  int64_t v2 = *(void *)(v39 + 64);
  char v3 = alloca(v2);
  size_t v4 = alloca(v2);
  uint64_t v44 = &v38;
  uint64_t v5 = alloca(v2);
  Swift::String v6 = alloca(v2);
  char v43 = &v38;
  uint64_t v7 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  int64_t v8 = *(void *)(*(void *)(v7 - 8) + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  int64_t v11 = *(void *)(*(void *)(type metadata accessor for MLTextClassifier.FeatureExtractorType(0) - 8) + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = alloca(v11);
  Swift::String v15 = alloca(v11);
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v42, (uint64_t)&v38, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  if (swift_getEnumCaseMultiPayload(&v38, v7) != 2)
  {
    uint64_t v18 = type metadata accessor for MLTextClassifier.ModelAlgorithmType;
    Swift::String v17 = &v38;
    goto LABEL_5;
  }
  outlined init with take of MLClassifierMetrics((uint64_t)&v38, (uint64_t)&v38, type metadata accessor for MLTextClassifier.FeatureExtractorType);
  outlined init with copy of MLTrainingSessionParameters((uint64_t)&v38, (uint64_t)&v38, type metadata accessor for MLTextClassifier.FeatureExtractorType);
  uint64_t v16 = v40;
  if (__swift_getEnumTagSinglePayload((uint64_t)&v38, 4, v40))
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v38, type metadata accessor for MLTextClassifier.FeatureExtractorType);
    Swift::String v17 = &v38;
    uint64_t v18 = type metadata accessor for MLTextClassifier.FeatureExtractorType;
LABEL_5:
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v17, v18);
    return;
  }
  uint64_t v42 = &v38;
  uint64_t v19 = v43;
  uint64_t v20 = v39;
  (*(void (**)(long long *, long long *, uint64_t))(v39 + 32))(v43, &v38, v16);
  char v21 = URL.isFileURL.getter();
  (*(void (**)(long long *, long long *, uint64_t))(v20 + 16))(v44, v19, v16);
  if (v21)
  {
    uint64_t v22 = v44;
    uint64_t v23 = URL.pathExtension.getter();
    char v25 = v24;
    char v45 = specialized Sequence<>.contains(_:)(v23, v24, &outlined read-only object #0 of MLTextClassifier.ModelParameters.validateCustomEmbeddingURL());
    swift_bridgeObjectRelease(v25);
    char v26 = *(void (**)(long long *, uint64_t))(v20 + 8);
    uint64_t v27 = v16;
    v26(v22, v16);
    if (v45)
    {
      v26(v43, v16);
      uint64_t v18 = type metadata accessor for MLTextClassifier.FeatureExtractorType;
      Swift::String v17 = v42;
      goto LABEL_5;
    }
    uint64_t v44 = (long long *)v26;
  }
  else
  {
    char v28 = v44;
    uint64_t v44 = *(long long **)(v20 + 8);
    ((void (*)(long long *, uint64_t))v44)(v28, v16);
    uint64_t v27 = v16;
  }
  *(void *)&long long v38 = 0;
  *((void *)&v38 + 1) = 0xE000000000000000;
  _StringGuts.grow(_:)(52);
  v29._char object = "cified, default to use 'label'" + 0x8000000000000000;
  v29._uint64_t countAndFlagsBits = 0xD000000000000015;
  String.append(_:)(v29);
  uint64_t v30 = lazy protocol witness table accessor for type URL and conformance URL();
  uint64_t v31 = dispatch thunk of CustomStringConvertible.description.getter(v27, v30);
  char v33 = (char)v32;
  v29._uint64_t countAndFlagsBits = v31;
  v29._char object = v32;
  String.append(_:)(v29);
  swift_bridgeObjectRelease(v33);
  v29._char object = "The custom embedding " + 0x8000000000000000;
  v29._uint64_t countAndFlagsBits = 0xD00000000000001DLL;
  String.append(_:)(v29);
  long long v41 = v38;
  v29._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  swift_allocError(&type metadata for MLCreateError, v29._object, 0, 0);
  *(_OWORD *)uint64_t v34 = v41;
  *(_OWORD *)(v34 + 16) = 0;
  *(_OWORD *)(v34 + 32) = 0;
  *(unsigned char *)(v34 + 48) = 0;
  swift_willThrow(&type metadata for MLCreateError, v29._object, v34, v35, v36, v37);
  ((void (*)(long long *, uint64_t))v44)(v43, v40);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v42, type metadata accessor for MLTextClassifier.FeatureExtractorType);
}

id MLTextClassifier.ModelParameters.debugDescription.getter(uint64_t a1)
{
  return MLTextClassifier.ModelParameters.description.getter(a1);
}

id MLTextClassifier.ModelParameters.playgroundDescription.getter(uint64_t a1)
{
  int64_t v2 = v1;
  id result = MLTextClassifier.ModelParameters.description.getter(a1);
  v2[3] = &type metadata for String;
  *int64_t v2 = result;
  v2[1] = v4;
  return result;
}

id protocol witness for CustomStringConvertible.description.getter in conformance MLTextClassifier.ModelParameters(uint64_t a1)
{
  return MLTextClassifier.ModelParameters.description.getter(a1);
}

id protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLTextClassifier.ModelParameters(uint64_t a1)
{
  return MLTextClassifier.ModelParameters.debugDescription.getter(a1);
}

id protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLTextClassifier.ModelParameters(uint64_t a1)
{
  return MLTextClassifier.ModelParameters.playgroundDescription.getter(a1);
}

uint64_t MLTextClassifier.ModelParameters.validationData.getter(__m128 a1)
{
  uint64_t v2 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  int64_t v3 = *(void *)(*(void *)(v2 - 8) + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v6 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  outlined init with copy of Any?(v1 + *(int *)(v6 + 24), (uint64_t)&v10);
  if (!v11) {
    BUG();
  }
  outlined init with take of Any(&v10, v9);
  swift_dynamicCast(&v8, v9, (char *)&type metadata for Any + 8, v2, 7);
  MLTextClassifier.ModelParameters.ValidationData.table.getter(a1);
  return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v8, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
}

uint64_t key path getter for MLTextClassifier.ModelParameters.validationData : MLTextClassifier.ModelParameters(__m128 a1)
{
  uint64_t v2 = v1;
  MLTextClassifier.ModelParameters.validationData.getter(a1);
  uint64_t result = v4;
  *(void *)uint64_t v2 = v4;
  *(unsigned char *)(v2 + 8) = v5;
  return result;
}

uint64_t key path setter for MLTextClassifier.ModelParameters.validationData : MLTextClassifier.ModelParameters(uint64_t a1)
{
  int v1 = *(_DWORD *)(a1 + 8);
  uint64_t v3 = *(void *)a1;
  char v4 = v1;
  outlined copy of MLDataTable?(v3, v1);
  return MLTextClassifier.ModelParameters.validationData.setter((uint64_t)&v3);
}

uint64_t MLTextClassifier.ModelParameters.validationData.setter(uint64_t a1)
{
  uint64_t v2 = *(void *)a1;
  char v3 = *(unsigned char *)(a1 + 8);
  uint64_t v4 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  v9[3] = v4;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v9);
  uint64_t v6 = boxed_opaque_existential_1;
  if (v3 == -1)
  {
    *(_OWORD *)boxed_opaque_existential_1 = 0;
    *((_WORD *)boxed_opaque_existential_1 + 8) = 256;
    swift_storeEnumTagMultiPayload(boxed_opaque_existential_1, v4, 0);
  }
  else
  {
    uint64_t v11 = v1;
    uint64_t v12 = v2;
    v9[4] = v2;
    char v10 = v3 & 1;
    if (MLDataTable.size.getter())
    {
      *uint64_t v6 = v12;
      *((unsigned char *)v6 + 8) = v3 & 1;
      _OWORD v6[2] = 1954047348;
      v6[3] = 0xE400000000000000;
      void v6[4] = 0x6C6562616CLL;
      v6[5] = 0xE500000000000000;
      swift_storeEnumTagMultiPayload(v6, v4, 1);
    }
    else
    {
      outlined consume of MLDataTable?(v12, v3);
      swift_storeEnumTagMultiPayload(v6, v4, 5);
    }
    uint64_t v1 = v11;
  }
  uint64_t v7 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  return outlined assign with take of Any?((uint64_t)v9, *(int *)(v7 + 24) + v1);
}

void (*MLTextClassifier.ModelParameters.validationData.modify(void *a1, __m128 a2))(uint64_t *a1, char a2)
{
  char v3 = malloc(0x38uLL);
  *a1 = v3;
  v3[6] = v2;
  MLTextClassifier.ModelParameters.validationData.getter(a2);
  return MLTextClassifier.ModelParameters.validationData.modify;
}

void MLTextClassifier.ModelParameters.validationData.modify(uint64_t *a1, char a2)
{
  uint64_t v2 = *a1;
  uint64_t v21 = *(void *)(*a1 + 32);
  char v3 = *(unsigned char *)(*a1 + 40);
  uint64_t v4 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  *(void *)(v2 + 24) = v4;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1((void *)v2);
  uint64_t v6 = boxed_opaque_existential_1;
  if (a2)
  {
    if (v3 == -1)
    {
      *(_OWORD *)boxed_opaque_existential_1 = 0;
      *((_WORD *)boxed_opaque_existential_1 + 8) = 256;
      uint64_t v9 = boxed_opaque_existential_1;
      uint64_t v10 = v4;
      uint64_t v11 = 0;
    }
    else
    {
      char v7 = v3;
      char v8 = v3 & 1;
      outlined copy of MLDataTable?(v21, v7);
      if (MLDataTable.size.getter())
      {
        *uint64_t v6 = v21;
        *((unsigned char *)v6 + 8) = v8;
        _OWORD v6[2] = 1954047348;
        v6[3] = 0xE400000000000000;
        void v6[4] = 0x6C6562616CLL;
        v6[5] = 0xE500000000000000;
        uint64_t v19 = 1;
      }
      else
      {
        outlined consume of MLDataTable?(v21, v7);
        uint64_t v19 = 5;
      }
      uint64_t v11 = v19;
      uint64_t v9 = v6;
      uint64_t v10 = v4;
    }
    swift_storeEnumTagMultiPayload(v9, v10, v11);
    uint64_t v15 = *(void *)(v2 + 48);
    uint64_t v16 = type metadata accessor for MLTextClassifier.ModelParameters(0);
    outlined assign with take of Any?(v2, v15 + *(int *)(v16 + 24));
    outlined consume of MLDataTable?(*(void *)(v2 + 32), *(_DWORD *)(v2 + 40));
  }
  else
  {
    if (v3 == -1)
    {
      *(_OWORD *)boxed_opaque_existential_1 = 0;
      *((_WORD *)boxed_opaque_existential_1 + 8) = 256;
      uint64_t v12 = boxed_opaque_existential_1;
      uint64_t v13 = v4;
      uint64_t v14 = 0;
    }
    else
    {
      if (MLDataTable.size.getter())
      {
        *uint64_t v6 = v21;
        *((unsigned char *)v6 + 8) = v3 & 1;
        _OWORD v6[2] = 1954047348;
        v6[3] = 0xE400000000000000;
        void v6[4] = 0x6C6562616CLL;
        v6[5] = 0xE500000000000000;
        uint64_t v20 = 1;
      }
      else
      {
        outlined consume of MLDataTable?(v21, v3);
        uint64_t v20 = 5;
      }
      uint64_t v14 = v20;
      uint64_t v12 = v6;
      uint64_t v13 = v4;
    }
    swift_storeEnumTagMultiPayload(v12, v13, v14);
    uint64_t v17 = *(void *)(v2 + 48);
    uint64_t v18 = type metadata accessor for MLTextClassifier.ModelParameters(0);
    outlined assign with take of Any?(v2, v17 + *(int *)(v18 + 24));
  }
  free((void *)v2);
}

uint64_t MLTextClassifier.ModelParameters.textColumnValidationData.getter()
{
  uint64_t v1 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  int64_t v2 = *(void *)(*(void *)(v1 - 8) + 64);
  char v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v5 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  outlined init with copy of Any?(v0 + *(int *)(v5 + 24), (uint64_t)&v13);
  if (!v14) {
    BUG();
  }
  outlined init with take of Any(&v13, &v11);
  swift_dynamicCast(&v11, &v11, (char *)&type metadata for Any + 8, v1, 7);
  if (swift_getEnumCaseMultiPayload(&v11, v1) == 1)
  {
    uint64_t v6 = v11;
    uint64_t v7 = v12;
    char v8 = BYTE8(v11);
    swift_bridgeObjectRelease(BYTE8(v13));
    outlined consume of Result<_DataTable, Error>(v6, v8);
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v11, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
    uint64_t v9 = *(int *)(v5 + 28);
    uint64_t v7 = *(void *)(v0 + v9);
    swift_bridgeObjectRetain(*(void *)(v0 + v9 + 8));
  }
  return v7;
}

uint64_t MLTextClassifier.ModelParameters.textColumnValidationData.setter(uint64_t a1, unint64_t a2)
{
  unint64_t v26 = a2;
  uint64_t v25 = a1;
  uint64_t v3 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  int64_t v4 = *(void *)(*(void *)(v3 - 8) + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v7 = alloca(v4);
  char v8 = alloca(v4);
  uint64_t v27 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  uint64_t v9 = *(int *)(v27 + 24);
  uint64_t v24 = v2;
  outlined init with copy of Any?(v2 + v9, (uint64_t)&v21);
  if (!v22) {
    BUG();
  }
  outlined init with take of Any(&v21, &v18);
  swift_dynamicCast(&v18, &v18, (char *)&type metadata for Any + 8, v3, 7);
  if (swift_getEnumCaseMultiPayload(&v18, v3) == 1)
  {
    uint64_t v10 = v18;
    char v28 = BYTE8(v18);
    long long v23 = v21;
    swift_bridgeObjectRelease(v20);
    uint64_t v11 = *(int *)(v27 + 28);
    uint64_t v12 = v24;
    swift_bridgeObjectRelease(*(void *)(v24 + v11 + 8));
    uint64_t v13 = v25;
    if (!v26) {
      uint64_t v13 = 1954047348;
    }
    unint64_t v14 = 0xE400000000000000;
    if (v26) {
      unint64_t v14 = v26;
    }
    *(_OWORD *)(v12 + v11) = 0;
    *(void *)&long long v18 = v10;
    BYTE8(v18) = v28;
    uint64_t v19 = v13;
    unint64_t v20 = v14;
    long long v21 = v23;
    swift_storeEnumTagMultiPayload(&v18, v3, 1);
    return MLTextClassifier.ModelParameters.validation.setter((uint64_t)&v18);
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v18, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
    uint64_t v16 = *(int *)(v27 + 28);
    uint64_t v17 = v24;
    swift_bridgeObjectRelease(*(void *)(v24 + v16 + 8));
    *(void *)(v17 + v16) = v25;
    uint64_t result = v26;
    *(void *)(v17 + v16 + 8) = v26;
  }
  return result;
}

uint64_t (*MLTextClassifier.ModelParameters.textColumnValidationData.modify(void *a1))(uint64_t *a1, char a2)
{
  a1[2] = v1;
  *a1 = MLTextClassifier.ModelParameters.textColumnValidationData.getter(a1);
  a1[1] = v2;
  return MLTextClassifier.ModelParameters.textColumnValidationData.modify;
}

uint64_t MLTextClassifier.ModelParameters.textColumnValidationData.modify(uint64_t *a1, char a2)
{
  return MLWordTagger.ModelParameters.tokenColumnValidationData.modify(a1, a2, (uint64_t (*)(uint64_t, uint64_t))MLTextClassifier.ModelParameters.textColumnValidationData.setter);
}

uint64_t MLTextClassifier.ModelParameters.init(validationData:algorithm:language:)(uint64_t a1, uint64_t a2, void *a3)
{
  uint64_t v5 = v3;
  uint64_t v6 = (int *)type metadata accessor for MLTextClassifier.ModelParameters(0);
  uint64_t v7 = v6[5];
  uint64_t v8 = v6[6];
  *(_OWORD *)(v5 + v8 + 16) = 0;
  uint64_t v26 = v8;
  *(_OWORD *)(v5 + v8) = 0;
  *(_OWORD *)(v5 + v6[7]) = 0;
  *(_OWORD *)(v5 + v6[8]) = 0;
  uint64_t v9 = v6[9];
  *(void *)(v5 + v9) = 0;
  *(unsigned char *)(v5 + v9 + 8) = 1;
  uint64_t v24 = a2;
  outlined init with copy of MLTrainingSessionParameters(a2, v5, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  *(void *)(v5 + v7) = a3;
  id v25 = a3;
  uint64_t v23 = a1;
  uint64_t v10 = static _TextUtilities.getTextLabeledDictionary(from:)(a1, 0.0);
  LOBYTE(a3) = (_BYTE)v10;
  specialized generateTextTable<A>(_:textColumn:labelColumn:using:)((uint64_t)v10, 1954047348, 0xE400000000000000, 0x6C6562616CLL, 0xE500000000000000);
  swift_bridgeObjectRelease((_BYTE)a3);
  uint64_t v28 = v20;
  char v19 = v21;
  v26 += v5;
  uint64_t v11 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  uint64_t v22 = v11;
  uint64_t v12 = __swift_allocate_boxed_opaque_existential_1(&v20);
  uint64_t v13 = v12;
  if (v19 == -1)
  {
    *(_OWORD *)uint64_t v12 = 0;
    *((_WORD *)v12 + 8) = 256;
    uint64_t v15 = v12;
    uint64_t v16 = v11;
    uint64_t v17 = 0;
LABEL_6:
    swift_storeEnumTagMultiPayload(v15, v16, v17);
    goto LABEL_7;
  }
  uint64_t v27 = v11;
  uint64_t v14 = v28;
  if (!MLDataTable.size.getter())
  {
    outlined consume of MLDataTable?(v14, v19);
    uint64_t v17 = 5;
    uint64_t v15 = v13;
    uint64_t v16 = v27;
    goto LABEL_6;
  }
  *uint64_t v13 = v14;
  *((unsigned char *)v13 + 8) = v19 != 0;
  v13[2] = 1954047348;
  v13[3] = 0xE400000000000000;
  v13[4] = 0x6C6562616CLL;
  v13[5] = 0xE500000000000000;
  swift_storeEnumTagMultiPayload(v13, v27, 1);
LABEL_7:
  outlined assign with take of Any?((uint64_t)&v20, v26);
  MLTextClassifier.ModelParameters.textColumnValidationData.setter(1954047348, 0xE400000000000000);
  MLTextClassifier.ModelParameters.labelColumnValidationData.setter(0x6C6562616CLL, 0xE500000000000000);

  outlined destroy of MLActivityClassifier.ModelParameters(v24, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  return outlined destroy of MLActivityClassifier.ModelParameters(v23, type metadata accessor for MLTextClassifier.DataSource);
}

{
  uint64_t v3;
  uint64_t v5;
  int *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  id v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t *v15;
  uint64_t v16;
  uint64_t *v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v21;
  char v22;
  uint64_t v23;
  id v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;

  uint64_t v5 = v3;
  uint64_t v6 = (int *)type metadata accessor for MLTextClassifier.ModelParameters(0);
  uint64_t v7 = v6[5];
  uint64_t v8 = v6[6];
  *(_OWORD *)(v5 + v8 + 16) = 0;
  uint64_t v27 = v8;
  *(_OWORD *)(v5 + v8) = 0;
  *(_OWORD *)(v5 + v6[7]) = 0;
  *(_OWORD *)(v5 + v6[8]) = 0;
  uint64_t v9 = v6[9];
  *(void *)(v5 + v9) = 0;
  *(unsigned char *)(v5 + v9 + 8) = 1;
  uint64_t v26 = a2;
  outlined init with copy of MLTrainingSessionParameters(a2, v5, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  *(void *)(v5 + v7) = a3;
  uint64_t v10 = a3;
  specialized generateTextTable<A>(_:textColumn:labelColumn:using:)(a1, 1954047348, 0xE400000000000000, 0x6C6562616CLL, 0xE500000000000000);
  uint64_t v24 = v10;
  swift_bridgeObjectRelease(a1);
  uint64_t v11 = v21;
  uint64_t v12 = v22;
  v27 += v5;
  uint64_t v13 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  uint64_t v23 = v13;
  uint64_t v14 = __swift_allocate_boxed_opaque_existential_1(&v21);
  uint64_t v15 = v14;
  if (v12 == -1)
  {
    *(_OWORD *)uint64_t v14 = 0;
    *((_WORD *)v14 + 8) = 256;
    uint64_t v17 = v14;
    long long v18 = v13;
    char v19 = 0;
LABEL_6:
    swift_storeEnumTagMultiPayload(v17, v18, v19);
    uint64_t v16 = v26;
    goto LABEL_7;
  }
  id v25 = v13;
  if (!MLDataTable.size.getter())
  {
    outlined consume of MLDataTable?(v11, v12);
    char v19 = 5;
    uint64_t v17 = v15;
    long long v18 = v25;
    goto LABEL_6;
  }
  uint64_t *v15 = v11;
  *((unsigned char *)v15 + 8) = v12 != 0;
  v15[2] = 1954047348;
  v15[3] = 0xE400000000000000;
  v15[4] = 0x6C6562616CLL;
  v15[5] = 0xE500000000000000;
  swift_storeEnumTagMultiPayload(v15, v25, 1);
  uint64_t v16 = v26;
LABEL_7:
  outlined assign with take of Any?((uint64_t)&v21, v27);
  MLTextClassifier.ModelParameters.textColumnValidationData.setter(1954047348, 0xE400000000000000);
  MLTextClassifier.ModelParameters.labelColumnValidationData.setter(0x6C6562616CLL, 0xE500000000000000);

  return outlined destroy of MLActivityClassifier.ModelParameters(v16, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
}

uint64_t MLTextClassifier.ModelParameters.labelColumnValidationData.setter(uint64_t a1, unint64_t a2)
{
  unint64_t v25 = a2;
  uint64_t v24 = a1;
  uint64_t v3 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  int64_t v4 = *(void *)(*(void *)(v3 - 8) + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  uint64_t v26 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  uint64_t v9 = *(int *)(v26 + 24);
  uint64_t v23 = v2;
  outlined init with copy of Any?(v2 + v9, (uint64_t)&v20);
  if (!v21) {
    BUG();
  }
  outlined init with take of Any(&v20, &v18);
  swift_dynamicCast(&v18, &v18, (char *)&type metadata for Any + 8, v3, 7);
  if (swift_getEnumCaseMultiPayload(&v18, v3) == 1)
  {
    uint64_t v10 = v18;
    char v27 = BYTE8(v18);
    long long v22 = v19;
    swift_bridgeObjectRelease(BYTE8(v20));
    uint64_t v11 = *(int *)(v26 + 32);
    uint64_t v12 = v23;
    swift_bridgeObjectRelease(*(void *)(v23 + v11 + 8));
    uint64_t v13 = v24;
    if (!v25) {
      uint64_t v13 = 0x6C6562616CLL;
    }
    unint64_t v14 = 0xE500000000000000;
    if (v25) {
      unint64_t v14 = v25;
    }
    *(_OWORD *)(v12 + v11) = 0;
    *(void *)&long long v18 = v10;
    BYTE8(v18) = v27;
    long long v19 = v22;
    *(void *)&long long v20 = v13;
    *((void *)&v20 + 1) = v14;
    swift_storeEnumTagMultiPayload(&v18, v3, 1);
    return MLTextClassifier.ModelParameters.validation.setter((uint64_t)&v18);
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v18, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
    uint64_t v16 = *(int *)(v26 + 32);
    uint64_t v17 = v23;
    swift_bridgeObjectRelease(*(void *)(v23 + v16 + 8));
    *(void *)(v17 + v16) = v24;
    uint64_t result = v25;
    *(void *)(v17 + v16 + 8) = v25;
  }
  return result;
}

uint64_t outlined assign with take of MLTextClassifier.ModelAlgorithmType(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 40))(a2, a1, v2);
  return a2;
}

uint64_t MLTextClassifier.ModelParameters.labelColumnValidationData.getter()
{
  uint64_t v1 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  int64_t v2 = *(void *)(*(void *)(v1 - 8) + 64);
  uint64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  uint64_t v5 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  outlined init with copy of Any?(v0 + *(int *)(v5 + 24), (uint64_t)&v13);
  if (!v14) {
    BUG();
  }
  outlined init with take of Any(&v13, &v11);
  swift_dynamicCast(&v11, &v11, (char *)&type metadata for Any + 8, v1, 7);
  if (swift_getEnumCaseMultiPayload(&v11, v1) == 1)
  {
    uint64_t v6 = v11;
    uint64_t v7 = v13;
    char v8 = BYTE8(v11);
    swift_bridgeObjectRelease(v12);
    outlined consume of Result<_DataTable, Error>(v6, v8);
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v11, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
    uint64_t v9 = *(int *)(v5 + 32);
    uint64_t v7 = *(void *)(v0 + v9);
    swift_bridgeObjectRetain(*(void *)(v0 + v9 + 8));
  }
  return v7;
}

uint64_t (*MLTextClassifier.ModelParameters.labelColumnValidationData.modify(void *a1))(uint64_t *a1, char a2)
{
  a1[2] = v1;
  *a1 = MLTextClassifier.ModelParameters.labelColumnValidationData.getter(a1);
  a1[1] = v2;
  return MLTextClassifier.ModelParameters.labelColumnValidationData.modify;
}

uint64_t MLTextClassifier.ModelParameters.labelColumnValidationData.modify(uint64_t *a1, char a2)
{
  return MLWordTagger.ModelParameters.tokenColumnValidationData.modify(a1, a2, (uint64_t (*)(uint64_t, uint64_t))MLTextClassifier.ModelParameters.labelColumnValidationData.setter);
}

uint64_t sub_2BFAF4(uint64_t a1)
{
  return MLTextClassifier.ModelParameters.validation.getter(a1);
}

uint64_t sub_2BFB0B(uint64_t a1)
{
  return key path setter for MLTextClassifier.ModelParameters.validation : MLTextClassifier.ModelParameters(a1);
}

uint64_t sub_2BFB15()
{
  return key path getter for MLTextClassifier.ModelParameters.maxIterations : MLTextClassifier.ModelParameters();
}

uint64_t sub_2BFB1F(uint64_t a1)
{
  return key path setter for MLTextClassifier.ModelParameters.maxIterations : MLTextClassifier.ModelParameters(a1);
}

uint64_t sub_2BFB29(__m128 a1)
{
  return key path getter for MLTextClassifier.ModelParameters.validationData : MLTextClassifier.ModelParameters(a1);
}

uint64_t sub_2BFB33(uint64_t a1)
{
  return key path setter for MLTextClassifier.ModelParameters.validationData : MLTextClassifier.ModelParameters(a1);
}

uint64_t sub_2BFB3D(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t result = MLTextClassifier.ModelParameters.textColumnValidationData.getter(a1);
  *uint64_t v2 = result;
  v2[1] = v4;
  return result;
}

uint64_t sub_2BFB5B(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for MLWordTagger.ModelParameters.tokenColumnValidationData : MLWordTagger.ModelParameters(a1, a2, a3, a4, (uint64_t (*)(uint64_t, uint64_t))MLTextClassifier.ModelParameters.textColumnValidationData.setter);
}

uint64_t sub_2BFB6D(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t result = MLTextClassifier.ModelParameters.labelColumnValidationData.getter(a1);
  *uint64_t v2 = result;
  v2[1] = v4;
  return result;
}

uint64_t sub_2BFB8B(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for MLWordTagger.ModelParameters.tokenColumnValidationData : MLWordTagger.ModelParameters(a1, a2, a3, a4, (uint64_t (*)(uint64_t, uint64_t))MLTextClassifier.ModelParameters.labelColumnValidationData.setter);
}

void *initializeBufferWithCopyOfBuffer for MLTextClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v3 = __dst;
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v9 = *(void *)__src;
    void *v3 = *(void *)__src;
    uint64_t v3 = (void *)(v9 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    uint64_t v6 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
    if (swift_getEnumCaseMultiPayload(__src, v6) == 2)
    {
      uint64_t v7 = type metadata accessor for URL(0);
      if (__swift_getEnumTagSinglePayload((uint64_t)__src, 4, v7))
      {
        uint64_t v8 = type metadata accessor for MLTextClassifier.FeatureExtractorType(0);
        memcpy(__dst, __src, *(void *)(*(void *)(v8 - 8) + 64));
      }
      else
      {
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
        __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 4, v7);
      }
      uint64_t v10 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLTextClassifier.FeatureExtractorType, revision: Int?))
                   + 48);
      __dst[v10 + 8] = __src[v10 + 8];
      *(void *)&__dst[v10] = *(void *)&__src[v10];
      swift_storeEnumTagMultiPayload(__dst, v6, 2);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
    }
    uint64_t v11 = a3[5];
    char v12 = *(void **)&__src[v11];
    *(void *)((char *)v3 + v11) = v12;
    uint64_t v24 = a3;
    uint64_t v13 = a3[6];
    uint64_t v14 = (char *)v3 + v13;
    uint64_t v15 = &__src[v13];
    uint64_t v16 = *(void *)&__src[v13 + 24];
    v12;
    if (v16)
    {
      *((void *)v14 + 3) = v16;
      (**(void (***)(char *, char *, uint64_t))(v16 - 8))(v14, v15, v16);
    }
    else
    {
      long long v17 = *(_OWORD *)v15;
      *((_OWORD *)v14 + 1) = *((_OWORD *)v15 + 1);
      *(_OWORD *)uint64_t v14 = v17;
    }
    uint64_t v18 = v24[7];
    *(void *)((char *)v3 + v18) = *(void *)&__src[v18];
    uint64_t v19 = *(void *)&__src[v18 + 8];
    *(void *)((char *)v3 + v18 + 8) = v19;
    uint64_t v20 = v24[8];
    *(void *)((char *)v3 + v20) = *(void *)&__src[v20];
    uint64_t v21 = *(void *)&__src[v20 + 8];
    *(void *)((char *)v3 + v20 + 8) = v21;
    uint64_t v22 = v24[9];
    *((unsigned char *)v3 + v22 + 8) = __src[v22 + 8];
    *(void *)((char *)v3 + v22) = *(void *)&__src[v22];
    swift_bridgeObjectRetain(v19);
    swift_bridgeObjectRetain(v21);
  }
  return v3;
}

uint64_t destroy for MLTextClassifier.ModelParameters(uint64_t a1, int *a2)
{
  uint64_t v3 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  if (swift_getEnumCaseMultiPayload(a1, v3) == 2)
  {
    uint64_t v4 = type metadata accessor for URL(0);
    if (!__swift_getEnumTagSinglePayload(a1, 4, v4)) {
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
    }
  }

  uint64_t v5 = a2[6];
  if (*(void *)(a1 + v5 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + v5));
  }
  swift_bridgeObjectRelease(*(void *)(a1 + a2[7] + 8));
  return swift_bridgeObjectRelease(*(void *)(a1 + a2[8] + 8));
}

char *initializeWithCopy for MLTextClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v5 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  if (swift_getEnumCaseMultiPayload(__src, v5) == 2)
  {
    uint64_t v6 = type metadata accessor for URL(0);
    if (__swift_getEnumTagSinglePayload((uint64_t)__src, 4, v6))
    {
      uint64_t v7 = type metadata accessor for MLTextClassifier.FeatureExtractorType(0);
      memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
    }
    else
    {
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16))(__dst, __src, v6);
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 4, v6);
    }
    uint64_t v8 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLTextClassifier.FeatureExtractorType, revision: Int?))
                + 48);
    __dst[v8 + 8] = __src[v8 + 8];
    *(void *)&__dst[v8] = *(void *)&__src[v8];
    swift_storeEnumTagMultiPayload(__dst, v5, 2);
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
  }
  uint64_t v9 = a3[5];
  uint64_t v10 = *(void **)&__src[v9];
  *(void *)&__dst[v9] = v10;
  uint64_t v22 = a3;
  uint64_t v11 = a3[6];
  char v12 = &__dst[v11];
  uint64_t v13 = &__src[v11];
  uint64_t v14 = *(void *)&__src[v11 + 24];
  v10;
  if (v14)
  {
    *((void *)v12 + 3) = v14;
    (**(void (***)(char *, char *, uint64_t))(v14 - 8))(v12, v13, v14);
  }
  else
  {
    long long v15 = *(_OWORD *)v13;
    *((_OWORD *)v12 + 1) = *((_OWORD *)v13 + 1);
    *(_OWORD *)char v12 = v15;
  }
  uint64_t v16 = v22[7];
  *(void *)&__dst[v16] = *(void *)&__src[v16];
  uint64_t v17 = *(void *)&__src[v16 + 8];
  *(void *)&__dst[v16 + 8] = v17;
  uint64_t v18 = v22[8];
  *(void *)&__dst[v18] = *(void *)&__src[v18];
  uint64_t v19 = *(void *)&__src[v18 + 8];
  *(void *)&__dst[v18 + 8] = v19;
  uint64_t v20 = v22[9];
  __dst[v20 + 8] = __src[v20 + 8];
  *(void *)&__dst[v20] = *(void *)&__src[v20];
  swift_bridgeObjectRetain(v17);
  swift_bridgeObjectRetain(v19);
  return __dst;
}

char *assignWithCopy for MLTextClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)__dst, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
    uint64_t v5 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
    if (swift_getEnumCaseMultiPayload(__src, v5) == 2)
    {
      uint64_t v6 = type metadata accessor for URL(0);
      if (__swift_getEnumTagSinglePayload((uint64_t)__src, 4, v6))
      {
        uint64_t v7 = type metadata accessor for MLTextClassifier.FeatureExtractorType(0);
        memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
      }
      else
      {
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16))(__dst, __src, v6);
        __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 4, v6);
      }
      uint64_t v8 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLTextClassifier.FeatureExtractorType, revision: Int?))
                  + 48);
      __dst[v8 + 8] = __src[v8 + 8];
      *(void *)&__dst[v8] = *(void *)&__src[v8];
      swift_storeEnumTagMultiPayload(__dst, v5, 2);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
    }
  }
  uint64_t v9 = a3[5];
  uint64_t v10 = *(void **)&__dst[v9];
  uint64_t v11 = *(void **)&__src[v9];
  *(void *)&__dst[v9] = v11;
  v11;

  uint64_t v12 = a3[6];
  uint64_t v13 = &__dst[v12];
  uint64_t v14 = &__src[v12];
  uint64_t v15 = *(void *)&__src[v12 + 24];
  if (!*(void *)&__dst[v12 + 24])
  {
    if (v15)
    {
      *((void *)v13 + 3) = v15;
      (**(void (***)(char *, char *))(v15 - 8))(v13, v14);
      goto LABEL_15;
    }
LABEL_14:
    long long v16 = *(_OWORD *)v14;
    *((_OWORD *)v13 + 1) = *((_OWORD *)v14 + 1);
    *(_OWORD *)uint64_t v13 = v16;
    goto LABEL_15;
  }
  if (!v15)
  {
    __swift_destroy_boxed_opaque_existential_1Tm(&__dst[v12]);
    goto LABEL_14;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)&__dst[v12], (uint64_t *)&__src[v12]);
LABEL_15:
  uint64_t v17 = a3[7];
  *(void *)&__dst[v17] = *(void *)&__src[v17];
  uint64_t v18 = *(void *)&__src[v17 + 8];
  uint64_t v19 = *(void *)&__dst[v17 + 8];
  *(void *)&__dst[v17 + 8] = v18;
  swift_bridgeObjectRetain(v18);
  swift_bridgeObjectRelease(v19);
  uint64_t v20 = a3[8];
  *(void *)&__dst[v20] = *(void *)&__src[v20];
  uint64_t v21 = *(void *)&__src[v20 + 8];
  uint64_t v22 = *(void *)&__dst[v20 + 8];
  *(void *)&__dst[v20 + 8] = v21;
  swift_bridgeObjectRetain(v21);
  swift_bridgeObjectRelease(v22);
  uint64_t v23 = a3[9];
  __dst[v23 + 8] = __src[v23 + 8];
  *(void *)&__dst[v23] = *(void *)&__src[v23];
  return __dst;
}

char *initializeWithTake for MLTextClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v4 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  if (swift_getEnumCaseMultiPayload(__src, v4) == 2)
  {
    uint64_t v5 = type metadata accessor for URL(0);
    if (__swift_getEnumTagSinglePayload((uint64_t)__src, 4, v5))
    {
      uint64_t v6 = type metadata accessor for MLTextClassifier.FeatureExtractorType(0);
      memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
    }
    else
    {
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v5 - 8) + 32))(__dst, __src, v5);
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 4, v5);
    }
    uint64_t v7 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLTextClassifier.FeatureExtractorType, revision: Int?))
                + 48);
    __dst[v7 + 8] = __src[v7 + 8];
    *(void *)&__dst[v7] = *(void *)&__src[v7];
    swift_storeEnumTagMultiPayload(__dst, v4, 2);
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v4 - 8) + 64));
  }
  *(void *)&__dst[a3[5]] = *(void *)&__src[a3[5]];
  uint64_t v8 = a3[6];
  long long v9 = *(_OWORD *)&__src[v8];
  *(_OWORD *)&__dst[v8 + 16] = *(_OWORD *)&__src[v8 + 16];
  *(_OWORD *)&__dst[v8] = v9;
  *(_OWORD *)&__dst[a3[7]] = *(_OWORD *)&__src[a3[7]];
  *(_OWORD *)&__dst[a3[8]] = *(_OWORD *)&__src[a3[8]];
  uint64_t v10 = a3[9];
  *(void *)&__dst[v10] = *(void *)&__src[v10];
  __dst[v10 + 8] = __src[v10 + 8];
  return __dst;
}

char *assignWithTake for MLTextClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)__dst, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
    uint64_t v5 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
    if (swift_getEnumCaseMultiPayload(__src, v5) == 2)
    {
      uint64_t v6 = type metadata accessor for URL(0);
      if (__swift_getEnumTagSinglePayload((uint64_t)__src, 4, v6))
      {
        uint64_t v7 = type metadata accessor for MLTextClassifier.FeatureExtractorType(0);
        memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
      }
      else
      {
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 32))(__dst, __src, v6);
        __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 4, v6);
      }
      uint64_t v8 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLTextClassifier.FeatureExtractorType, revision: Int?))
                  + 48);
      __dst[v8 + 8] = __src[v8 + 8];
      *(void *)&__dst[v8] = *(void *)&__src[v8];
      swift_storeEnumTagMultiPayload(__dst, v5, 2);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
    }
  }
  uint64_t v9 = a3[5];
  uint64_t v10 = *(void **)&__dst[v9];
  *(void *)&__dst[v9] = *(void *)&__src[v9];

  uint64_t v11 = a3[6];
  uint64_t v12 = &__dst[v11];
  if (*(void *)&__dst[v11 + 24]) {
    __swift_destroy_boxed_opaque_existential_1Tm(&__dst[v11]);
  }
  long long v13 = *(_OWORD *)&__src[v11];
  *((_OWORD *)v12 + 1) = *(_OWORD *)&__src[v11 + 16];
  *(_OWORD *)uint64_t v12 = v13;
  uint64_t v14 = a3[7];
  *(void *)&__dst[v14] = *(void *)&__src[v14];
  uint64_t v15 = *(void *)&__dst[v14 + 8];
  *(void *)&__dst[v14 + 8] = *(void *)&__src[v14 + 8];
  swift_bridgeObjectRelease(v15);
  uint64_t v16 = a3[8];
  *(void *)&__dst[v16] = *(void *)&__src[v16];
  uint64_t v17 = *(void *)&__dst[v16 + 8];
  *(void *)&__dst[v16 + 8] = *(void *)&__src[v16 + 8];
  swift_bridgeObjectRelease(v17);
  uint64_t v18 = a3[9];
  __dst[v18 + 8] = __src[v18 + 8];
  *(void *)&__dst[v18] = *(void *)&__src[v18];
  return __dst;
}

uint64_t getEnumTagSinglePayload for MLTextClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_2C0437);
}

uint64_t sub_2C0437(uint64_t a1, unsigned int a2, uint64_t a3)
{
  unsigned int v4 = 0;
  uint64_t v5 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(a1, a2, v5);
  }
  int v7 = -1;
  if ((int)((*(void *)(a1 + *(int *)(a3 + 20)) >> 1) - 1) >= 0) {
    int v7 = (*(void *)(a1 + *(int *)(a3 + 20)) >> 1) - 1;
  }
  unsigned int v8 = v7 + 1;
  if ((*(void *)(a1 + *(int *)(a3 + 20)) & 0xFFFFFFFF00000001) == 0) {
    return v8;
  }
  return v4;
}

uint64_t storeEnumTagSinglePayload for MLTextClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_2C04B9);
}

uint64_t sub_2C04B9(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  if (*(_DWORD *)(*(void *)(v6 - 8) + 84) == a3) {
    return __swift_storeEnumTagSinglePayload(a1, a2, a2, v6);
  }
  uint64_t result = *(int *)(a4 + 20);
  *(void *)(a1 + result) = 2 * a2;
  return result;
}

uint64_t type metadata completion function for MLTextClassifier.ModelParameters(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLTextClassifier.ModelAlgorithmType(319);
  if (v2 <= 0x3F)
  {
    v3[0] = *(void *)(result - 8) + 64;
    v3[1] = "\b";
    v3[2] = &unk_351B10;
    v3[3] = &unk_351B28;
    v3[4] = &unk_351B28;
    v3[5] = &unk_351B40;
    swift_initStructMetadata(a1, 256, 6, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t MLHandActionClassifier.GraphCNN.compile()()
{
  v1[2] = v0;
  uint64_t v2 = type metadata accessor for Model(0);
  v1[3] = v2;
  uint64_t v3 = *(void *)(v2 - 8);
  v1[4] = v3;
  v1[5] = swift_task_alloc((*(void *)(v3 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLHandActionClassifier.GraphCNN.compile(), 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4[13];

  v4[12] = v0 | 0x1000000000000000;
  v4[11] = v1;
  memset(v4, 0, 72);
  MLHandActionClassifier.GraphCNN.export(metadata:)(v4);
  type metadata accessor for MLModel();
  uint64_t v2 = (uint64_t *)swift_task_alloc(dword_3A701C);
  *(void *)(v1 + 48) = v2;
  *uint64_t v2 = v1;
  v2[1] = (uint64_t)MLHandActionClassifier.GraphCNN.compile();
  return static MLModel.compile(_:)(*(void *)(v1 + 40));
}

{
  uint64_t v0;
  uint64_t v1;

  uint64_t v1 = *(void *)(v0 + 40);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 32) + 8))(v1, *(void *)(v0 + 24));
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLHandActionClassifier.GraphCNN.compile()(uint64_t a1)
{
  uint64_t v5 = *(void *)(*v2 + 48);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 56) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = MLHandActionClassifier.GraphCNN.compile();
  }
  else
  {
    *(void *)(v4 + 64) = a1;
    uint64_t v6 = MLSupportVectorClassifier.Model.exportAsCoreMLModel();
  }
  return swift_task_switch(v6, 0, 0);
}

void *MLHandActionClassifier.GraphCNN.trainableSublayers()()
{
  uint64_t v1 = type metadata accessor for BatchNorm(0);
  uint64_t v48 = *(void *)(v1 - 8);
  int64_t v2 = *(void *)(v48 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  char v45 = &v33;
  uint64_t v42 = type metadata accessor for Dense(0);
  uint64_t v46 = *(void *)(v42 - 8);
  int64_t v5 = *(void *)(v46 + 64);
  uint64_t v6 = alloca(v5);
  int v7 = alloca(v5);
  char v43 = &v33;
  uint64_t v54 = type metadata accessor for Conv2D(0);
  uint64_t v44 = *(void *)(v54 - 8);
  int64_t v8 = *(void *)(v44 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  long long v41 = &v33;
  uint64_t v11 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  int64_t v12 = *(void *)(*(void *)(v11 - 8) + 64);
  long long v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v15 = OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model + v0;
  swift_beginAccess(v15, v34, 0, 0);
  outlined init with copy of MLTrainingSessionParameters(v15, (uint64_t)&v33, type metadata accessor for MLHandActionClassifier.GraphCNNModel);
  uint64_t v16 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, (uint64_t)&protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  uint64_t v17 = Layer.sublayers(recursively:)(1, v11, v16);
  outlined destroy of MLImageClassifier.ModelParameters.ValidationData((uint64_t)&v33, type metadata accessor for MLHandActionClassifier.GraphCNNModel);
  swift_retain();
  uint64_t v18 = dispatch thunk of _AnySequenceBox._makeIterator()(v17);
  uint64_t v49 = v17;
  swift_release();
  uint64_t v53 = v18;
  dispatch thunk of _AnyIteratorBoxBase.next()(v17);
  if (v40)
  {
    uint64_t v47 = v1;
    uint64_t v55 = _swiftEmptyArrayStorage;
    uint64_t v19 = v54;
    do
    {
      outlined init with take of MLIdentifier(&v39, (uint64_t)v36);
      outlined init with copy of TabularRegressionTask((uint64_t)v36, (uint64_t)v35);
      uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Layer);
      uint64_t v21 = v41;
      if (swift_dynamicCast(v41, v35, v20, v19, 0))
      {
        outlined init with copy of TabularRegressionTask((uint64_t)v36, (uint64_t)&v50);
        (*(void (**)(uint64_t *, uint64_t))(v44 + 8))(v21, v19);
      }
      else
      {
        uint64_t v22 = v43;
        uint64_t v23 = v42;
        if (swift_dynamicCast(v43, v35, v20, v42, 0))
        {
          outlined init with copy of TabularRegressionTask((uint64_t)v36, (uint64_t)&v50);
          (*(void (**)(uint64_t *, uint64_t))(v46 + 8))(v22, v23);
          uint64_t v19 = v54;
        }
        else
        {
          uint64_t v24 = v45;
          uint64_t v25 = v47;
          if (swift_dynamicCast(v45, v35, v20, v47, 0))
          {
            outlined init with copy of TabularRegressionTask((uint64_t)v36, (uint64_t)&v50);
            (*(void (**)(uint64_t *, uint64_t))(v48 + 8))(v24, v25);
            uint64_t v19 = v54;
          }
          else
          {
            uint64_t v26 = v37;
            uint64_t v27 = v38;
            __swift_project_boxed_opaque_existential_0Tm(v36, v37);
            uint64_t v28 = Layer.parameters(recursively:)(0, v26, v27);
            uint64_t v29 = *(void *)(v28 + 16);
            swift_bridgeObjectRelease(v28);
            if (v29)
            {
              outlined init with copy of TabularRegressionTask((uint64_t)v36, (uint64_t)&v50);
            }
            else
            {
              long long v51 = 0;
              long long v50 = 0;
              uint64_t v52 = 0;
            }
            uint64_t v19 = v54;
          }
        }
      }
      __swift_destroy_boxed_opaque_existential_1Tm(v35);
      __swift_destroy_boxed_opaque_existential_1Tm(v36);
      if (*((void *)&v51 + 1))
      {
        outlined init with take of MLIdentifier(&v50, (uint64_t)v35);
        outlined init with take of MLIdentifier(v35, (uint64_t)&v50);
        if (!swift_isUniquelyReferenced_nonNull_native(v55)) {
          uint64_t v55 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v55[2] + 1, 1, (uint64_t)v55);
        }
        unint64_t v30 = v55[2];
        if (v55[3] >> 1 <= v30) {
          uint64_t v55 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v55[3] >= 2uLL, v30 + 1, 1, (uint64_t)v55);
        }
        uint64_t v31 = v55;
        v55[2] = v30 + 1;
        outlined init with take of MLIdentifier(&v50, (uint64_t)&v31[5 * v30 + 4]);
      }
      else
      {
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v50, &demangling cache variable for type metadata for Layer?);
      }
      dispatch thunk of _AnyIteratorBoxBase.next()(&v50);
    }
    while (v40);
  }
  else
  {
    uint64_t v55 = _swiftEmptyArrayStorage;
  }
  swift_release();
  swift_release();
  return v55;
}

uint64_t MLHandActionClassifier.GraphCNN.export(metadata:)(uint64_t *a1)
{
  uint64_t v112 = v2;
  uint64_t v120 = v1;
  uint64_t v83 = type metadata accessor for ModelKind(0);
  uint64_t v84 = *(void *)(v83 - 8);
  int64_t v3 = *(void *)(v84 + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  uint64_t v85 = &v82;
  uint64_t v86 = type metadata accessor for NeuralNetworkClassifier.ClassLabels(0);
  uint64_t v87 = *(void *)(v86 - 8);
  int64_t v6 = *(void *)(v87 + 64);
  int v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v89 = &v82;
  uint64_t v91 = type metadata accessor for NeuralNetwork.ArrayShapeMapping(0);
  uint64_t v92 = *(void *)(v91 - 8);
  int64_t v9 = *(void *)(v92 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  unsigned int v93 = &v82;
  uint64_t v88 = type metadata accessor for NeuralNetworkClassifier(0);
  uint64_t v113 = *(void *)(v88 - 8);
  int64_t v12 = *(void *)(v113 + 64);
  long long v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v90 = &v82;
  uint64_t v114 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType(0);
  uint64_t v115 = *(void *)(v114 - 8);
  int64_t v15 = *(void *)(v115 + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  v103 = &v82;
  uint64_t v95 = type metadata accessor for FeatureType(0);
  uint64_t v96 = *(void *)(v95 - 8);
  int64_t v18 = *(void *)(v96 + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  v121 = (char *)&v82;
  uint64_t v21 = alloca(v18);
  uint64_t v22 = alloca(v18);
  uint64_t v97 = &v82;
  uint64_t v23 = alloca(v18);
  uint64_t v24 = alloca(v18);
  v122 = &v82;
  uint64_t v25 = type metadata accessor for LearningPhase(0);
  uint64_t v123 = *(void *)(v25 - 8);
  uint64_t v118 = (void *)v25;
  int64_t v26 = *(void *)(v123 + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  uint64_t v107 = *a1;
  uint64_t v94 = a1[1];
  uint64_t v110 = a1[2];
  uint64_t v111 = a1[3];
  uint64_t v105 = a1[4];
  unint64_t v106 = a1[5];
  uint64_t v108 = a1[6];
  uint64_t v109 = a1[7];
  uint64_t v104 = a1[8];
  uint64_t v29 = v2 + OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model;
  swift_beginAccess(v2 + OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model, &v116, 33, 0);
  uint64_t v30 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  uint64_t v31 = *(int *)(v30 + 36);
  uint64_t v119 = v30;
  *(unsigned char *)(v31 + v29) = 1;
  uint64_t v124 = v29;
  uint64_t v32 = v25;
  uint64_t v33 = v123;
  (*(void (**)(uint64_t *, void, uint64_t))(v123 + 104))(&v82, enum case for LearningPhase.inference(_:), v32);
  uint64_t v34 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, (uint64_t)&protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  Layer.prepare(for:)(&v82, v30, v34);
  swift_endAccess(&v116);
  (*(void (**)(uint64_t *, void *))(v33 + 8))(&v82, v118);
  uint64_t v118 = MLHandActionClassifier.GraphCNN.updatedCoreMLLayers()();
  Model.init()();
  Model.specificationVersion.setter(4);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  uint64_t v98 = v35;
  uint64_t v36 = *(void *)(type metadata accessor for FeatureDescription(0) - 8);
  uint64_t v123 = *(void *)(v36 + 72);
  uint64_t v37 = *(unsigned __int8 *)(v36 + 80);
  uint64_t v38 = (v37 + 32) & ~v37;
  uint64_t v100 = v38;
  uint64_t v99 = v37 | 7;
  uint64_t v39 = swift_allocObject(v35, v38 + v123, v37 | 7);
  uint64_t v101 = v39;
  *(void *)(v39 + 16) = 1;
  *(void *)(v39 + 24) = 2;
  uint64_t v102 = v38 + v39;
  uint64_t v40 = v103;
  (*(void (**)(uint64_t *, void, uint64_t))(v115 + 104))(v103, enum case for FeatureType.ShapedArrayParameters.DataType.float32(_:), v114);
  uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v42 = (void *)swift_allocObject(v41, 56, 7);
  int v42[2] = 3;
  v42[3] = 6;
  uint64_t v43 = v119;
  uint64_t v44 = v124;
  v42[4] = *(void *)(*(int *)(v119 + 40) + v124);
  v42[5] = 3;
  v42[6] = 21;
  static FeatureType.shapedArray(dataType:shape:optional:)(v40, v42, 0);
  swift_bridgeObjectRelease((_BYTE)v42);
  (*(void (**)(uint64_t *, uint64_t))(v115 + 8))(v40, v114);
  unint64_t v116 = 0;
  uint64_t v117 = (char *)0xE000000000000000;
  _StringGuts.grow(_:)(446);
  v48._char object = (void *)0xE200000000000000;
  v48._uint64_t countAndFlagsBits = 8257;
  String.append(_:)(v48);
  uint64_t v45 = *(int *)(v43 + 40);
  uint64_t v46 = v43;
  BOOL v47 = *(void *)(v45 + v44) < 2;
  v48._uint64_t countAndFlagsBits = 0x736F7020646E6168;
  if (*(uint64_t *)(v45 + v44) >= 2) {
    v48._uint64_t countAndFlagsBits = 0xD000000000000016;
  }
  uint64_t v49 = (char *)0xE900000000000065;
  if (!v47) {
    uint64_t v49 = "Most likely hand " + 0x8000000000000000;
  }
  v48._char object = v49;
  String.append(_:)(v48);
  swift_bridgeObjectRelease((_BYTE)v49);
  v50._uint64_t countAndFlagsBits = 0xD000000000000052;
  v50._char object = " channels, but coreml has " + 0x8000000000000000;
  String.append(_:)(v50);
  uint64_t v51 = v124;
  uint64_t v82 = *(void *)(*(int *)(v46 + 40) + v124);
  uint64_t v52 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  char v54 = (char)v53;
  v50._uint64_t countAndFlagsBits = v52;
  v50._char object = v53;
  String.append(_:)(v50);
  swift_bridgeObjectRelease(v54);
  v50._uint64_t countAndFlagsBits = 0x656D61726620;
  v56._char object = (void *)0xE600000000000000;
  String.append(_:)(v56);
  uint64_t v55 = *(int *)(v46 + 40);
  v56._uint64_t countAndFlagsBits = 115;
  if (*(uint64_t *)(v55 + v51) < 2) {
    v56._uint64_t countAndFlagsBits = 0;
  }
  v56._char object = (void *)(((*(void *)(v55 + v51) >= 2) | 0xFFFFFFFFFFFFFFE0) << 56);
  String.append(_:)(v56);
  swift_bridgeObjectRelease(0);
  unint64_t v57 = 0xD00000000000015ELL;
  v62._char object = "o index time over " + 0x8000000000000000;
  String.append(_:)(v62);
  FeatureDescription.init(name:type:description:)(0x7365736F70, 0xE500000000000000, v122, v116, v117);
  Model.inputs.setter(v101);
  uint64_t v58 = swift_allocObject(v98, v100 + 2 * v123, v99);
  v122 = (uint64_t *)v58;
  *(void *)(v58 + 16) = 2;
  *(void *)(v58 + 24) = 4;
  uint64_t v59 = v97;
  static FeatureType.dictionaryWithStringKeys(optional:)(0);
  FeatureDescription.init(name:type:description:)(0xD000000000000012, "shape does not match." + 0x8000000000000000, v59, 0xD000000000000039, "ttlePIP, littleDIP, littleTip." + 0x8000000000000000);
  uint64_t v60 = v121;
  FeatureType.StringParameters.init(optional:)(0);
  (*(void (**)(char *, void, uint64_t))(v96 + 104))(v60, enum case for FeatureType.string(_:), v95);
  unint64_t v116 = 0;
  uint64_t v117 = (char *)0xE000000000000000;
  _StringGuts.grow(_:)(29);
  swift_bridgeObjectRelease((_BYTE)v117);
  unint64_t v116 = 0xD000000000000011;
  uint64_t v117 = "orresponding confidences." + 0x8000000000000000;
  uint64_t v61 = *(int *)(v119 + 40);
  v62._uint64_t countAndFlagsBits = 1702063984;
  if (*(uint64_t *)(v61 + v124) >= 2) {
    v62._uint64_t countAndFlagsBits = 0x6E6F69746361;
  }
  v62._char object = (void *)(((*(void *)(v61 + v124) >= 2) | 0xFFFFFFFFFFFFFFF2) << 57);
  String.append(_:)(v62);
  swift_bridgeObjectRelease(0);
  v63._uint64_t countAndFlagsBits = 0x726F676574616320;
  v63._char object = (void *)0xEA00000000002E79;
  String.append(_:)(v63);
  FeatureDescription.init(name:type:description:)(0x6C6562616CLL, 0xE500000000000000, v121, v116, v117);
  Model.outputs.setter(v122);
  uint64_t v64 = v94;
  Model.predictedFeatureName.setter(0x6C6562616CLL, 0xE500000000000000);
  v121 = "shape does not match." + 0x8000000000000000;
  Model.predictedProbabilitiesName.setter(0xD000000000000012, "shape does not match." + 0x8000000000000000);
  if (v64)
  {
    uint64_t v65 = v111;
    swift_bridgeObjectRetain(v111);
    Model.modelDescription.setter(v110, v65);
    uint64_t v66 = v109;
    swift_bridgeObjectRetain(v109);
    Model.versionString.setter(v108, v66);
    swift_bridgeObjectRetain(v64);
    Model.author.setter(v107, v64);
    uint64_t v67 = v105;
    if (!v106) {
      uint64_t v67 = 0;
    }
    unint64_t v68 = 0xE000000000000000;
    if (v106) {
      unint64_t v68 = v106;
    }
    swift_bridgeObjectRetain(v106);
    Model.license.setter(v67, v68);
    char v69 = v104;
    if (v104)
    {
      uint64_t v70 = v104;
    }
    else
    {
      uint64_t v70 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for String, &protocol witness table for String);
      char v69 = 0;
    }
    swift_bridgeObjectRetain(v69);
    Model.metadata.setter(v70);
  }
  unint64_t v116 = *(void *)(v124 + *(int *)(v119 + 40));
  uint64_t v71 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  uint64_t v73 = v72;
  uint64_t v74 = (void (*)(unint64_t *, void))Model.metadata.modify(&v116);
  specialized Dictionary._Variant.setValue(_:forKey:)(v71, v73, 0xD000000000000016, (uint64_t)("Number of Labels" + 0x8000000000000000));
  v74(&v116, 0);
  uint64_t v75 = v90;
  NeuralNetworkClassifier.init(layers:preprocessors:)(v118, _swiftEmptyArrayStorage);
  uint64_t v76 = v93;
  (*(void (**)(uint64_t *, void, uint64_t))(v92 + 104))(v93, enum case for NeuralNetwork.ArrayShapeMapping.exactArrayMapping(_:), v91);
  NeuralNetworkClassifier.arrayInputShapeMapping.setter(v76);
  NeuralNetworkClassifier.labelProbabilityLayerName.setter(0xD000000000000012, v121);
  uint64_t v77 = *(void *)(v112 + 16);
  uint64_t v78 = v89;
  *uint64_t v89 = v77;
  (*(void (**)(uint64_t *, void, uint64_t))(v87 + 104))(v78, enum case for NeuralNetworkClassifier.ClassLabels.string(_:), v86);
  swift_bridgeObjectRetain(v77);
  NeuralNetworkClassifier.classLabels.setter(v78);
  uint64_t v79 = v85;
  uint64_t v80 = v88;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v113 + 16))(v85, v75, v88);
  (*(void (**)(uint64_t *, void, uint64_t))(v84 + 104))(v79, enum case for ModelKind.neuralNetworkClassifier(_:), v83);
  Model.kind.setter(v79);
  (*(void (**)(uint64_t *, uint64_t))(v113 + 8))(v75, v80);
  uint64_t result = *(int *)(v119 + 36);
  *(unsigned char *)(v124 + result) = 0;
  return result;
}

void *specialized _ModelCheckpoint<>.layerStateKeyPathLookup.getter()
{
  uint64_t v35 = type metadata accessor for LayerState(0);
  uint64_t v36 = *(void *)(v35 - 8);
  int64_t v1 = *(void *)(v36 + 64);
  uint64_t v2 = alloca(v1);
  int64_t v3 = alloca(v1);
  uint64_t v37 = &v32;
  uint64_t v4 = type metadata accessor for MLActivityClassifier.Model(0);
  int64_t v5 = *(void *)(*(void *)(v4 - 8) + 64);
  int64_t v6 = alloca(v5);
  int v7 = alloca(v5);
  uint64_t v8 = OBJC_IVAR____TtCVV8CreateML20MLActivityClassifier7Trainer14ModelContainer_model + v0;
  swift_beginAccess(v8, v33, 0, 0);
  uint64_t v34 = v8;
  outlined init with copy of MLTrainingSessionParameters(v8, (uint64_t)&v32, type metadata accessor for MLActivityClassifier.Model);
  uint64_t v9 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model and conformance MLActivityClassifier.Model, type metadata accessor for MLActivityClassifier.Model, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model);
  uint64_t v10 = Layer.layerStateKeyPaths(recursively:)(1, v4, v9);
  uint64_t v38 = &v32;
  outlined destroy of MLImageClassifier.ModelParameters.ValidationData((uint64_t)&v32, type metadata accessor for MLActivityClassifier.Model);
  uint64_t v11 = v10 & 0xFFFFFFFFFFFFF8;
  if ((v10 & 0x4000000000000001) != 0)
  {
    if (v10) {
      uint64_t v11 = v10;
    }
    swift_bridgeObjectRetain(v10);
    uint64_t v12 = _CocoaArrayWrapper.endIndex.getter(v11);
    swift_bridgeObjectRelease(v10);
  }
  else
  {
    uint64_t v12 = *(void *)((char *)&dword_10 + (v10 & 0xFFFFFFFFFFFFF8));
  }
  long long v13 = _swiftEmptyDictionarySingleton;
  if (v12)
  {
    uint64_t v14 = 0;
    uint64_t v39 = v10;
    uint64_t v40 = v12;
    do
    {
      if ((v10 & 0xC000000000000003) != 0)
      {
        uint64_t v15 = specialized _ArrayBuffer._getElementSlowPath(_:)(v14, v10);
      }
      else
      {
        uint64_t v15 = *(void *)(v10 + 8 * v14 + 32);
        swift_retain();
      }
      BOOL v16 = __OFADD__(1, v14);
      uint64_t v17 = v14 + 1;
      if (v16) {
        BUG();
      }
      uint64_t v41 = v17;
      uint64_t v18 = (uint64_t)v38;
      outlined init with copy of MLTrainingSessionParameters(v34, (uint64_t)v38, type metadata accessor for MLActivityClassifier.Model);
      swift_retain();
      uint64_t v19 = v15;
      uint64_t v20 = v37;
      swift_getAtKeyPath(v18, v19);
      uint64_t v42 = v19;
      swift_release();
      outlined destroy of MLImageClassifier.ModelParameters.ValidationData(v18, type metadata accessor for MLActivityClassifier.Model);
      LODWORD(v18) = LayerState.id.getter();
      (*(void (**)(uint64_t *, uint64_t))(v36 + 8))(v20, v35);
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v13);
      uint64_t v43 = v13;
      unsigned int v44 = v18;
      unint64_t v23 = specialized __RawDictionaryStorage.find<A>(_:)(v18);
      BOOL v24 = (v22 & 1) == 0;
      BOOL v16 = __OFADD__(v13[2], v24);
      Swift::Int v25 = v13[2] + v24;
      if (v16) {
        BUG();
      }
      char v26 = v22;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<UInt32, WritableKeyPath<MLActivityClassifier.Model, LayerState>>);
      if (_NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v25))
      {
        unint64_t v23 = specialized __RawDictionaryStorage.find<A>(_:)(v44);
        if ((v26 & 1) != (v27 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for UInt32);
          BUG();
        }
      }
      long long v13 = v43;
      if (v26)
      {
        uint64_t v28 = v43[7];
        swift_release();
        *(void *)(v28 + 8 * v23) = v42;
        uint64_t v14 = v41;
      }
      else
      {
        v43[(v23 >> 6) + 8] |= 1 << v23;
        *(_DWORD *)(v13[6] + 4 * v23) = v44;
        *(void *)(v13[7] + 8 * v23) = v42;
        uint64_t v29 = v13[2];
        BOOL v16 = __OFADD__(1, v29);
        uint64_t v30 = v29 + 1;
        uint64_t v14 = v41;
        if (v16) {
          BUG();
        }
        v13[2] = v30;
      }
      swift_bridgeObjectRelease(0);
      uint64_t v10 = v39;
    }
    while (v14 != v40);
  }
  swift_bridgeObjectRelease(v10);
  return v13;
}

{
  uint64_t v0;
  int64_t v1;
  void *v2;
  void *v3;
  uint64_t v4;
  int64_t v5;
  void *v6;
  void *v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v14;
  uint64_t v15;
  BOOL v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t *v20;
  char isUniquelyReferenced_nonNull_native;
  char v22;
  unint64_t v23;
  BOOL v24;
  Swift::Int v25;
  char v26;
  char v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v32;
  char v33[24];
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t *v37;
  uint64_t *v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  void *v43;
  unsigned int v44;

  uint64_t v35 = type metadata accessor for LayerState(0);
  uint64_t v36 = *(void *)(v35 - 8);
  int64_t v1 = *(void *)(v36 + 64);
  uint64_t v2 = alloca(v1);
  int64_t v3 = alloca(v1);
  uint64_t v37 = &v32;
  uint64_t v4 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  int64_t v5 = *(void *)(*(void *)(v4 - 8) + 64);
  int64_t v6 = alloca(v5);
  int v7 = alloca(v5);
  uint64_t v8 = OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model + v0;
  swift_beginAccess(v8, v33, 0, 0);
  uint64_t v34 = v8;
  outlined init with copy of MLTrainingSessionParameters(v8, (uint64_t)&v32, type metadata accessor for MLHandActionClassifier.GraphCNNModel);
  uint64_t v9 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, (uint64_t)&protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  uint64_t v10 = Layer.layerStateKeyPaths(recursively:)(1, v4, v9);
  uint64_t v38 = &v32;
  outlined destroy of MLImageClassifier.ModelParameters.ValidationData((uint64_t)&v32, type metadata accessor for MLHandActionClassifier.GraphCNNModel);
  uint64_t v11 = v10 & 0xFFFFFFFFFFFFF8;
  if ((v10 & 0x4000000000000001) != 0)
  {
    if (v10) {
      uint64_t v11 = v10;
    }
    swift_bridgeObjectRetain(v10);
    uint64_t v12 = _CocoaArrayWrapper.endIndex.getter(v11);
    swift_bridgeObjectRelease(v10);
  }
  else
  {
    uint64_t v12 = *(void *)((char *)&dword_10 + (v10 & 0xFFFFFFFFFFFFF8));
  }
  long long v13 = _swiftEmptyDictionarySingleton;
  if (v12)
  {
    uint64_t v14 = 0;
    uint64_t v39 = v10;
    uint64_t v40 = v12;
    do
    {
      if ((v10 & 0xC000000000000003) != 0)
      {
        uint64_t v15 = specialized _ArrayBuffer._getElementSlowPath(_:)(v14, v10);
      }
      else
      {
        uint64_t v15 = *(void *)(v10 + 8 * v14 + 32);
        swift_retain();
      }
      BOOL v16 = __OFADD__(1, v14);
      uint64_t v17 = v14 + 1;
      if (v16) {
        BUG();
      }
      uint64_t v41 = v17;
      uint64_t v18 = (uint64_t)v38;
      outlined init with copy of MLTrainingSessionParameters(v34, (uint64_t)v38, type metadata accessor for MLHandActionClassifier.GraphCNNModel);
      swift_retain();
      uint64_t v19 = v15;
      uint64_t v20 = v37;
      swift_getAtKeyPath(v18, v19);
      uint64_t v42 = v19;
      swift_release();
      outlined destroy of MLImageClassifier.ModelParameters.ValidationData(v18, type metadata accessor for MLHandActionClassifier.GraphCNNModel);
      LODWORD(v18) = LayerState.id.getter();
      (*(void (**)(uint64_t *, uint64_t))(v36 + 8))(v20, v35);
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v13);
      uint64_t v43 = v13;
      unsigned int v44 = v18;
      unint64_t v23 = specialized __RawDictionaryStorage.find<A>(_:)(v18);
      BOOL v24 = (v22 & 1) == 0;
      BOOL v16 = __OFADD__(v13[2], v24);
      Swift::Int v25 = v13[2] + v24;
      if (v16) {
        BUG();
      }
      char v26 = v22;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<UInt32, WritableKeyPath<MLHandActionClassifier.GraphCNNModel, LayerState>>);
      if (_NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v25))
      {
        unint64_t v23 = specialized __RawDictionaryStorage.find<A>(_:)(v44);
        if ((v26 & 1) != (v27 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for UInt32);
          BUG();
        }
      }
      long long v13 = v43;
      if (v26)
      {
        uint64_t v28 = v43[7];
        swift_release();
        *(void *)(v28 + 8 * v23) = v42;
        uint64_t v14 = v41;
      }
      else
      {
        v43[(v23 >> 6) + 8] |= 1 << v23;
        *(_DWORD *)(v13[6] + 4 * v23) = v44;
        *(void *)(v13[7] + 8 * v23) = v42;
        uint64_t v29 = v13[2];
        BOOL v16 = __OFADD__(1, v29);
        uint64_t v30 = v29 + 1;
        uint64_t v14 = v41;
        if (v16) {
          BUG();
        }
        v13[2] = v30;
      }
      swift_bridgeObjectRelease(0);
      uint64_t v10 = v39;
    }
    while (v14 != v40);
  }
  swift_bridgeObjectRelease(v10);
  return v13;
}

uint64_t NeuralNetwork.Layer.loadConv2DFromNeuralNetworks(_:useBias:into:)(void (*a1)(uint64_t *, uint64_t), int a2, uint64_t a3)
{
  int v51 = a2;
  uint64_t v53 = a1;
  uint64_t v49 = type metadata accessor for Conv2D(0);
  uint64_t v48 = *(void *)(v49 - 8);
  int64_t v4 = *(void *)(v48 + 64);
  int64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v52 = &v39;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.WeightParameters?)
                             - 8)
                 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v45 = &v39;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?)
                              - 8)
                  + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  unsigned int v44 = &v39;
  uint64_t v43 = type metadata accessor for Tensor(0);
  long long v13 = *(uint64_t **)(v43 - 8);
  int64_t v14 = v13[8];
  uint64_t v15 = alloca(v14);
  BOOL v16 = alloca(v14);
  uint64_t v46 = &v39;
  uint64_t v17 = alloca(v14);
  uint64_t v18 = alloca(v14);
  uint64_t v47 = type metadata accessor for NeuralNetwork.WeightParameters(0);
  int64_t v19 = *(void *)(*(void *)(v47 - 8) + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  uint64_t v50 = a3;
  uint64_t v22 = NeuralNetwork.Layer.ConvolutionParameters.outputChannelCount.getter();
  if (v22 != Conv2D.filterCount.getter())
  {
    (*(void (**)(uint64_t *, void (*)(uint64_t *, uint64_t), uint64_t))(v48 + 16))(v52, v53, v49);
    uint64_t v40 = 0;
    unint64_t v41 = 0xE000000000000000;
    _StringGuts.grow(_:)(99);
    v32._uint64_t countAndFlagsBits = 0xD00000000000003BLL;
    v32._char object = "Cannot load convolution layer " + 0x8000000000000000;
    String.append(_:)(v32);
    uint64_t v42 = Conv2D.filterCount.getter();
    uint64_t v33 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char v35 = (char)v34;
    v32._uint64_t countAndFlagsBits = v33;
    v32._char object = v34;
    String.append(_:)(v32);
    swift_bridgeObjectRelease(v35);
    v32._char object = "ral networks framework has " + 0x8000000000000000;
    v32._uint64_t countAndFlagsBits = 0xD00000000000001ALL;
    String.append(_:)(v32);
    uint64_t v42 = NeuralNetwork.Layer.ConvolutionParameters.outputChannelCount.getter();
    uint64_t v36 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char v38 = (char)v37;
    v32._uint64_t countAndFlagsBits = v36;
    v32._char object = v37;
    String.append(_:)(v32);
    swift_bridgeObjectRelease(v38);
    v32._uint64_t countAndFlagsBits = 0x6C656E6E61686320;
    v32._char object = (void *)0xEA00000000002E73;
    String.append(_:)(v32);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v40, v41, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 877, 0);
    BUG();
  }
  Conv2D.weight.getter();
  uint64_t v23 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  uint64_t v52 = v13;
  BOOL v24 = (void (*)(uint64_t *, uint64_t))v13[1];
  uint64_t v25 = v43;
  v24(&v39, v43);
  NeuralNetwork.WeightParameters.init(_:updatable:)(v23, 0);
  uint64_t result = NeuralNetwork.Layer.ConvolutionParameters.weights.setter(&v39);
  if (v51)
  {
    uint64_t v27 = (uint64_t)v44;
    Conv2D.bias.getter();
    if (__swift_getEnumTagSinglePayload(v27, 1, v25) == 1)
    {
      return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v27, &demangling cache variable for type metadata for Tensor?);
    }
    else
    {
      uint64_t v53 = v24;
      uint64_t v28 = v46;
      ((void (*)(uint64_t *, uint64_t, uint64_t))v52[4])(v46, v27, v25);
      uint64_t v29 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
      uint64_t v30 = v25;
      uint64_t v31 = (uint64_t)v45;
      NeuralNetwork.WeightParameters.init(_:updatable:)(v29, 0);
      __swift_storeEnumTagSinglePayload(v31, 0, 1, v47);
      NeuralNetwork.Layer.ConvolutionParameters.bias.setter(v31);
      return ((uint64_t (*)(uint64_t *, uint64_t))v53)(v28, v30);
    }
  }
  return result;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel()()
{
  uint64_t v437 = v0;
  uint64_t v479 = v1;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Parameter?)
                             - 8)
                 + 64);
  int64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  v427 = v403;
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dense?)
                             - 8)
                 + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  v406 = v403;
  uint64_t v455 = type metadata accessor for Dense(0);
  uint64_t v456 = *(void *)(v455 - 8);
  int64_t v11 = *(void *)(v456 + 64);
  uint64_t v12 = alloca(v11);
  long long v13 = alloca(v11);
  v471 = v403;
  uint64_t v462 = type metadata accessor for NeuralNetwork.Layer.InnerProductParameters(0);
  uint64_t v461 = *(void *)(v462 - 8);
  int64_t v14 = *(void *)(v461 + 64);
  uint64_t v15 = alloca(v14);
  BOOL v16 = alloca(v14);
  v474 = v403;
  uint64_t v420 = type metadata accessor for LayerState(0);
  uint64_t v421 = *(void *)(v420 - 8);
  int64_t v17 = *(void *)(v421 + 64);
  uint64_t v18 = alloca(v17);
  int64_t v19 = alloca(v17);
  v422 = v403;
  uint64_t v20 = alloca(v17);
  uint64_t v21 = alloca(v17);
  v423 = v403;
  int64_t v22 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for BatchNorm?)
                              - 8)
                  + 64);
  uint64_t v23 = alloca(v22);
  BOOL v24 = alloca(v22);
  v419 = v403;
  uint64_t v466 = type metadata accessor for BatchNorm(0);
  uint64_t v468 = *(void *)(v466 - 8);
  int64_t v25 = *(void *)(v468 + 64);
  char v26 = alloca(v25);
  uint64_t v27 = alloca(v25);
  v485 = v403;
  uint64_t v467 = type metadata accessor for NeuralNetwork.Layer.BatchNormalizeParameters(0);
  uint64_t v465 = *(void *)(v467 - 8);
  int64_t v28 = *(void *)(v465 + 64);
  uint64_t v29 = alloca(v28);
  uint64_t v30 = alloca(v28);
  v472 = v403;
  int64_t v31 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?)
                              - 8)
                  + 64);
  Swift::String v32 = alloca(v31);
  uint64_t v33 = alloca(v31);
  v429 = v403;
  uint64_t v34 = alloca(v31);
  char v35 = alloca(v31);
  v416 = v403;
  uint64_t v36 = alloca(v31);
  uint64_t v37 = alloca(v31);
  v454 = v403;
  int64_t v38 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?)
                              - 8)
                  + 64);
  uint64_t v39 = alloca(v38);
  uint64_t v40 = alloca(v38);
  v469 = v403;
  uint64_t v408 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.Extent<Int>);
  uint64_t v409 = *(void *)(v408 - 8);
  int64_t v41 = *(void *)(v409 + 64);
  uint64_t v42 = alloca(v41);
  uint64_t v43 = alloca(v41);
  v410 = v403;
  unsigned int v44 = alloca(v41);
  uint64_t v45 = alloca(v41);
  v411 = v403;
  uint64_t v488 = type metadata accessor for TensorShape(0);
  uint64_t v480 = *(void *)(v488 - 8);
  int64_t v46 = *(void *)(v480 + 64);
  uint64_t v47 = alloca(v46);
  uint64_t v48 = alloca(v46);
  v428 = v403;
  uint64_t v49 = alloca(v46);
  uint64_t v50 = alloca(v46);
  v407 = v403;
  int v51 = alloca(v46);
  uint64_t v52 = alloca(v46);
  v432 = v403;
  uint64_t v53 = alloca(v46);
  char v54 = alloca(v46);
  v464 = v403;
  uint64_t v55 = alloca(v46);
  Swift::String v56 = alloca(v46);
  v412 = v403;
  uint64_t v470 = type metadata accessor for Tensor(0);
  uint64_t v439 = *(void *)(v470 - 8);
  int64_t v57 = *(void *)(v439 + 64);
  uint64_t v58 = alloca(v57);
  uint64_t v59 = alloca(v57);
  v430 = v403;
  uint64_t v60 = alloca(v57);
  uint64_t v61 = alloca(v57);
  v417 = v403;
  Swift::String v62 = alloca(v57);
  Swift::String v63 = alloca(v57);
  v424 = v403;
  uint64_t v64 = alloca(v57);
  uint64_t v65 = alloca(v57);
  v418 = v403;
  uint64_t v452 = type metadata accessor for Parameter(0);
  uint64_t v438 = *(void *)(v452 - 8);
  int64_t v66 = *(void *)(v438 + 64);
  uint64_t v67 = alloca(v66);
  unint64_t v68 = alloca(v66);
  v413 = v403;
  char v69 = alloca(v66);
  uint64_t v70 = alloca(v66);
  v425 = v403;
  uint64_t v71 = alloca(v66);
  uint64_t v72 = alloca(v66);
  v426 = v403;
  uint64_t v73 = alloca(v66);
  uint64_t v74 = alloca(v66);
  v414 = v403;
  int64_t v75 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Conv2D?)
                              - 8)
                  + 64);
  uint64_t v76 = alloca(v75);
  uint64_t v77 = alloca(v75);
  v415 = v403;
  uint64_t v442 = type metadata accessor for Conv2D(0);
  uint64_t v443 = *(void *)(v442 - 8);
  int64_t v78 = *(void *)(v443 + 64);
  uint64_t v79 = alloca(v78);
  uint64_t v80 = alloca(v78);
  v450 = v403;
  uint64_t v440 = type metadata accessor for NeuralNetwork.Layer.ConvolutionParameters(0);
  uint64_t v441 = *(void *)(v440 - 8);
  int64_t v81 = *(void *)(v441 + 64);
  uint64_t v82 = alloca(v81);
  uint64_t v83 = alloca(v81);
  v449 = v403;
  v405[0] = type metadata accessor for NeuralNetwork.Layer.Kind(0);
  uint64_t v448 = *(void *)(v405[0] - 8);
  int64_t v84 = *(void *)(v448 + 64);
  uint64_t v85 = alloca(v84);
  uint64_t v86 = alloca(v84);
  v476 = v403;
  uint64_t v497 = type metadata accessor for NeuralNetwork.Layer(0);
  uint64_t v498 = *(void *)(v497 - 8);
  int64_t v87 = *(void *)(v498 + 64);
  uint64_t v88 = alloca(v87);
  uint64_t v89 = alloca(v87);
  v502 = v403;
  int64_t v90 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                              - 8)
                  + 64);
  uint64_t v91 = alloca(v90);
  uint64_t v92 = alloca(v90);
  v463 = v403;
  uint64_t v494 = type metadata accessor for URL(0);
  uint64_t v93 = *(void *)(v494 - 8);
  int64_t v94 = *(void *)(v93 + 64);
  uint64_t v95 = alloca(v94);
  uint64_t v96 = alloca(v94);
  v486 = v403;
  uint64_t v97 = alloca(v94);
  uint64_t v98 = alloca(v94);
  v484 = v403;
  uint64_t v99 = alloca(v94);
  uint64_t v100 = alloca(v94);
  uint64_t v101 = alloca(v94);
  uint64_t v102 = alloca(v94);
  v475 = v403;
  uint64_t ObjCClassFromMetadata = swift_getObjCClassFromMetadata();
  uint64_t v104 = objc_opt_self(NSBundle);
  id v105 = [v104 bundleForClass:ObjCClassFromMetadata];
  id v106 = v105;
  v431._uint64_t countAndFlagsBits = 0xD00000000000001ELL;
  id v107 = outlined bridged method (mbbnn) of @objc NSBundle.url(forResource:withExtension:)(0xD00000000000001ELL, (uint64_t)(" is not a valid CoreML model." + 0x8000000000000000), 0x73746867696577, 0xE700000000000000, v106);

  if (!v107)
  {
    uint64_t v109 = (uint64_t)v463;
    __swift_storeEnumTagSinglePayload((uint64_t)v463, 1, 1, v494);
    goto LABEL_98;
  }
  static URL._unconditionallyBridgeFromObjectiveC(_:)(v107);

  uint64_t v500 = v93;
  uint64_t v108 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v93 + 32);
  uint64_t v109 = (uint64_t)v463;
  uint64_t v110 = v494;
  v108(v463, v403, v494);
  __swift_storeEnumTagSinglePayload(v109, 0, 1, v110);
  if (__swift_getEnumTagSinglePayload(v109, 1, v110) == 1)
  {
LABEL_98:
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v109, &demangling cache variable for type metadata for URL?);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000002ALL, "+ModelExport.swift" + 0x8000000000000000, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 554, 0);
    goto LABEL_121;
  }
  uint64_t v111 = v475;
  v108(v475, (uint64_t *)v109, v110);
  if (one-time initialization token for logger != -1) {
    swift_once(&one-time initialization token for logger, one-time initialization function for logger);
  }
  uint64_t v112 = type metadata accessor for Logger(0);
  uint64_t v113 = __swift_project_value_buffer(v112, (uint64_t)static MLHandActionClassifier.logger);
  v463 = *(uint64_t **)(v500 + 16);
  ((void (*)(uint64_t *, uint64_t *, uint64_t))v463)(v484, v111, v110);
  v405[1] = v113;
  uint64_t v114 = (os_log_s *)Logger.logObject.getter();
  os_log_type_t v115 = static os_log_type_t.info.getter();
  int v116 = v115;
  os_log_t log = v114;
  if (os_log_type_enabled(v114, v115))
  {
    uint64_t v117 = (uint8_t *)swift_slowAlloc(12, -1);
    v444 = (void *)swift_slowAlloc(32, -1);
    char object = v444;
    *(_DWORD *)uint64_t v117 = 136315138;
    v496 = v117 + 4;
    uint64_t v118 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type URL and conformance URL, (uint64_t (*)(uint64_t))&type metadata accessor for URL, (uint64_t)&protocol conformance descriptor for URL);
    uint64_t v119 = v484;
    *(_DWORD *)type = v116;
    uint64_t v120 = v494;
    uint64_t v121 = dispatch thunk of CustomStringConvertible.description.getter(v494, v118);
    char v123 = v122;
    uint64_t v404 = getNullTerminatedUTF8PointerImpl(_:storingStringOwnersIn:)(v121, v122, (uint64_t *)&object);
    UnsafeMutableRawBufferPointer.copyMemory(from:)(&v404, v405, v496, v117 + 12);
    swift_bridgeObjectRelease(v123);
    uint64_t v124 = *(void (**)(uint64_t *, uint64_t))(v500 + 8);
    v124(v119, v120);
    os_log_t v125 = log;
    _os_log_impl(&dword_0, log, type[0], "Loading pre-trained model at %s", v117, 0xCu);
    v126 = v444;
    swift_arrayDestroy(v444, 1, (char *)&type metadata for Any + 8);
    swift_slowDealloc(v126, -1, -1);
    uint64_t v127 = v117;
    v128 = v475;
    swift_slowDealloc(v127, -1, -1);

    uint64_t v129 = v494;
  }
  else
  {
    v128 = v111;
    uint64_t v124 = *(void (**)(uint64_t *, uint64_t))(v500 + 8);
    uint64_t v129 = v494;
    v124(v484, v494);
  }
  uint64_t v130 = (uint64_t)v486;
  ((void (*)(uint64_t *, uint64_t *, uint64_t))v463)(v486, v128, v129);
  uint64_t v131 = v437;
  uint64_t v132 = Data.init(contentsOf:options:)(v130, 0);
  if (v131)
  {
    uint64_t v500 = v131;
    v124((uint64_t *)v130, v129);
    v124(v128, v129);
    return;
  }
  BlobsFile.init(data:)(v132, v133, v2, v3, v4);
  uint64_t v500 = 0;
  v477 = v124;
  v124((uint64_t *)v130, v129);
  uint64_t v134 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, [String : Int])>);
  v135 = (void *)swift_allocObject(v134, 920, 7);
  v135[2] = 37;
  v135[3] = 74;
  v135[4] = "_UnsafeHandle";
  v135[5] = 0xE300000000000000;
  v135[6] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #0 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[7] = 3616376;
  v135[8] = 0xE300000000000000;
  v135[9] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #1 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[10] = 120;
  v135[11] = 0xE100000000000000;
  v135[12] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #2 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[13] = 0x332E7475706E69;
  v135[14] = 0xE700000000000000;
  v135[15] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #3 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[16] = 0x352E7475706E69;
  v135[17] = 0xE700000000000000;
  v135[18] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #4 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[19] = 0x372E7475706E69;
  v135[20] = 0xE700000000000000;
  v135[21] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #5 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[22] = 0x382E7475706E69;
  v135[23] = 0xE700000000000000;
  v135[24] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #6 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[25] = 0x392E7475706E69;
  v135[26] = 0xE700000000000000;
  v135[27] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #7 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[28] = 0x32312E7475706E69;
  v135[29] = 0xE800000000000000;
  v135[30] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #8 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[31] = 0x34312E7475706E69;
  v135[32] = 0xE800000000000000;
  v135[33] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #9 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[34] = 0x35312E7475706E69;
  v135[35] = 0xE800000000000000;
  v135[36] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #10 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[37] = 0x36312E7475706E69;
  v135[38] = 0xE800000000000000;
  v135[39] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #11 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[40] = 0x39312E7475706E69;
  v135[41] = 0xE800000000000000;
  v135[42] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #12 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[43] = 0x31322E7475706E69;
  v135[44] = 0xE800000000000000;
  v135[45] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #13 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[46] = 0x32322E7475706E69;
  v135[47] = 0xE800000000000000;
  v135[48] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #14 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[49] = 0x33322E7475706E69;
  v135[50] = 0xE800000000000000;
  v135[51] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #15 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[52] = 0x36322E7475706E69;
  v135[53] = 0xE800000000000000;
  v135[54] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #16 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[55] = 0x38322E7475706E69;
  v135[56] = 0xE800000000000000;
  v135[57] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #17 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[58] = 0x39322E7475706E69;
  v135[59] = 0xE800000000000000;
  v135[60] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #18 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[61] = 0x30332E7475706E69;
  v135[62] = 0xE800000000000000;
  v135[63] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #19 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[64] = 0x33332E7475706E69;
  v135[65] = 0xE800000000000000;
  v135[66] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #20 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[67] = 0x35332E7475706E69;
  v135[68] = 0xE800000000000000;
  v135[69] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #21 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[70] = 0x36332E7475706E69;
  v135[71] = 0xE800000000000000;
  v135[72] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #22 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[73] = 0x39332E7475706E69;
  v135[74] = 0xE800000000000000;
  v135[75] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #23 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[76] = 0x31342E7475706E69;
  v135[77] = 0xE800000000000000;
  v135[78] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #24 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[79] = 0x32342E7475706E69;
  v135[80] = 0xE800000000000000;
  v135[81] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #25 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[82] = 0x33342E7475706E69;
  v135[83] = 0xE800000000000000;
  v135[84] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #26 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[85] = 0x36342E7475706E69;
  v135[86] = 0xE800000000000000;
  v135[87] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #27 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[88] = 0x38342E7475706E69;
  v135[89] = 0xE800000000000000;
  v135[90] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #28 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[91] = 0x39342E7475706E69;
  v135[92] = 0xE800000000000000;
  v135[93] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #29 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[94] = 0x30352E7475706E69;
  v135[95] = 0xE800000000000000;
  v135[96] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #30 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[97] = 0x6C61756469736572;
  v135[98] = 0xEA0000000000312ELL;
  v135[99] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #31 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[100] = 0x6C61756469736572;
  v135[101] = 0xEA0000000000322ELL;
  v135[102] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #32 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[103] = 0x6C61756469736572;
  v135[104] = 0xEA0000000000332ELL;
  v135[105] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #33 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[106] = 0x6C61756469736572;
  v135[107] = 0xEA0000000000342ELL;
  v135[108] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #34 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[109] = 0x6C61756469736572;
  v135[110] = 0xEA0000000000352ELL;
  v135[111] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #35 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  v135[112] = 0x6C61756469736572;
  v135[113] = 0xE800000000000000;
  v135[114] = Dictionary.init(dictionaryLiteral:)(&outlined read-only object #36 of MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel(), &type metadata for String, &type metadata for Int, &protocol witness table for String);
  uint64_t v136 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Int]);
  uint64_t v487 = Dictionary.init(dictionaryLiteral:)(v135, &type metadata for String, v136, &protocol witness table for String);
  uint64_t v137 = v479;
  v138 = MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:)(3uLL, 0x15uLL);
  v481 = MLHandActionClassifier.GraphCNN.coreMLTrainableLayerNames(from:)((uint64_t)v138);
  v486 = MLHandActionClassifier.GraphCNN.getCoreMLAndNeuralNetworksTrainableLayerMap(_:)((uint64_t)v481);
  uint64_t v139 = MLHandActionClassifier.GraphCNN.trainableSublayers()();
  *(void *)type = specialized _ModelCheckpoint<>.parameterKeyPathLookup.getter();
  v483 = specialized _ModelCheckpoint<>.layerStateKeyPathLookup.getter();
  uint64_t v140 = v138[2];
  v496 = (uint8_t *)v139;
  v478 = v138;
  if (!v140)
  {
LABEL_77:
    outlined release of BlobsFile(v403);
    swift_bridgeObjectRelease(v487);
    swift_bridgeObjectRelease((_BYTE)v478);
    swift_bridgeObjectRelease((_BYTE)v483);
    swift_bridgeObjectRelease(type[0]);
    swift_bridgeObjectRelease((_BYTE)v496);
    swift_bridgeObjectRelease((_BYTE)v486);
    char v344 = (char)v481;
    goto LABEL_84;
  }
  uint64_t v479 = OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model + v137;
  v141 = (void *)((char *)v138 + ((*(unsigned __int8 *)(v498 + 80) + 32) & ~*(unsigned __int8 *)(v498 + 80)));
  LODWORD(v463) = enum case for NeuralNetwork.Layer.Kind.innerProduct(_:);
  int v435 = enum case for NeuralNetwork.Layer.Kind.convolution(_:);
  int v436 = enum case for NeuralNetwork.Layer.Kind.batchNormalize(_:);
  v445 = v139 + 4;
  os_log_t log = *(os_log_t *)(v498 + 16);
  v444 = *(void **)(v498 + 72);
  v142 = v502;
  uint64_t v143 = v476;
  while (1)
  {
    uint64_t v437 = v140;
    v484 = v141;
    ((void (*)(uint64_t *, uint64_t *, uint64_t))log)(v142, v141, v497);
    NeuralNetwork.Layer.kind.getter();
    v144 = v143;
    uint64_t v145 = v405[0];
    uint64_t v146 = v143;
    uint64_t v147 = v448;
    int v148 = (*(uint64_t (**)(uint64_t *, void))(v448 + 88))(v144, v405[0]);
    if (v148 == v463) {
      break;
    }
    if (v148 == v435)
    {
      v163 = v476;
      (*(void (**)(uint64_t *, uint64_t))(v448 + 96))(v476, v145);
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v441 + 32))(v449, v163, v440);
      uint64_t v164 = NeuralNetwork.Layer.name.getter();
      char v166 = v165;
      uint64_t v167 = (uint64_t)v486;
      if (!v486[2] || (unint64_t v168 = specialized __RawDictionaryStorage.find<A>(_:)(v164, v165), (v169 & 1) == 0))
      {
        swift_bridgeObjectRelease(v166);
        char object = 0;
        v491 = (char *)0xE000000000000000;
        _StringGuts.grow(_:)(67);
        v353._uint64_t countAndFlagsBits = 0xD000000000000032;
        v353._char object = "etrained hand action model" + 0x8000000000000000;
        String.append(_:)(v353);
        uint64_t v354 = NeuralNetwork.Layer.name.getter();
        char v356 = (char)v355;
        v353._uint64_t countAndFlagsBits = v354;
        v353._char object = v355;
        String.append(_:)(v353);
        swift_bridgeObjectRelease(v356);
        v353._uint64_t countAndFlagsBits = 0x65726F63206E6920;
        v353._char object = (void *)0xEF63657073206C6DLL;
        String.append(_:)(v353);
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 619, 0);
        goto LABEL_121;
      }
      uint64_t v170 = *(void *)(*(void *)(v167 + 56) + 8 * v168);
      swift_bridgeObjectRelease(v166);
      uint64_t v171 = v487;
      if (v170 < 0) {
        BUG();
      }
      if ((unint64_t)v170 >= *((void *)v496 + 2)) {
        BUG();
      }
      outlined init with copy of TabularRegressionTask((uint64_t)&v445[5 * v170], (uint64_t)&object);
      uint64_t v172 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Layer);
      uint64_t v173 = (uint64_t)v415;
      uint64_t v174 = v442;
      if (!swift_dynamicCast(v415, &object, v172, v442, 6))
      {
        __swift_storeEnumTagSinglePayload(v173, 1, 1, v174);
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v173, &demangling cache variable for type metadata for Conv2D?);
        char object = 0;
        v491 = (char *)0xE000000000000000;
        _StringGuts.grow(_:)(80);
        v379._uint64_t countAndFlagsBits = 0xD00000000000003FLL;
        v379._char object = "layer state keypaths for " + 0x8000000000000000;
        String.append(_:)(v379);
        uint64_t v380 = NeuralNetwork.Layer.name.getter();
        char v382 = (char)v381;
        v379._uint64_t countAndFlagsBits = v380;
        v379._char object = v381;
        String.append(_:)(v379);
        swift_bridgeObjectRelease(v382);
        v379._uint64_t countAndFlagsBits = 0x65726F63206E6920;
        v379._char object = (void *)0xEF63657073206C6DLL;
        String.append(_:)(v379);
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 622, 0);
        goto LABEL_121;
      }
      __swift_storeEnumTagSinglePayload(v173, 0, 1, v174);
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v443 + 32))(v450, v173, v174);
      uint64_t v175 = NeuralNetwork.Layer.name.getter();
      char v177 = v176;
      if (!*(void *)(v171 + 16)
        || (unint64_t v178 = specialized __RawDictionaryStorage.find<A>(_:)(v175, v176), v180 = v452, (v179 & 1) == 0))
      {
        char v357 = v177;
LABEL_102:
        swift_bridgeObjectRelease(v357);
        char object = 0;
        v491 = (char *)0xE000000000000000;
        _StringGuts.grow(_:)(57);
        v358._char object = "ework layer to convolution for " + 0x8000000000000000;
        v358._uint64_t countAndFlagsBits = v431._countAndFlagsBits;
        String.append(_:)(v358);
        uint64_t v359 = NeuralNetwork.Layer.name.getter();
        char v361 = (char)v360;
        v358._uint64_t countAndFlagsBits = v359;
        v358._char object = v360;
        String.append(_:)(v358);
        swift_bridgeObjectRelease(v361);
        v358._char object = "Cannot load innerProduct layer " + 0x8000000000000000;
        v358._uint64_t countAndFlagsBits = 0xD000000000000019;
        String.append(_:)(v358);
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 628, 0);
        goto LABEL_121;
      }
      uint64_t v181 = *(void *)(*(void *)(v171 + 56) + 8 * v178);
      swift_bridgeObjectRetain(v181);
      swift_bridgeObjectRelease(v177);
      if (!*(void *)(v181 + 16)
        || (unint64_t v182 = specialized __RawDictionaryStorage.find<A>(_:)(0x746867696577, 0xE600000000000000),
            (v183 & 1) == 0))
      {
        char v357 = v181;
        goto LABEL_102;
      }
      v489 = *(char **)(*(void *)(v181 + 56) + 8 * v182);
      swift_bridgeObjectRelease(v181);
      v184 = v414;
      Conv2D.$weight.getter();
      unsigned int v185 = Parameter.id.getter(v181);
      (*(void (**)(uint64_t *, uint64_t))(v438 + 8))(v184, v180);
      uint64_t v186 = *(void *)type;
      if (!*(void *)(*(void *)type + 16)
        || (unint64_t v187 = specialized __RawDictionaryStorage.find<A>(_:)(v185), (v188 & 1) == 0))
      {
        char object = 0;
        v491 = (char *)0xE000000000000000;
        _StringGuts.grow(_:)(64);
        v362._uint64_t countAndFlagsBits = 0xD00000000000003DLL;
        v362._char object = " in from MIL Blob Storage" + 0x8000000000000000;
        String.append(_:)(v362);
        uint64_t v363 = NeuralNetwork.Layer.name.getter();
        char v365 = (char)v364;
        v362._uint64_t countAndFlagsBits = v363;
        v362._char object = v364;
        String.append(_:)(v362);
        swift_bridgeObjectRelease(v365);
        v362._uint64_t countAndFlagsBits = 46;
        v362._char object = (void *)0xE100000000000000;
        String.append(_:)(v362);
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 631, 0);
        goto LABEL_121;
      }
      uint64_t v189 = *(void *)(*(void *)(v186 + 56) + 8 * v187);
      uint64_t v190 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
      v191 = (void *)swift_allocObject(v190, 64, 7);
      v191[2] = 4;
      v191[3] = 8;
      uint64_t v501 = v189;
      swift_retain();
      v191[4] = NeuralNetwork.Layer.ConvolutionParameters.outputChannelCount.getter(v189);
      uint64_t v192 = NeuralNetwork.Layer.ConvolutionParameters.kernelChannelCount.getter();
      unint64_t v499 = (unint64_t)v191;
      v191[5] = v192;
      v193 = v411;
      NeuralNetwork.Layer.ConvolutionParameters.kernelSize.getter();
      uint64_t v194 = v408;
      NeuralNetwork.Extent.height.getter(v408);
      v482 = *(double (**)(uint64_t *, uint64_t))(v409 + 8);
      v482(v193, v194);
      unint64_t v473 = v499 + 56;
      v195 = v410;
      NeuralNetwork.Layer.ConvolutionParameters.kernelSize.getter();
      NeuralNetwork.Extent.width.getter(v194);
      *(double *)v2.i64 = v482(v195, v194);
      v196 = v412;
      TensorShape.init(_:)(v499, *(double *)v2.i64);
      uint64_t v197 = v500;
      v202 = BlobsFile.floatBlob(at:)((uint64_t)v489, v194, v198, v199, v200, v201);
      uint64_t v500 = v197;
      if (v197)
      {
        swift_release();
        outlined release of BlobsFile(v403);
        swift_bridgeObjectRelease((_BYTE)v483);
        swift_bridgeObjectRelease(type[0]);
        swift_bridgeObjectRelease((_BYTE)v496);
        swift_bridgeObjectRelease((_BYTE)v486);
        swift_bridgeObjectRelease((_BYTE)v481);
        swift_bridgeObjectRelease(v487);
        (*(void (**)(uint64_t *, uint64_t))(v480 + 8))(v196, v488);
        (*(void (**)(uint64_t *, uint64_t))(v443 + 8))(v450, v442);
        v345 = v449;
        uint64_t v346 = v440;
        uint64_t v347 = v441;
        goto LABEL_83;
      }
      char object = v202;
      uint64_t v203 = type metadata accessor for ComputeDevice(0);
      v204 = v196;
      uint64_t v205 = (uint64_t)v469;
      __swift_storeEnumTagSinglePayload((uint64_t)v469, 1, 1, v203);
      uint64_t v206 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
      lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float], (uint64_t)&protocol conformance descriptor for [A]);
      v207 = v418;
      Tensor.init<A>(shape:scalars:on:)(v204, &object, v205, v206);
      swift_beginAccess(v479, &object, 33, 0);
      uint64_t v208 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, (uint64_t)&protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
      uint64_t v209 = (uint64_t)v454;
      Layer.updateValue<A>(_:for:)(v207, v501, v208, &protocol witness table for Parameter);
      swift_endAccess(&object);
      swift_release();
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v209, &demangling cache variable for type metadata for Tensor?);
      (*(void (**)(uint64_t *, uint64_t))(v439 + 8))(v207, v470);
      (*(void (**)(uint64_t *, uint64_t))(v443 + 8))(v450, v442);
      v210 = v449;
      uint64_t v211 = v440;
      uint64_t v212 = v441;
    }
    else
    {
      uint64_t v143 = v476;
      v142 = v502;
      if (v148 != v436)
      {
        (*(void (**)(uint64_t *, uint64_t))(v498 + 8))(v502, v497);
        v160 = v143;
        uint64_t v161 = v145;
        uint64_t v162 = v448;
LABEL_75:
        (*(void (**)(uint64_t *, uint64_t))(v162 + 8))(v160, v161);
        goto LABEL_76;
      }
      (*(void (**)(uint64_t *, uint64_t))(v448 + 96))(v476, v145);
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v465 + 32))(v472, v143, v467);
      uint64_t v213 = NeuralNetwork.Layer.name.getter();
      char v215 = v214;
      uint64_t v216 = specialized Dictionary.subscript.getter(v213, v214, (uint64_t)v486);
      char v218 = v217;
      swift_bridgeObjectRelease(v215);
      if (v218)
      {
        char object = 0;
        v491 = (char *)0xE000000000000000;
        _StringGuts.grow(_:)(67);
        v391._uint64_t countAndFlagsBits = 0xD000000000000032;
        v391._char object = "etrained hand action model" + 0x8000000000000000;
        String.append(_:)(v391);
        uint64_t v392 = NeuralNetwork.Layer.name.getter();
        char v394 = (char)v393;
        v391._uint64_t countAndFlagsBits = v392;
        v391._char object = v393;
        String.append(_:)(v391);
        swift_bridgeObjectRelease(v394);
        v391._uint64_t countAndFlagsBits = 0x65726F63206E6920;
        v391._char object = (void *)0xEF63657073206C6DLL;
        String.append(_:)(v391);
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 641, 0);
        goto LABEL_121;
      }
      uint64_t v219 = v466;
      if (v216 < 0) {
        BUG();
      }
      v220 = v485;
      if ((unint64_t)v216 >= *((void *)v496 + 2)) {
        BUG();
      }
      outlined init with copy of TabularRegressionTask((uint64_t)&v445[5 * v216], (uint64_t)&object);
      uint64_t v221 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Layer);
      uint64_t v222 = (uint64_t)v419;
      if (!swift_dynamicCast(v419, &object, v221, v219, 6))
      {
        __swift_storeEnumTagSinglePayload(v222, 1, 1, v219);
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v222, &demangling cache variable for type metadata for BatchNorm?);
        char object = 0;
        v491 = (char *)0xE000000000000000;
        _StringGuts.grow(_:)(88);
        v395._uint64_t countAndFlagsBits = 0xD000000000000047;
        String.append(_:)(v395);
        uint64_t v396 = NeuralNetwork.Layer.name.getter();
        char v398 = (char)v397;
        v395._uint64_t countAndFlagsBits = v396;
        v395._char object = v397;
        String.append(_:)(v395);
        swift_bridgeObjectRelease(v398);
        v395._uint64_t countAndFlagsBits = 0x65726F63206E6920;
        v395._char object = (void *)0xEF63657073206C6DLL;
        String.append(_:)(v395);
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 644, 0);
        goto LABEL_121;
      }
      __swift_storeEnumTagSinglePayload(v222, 0, 1, v219);
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v468 + 32))(v220, v222, v219);
      uint64_t v223 = NeuralNetwork.Layer.name.getter();
      char v225 = v224;
      uint64_t v226 = specialized Dictionary.subscript.getter(v223, v224, v487);
      swift_bridgeObjectRelease(v225);
      if (!v226) {
        goto LABEL_109;
      }
      uint64_t v227 = specialized Dictionary.subscript.getter(1851876717, 0xE400000000000000, v226);
      if ((v228 & 1) != 0
        || (uint64_t v229 = v227,
            uint64_t v230 = specialized Dictionary.subscript.getter(0x65636E6169726176, 0xE800000000000000, v226),
            (v231 & 1) != 0)
        || (uint64_t v232 = v230,
            uint64_t v501 = specialized Dictionary.subscript.getter(1635018082, 0xE400000000000000, v226),
            (v233 & 1) != 0))
      {
        swift_bridgeObjectRelease(v226);
LABEL_109:
        char object = 0;
        v491 = (char *)0xE000000000000000;
        _StringGuts.grow(_:)(55);
        v375._uint64_t countAndFlagsBits = 0xD00000000000001CLL;
        v375._char object = "layer to batchnorm for " + 0x8000000000000000;
        String.append(_:)(v375);
        uint64_t v376 = NeuralNetwork.Layer.name.getter();
        char v378 = (char)v377;
        v375._uint64_t countAndFlagsBits = v376;
        v375._char object = v377;
        String.append(_:)(v375);
        swift_bridgeObjectRelease(v378);
        v375._char object = "Cannot load innerProduct layer " + 0x8000000000000000;
        v375._uint64_t countAndFlagsBits = 0xD000000000000019;
        String.append(_:)(v375);
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 653, 0);
        goto LABEL_121;
      }
      v482 = (double (*)(uint64_t *, uint64_t))specialized Dictionary.subscript.getter(0x616D6D6167, 0xE500000000000000, v226);
      char v235 = v234;
      swift_bridgeObjectRelease(v226);
      if (v235) {
        goto LABEL_109;
      }
      uint64_t v236 = NeuralNetwork.Layer.BatchNormalizeParameters.inputChannelCount.getter();
      uint64_t v237 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
      v238 = (void *)swift_allocObject(v237, 40, 7);
      v238[2] = 1;
      v238[3] = 2;
      unint64_t v499 = v236;
      v238[4] = v236;
      v239 = v464;
      TensorShape.init(_:)(v238, *(double *)v2.i64);
      uint64_t v240 = v500;
      v245 = BlobsFile.floatBlob(at:)(v229, 40, v241, v242, v243, v244);
      if (v240)
      {
        uint64_t v500 = v240;
        outlined release of BlobsFile(v403);
        swift_bridgeObjectRelease((_BYTE)v483);
        swift_bridgeObjectRelease(type[0]);
        swift_bridgeObjectRelease((_BYTE)v496);
        swift_bridgeObjectRelease((_BYTE)v486);
        swift_bridgeObjectRelease((_BYTE)v481);
        swift_bridgeObjectRelease(v487);
        (*(void (**)(uint64_t *, uint64_t))(v480 + 8))(v239, v488);
        (*(void (**)(uint64_t *, uint64_t))(v468 + 8))(v485, v466);
        v345 = v472;
        uint64_t v346 = v467;
        uint64_t v347 = v465;
        goto LABEL_83;
      }
      v489 = v245;
      v447 = BlobsFile.floatBlob(at:)(v232, 40, v246, v247, v248, v249);
      v433 = BlobsFile.floatBlob(at:)(v501, 40, v250, v251, v252, v253);
      v254 = v482;
      v259 = BlobsFile.floatBlob(at:)((uint64_t)v482, 40, v255, v256, v257, v258);
      uint64_t v500 = 0;
      v431._char object = v259;
      v260 = v426;
      BatchNorm.$offset.getter();
      unsigned int v261 = Parameter.id.getter(v254);
      v262 = v260;
      uint64_t v263 = v452;
      uint64_t v501 = *(void *)(v438 + 8);
      ((void (*)(uint64_t *, uint64_t))v501)(v262, v452);
      uint64_t v264 = v261;
      uint64_t v265 = *(void *)type;
      uint64_t v446 = specialized Dictionary.subscript.getter(v261, *(uint64_t *)type);
      if (!v446) {
        goto LABEL_115;
      }
      v266 = v425;
      BatchNorm.$scale.getter();
      unsigned int v267 = Parameter.id.getter(v264);
      ((void (*)(uint64_t *, uint64_t))v501)(v266, v263);
      uint64_t v268 = specialized Dictionary.subscript.getter(v267, v265);
      if (!v268) {
        goto LABEL_114;
      }
      uint64_t v434 = v268;
      v269 = v423;
      BatchNorm.$runningMean.getter();
      unsigned int v270 = LayerState.id.getter();
      v271 = v269;
      uint64_t v272 = v420;
      uint64_t v501 = *(void *)(v421 + 8);
      ((void (*)(uint64_t *, uint64_t))v501)(v271, v420);
      v273 = v483;
      uint64_t v460 = specialized Dictionary.subscript.getter(v270, (uint64_t)v483);
      if (!v460) {
        goto LABEL_113;
      }
      v274 = v422;
      BatchNorm.$runningVariance.getter();
      unsigned int v275 = LayerState.id.getter();
      ((void (*)(uint64_t *, uint64_t))v501)(v274, v272);
      v453 = (void (*)(uint64_t *, uint64_t))specialized Dictionary.subscript.getter(v275, (uint64_t)v273);
      if (!v453)
      {
        swift_release();
LABEL_113:
        swift_release();
LABEL_114:
        swift_release();
LABEL_115:
        char object = 0;
        v491 = (char *)0xE000000000000000;
        _StringGuts.grow(_:)(74);
        v387._uint64_t countAndFlagsBits = 0xD000000000000039;
        v387._char object = "Cannot load batchnorm layer " + 0x8000000000000000;
        String.append(_:)(v387);
        uint64_t v388 = NeuralNetwork.Layer.name.getter();
        char v390 = (char)v389;
        v387._uint64_t countAndFlagsBits = v388;
        v387._char object = v389;
        String.append(_:)(v387);
        swift_bridgeObjectRelease(v390);
        v387._uint64_t countAndFlagsBits = 0x65726F63206E6920;
        v387._char object = (void *)0xEF63657073206C6DLL;
        String.append(_:)(v387);
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 670, 0);
LABEL_121:
        BUG();
      }
      v276 = v432;
      uint64_t v501 = *(void *)(v480 + 16);
      ((void (*)(uint64_t *, uint64_t *, uint64_t))v501)(v432, v464, v488);
      uint64_t v277 = (uint64_t)v469;
      v278 = v424;
      if ((v499 & 0x8000000000000000) != 0) {
        BUG();
      }
      if (*((void *)v489 + 2) < v499) {
        BUG();
      }
      char object = v489;
      v491 = v489 + 32;
      uint64_t v492 = 0;
      v489 = (char *)(2 * v499 + 1);
      uint64_t v493 = (uint64_t)v489;
      v482 = (double (*)(uint64_t *, uint64_t))type metadata accessor for ComputeDevice(0);
      __swift_storeEnumTagSinglePayload(v277, 1, 1, (uint64_t)v482);
      uint64_t v279 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ArraySlice<Float>);
      uint64_t v280 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type ArraySlice<Float> and conformance ArraySlice<A>, &demangling cache variable for type metadata for ArraySlice<Float>, (uint64_t)&protocol conformance descriptor for ArraySlice<A>);
      unint64_t v473 = v279;
      uint64_t v458 = v280;
      Tensor.init<A>(shape:scalars:on:)(v276, &object, v277, v279);
      swift_beginAccess(v479, &object, 33, 0);
      uint64_t v281 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, (uint64_t)&protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
      uint64_t v282 = (uint64_t)v454;
      uint64_t v459 = v281;
      Layer.updateValue<A>(_:for:)(v278, v460, v281, &protocol witness table for LayerState);
      swift_endAccess(&object);
      v457 = *(void (**)(uint64_t *, uint64_t))(v439 + 8);
      v457(v278, v470);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v282, &demangling cache variable for type metadata for Tensor?);
      v283 = v432;
      ((void (*)(uint64_t *, uint64_t *, uint64_t))v501)(v432, v464, v488);
      if (*((void *)v447 + 2) < v499) {
        BUG();
      }
      char object = v447;
      v491 = v447 + 32;
      uint64_t v492 = 0;
      uint64_t v493 = (uint64_t)v489;
      uint64_t v284 = (uint64_t)v469;
      __swift_storeEnumTagSinglePayload((uint64_t)v469, 1, 1, (uint64_t)v482);
      Tensor.init<A>(shape:scalars:on:)(v283, &object, v284, v473);
      swift_beginAccess(v479, &object, 33, 0);
      uint64_t v285 = (uint64_t)v454;
      Layer.updateValue<A>(_:for:)(v278, v453, v459, &protocol witness table for LayerState);
      swift_endAccess(&object);
      v457(v278, v470);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v285, &demangling cache variable for type metadata for Tensor?);
      ((void (*)(uint64_t *, uint64_t *, uint64_t))v501)(v283, v464, v488);
      if (*((void *)v433 + 2) < v499) {
        BUG();
      }
      char object = v433;
      v491 = v433 + 32;
      uint64_t v492 = 0;
      uint64_t v493 = (uint64_t)v489;
      uint64_t v286 = (uint64_t)v469;
      __swift_storeEnumTagSinglePayload((uint64_t)v469, 1, 1, (uint64_t)v482);
      Tensor.init<A>(shape:scalars:on:)(v283, &object, v286, v473);
      swift_beginAccess(v479, &object, 33, 0);
      uint64_t v287 = (uint64_t)v454;
      Layer.updateValue<A>(_:for:)(v278, v446, v459, &protocol witness table for Parameter);
      swift_endAccess(&object);
      v457(v278, v470);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v287, &demangling cache variable for type metadata for Tensor?);
      ((void (*)(uint64_t *, uint64_t *, uint64_t))v501)(v283, v464, v488);
      if (*((void *)v431._object + 2) < v499) {
        BUG();
      }
      char object = v431._object;
      v491 = (char *)v431._object + 32;
      uint64_t v492 = 0;
      uint64_t v493 = (uint64_t)v489;
      uint64_t v288 = (uint64_t)v469;
      __swift_storeEnumTagSinglePayload((uint64_t)v469, 1, 1, (uint64_t)v482);
      Tensor.init<A>(shape:scalars:on:)(v283, &object, v288, v473);
      swift_beginAccess(v479, &object, 33, 0);
      uint64_t v289 = (uint64_t)v454;
      Layer.updateValue<A>(_:for:)(v278, v434, v459, &protocol witness table for Parameter);
      swift_endAccess(&object);
      swift_release();
      swift_release();
      swift_release();
      swift_release();
      v457(v278, v470);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v289, &demangling cache variable for type metadata for Tensor?);
      (*(void (**)(uint64_t *, uint64_t))(v480 + 8))(v464, v488);
      (*(void (**)(uint64_t *, uint64_t))(v468 + 8))(v485, v466);
      v210 = v472;
      uint64_t v211 = v467;
      uint64_t v212 = v465;
    }
LABEL_73:
    (*(void (**)(uint64_t *, uint64_t))(v212 + 8))(v210, v211);
    v142 = v502;
    (*(void (**)(uint64_t *, uint64_t))(v498 + 8))(v502, v497);
    uint64_t v143 = v476;
LABEL_76:
    v141 = (uint64_t *)((char *)v484 + (void)v444);
    uint64_t v140 = v437 - 1;
    if (v437 == 1) {
      goto LABEL_77;
    }
  }
  (*(void (**)(uint64_t *, uint64_t))(v147 + 96))(v146, v145);
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v461 + 32))(v474, v146, v462);
  uint64_t v149 = NeuralNetwork.Layer.name.getter();
  char v151 = v150;
  uint64_t v152 = (uint64_t)v486;
  if (!v486[2] || (uint64_t v143 = v146, v153 = specialized __RawDictionaryStorage.find<A>(_:)(v149, v150), (v154 & 1) == 0))
  {
    swift_bridgeObjectRelease(v151);
    char object = 0;
    v491 = (char *)0xE000000000000000;
    _StringGuts.grow(_:)(67);
    v349._uint64_t countAndFlagsBits = 0xD000000000000032;
    v349._char object = "etrained hand action model" + 0x8000000000000000;
    String.append(_:)(v349);
    uint64_t v350 = NeuralNetwork.Layer.name.getter();
    char v352 = (char)v351;
    v349._uint64_t countAndFlagsBits = v350;
    v349._char object = v351;
    String.append(_:)(v349);
    swift_bridgeObjectRelease(v352);
    v349._uint64_t countAndFlagsBits = 0x65726F63206E6920;
    v349._char object = (void *)0xEF63657073206C6DLL;
    String.append(_:)(v349);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 690, 0);
    goto LABEL_121;
  }
  uint64_t v155 = *(void *)(*(void *)(v152 + 56) + 8 * v153);
  swift_bridgeObjectRelease(v151);
  if (v155 == v481[2] - 1)
  {
    v156 = (os_log_s *)Logger.logObject.getter();
    os_log_type_t v157 = static os_log_type_t.info.getter();
    if (os_log_type_enabled(v156, v157))
    {
      v158 = (uint8_t *)swift_slowAlloc(2, -1);
      *(_WORD *)v158 = 0;
      _os_log_impl(&dword_0, v156, v157, "Skipping last innerProduct layer when loading the pretrained-model.", v158, 2u);
      v159 = v158;
      uint64_t v143 = v476;
      swift_slowDealloc(v159, -1, -1);
    }

    (*(void (**)(uint64_t *, uint64_t))(v461 + 8))(v474, v462);
    v142 = v502;
    v160 = v502;
    uint64_t v161 = v497;
    uint64_t v162 = v498;
    goto LABEL_75;
  }
  uint64_t v290 = v455;
  if (v155 < 0) {
    BUG();
  }
  if ((unint64_t)v155 >= *((void *)v496 + 2)) {
    BUG();
  }
  outlined init with copy of TabularRegressionTask((uint64_t)&v445[5 * v155], (uint64_t)&object);
  uint64_t v291 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Layer);
  uint64_t v292 = (uint64_t)v406;
  if (!swift_dynamicCast(v406, &object, v291, v290, 6))
  {
    __swift_storeEnumTagSinglePayload(v292, 1, 1, v290);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v292, &demangling cache variable for type metadata for Dense?);
    char object = 0;
    v491 = (char *)0xE000000000000000;
    _StringGuts.grow(_:)(81);
    v383._uint64_t countAndFlagsBits = 0xD000000000000040;
    v383._char object = "amework layer for " + 0x8000000000000000;
    String.append(_:)(v383);
    uint64_t v384 = NeuralNetwork.Layer.name.getter();
    char v386 = (char)v385;
    v383._uint64_t countAndFlagsBits = v384;
    v383._char object = v385;
    String.append(_:)(v383);
    swift_bridgeObjectRelease(v386);
    v383._uint64_t countAndFlagsBits = 0x65726F63206E6920;
    v383._char object = (void *)0xEF63657073206C6DLL;
    String.append(_:)(v383);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 698, 0);
    goto LABEL_121;
  }
  __swift_storeEnumTagSinglePayload(v292, 0, 1, v290);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v456 + 32))(v471, v292, v290);
  uint64_t v293 = NeuralNetwork.Layer.name.getter();
  char v295 = v294;
  uint64_t v296 = v487;
  if (!*(void *)(v487 + 16)
    || (unint64_t v297 = specialized __RawDictionaryStorage.find<A>(_:)(v293, v294), v299 = v452, (v298 & 1) == 0))
  {
    char v366 = v295;
LABEL_106:
    swift_bridgeObjectRelease(v366);
    char object = 0;
    v491 = (char *)0xE000000000000000;
    _StringGuts.grow(_:)(58);
    v367._uint64_t countAndFlagsBits = 0xD00000000000001FLL;
    v367._char object = "nnerProduct for " + 0x8000000000000000;
    String.append(_:)(v367);
    uint64_t v368 = NeuralNetwork.Layer.name.getter();
    char v370 = (char)v369;
    v367._uint64_t countAndFlagsBits = v368;
    v367._char object = v369;
    String.append(_:)(v367);
    swift_bridgeObjectRelease(v370);
    v367._char object = "Cannot load innerProduct layer " + 0x8000000000000000;
    v367._uint64_t countAndFlagsBits = 0xD000000000000019;
    String.append(_:)(v367);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 704, 0);
    goto LABEL_121;
  }
  uint64_t v300 = *(void *)(*(void *)(v296 + 56) + 8 * v297);
  swift_bridgeObjectRetain(v300);
  swift_bridgeObjectRelease(v295);
  if (!*(void *)(v300 + 16)
    || (unint64_t v301 = specialized __RawDictionaryStorage.find<A>(_:)(0x746867696577, 0xE600000000000000), (v302 & 1) == 0))
  {
    char v366 = v300;
    goto LABEL_106;
  }
  uint64_t v501 = v300;
  unint64_t v499 = *(void *)(*(void *)(v300 + 56) + 8 * v301);
  v303 = v413;
  Dense.$weight.getter();
  unsigned int v304 = Parameter.id.getter(0x746867696577);
  v489 = *(char **)(v438 + 8);
  ((void (*)(uint64_t *, uint64_t))v489)(v303, v299);
  uint64_t v305 = *(void *)type;
  if (!*(void *)(*(void *)type + 16)
    || (unint64_t v306 = specialized __RawDictionaryStorage.find<A>(_:)(v304), (v307 & 1) == 0))
  {
    char object = 0;
    v491 = (char *)0xE000000000000000;
    _StringGuts.grow(_:)(64);
    v371._uint64_t countAndFlagsBits = 0xD00000000000003DLL;
    v371._char object = " in from MIL Blob Storage" + 0x8000000000000000;
    String.append(_:)(v371);
    uint64_t v372 = NeuralNetwork.Layer.name.getter();
    char v374 = (char)v373;
    v371._uint64_t countAndFlagsBits = v372;
    v371._char object = v373;
    String.append(_:)(v371);
    swift_bridgeObjectRelease(v374);
    v371._uint64_t countAndFlagsBits = 46;
    v371._char object = (void *)0xE100000000000000;
    String.append(_:)(v371);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 707, 0);
    goto LABEL_121;
  }
  unint64_t v308 = *(void *)(*(void *)(v305 + 56) + 8 * v306);
  v482 = (double (*)(uint64_t *, uint64_t))__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  v309 = (void *)swift_allocObject(v482, 48, 7);
  v309[2] = 2;
  v309[3] = 4;
  swift_retain();
  v309[4] = NeuralNetwork.Layer.InnerProductParameters.outputChannelCount.getter(v308);
  v309[5] = NeuralNetwork.Layer.InnerProductParameters.inputChannelCount.getter();
  v310 = v407;
  TensorShape.init(_:)(v309, *(double *)v2.i64);
  uint64_t v311 = v500;
  v316 = BlobsFile.floatBlob(at:)(v499, 48, v312, v313, v314, v315);
  uint64_t v500 = v311;
  if (v311)
  {
    swift_release();
    swift_bridgeObjectRelease(v501);
    outlined release of BlobsFile(v403);
    swift_bridgeObjectRelease((_BYTE)v483);
    swift_bridgeObjectRelease(type[0]);
    swift_bridgeObjectRelease((_BYTE)v496);
    swift_bridgeObjectRelease((_BYTE)v486);
    swift_bridgeObjectRelease((_BYTE)v481);
    swift_bridgeObjectRelease(v487);
    v348 = v310;
    goto LABEL_82;
  }
  char object = v316;
  uint64_t v317 = type metadata accessor for ComputeDevice(0);
  unint64_t v499 = v308;
  uint64_t v318 = (uint64_t)v469;
  unint64_t v473 = v317;
  __swift_storeEnumTagSinglePayload((uint64_t)v469, 1, 1, v317);
  uint64_t v319 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  uint64_t v320 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float], (uint64_t)&protocol conformance descriptor for [A]);
  v321 = v417;
  v457 = (void (*)(uint64_t *, uint64_t))v319;
  uint64_t v458 = v320;
  Tensor.init<A>(shape:scalars:on:)(v310, &object, v318, v319);
  swift_beginAccess(v479, &object, 33, 0);
  uint64_t v322 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, (uint64_t)&protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  uint64_t v323 = (uint64_t)v416;
  uint64_t v459 = v322;
  Layer.updateValue<A>(_:for:)(v321, v499, v322, &protocol witness table for Parameter);
  swift_endAccess(&object);
  v324 = *(void (**)(uint64_t *, uint64_t))(v439 + 8);
  v324(v321, v470);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v323, &demangling cache variable for type metadata for Tensor?);
  uint64_t v325 = v501;
  if (!*(void *)(v501 + 16)
    || (unint64_t v326 = specialized __RawDictionaryStorage.find<A>(_:)(1935763810, 0xE400000000000000), (v327 & 1) == 0))
  {
    swift_release();
    swift_bridgeObjectRelease(v325);
    goto LABEL_72;
  }
  v453 = v324;
  uint64_t v460 = *(void *)(*(void *)(v325 + 56) + 8 * v326);
  swift_bridgeObjectRelease(v325);
  uint64_t v328 = (uint64_t)v427;
  Dense.$bias.getter();
  uint64_t v329 = v452;
  if (__swift_getEnumTagSinglePayload(v328, 1, v452) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v328, &demangling cache variable for type metadata for Parameter?);
LABEL_119:
    char object = 0;
    v491 = (char *)0xE000000000000000;
    _StringGuts.grow(_:)(62);
    v399._uint64_t countAndFlagsBits = 0xD00000000000003BLL;
    String.append(_:)(v399);
    uint64_t v400 = NeuralNetwork.Layer.name.getter();
    char v402 = (char)v401;
    v399._uint64_t countAndFlagsBits = v400;
    v399._char object = v401;
    String.append(_:)(v399);
    swift_bridgeObjectRelease(v402);
    v399._uint64_t countAndFlagsBits = 46;
    v399._char object = (void *)0xE100000000000000;
    String.append(_:)(v399);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, object, v491, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 721, 0);
    goto LABEL_121;
  }
  unsigned int v330 = Parameter.id.getter(v328);
  ((void (*)(uint64_t, uint64_t))v489)(v328, v329);
  os_log_type_t v331 = type[0];
  uint64_t v501 = specialized Dictionary.subscript.getter(v330, *(uint64_t *)type);
  if (!v501) {
    goto LABEL_119;
  }
  v332 = v482;
  v333 = (void *)swift_allocObject(v482, 40, 7);
  v333[2] = 1;
  v333[3] = 2;
  v333[4] = NeuralNetwork.Layer.InnerProductParameters.outputChannelCount.getter(v332);
  v334 = v428;
  TensorShape.init(_:)(v333, *(double *)v2.i64);
  uint64_t v335 = v500;
  v340 = BlobsFile.floatBlob(at:)(v460, 40, v336, v337, v338, v339);
  uint64_t v500 = v335;
  if (!v335)
  {
    char object = v340;
    uint64_t v341 = (uint64_t)v469;
    __swift_storeEnumTagSinglePayload((uint64_t)v469, 1, 1, v473);
    v342 = v430;
    Tensor.init<A>(shape:scalars:on:)(v334, &object, v341, v457);
    swift_beginAccess(v479, &object, 33, 0);
    uint64_t v343 = (uint64_t)v429;
    Layer.updateValue<A>(_:for:)(v342, v501, v459, &protocol witness table for Parameter);
    swift_endAccess(&object);
    swift_release();
    swift_release();
    v453(v342, v470);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v343, &demangling cache variable for type metadata for Tensor?);
LABEL_72:
    (*(void (**)(uint64_t *, uint64_t))(v456 + 8))(v471, v455);
    v210 = v474;
    uint64_t v211 = v462;
    uint64_t v212 = v461;
    goto LABEL_73;
  }
  swift_release();
  swift_release();
  outlined release of BlobsFile(v403);
  swift_bridgeObjectRelease((_BYTE)v483);
  swift_bridgeObjectRelease(v331);
  swift_bridgeObjectRelease((_BYTE)v496);
  swift_bridgeObjectRelease((_BYTE)v486);
  swift_bridgeObjectRelease((_BYTE)v481);
  swift_bridgeObjectRelease(v487);
  v348 = v334;
LABEL_82:
  (*(void (**)(uint64_t *, uint64_t))(v480 + 8))(v348, v488);
  (*(void (**)(uint64_t *, uint64_t))(v456 + 8))(v471, v455);
  v345 = v474;
  uint64_t v346 = v462;
  uint64_t v347 = v461;
LABEL_83:
  (*(void (**)(uint64_t *, uint64_t))(v347 + 8))(v345, v346);
  (*(void (**)(uint64_t *, uint64_t))(v498 + 8))(v502, v497);
  char v344 = (char)v478;
LABEL_84:
  swift_bridgeObjectRelease(v344);
  v477(v475, v494);
}

void *MLHandActionClassifier.GraphCNN.coreMLTrainableLayerNames(from:)(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for NeuralNetwork.Layer.Kind(0);
  uint64_t v2 = *(void *)(v1 - 8);
  int64_t v3 = *(void *)(v2 + 64);
  __m128 v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  uint64_t v59 = &v45;
  uint64_t v6 = type metadata accessor for NeuralNetwork.Layer(0);
  uint64_t v7 = *(void *)(v6 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  int64_t v11 = &v45;
  if (*(void *)(a1 + 16))
  {
    uint64_t v47 = *(void *)(a1 + 16);
    uint64_t v12 = a1 + ((*(unsigned __int8 *)(v7 + 80) + 32) & ~*(unsigned __int8 *)(v7 + 80));
    uint64_t v48 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v7 + 16);
    uint64_t v46 = v7;
    uint64_t v49 = *(void *)(v7 + 72);
    int v52 = enum case for NeuralNetwork.Layer.Kind.innerProduct(_:);
    int v53 = enum case for NeuralNetwork.Layer.Kind.convolution(_:);
    int v54 = enum case for NeuralNetwork.Layer.Kind.batchNormalize(_:);
    uint64_t v51 = a1;
    uint64_t v13 = v6;
    swift_bridgeObjectRetain(a1);
    uint64_t v14 = v12;
    uint64_t v60 = _swiftEmptyArrayStorage;
    uint64_t v50 = v1;
    uint64_t v15 = v59;
    uint64_t v56 = v2;
    uint64_t v57 = v13;
    while (1)
    {
      uint64_t v45 = v14;
      v48(v11, v14, v13);
      NeuralNetwork.Layer.kind.getter();
      uint64_t v16 = v56;
      int v17 = (*(uint64_t (**)(uint64_t *, uint64_t))(v56 + 88))(v15, v1);
      uint64_t v18 = v11;
      if (v17 == v52)
      {
        uint64_t v55 = NeuralNetwork.Layer.name.getter();
        uint64_t v20 = v19;
        uint64_t v21 = v60;
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v60);
        uint64_t v58 = v20;
        if (!isUniquelyReferenced_nonNull_native) {
          uint64_t v21 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v21[2] + 1, 1, (uint64_t)v21);
        }
        unint64_t v23 = v21[2];
        if (v21[3] >> 1 <= v23) {
          uint64_t v21 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v21[3] >= 2uLL, v23 + 1, 1, (uint64_t)v21);
        }
        uint64_t v24 = v57;
        uint64_t v25 = v55;
        v21[2] = v23 + 1;
        uint64_t v60 = v21;
        char v26 = &v21[2 * v23 + 4];
        uint64_t *v26 = v25;
        uint64_t v16 = v56;
        uint64_t v15 = v59;
        uint64_t v27 = v58;
      }
      else if (v17 == v53)
      {
        uint64_t v58 = NeuralNetwork.Layer.name.getter();
        uint64_t v27 = v28;
        uint64_t v29 = v60;
        if (!swift_isUniquelyReferenced_nonNull_native(v60)) {
          uint64_t v60 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v29[2] + 1, 1, (uint64_t)v29);
        }
        uint64_t v16 = v56;
        uint64_t v15 = v59;
        unint64_t v30 = v60[2];
        unint64_t v31 = v60[3];
        uint64_t v32 = v30 + 1;
        if (v31 >> 1 <= v30)
        {
          uint64_t v55 = v30 + 1;
          uint64_t v42 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v31 >= 2, v30 + 1, 1, (uint64_t)v60);
          uint64_t v32 = v55;
          uint64_t v60 = v42;
        }
        uint64_t v24 = v57;
        uint64_t v33 = v58;
        uint64_t v34 = v60;
        v60[2] = v32;
        char v26 = &v34[2 * v30 + 4];
        uint64_t *v26 = v33;
      }
      else
      {
        if (v17 != v54)
        {
          uint64_t v15 = v59;
          uint64_t v24 = v57;
          goto LABEL_22;
        }
        uint64_t v58 = NeuralNetwork.Layer.name.getter();
        uint64_t v27 = v35;
        uint64_t v36 = v60;
        if (!swift_isUniquelyReferenced_nonNull_native(v60)) {
          uint64_t v36 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v36[2] + 1, 1, (uint64_t)v36);
        }
        unint64_t v37 = v36[2];
        uint64_t v60 = v36;
        unint64_t v38 = v36[3];
        unint64_t v39 = v37 + 1;
        uint64_t v16 = v56;
        if (v38 >> 1 <= v37)
        {
          uint64_t v43 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v38 >= 2, v37 + 1, 1, (uint64_t)v60);
          unint64_t v39 = v37 + 1;
          uint64_t v60 = v43;
        }
        uint64_t v15 = v59;
        uint64_t v40 = v60;
        v60[2] = v39;
        char v26 = &v40[2 * v37 + 4];
        uint64_t *v26 = v58;
        uint64_t v24 = v57;
      }
      v26[1] = v27;
      uint64_t v1 = v50;
LABEL_22:
      int64_t v41 = v18;
      int64_t v11 = v18;
      uint64_t v13 = v24;
      (*(void (**)(uint64_t *))(v46 + 8))(v41);
      (*(void (**)(uint64_t *, uint64_t))(v16 + 8))(v15, v1);
      uint64_t v14 = v49 + v45;
      if (!--v47)
      {
        swift_bridgeObjectRelease(v51);
        return v60;
      }
    }
  }
  return _swiftEmptyArrayStorage;
}

void *MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:)(unint64_t a1, unint64_t a2)
{
  uint64_t v549 = v2;
  unint64_t v595 = a2;
  unint64_t v607 = a1;
  uint64_t v523 = type metadata accessor for NeuralNetwork.Layer.Kind(0);
  uint64_t v524 = *(void *)(v523 - 8);
  int64_t v3 = *(void *)(v524 + 64);
  __m128 v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  v522 = v520;
  uint64_t v550 = type metadata accessor for NeuralNetwork.Layer.PoolParameters(0);
  uint64_t v551 = *(void *)(v550 - 8);
  int64_t v6 = *(void *)(v551 + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  v552 = v520;
  int64_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.Layer.PoolParameters.Padding?)
                             - 8)
                 + 64);
  int64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  v593 = v520;
  uint64_t v599 = type metadata accessor for NeuralNetwork.Layer.PoolParameters.Kind(0);
  uint64_t v597 = *(void *)(v599 - 8);
  int64_t v12 = *(void *)(v597 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  v594 = v520;
  int64_t v15 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?)
                              - 8)
                  + 64);
  uint64_t v16 = alloca(v15);
  int v17 = alloca(v15);
  v602 = v520;
  uint64_t v604 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.Extent<Int>);
  uint64_t v539 = *(void *)(v604 - 8);
  int64_t v18 = *(void *)(v539 + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  v605 = v520;
  uint64_t v21 = alloca(v18);
  int64_t v22 = alloca(v18);
  v606 = v520;
  uint64_t v612 = type metadata accessor for NeuralNetwork.Layer(0);
  v611 = *(void **)(v612 - 8);
  int64_t v23 = v611[8];
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  v521 = v520;
  char v26 = alloca(v23);
  uint64_t v27 = alloca(v23);
  v525 = v520;
  uint64_t v28 = alloca(v23);
  uint64_t v29 = alloca(v23);
  v582 = v520;
  unint64_t v30 = alloca(v23);
  unint64_t v31 = alloca(v23);
  v553 = v520;
  uint64_t v32 = alloca(v23);
  uint64_t v33 = alloca(v23);
  v526 = v520;
  uint64_t v34 = alloca(v23);
  uint64_t v35 = alloca(v23);
  uint64_t v36 = alloca(v23);
  unint64_t v37 = alloca(v23);
  v527 = v520;
  unint64_t v38 = alloca(v23);
  unint64_t v39 = alloca(v23);
  v555 = v520;
  uint64_t v40 = alloca(v23);
  int64_t v41 = alloca(v23);
  v528 = v520;
  uint64_t v42 = alloca(v23);
  uint64_t v43 = alloca(v23);
  v529 = v520;
  unsigned int v44 = alloca(v23);
  uint64_t v45 = alloca(v23);
  v584 = v520;
  uint64_t v46 = alloca(v23);
  uint64_t v47 = alloca(v23);
  v556 = v520;
  uint64_t v48 = alloca(v23);
  uint64_t v49 = alloca(v23);
  v530 = v520;
  uint64_t v50 = alloca(v23);
  uint64_t v51 = alloca(v23);
  v585 = v520;
  int v52 = alloca(v23);
  int v53 = alloca(v23);
  v531 = v520;
  int v54 = alloca(v23);
  uint64_t v55 = alloca(v23);
  v557 = v520;
  uint64_t v56 = alloca(v23);
  uint64_t v57 = alloca(v23);
  v532 = v520;
  uint64_t v58 = alloca(v23);
  uint64_t v59 = alloca(v23);
  v533 = v520;
  uint64_t v60 = alloca(v23);
  uint64_t v61 = alloca(v23);
  v586 = v520;
  Swift::String v62 = alloca(v23);
  Swift::String v63 = alloca(v23);
  v558 = v520;
  uint64_t v64 = alloca(v23);
  uint64_t v65 = alloca(v23);
  v559 = v520;
  int64_t v66 = alloca(v23);
  uint64_t v67 = alloca(v23);
  v560 = v520;
  unint64_t v68 = alloca(v23);
  char v69 = alloca(v23);
  v534 = v520;
  uint64_t v70 = alloca(v23);
  uint64_t v71 = alloca(v23);
  v535 = v520;
  uint64_t v72 = alloca(v23);
  uint64_t v73 = alloca(v23);
  v587 = v520;
  uint64_t v74 = alloca(v23);
  int64_t v75 = alloca(v23);
  v561 = v520;
  uint64_t v76 = alloca(v23);
  uint64_t v77 = alloca(v23);
  v562 = v520;
  int64_t v78 = alloca(v23);
  uint64_t v79 = alloca(v23);
  v588 = v520;
  uint64_t v80 = alloca(v23);
  int64_t v81 = alloca(v23);
  v563 = v520;
  uint64_t v82 = alloca(v23);
  uint64_t v83 = alloca(v23);
  v564 = v520;
  int64_t v84 = alloca(v23);
  uint64_t v85 = alloca(v23);
  v536 = v520;
  uint64_t v86 = alloca(v23);
  int64_t v87 = alloca(v23);
  v565 = v520;
  uint64_t v88 = alloca(v23);
  uint64_t v89 = alloca(v23);
  v566 = v520;
  int64_t v90 = alloca(v23);
  uint64_t v91 = alloca(v23);
  v567 = v520;
  uint64_t v92 = alloca(v23);
  uint64_t v93 = alloca(v23);
  v568 = v520;
  int64_t v94 = alloca(v23);
  uint64_t v95 = alloca(v23);
  v589 = v520;
  uint64_t v96 = alloca(v23);
  uint64_t v97 = alloca(v23);
  v569 = v520;
  uint64_t v98 = alloca(v23);
  uint64_t v99 = alloca(v23);
  v570 = v520;
  uint64_t v100 = alloca(v23);
  uint64_t v101 = alloca(v23);
  v537 = v520;
  uint64_t v102 = alloca(v23);
  v103 = alloca(v23);
  v571 = v520;
  uint64_t v104 = alloca(v23);
  id v105 = alloca(v23);
  v572 = v520;
  id v106 = alloca(v23);
  id v107 = alloca(v23);
  v573 = v520;
  uint64_t v108 = alloca(v23);
  uint64_t v109 = alloca(v23);
  v574 = v520;
  uint64_t v110 = alloca(v23);
  uint64_t v111 = alloca(v23);
  v590 = v520;
  uint64_t v112 = alloca(v23);
  uint64_t v113 = alloca(v23);
  v575 = v520;
  uint64_t v114 = alloca(v23);
  os_log_type_t v115 = alloca(v23);
  v576 = v520;
  int v116 = alloca(v23);
  uint64_t v117 = alloca(v23);
  v538 = v520;
  uint64_t v118 = alloca(v23);
  uint64_t v119 = alloca(v23);
  v577 = v520;
  uint64_t v120 = alloca(v23);
  uint64_t v121 = alloca(v23);
  v578 = v520;
  int64_t v122 = alloca(v23);
  char v123 = alloca(v23);
  v579 = v520;
  uint64_t v124 = alloca(v23);
  os_log_t v125 = alloca(v23);
  v580 = v520;
  v126 = alloca(v23);
  uint64_t v127 = alloca(v23);
  v591 = v520;
  v128 = alloca(v23);
  uint64_t v129 = alloca(v23);
  v540 = v520;
  uint64_t v130 = alloca(v23);
  uint64_t v131 = alloca(v23);
  v581 = v520;
  uint64_t v132 = alloca(v23);
  unint64_t v133 = alloca(v23);
  v541 = v520;
  uint64_t v134 = alloca(v23);
  v135 = alloca(v23);
  v542 = v520;
  uint64_t v136 = alloca(v23);
  uint64_t v137 = alloca(v23);
  v543 = v520;
  v138 = alloca(v23);
  uint64_t v139 = alloca(v23);
  v601 = v520;
  uint64_t v140 = alloca(v23);
  v141 = alloca(v23);
  v544 = v520;
  v142 = alloca(v23);
  uint64_t v143 = alloca(v23);
  v592 = v520;
  v144 = alloca(v23);
  uint64_t v145 = alloca(v23);
  v598 = v520;
  uint64_t v146 = alloca(v23);
  uint64_t v147 = alloca(v23);
  v545 = v520;
  int v148 = alloca(v23);
  uint64_t v149 = alloca(v23);
  v546 = v520;
  uint64_t v150 = alloca(v23);
  char v151 = alloca(v23);
  v603 = v520;
  uint64_t v152 = alloca(v23);
  unint64_t v153 = alloca(v23);
  v600 = v520;
  char v154 = alloca(v23);
  uint64_t v155 = alloca(v23);
  v596 = v520;
  v156 = alloca(v23);
  os_log_type_t v157 = alloca(v23);
  v158 = alloca(v23);
  v159 = alloca(v23);
  v614 = _swiftEmptyArrayStorage;
  static NeuralNetwork.Layer.expandDimensions(name:inputName:outputName:axes:)(3288696, 0xE300000000000000, 0x7365736F70, 0xE500000000000000, 3288696, 0xE300000000000000, &outlined read-only object #0 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:));
  v160 = v614;
  char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v614);
  v583 = v520;
  if (!isUniquelyReferenced_nonNull_native) {
    v160 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v160[2] + 1, 1, (uint64_t)v160);
  }
  unint64_t v162 = v160[2];
  if (v160[3] >> 1 <= v162) {
    v160 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v160[3] >= 2uLL, v162 + 1, 1, (uint64_t)v160);
  }
  v160[2] = v162 + 1;
  uint64_t v609 = (*((unsigned __int8 *)v611 + 80) + 32) & ~*((unsigned __int8 *)v611 + 80);
  v163 = (void *)v611[4];
  uint64_t v610 = v611[9];
  v611 = v163;
  ((void (*)(char *, unsigned char *, uint64_t))v163)((char *)v160 + v609 + v610 * v162, v520, v612);
  v614 = v160;
  static NeuralNetwork.Layer.transpose(name:inputName:outputName:axes:)(&loc_332E78, 0xE300000000000000, 3288696, 0xE300000000000000, &loc_332E78, 0xE300000000000000, &outlined read-only object #1 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:));
  uint64_t v164 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v164 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v164[2] + 1, 1, (uint64_t)v164);
  }
  unint64_t v165 = v164[2];
  if (v164[3] >> 1 <= v165) {
    uint64_t v164 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v164[3] >= 2uLL, v165 + 1, 1, (uint64_t)v164);
  }
  v164[2] = v165 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v164 + v609 + v610 * v165, v520, v612);
  v614 = v164;
  uint64_t v554 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  char v166 = (void *)swift_allocObject(v554, 56, 7);
  v166[2] = 3;
  v166[3] = 6;
  v166[4] = 1;
  uint64_t v167 = v549 + OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model;
  swift_beginAccess(v549 + OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model, v520, 0, 0);
  uint64_t v548 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  uint64_t v168 = *(int *)(v548 + 40);
  uint64_t v547 = v167;
  v166[5] = *(void *)(v168 + v167);
  v166[6] = -1;
  char v169 = v596;
  static NeuralNetwork.Layer.reshapeStatic(name:inputName:outputName:targetShape:)(3420209, 0xE300000000000000, &loc_332E78, 0xE300000000000000, 3420209, 0xE300000000000000, v166);
  swift_bridgeObjectRelease((_BYTE)v166);
  uint64_t v170 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v170 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v170[2] + 1, 1, (uint64_t)v170);
  }
  unint64_t v171 = v170[2];
  if (v170[3] >> 1 <= v171) {
    uint64_t v170 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v170[3] >= 2uLL, v171 + 1, 1, (uint64_t)v170);
  }
  v170[2] = v171 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v170 + v609 + v610 * v171, v169, v612);
  v614 = v170;
  static NeuralNetwork.Layer.expandDimensions(name:inputName:outputName:axes:)(3419768, 0xE300000000000000, 3420209, 0xE300000000000000, 3419768, 0xE300000000000000, &outlined read-only object #2 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:));
  uint64_t v172 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v172 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v172[2] + 1, 1, (uint64_t)v172);
  }
  unint64_t v173 = v172[2];
  if (v172[3] >> 1 <= v173) {
    uint64_t v172 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v172[3] >= 2uLL, v173 + 1, 1, (uint64_t)v172);
  }
  v172[2] = v173 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v172 + v609 + v610 * v173, v600, v612);
  v614 = v172;
  static NeuralNetwork.Layer.transpose(name:inputName:outputName:axes:)(0x312E7475706E69, 0xE700000000000000, 3419768, 0xE300000000000000, 0x312E7475706E69, 0xE700000000000000, &outlined read-only object #3 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:));
  uint64_t v174 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v174 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v174[2] + 1, 1, (uint64_t)v174);
  }
  unint64_t v175 = v174[2];
  if (v174[3] >> 1 <= v175) {
    uint64_t v174 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v174[3] >= 2uLL, v175 + 1, 1, (uint64_t)v174);
  }
  v174[2] = v175 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v174 + v609 + v610 * v175, v603, v612);
  unint64_t v176 = v595 * v607;
  if (!is_mul_ok(v595, v607)) {
    BUG();
  }
  char v177 = v546;
  v607 *= v595;
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)("_UnsafeHandle", 0xE300000000000000, 0x312E7475706E69, 0xE700000000000000, "_UnsafeHandle", 0xE300000000000000, v176);
  unint64_t v178 = v174[2];
  if (v174[3] >> 1 <= v178) {
    uint64_t v174 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v174[3] >= 2uLL, v178 + 1, 1, (uint64_t)v174);
  }
  v174[2] = v178 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v174 + v609 + v610 * v178, v177, v612);
  v614 = v174;
  char v179 = v545;
  static NeuralNetwork.Layer.transpose(name:inputName:outputName:axes:)(&unk_353231, 0xE300000000000000, "_UnsafeHandle", 0xE300000000000000, &unk_353231, 0xE300000000000000, &outlined read-only object #4 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:));
  uint64_t v180 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v180 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v180[2] + 1, 1, (uint64_t)v180);
  }
  unint64_t v181 = v180[2];
  if (v180[3] >> 1 <= v181) {
    uint64_t v180 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v180[3] >= 2uLL, v181 + 1, 1, (uint64_t)v180);
  }
  v180[2] = v181 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v180 + v609 + v610 * v181, v179, v612);
  v614 = v180;
  static NeuralNetwork.Layer.squeeze(name:inputName:outputName:axes:)(&unk_362E78, 0xE300000000000000, &unk_353231, 0xE300000000000000, &unk_362E78, 0xE300000000000000, &outlined read-only object #5 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:));
  unint64_t v182 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    unint64_t v182 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v182[2] + 1, 1, (uint64_t)v182);
  }
  char v183 = v592;
  unint64_t v184 = v182[2];
  if (v182[3] >> 1 <= v184) {
    unint64_t v182 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v182[3] >= 2uLL, v184 + 1, 1, (uint64_t)v182);
  }
  v182[2] = v184 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v182 + v609 + v610 * v184, v598, v612);
  static NeuralNetwork.Layer.innerProduct(name:inputName:outputName:inputChannelCount:outputChannelCount:)(3616376, 0xE300000000000000, &unk_362E78, 0xE300000000000000, 3616376, 0xE300000000000000, v607, 704);
  unint64_t v185 = v182[2];
  if (v182[3] >> 1 <= v185) {
    unint64_t v182 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v182[3] >= 2uLL, v185 + 1, 1, (uint64_t)v182);
  }
  v182[2] = v185 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v182 + v609 + v610 * v185, v183, v612);
  v614 = v182;
  uint64_t v186 = (void *)swift_allocObject(v554, 64, 7);
  v186[2] = 4;
  v186[3] = 8;
  v186[4] = 1;
  v186[5] = *(void *)(v547 + *(int *)(v548 + 40));
  v186[6] = 44;
  v186[7] = 16;
  unint64_t v187 = v544;
  static NeuralNetwork.Layer.reshapeStatic(name:inputName:outputName:targetShape:)(&unk_353431, 0xE300000000000000, 3616376, 0xE300000000000000, &unk_353431, 0xE300000000000000, v186);
  swift_bridgeObjectRelease((_BYTE)v186);
  char v188 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    char v188 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v188[2] + 1, 1, (uint64_t)v188);
  }
  unint64_t v189 = v188[2];
  if (v188[3] >> 1 <= v189) {
    char v188 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v188[3] >= 2uLL, v189 + 1, 1, (uint64_t)v188);
  }
  v188[2] = v189 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v188 + v609 + v610 * v189, v187, v612);
  v614 = v188;
  static NeuralNetwork.Layer.transpose(name:inputName:outputName:axes:)(0x322E7475706E69, 0xE700000000000000, &unk_353431, 0xE300000000000000, 0x322E7475706E69, 0xE700000000000000, &outlined read-only object #6 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:));
  uint64_t v190 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v190 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v190[2] + 1, 1, (uint64_t)v190);
  }
  unint64_t v191 = v190[2];
  if (v190[3] >> 1 <= v191) {
    uint64_t v190 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v190[3] >= 2uLL, v191 + 1, 1, (uint64_t)v190);
  }
  v190[2] = v191 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v190 + v609 + v610 * v191, v601, v612);
  uint64_t v192 = v543;
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x332E7475706E69, 0xE700000000000000, 0x322E7475706E69, 0xE700000000000000, 0x332E7475706E69, 0xE700000000000000, 16);
  unint64_t v193 = v190[2];
  if (v190[3] >> 1 <= v193) {
    uint64_t v190 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v190[3] >= 2uLL, v193 + 1, 1, (uint64_t)v190);
  }
  v190[2] = v193 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v190 + v609 + v610 * v193, v192, v612);
  uint64_t v194 = v542;
  static NeuralNetwork.Layer.relu(name:inputName:outputName:)(0x342E7475706E69, 0xE700000000000000, 0x332E7475706E69, 0xE700000000000000, 0x342E7475706E69, 0xE700000000000000);
  unint64_t v195 = v190[2];
  if (v190[3] >> 1 <= v195) {
    uint64_t v190 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v190[3] >= 2uLL, v195 + 1, 1, (uint64_t)v190);
  }
  v190[2] = v195 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v190 + v609 + v610 * v195, v194, v612);
  v614 = v190;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v196 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v197 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  unsigned int v198 = enum case for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind.valid(_:);
  uint64_t v199 = type metadata accessor for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind(0);
  uint64_t v200 = *(unsigned char **)(*(void *)(v199 - 8) + 104);
  LODWORD(v600) = v198;
  v601 = v200;
  ((void (*)(uint64_t, void, uint64_t))v200)(v197, v198, v199);
  v603 = (unsigned char *)v199;
  __swift_storeEnumTagSinglePayload(v197, 0, 1, v199);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v201 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  v202 = v541;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x352E7475706E69, 0xE700000000000000, 0x342E7475706E69, 0xE700000000000000, 0x352E7475706E69, 0xE700000000000000, 32, 16, 1, v196, v201, v197);
  uint64_t v203 = *(void (**)(unsigned char *, uint64_t))(v539 + 8);
  v204 = v201;
  uint64_t v205 = v604;
  v203(v204, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v197, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  unint64_t v607 = (unint64_t)v203;
  v203(v196, v205);
  uint64_t v206 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v206 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v206[2] + 1, 1, (uint64_t)v206);
  }
  unint64_t v207 = v206[2];
  if (v206[3] >> 1 <= v207) {
    uint64_t v206 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v206[3] >= 2uLL, v207 + 1, 1, (uint64_t)v206);
  }
  v206[2] = v207 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v206 + v609 + v610 * v207, v202, v612);
  v614 = v206;
  uint64_t v208 = *(void (**)(unsigned char *, void, uint64_t))(v597 + 104);
  uint64_t v209 = v594;
  LODWORD(v596) = enum case for NeuralNetwork.Layer.PoolParameters.Kind.average(_:);
  unint64_t v595 = (unint64_t)v208;
  v208(v594, enum case for NeuralNetwork.Layer.PoolParameters.Kind.average(_:), v599);
  uint64_t v613 = 1;
  uint64_t v608 = 3;
  v210 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v211 = (uint64_t)v593;
  static NeuralNetwork.Layer.PoolParameters.Padding.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(0, 0, 1, 1);
  v598 = (unsigned char *)type metadata accessor for NeuralNetwork.Layer.PoolParameters.Padding(0);
  __swift_storeEnumTagSinglePayload(v211, 0, 1, (uint64_t)v598);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v212 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.pool(name:inputName:outputName:kind:kernelSize:strides:padding:)(0x362E7475706E69, 0xE700000000000000, 0x352E7475706E69, 0xE700000000000000, 0x362E7475706E69, 0xE700000000000000, v209, v210, v212, v211);
  uint64_t v213 = v212;
  uint64_t v214 = v604;
  char v215 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v213, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v211, &demangling cache variable for type metadata for NeuralNetwork.Layer.PoolParameters.Padding?);
  v215(v210, v214);
  uint64_t v597 = *(void *)(v597 + 8);
  ((void (*)(unsigned char *, uint64_t))v597)(v209, v599);
  uint64_t v216 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v216 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v216[2] + 1, 1, (uint64_t)v216);
  }
  unint64_t v217 = v216[2];
  if (v216[3] >> 1 <= v217) {
    uint64_t v216 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v216[3] >= 2uLL, v217 + 1, 1, (uint64_t)v216);
  }
  v216[2] = v217 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v216 + v609 + v610 * v217, v581, v612);
  v614 = v216;
  uint64_t v613 = 9;
  uint64_t v608 = 1;
  char v218 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v219 = (uint64_t)v602;
  static NeuralNetwork.Layer.ConvolutionParameters.PaddingKind.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(4, 4, 0, 0);
  __swift_storeEnumTagSinglePayload(v219, 0, 1, (uint64_t)v603);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v220 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v221 = v540;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x372E7475706E69, 0xE700000000000000, 0x362E7475706E69, 0xE700000000000000, 0x372E7475706E69, 0xE700000000000000, 8, 32, 1, v218, v220, v219);
  uint64_t v222 = v220;
  uint64_t v223 = v604;
  uint64_t v224 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v222, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v219, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v224(v218, v223);
  char v225 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    char v225 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v225[2] + 1, 1, (uint64_t)v225);
  }
  uint64_t v226 = v591;
  unint64_t v227 = v225[2];
  if (v225[3] >> 1 <= v227) {
    char v225 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v225[3] >= 2uLL, v227 + 1, 1, (uint64_t)v225);
  }
  v225[2] = v227 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v225 + v609 + v610 * v227, v221, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x382E7475706E69, 0xE700000000000000, 0x372E7475706E69, 0xE700000000000000, 0x382E7475706E69, 0xE700000000000000, 8);
  unint64_t v228 = v225[2];
  if (v225[3] >> 1 <= v228) {
    char v225 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v225[3] >= 2uLL, v228 + 1, 1, (uint64_t)v225);
  }
  v225[2] = v228 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v225 + v609 + v610 * v228, v226, v612);
  v614 = v225;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v229 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v230 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v231 = (uint64_t)v603;
  ((void (*)(uint64_t, void, unsigned char *))v601)(v230, v600, v603);
  __swift_storeEnumTagSinglePayload(v230, 0, 1, v231);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v232 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x392E7475706E69, 0xE700000000000000, 0x342E7475706E69, 0xE700000000000000, 0x392E7475706E69, 0xE700000000000000, 8, 16, 1, v229, v232, v230);
  char v233 = v232;
  uint64_t v234 = v604;
  char v235 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v233, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v230, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v235(v229, v234);
  uint64_t v236 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v236 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v236[2] + 1, 1, (uint64_t)v236);
  }
  unint64_t v237 = v236[2];
  if (v236[3] >> 1 <= v237) {
    uint64_t v236 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v236[3] >= 2uLL, v237 + 1, 1, (uint64_t)v236);
  }
  v236[2] = v237 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v236 + v609 + v610 * v237, v580, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x6C61756469736572, 0xEA0000000000312ELL, 0x392E7475706E69, 0xE700000000000000, 0x6C61756469736572, 0xEA0000000000312ELL, 8);
  unint64_t v238 = v236[2];
  if (v236[3] >> 1 <= v238) {
    uint64_t v236 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v236[3] >= 2uLL, v238 + 1, 1, (uint64_t)v236);
  }
  v236[2] = v238 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v236 + v609 + v610 * v238, v579, v612);
  v614 = v236;
  static NeuralNetwork.Layer.add(name:inputNames:outputName:)(0x30312E7475706E69, 0xE800000000000000, &outlined read-only object #7 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:), 0x30312E7475706E69, 0xE800000000000000);
  v239 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    v239 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v239[2] + 1, 1, (uint64_t)v239);
  }
  unint64_t v240 = v239[2];
  if (v239[3] >> 1 <= v240) {
    v239 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v239[3] >= 2uLL, v240 + 1, 1, (uint64_t)v239);
  }
  v239[2] = v240 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v239 + v609 + v610 * v240, v578, v612);
  static NeuralNetwork.Layer.relu(name:inputName:outputName:)(0x31312E7475706E69, 0xE800000000000000, 0x30312E7475706E69, 0xE800000000000000, 0x31312E7475706E69, 0xE800000000000000);
  unint64_t v241 = v239[2];
  if (v239[3] >> 1 <= v241) {
    v239 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v239[3] >= 2uLL, v241 + 1, 1, (uint64_t)v239);
  }
  v239[2] = v241 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v239 + v609 + v610 * v241, v577, v612);
  v614 = v239;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v242 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v243 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v244 = (uint64_t)v603;
  ((void (*)(uint64_t, void, unsigned char *))v601)(v243, v600, v603);
  __swift_storeEnumTagSinglePayload(v243, 0, 1, v244);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v245 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v246 = v538;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x32312E7475706E69, 0xE800000000000000, 0x31312E7475706E69, 0xE800000000000000, 0x32312E7475706E69, 0xE800000000000000, 16, 8, 1, v242, v245, v243);
  uint64_t v247 = v245;
  uint64_t v248 = v604;
  uint64_t v249 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v247, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v243, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v249(v242, v248);
  uint64_t v250 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v250 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v250[2] + 1, 1, (uint64_t)v250);
  }
  unint64_t v251 = v250[2];
  if (v250[3] >> 1 <= v251) {
    uint64_t v250 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v250[3] >= 2uLL, v251 + 1, 1, (uint64_t)v250);
  }
  v250[2] = v251 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v250 + v609 + v610 * v251, v246, v612);
  v614 = v250;
  uint64_t v252 = v594;
  ((void (*)(unsigned char *, void, uint64_t))v595)(v594, v596, v599);
  uint64_t v613 = 1;
  uint64_t v608 = 3;
  uint64_t v253 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v254 = (uint64_t)v593;
  static NeuralNetwork.Layer.PoolParameters.Padding.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(0, 0, 1, 1);
  __swift_storeEnumTagSinglePayload(v254, 0, 1, (uint64_t)v598);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v255 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.pool(name:inputName:outputName:kind:kernelSize:strides:padding:)(0x33312E7475706E69, 0xE800000000000000, 0x32312E7475706E69, 0xE800000000000000, 0x33312E7475706E69, 0xE800000000000000, v252, v253, v255, v254);
  uint64_t v256 = v255;
  uint64_t v257 = v604;
  uint64_t v258 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v256, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v254, &demangling cache variable for type metadata for NeuralNetwork.Layer.PoolParameters.Padding?);
  v258(v253, v257);
  ((void (*)(unsigned char *, uint64_t))v597)(v252, v599);
  v259 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    v259 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v259[2] + 1, 1, (uint64_t)v259);
  }
  unint64_t v260 = v259[2];
  if (v259[3] >> 1 <= v260) {
    v259 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v259[3] >= 2uLL, v260 + 1, 1, (uint64_t)v259);
  }
  v259[2] = v260 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v259 + v609 + v610 * v260, v576, v612);
  v614 = v259;
  uint64_t v613 = 9;
  uint64_t v608 = 1;
  unsigned int v261 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v262 = (uint64_t)v602;
  static NeuralNetwork.Layer.ConvolutionParameters.PaddingKind.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(4, 4, 0, 0);
  __swift_storeEnumTagSinglePayload(v262, 0, 1, (uint64_t)v603);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v263 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x34312E7475706E69, 0xE800000000000000, 0x33312E7475706E69, 0xE800000000000000, 0x34312E7475706E69, 0xE800000000000000, 16, 16, 1, v261, v263, v262);
  uint64_t v264 = v263;
  uint64_t v265 = v604;
  v266 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v264, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v262, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v266(v261, v265);
  unsigned int v267 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    unsigned int v267 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v267[2] + 1, 1, (uint64_t)v267);
  }
  uint64_t v268 = v590;
  unint64_t v269 = v267[2];
  if (v267[3] >> 1 <= v269) {
    unsigned int v267 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v267[3] >= 2uLL, v269 + 1, 1, (uint64_t)v267);
  }
  v267[2] = v269 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v267 + v609 + v610 * v269, v575, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x35312E7475706E69, 0xE800000000000000, 0x34312E7475706E69, 0xE800000000000000, 0x35312E7475706E69, 0xE800000000000000, 16);
  unint64_t v270 = v267[2];
  if (v267[3] >> 1 <= v270) {
    unsigned int v267 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v267[3] >= 2uLL, v270 + 1, 1, (uint64_t)v267);
  }
  v267[2] = v270 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v267 + v609 + v610 * v270, v268, v612);
  v614 = v267;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v271 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v272 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v273 = (uint64_t)v603;
  ((void (*)(uint64_t, void, unsigned char *))v601)(v272, v600, v603);
  __swift_storeEnumTagSinglePayload(v272, 0, 1, v273);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v274 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x36312E7475706E69, 0xE800000000000000, 0x31312E7475706E69, 0xE800000000000000, 0x36312E7475706E69, 0xE800000000000000, 16, 8, 1, v271, v274, v272);
  unsigned int v275 = v274;
  uint64_t v276 = v604;
  uint64_t v277 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v275, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v272, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v277(v271, v276);
  v278 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    v278 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v278[2] + 1, 1, (uint64_t)v278);
  }
  unint64_t v279 = v278[2];
  if (v278[3] >> 1 <= v279) {
    v278 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v278[3] >= 2uLL, v279 + 1, 1, (uint64_t)v278);
  }
  v278[2] = v279 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v278 + v609 + v610 * v279, v574, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x6C61756469736572, 0xEA0000000000322ELL, 0x36312E7475706E69, 0xE800000000000000, 0x6C61756469736572, 0xEA0000000000322ELL, 16);
  unint64_t v280 = v278[2];
  if (v278[3] >> 1 <= v280) {
    v278 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v278[3] >= 2uLL, v280 + 1, 1, (uint64_t)v278);
  }
  v278[2] = v280 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v278 + v609 + v610 * v280, v573, v612);
  v614 = v278;
  static NeuralNetwork.Layer.add(name:inputNames:outputName:)(0x37312E7475706E69, 0xE800000000000000, &outlined read-only object #8 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:), 0x37312E7475706E69, 0xE800000000000000);
  uint64_t v281 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v281 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v281[2] + 1, 1, (uint64_t)v281);
  }
  unint64_t v282 = v281[2];
  if (v281[3] >> 1 <= v282) {
    uint64_t v281 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v281[3] >= 2uLL, v282 + 1, 1, (uint64_t)v281);
  }
  v281[2] = v282 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v281 + v609 + v610 * v282, v572, v612);
  static NeuralNetwork.Layer.relu(name:inputName:outputName:)(0x38312E7475706E69, 0xE800000000000000, 0x37312E7475706E69, 0xE800000000000000, 0x38312E7475706E69, 0xE800000000000000);
  unint64_t v283 = v281[2];
  if (v281[3] >> 1 <= v283) {
    uint64_t v281 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v281[3] >= 2uLL, v283 + 1, 1, (uint64_t)v281);
  }
  v281[2] = v283 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v281 + v609 + v610 * v283, v571, v612);
  v614 = v281;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v284 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v285 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v286 = (uint64_t)v603;
  ((void (*)(uint64_t, void, unsigned char *))v601)(v285, v600, v603);
  __swift_storeEnumTagSinglePayload(v285, 0, 1, v286);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v287 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v288 = v537;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x39312E7475706E69, 0xE800000000000000, 0x38312E7475706E69, 0xE800000000000000, 0x39312E7475706E69, 0xE800000000000000, 32, 16, 1, v284, v287, v285);
  uint64_t v289 = v287;
  uint64_t v290 = v604;
  uint64_t v291 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v289, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v285, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v291(v284, v290);
  uint64_t v292 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v292 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v292[2] + 1, 1, (uint64_t)v292);
  }
  unint64_t v293 = v292[2];
  if (v292[3] >> 1 <= v293) {
    uint64_t v292 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v292[3] >= 2uLL, v293 + 1, 1, (uint64_t)v292);
  }
  v292[2] = v293 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v292 + v609 + v610 * v293, v288, v612);
  v614 = v292;
  uint64_t v294 = v594;
  ((void (*)(unsigned char *, void, uint64_t))v595)(v594, v596, v599);
  uint64_t v613 = 1;
  uint64_t v608 = 3;
  char v295 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v296 = (uint64_t)v593;
  static NeuralNetwork.Layer.PoolParameters.Padding.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(0, 0, 1, 1);
  __swift_storeEnumTagSinglePayload(v296, 0, 1, (uint64_t)v598);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  unint64_t v297 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.pool(name:inputName:outputName:kind:kernelSize:strides:padding:)(0x30322E7475706E69, 0xE800000000000000, 0x39312E7475706E69, 0xE800000000000000, 0x30322E7475706E69, 0xE800000000000000, v294, v295, v297, v296);
  char v298 = v297;
  uint64_t v299 = v604;
  uint64_t v300 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v298, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v296, &demangling cache variable for type metadata for NeuralNetwork.Layer.PoolParameters.Padding?);
  v300(v295, v299);
  ((void (*)(unsigned char *, uint64_t))v597)(v294, v599);
  unint64_t v301 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    unint64_t v301 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v301[2] + 1, 1, (uint64_t)v301);
  }
  unint64_t v302 = v301[2];
  if (v301[3] >> 1 <= v302) {
    unint64_t v301 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v301[3] >= 2uLL, v302 + 1, 1, (uint64_t)v301);
  }
  v301[2] = v302 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v301 + v609 + v610 * v302, v570, v612);
  v614 = v301;
  uint64_t v613 = 9;
  uint64_t v608 = 1;
  v303 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v304 = (uint64_t)v602;
  static NeuralNetwork.Layer.ConvolutionParameters.PaddingKind.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(4, 4, 0, 0);
  __swift_storeEnumTagSinglePayload(v304, 0, 1, (uint64_t)v603);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v305 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x31322E7475706E69, 0xE800000000000000, 0x30322E7475706E69, 0xE800000000000000, 0x31322E7475706E69, 0xE800000000000000, 32, 32, 1, v303, v305, v304);
  unint64_t v306 = v305;
  uint64_t v307 = v604;
  unint64_t v308 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v306, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v304, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v308(v303, v307);
  v309 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    v309 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v309[2] + 1, 1, (uint64_t)v309);
  }
  v310 = v589;
  unint64_t v311 = v309[2];
  if (v309[3] >> 1 <= v311) {
    v309 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v309[3] >= 2uLL, v311 + 1, 1, (uint64_t)v309);
  }
  v309[2] = v311 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v309 + v609 + v610 * v311, v569, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x32322E7475706E69, 0xE800000000000000, 0x31322E7475706E69, 0xE800000000000000, 0x32322E7475706E69, 0xE800000000000000, 32);
  unint64_t v312 = v309[2];
  if (v309[3] >> 1 <= v312) {
    v309 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v309[3] >= 2uLL, v312 + 1, 1, (uint64_t)v309);
  }
  v309[2] = v312 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v309 + v609 + v610 * v312, v310, v612);
  v614 = v309;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v313 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v314 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v315 = (uint64_t)v603;
  ((void (*)(uint64_t, void, unsigned char *))v601)(v314, v600, v603);
  __swift_storeEnumTagSinglePayload(v314, 0, 1, v315);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v316 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x33322E7475706E69, 0xE800000000000000, 0x38312E7475706E69, 0xE800000000000000, 0x33322E7475706E69, 0xE800000000000000, 32, 16, 1, v313, v316, v314);
  uint64_t v317 = v316;
  uint64_t v318 = v604;
  uint64_t v319 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v317, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v314, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v319(v313, v318);
  uint64_t v320 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v320 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v320[2] + 1, 1, (uint64_t)v320);
  }
  unint64_t v321 = v320[2];
  if (v320[3] >> 1 <= v321) {
    uint64_t v320 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v320[3] >= 2uLL, v321 + 1, 1, (uint64_t)v320);
  }
  v320[2] = v321 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v320 + v609 + v610 * v321, v568, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x6C61756469736572, 0xEA0000000000332ELL, 0x33322E7475706E69, 0xE800000000000000, 0x6C61756469736572, 0xEA0000000000332ELL, 32);
  unint64_t v322 = v320[2];
  if (v320[3] >> 1 <= v322) {
    uint64_t v320 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v320[3] >= 2uLL, v322 + 1, 1, (uint64_t)v320);
  }
  v320[2] = v322 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v320 + v609 + v610 * v322, v567, v612);
  v614 = v320;
  static NeuralNetwork.Layer.add(name:inputNames:outputName:)(0x34322E7475706E69, 0xE800000000000000, &outlined read-only object #9 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:), 0x34322E7475706E69, 0xE800000000000000);
  uint64_t v323 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v323 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v323[2] + 1, 1, (uint64_t)v323);
  }
  unint64_t v324 = v323[2];
  if (v323[3] >> 1 <= v324) {
    uint64_t v323 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v323[3] >= 2uLL, v324 + 1, 1, (uint64_t)v323);
  }
  v323[2] = v324 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v323 + v609 + v610 * v324, v566, v612);
  static NeuralNetwork.Layer.relu(name:inputName:outputName:)(0x35322E7475706E69, 0xE800000000000000, 0x34322E7475706E69, 0xE800000000000000, 0x35322E7475706E69, 0xE800000000000000);
  unint64_t v325 = v323[2];
  if (v323[3] >> 1 <= v325) {
    uint64_t v323 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v323[3] >= 2uLL, v325 + 1, 1, (uint64_t)v323);
  }
  v323[2] = v325 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v323 + v609 + v610 * v325, v565, v612);
  v614 = v323;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  unint64_t v326 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v327 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v328 = (uint64_t)v603;
  ((void (*)(uint64_t, void, unsigned char *))v601)(v327, v600, v603);
  __swift_storeEnumTagSinglePayload(v327, 0, 1, v328);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v329 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  unsigned int v330 = v536;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x36322E7475706E69, 0xE800000000000000, 0x35322E7475706E69, 0xE800000000000000, 0x36322E7475706E69, 0xE800000000000000, 64, 32, 1, v326, v329, v327);
  os_log_type_t v331 = v329;
  uint64_t v332 = v604;
  v333 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v331, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v327, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v333(v326, v332);
  v334 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    v334 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v334[2] + 1, 1, (uint64_t)v334);
  }
  unint64_t v335 = v334[2];
  if (v334[3] >> 1 <= v335) {
    v334 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v334[3] >= 2uLL, v335 + 1, 1, (uint64_t)v334);
  }
  v334[2] = v335 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v334 + v609 + v610 * v335, v330, v612);
  v614 = v334;
  uint64_t v336 = v594;
  ((void (*)(unsigned char *, void, uint64_t))v595)(v594, v596, v599);
  uint64_t v613 = 1;
  uint64_t v608 = 3;
  uint64_t v337 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v338 = (uint64_t)v593;
  static NeuralNetwork.Layer.PoolParameters.Padding.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(0, 0, 1, 1);
  __swift_storeEnumTagSinglePayload(v338, 0, 1, (uint64_t)v598);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v339 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.pool(name:inputName:outputName:kind:kernelSize:strides:padding:)(0x37322E7475706E69, 0xE800000000000000, 0x36322E7475706E69, 0xE800000000000000, 0x37322E7475706E69, 0xE800000000000000, v336, v337, v339, v338);
  v340 = v339;
  uint64_t v341 = v604;
  v342 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v340, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v338, &demangling cache variable for type metadata for NeuralNetwork.Layer.PoolParameters.Padding?);
  v342(v337, v341);
  ((void (*)(unsigned char *, uint64_t))v597)(v336, v599);
  uint64_t v343 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v343 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v343[2] + 1, 1, (uint64_t)v343);
  }
  unint64_t v344 = v343[2];
  if (v343[3] >> 1 <= v344) {
    uint64_t v343 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v343[3] >= 2uLL, v344 + 1, 1, (uint64_t)v343);
  }
  v343[2] = v344 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v343 + v609 + v610 * v344, v564, v612);
  v614 = v343;
  uint64_t v613 = 9;
  uint64_t v608 = 1;
  v345 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v613 = 2;
  uint64_t v608 = 2;
  uint64_t v346 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v347 = (uint64_t)v602;
  static NeuralNetwork.Layer.ConvolutionParameters.PaddingKind.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(4, 4, 0, 0);
  __swift_storeEnumTagSinglePayload(v347, 0, 1, (uint64_t)v603);
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x38322E7475706E69, 0xE800000000000000, 0x37322E7475706E69, 0xE800000000000000, 0x38322E7475706E69, 0xE800000000000000, 64, 64, 1, v345, v346, v347);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v347, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v348 = v346;
  uint64_t v349 = v604;
  uint64_t v350 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v348, v604);
  v350(v345, v349);
  v351 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    v351 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v351[2] + 1, 1, (uint64_t)v351);
  }
  char v352 = v588;
  unint64_t v353 = v351[2];
  if (v351[3] >> 1 <= v353) {
    v351 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v351[3] >= 2uLL, v353 + 1, 1, (uint64_t)v351);
  }
  v351[2] = v353 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v351 + v609 + v610 * v353, v563, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x39322E7475706E69, 0xE800000000000000, 0x38322E7475706E69, 0xE800000000000000, 0x39322E7475706E69, 0xE800000000000000, 64);
  unint64_t v354 = v351[2];
  if (v351[3] >> 1 <= v354) {
    v351 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v351[3] >= 2uLL, v354 + 1, 1, (uint64_t)v351);
  }
  v351[2] = v354 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v351 + v609 + v610 * v354, v352, v612);
  v614 = v351;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v355 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v613 = 2;
  uint64_t v608 = 2;
  char v356 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v357 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v358 = (uint64_t)v603;
  ((void (*)(uint64_t, void, unsigned char *))v601)(v357, v600, v603);
  __swift_storeEnumTagSinglePayload(v357, 0, 1, v358);
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x30332E7475706E69, 0xE800000000000000, 0x35322E7475706E69, 0xE800000000000000, 0x30332E7475706E69, 0xE800000000000000, 64, 32, 1, v355, v356, v357);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v357, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  uint64_t v359 = v356;
  uint64_t v360 = v604;
  char v361 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v359, v604);
  v361(v355, v360);
  Swift::String v362 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    Swift::String v362 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v362[2] + 1, 1, (uint64_t)v362);
  }
  uint64_t v363 = v587;
  unint64_t v364 = v362[2];
  if (v362[3] >> 1 <= v364) {
    Swift::String v362 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v362[3] >= 2uLL, v364 + 1, 1, (uint64_t)v362);
  }
  v362[2] = v364 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v362 + v609 + v610 * v364, v562, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x6C61756469736572, 0xEA0000000000342ELL, 0x30332E7475706E69, 0xE800000000000000, 0x6C61756469736572, 0xEA0000000000342ELL, 64);
  unint64_t v365 = v362[2];
  if (v362[3] >> 1 <= v365) {
    Swift::String v362 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v362[3] >= 2uLL, v365 + 1, 1, (uint64_t)v362);
  }
  v362[2] = v365 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v362 + v609 + v610 * v365, v561, v612);
  v614 = v362;
  static NeuralNetwork.Layer.add(name:inputNames:outputName:)(0x31332E7475706E69, 0xE800000000000000, &outlined read-only object #10 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:), 0x31332E7475706E69, 0xE800000000000000);
  char v366 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    char v366 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v366[2] + 1, 1, (uint64_t)v366);
  }
  unint64_t v367 = v366[2];
  if (v366[3] >> 1 <= v367) {
    char v366 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v366[3] >= 2uLL, v367 + 1, 1, (uint64_t)v366);
  }
  v366[2] = v367 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v366 + v609 + v610 * v367, v363, v612);
  uint64_t v368 = v535;
  static NeuralNetwork.Layer.relu(name:inputName:outputName:)(0x32332E7475706E69, 0xE800000000000000, 0x31332E7475706E69, 0xE800000000000000, 0x32332E7475706E69, 0xE800000000000000);
  unint64_t v369 = v366[2];
  if (v366[3] >> 1 <= v369) {
    char v366 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v366[3] >= 2uLL, v369 + 1, 1, (uint64_t)v366);
  }
  v366[2] = v369 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v366 + v609 + v610 * v369, v368, v612);
  v614 = v366;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  char v370 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v371 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v372 = (uint64_t)v603;
  ((void (*)(uint64_t, void, unsigned char *))v601)(v371, v600, v603);
  __swift_storeEnumTagSinglePayload(v371, 0, 1, v372);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v373 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  char v374 = v534;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x33332E7475706E69, 0xE800000000000000, 0x32332E7475706E69, 0xE800000000000000, 0x33332E7475706E69, 0xE800000000000000, 128, 64, 1, v370, v373, v371);
  Swift::String v375 = v373;
  uint64_t v376 = v604;
  v377 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v375, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v371, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v377(v370, v376);
  char v378 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    char v378 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v378[2] + 1, 1, (uint64_t)v378);
  }
  unint64_t v379 = v378[2];
  if (v378[3] >> 1 <= v379) {
    char v378 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v378[3] >= 2uLL, v379 + 1, 1, (uint64_t)v378);
  }
  v378[2] = v379 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v378 + v609 + v610 * v379, v374, v612);
  v614 = v378;
  uint64_t v380 = v594;
  ((void (*)(unsigned char *, void, uint64_t))v595)(v594, v596, v599);
  uint64_t v613 = 1;
  uint64_t v608 = 3;
  v381 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v382 = (uint64_t)v593;
  static NeuralNetwork.Layer.PoolParameters.Padding.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(0, 0, 1, 1);
  __swift_storeEnumTagSinglePayload(v382, 0, 1, (uint64_t)v598);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  Swift::String v383 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.pool(name:inputName:outputName:kind:kernelSize:strides:padding:)(0x34332E7475706E69, 0xE800000000000000, 0x33332E7475706E69, 0xE800000000000000, 0x34332E7475706E69, 0xE800000000000000, v380, v381, v383, v382);
  uint64_t v384 = v383;
  uint64_t v385 = v604;
  char v386 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v384, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v382, &demangling cache variable for type metadata for NeuralNetwork.Layer.PoolParameters.Padding?);
  v386(v381, v385);
  ((void (*)(unsigned char *, uint64_t))v597)(v380, v599);
  Swift::String v387 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    Swift::String v387 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v387[2] + 1, 1, (uint64_t)v387);
  }
  unint64_t v388 = v387[2];
  if (v387[3] >> 1 <= v388) {
    Swift::String v387 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v387[3] >= 2uLL, v388 + 1, 1, (uint64_t)v387);
  }
  v387[2] = v388 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v387 + v609 + v610 * v388, v560, v612);
  v614 = v387;
  uint64_t v613 = 9;
  uint64_t v608 = 1;
  v389 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v390 = (uint64_t)v602;
  static NeuralNetwork.Layer.ConvolutionParameters.PaddingKind.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(4, 4, 0, 0);
  __swift_storeEnumTagSinglePayload(v390, 0, 1, (uint64_t)v603);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  Swift::String v391 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x35332E7475706E69, 0xE800000000000000, 0x34332E7475706E69, 0xE800000000000000, 0x35332E7475706E69, 0xE800000000000000, 64, 128, 1, v389, v391, v390);
  uint64_t v392 = v391;
  uint64_t v393 = v604;
  char v394 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v392, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v390, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v394(v389, v393);
  Swift::String v395 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    Swift::String v395 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v395[2] + 1, 1, (uint64_t)v395);
  }
  uint64_t v396 = v586;
  unint64_t v397 = v395[2];
  if (v395[3] >> 1 <= v397) {
    Swift::String v395 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v395[3] >= 2uLL, v397 + 1, 1, (uint64_t)v395);
  }
  v395[2] = v397 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v395 + v609 + v610 * v397, v559, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x36332E7475706E69, 0xE800000000000000, 0x35332E7475706E69, 0xE800000000000000, 0x36332E7475706E69, 0xE800000000000000, 64);
  unint64_t v398 = v395[2];
  if (v395[3] >> 1 <= v398) {
    Swift::String v395 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v395[3] >= 2uLL, v398 + 1, 1, (uint64_t)v395);
  }
  v395[2] = v398 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v395 + v609 + v610 * v398, v558, v612);
  v614 = v395;
  static NeuralNetwork.Layer.add(name:inputNames:outputName:)(0x37332E7475706E69, 0xE800000000000000, &outlined read-only object #11 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:), 0x37332E7475706E69, 0xE800000000000000);
  Swift::String v399 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    Swift::String v399 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v399[2] + 1, 1, (uint64_t)v399);
  }
  unint64_t v400 = v399[2];
  if (v399[3] >> 1 <= v400) {
    Swift::String v399 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v399[3] >= 2uLL, v400 + 1, 1, (uint64_t)v399);
  }
  v399[2] = v400 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v399 + v609 + v610 * v400, v396, v612);
  v401 = v533;
  static NeuralNetwork.Layer.relu(name:inputName:outputName:)(0x38332E7475706E69, 0xE800000000000000, 0x37332E7475706E69, 0xE800000000000000, 0x38332E7475706E69, 0xE800000000000000);
  unint64_t v402 = v399[2];
  if (v399[3] >> 1 <= v402) {
    Swift::String v399 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v399[3] >= 2uLL, v402 + 1, 1, (uint64_t)v399);
  }
  v399[2] = v402 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v399 + v609 + v610 * v402, v401, v612);
  v614 = v399;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v403 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v404 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v405 = (uint64_t)v603;
  ((void (*)(uint64_t, void, unsigned char *))v601)(v404, v600, v603);
  __swift_storeEnumTagSinglePayload(v404, 0, 1, v405);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v406 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  v407 = v532;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x39332E7475706E69, 0xE800000000000000, 0x38332E7475706E69, 0xE800000000000000, 0x39332E7475706E69, 0xE800000000000000, 128, 64, 1, v403, v406, v404);
  uint64_t v408 = v406;
  uint64_t v409 = v604;
  v410 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v408, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v404, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v410(v403, v409);
  v411 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    v411 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v411[2] + 1, 1, (uint64_t)v411);
  }
  unint64_t v412 = v411[2];
  if (v411[3] >> 1 <= v412) {
    v411 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v411[3] >= 2uLL, v412 + 1, 1, (uint64_t)v411);
  }
  v411[2] = v412 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v411 + v609 + v610 * v412, v407, v612);
  v614 = v411;
  v413 = v594;
  ((void (*)(unsigned char *, void, uint64_t))v595)(v594, v596, v599);
  uint64_t v613 = 1;
  uint64_t v608 = 3;
  v414 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v415 = (uint64_t)v593;
  static NeuralNetwork.Layer.PoolParameters.Padding.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(0, 0, 1, 1);
  __swift_storeEnumTagSinglePayload(v415, 0, 1, (uint64_t)v598);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v416 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.pool(name:inputName:outputName:kind:kernelSize:strides:padding:)(0x30342E7475706E69, 0xE800000000000000, 0x39332E7475706E69, 0xE800000000000000, 0x30342E7475706E69, 0xE800000000000000, v413, v414, v416, v415);
  v417 = v416;
  uint64_t v418 = v604;
  v419 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v417, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v415, &demangling cache variable for type metadata for NeuralNetwork.Layer.PoolParameters.Padding?);
  v419(v414, v418);
  ((void (*)(unsigned char *, uint64_t))v597)(v413, v599);
  uint64_t v420 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v420 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v420[2] + 1, 1, (uint64_t)v420);
  }
  unint64_t v421 = v420[2];
  if (v420[3] >> 1 <= v421) {
    uint64_t v420 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v420[3] >= 2uLL, v421 + 1, 1, (uint64_t)v420);
  }
  v420[2] = v421 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v420 + v609 + v610 * v421, v557, v612);
  v614 = v420;
  uint64_t v613 = 9;
  uint64_t v608 = 1;
  v422 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v613 = 2;
  uint64_t v608 = 2;
  v423 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v424 = (uint64_t)v602;
  static NeuralNetwork.Layer.ConvolutionParameters.PaddingKind.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(4, 4, 0, 0);
  __swift_storeEnumTagSinglePayload(v424, 0, 1, (uint64_t)v603);
  v425 = v531;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x31342E7475706E69, 0xE800000000000000, 0x30342E7475706E69, 0xE800000000000000, 0x31342E7475706E69, 0xE800000000000000, 128, 128, 1, v422, v423, v424);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v424, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v426 = v423;
  uint64_t v427 = v604;
  v428 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v426, v604);
  v428(v422, v427);
  v429 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    v429 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v429[2] + 1, 1, (uint64_t)v429);
  }
  v430 = v585;
  unint64_t v431 = v429[2];
  if (v429[3] >> 1 <= v431) {
    v429 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v429[3] >= 2uLL, v431 + 1, 1, (uint64_t)v429);
  }
  v429[2] = v431 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v429 + v609 + v610 * v431, v425, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x32342E7475706E69, 0xE800000000000000, 0x31342E7475706E69, 0xE800000000000000, 0x32342E7475706E69, 0xE800000000000000, 128);
  unint64_t v432 = v429[2];
  if (v429[3] >> 1 <= v432) {
    v429 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v429[3] >= 2uLL, v432 + 1, 1, (uint64_t)v429);
  }
  v429[2] = v432 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v429 + v609 + v610 * v432, v430, v612);
  v614 = v429;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v433 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v613 = 2;
  uint64_t v608 = 2;
  uint64_t v434 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v435 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v436 = (uint64_t)v603;
  ((void (*)(uint64_t, void, unsigned char *))v601)(v435, v600, v603);
  __swift_storeEnumTagSinglePayload(v435, 0, 1, v436);
  uint64_t v437 = v530;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x33342E7475706E69, 0xE800000000000000, 0x38332E7475706E69, 0xE800000000000000, 0x33342E7475706E69, 0xE800000000000000, 128, 64, 1, v433, v434, v435);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v435, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  uint64_t v438 = v434;
  uint64_t v439 = v604;
  uint64_t v440 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v438, v604);
  v440(v433, v439);
  uint64_t v441 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v441 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v441[2] + 1, 1, (uint64_t)v441);
  }
  uint64_t v442 = v584;
  unint64_t v443 = v441[2];
  if (v441[3] >> 1 <= v443) {
    uint64_t v441 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v441[3] >= 2uLL, v443 + 1, 1, (uint64_t)v441);
  }
  v441[2] = v443 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v441 + v609 + v610 * v443, v437, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x6C61756469736572, 0xEA0000000000352ELL, 0x33342E7475706E69, 0xE800000000000000, 0x6C61756469736572, 0xEA0000000000352ELL, 128);
  unint64_t v444 = v441[2];
  if (v441[3] >> 1 <= v444) {
    uint64_t v441 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v441[3] >= 2uLL, v444 + 1, 1, (uint64_t)v441);
  }
  v441[2] = v444 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v441 + v609 + v610 * v444, v556, v612);
  v614 = v441;
  static NeuralNetwork.Layer.add(name:inputNames:outputName:)(0x34342E7475706E69, 0xE800000000000000, &outlined read-only object #12 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:), 0x34342E7475706E69, 0xE800000000000000);
  v445 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    v445 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v445[2] + 1, 1, (uint64_t)v445);
  }
  unint64_t v446 = v445[2];
  if (v445[3] >> 1 <= v446) {
    v445 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v445[3] >= 2uLL, v446 + 1, 1, (uint64_t)v445);
  }
  v445[2] = v446 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v445 + v609 + v610 * v446, v442, v612);
  v447 = v529;
  static NeuralNetwork.Layer.relu(name:inputName:outputName:)(0x35342E7475706E69, 0xE800000000000000, 0x34342E7475706E69, 0xE800000000000000, 0x35342E7475706E69, 0xE800000000000000);
  unint64_t v448 = v445[2];
  if (v445[3] >> 1 <= v448) {
    v445 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v445[3] >= 2uLL, v448 + 1, 1, (uint64_t)v445);
  }
  v445[2] = v448 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v445 + v609 + v610 * v448, v447, v612);
  v614 = v445;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v449 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v450 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v451 = (uint64_t)v603;
  ((void (*)(uint64_t, void, unsigned char *))v601)(v450, v600, v603);
  __swift_storeEnumTagSinglePayload(v450, 0, 1, v451);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v452 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  v453 = v528;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x36342E7475706E69, 0xE800000000000000, 0x35342E7475706E69, 0xE800000000000000, 0x36342E7475706E69, 0xE800000000000000, 256, 128, 1, v449, v452, v450);
  v454 = v452;
  uint64_t v455 = v604;
  uint64_t v456 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v454, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v450, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v456(v449, v455);
  v457 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    v457 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v457[2] + 1, 1, (uint64_t)v457);
  }
  unint64_t v458 = v457[2];
  if (v457[3] >> 1 <= v458) {
    v457 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v457[3] >= 2uLL, v458 + 1, 1, (uint64_t)v457);
  }
  v457[2] = v458 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v457 + v609 + v610 * v458, v453, v612);
  v614 = v457;
  uint64_t v459 = v594;
  ((void (*)(unsigned char *, void, uint64_t))v595)(v594, v596, v599);
  uint64_t v613 = 1;
  uint64_t v608 = 3;
  uint64_t v460 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v461 = (uint64_t)v593;
  static NeuralNetwork.Layer.PoolParameters.Padding.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(0, 0, 1, 1);
  __swift_storeEnumTagSinglePayload(v461, 0, 1, (uint64_t)v598);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v462 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  static NeuralNetwork.Layer.pool(name:inputName:outputName:kind:kernelSize:strides:padding:)(0x37342E7475706E69, 0xE800000000000000, 0x36342E7475706E69, 0xE800000000000000, 0x37342E7475706E69, 0xE800000000000000, v459, v460, v462, v461);
  v463 = v462;
  uint64_t v464 = v604;
  uint64_t v465 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v463, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v461, &demangling cache variable for type metadata for NeuralNetwork.Layer.PoolParameters.Padding?);
  v465(v460, v464);
  ((void (*)(unsigned char *, uint64_t))v597)(v459, v599);
  uint64_t v466 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v466 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v466[2] + 1, 1, (uint64_t)v466);
  }
  unint64_t v467 = v466[2];
  if (v466[3] >> 1 <= v467) {
    uint64_t v466 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v466[3] >= 2uLL, v467 + 1, 1, (uint64_t)v466);
  }
  v466[2] = v467 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v466 + v609 + v610 * v467, v555, v612);
  v614 = v466;
  uint64_t v613 = 9;
  uint64_t v608 = 1;
  uint64_t v468 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v469 = (uint64_t)v602;
  static NeuralNetwork.Layer.ConvolutionParameters.PaddingKind.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(4, 4, 0, 0);
  __swift_storeEnumTagSinglePayload(v469, 0, 1, (uint64_t)v603);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v470 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  v471 = v527;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x38342E7475706E69, 0xE800000000000000, 0x37342E7475706E69, 0xE800000000000000, 0x38342E7475706E69, 0xE800000000000000, 256, 256, 1, v468, v470, v469);
  v472 = v470;
  uint64_t v473 = v604;
  v474 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v472, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v469, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v474(v468, v473);
  v475 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    v475 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v475[2] + 1, 1, (uint64_t)v475);
  }
  v476 = v583;
  unint64_t v477 = v475[2];
  if (v475[3] >> 1 <= v477) {
    v475 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v475[3] >= 2uLL, v477 + 1, 1, (uint64_t)v475);
  }
  v475[2] = v477 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v475 + v609 + v610 * v477, v471, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x39342E7475706E69, 0xE800000000000000, 0x38342E7475706E69, 0xE800000000000000, 0x39342E7475706E69, 0xE800000000000000, 256);
  unint64_t v478 = v475[2];
  if (v475[3] >> 1 <= v478) {
    v475 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v475[3] >= 2uLL, v478 + 1, 1, (uint64_t)v475);
  }
  v475[2] = v478 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v475 + v609 + v610 * v478, v476, v612);
  v614 = v475;
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  uint64_t v479 = v606;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v480 = (uint64_t)v602;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v481 = (uint64_t)v603;
  ((void (*)(uint64_t, void, unsigned char *))v601)(v480, v600, v603);
  __swift_storeEnumTagSinglePayload(v480, 0, 1, v481);
  uint64_t v613 = 1;
  uint64_t v608 = 1;
  v482 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  v483 = v526;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(0x30352E7475706E69, 0xE800000000000000, 0x35342E7475706E69, 0xE800000000000000, 0x30352E7475706E69, 0xE800000000000000, 256, 128, 1, v479, v482, v480);
  v484 = v482;
  uint64_t v485 = v604;
  v486 = (void (*)(unsigned char *, uint64_t))v607;
  ((void (*)(unsigned char *, uint64_t))v607)(v484, v604);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v480, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  v486(v479, v485);
  uint64_t v487 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    uint64_t v487 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v487[2] + 1, 1, (uint64_t)v487);
  }
  uint64_t v488 = v582;
  unint64_t v489 = v487[2];
  if (v487[3] >> 1 <= v489) {
    uint64_t v487 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v487[3] >= 2uLL, v489 + 1, 1, (uint64_t)v487);
  }
  v487[2] = v489 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v487 + v609 + v610 * v489, v483, v612);
  static NeuralNetwork.Layer.batchNormalize(name:inputName:outputName:inputChannelCount:)(0x6C61756469736572, 0xE800000000000000, 0x30352E7475706E69, 0xE800000000000000, 0x6C61756469736572, 0xE800000000000000, 256);
  unint64_t v490 = v487[2];
  if (v487[3] >> 1 <= v490) {
    uint64_t v487 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v487[3] >= 2uLL, v490 + 1, 1, (uint64_t)v487);
  }
  v487[2] = v490 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v487 + v609 + v610 * v490, v553, v612);
  v614 = v487;
  static NeuralNetwork.Layer.add(name:inputNames:outputName:)(0x31352E7475706E69, 0xE800000000000000, &outlined read-only object #13 of MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:), 0x31352E7475706E69, 0xE800000000000000);
  v491 = v614;
  if (!swift_isUniquelyReferenced_nonNull_native(v614)) {
    v491 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v491[2] + 1, 1, (uint64_t)v491);
  }
  unint64_t v492 = v491[2];
  if (v491[3] >> 1 <= v492) {
    v491 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v491[3] >= 2uLL, v492 + 1, 1, (uint64_t)v491);
  }
  v491[2] = v492 + 1;
  ((void (*)(char *, unsigned char *, uint64_t))v611)((char *)v491 + v609 + v610 * v492, v488, v612);
  uint64_t v493 = (uint64_t)v525;
  static NeuralNetwork.Layer.relu(name:inputName:outputName:)(0x32352E7475706E69, 0xE800000000000000, 0x31352E7475706E69, 0xE800000000000000, 0x32352E7475706E69, 0xE800000000000000);
  v614 = v491;
  unint64_t v494 = v491[2];
  if (v491[3] >> 1 <= v494) {
    v614 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v491[3] >= 2uLL, v494 + 1, 1, (uint64_t)v491);
  }
  specialized Array._appendElementAssumeUniqueAndCapacity(_:newElement:)(v494, v493);
  MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
  ((void (*)(unsigned char *, void, uint64_t))v595)(v594, v596, v599);
  uint64_t v613 = 0;
  uint64_t v608 = 0;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v613 = 0;
  uint64_t v608 = 0;
  v495 = v605;
  NeuralNetwork.Extent.init(height:width:)(&v613, &v608, &type metadata for Int, &protocol witness table for Int);
  uint64_t v496 = (uint64_t)v593;
  NeuralNetwork.ValidPaddingParameters.init()();
  uint64_t v497 = (uint64_t)v598;
  (*(void (**)(uint64_t, void, unsigned char *))(*((void *)v598 - 1) + 104))(v496, enum case for NeuralNetwork.Layer.PoolParameters.Padding.valid(_:), v598);
  __swift_storeEnumTagSinglePayload(v496, 0, 1, v497);
  uint64_t v498 = v552;
  NeuralNetwork.Layer.PoolParameters.init(kind:kernelSize:strides:padding:)(v594, v606, v495, v496);
  NeuralNetwork.Layer.PoolParameters.averageExcludesPadding.setter(1);
  unint64_t v499 = v498;
  NeuralNetwork.Layer.PoolParameters.doesGlobalPooling.setter(1);
  uint64_t v500 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t v501 = swift_allocObject(v500, 48, 7);
  uint64_t v502 = specialized static Array._adoptStorage(_:count:)(v501, 1);
  void *v503 = 0x32352E7475706E69;
  v503[1] = 0xE800000000000000;
  uint64_t v612 = specialized _finalizeUninitializedArray<A>(_:)(v502);
  uint64_t v504 = swift_allocObject(v500, 48, 7);
  uint64_t v505 = specialized static Array._adoptStorage(_:count:)(v504, 1);
  void *v506 = &unk_382E78;
  v506[1] = 0xE300000000000000;
  uint64_t v507 = specialized _finalizeUninitializedArray<A>(_:)(v505);
  v508 = v522;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v551 + 16))(v522, v499, v550);
  (*(void (**)(unsigned char *, void, uint64_t))(v524 + 104))(v508, enum case for NeuralNetwork.Layer.Kind.pool(_:), v523);
  uint64_t v509 = (uint64_t)v521;
  NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)(&unk_382E78, 0xE300000000000000, v612, v507, v508);
  specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
  uint64_t v510 = v614[2];
  specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v510);
  specialized Array._appendElementAssumeUniqueAndCapacity(_:newElement:)(v510, v509);
  MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
  uint64_t v511 = swift_allocObject(v554, 48, 7);
  uint64_t v512 = specialized static Array._adoptStorage(_:count:)(v511, 2);
  void *v513 = 1;
  v513[1] = 256;
  uint64_t v514 = specialized _finalizeUninitializedArray<A>(_:)(v512);
  LOBYTE(v510) = v514;
  static NeuralNetwork.Layer.reshapeStatic(name:inputName:outputName:targetShape:)(0x33352E7475706E69, 0xE800000000000000, &unk_382E78, 0xE300000000000000, 0x33352E7475706E69, 0xE800000000000000, v514);
  swift_bridgeObjectRelease(v510);
  specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
  uint64_t v515 = v614[2];
  specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v515);
  specialized Array._appendElementAssumeUniqueAndCapacity(_:newElement:)(v515, v509);
  MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
  uint64_t v516 = specialized Array.count.getter(*(void *)(v549 + 16));
  static NeuralNetwork.Layer.innerProduct(name:inputName:outputName:inputChannelCount:outputChannelCount:)(120, 0xE100000000000000, 0x33352E7475706E69, 0xE800000000000000, 120, 0xE100000000000000, 256, v516);
  specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
  uint64_t v517 = v614[2];
  specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v517);
  specialized Array._appendElementAssumeUniqueAndCapacity(_:newElement:)(v517, v509);
  MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
  static NeuralNetwork.Layer.softmaxND(name:inputName:outputName:axis:)(&unk_383433, 0xE300000000000000, 120, 0xE100000000000000, 0xD000000000000012, "shape does not match." + 0x8000000000000000, 1);
  specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
  uint64_t v518 = v614[2];
  specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v518);
  specialized Array._appendElementAssumeUniqueAndCapacity(_:newElement:)(v518, v509);
  MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
  (*(void (**)(unsigned char *, uint64_t))(v551 + 8))(v552, v550);
  return v614;
}

void *MLHandActionClassifier.GraphCNN.getCoreMLAndNeuralNetworksTrainableLayerMap(_:)(uint64_t a1)
{
  uint64_t v1 = (void *)Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for Int, &protocol witness table for String);
  uint64_t v22 = *(void *)(a1 + 16);
  if (v22)
  {
    swift_bridgeObjectRetain(a1);
    uint64_t v2 = (uint64_t *)(a1 + 40);
    uint64_t v3 = 0;
    do
    {
      uint64_t v23 = v3;
      uint64_t v4 = *(v2 - 1);
      uint64_t v21 = v2;
      uint64_t v5 = *v2;
      swift_bridgeObjectRetain(*v2);
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v1);
      uint64_t v24 = v4;
      uint64_t v20 = v5;
      unint64_t v8 = specialized __RawDictionaryStorage.find<A>(_:)(v4, v5);
      BOOL v9 = (v7 & 1) == 0;
      BOOL v10 = __OFADD__(v1[2], v9);
      Swift::Int v11 = v1[2] + v9;
      if (v10) {
        BUG();
      }
      char v12 = v7;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, Int>);
      if (_NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v11))
      {
        unint64_t v8 = specialized __RawDictionaryStorage.find<A>(_:)(v24, v20);
        if ((v12 & 1) != (v13 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
          BUG();
        }
      }
      if (v12)
      {
        uint64_t v14 = v23;
        *(void *)(v1[7] + 8 * v8) = v23;
      }
      else
      {
        v1[(v8 >> 6) + 8] |= 1 << v8;
        uint64_t v15 = v1[6];
        uint64_t v16 = 16 * v8;
        *(void *)(v15 + v16) = v24;
        *(void *)(v15 + v16 + 8) = v20;
        uint64_t v14 = v23;
        *(void *)(v1[7] + 8 * v8) = v23;
        uint64_t v17 = v1[2];
        BOOL v10 = __OFADD__(1, v17);
        uint64_t v18 = v17 + 1;
        if (v10) {
          BUG();
        }
        v1[2] = v18;
        swift_bridgeObjectRetain(v20);
      }
      uint64_t v3 = v14 + 1;
      swift_bridgeObjectRelease(v20);
      swift_bridgeObjectRelease(0);
      uint64_t v2 = v21 + 2;
    }
    while (v22 != v3);
    swift_bridgeObjectRelease(a1);
  }
  return v1;
}

void *MLHandActionClassifier.GraphCNN.updatedCoreMLLayers()()
{
  uint64_t v161 = v0;
  int64_t v1 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dense?)
                             - 8)
                 + 64);
  uint64_t v2 = alloca(v1);
  uint64_t v3 = alloca(v1);
  char v123 = &v118;
  uint64_t v150 = type metadata accessor for Dense(0);
  uint64_t v130 = *(void *)(v150 - 8);
  int64_t v4 = *(void *)(v130 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v143 = type metadata accessor for NeuralNetwork.Layer.InnerProductParameters(0);
  uint64_t v128 = *(void *)(v143 - 8);
  int64_t v7 = *(void *)(v128 + 64);
  unint64_t v8 = alloca(v7);
  BOOL v9 = alloca(v7);
  uint64_t v129 = &v118;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for BatchNorm?)
                              - 8)
                  + 64);
  Swift::Int v11 = alloca(v10);
  char v12 = alloca(v10);
  os_log_t v125 = &v118;
  uint64_t v139 = type metadata accessor for BatchNorm(0);
  uint64_t v140 = *(void *)(v139 - 8);
  int64_t v13 = *(void *)(v140 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  int v148 = &v118;
  uint64_t v138 = type metadata accessor for NeuralNetwork.Layer.BatchNormalizeParameters(0);
  uint64_t v133 = *(void *)(v138 - 8);
  int64_t v16 = *(void *)(v133 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v149 = &v118;
  int64_t v19 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Conv2D?)
                              - 8)
                  + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  uint64_t v124 = &v118;
  uint64_t v136 = type metadata accessor for Conv2D(0);
  uint64_t v137 = *(void *)(v136 - 8);
  int64_t v22 = *(void *)(v137 + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  uint64_t v146 = (void (*)(uint64_t *, uint64_t))&v118;
  uint64_t v134 = type metadata accessor for NeuralNetwork.Layer.ConvolutionParameters(0);
  uint64_t v135 = *(void *)(v134 - 8);
  int64_t v25 = *(void *)(v135 + 64);
  char v26 = alloca(v25);
  uint64_t v27 = alloca(v25);
  uint64_t v132 = &v118;
  uint64_t v158 = type metadata accessor for NeuralNetwork.Layer.Kind(0);
  uint64_t v157 = *(void *)(v158 - 8);
  int64_t v28 = *(void *)(v157 + 64);
  uint64_t v29 = alloca(v28);
  unint64_t v30 = alloca(v28);
  v144 = &v118;
  unint64_t v31 = alloca(v28);
  uint64_t v32 = alloca(v28);
  uint64_t v33 = type metadata accessor for NeuralNetwork.Layer(0);
  uint64_t v118 = *(void *)(v33 - 8);
  int64_t v34 = *(void *)(v118 + 64);
  uint64_t v35 = alloca(v34);
  uint64_t v36 = alloca(v34);
  uint64_t v120 = &v118;
  unint64_t v37 = alloca(v34);
  unint64_t v38 = alloca(v34);
  uint64_t v119 = &v118;
  unint64_t v39 = MLHandActionClassifier.GraphCNN.defineCoreMLLayers(numberOfKeypointsChannels:numberOfKeypoints:)(3uLL, 0x15uLL);
  swift_bridgeObjectRetain((_BYTE)v39);
  uint64_t v40 = MLHandActionClassifier.GraphCNN.coreMLTrainableLayerNames(from:)((uint64_t)v39);
  swift_bridgeObjectRelease((_BYTE)v39);
  uint64_t v147 = v40;
  v156 = MLHandActionClassifier.GraphCNN.getCoreMLAndNeuralNetworksTrainableLayerMap(_:)((uint64_t)v40);
  int64_t v41 = MLHandActionClassifier.GraphCNN.trainableSublayers()();
  uint64_t v42 = v39;
  uint64_t v121 = v39[2];
  uint64_t v152 = v41;
  if (v121)
  {
    unsigned int v153 = enum case for NeuralNetwork.Layer.Kind.innerProduct(_:);
    unsigned int v154 = enum case for NeuralNetwork.Layer.Kind.convolution(_:);
    unsigned int v155 = enum case for NeuralNetwork.Layer.Kind.batchNormalize(_:);
    uint64_t v145 = v41 + 4;
    unint64_t v43 = 0;
    uint64_t v131 = (uint64_t (*)(uint64_t *, uint64_t))&v118;
    int64_t v122 = &v118;
    uint64_t v151 = v33;
    do
    {
      if (v43 >= v42[2]) {
        BUG();
      }
      uint64_t v161 = v42;
      uint64_t v44 = v118;
      uint64_t v141 = (*(unsigned __int8 *)(v118 + 80) + 32) & ~*(unsigned __int8 *)(v118 + 80);
      uint64_t v142 = v43 * *(void *)(v118 + 72);
      uint64_t v45 = (char *)v42 + v141 + v142;
      uint64_t v46 = *(void (**)(uint64_t *, char *, uint64_t))(v118 + 16);
      uint64_t v47 = v119;
      unint64_t v160 = v43;
      v46(v119, v45, v33);
      v159._uint64_t countAndFlagsBits = NeuralNetwork.Layer.name.getter();
      v159._char object = v48;
      uint64_t v49 = *(void (**)(uint64_t *, uint64_t))(v44 + 8);
      v49(v47, v33);
      if (v160 >= v161[2]) {
        BUG();
      }
      uint64_t v50 = v120;
      v46(v120, v45, v33);
      uint64_t v51 = v122;
      NeuralNetwork.Layer.kind.getter();
      v49(v50, v33);
      uint64_t v52 = v158;
      uint64_t v53 = v157;
      int v54 = (*(uint64_t (**)(uint64_t *, uint64_t))(v157 + 88))(v51, v158);
      if (v54 == v153)
      {
        (*(void (**)(uint64_t *, uint64_t))(v53 + 96))(v51, v52);
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v128 + 32))(v129, v51, v143);
        uint64_t v56 = v156;
        if (!v156[2]) {
          goto LABEL_62;
        }
        char object = v159._object;
        swift_bridgeObjectRetain(v159._object);
        unint64_t v58 = specialized __RawDictionaryStorage.find<A>(_:)(v159._countAndFlagsBits, (uint64_t)object);
        uint64_t v60 = v131;
        if ((v59 & 1) == 0)
        {
          swift_bridgeObjectRelease((_BYTE)object);
LABEL_62:
          uint64_t v126 = 0;
          unint64_t v127 = 0xE000000000000000;
          _StringGuts.grow(_:)(80);
          v112._char object = "sequence of hand poses" + 0x8000000000000000;
          v112._uint64_t countAndFlagsBits = 0xD00000000000003FLL;
          String.append(_:)(v112);
          String.append(_:)(v159);
          v112._uint64_t countAndFlagsBits = 0x65726F63206E6920;
          v112._char object = (void *)0xEF63657073206C6DLL;
          String.append(_:)(v112);
          _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v126, v127, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 770, 0);
          goto LABEL_70;
        }
        uint64_t v61 = *(void *)(v56[7] + 8 * v58);
        swift_bridgeObjectRelease((_BYTE)object);
        uint64_t v62 = (uint64_t)v123;
        if (v61 < 0) {
          BUG();
        }
        if ((unint64_t)v61 >= v152[2]) {
          BUG();
        }
        outlined init with copy of TabularRegressionTask((uint64_t)&v145[5 * v61], (uint64_t)&v126);
        uint64_t v63 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Layer);
        if (!swift_dynamicCast(v62, &v126, v63, v150, 6))
        {
          __swift_storeEnumTagSinglePayload(v62, 1, 1, v150);
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for Dense?);
          uint64_t v126 = 0;
          unint64_t v127 = 0xE000000000000000;
          _StringGuts.grow(_:)(81);
          v113._uint64_t countAndFlagsBits = 0xD000000000000040;
          v113._char object = "amework layer for " + 0x8000000000000000;
          String.append(_:)(v113);
          String.append(_:)(v159);
          v113._uint64_t countAndFlagsBits = 0x65726F63206E6920;
          v113._char object = (void *)0xEF63657073206C6DLL;
          String.append(_:)(v113);
          _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v126, v127, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 773, 0);
          goto LABEL_70;
        }
        uint64_t v64 = v150;
        __swift_storeEnumTagSinglePayload(v62, 0, 1, v150);
        swift_bridgeObjectRelease(v159._object);
        (*(void (**)(uint64_t (*)(uint64_t *, uint64_t), uint64_t, uint64_t))(v130 + 32))(v60, v62, v64);
        uint64_t v65 = v147[2] - 1;
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v161);
        if (v61 == v65)
        {
          uint64_t v67 = v143;
          unint64_t v68 = v160;
          if (!isUniquelyReferenced_nonNull_native)
          {
            uint64_t v108 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v161);
            unint64_t v68 = v160;
            uint64_t v161 = v108;
          }
          char v69 = v161;
          uint64_t v70 = v158;
          if (v68 >= v161[2]) {
            BUG();
          }
        }
        else
        {
          uint64_t v67 = v143;
          unint64_t v103 = v160;
          if (!isUniquelyReferenced_nonNull_native)
          {
            uint64_t v109 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v161);
            unint64_t v103 = v160;
            uint64_t v161 = v109;
          }
          char v69 = v161;
          uint64_t v70 = v158;
          if (v103 >= v161[2]) {
            BUG();
          }
        }
        uint64_t v161 = v69;
        BOOL v104 = v61 == v65;
        uint64_t v105 = (uint64_t)v129;
        NeuralNetwork.Layer.loadInnerProductFromNeuralNetworks(_:useBias:into:)(v60, v104, (uint64_t)v129);
        id v106 = v144;
        uint64_t v107 = v128;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v128 + 16))(v144, v105, v67);
        (*(void (**)(uint64_t *, void, uint64_t))(v157 + 104))(v106, v153, v70);
        if (v160 >= v161[2]) {
          BUG();
        }
        NeuralNetwork.Layer.kind.setter(v106);
        (*(void (**)(uint64_t (*)(uint64_t *, uint64_t), uint64_t))(v130 + 8))(v131, v150);
        (*(void (**)(uint64_t, uint64_t))(v107 + 8))(v105, v67);
        uint64_t v42 = v161;
        uint64_t v33 = v151;
      }
      else
      {
        uint64_t v71 = (uint64_t)v132;
        if (v54 == v154)
        {
          (*(void (**)(uint64_t *, uint64_t, uint64_t, uint64_t))(v53 + 96))(v51, v52, v55, v133);
          (*(void (**)(uint64_t, uint64_t *, uint64_t))(v135 + 32))(v71, v51, v134);
          uint64_t v72 = v156;
          if (!v156[2]) {
            goto LABEL_65;
          }
          uint64_t v73 = v159._object;
          swift_bridgeObjectRetain(v159._object);
          unint64_t v74 = specialized __RawDictionaryStorage.find<A>(_:)(v159._countAndFlagsBits, (uint64_t)v73);
          if ((v75 & 1) == 0)
          {
            swift_bridgeObjectRelease((_BYTE)v73);
LABEL_65:
            uint64_t v126 = 0;
            unint64_t v127 = 0xE000000000000000;
            _StringGuts.grow(_:)(79);
            v114._uint64_t countAndFlagsBits = 0xD00000000000003ELL;
            v114._char object = "ework layer to batchnorm for " + 0x8000000000000000;
            String.append(_:)(v114);
            String.append(_:)(v159);
            v114._uint64_t countAndFlagsBits = 0x65726F63206E6920;
            v114._char object = (void *)0xEF63657073206C6DLL;
            String.append(_:)(v114);
            _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v126, v127, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 749, 0);
            goto LABEL_70;
          }
          uint64_t v76 = *(void *)(v72[7] + 8 * v74);
          swift_bridgeObjectRelease((_BYTE)v73);
          uint64_t v77 = (uint64_t)v124;
          int64_t v78 = v144;
          if (v76 < 0) {
            BUG();
          }
          if ((unint64_t)v76 >= v152[2]) {
            BUG();
          }
          outlined init with copy of TabularRegressionTask((uint64_t)&v145[5 * v76], (uint64_t)&v126);
          uint64_t v79 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Layer);
          uint64_t v80 = v136;
          if (!swift_dynamicCast(v77, &v126, v79, v136, 6))
          {
            __swift_storeEnumTagSinglePayload(v77, 1, 1, v80);
            outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v77, &demangling cache variable for type metadata for Conv2D?);
            uint64_t v126 = 0;
            unint64_t v127 = 0xE000000000000000;
            _StringGuts.grow(_:)(80);
            v115._char object = "layer state keypaths for " + 0x8000000000000000;
            v115._uint64_t countAndFlagsBits = 0xD00000000000003FLL;
            String.append(_:)(v115);
            String.append(_:)(v159);
            v115._uint64_t countAndFlagsBits = 0x65726F63206E6920;
            v115._char object = (void *)0xEF63657073206C6DLL;
            String.append(_:)(v115);
            _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v126, v127, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 752, 0);
            goto LABEL_70;
          }
          __swift_storeEnumTagSinglePayload(v77, 0, 1, v80);
          swift_bridgeObjectRelease(v159._object);
          (*(void (**)(void (*)(uint64_t *, uint64_t), uint64_t, uint64_t))(v137 + 32))(v146, v77, v80);
          int64_t v81 = v161;
          if (!swift_isUniquelyReferenced_nonNull_native(v161)) {
            int64_t v81 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v81);
          }
          if (v160 >= v81[2]) {
            BUG();
          }
          uint64_t v82 = (uint64_t)v132;
          uint64_t v83 = v81;
          NeuralNetwork.Layer.loadConv2DFromNeuralNetworks(_:useBias:into:)(v146, 0, (uint64_t)v132);
          int64_t v84 = v78;
          uint64_t v85 = v134;
          uint64_t v86 = v78;
          uint64_t v87 = v135;
          (*(void (**)(uint64_t *, uint64_t, uint64_t))(v135 + 16))(v84, v82, v134);
          (*(void (**)(uint64_t *, void, uint64_t))(v157 + 104))(v86, v154, v158);
          if (v160 >= v83[2]) {
            BUG();
          }
          uint64_t v161 = v83;
          NeuralNetwork.Layer.kind.setter(v86);
          (*(void (**)(void, uint64_t))(v137 + 8))(v146, v136);
          (*(void (**)(uint64_t, uint64_t))(v87 + 8))(v82, v85);
          goto LABEL_44;
        }
        if (v54 != v155)
        {
          swift_bridgeObjectRelease(v159._object);
          (*(void (**)(uint64_t *, uint64_t))(v157 + 8))(v51, v158);
LABEL_44:
          uint64_t v33 = v151;
          uint64_t v42 = v161;
          goto LABEL_45;
        }
        uint64_t v88 = v133;
        (*(void (**)(uint64_t *, uint64_t))(v157 + 96))(v51, v158);
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v88 + 32))(v149, v51, v138);
        uint64_t v89 = v156;
        int64_t v90 = v159._object;
        if (!v156[2]) {
          goto LABEL_68;
        }
        swift_bridgeObjectRetain(v159._object);
        unint64_t v91 = specialized __RawDictionaryStorage.find<A>(_:)(v159._countAndFlagsBits, (uint64_t)v90);
        if ((v92 & 1) == 0)
        {
          swift_bridgeObjectRelease((_BYTE)v90);
LABEL_68:
          uint64_t v126 = 0;
          unint64_t v127 = 0xE000000000000000;
          _StringGuts.grow(_:)(77);
          v116._uint64_t countAndFlagsBits = 0xD00000000000003CLL;
          v116._char object = "amework innerProduct layer for " + 0x8000000000000000;
          String.append(_:)(v116);
          v116._uint64_t countAndFlagsBits = v159._countAndFlagsBits;
          v116._char object = v90;
          String.append(_:)(v116);
          v116._uint64_t countAndFlagsBits = 0x65726F63206E6920;
          v116._char object = (void *)0xEF63657073206C6DLL;
          String.append(_:)(v116);
          _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v126, v127, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 760, 0);
LABEL_70:
          BUG();
        }
        uint64_t v93 = *(void *)(v89[7] + 8 * v91);
        swift_bridgeObjectRelease((_BYTE)v90);
        uint64_t v94 = (uint64_t)v125;
        uint64_t v95 = v144;
        if (v93 < 0) {
          BUG();
        }
        if ((unint64_t)v93 >= v152[2]) {
          BUG();
        }
        outlined init with copy of TabularRegressionTask((uint64_t)&v145[5 * v93], (uint64_t)&v126);
        uint64_t v96 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Layer);
        uint64_t v97 = v139;
        if (!swift_dynamicCast(v94, &v126, v96, v139, 6))
        {
          __swift_storeEnumTagSinglePayload(v94, 1, 1, v97);
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v94, &demangling cache variable for type metadata for BatchNorm?);
          uint64_t v126 = 0;
          unint64_t v127 = 0xE000000000000000;
          _StringGuts.grow(_:)(78);
          v117._uint64_t countAndFlagsBits = 0xD00000000000003DLL;
          v117._char object = "amework batchnorm layer for " + 0x8000000000000000;
          String.append(_:)(v117);
          v117._uint64_t countAndFlagsBits = v159._countAndFlagsBits;
          v117._char object = v90;
          String.append(_:)(v117);
          v117._uint64_t countAndFlagsBits = 0x65726F63206E6920;
          v117._char object = (void *)0xEF63657073206C6DLL;
          String.append(_:)(v117);
          _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v126, v127, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 763, 0);
          goto LABEL_70;
        }
        __swift_storeEnumTagSinglePayload(v94, 0, 1, v97);
        swift_bridgeObjectRelease((_BYTE)v90);
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v140 + 32))(v148, v94, v97);
        uint64_t v98 = v161;
        if (!swift_isUniquelyReferenced_nonNull_native(v161)) {
          uint64_t v161 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v98);
        }
        uint64_t v99 = (uint64_t)v149;
        uint64_t v100 = v161;
        if (v160 >= v161[2]) {
          BUG();
        }
        NeuralNetwork.Layer.loadBatchNormFromNeuralNetworks(_:into:)((uint64_t)v148, (uint64_t)v149);
        uint64_t v101 = v138;
        uint64_t v102 = v133;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v133 + 16))(v95, v99, v138);
        (*(void (**)(uint64_t *, void, uint64_t))(v157 + 104))(v95, v155, v158);
        if (v160 >= v100[2]) {
          BUG();
        }
        NeuralNetwork.Layer.kind.setter(v95);
        (*(void (**)(uint64_t *, uint64_t))(v140 + 8))(v148, v139);
        (*(void (**)(uint64_t, uint64_t))(v102 + 8))(v99, v101);
        uint64_t v33 = v151;
        uint64_t v42 = v100;
      }
LABEL_45:
      unint64_t v43 = v160 + 1;
    }
    while (v121 != v160 + 1);
  }
  uint64_t v110 = v42;
  swift_bridgeObjectRelease((_BYTE)v156);
  swift_bridgeObjectRelease((_BYTE)v147);
  swift_bridgeObjectRelease((_BYTE)v152);
  return v110;
}

uint64_t NeuralNetwork.Layer.loadBatchNormFromNeuralNetworks(_:into:)(uint64_t a1, uint64_t a2)
{
  uint64_t v19 = a2;
  v16[1] = a1;
  uint64_t v18 = type metadata accessor for Tensor(0);
  uint64_t v2 = *(void *)(v18 - 8);
  int64_t v3 = *(void *)(v2 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.WeightParameters?)
                             - 8)
                 + 64);
  int64_t v7 = alloca(v6);
  unint64_t v8 = alloca(v6);
  BatchNorm.scale.getter();
  uint64_t v9 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  v16[0] = *(void *)(v2 + 8);
  ((void (*)(void *, uint64_t))v16[0])(v16, v18);
  NeuralNetwork.WeightParameters.init(_:updatable:)(v9, 0);
  uint64_t v17 = type metadata accessor for NeuralNetwork.WeightParameters(0);
  __swift_storeEnumTagSinglePayload((uint64_t)v16, 0, 1, v17);
  NeuralNetwork.Layer.BatchNormalizeParameters.scale.setter(v16);
  BatchNorm.offset.getter();
  uint64_t v10 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  ((void (*)(void *, uint64_t))v16[0])(v16, v18);
  NeuralNetwork.WeightParameters.init(_:updatable:)(v10, 0);
  __swift_storeEnumTagSinglePayload((uint64_t)v16, 0, 1, v17);
  NeuralNetwork.Layer.BatchNormalizeParameters.offset.setter(v16);
  BatchNorm.runningMean.getter();
  uint64_t v11 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  uint64_t v12 = v18;
  int64_t v13 = (void (*)(void *, uint64_t))v16[0];
  ((void (*)(void *, uint64_t))v16[0])(v16, v18);
  NeuralNetwork.WeightParameters.init(_:updatable:)(v11, 0);
  __swift_storeEnumTagSinglePayload((uint64_t)v16, 0, 1, v17);
  NeuralNetwork.Layer.BatchNormalizeParameters.mean.setter(v16);
  BatchNorm.runningVariance.getter();
  uint64_t v14 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  v13(v16, v12);
  NeuralNetwork.WeightParameters.init(_:updatable:)(v14, 0);
  __swift_storeEnumTagSinglePayload((uint64_t)v16, 0, 1, v17);
  return NeuralNetwork.Layer.BatchNormalizeParameters.variance.setter(v16);
}

uint64_t NeuralNetwork.Layer.loadInnerProductFromNeuralNetworks(_:useBias:into:)(uint64_t (*a1)(uint64_t *, uint64_t), int a2, uint64_t a3)
{
  int v51 = a2;
  uint64_t v53 = a1;
  uint64_t v49 = type metadata accessor for Dense(0);
  uint64_t v48 = *(void *)(v49 - 8);
  int64_t v4 = *(void *)(v48 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v52 = &v39;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.WeightParameters?)
                             - 8)
                 + 64);
  unint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v45 = &v39;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?)
                              - 8)
                  + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v44 = &v39;
  uint64_t v43 = type metadata accessor for Tensor(0);
  int64_t v13 = *(uint64_t **)(v43 - 8);
  int64_t v14 = v13[8];
  uint64_t v15 = alloca(v14);
  int64_t v16 = alloca(v14);
  uint64_t v46 = &v39;
  uint64_t v17 = alloca(v14);
  uint64_t v18 = alloca(v14);
  uint64_t v47 = type metadata accessor for NeuralNetwork.WeightParameters(0);
  int64_t v19 = *(void *)(*(void *)(v47 - 8) + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  uint64_t v50 = a3;
  uint64_t v22 = NeuralNetwork.Layer.InnerProductParameters.outputChannelCount.getter();
  if (v22 != Dense.unitCount.getter())
  {
    (*(void (**)(uint64_t *, uint64_t (*)(uint64_t *, uint64_t), uint64_t))(v48 + 16))(v52, v53, v49);
    uint64_t v40 = 0;
    unint64_t v41 = 0xE000000000000000;
    _StringGuts.grow(_:)(86);
    v32._uint64_t countAndFlagsBits = 0xD000000000000041;
    v32._char object = "amework convolution layer for " + 0x8000000000000000;
    String.append(_:)(v32);
    uint64_t v42 = Dense.unitCount.getter();
    uint64_t v33 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char v35 = (char)v34;
    v32._uint64_t countAndFlagsBits = v33;
    v32._char object = v34;
    String.append(_:)(v32);
    swift_bridgeObjectRelease(v35);
    v32._char object = "ks framework has " + 0x8000000000000000;
    v32._uint64_t countAndFlagsBits = 0xD000000000000011;
    String.append(_:)(v32);
    uint64_t v42 = NeuralNetwork.Layer.InnerProductParameters.outputChannelCount.getter();
    uint64_t v36 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char v38 = (char)v37;
    v32._uint64_t countAndFlagsBits = v36;
    v32._char object = v37;
    String.append(_:)(v32);
    swift_bridgeObjectRelease(v38);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v40, v41, "CreateML/_MLHandActionClassifier+ModelExport.swift", 50, 2, 891, 0);
    BUG();
  }
  Dense.weight.getter();
  uint64_t v23 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  uint64_t v52 = v13;
  uint64_t v24 = (void (*)(uint64_t *, uint64_t))v13[1];
  uint64_t v25 = v43;
  v24(&v39, v43);
  NeuralNetwork.WeightParameters.init(_:updatable:)(v23, 0);
  uint64_t result = NeuralNetwork.Layer.InnerProductParameters.weights.setter(&v39);
  if (v51)
  {
    uint64_t v27 = (uint64_t)v44;
    Dense.bias.getter();
    if (__swift_getEnumTagSinglePayload(v27, 1, v25) == 1)
    {
      return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v27, &demangling cache variable for type metadata for Tensor?);
    }
    else
    {
      uint64_t v53 = (uint64_t (*)(uint64_t *, uint64_t))v24;
      int64_t v28 = v46;
      ((void (*)(uint64_t *, uint64_t, uint64_t))v52[4])(v46, v27, v25);
      uint64_t v29 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
      uint64_t v30 = v25;
      uint64_t v31 = (uint64_t)v45;
      NeuralNetwork.WeightParameters.init(_:updatable:)(v29, 0);
      __swift_storeEnumTagSinglePayload(v31, 0, 1, v47);
      NeuralNetwork.Layer.InnerProductParameters.bias.setter(v31);
      return v53(v28, v30);
    }
  }
  return result;
}

id outlined bridged method (mbbnn) of @objc NSBundle.url(forResource:withExtension:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void *a5)
{
  NSString v7 = String._bridgeToObjectiveC()();
  swift_bridgeObjectRelease(a2);
  NSString v8 = String._bridgeToObjectiveC()();
  swift_bridgeObjectRelease(a4);
  id v9 = [a5 URLForResource:v7 withExtension:v8];
  id v10 = v9;

  return v10;
}

uint64_t static BatchNorm.loadLayer(from:layerName:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v76 = v4;
  uint64_t v77 = v3;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TensorShape?)
                             - 8)
                 + 64);
  NSString v8 = alloca(v7);
  id v9 = alloca(v7);
  char v75 = &v74;
  int64_t v10 = *(void *)(*(void *)(type metadata accessor for Tensor(0) - 8) + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  int64_t v78 = &v74;
  int64_t v13 = alloca(v10);
  int64_t v14 = alloca(v10);
  int64_t v81 = &v74;
  uint64_t v15 = alloca(v10);
  int64_t v16 = alloca(v10);
  uint64_t v79 = &v74;
  uint64_t v17 = alloca(v10);
  uint64_t v18 = alloca(v10);
  uint64_t v80 = &v74;
  uint64_t v89 = a2;
  uint64_t v86 = a2;
  double v87 = *(double *)&a3;
  swift_bridgeObjectRetain(a3);
  v19._uint64_t countAndFlagsBits = 0x74657366666F2ELL;
  v19._char object = (void *)0xE700000000000000;
  String.append(_:)(v19);
  char v20 = LOBYTE(v87);
  uint64_t v21 = specialized Dictionary.subscript.getter(v86, *(uint64_t *)&v87, a1);
  swift_bridgeObjectRelease(v20);
  if (!v21)
  {
    uint64_t v86 = 0;
    double v87 = -2.681561585988519e154;
    _StringGuts.grow(_:)(39);
    char v56 = LOBYTE(v87);
    swift_bridgeObjectRetain(a3);
    swift_bridgeObjectRelease(v56);
    uint64_t v86 = v89;
    double v87 = *(double *)&a3;
    v57._uint64_t countAndFlagsBits = 0xD000000000000025;
    v57._char object = ", but coreml has ";
LABEL_20:
    v57._char object = (void *)((unint64_t)v57._object | 0x8000000000000000);
    String.append(_:)(v57);
    uint64_t v67 = v86;
    uint64_t v68 = *(void *)&v87;
    uint64_t v69 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v69, 0, 0);
    *(void *)uint64_t v70 = v67;
    *(void *)(v70 + 8) = v68;
    *(_OWORD *)(v70 + 16) = 0;
    *(_OWORD *)(v70 + 32) = 0;
    *(unsigned char *)(v70 + 48) = 2;
    return swift_willThrow(&type metadata for MLCreateError, v69, v70, v71, v72, v73);
  }
  uint64_t v86 = v89;
  double v87 = *(double *)&a3;
  swift_bridgeObjectRetain(a3);
  v22._uint64_t countAndFlagsBits = 0x656C6163732ELL;
  v22._char object = (void *)0xE600000000000000;
  String.append(_:)(v22);
  char v23 = LOBYTE(v87);
  uint64_t v24 = specialized Dictionary.subscript.getter(v86, *(uint64_t *)&v87, a1);
  double v88 = *(double *)&a3;
  uint64_t v25 = a1;
  uint64_t v26 = v24;
  swift_bridgeObjectRelease(v23);
  uint64_t v85 = v26;
  if (!v26)
  {
    swift_bridgeObjectRelease(v21);
    uint64_t v86 = 0;
    double v87 = -2.681561585988519e154;
    _StringGuts.grow(_:)(38);
    char v58 = LOBYTE(v87);
    uint64_t v59 = *(void *)&v88;
    swift_bridgeObjectRetain(LOBYTE(v88));
    swift_bridgeObjectRelease(v58);
    uint64_t v86 = v89;
    double v87 = *(double *)&v59;
    v57._uint64_t countAndFlagsBits = 0xD000000000000024;
    v57._char object = "d in state dictionary";
    goto LABEL_20;
  }
  uint64_t v86 = v89;
  double v87 = v88;
  swift_bridgeObjectRetain(LOBYTE(v88));
  v27._uint64_t countAndFlagsBits = 0x676E696E6E75722ELL;
  v27._char object = (void *)0xEC0000006E61654DLL;
  String.append(_:)(v27);
  char v28 = LOBYTE(v87);
  uint64_t v29 = specialized Dictionary.subscript.getter(v86, *(uint64_t *)&v87, v25);
  swift_bridgeObjectRelease(v28);
  uint64_t v83 = v29;
  if (!v29)
  {
    swift_bridgeObjectRelease(v85);
    swift_bridgeObjectRelease(v21);
    uint64_t v86 = 0;
    double v87 = -2.681561585988519e154;
    _StringGuts.grow(_:)(44);
    char v60 = LOBYTE(v87);
    uint64_t v61 = *(void *)&v88;
    swift_bridgeObjectRetain(LOBYTE(v88));
    swift_bridgeObjectRelease(v60);
    uint64_t v86 = v89;
    double v87 = *(double *)&v61;
    v57._uint64_t countAndFlagsBits = 0xD00000000000002ALL;
    v57._char object = " in state dictionary";
    goto LABEL_20;
  }
  uint64_t v84 = v21;
  uint64_t v86 = 0;
  double v87 = -2.681561585988519e154;
  _StringGuts.grow(_:)(18);
  char v30 = LOBYTE(v87);
  uint64_t v31 = *(void *)&v88;
  swift_bridgeObjectRetain(LOBYTE(v88));
  swift_bridgeObjectRelease(v30);
  uint64_t v86 = v89;
  double v87 = *(double *)&v31;
  v32._char object = " found in state dictionary" + 0x8000000000000000;
  v32._uint64_t countAndFlagsBits = 0xD000000000000010;
  String.append(_:)(v32);
  char v33 = LOBYTE(v87);
  uint64_t v34 = specialized Dictionary.subscript.getter(v86, *(uint64_t *)&v87, v25);
  swift_bridgeObjectRelease(v33);
  uint64_t v82 = v34;
  uint64_t v35 = v31;
  if (!v34)
  {
    swift_bridgeObjectRelease(v83);
    swift_bridgeObjectRelease(v85);
    swift_bridgeObjectRelease(v84);
    uint64_t v86 = 0;
    double v87 = -2.681561585988519e154;
    _StringGuts.grow(_:)(48);
    char v62 = LOBYTE(v87);
    swift_bridgeObjectRetain(v35);
    swift_bridgeObjectRelease(v62);
    uint64_t v86 = v89;
    double v87 = *(double *)&v35;
    v57._uint64_t countAndFlagsBits = 0xD00000000000002ELL;
    v57._char object = ".runningVariance";
    goto LABEL_20;
  }
  uint64_t v86 = v89;
  double v87 = *(double *)&v31;
  swift_bridgeObjectRetain(v31);
  v36._uint64_t countAndFlagsBits = 0x75746E656D6F6D2ELL;
  v36._char object = (void *)0xE90000000000006DLL;
  String.append(_:)(v36);
  char v37 = LOBYTE(v87);
  uint64_t v38 = specialized Dictionary.subscript.getter(v86, *(uint64_t *)&v87, v25);
  swift_bridgeObjectRelease(v37);
  char v39 = v84;
  if (!v38)
  {
LABEL_17:
    swift_bridgeObjectRelease(v82);
    swift_bridgeObjectRelease(v83);
    swift_bridgeObjectRelease(v85);
    swift_bridgeObjectRelease(v39);
    uint64_t v86 = 0;
    double v87 = -2.681561585988519e154;
    _StringGuts.grow(_:)(41);
    char v63 = LOBYTE(v87);
    uint64_t v64 = *(void *)&v88;
    swift_bridgeObjectRetain(LOBYTE(v88));
    swift_bridgeObjectRelease(v63);
    uint64_t v86 = v89;
    double v87 = *(double *)&v64;
    v57._uint64_t countAndFlagsBits = 0xD000000000000027;
    v57._char object = " not found in state dictionary";
    goto LABEL_20;
  }
  if (*(void *)(v38 + 16) != 1)
  {
    swift_bridgeObjectRelease(v38);
    goto LABEL_17;
  }
  uint64_t v86 = v89;
  double v87 = v88;
  swift_bridgeObjectRetain(LOBYTE(v88));
  v40._uint64_t countAndFlagsBits = 0x6E6F6C697370652ELL;
  v40._char object = (void *)0xE800000000000000;
  String.append(_:)(v40);
  char v41 = LOBYTE(v87);
  uint64_t v42 = v38;
  uint64_t v43 = specialized Dictionary.subscript.getter(v86, *(uint64_t *)&v87, v25);
  LOBYTE(v40._countAndFlagsBits) = v41;
  char v44 = v84;
  swift_bridgeObjectRelease(v40._countAndFlagsBits);
  if (!v43)
  {
LABEL_19:
    swift_bridgeObjectRelease(v42);
    swift_bridgeObjectRelease(v82);
    swift_bridgeObjectRelease(v83);
    swift_bridgeObjectRelease(v85);
    swift_bridgeObjectRelease(v44);
    uint64_t v86 = 0;
    double v87 = -2.681561585988519e154;
    _StringGuts.grow(_:)(40);
    char v65 = LOBYTE(v87);
    uint64_t v66 = *(void *)&v88;
    swift_bridgeObjectRetain(LOBYTE(v88));
    swift_bridgeObjectRelease(v65);
    uint64_t v86 = v89;
    double v87 = *(double *)&v66;
    v57._uint64_t countAndFlagsBits = 0xD000000000000026;
    v57._char object = "und in state dictionary";
    goto LABEL_20;
  }
  if (*(void *)(v43 + 16) != 1)
  {
    swift_bridgeObjectRelease(v43);
    goto LABEL_19;
  }
  if (!*(void *)(v42 + 16)) {
    BUG();
  }
  double v88 = *(double *)(v42 + 32);
  swift_bridgeObjectRelease(v42);
  uint64_t v45 = type metadata accessor for TensorShape(0);
  uint64_t v46 = (uint64_t)v75;
  __swift_storeEnumTagSinglePayload((uint64_t)v75, 1, 1, v45);
  char v47 = v84;
  Array<A>.floatTensor(shape:)(v46, v84);
  swift_bridgeObjectRelease(v47);
  outlined destroy of TensorShape?(v46);
  uint64_t v89 = v45;
  __swift_storeEnumTagSinglePayload(v46, 1, 1, v45);
  char v48 = v85;
  Array<A>.floatTensor(shape:)(v46, v85);
  swift_bridgeObjectRelease(v48);
  outlined destroy of TensorShape?(v46);
  if (!*(void *)(v43 + 16)) {
    BUG();
  }
  float v49 = v88;
  *(float *)&uint64_t v85 = v49;
  float v50 = *(double *)(v43 + 32);
  *(float *)&double v88 = v50;
  swift_bridgeObjectRelease(v43);
  uint64_t v51 = v89;
  __swift_storeEnumTagSinglePayload(v46, 1, 1, v89);
  char v52 = v83;
  Array<A>.floatTensor(shape:)(v46, v83);
  swift_bridgeObjectRelease(v52);
  outlined destroy of TensorShape?(v46);
  __swift_storeEnumTagSinglePayload(v46, 1, 1, v51);
  uint64_t v53 = v78;
  char v54 = v82;
  Array<A>.floatTensor(shape:)(v46, v82);
  swift_bridgeObjectRelease(v54);
  outlined destroy of TensorShape?(v46);
  return BatchNorm.init(momentum:offset:scale:epsilon:runningMean:runningVariance:)(v80, v79, v81, v53, *(float *)&v85, *(float *)&v88);
}

uint64_t MLImageClassifier.FeatureExtractor.init(type:)(uint64_t a1, uint64_t a2)
{
  v2[13] = a2;
  v2[12] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComposedTransformer<ImageScaler, MLModelImageFeatureExtractor>);
  v2[14] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[15] = v4;
  v2[16] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
  v2[17] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  v2[18] = v6;
  v2[19] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLImageClassifier.FeatureExtractor.init(type:), 0, 0);
}

uint64_t MLImageClassifier.FeatureExtractor.init(type:)()
{
  uint64_t v1 = *(void *)(v0 + 152);
  uint64_t v2 = *(void *)(v0 + 144);
  outlined init with copy of MLImageClassifier.FeatureExtractorType(*(void *)(v0 + 104), v1);
  if (swift_getEnumCaseMultiPayload(v1, v2) == 1)
  {
    outlined init with take of MLImageClassifier.CustomFeatureExtractor(*(void *)(v0 + 152), *(void *)(v0 + 136));
    uint64_t v3 = (void *)swift_task_alloc(dword_3A4624);
    *(void *)(v0 + 160) = v3;
    void *v3 = v0;
    v3[1] = MLImageClassifier.FeatureExtractor.init(type:);
    return MLImageClassifier.CustomFeatureExtractor.buildTransformer()(*(void *)(v0 + 128));
  }
  else
  {
    uint64_t v5 = *(void *)(v0 + 152);
    uint64_t v12 = *(void *)(v0 + 96);
    uint64_t v6 = *(void *)(v0 + 104);
    if (*(unsigned char *)(v5 + 8)) {
      uint64_t v7 = 2;
    }
    else {
      uint64_t v7 = *(void *)v5;
    }
    id v8 = objc_allocWithZone((Class)CIContext);
    id v9 = [v8 init];
    *(void *)(v0 + 40) = type metadata accessor for ImageFeaturePrint(0);
    *(void *)(v0 + 48) = &protocol witness table for ImageFeaturePrint;
    __swift_allocate_boxed_opaque_existential_1((void *)(v0 + 16));
    ImageFeaturePrint.init(revision:cropAndScale:context:)(v7, 0, v9);
    outlined destroy of MLActivityClassifier.ModelParameters(v6, type metadata accessor for MLImageClassifier.FeatureExtractorType);
    outlined init with take of MLIdentifier((long long *)(v0 + 16), v12);
    uint64_t v10 = *(void *)(v0 + 128);
    uint64_t v11 = *(void *)(v0 + 136);
    swift_task_dealloc(*(void *)(v0 + 152));
    swift_task_dealloc(v11);
    swift_task_dealloc(v10);
    return (*(uint64_t (**)(void))(v0 + 8))();
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 160);
  *(void *)(*(void *)v1 + 168) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLImageClassifier.FeatureExtractor.init(type:);
  }
  else {
    uint64_t v3 = MLImageClassifier.FeatureExtractor.init(type:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  void *boxed_opaque_existential_1;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  id v9 = *(void *)(v0 + 136);
  uint64_t v1 = *(void *)(v0 + 128);
  uint64_t v2 = *(void *)(v0 + 120);
  uint64_t v3 = *(void *)(v0 + 112);
  id v8 = *(void *)(v0 + 96);
  uint64_t v10 = *(void *)(v0 + 104);
  *(void *)(v0 + 80) = v3;
  *(void *)(v0 + 88) = lazy protocol witness table accessor for type ComposedTransformer<ImageScaler, MLModelImageFeatureExtractor> and conformance ComposedTransformer<A, B>();
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1((void *)(v0 + 56));
  (*(void (**)(void *, uint64_t, uint64_t))(v2 + 32))(boxed_opaque_existential_1, v1, v3);
  outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  outlined destroy of MLActivityClassifier.ModelParameters(v9, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
  outlined init with take of MLIdentifier((long long *)(v0 + 56), v8);
  uint64_t v5 = *(void *)(v0 + 128);
  uint64_t v6 = *(void *)(v0 + 136);
  swift_task_dealloc(*(void *)(v0 + 152));
  swift_task_dealloc(v6);
  swift_task_dealloc(v5);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v1 = *(void *)(v0 + 152);
  uint64_t v2 = *(void *)(v0 + 136);
  uint64_t v3 = *(void *)(v0 + 128);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 104), type metadata accessor for MLImageClassifier.FeatureExtractorType);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t lazy protocol witness table accessor for type ComposedTransformer<ImageScaler, MLModelImageFeatureExtractor> and conformance ComposedTransformer<A, B>()
{
  uint64_t result = lazy protocol witness table cache variable for type ComposedTransformer<ImageScaler, MLModelImageFeatureExtractor> and conformance ComposedTransformer<A, B>;
  if (!lazy protocol witness table cache variable for type ComposedTransformer<ImageScaler, MLModelImageFeatureExtractor> and conformance ComposedTransformer<A, B>)
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for ComposedTransformer<ImageScaler, MLModelImageFeatureExtractor>);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ComposedTransformer<A, B>, v1);
    lazy protocol witness table cache variable for type ComposedTransformer<ImageScaler, MLModelImageFeatureExtractor> and conformance ComposedTransformer<A, B> = result;
  }
  return result;
}

uint64_t destroy for MLImageClassifier.FeatureExtractor(void *a1)
{
  return __swift_destroy_boxed_opaque_existential_1Tm(a1);
}

uint64_t initializeWithCopy for MLImageClassifier.FeatureExtractor(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 24);
  *(_OWORD *)(a1 + 24) = *(_OWORD *)(a2 + 24);
  (**(void (***)(uint64_t))(v2 - 8))(a1);
  return a1;
}

uint64_t *assignWithCopy for MLImageClassifier.FeatureExtractor(uint64_t *a1, uint64_t *a2)
{
  return a1;
}

void __swift_assign_boxed_opaque_existential_1(uint64_t *a1, uint64_t *a2)
{
  if (a1 != a2)
  {
    uint64_t v3 = a1[3];
    uint64_t v4 = a2[3];
    if (v3 == v4)
    {
      uint64_t v8 = *(void *)(v3 - 8);
      if ((*(unsigned char *)(v8 + 82) & 2) != 0)
      {
        uint64_t v10 = *a1;
        uint64_t v11 = *a2;
        swift_retain(*a2);
        swift_release(v10);
        *a1 = v11;
      }
      else
      {
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v8 + 24))(a1, a2, a1[3]);
      }
    }
    else
    {
      a1[3] = v4;
      a1[4] = a2[4];
      uint64_t v5 = *(void *)(v3 - 8);
      uint64_t v6 = *(void *)(v4 - 8);
      int v7 = *(_DWORD *)(v6 + 80);
      if ((*(unsigned char *)(v5 + 82) & 2) != 0)
      {
        uint64_t v9 = *a1;
        if ((v7 & 0x20000) != 0)
        {
          uint64_t v13 = *a2;
          *a1 = *a2;
          swift_retain(v13);
        }
        else
        {
          (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v6 + 16))(a1, a2, v4);
        }
        swift_release(v9);
      }
      else
      {
        uint64_t v16 = *(void *)(v4 - 8);
        uint64_t v15 = v5;
        (*(void (**)(unsigned char *, uint64_t *, uint64_t))(v5 + 32))(v14, a1, v3);
        if ((v7 & 0x20000) != 0)
        {
          uint64_t v12 = *a2;
          *a1 = *a2;
          swift_retain(v12);
        }
        else
        {
          (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v16 + 16))(a1, a2, v4);
        }
        (*(void (**)(unsigned char *, uint64_t))(v15 + 8))(v14, v3);
      }
    }
  }
}

uint64_t __swift_memcpy40_8(uint64_t a1, long long *a2)
{
  uint64_t result = a1;
  *(void *)(a1 + 32) = *((void *)a2 + 4);
  long long v3 = *a2;
  *(_OWORD *)(a1 + 16) = a2[1];
  *(_OWORD *)a1 = v3;
  return result;
}

uint64_t assignWithTake for MLImageClassifier.FeatureExtractor(uint64_t a1, long long *a2)
{
  __swift_destroy_boxed_opaque_existential_1Tm((void *)a1);
  *(void *)(a1 + 32) = *((void *)a2 + 4);
  long long v2 = *a2;
  *(_OWORD *)(a1 + 16) = a2[1];
  *(_OWORD *)a1 = v2;
  return a1;
}

uint64_t getEnumTagSinglePayload for MLImageClassifier.FeatureExtractor(uint64_t a1, int a2)
{
  if (a2)
  {
    if (a2 < 0 && *(unsigned char *)(a1 + 40)) {
      int v2 = *(_DWORD *)a1 + 0x7FFFFFFF;
    }
    else {
      int v2 = (*(void *)(a1 + 24) & 0xFFFFFFFF00000001) != 0 ? -1 : *(void *)(a1 + 24) >> 1;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for MLImageClassifier.FeatureExtractor(uint64_t a1, int a2, int a3)
{
  if (a2 < 0)
  {
    *(_OWORD *)(a1 + 8) = 0;
    *(_OWORD *)(a1 + 24) = 0;
    *(void *)a1 = a2 + 0x80000000;
    if (a3 < 0) {
      *(unsigned char *)(a1 + 40) = 1;
    }
  }
  else
  {
    if (a3 < 0) {
      *(unsigned char *)(a1 + 40) = 0;
    }
    if (a2) {
      *(void *)(a1 + 24) = 2 * (a2 - 1);
    }
  }
}

ValueMetadata *type metadata accessor for MLImageClassifier.FeatureExtractor()
{
  return &type metadata for MLImageClassifier.FeatureExtractor;
}

char **one-time initialization function for predictor()
{
  static CosineSimilarity.predictor = (uint64_t)&type metadata for CosineSimilarityPredictor;
  uint64_t result = &protocol witness table for CosineSimilarityPredictor;
  qword_3C7080 = (uint64_t)&protocol witness table for CosineSimilarityPredictor;
  return result;
}

void *static CosineSimilarity.buildItemStatistics(ratings:count:)(void *a1, uint64_t a2)
{
  int v2 = specialized Array.init(repeating:count:)(0, a2, 0.0);
  uint64_t v27 = a1[3];
  uint64_t v28 = a1[4];
  v29[0] = a1[5];
  outlined retain of [Int](&v27);
  outlined retain of [Int](&v28);
  outlined retain of ContiguousArray<Double>(v29);
  specialized SparseMatrix.IndexedSequence.Iterator.init(base:)((uint64_t)a1);
  specialized SparseMatrix.IndexedSequence.Iterator.next()(a1, a2, v3, v4, v5, v6);
  if ((v9 & 1) == 0)
  {
    uint64_t v10 = v7;
    double v11 = v8;
    do
    {
      uint64_t v12 = v2;
      if (!swift_isUniquelyReferenced_nonNull_native(v2))
      {
        uint64_t v12 = v2;
        int v2 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v2);
      }
      if (v10 < 0) {
        BUG();
      }
      if ((unint64_t)v10 >= v2[2]) {
        BUG();
      }
      uint64_t v16 = 2 * v10;
      *(double *)&v2[v16 + 5] = v11 * v11 + *(double *)&v2[v16 + 5];
      uint64_t v17 = v2[v16 + 4];
      BOOL v18 = __OFADD__(1, v17);
      uint64_t v19 = v17 + 1;
      if (v18) {
        BUG();
      }
      char v20 = &v2[v16 + 4];
      *char v20 = v19;
      specialized SparseMatrix.IndexedSequence.Iterator.next()(v12, a2, v13, v20, v14, v15);
      uint64_t v10 = v21;
      double v11 = v22;
    }
    while ((v23 & 1) == 0);
  }
  swift_release();
  swift_bridgeObjectRelease(v26);
  swift_bridgeObjectRelease(v25);
  return v2;
}

void static CosineSimilarityPredictor.updatePrediction(_:itemScore:neighborScore:)(double *a1, double a2, double a3)
{
  *a1 = a2 * a3 + *a1;
}

__m128 static CosineSimilarityPredictor.finalizePrediction(_:userRatingCount:)(uint64_t a1, __m128 a2)
{
  long long v2 = 0;
  if (a1)
  {
    *(double *)a2.i64 = *(double *)a2.i64 / (double)(int)a1;
    return a2;
  }
  return (__m128)v2;
}

double protocol witness for static ItemSimilarityPredictor.interactionScoreRange.getter in conformance CosineSimilarityPredictor()
{
  return -1.0;
}

void protocol witness for static ItemSimilarityPredictor.updatePrediction(_:itemScore:neighborScore:) in conformance CosineSimilarityPredictor(double *a1, double a2, double a3)
{
}

__m128 protocol witness for static ItemSimilarityPredictor.finalizePrediction(_:userRatingCount:) in conformance CosineSimilarityPredictor(uint64_t a1, __m128 a2)
{
  return static CosineSimilarityPredictor.finalizePrediction(_:userRatingCount:)(a1, a2);
}

ValueMetadata *type metadata accessor for CosineSimilarityPredictor()
{
  return &type metadata for CosineSimilarityPredictor;
}

uint64_t _sScTss5NeverORs_rlE8priority9operationScTyxABGScPSg_xyYaYAcntcfCyt_Tgm5(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = type metadata accessor for TaskPriority(0);
  uint64_t v20 = a2;
  if (__swift_getEnumTagSinglePayload(a1, 1, v4) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, &demangling cache variable for type metadata for TaskPriority?);
    uint64_t v5 = 7168;
  }
  else
  {
    unsigned __int8 v6 = TaskPriority.rawValue.getter();
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
    uint64_t v5 = v6 | 0x1C00;
  }
  uint64_t v7 = *(void *)(a3 + 16);
  if (v7)
  {
    uint64_t v8 = *(void *)(a3 + 24);
    uint64_t ObjectType = swift_getObjectType(*(void *)(a3 + 16));
    swift_unknownObjectRetain(v7);
    uint64_t v10 = dispatch thunk of Actor.unownedExecutor.getter(ObjectType, v8);
    uint64_t v12 = v11;
    swift_unknownObjectRelease(v7);
  }
  else
  {
    uint64_t v10 = 0;
    uint64_t v12 = 0;
  }
  uint64_t v13 = swift_allocObject(&unk_39D5F8, 32, 7);
  *(void *)(v13 + 16) = v20;
  *(void *)(v13 + 24) = a3;
  if (v10 | v12)
  {
    uint64_t v15 = &v17;
    long long v17 = 0;
    uint64_t v18 = v10;
    uint64_t v19 = v12;
  }
  else
  {
    uint64_t v15 = 0;
  }
  return swift_task_create(v5, v15, (char *)&type metadata for () + 8, &_sxIeAgHr_xs5Error_pIegHrzo_s8SendableRzs5NeverORs_r0_lTRyt_Tg5TATu, v13, v14, v17, *((void *)&v17 + 1), v18, v19);
}

uint64_t MLImageClassifier.init(_:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v3[4] = a3;
  v3[3] = a2;
  v3[2] = a1;
  uint64_t v4 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  v3[5] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0);
  v3[6] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLImageClassifier.init(_:parameters:), 0, 0);
}

uint64_t MLImageClassifier.init(_:parameters:)()
{
  uint64_t v13 = *(void *)(v0 + 48);
  uint64_t v12 = *(void *)(v0 + 40);
  uint64_t v14 = *(void *)(v0 + 32);
  uint64_t v1 = *(void *)(v0 + 16);
  uint64_t v15 = *(void *)(v0 + 24);
  long long v2 = (_DWORD *)type metadata accessor for MLImageClassifier(0);
  *(_DWORD *)(v0 + 80) = v2[6];
  MLClassifierMetrics.init()();
  uint64_t v3 = (int)v2[7];
  *(_DWORD *)(v0 + 84) = v3;
  uint64_t v4 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v5 = swift_allocError(&type metadata for MLCreateError, v4, 0, 0);
  *(void *)uint64_t v6 = 0xD0000000000000C0;
  *(void *)(v6 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v6 + 16) = 0;
  *(_OWORD *)(v6 + 32) = 0;
  *(unsigned char *)(v6 + 48) = 0;
  *(void *)(v1 + v3) = v5;
  uint64_t v7 = type metadata accessor for MLClassifierMetrics.Contents(0);
  swift_storeEnumTagMultiPayload(v3 + v1, v7, 2);
  uint64_t v8 = (int)v2[8];
  *(_DWORD *)(v0 + 88) = v8;
  outlined init with copy of MLTrainingSessionParameters(v15, v1 + v8, type metadata accessor for MLImageClassifier.Model);
  outlined init with copy of MLImageClassifier.ModelParameters(v14, v1 + 8);
  MLImageClassifier.ModelParameters.algorithm.getter(v14);
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType));
  swift_bridgeObjectRelease(*(void *)(v13 + *(int *)(v9 + 48)));
  outlined init with take of MLClassifierMetrics(v13, v12, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v10 = (void *)swift_task_alloc(dword_3A801C);
  *(void *)(v0 + 56) = v10;
  void *v10 = v0;
  v10[1] = MLImageClassifier.init(_:parameters:);
  return MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  uint64_t v6;

  uint64_t v1 = *(void *)(v0 + 72);
  uint64_t v6 = *(void *)(v0 + 48);
  long long v2 = *(void *)(v0 + 40);
  uint64_t v3 = *(void **)(v0 + 16);
  uint64_t v4 = *(void *)(v0 + 24);
  outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v0 + 32));
  outlined destroy of MLActivityClassifier.ModelParameters(v4, type metadata accessor for MLImageClassifier.Model);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  void *v3 = v1;
  swift_task_dealloc(v6);
  swift_task_dealloc(v2);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;

  uint64_t v7 = *(void *)(v0 + 48);
  uint64_t v1 = *(void *)(v0 + 40);
  long long v2 = *(void *)(v0 + 16);
  uint64_t v9 = *(void *)(v0 + 24);
  uint64_t v8 = v2 + 8;
  uint64_t v3 = v2 + *(int *)(v0 + 88);
  uint64_t v4 = v2 + *(int *)(v0 + 84);
  uint64_t v5 = v2 + *(int *)(v0 + 80);
  outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v0 + 32));
  outlined destroy of MLActivityClassifier.ModelParameters(v9, type metadata accessor for MLImageClassifier.Model);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  outlined destroy of MLImageClassifier.ModelParameters(v8);
  outlined destroy of MLActivityClassifier.ModelParameters(v5, type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(v4, type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLImageClassifier.Model);
  swift_task_dealloc(v7);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLImageClassifier.init(_:parameters:)(uint64_t a1)
{
  uint64_t v5 = *(void *)(*v2 + 56);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 64) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = MLImageClassifier.init(_:parameters:);
  }
  else
  {
    *(void *)(v4 + 72) = a1;
    uint64_t v6 = MLImageClassifier.init(_:parameters:);
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t MLImageClassifier.init(checkpoint:)(uint64_t a1)
{
  uint64_t v139 = v2;
  uint64_t v138 = a1;
  uint64_t v3 = v1;
  uint64_t v115 = *(void *)(type metadata accessor for MLImageClassifier.FeatureExtractorType(0) - 8);
  int64_t v4 = *(void *)(v115 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  char v123 = v105;
  int64_t v113 = v4;
  uint64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  uint64_t v133 = v105;
  uint64_t v117 = *(void *)(type metadata accessor for MLImageClassifier.Model(0) - 8);
  int64_t v9 = *(void *)(v117 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  Swift::String v116 = v105;
  int64_t v114 = v9;
  uint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v130 = v105;
  uint64_t v107 = type metadata accessor for MLImageClassifier.Classifier(0);
  int64_t v14 = *(void *)(*(void *)(v107 - 8) + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v131 = v105;
  uint64_t v108 = type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0);
  int64_t v17 = *(void *)(*(void *)(v108 - 8) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v118 = v105;
  uint64_t v20 = alloca(v17);
  uint64_t v21 = alloca(v17);
  uint64_t v110 = v105;
  double v22 = alloca(v17);
  char v23 = alloca(v17);
  uint64_t v109 = v105;
  uint64_t v111 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  int64_t v24 = *(void *)(*(void *)(v111 - 8) + 64);
  char v25 = alloca(v24);
  char v26 = alloca(v24);
  Swift::String v112 = v105;
  uint64_t v27 = alloca(v24);
  uint64_t v28 = alloca(v24);
  uint64_t v128 = v105;
  uint64_t v132 = (int *)type metadata accessor for MLImageClassifier.PersistentParameters(0);
  int64_t v29 = *(void *)(*((void *)v132 - 1) + 64);
  char v30 = alloca(v29);
  uint64_t v31 = alloca(v29);
  unint64_t v127 = v105;
  uint64_t v126 = type metadata accessor for URL(0);
  uint64_t v134 = *(void *)(v126 - 8);
  int64_t v32 = *(void *)(v134 + 64);
  char v33 = alloca(v32);
  uint64_t v34 = alloca(v32);
  uint64_t v135 = (void (*)(uint64_t, uint64_t))v105;
  uint64_t v35 = alloca(v32);
  Swift::String v36 = alloca(v32);
  uint64_t v129 = v105;
  char v37 = alloca(v32);
  uint64_t v38 = alloca(v32);
  uint64_t v136 = v105;
  char v39 = alloca(v32);
  Swift::String v40 = alloca(v32);
  uint64_t v140 = v105;
  uint64_t v41 = type metadata accessor for MLImageClassifier(0);
  uint64_t v124 = v3 + *(int *)(v41 + 24);
  MLClassifierMetrics.init()();
  uint64_t v119 = v41;
  uint64_t v42 = *(int *)(v41 + 28);
  uint64_t v43 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v44 = swift_allocError(&type metadata for MLCreateError, v43, 0, 0);
  *(void *)uint64_t v45 = 0xD0000000000000C0;
  *(void *)(v45 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v45 + 16) = 0;
  *(_OWORD *)(v45 + 32) = 0;
  *(unsigned char *)(v45 + 48) = 0;
  *(void *)(v3 + v42) = v44;
  uint64_t v46 = type metadata accessor for MLClassifierMetrics.Contents(0);
  uint64_t v125 = v42 + v3;
  swift_storeEnumTagMultiPayload(v42 + v3, v46, 2);
  uint64_t v47 = *(unsigned __int8 *)(v138 + *(int *)(type metadata accessor for MLCheckpoint(0) + 20));
  uint64_t v122 = v3;
  switch(v47)
  {
    case 0:
      uint64_t v137 = v43;
      uint64_t v48 = 0x696C616974696E69;
      unint64_t v49 = 0xEB0000000064657ALL;
      break;
    case 1:
      uint64_t v137 = v43;
      uint64_t v48 = 0x6974636172747865;
      goto LABEL_6;
    case 2:
      unint64_t v50 = 0xE800000000000000;
      swift_bridgeObjectRelease(0);
      goto LABEL_9;
    case 3:
      uint64_t v137 = v43;
      uint64_t v48 = 0x697461756C617665;
LABEL_6:
      unint64_t v49 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v137 = v43;
      unint64_t v49 = 0xEB00000000676E69;
      uint64_t v48 = 0x636E657265666E69;
      break;
    case 5:
      JUMPOUT(0x2CDF58);
  }
  char v51 = _stringCompareWithSmolCheck(_:_:expecting:)(v48, v49, 0x676E696E69617274, 0xE800000000000000, 0);
  unint64_t v50 = v49;
  swift_bridgeObjectRelease(v49);
  if ((v51 & 1) == 0)
  {
    uint64_t v61 = v137;
    swift_allocError(&type metadata for MLCreateError, v137, 0, 0);
    *(void *)uint64_t v62 = 0xD00000000000003CLL;
    *(void *)(v62 + 8) = "nd in state dictionary" + 0x8000000000000000;
    *(_OWORD *)(v62 + 16) = 0;
    *(_OWORD *)(v62 + 32) = 0;
    *(unsigned char *)(v62 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v61, v62, v63, v64, v65);
    outlined destroy of MLActivityClassifier.ModelParameters(v138, type metadata accessor for MLCheckpoint);
    uint64_t v59 = v124;
    uint64_t v60 = v125;
    goto LABEL_19;
  }
LABEL_9:
  URL.deletingLastPathComponent()(v50);
  uint64_t v52 = (uint64_t)v129;
  URL.appendingPathComponent(_:)(0x6C65646F6DLL, 0xE500000000000000);
  URL.appendingPathExtension(_:)(6777712, 0xE300000000000000);
  uint64_t v53 = v134;
  char v54 = *(void (**)(uint64_t, uint64_t))(v134 + 8);
  uint64_t v55 = v126;
  v54(v52, v126);
  uint64_t v56 = (uint64_t)v135;
  (*(void (**)(void (*)(uint64_t, uint64_t), void *, uint64_t))(v53 + 16))(v135, v140, v55);
  uint64_t v57 = (uint64_t)v127;
  uint64_t v58 = v139;
  MLImageClassifier.PersistentParameters.init(sessionDirectory:)(v56);
  if (v58)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(v138, type metadata accessor for MLCheckpoint);
    v54((uint64_t)v136, v55);
    v54((uint64_t)v140, v55);
    uint64_t v59 = v124;
    uint64_t v60 = v125;
LABEL_19:
    outlined destroy of MLActivityClassifier.ModelParameters(v59, type metadata accessor for MLClassifierMetrics);
    return outlined destroy of MLActivityClassifier.ModelParameters(v60, type metadata accessor for MLClassifierMetrics);
  }
  uint64_t v135 = v54;
  uint64_t v66 = v132;
  outlined init with copy of MLTrainingSessionParameters(v57 + v132[5], (uint64_t)v128, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  uint64_t v137 = *(void *)(v57 + v66[8]);
  uint64_t v120 = *(void *)(v57 + v66[9]);
  uint64_t v67 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType));
  uint64_t v139 = 0;
  uint64_t v121 = v67;
  uint64_t v68 = *(int *)(v67 + 48);
  uint64_t v69 = (uint64_t)v109;
  outlined init with copy of MLTrainingSessionParameters(v57 + v66[6], (uint64_t)v109, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v70 = *(void *)(v57 + v66[7]);
  uint64_t v71 = 0;
  if (v70 != 2) {
    uint64_t v71 = v70;
  }
  *(void *)(v69 + v68) = v71;
  uint64_t v72 = v122;
  uint64_t v134 = v122 + 8;
  uint64_t v132 = (int *)(v122 + 24);
  uint64_t v129 = (void *)(v122 + 56);
  *(_OWORD *)(v122 + 72) = 0;
  *(_OWORD *)(v72 + 56) = 0;
  *(_OWORD *)(v72 + 40) = 0;
  *(_OWORD *)(v72 + 24) = 0;
  *(void *)(v72 + 8) = v137;
  *(void *)(v72 + 16) = v120;
  uint64_t v73 = (uint64_t)v112;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v128, (uint64_t)v112, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  uint64_t v106 = v111;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v105);
  outlined init with take of MLClassifierMetrics(v73, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined copy of MLImageClassifier.ModelParameters.ClassifierType?(v70);
  outlined assign with take of Any?((uint64_t)v105, (uint64_t)v132);
  uint64_t v75 = (uint64_t)v110;
  outlined init with copy of MLTrainingSessionParameters(v69, (uint64_t)v110, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  uint64_t v106 = v108;
  uint64_t v76 = __swift_allocate_boxed_opaque_existential_1(v105);
  outlined init with take of MLClassifierMetrics(v75, (uint64_t)v76, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  outlined assign with take of Any?((uint64_t)v105, (uint64_t)v129);
  uint64_t v77 = v69;
  uint64_t v78 = v134;
  outlined destroy of MLActivityClassifier.ModelParameters(v77, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v128, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined init with copy of MLImageClassifier.ModelParameters(v78, (uint64_t)v105);
  uint64_t v79 = (uint64_t)v131;
  MLImageClassifier.Classifier.init(labels:parameters:)((uint64_t)&_swiftEmptySetSingleton, v105);
  uint64_t v80 = lazy protocol witness table accessor for type MLImageClassifier.Classifier and conformance MLImageClassifier.Classifier();
  uint64_t v81 = (uint64_t)v130;
  uint64_t v82 = v136;
  uint64_t v83 = v136;
  uint64_t v84 = v139;
  UpdatableSupervisedEstimator.readWithOptimizer(from:)(v136, v107, v80);
  uint64_t v139 = v84;
  if (v84)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(v138, type metadata accessor for MLCheckpoint);
LABEL_18:
    outlined destroy of MLActivityClassifier.ModelParameters(v79, type metadata accessor for MLImageClassifier.Classifier);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v127, type metadata accessor for MLImageClassifier.PersistentParameters);
    uint64_t v97 = v82;
    uint64_t v98 = v126;
    uint64_t v99 = v135;
    v135((uint64_t)v97, v126);
    v99((uint64_t)v140, v98);
    outlined destroy of MLImageClassifier.ModelParameters(v78);
    uint64_t v59 = v124;
    uint64_t v60 = v125;
    goto LABEL_19;
  }
  uint64_t v85 = v118;
  MLImageClassifier.ModelParameters.algorithm.getter(v83);
  swift_bridgeObjectRelease(*(void *)((char *)v85 + *(int *)(v121 + 48)));
  uint64_t v86 = (uint64_t)v85;
  uint64_t v87 = (uint64_t)v133;
  outlined init with take of MLClassifierMetrics(v86, (uint64_t)v133, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v88 = v81;
  uint64_t v89 = (uint64_t)v116;
  outlined init with copy of MLTrainingSessionParameters(v88, (uint64_t)v116, type metadata accessor for MLImageClassifier.Model);
  outlined init with copy of MLTrainingSessionParameters(v87, (uint64_t)v123, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v90 = *(unsigned __int8 *)(v117 + 80);
  uint64_t v91 = ~*(unsigned __int8 *)(v117 + 80) & (v90 + 16);
  uint64_t v92 = *(unsigned __int8 *)(v115 + 80);
  int64_t v93 = ~v92 & (v91 + v92 + v114);
  uint64_t v94 = swift_allocObject(&unk_39D5A8, v93 + v113, v92 | v90 | 7);
  outlined init with take of MLClassifierMetrics(v89, v94 + v91, type metadata accessor for MLImageClassifier.Model);
  outlined init with take of MLClassifierMetrics((uint64_t)v123, v94 + v93, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v95 = v139;
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLImageClassifier.init(checkpoint:), v94);
  if (v95)
  {
    uint64_t v139 = v95;
    swift_release();
    outlined destroy of MLActivityClassifier.ModelParameters(v138, type metadata accessor for MLCheckpoint);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v133, type metadata accessor for MLImageClassifier.FeatureExtractorType);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v130, type metadata accessor for MLImageClassifier.Model);
    uint64_t v79 = (uint64_t)v131;
    uint64_t v82 = v136;
    uint64_t v78 = v134;
    goto LABEL_18;
  }
  uint64_t v101 = v96;
  swift_release();
  outlined destroy of MLActivityClassifier.ModelParameters(v138, type metadata accessor for MLCheckpoint);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v133, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v131, type metadata accessor for MLImageClassifier.Classifier);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v127, type metadata accessor for MLImageClassifier.PersistentParameters);
  uint64_t v102 = v126;
  unint64_t v103 = v135;
  v135((uint64_t)v136, v126);
  v103((uint64_t)v140, v102);
  uint64_t v104 = v122;
  *(void *)uint64_t v122 = v101;
  return outlined init with take of MLClassifierMetrics((uint64_t)v130, v104 + *(int *)(v119 + 32), type metadata accessor for MLImageClassifier.Model);
}

uint64_t lazy protocol witness table accessor for type MLImageClassifier.Classifier and conformance MLImageClassifier.Classifier()
{
  uint64_t result = lazy protocol witness table cache variable for type MLImageClassifier.Classifier and conformance MLImageClassifier.Classifier;
  if (!lazy protocol witness table cache variable for type MLImageClassifier.Classifier and conformance MLImageClassifier.Classifier)
  {
    uint64_t v1 = type metadata accessor for MLImageClassifier.Classifier(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLImageClassifier.Classifier, v1);
    lazy protocol witness table cache variable for type MLImageClassifier.Classifier and conformance MLImageClassifier.Classifier = result;
  }
  return result;
}

uint64_t closure #1 in MLImageClassifier.init(checkpoint:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)(v3 + 16) = a1;
  uint64_t v5 = (void *)swift_task_alloc(dword_3A801C);
  *(void *)(v3 + 24) = v5;
  *uint64_t v5 = v3;
  v5[1] = closure #1 in MLRandomForestRegressor.init(checkpoint:);
  return MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:)(a3);
}

uint64_t sub_2CE009()
{
  uint64_t v1 = *(void *)(type metadata accessor for MLImageClassifier.Model(0) - 8);
  uint64_t v2 = *(unsigned __int8 *)(v1 + 80);
  uint64_t v3 = ~*(unsigned __int8 *)(v1 + 80) & (v2 + 16);
  uint64_t v4 = v3 + *(void *)(v1 + 64);
  uint64_t v5 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  uint64_t v6 = *(void *)(v5 - 8);
  uint64_t v15 = *(unsigned __int8 *)(v6 + 80);
  uint64_t v7 = ~v15 & (v15 + v4);
  uint64_t v16 = *(void *)(v6 + 64);
  uint64_t v8 = v0 + v3;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  uint64_t v10 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (swift_getEnumCaseMultiPayload(v8, v9) == 1) {
    uint64_t v10 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(v10);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v11 - 8) + 8))(v8, v11);
  if (swift_getEnumCaseMultiPayload(v7 + v0, v5) == 1)
  {
    uint64_t v12 = type metadata accessor for URL(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v12 - 8) + 8))(v7 + v0, v12);
    uint64_t v13 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
    swift_bridgeObjectRelease(*(void *)(v7 + v0 + *(int *)(v13 + 20) + 8));
  }
  return swift_deallocObject(v0, v16 + v7, v15 | v2 | 7);
}

uint64_t partial apply for closure #1 in MLImageClassifier.init(checkpoint:)(uint64_t a1)
{
  uint64_t v3 = *(void *)(type metadata accessor for MLImageClassifier.Model(0) - 8);
  uint64_t v4 = ~*(unsigned __int8 *)(v3 + 80) & (*(unsigned __int8 *)(v3 + 80) + 16);
  uint64_t v5 = v4 + *(void *)(v3 + 64);
  uint64_t v6 = *(unsigned __int8 *)(*(void *)(type metadata accessor for MLImageClassifier.FeatureExtractorType(0) - 8)
                          + 80);
  uint64_t v7 = (void *)swift_task_alloc(dword_3AEB7C);
  *(void *)(v2 + 16) = v7;
  *uint64_t v7 = v2;
  v7[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLImageClassifier.init(checkpoint:)(a1, v1 + v4, v1 + ((v6 + v5) & ~v6));
}

void *static MLImageClassifier.train(trainingData:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t result = (void *)static MLImageClassifier.makeTrainingSession(trainingData:parameters:sessionParameters:)(a1, a2, a3);
  if (!v3)
  {
    uint64_t v5 = (uint64_t)result;
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLImageClassifier>);
    uint64_t v7 = (void *)swift_allocObject(v6, *(unsigned int *)(v6 + 48), *(unsigned __int16 *)(v6 + 52));
    return specialized MLJob.init(_:)(v7, v5);
  }
  return result;
}

uint64_t static MLImageClassifier.makeTrainingSession(trainingData:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v17 = a3;
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v16 = v15;
  uint64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  uint64_t result = static _ImageUtilities.getImageURLsAndLabels(from:)(a1);
  if (!v3)
  {
    uint64_t v10 = result;
    outlined init with copy of MLImageClassifier.ModelParameters(a2, (uint64_t)v15);
    outlined init with copy of MLTrainingSessionParameters(v17, (uint64_t)v15, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v11 = type metadata accessor for ImageClassifierTrainingSessionDelegate(0);
    swift_allocObject(v11, *(unsigned int *)(v11 + 48), *(unsigned __int16 *)(v11 + 52));
    uint64_t v12 = ImageClassifierTrainingSessionDelegate.init(filesByLabel:modelParameters:sessionParameters:)(v10, (uint64_t)v15, (uint64_t)v15);
    v15[3] = v11;
    v15[4] = &protocol witness table for ImageClassifierTrainingSessionDelegate;
    v15[0] = v12;
    uint64_t v13 = (uint64_t)v16;
    outlined init with copy of MLTrainingSessionParameters(v17, (uint64_t)v16, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>);
    swift_allocObject(v14, *(unsigned int *)(v14 + 48), *(unsigned __int16 *)(v14 + 52));
    return specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)v15, v13, 12);
  }
  return result;
}

void *static MLImageClassifier.resume(_:)(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLImageClassifier>);
  uint64_t v2 = (void *)swift_allocObject(v1, *(unsigned int *)(v1 + 48), *(unsigned __int16 *)(v1 + 52));
  swift_retain();
  return specialized MLJob.init(_:)(v2, a1);
}

uint64_t static MLImageClassifier.restoreTrainingSession(sessionParameters:)(uint64_t a1)
{
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  uint64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  uint64_t v12 = v11;
  uint64_t v5 = alloca(v2);
  uint64_t v6 = alloca(v2);
  outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v11, type metadata accessor for MLTrainingSessionParameters);
  uint64_t v7 = type metadata accessor for ImageClassifierTrainingSessionDelegate(0);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  uint64_t result = ImageClassifierTrainingSessionDelegate.init(sessionParameters:)((uint64_t)v11);
  if (!v1)
  {
    v11[3] = v7;
    v11[4] = &protocol witness table for ImageClassifierTrainingSessionDelegate;
    v11[0] = result;
    uint64_t v9 = (uint64_t)v12;
    outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v12, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>);
    swift_allocObject(v10, *(unsigned int *)(v10 + 48), *(unsigned __int16 *)(v10 + 52));
    return specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)v11, v9, 12);
  }
  return result;
}

uint64_t closure #1 in closure #1 in static MLImageClassifier.resume(_:)(uint64_t a1, char a2, uint64_t a3, void (*a4)(uint64_t *), uint64_t a5)
{
  uint64_t v22 = a5;
  char v23 = a4;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLImageClassifier, Error>);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TaskPriority?)
                              - 8)
                  + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  if (a2)
  {
    uint64_t v19 = a1;
    swift_storeEnumTagMultiPayload(&v19, v6, 1);
    swift_errorRetain(a1);
    v23(&v19);
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v19, &demangling cache variable for type metadata for Result<MLImageClassifier, Error>);
  }
  else
  {
    outlined init with copy of TabularRegressionTask(direct field offset for MLTrainingSession.delegate + a3, (uint64_t)v20);
    uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingSessionDelegate);
    uint64_t v14 = type metadata accessor for ImageClassifierTrainingSessionDelegate(0);
    swift_dynamicCast(&v21, v20, v13, v14, 7);
    uint64_t v15 = v21;
    uint64_t v16 = type metadata accessor for TaskPriority(0);
    __swift_storeEnumTagSinglePayload((uint64_t)&v19, 1, 1, v16);
    uint64_t v17 = swift_allocObject(&unk_39D5D0, 56, 7);
    *(_OWORD *)(v17 + 16) = 0;
    *(void *)(v17 + 32) = v15;
    *(void *)(v17 + 40) = v23;
    *(void *)(v17 + 48) = v22;
    swift_retain();
    _sScTss5NeverORs_rlE8priority9operationScTyxABGScPSg_xyYaYAcntcfCyt_Tgm5((uint64_t)&v19, (uint64_t)&async function pointer to partial apply for closure #1 in closure #1 in closure #1 in static MLImageClassifier.resume(_:), v17);
    return swift_release();
  }
}

uint64_t closure #1 in closure #1 in closure #1 in static MLImageClassifier.resume(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  void v6[4] = a6;
  v6[3] = a5;
  _OWORD v6[2] = a4;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLImageClassifier, Error>);
  v6[5] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(closure #1 in closure #1 in closure #1 in static MLImageClassifier.resume(_:), 0, 0);
}

uint64_t closure #1 in closure #1 in closure #1 in static MLImageClassifier.resume(_:)()
{
  uint64_t v1 = (char *)&async function pointer to specialized Result<>.init(catching:)
     + async function pointer to specialized Result<>.init(catching:);
  uint64_t v2 = dword_3AE62C;
  swift_retain();
  uint64_t v3 = (void *)swift_task_alloc(v2);
  v0[6] = v3;
  void *v3 = v0;
  v3[1] = closure #1 in closure #1 in closure #1 in static MLImageClassifier.resume(_:);
  return ((uint64_t (*)(void, void))v1)(v0[5], v0[2]);
}

{
  uint64_t v0;

  swift_task_dealloc(*(void *)(*(void *)v0 + 48));
  return swift_task_switch(closure #1 in closure #1 in closure #1 in static MLImageClassifier.resume(_:), 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;

  uint64_t v1 = *(void *)(v0 + 40);
  (*(void (**)(uint64_t))(v0 + 24))(v1);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, &demangling cache variable for type metadata for Result<MLImageClassifier, Error>);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t sub_2CE782()
{
  swift_unknownObjectRelease(v0[2]);
  swift_release(v0[4]);
  swift_release(v0[6]);
  return swift_deallocObject(v0, 56, 7);
}

uint64_t partial apply for closure #1 in closure #1 in closure #1 in static MLImageClassifier.resume(_:)(uint64_t a1)
{
  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v5 = v1[6];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AEB9C);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for specialized closure #1 in blockAwait<A>(_:);
  return closure #1 in closure #1 in closure #1 in static MLImageClassifier.resume(_:)(a1, v3, v4, v8, v9, v5);
}

uint64_t _sxIeAgHr_xs5Error_pIegHrzo_s8SendableRzs5NeverORs_r0_lTRyt_Tg5(uint64_t a1, int *a2)
{
  uint64_t v3 = (uint64_t (*)(uint64_t))((char *)a2 + *a2);
  uint64_t v4 = (void *)swift_task_alloc(a2[1]);
  *(void *)(v2 + 16) = v4;
  *uint64_t v4 = v2;
  v4[1] = _sxIeAgHr_xs5Error_pIegHrzo_s8SendableRzs5NeverORs_r0_lTRyt_Tg5TQ0_;
  return v3(a1);
}

uint64_t _sxIeAgHr_xs5Error_pIegHrzo_s8SendableRzs5NeverORs_r0_lTRyt_Tg5TQ0_()
{
  uint64_t v2 = *v0;
  swift_task_dealloc(*(void *)(*v0 + 16));
  return (*(uint64_t (**)(void))(v2 + 8))();
}

uint64_t sub_2CE8E6()
{
  swift_release(*(void *)(v0 + 24));
  return swift_deallocObject(v0, 32, 7);
}

uint64_t _sxIeAgHr_xs5Error_pIegHrzo_s8SendableRzs5NeverORs_r0_lTRyt_Tg5TA(uint64_t a1)
{
  uint64_t v3 = *(void *)(v1 + 16);
  uint64_t v4 = *(void *)(v1 + 24);
  uint64_t v5 = (void *)swift_task_alloc(dword_3AEBAC);
  *(void *)(v2 + 16) = v5;
  *uint64_t v5 = v2;
  v5[1] = partial apply for closure #1 in closure #1 in closure #1 in closure #1 in static MLObjectDetector.resume(_:);
  return ((uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)&_sxIeAgHr_xs5Error_pIegHrzo_s8SendableRzs5NeverORs_r0_lTRyt_Tg5Tu
                                                            + _sxIeAgHr_xs5Error_pIegHrzo_s8SendableRzs5NeverORs_r0_lTRyt_Tg5Tu))(a1, v3, v4);
}

uint64_t specialized SetAlgebra<>.init(arrayLiteral:)(uint64_t a1)
{
  return specialized SetAlgebra<>.init(arrayLiteral:)(a1);
}

{
  uint64_t *v1;
  uint64_t *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t result;

  uint64_t v2 = v1;
  uint64_t v3 = *(void *)(a1 + 16);
  if (v3)
  {
    uint64_t v4 = 0;
    uint64_t v5 = 0;
    uint64_t v6 = 0;
    do
    {
      uint64_t v7 = *(void *)(a1 + 8 * v4 + 32) & ~v6;
      if (v7) {
        uint64_t v7 = *(void *)(a1 + 8 * v4 + 32);
      }
      uint64_t v6 = v5 | v7;
      ++v4;
      uint64_t v5 = v6;
    }
    while (v3 != v4);
  }
  else
  {
    uint64_t v6 = 0;
  }
  uint64_t result = swift_bridgeObjectRelease(a1);
  *uint64_t v2 = v6;
  return result;
}

void *MLHandPoseClassifier.ImageAugmentationOptions.init(rawValue:)(uint64_t a1)
{
  *uint64_t result = a1;
  return result;
}

uint64_t *specialized OptionSet.union(_:)(uint64_t a1, uint64_t a2)
{
  *uint64_t result = a2 | a1;
  return result;
}

{
  return specialized OptionSet.union(_:)(a1, a2);
}

uint64_t *specialized OptionSet.symmetricDifference(_:)(uint64_t a1, uint64_t a2)
{
  *uint64_t result = a2 ^ a1;
  return result;
}

{
  return specialized OptionSet.symmetricDifference(_:)(a1, a2);
}

uint64_t specialized OptionSet<>.remove(_:)(uint64_t a1)
{
  return specialized OptionSet<>.remove(_:)(a1);
}

{
  uint64_t result;
  void *v2;
  uint64_t v3;

  uint64_t v3 = a1 & *v2;
  if (v3) {
    *v2 &= ~a1;
  }
  *(void *)uint64_t result = v3;
  *(unsigned char *)(result + 8) = v3 == 0;
  return result;
}

uint64_t specialized OptionSet<>.update(with:)(uint64_t a1)
{
  return specialized OptionSet<>.update(with:)(a1);
}

{
  uint64_t result;
  uint64_t *v2;
  uint64_t v3;
  uint64_t v4;

  uint64_t v3 = *v2;
  *v2 |= a1;
  uint64_t v4 = a1 & v3;
  *(void *)uint64_t result = v4;
  *(unsigned char *)(result + 8) = v4 == 0;
  return result;
}

void specialized OptionSet<>.formSymmetricDifference(_:)(uint64_t a1)
{
  *v1 ^= a1;
}

{
  specialized OptionSet<>.formSymmetricDifference(_:)(a1);
}

uint64_t *specialized SetAlgebra.subtracting(_:)(uint64_t a1, uint64_t a2)
{
  *uint64_t result = a2 & ~a1;
  return result;
}

{
  return specialized SetAlgebra.subtracting(_:)(a1, a2);
}

BOOL specialized SetAlgebra.isDisjoint(with:)(uint64_t a1, uint64_t a2)
{
  return (a1 & a2) == 0;
}

{
  return specialized SetAlgebra.isDisjoint(with:)(a1, a2);
}

BOOL specialized SetAlgebra.isEmpty.getter(uint64_t a1)
{
  return a1 == 0;
}

void specialized SetAlgebra.subtract(_:)(uint64_t a1)
{
  *v1 &= ~a1;
}

{
  specialized SetAlgebra.subtract(_:)(a1);
}

uint64_t MLHandPoseClassifier.ImageAugmentationOptions.rawValue.getter()
{
  return *(void *)v0;
}

void *static MLHandPoseClassifier.ImageAugmentationOptions.horizontallyFlip.getter()
{
  *uint64_t result = 1;
  return result;
}

void *static MLHandPoseClassifier.ImageAugmentationOptions.rotate.getter()
{
  *uint64_t result = 2;
  return result;
}

void *static MLHandPoseClassifier.ImageAugmentationOptions.translate.getter()
{
  *uint64_t result = 4;
  return result;
}

void *static MLHandPoseClassifier.ImageAugmentationOptions.scale.getter()
{
  *uint64_t result = 8;
  return result;
}

uint64_t base witness table accessor for RawRepresentable in MLHandPoseClassifier.ImageAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions();
}

uint64_t lazy protocol witness table accessor for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions()
{
  uint64_t result = lazy protocol witness table cache variable for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLHandPoseClassifier.ImageAugmentationOptions, &type metadata for MLHandPoseClassifier.ImageAugmentationOptions);
    lazy protocol witness table cache variable for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLHandPoseClassifier.ImageAugmentationOptions, &type metadata for MLHandPoseClassifier.ImageAugmentationOptions);
    lazy protocol witness table cache variable for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLHandPoseClassifier.ImageAugmentationOptions, &type metadata for MLHandPoseClassifier.ImageAugmentationOptions);
    lazy protocol witness table cache variable for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLHandPoseClassifier.ImageAugmentationOptions, &type metadata for MLHandPoseClassifier.ImageAugmentationOptions);
    lazy protocol witness table cache variable for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions = result;
  }
  return result;
}

uint64_t base witness table accessor for SetAlgebra in MLHandPoseClassifier.ImageAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions();
}

void *protocol witness for OptionSet.init(rawValue:) in conformance MLHandPoseClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return MLHandPoseClassifier.ImageAugmentationOptions.init(rawValue:)(*a1);
}

uint64_t protocol witness for Decodable.init(from:) in conformance MLHandPoseClassifier.ImageAugmentationOptions(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = lazy protocol witness table accessor for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions();
  return RawRepresentable<>.init(from:)(a1, a2, a3, v3);
}

uint64_t protocol witness for Encodable.encode(to:) in conformance MLHandPoseClassifier.ImageAugmentationOptions(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = lazy protocol witness table accessor for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions();
  return RawRepresentable<>.encode(to:)(a1, a2, a3, v4);
}

uint64_t base witness table accessor for Equatable in MLHandPoseClassifier.ImageAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions();
}

uint64_t base witness table accessor for ExpressibleByArrayLiteral in MLHandPoseClassifier.ImageAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLHandPoseClassifier.ImageAugmentationOptions and conformance MLHandPoseClassifier.ImageAugmentationOptions();
}

uint64_t protocol witness for SetAlgebra.remove(_:) in conformance MLHandPoseClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet<>.remove(_:)(*a1);
}

uint64_t protocol witness for SetAlgebra.update(with:) in conformance MLHandPoseClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet<>.update(with:)(*a1);
}

void *protocol witness for RawRepresentable.init(rawValue:) in conformance MLHandPoseClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  uint64_t v2 = v1;
  uint64_t result = MLHandPoseClassifier.ImageAugmentationOptions.init(rawValue:)(*a1);
  *(unsigned char *)(v2 + 8) = 0;
  return result;
}

uint64_t protocol witness for RawRepresentable.rawValue.getter in conformance MLHandPoseClassifier.ImageAugmentationOptions(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t result = MLHandPoseClassifier.ImageAugmentationOptions.rawValue.getter(a1);
  *uint64_t v2 = result;
  return result;
}

uint64_t protocol witness for ExpressibleByArrayLiteral.init(arrayLiteral:) in conformance MLHandPoseClassifier.ImageAugmentationOptions(uint64_t a1)
{
  return specialized SetAlgebra<>.init(arrayLiteral:)(a1);
}

ValueMetadata *type metadata accessor for MLHandPoseClassifier.ImageAugmentationOptions()
{
  return &type metadata for MLHandPoseClassifier.ImageAugmentationOptions;
}

char MLUntypedColumn.subscript.getter(uint64_t a1, double a2)
{
  uint64_t v4 = v2;
  if (*(unsigned char *)(v3 + 8))
  {
    long long v5 = 0;
    char result = 6;
  }
  else
  {
    uint64_t v7 = *(void *)v3;
    swift_retain();
    _UntypedColumn.valueAtIndex(index:)(a1, a2);
    outlined consume of Result<_DataTable, Error>(v7, 0);
    long long v5 = v8;
    char result = v9;
  }
  *(_OWORD *)uint64_t v4 = v5;
  *(unsigned char *)(v4 + 16) = result;
  return result;
}

uint64_t MLUntypedColumn.count.getter()
{
  if (*(unsigned char *)(v0 + 8)) {
    return -1;
  }
  uint64_t v2 = *(void *)v0;
  swift_retain();
  uint64_t v3 = CMLColumn.size.getter();
  outlined consume of Result<_DataTable, Error>(v2, 0);
  return v3;
}

uint64_t MLUntypedColumn.dropDuplicates()()
{
  uint64_t v2 = v0;
  uint64_t v3 = *(void *)v1;
  if (*(unsigned char *)(v1 + 8))
  {
    v17[0] = *(void *)v1;
    outlined copy of Result<_DataTable, Error>(v3, 1);
    swift_errorRetain(v3);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v5 = _getErrorEmbeddedNSError<A>(_:)(v17, v4, &protocol self-conformance witness table for Error);
    if (v5)
    {
      uint64_t v6 = v5;
      outlined consume of Result<_DataTable, Error>(v3, 1);
    }
    else
    {
      uint64_t v6 = swift_allocError(v4, &protocol self-conformance witness table for Error, 0, 0);
      uint64_t *v9 = v17[0];
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 1);
    char v11 = 1;
  }
  else
  {
    uint64_t v7 = *(void *)(*(void *)(v3 + 16) + 16);
    swift_retain();
    uint64_t v8 = specialized handling<A, B>(_:_:)(v7);
    uint64_t v12 = v8;
    if (!v8) {
      BUG();
    }
    char v11 = 0;
    uint64_t v13 = type metadata accessor for CMLColumn();
    uint64_t v14 = swift_allocObject(v13, 24, 7);
    *(void *)(v14 + 16) = v12;
    uint64_t v15 = v14;
    uint64_t v16 = type metadata accessor for _UntypedColumn();
    uint64_t v6 = swift_allocObject(v16, 24, 7);
    *(void *)(v6 + 16) = v15;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 0);
  }
  *(void *)uint64_t v2 = v6;
  *(unsigned char *)(v2 + 8) = v11;
  return result;
}

uint64_t MLUntypedColumn.init<A>(_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for closure #1 in MLUntypedColumn.init<A>(_:));
  char v6 = v5;
  uint64_t result = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(a2 - 8) + 8))(a1, a2);
  *(void *)uint64_t v3 = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(v3 + 8) = v6 & 1;
  return result;
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5;
  char v5;
  char v6;
  uint64_t result;

  uint64_t v3 = v2;
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for closure #1 in MLUntypedColumn.init<A>(_:));
  char v6 = v5;
  uint64_t result = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(a2 - 8) + 8))(a1, a2);
  *(void *)uint64_t v3 = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(v3 + 8) = v6 & 1;
  return result;
}

uint64_t _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5(void (*a1)(void *))
{
  a1(v3);
  return v2;
}

uint64_t _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML20MLHandPoseClassifierV_s5Error_pTgm5(void (*a1)(uint64_t *), uint64_t a2)
{
  return _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML20MLHandPoseClassifierV_s5Error_pTgm5Tm(a1, a2, &demangling cache variable for type metadata for Result<MLHandPoseClassifier, Error>);
}

uint64_t _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML22MLHandActionClassifierV_s5Error_pTgm5(void (*a1)(uint64_t *), uint64_t a2)
{
  return _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML20MLHandPoseClassifierV_s5Error_pTgm5Tm(a1, a2, &demangling cache variable for type metadata for Result<MLHandActionClassifier, Error>);
}

uint64_t _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML20MLHandPoseClassifierV_s5Error_pTgm5Tm(void (*a1)(uint64_t *), uint64_t a2, uint64_t *a3)
{
  uint64_t v12 = v3;
  char v11 = a3;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(a3);
  int64_t v5 = *(void *)(*(void *)(v4 - 8) + 64);
  char v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  a1(&v10);
  swift_storeEnumTagMultiPayload(v9, v4, 0);
  return outlined init with take of DataFrame?((uint64_t)v9, v12, v11);
}

char MLUntypedColumn.type.getter()
{
  char v5 = HIBYTE(v0);
  uint64_t v2 = v0;
  char result = 6;
  if (!*(unsigned char *)(v1 + 8))
  {
    uint64_t v4 = *(void *)v1;
    swift_retain();
    _UntypedColumn.type.getter();
    outlined consume of Result<_DataTable, Error>(v4, 0);
    char result = v5;
  }
  *uint64_t v2 = result;
  return result;
}

uint64_t MLUntypedColumn.map<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MLUntypedColumn.map<A>(_:)(a1, a2, a3, a4, 1);
}

{
  void *v6;

  char v6 = (void *)swift_allocObject(&unk_39D648, 48, 7);
  _OWORD v6[2] = a3;
  v6[3] = a4;
  void v6[4] = a1;
  v6[5] = a2;
  swift_retain();
  MLUntypedColumn.map<A>(skipUndefined:_:)(1, (uint64_t)partial apply for thunk for @escaping @callee_guaranteed (@in_guaranteed MLDataValue) -> (@out A), (uint64_t)v6, a3, a4);
  return swift_release();
}

uint64_t MLUntypedColumn.ints.getter()
{
  char v4 = HIBYTE(result);
  uint64_t v2 = result;
  if (*(unsigned char *)(v1 + 8)
    || (uint64_t v3 = *(void *)v1,
        outlined copy of Result<_DataTable, Error>(v3, 0),
        _UntypedColumn.type.getter(),
        uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 0),
        v4))
  {
    *(void *)uint64_t v2 = 0;
    *(unsigned char *)(v2 + 8) = -1;
  }
  else
  {
    *(void *)uint64_t v2 = v3;
    *(unsigned char *)(v2 + 8) = 0;
    return outlined copy of Result<_DataTable, Error>(v3, 0);
  }
  return result;
}

uint64_t static MLUntypedColumn.== infix(_:_:)(uint64_t a1, void *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 4);
}

uint64_t MLUntypedColumn.strings.getter()
{
  char v4 = HIBYTE(result);
  uint64_t v2 = result;
  if (*(unsigned char *)(v1 + 8)
    || (uint64_t v3 = *(void *)v1,
        outlined copy of Result<_DataTable, Error>(v3, 0),
        _UntypedColumn.type.getter(),
        uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 0),
        v4 != 2))
  {
    *(void *)uint64_t v2 = 0;
    *(unsigned char *)(v2 + 8) = -1;
  }
  else
  {
    *(void *)uint64_t v2 = v3;
    *(unsigned char *)(v2 + 8) = 0;
    return outlined copy of Result<_DataTable, Error>(v3, 0);
  }
  return result;
}

uint64_t static MLUntypedColumn.== infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, (uint64_t)"==");
}

uint64_t static MLUntypedColumn.!= infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, (uint64_t)"!=");
}

uint64_t static MLUntypedColumn.== infix(_:_:)(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v4 = v3;
  uint64_t v5 = *a1;
  if (*((unsigned char *)a1 + 8))
  {
    uint64_t result = swift_errorRetain(*a1);
    char v7 = 1;
  }
  else
  {
    uint64_t v8 = *a2;
    if (*((unsigned char *)a2 + 8))
    {
      uint64_t result = swift_errorRetain(*a2);
      char v7 = 1;
      uint64_t v5 = v8;
    }
    else
    {
      uint64_t v10 = *(void *)(*(void *)(v5 + 16) + 16);
      uint64_t v16 = *(void *)(*(void *)(v8 + 16) + 16);
      outlined copy of Result<_DataTable, Error>(v8, 0);
      outlined copy of Result<_DataTable, Error>(v5, 0);
      uint64_t v17 = specialized handling<A, B, C, D>(_:_:_:_:)(v10, a3, v16);
      if (!v17) {
        BUG();
      }
      char v7 = 0;
      uint64_t v11 = type metadata accessor for CMLColumn();
      uint64_t v12 = swift_allocObject(v11, 24, 7);
      *(void *)(v12 + 16) = v17;
      uint64_t v13 = type metadata accessor for _UntypedColumn();
      uint64_t v14 = swift_allocObject(v13, 24, 7);
      *(void *)(v14 + 16) = v12;
      uint64_t v15 = v14;
      outlined consume of Result<_DataTable, Error>(v8, 0);
      uint64_t result = outlined consume of Result<_DataTable, Error>(v5, 0);
      uint64_t v5 = v15;
    }
  }
  *(void *)uint64_t v4 = v5;
  *(unsigned char *)(v4 + 8) = v7;
  return result;
}

uint64_t static MLUntypedColumn.> infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, (uint64_t)">");
}

uint64_t static MLUntypedColumn.< infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, (uint64_t)"<");
}

uint64_t static MLUntypedColumn.>= infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, (uint64_t)">=");
}

uint64_t static MLUntypedColumn.<= infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, (uint64_t)"<=");
}

uint64_t static MLUntypedColumn.!= infix(_:_:)(uint64_t a1, void *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 5);
}

uint64_t static MLUntypedColumn.== infix(_:_:)(uint64_t a1, void *a2, int a3)
{
  uint64_t v4 = v3;
  uint64_t v5 = *(void *)a1;
  if (*(unsigned char *)(a1 + 8))
  {
    double v19 = *(double *)a1;
    outlined copy of Result<_DataTable, Error>(v5, 1);
    swift_errorRetain(v5);
    uint64_t v6 = v5;
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v8 = _getErrorEmbeddedNSError<A>(_:)(&v19, v7, &protocol self-conformance witness table for Error);
    if (v8)
    {
      uint64_t v9 = v8;
      outlined consume of Result<_DataTable, Error>(v6, 1);
    }
    else
    {
      uint64_t v9 = swift_allocError(v7, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v14 = v19;
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v6, 1);
    char v15 = 1;
  }
  else
  {
    uint64_t v23 = v3;
    LODWORD(v26) = a3;
    uint64_t v22 = type metadata accessor for _UntypedColumn();
    uint64_t v10 = a2[3];
    uint64_t v11 = a2[4];
    __swift_project_boxed_opaque_existential_0Tm(a2, v10);
    char v25 = *(void (**)(uint64_t, uint64_t))(v11 + 32);
    swift_retain();
    v25(v10, v11);
    double v12 = v19;
    char v25 = v20;
    int v24 = v21;
    v17[0] = v19;
    *(void *)&v17[1] = v20;
    char v18 = v21;
    char v13 = v26;
    uint64_t v26 = v5;
    uint64_t v9 = static _UntypedColumn.performRightScalar(op:a:b:)(v13, v5, v17);
    outlined consume of MLDataValue(*(void **)&v12, v25, v24);
    char v15 = 0;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v26, 0);
    uint64_t v4 = v23;
  }
  *(void *)uint64_t v4 = v9;
  *(unsigned char *)(v4 + 8) = v15;
  return result;
}

uint64_t static MLUntypedColumn.> infix(_:_:)(uint64_t a1, void *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 7);
}

uint64_t static MLUntypedColumn.< infix(_:_:)(uint64_t a1, void *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 6);
}

uint64_t static MLUntypedColumn.>= infix(_:_:)(uint64_t a1, void *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 9);
}

uint64_t static MLUntypedColumn.<= infix(_:_:)(uint64_t a1, void *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 8);
}

uint64_t static MLUntypedColumn.== infix(_:_:)(void *a1, uint64_t a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 4);
}

uint64_t static MLUntypedColumn.!= infix(_:_:)(void *a1, uint64_t a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 5);
}

uint64_t static MLUntypedColumn.== infix(_:_:)(void *a1, uint64_t a2, int a3)
{
  uint64_t v4 = v3;
  uint64_t v5 = *(void *)a2;
  if (*(unsigned char *)(a2 + 8))
  {
    double v19 = *(double *)a2;
    outlined copy of Result<_DataTable, Error>(v5, 1);
    swift_errorRetain(v5);
    uint64_t v6 = v5;
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v8 = _getErrorEmbeddedNSError<A>(_:)(&v19, v7, &protocol self-conformance witness table for Error);
    if (v8)
    {
      uint64_t v9 = v8;
      outlined consume of Result<_DataTable, Error>(v6, 1);
    }
    else
    {
      uint64_t v9 = swift_allocError(v7, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v14 = v19;
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v6, 1);
    char v15 = 1;
  }
  else
  {
    uint64_t v23 = v3;
    LODWORD(v26) = a3;
    uint64_t v22 = type metadata accessor for _UntypedColumn();
    uint64_t v10 = a1[3];
    uint64_t v11 = a1[4];
    __swift_project_boxed_opaque_existential_0Tm(a1, v10);
    char v25 = *(void (**)(uint64_t, uint64_t))(v11 + 32);
    swift_retain();
    v25(v10, v11);
    double v12 = v19;
    char v25 = v20;
    int v24 = v21;
    v17[0] = v19;
    *(void *)&v17[1] = v20;
    char v18 = v21;
    char v13 = v26;
    uint64_t v26 = v5;
    uint64_t v9 = static _UntypedColumn.performLeftScalar(op:a:b:)(v13, v17, v5);
    outlined consume of MLDataValue(*(void **)&v12, v25, v24);
    char v15 = 0;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v26, 0);
    uint64_t v4 = v23;
  }
  *(void *)uint64_t v4 = v9;
  *(unsigned char *)(v4 + 8) = v15;
  return result;
}

uint64_t static MLUntypedColumn.> infix(_:_:)(void *a1, uint64_t a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 7);
}

uint64_t static MLUntypedColumn.< infix(_:_:)(void *a1, uint64_t a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 6);
}

uint64_t static MLUntypedColumn.>= infix(_:_:)(void *a1, uint64_t a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 9);
}

uint64_t static MLUntypedColumn.<= infix(_:_:)(void *a1, uint64_t a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 8);
}

uint64_t static MLUntypedColumn.+ infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, (uint64_t)"+");
}

uint64_t static MLUntypedColumn.- infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, (uint64_t)"-");
}

uint64_t static MLUntypedColumn.* infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, (uint64_t)"*");
}

uint64_t static MLUntypedColumn./ infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, (uint64_t)"/");
}

uint64_t MLUntypedColumn.map<A>(to:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v71 = a3;
  v66[2] = v3;
  uint64_t v72 = a2;
  uint64_t v6 = type metadata accessor for Optional(0, a2);
  uint64_t v7 = *(void *)(v6 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v67 = v66;
  *(void *)&long long v73 = *(void *)v4;
  char v76 = *(unsigned char *)(v4 + 8);
  *(void *)&v74[0] = 0;
  *((void *)&v74[0] + 1) = 0xE000000000000000;
  _StringGuts.grow(_:)(25);
  swift_bridgeObjectRelease(BYTE8(v74[0]));
  *(void *)&v74[0] = 0xD000000000000016;
  *((void *)&v74[0] + 1) = "==" + 0x8000000000000000;
  v11._uint64_t countAndFlagsBits = _typeName(_:qualified:)(a1, 0);
  char object = (char)v11._object;
  String.append(_:)(v11);
  swift_bridgeObjectRelease(object);
  v13._uint64_t countAndFlagsBits = 46;
  v13._char object = (void *)0xE100000000000000;
  String.append(_:)(v13);
  long long v70 = v74[0];
  uint64_t v14 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v15 = swift_allocError(&type metadata for MLCreateError, v14, 0, 0);
  *(_OWORD *)uint64_t v16 = v70;
  *(_OWORD *)(v16 + 16) = 0;
  *(_OWORD *)(v16 + 32) = 0;
  *(unsigned char *)(v16 + 48) = 1;
  if (swift_dynamicCastMetatype(a1, &type metadata for Int))
  {
    if (v76)
    {
      uint64_t v17 = v73;
LABEL_4:
      *(void *)&v74[0] = v17;
      outlined copy of Result<_DataTable, Error>(v17, 1);
      swift_errorRetain(v17);
      uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
      uint64_t v19 = _getErrorEmbeddedNSError<A>(_:)(v74, v18, &protocol self-conformance witness table for Error);
      if (v19)
      {
        uint64_t v20 = v19;
        outlined consume of Result<_DataTable, Error>(v17, 1);
      }
      else
      {
        uint64_t v20 = swift_allocError(v18, &protocol self-conformance witness table for Error, 0, 0);
        *int64_t v29 = *(void *)&v74[0];
      }
      char v77 = 1;
      uint64_t v30 = v15;
LABEL_28:
      swift_errorRelease(v30);
      outlined consume of Result<_DataTable, Error>(v17, 1);
      char v41 = v77;
      goto LABEL_34;
    }
    uint64_t v17 = v73;
    uint64_t v25 = *(void *)(*(void *)(v73 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(v73, 0);
    uint64_t v26 = specialized handling<A, B, C, D>(_:_:_:_:)(v25, 0, 0);
    uint64_t v33 = v26;
    uint64_t v75 = v15;
    if (!v26) {
      BUG();
    }
    goto LABEL_32;
  }
  uint64_t v75 = v15;
  char v21 = v76;
  uint64_t v68 = v6;
  *(void *)&long long v70 = v7;
  if (swift_dynamicCastMetatype(a1, &type metadata for Double))
  {
    uint64_t v17 = v73;
    if (v21)
    {
      *(void *)&v74[0] = v73;
      outlined copy of Result<_DataTable, Error>(v73, 1);
      swift_errorRetain(v17);
      uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
      uint64_t v23 = _getErrorEmbeddedNSError<A>(_:)(v74, v22, &protocol self-conformance witness table for Error);
      uint64_t v24 = v75;
      if (v23)
      {
        uint64_t v20 = v23;
        outlined consume of Result<_DataTable, Error>(v17, 1);
      }
      else
      {
        uint64_t v20 = swift_allocError(v22, &protocol self-conformance witness table for Error, 0, 0);
        void *v40 = *(void *)&v74[0];
      }
      char v77 = 1;
      uint64_t v30 = v24;
      goto LABEL_28;
    }
    uint64_t v31 = *(void *)(*(void *)(v73 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(v73, 0);
    uint64_t v32 = specialized handling<A, B, C, D>(_:_:_:_:)(v31, 1, 0);
    uint64_t v33 = v32;
    if (!v32) {
      BUG();
    }
LABEL_32:
    char v41 = 0;
    uint64_t v43 = type metadata accessor for CMLColumn();
    uint64_t v44 = swift_allocObject(v43, 24, 7);
    *(void *)(v44 + 16) = v33;
    uint64_t v45 = type metadata accessor for _UntypedColumn();
    uint64_t v20 = swift_allocObject(v45, 24, 7);
    *(void *)(v20 + 16) = v44;
    swift_errorRelease(v75);
    uint64_t v46 = v17;
LABEL_33:
    outlined consume of Result<_DataTable, Error>(v46, 0);
    goto LABEL_34;
  }
  uint64_t v27 = swift_dynamicCastMetatype(a1, &type metadata for String);
  uint64_t v17 = v73;
  char v28 = v21;
  if (v27)
  {
    uint64_t v15 = v75;
    if (v28) {
      goto LABEL_4;
    }
    uint64_t v42 = *(void *)(*(void *)(v73 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(v73, 0);
    uint64_t v33 = specialized handling<A, B, C, D>(_:_:_:_:)(v42, 2, 0);
    if (!v33) {
      BUG();
    }
    goto LABEL_32;
  }
  uint64_t v34 = swift_dynamicCastMetatype(a1, &type metadata for MLDataValue.SequenceType);
  uint64_t v15 = v75;
  if (!v34)
  {
    uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int]);
    if (!swift_dynamicCastMetatype(a1, v35))
    {
      uint64_t v36 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
      if (!swift_dynamicCastMetatype(a1, v36))
      {
        uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
        if (!swift_dynamicCastMetatype(a1, v37))
        {
          if (!swift_dynamicCastMetatype(a1, &type metadata for MLDataValue.DictionaryType))
          {
            char v41 = 1;
            uint64_t v20 = v15;
            goto LABEL_34;
          }
          if (v28) {
            goto LABEL_4;
          }
          uint64_t v65 = *(void *)(*(void *)(v17 + 16) + 16);
          outlined copy of Result<_DataTable, Error>(v17, 0);
          uint64_t v33 = specialized handling<A, B, C, D>(_:_:_:_:)(v65, 5, 0);
          if (!v33) {
            BUG();
          }
          goto LABEL_32;
        }
      }
    }
  }
  uint64_t v69 = v14;
  if ((v28 & 1) == 0)
  {
    uint64_t v48 = *(void *)(*(void *)(v17 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(v17, 0);
    uint64_t v49 = specialized handling<A, B, C, D>(_:_:_:_:)(v48, 4, 0);
    if (!v49) {
      BUG();
    }
    uint64_t v50 = v49;
    uint64_t v51 = type metadata accessor for CMLColumn();
    uint64_t v52 = swift_allocObject(v51, 24, 7);
    *(void *)(v52 + 16) = v50;
    uint64_t v53 = type metadata accessor for _UntypedColumn();
    uint64_t v20 = swift_allocObject(v53, 24, 7);
    *(void *)(v20 + 16) = v52;
    swift_errorRelease(v75);
    outlined consume of Result<_DataTable, Error>(v17, 0);
    goto LABEL_39;
  }
  *(void *)&v74[0] = v17;
  outlined copy of Result<_DataTable, Error>(v17, 1);
  swift_errorRetain(v17);
  uint64_t v38 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
  uint64_t v39 = _getErrorEmbeddedNSError<A>(_:)(v74, v38, &protocol self-conformance witness table for Error);
  if (v39)
  {
    uint64_t v20 = v39;
    outlined consume of Result<_DataTable, Error>(v17, 1);
  }
  else
  {
    uint64_t v20 = swift_allocError(v38, &protocol self-conformance witness table for Error, 0, 0);
    void *v54 = *(void *)&v74[0];
  }
  char v77 = 1;
  swift_errorRelease(v15);
  outlined consume of Result<_DataTable, Error>(v17, 1);
  char v41 = 1;
  if (!v77)
  {
LABEL_39:
    swift_retain_n(v20);
    uint64_t v55 = CMLColumn.size.getter();
    outlined consume of Result<_DataTable, Error>(v20, 0);
    if (v55 > 0)
    {
      swift_retain();
      _UntypedColumn.valueAtIndex(index:)(0, 0.0);
      outlined consume of Result<_DataTable, Error>(v20, 0);
      uint64_t v56 = (uint64_t)v67;
      uint64_t v57 = v72;
      (*(void (**)(_OWORD *, uint64_t))(v71 + 16))(v74, v72);
      int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v56, 1, v57);
      (*(void (**)(uint64_t, uint64_t))(v70 + 8))(v56, v68);
      if (EnumTagSinglePayload == 1)
      {
        *(void *)&v74[0] = 0;
        *((void *)&v74[0] + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(60);
        v59._uint64_t countAndFlagsBits = 0xD000000000000039;
        v59._char object = "Unable to map to type " + 0x8000000000000000;
        String.append(_:)(v59);
        uint64_t v60 = _typeName(_:qualified:)(a1, 0);
        char v62 = (char)v61;
        v59._uint64_t countAndFlagsBits = v60;
        v59._char object = v61;
        String.append(_:)(v59);
        swift_bridgeObjectRelease(v62);
        v59._uint64_t countAndFlagsBits = 46;
        v59._char object = (void *)0xE100000000000000;
        String.append(_:)(v59);
        long long v73 = v74[0];
        uint64_t v63 = swift_allocError(&type metadata for MLCreateError, v69, 0, 0);
        *(_OWORD *)uint64_t v64 = v73;
        *(_OWORD *)(v64 + 16) = 0;
        *(_OWORD *)(v64 + 32) = 0;
        *(unsigned char *)(v64 + 48) = 1;
        outlined consume of Result<_DataTable, Error>(v20, 0);
        outlined consume of Result<_DataTable, Error>(v20, 0);
        char v41 = 1;
        uint64_t v20 = v63;
        goto LABEL_34;
      }
    }
    char v41 = 0;
    uint64_t v46 = v20;
    goto LABEL_33;
  }
LABEL_34:
  *(void *)&v74[0] = v20;
  BYTE8(v74[0]) = v41 & 1;
  return MLDataColumn.init(from:)((uint64_t)v74);
}

uint64_t static MLUntypedColumn.+ infix(_:_:)(void *a1, uint64_t a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 0);
}

uint64_t static MLUntypedColumn.- infix(_:_:)(void *a1, uint64_t a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 1);
}

uint64_t static MLUntypedColumn.* infix(_:_:)(void *a1, uint64_t a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 3);
}

uint64_t static MLUntypedColumn./ infix(_:_:)(void *a1, uint64_t a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 2);
}

uint64_t static MLUntypedColumn.+ infix(_:_:)(uint64_t a1, void *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 0);
}

uint64_t static MLUntypedColumn.- infix(_:_:)(uint64_t a1, void *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 1);
}

uint64_t static MLUntypedColumn.* infix(_:_:)(uint64_t a1, void *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 3);
}

uint64_t static MLUntypedColumn./ infix(_:_:)(uint64_t a1, void *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, 2);
}

uint64_t static MLUntypedColumn.|| infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, (uint64_t)"|");
}

uint64_t static MLUntypedColumn.&& infix(_:_:)(uint64_t *a1, uint64_t *a2)
{
  return static MLUntypedColumn.== infix(_:_:)(a1, a2, (uint64_t)"&");
}

void *Array<A>.init(_:)(uint64_t a1, double a2)
{
  uint64_t v2 = *(void *)a1;
  uint64_t v3 = _swiftEmptyArrayStorage;
  char v13 = *(unsigned char *)(a1 + 8);
  if (!v13)
  {
    outlined copy of Result<_DataTable, Error>(v2, 0);
    uint64_t v4 = CMLColumn.size.getter();
    outlined consume of Result<_DataTable, Error>(v2, 0);
    uint64_t v11 = v4;
    if (v4 < 0) {
      BUG();
    }
    if (v4)
    {
      uint64_t v3 = _swiftEmptyArrayStorage;
      uint64_t v5 = 0;
      uint64_t v12 = v2;
      do
      {
        outlined copy of Result<_DataTable, Error>(v2, 0);
        _UntypedColumn.valueAtIndex(index:)(v5, a2);
        outlined consume of Result<_DataTable, Error>(v2, 0);
        if (!swift_isUniquelyReferenced_nonNull_native(v3)) {
          uint64_t v3 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3[2] + 1, 1, (uint64_t)v3);
        }
        unint64_t v6 = v3[2];
        if (v3[3] >> 1 <= v6) {
          uint64_t v3 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v3[3] >= 2uLL, v6 + 1, 1, (uint64_t)v3);
        }
        ++v5;
        v3[2] = v6 + 1;
        uint64_t v7 = 3 * v6;
        a2 = *(double *)&v9;
        *(_OWORD *)&v3[v7 + 4] = v9;
        LOBYTE(v3[v7 + 6]) = v10;
        uint64_t v2 = v12;
      }
      while (v11 != v5);
    }
  }
  outlined consume of Result<_DataTable, Error>(v2, v13);
  return v3;
}

uint64_t MLUntypedColumn.sequences.getter()
{
  char v4 = HIBYTE(result);
  uint64_t v2 = result;
  if (*(unsigned char *)(v1 + 8)
    || (uint64_t v3 = *(void *)v1,
        outlined copy of Result<_DataTable, Error>(v3, 0),
        _UntypedColumn.type.getter(),
        uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 0),
        v4 != 3))
  {
    *(void *)uint64_t v2 = 0;
    *(unsigned char *)(v2 + 8) = -1;
  }
  else
  {
    *(void *)uint64_t v2 = v3;
    *(unsigned char *)(v2 + 8) = 0;
    return outlined copy of Result<_DataTable, Error>(v3, 0);
  }
  return result;
}

uint64_t MLUntypedColumn.doubles.getter()
{
  char v4 = HIBYTE(result);
  uint64_t v2 = result;
  if (*(unsigned char *)(v1 + 8)
    || (uint64_t v3 = *(void *)v1,
        outlined copy of Result<_DataTable, Error>(v3, 0),
        _UntypedColumn.type.getter(),
        uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 0),
        v4 != 1))
  {
    *(void *)uint64_t v2 = 0;
    *(unsigned char *)(v2 + 8) = -1;
  }
  else
  {
    *(void *)uint64_t v2 = v3;
    *(unsigned char *)(v2 + 8) = 0;
    return outlined copy of Result<_DataTable, Error>(v3, 0);
  }
  return result;
}

uint64_t MLUntypedColumn.dictionaries.getter()
{
  char v4 = HIBYTE(result);
  uint64_t v2 = result;
  if (*(unsigned char *)(v1 + 8)
    || (uint64_t v3 = *(void *)v1,
        outlined copy of Result<_DataTable, Error>(v3, 0),
        _UntypedColumn.type.getter(),
        uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 0),
        v4 != 4))
  {
    *(void *)uint64_t v2 = 0;
    *(unsigned char *)(v2 + 8) = -1;
  }
  else
  {
    *(void *)uint64_t v2 = v3;
    *(unsigned char *)(v2 + 8) = 0;
    return outlined copy of Result<_DataTable, Error>(v3, 0);
  }
  return result;
}

uint64_t MLUntypedColumn.multiArrays.getter()
{
  char v4 = HIBYTE(result);
  uint64_t v2 = result;
  if (*(unsigned char *)(v1 + 8)
    || (uint64_t v3 = *(void *)v1,
        outlined copy of Result<_DataTable, Error>(v3, 0),
        _UntypedColumn.type.getter(),
        uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 0),
        v4 != 5))
  {
    *(void *)uint64_t v2 = 0;
    *(unsigned char *)(v2 + 8) = -1;
  }
  else
  {
    *(void *)uint64_t v2 = v3;
    *(unsigned char *)(v2 + 8) = 0;
    return outlined copy of Result<_DataTable, Error>(v3, 0);
  }
  return result;
}

uint64_t MLUntypedColumn.error.getter()
{
  if (*((unsigned char *)v0 + 8) != 1) {
    return 0;
  }
  uint64_t v1 = *v0;
  swift_errorRetain(*v0);
  return v1;
}

char MLUntypedColumn.isValid.getter()
{
  return *(unsigned char *)(v0 + 8) ^ 1;
}

uint64_t MLUntypedColumn.init(repeating:count:)(long long *a1, uint64_t a2)
{
  uint64_t v3 = v2;
  char v4 = *((unsigned char *)a1 + 16);
  long long v7 = *a1;
  char v8 = v4;
  uint64_t v5 = type metadata accessor for _UntypedColumn();
  swift_allocObject(v5, 24, 7);
  uint64_t result = _UntypedColumn.init(repeating:count:)((uint64_t)&v7, a2, *(double *)&v7);
  *(void *)uint64_t v3 = result;
  *(unsigned char *)(v3 + 8) = 0;
  return result;
}

uint64_t *MLUntypedColumn.init<A>(repeating:count:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v13 = a4;
  uint64_t v14 = a2;
  uint64_t v12 = v4;
  uint64_t v6 = *(void *)(a3 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  char v8 = alloca(v7);
  long long v9 = alloca(v7);
  type metadata accessor for _UntypedColumn();
  (*(void (**)(uint64_t **, uint64_t, uint64_t))(v6 + 16))(&v12, a1, a3);
  uint64_t v10 = _UntypedColumn.__allocating_init<A>(repeating:count:)((uint64_t)&v12, v14, a3, v13);
  (*(void (**)(uint64_t, uint64_t))(v6 + 8))(a1, a3);
  uint64_t result = v12;
  *uint64_t v12 = v10;
  *((unsigned char *)result + 8) = 0;
  return result;
}

uint64_t MLUntypedColumn.init()()
{
  uint64_t v1 = v0;
  uint64_t v2 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t result = swift_allocError(&type metadata for MLCreateError, v2, 0, 0);
  *(void *)uint64_t v4 = 0xD00000000000001DLL;
  *(void *)(v4 + 8) = "id column named '" + 0x8000000000000000;
  *(_OWORD *)(v4 + 16) = 0;
  *(_OWORD *)(v4 + 32) = 0;
  *(unsigned char *)(v4 + 48) = 1;
  *(void *)uint64_t v1 = result;
  *(unsigned char *)(v1 + 8) = 1;
  return result;
}

void MLUntypedColumn.append(contentsOf:)(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t v3 = *v1;
  char v4 = 1;
  if (*((unsigned char *)v2 + 8))
  {
    uint64_t v5 = v3;
  }
  else
  {
    uint64_t v5 = *(void *)a1;
    if (*(unsigned char *)(a1 + 8))
    {
      outlined copy of Result<_DataTable, Error>(*(void *)a1, 1);
      outlined consume of Result<_DataTable, Error>(v3, 0);
    }
    else
    {
      outlined copy of Result<_DataTable, Error>(*(void *)a1, 0);
      outlined copy of Result<_DataTable, Error>(v3, 0);
      uint64_t v6 = _UntypedColumn.appending(contentsOf:)(v5);
      outlined consume of Result<_DataTable, Error>(v5, 0);
      outlined consume of Result<_DataTable, Error>(v3, 0);
      outlined consume of Result<_DataTable, Error>(v3, 0);
      char v4 = 0;
      uint64_t v5 = v6;
    }
  }
  *uint64_t v2 = v5;
  *((unsigned char *)v2 + 8) = v4;
}

uint64_t MLUntypedColumn.subscript.getter(uint64_t *a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = *v2;
  if (*((unsigned char *)v2 + 8))
  {
    uint64_t result = swift_errorRetain(*v2);
    char v6 = 1;
  }
  else
  {
    uint64_t v7 = *a1;
    if (*((unsigned char *)a1 + 8))
    {
      uint64_t result = swift_errorRetain(*a1);
      char v6 = 1;
      uint64_t v4 = v7;
    }
    else
    {
      uint64_t v8 = *(void *)(*(void *)(v4 + 16) + 16);
      uint64_t v9 = *(void *)(*(void *)(v7 + 16) + 16);
      outlined copy of Result<_DataTable, Error>(*a1, 0);
      outlined copy of Result<_DataTable, Error>(v4, 0);
      uint64_t v15 = specialized handling<A, B, C>(_:_:_:)(v8, v9);
      if (!v15) {
        BUG();
      }
      char v6 = 0;
      uint64_t v10 = type metadata accessor for CMLColumn();
      uint64_t v11 = swift_allocObject(v10, 24, 7);
      *(void *)(v11 + 16) = v15;
      uint64_t v12 = type metadata accessor for _UntypedColumn();
      uint64_t v13 = swift_allocObject(v12, 24, 7);
      *(void *)(v13 + 16) = v11;
      uint64_t v14 = v13;
      outlined consume of Result<_DataTable, Error>(v7, 0);
      uint64_t result = outlined consume of Result<_DataTable, Error>(v4, 0);
      uint64_t v4 = v14;
    }
  }
  *(void *)uint64_t v3 = v4;
  *(unsigned char *)(v3 + 8) = v6;
  return result;
}

uint64_t MLUntypedColumn.materialize()()
{
  uint64_t v2 = *(void *)v1;
  if (*(unsigned char *)(v1 + 8))
  {
    uint64_t v3 = *(void *)v1;
    outlined copy of Result<_DataTable, Error>(*(void *)v1, 1);
    return swift_willThrow(v3, 1, v4, v5, v6, v7);
  }
  else
  {
    uint64_t v9 = v0;
    outlined copy of Result<_DataTable, Error>(v2, 0);
    CMLColumn.materialize()();
    uint64_t result = outlined consume of Result<_DataTable, Error>(v2, 0);
    if (!v10)
    {
      *(void *)uint64_t v9 = v2;
      *(unsigned char *)(v9 + 8) = 0;
      return outlined copy of Result<_DataTable, Error>(v2, 0);
    }
  }
  return result;
}

uint64_t MLUntypedColumn.subscript.getter(uint64_t a1, uint64_t a2)
{
  uint64_t v20 = a2;
  uint64_t v19 = v2;
  uint64_t v4 = *(void *)v3;
  char v5 = *(unsigned char *)(v3 + 8);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MLUntypedColumn)>);
  uint64_t inited = swift_initStackObject(v6, v14);
  *(void *)(inited + 16) = 1;
  *(void *)(inited + 24) = 2;
  *(void *)(inited + 32) = 7106403;
  *(void *)(inited + 40) = 0xE300000000000000;
  *(void *)(inited + 48) = v4;
  *(unsigned char *)(inited + 56) = v5;
  outlined copy of Result<_DataTable, Error>(v4, v5);
  uint64_t v8 = Dictionary.init(dictionaryLiteral:)(inited, &type metadata for String, &type metadata for MLUntypedColumn, &protocol witness table for String);
  specialized MLDataTable.init<A>(uniqueKeysWithValues:)(v8);
  uint64_t v9 = v15;
  char v10 = v16;
  uint64_t v17 = v15;
  char v18 = v16;
  MLDataTable.subscript.getter(a1, v20);
  outlined consume of Result<_DataTable, Error>(v9, v10);
  uint64_t v11 = v15;
  LOBYTE(inited) = v16;
  uint64_t v17 = v15;
  char v18 = v16;
  v12._uint64_t countAndFlagsBits = 7106403;
  v12._char object = (void *)0xE300000000000000;
  MLDataTable.subscript.getter(v12);
  return outlined consume of Result<_DataTable, Error>(v11, inited);
}

uint64_t MLUntypedColumn.init(doubles:)(uint64_t a1)
{
  return MLUntypedColumn.init(doubles:)(a1, 1);
}

uint64_t static MLUntypedColumn.== infix(_:_:)(uint64_t a1, long long *a2)
{
  uint64_t v3 = v2;
  uint64_t v4 = *(void *)a1;
  if (*(unsigned char *)(a1 + 8))
  {
    *(void *)&long long v12 = *(void *)a1;
    outlined copy of Result<_DataTable, Error>(v4, 1);
    swift_errorRetain(v4);
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v6 = _getErrorEmbeddedNSError<A>(_:)(&v12, v5, &protocol self-conformance witness table for Error);
    if (v6)
    {
      uint64_t v7 = v6;
      outlined consume of Result<_DataTable, Error>(v4, 1);
    }
    else
    {
      uint64_t v7 = swift_allocError(v5, &protocol self-conformance witness table for Error, 0, 0);
      void *v9 = v12;
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v4, 1);
    char v10 = 1;
  }
  else
  {
    char v8 = *((unsigned char *)a2 + 16);
    type metadata accessor for _UntypedColumn();
    long long v12 = *a2;
    char v13 = v8;
    swift_retain();
    uint64_t v7 = static _UntypedColumn.performRightScalar(op:a:b:)(4, v4, (double *)&v12);
    char v10 = 0;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v4, 0);
  }
  *(void *)uint64_t v3 = v7;
  *(unsigned char *)(v3 + 8) = v10;
  return result;
}

void *MLUntypedColumn.column<A>(type:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v15 = v3;
  uint64_t v6 = *(void *)v4;
  char v19 = *(unsigned char *)(v4 + 8);
  uint64_t v16 = v6;
  if (v19)
  {
    uint64_t v7 = 6;
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(v6, 0);
    _UntypedColumn.type.getter();
    outlined consume of Result<_DataTable, Error>(v6, 0);
    uint64_t v7 = v17;
  }
  (*(void (**)(uint64_t, uint64_t))(a3 + 8))(a2, a3);
  if (v7 == v17)
  {
    uint64_t v8 = v16;
    uint64_t v13 = v16;
    char v9 = v19;
    char v14 = v19;
    MLDataColumn.init(from:)((uint64_t)&v13);
    uint64_t v10 = v17;
    char v11 = v18;
    outlined copy of Result<_DataTable, Error>(v8, v9);
  }
  else
  {
    uint64_t v10 = 0;
    char v11 = -1;
  }
  uint64_t result = v15;
  void *v15 = v10;
  *((unsigned char *)result + 8) = v11;
  return result;
}

uint64_t MLUntypedColumn.copy()()
{
  return MLUntypedColumn.copy()(specialized handling<A, B>(_:_:));
}

BOOL MLUntypedColumn.isEmpty.getter()
{
  BOOL result = 1;
  if (!*(unsigned char *)(v0 + 8))
  {
    uint64_t v2 = *(void *)v0;
    outlined copy of Result<_DataTable, Error>(*(void *)v0, 0);
    uint64_t v3 = CMLColumn.size.getter();
    outlined consume of Result<_DataTable, Error>(v2, 0);
    return v3 <= 0;
  }
  return result;
}

uint64_t closure #1 in MLUntypedColumn.init<A>(_:)(uint64_t a1, uint64_t a2, void *a3, void *a4)
{
  uint64_t v17 = a4;
  char v14 = a3;
  char v18 = v4;
  uint64_t v15 = v5;
  uint64_t v16 = a1;
  uint64_t v6 = *(void *)(a2 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  uint64_t v8 = alloca(v7);
  char v9 = alloca(v7);
  type metadata accessor for _UntypedColumn();
  double v10 = (*(double (**)(uint64_t *, uint64_t, uint64_t))(v6 + 16))(&v13, v16, a2);
  uint64_t v11 = v15;
  uint64_t result = _UntypedColumn.__allocating_init<A>(_:)((uint64_t)&v13, a2, v14, v10);
  if (v11)
  {
    uint64_t result = (uint64_t)v17;
    *uint64_t v17 = v11;
  }
  else
  {
    *char v18 = result;
  }
  return result;
}

uint64_t closure #1 in MLUntypedColumn.init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t a4, void *a5)
{
  uint64_t v13 = a4;
  char v14 = a3;
  char v18 = v5;
  uint64_t v17 = a5;
  uint64_t v15 = v6;
  uint64_t v16 = a1;
  uint64_t v7 = *(void *)(a2 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  char v9 = alloca(v8);
  double v10 = alloca(v8);
  type metadata accessor for _UntypedColumn();
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v7 + 16))(&v13, v16, a2);
  uint64_t v11 = v15;
  uint64_t result = _UntypedColumn.__allocating_init<A>(_:)(&v13, a2, v14, v13);
  if (v11)
  {
    uint64_t result = (uint64_t)v17;
    *uint64_t v17 = v11;
  }
  else
  {
    *char v18 = result;
  }
  return result;
}

uint64_t partial apply for closure #1 in MLUntypedColumn.init<A>(_:)(void *a1)
{
  return closure #1 in MLUntypedColumn.init<A>(_:)(*(void *)(v1 + 40), *(void *)(v1 + 16), *(uint64_t **)(v1 + 24), *(void *)(v1 + 32), a1);
}

{
  uint64_t v1;

  return closure #1 in MLUntypedColumn.init<A>(_:)(*(void *)(v1 + 32), *(void *)(v1 + 16), *(void **)(v1 + 24), a1);
}

uint64_t MLUntypedColumn.init(_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  uint64_t v4 = type metadata accessor for _UntypedColumn();
  uint64_t v5 = swift_allocObject(v4, 24, 7);
  type metadata accessor for CMLColumn();
  uint64_t result = CMLColumn.__allocating_init(_:)(a1, a2);
  *(void *)(v5 + 16) = result;
  *(void *)uint64_t v3 = v5;
  *(unsigned char *)(v3 + 8) = 0;
  return result;
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t result;

  uint64_t v3 = v2;
  uint64_t v4 = type metadata accessor for _UntypedColumn();
  swift_allocObject(v4, 24, 7);
  uint64_t result = _UntypedColumn.init(_:)(a1, a2);
  *(void *)uint64_t v3 = result;
  *(unsigned char *)(v3 + 8) = 0;
  return result;
}

uint64_t MLUntypedColumn.subscript.getter(uint64_t a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = *v2;
  if (*((unsigned char *)v2 + 8))
  {
    uint64_t result = swift_errorRetain(*v2);
    char v6 = 1;
  }
  else
  {
    uint64_t v7 = *(void *)a1;
    if (*(unsigned char *)(a1 + 8))
    {
      uint64_t result = outlined copy of Result<_DataTable, Error>(*(void *)a1, 1);
      char v6 = 1;
      uint64_t v4 = v7;
    }
    else
    {
      uint64_t v8 = *(void *)(*(void *)(v4 + 16) + 16);
      uint64_t v9 = *(void *)(*(void *)(v7 + 16) + 16);
      outlined copy of Result<_DataTable, Error>(*(void *)a1, 0);
      outlined copy of Result<_DataTable, Error>(v4, 0);
      uint64_t v15 = specialized handling<A, B, C>(_:_:_:)(v8, v9);
      if (!v15) {
        BUG();
      }
      char v6 = 0;
      uint64_t v10 = type metadata accessor for CMLColumn();
      uint64_t v11 = swift_allocObject(v10, 24, 7);
      *(void *)(v11 + 16) = v15;
      uint64_t v12 = type metadata accessor for _UntypedColumn();
      uint64_t v13 = swift_allocObject(v12, 24, 7);
      *(void *)(v13 + 16) = v11;
      uint64_t v14 = v13;
      outlined consume of Result<_DataTable, Error>(v7, 0);
      uint64_t result = outlined consume of Result<_DataTable, Error>(v4, 0);
      uint64_t v4 = v14;
    }
  }
  *(void *)uint64_t v3 = v4;
  *(unsigned char *)(v3 + 8) = v6;
  return result;
}

uint64_t MLUntypedColumn.map<A>(skipUndefined:_:)(int a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  v24[1] = v5;
  LODWORD(v29) = a1;
  uint64_t v28 = *(void *)v6;
  char v10 = *(unsigned char *)(v6 + 8);
  uint64_t v11 = (void *)swift_allocObject(&unk_39D6F0, 48, 7);
  uint64_t v25 = a4;
  v11[2] = a4;
  uint64_t v12 = a5;
  uint64_t v13 = a3;
  uint64_t v14 = (uint64_t)v11;
  v11[3] = v12;
  v11[4] = a2;
  void v11[5] = v13;
  if (v10)
  {
    uint64_t v29 = v12;
    uint64_t v26 = v28;
    outlined copy of Result<_DataTable, Error>(v28, 1);
    swift_retain();
    outlined copy of Result<_DataTable, Error>(v28, 1);
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v16 = _getErrorEmbeddedNSError<A>(_:)(&v26, v15, &protocol self-conformance witness table for Error);
    if (v16)
    {
      uint64_t v17 = v16;
      uint64_t v18 = v28;
      outlined consume of Result<_DataTable, Error>(v28, 1);
      uint64_t v19 = v18;
    }
    else
    {
      uint64_t v17 = swift_allocError(v15, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v22 = v26;
      uint64_t v19 = v28;
    }
    outlined consume of Result<_DataTable, Error>(v19, 1);
    swift_release();
    char v21 = 1;
  }
  else
  {
    uint64_t v20 = v28;
    v24[0] = v28;
    swift_retain();
    outlined copy of Result<_DataTable, Error>(v28, 0);
    closure #2 in MLUntypedColumn.map<A>(skipUndefined:_:)((uint64_t)v24, (uint64_t)partial apply for closure #1 in MLUntypedColumn.map<A>(skipUndefined:_:), v14, v29, v25, v12);
    outlined consume of Result<_DataTable, Error>(v20, 0);
    swift_release();
    uint64_t v17 = v26;
    char v21 = 0;
  }
  uint64_t v26 = v17;
  char v27 = v21;
  return MLDataColumn.init(from:)((uint64_t)&v26);
}

uint64_t closure #1 in MLUntypedColumn.map<A>(skipUndefined:_:)(uint64_t a1, void (*a2)(void *), uint64_t a3, uint64_t a4, uint64_t a5, double a6)
{
  uint64_t v22 = a5;
  uint64_t v21 = a3;
  uint64_t v20 = a2;
  uint64_t v23 = type metadata accessor for Optional(0, a4);
  uint64_t v24 = *(void *)(v23 - 8);
  int64_t v7 = *(void *)(v24 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v26 = *(void *)(a4 - 8);
  int64_t v10 = *(void *)(v26 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v25 = v18;
  swift_retain();
  MLDataValue.init(_:)(a1, a6);
  uint64_t v13 = (void *)v18[0];
  char v14 = v19;
  char v27 = (void *)v18[1];
  v20(v18);
  if (__swift_getEnumTagSinglePayload((uint64_t)v18, 1, a4) == 1)
  {
    (*(void (**)(void *, uint64_t))(v24 + 8))(v18, v23);
    type metadata accessor for CMLFeatureValue();
    uint64_t v15 = CMLFeatureValue.__allocating_init()(0);
    outlined consume of MLDataValue(v13, v27, v14);
  }
  else
  {
    uint64_t v16 = v25;
    (*(void (**)(void *, void *, uint64_t))(v26 + 32))(v25, v18, a4);
    uint64_t v15 = MLDataValueConvertible.featureValue.getter(a4, v22);
    outlined consume of MLDataValue(v13, v27, v14);
    (*(void (**)(void *, uint64_t))(v26 + 8))(v16, a4);
  }
  return v15;
}

uint64_t closure #2 in MLUntypedColumn.map<A>(skipUndefined:_:)(uint64_t a1, uint64_t a2, uint64_t a3, char a4, uint64_t a5, uint64_t a6)
{
  uint64_t v9 = v6;
  (*(void (**)(uint64_t))(a6 + 8))(a5);
  uint64_t result = _UntypedColumn.map(_:skipUndefined:outputType:)(a2, a3, a4, v11);
  uint64_t *v9 = result;
  return result;
}

uint64_t thunk for @escaping @callee_guaranteed (@in_guaranteed MLDataValue) -> (@out A)(uint64_t a1, void (*a2)(uint64_t), uint64_t a3, uint64_t a4)
{
  uint64_t v6 = v4;
  a2(a1);
  return __swift_storeEnumTagSinglePayload(v6, 0, 1, a4);
}

uint64_t MLUntypedColumn.mapMissing<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MLUntypedColumn.map<A>(_:)(a1, a2, a3, a4, 0);
}

uint64_t MLUntypedColumn.map<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  return MLUntypedColumn.map<A>(skipUndefined:_:)(a5, a1, a2, a3, a4);
}

uint64_t MLUntypedColumn.dropMissing()()
{
  return MLUntypedColumn.copy()(specialized handling<A, B>(_:_:));
}

uint64_t MLUntypedColumn.copy()(uint64_t (*a1)(uint64_t))
{
  uint64_t v3 = v1;
  uint64_t v4 = *(void *)v2;
  if (*(unsigned char *)(v2 + 8))
  {
    v18[0] = *(void *)v2;
    outlined copy of Result<_DataTable, Error>(v4, 1);
    swift_errorRetain(v4);
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v6 = _getErrorEmbeddedNSError<A>(_:)(v18, v5, &protocol self-conformance witness table for Error);
    if (v6)
    {
      uint64_t v7 = v6;
      outlined consume of Result<_DataTable, Error>(v4, 1);
    }
    else
    {
      uint64_t v7 = swift_allocError(v5, &protocol self-conformance witness table for Error, 0, 0);
      uint64_t *v10 = v18[0];
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v4, 1);
    char v12 = 1;
  }
  else
  {
    uint64_t v8 = *(void *)(*(void *)(v4 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(*(void *)v2, 0);
    uint64_t v9 = a1(v8);
    uint64_t v13 = v9;
    if (!v9) {
      BUG();
    }
    char v12 = 0;
    uint64_t v14 = type metadata accessor for CMLColumn();
    uint64_t v15 = swift_allocObject(v14, 24, 7);
    *(void *)(v15 + 16) = v13;
    uint64_t v16 = v15;
    uint64_t v17 = type metadata accessor for _UntypedColumn();
    uint64_t v7 = swift_allocObject(v17, 24, 7);
    *(void *)(v7 + 16) = v16;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v4, 0);
  }
  *(void *)uint64_t v3 = v7;
  *(unsigned char *)(v3 + 8) = v12;
  return result;
}

uint64_t *MLUntypedColumn.fillMissing(with:)(long long *a1)
{
  uint64_t v3 = *(void *)v2;
  BOOL v4 = *(unsigned char *)(v2 + 8) == 0;
  uint64_t v21 = v1;
  if (v4)
  {
    char v8 = *((unsigned char *)a1 + 16);
    long long v19 = *a1;
    char v20 = v8;
    swift_retain();
    uint64_t v9 = MLDataValue.featureValue.getter(*(double *)&v19);
    uint64_t v10 = specialized handling<A, B, C>(_:_:_:)(*(void *)(*(void *)(v3 + 16) + 16), *(void *)(v9 + 16));
    uint64_t v14 = v10;
    if (!v10) {
      BUG();
    }
    char v12 = 0;
    uint64_t v15 = type metadata accessor for CMLColumn();
    uint64_t v16 = swift_allocObject(v15, 24, 7);
    *(void *)(v16 + 16) = v14;
    uint64_t v17 = v16;
    uint64_t v18 = type metadata accessor for _UntypedColumn();
    uint64_t v7 = swift_allocObject(v18, 24, 7);
    *(void *)(v7 + 16) = v17;
    swift_release();
    outlined consume of Result<_DataTable, Error>(v3, 0);
  }
  else
  {
    *(void *)&long long v19 = v3;
    outlined copy of Result<_DataTable, Error>(v3, 1);
    swift_errorRetain(v3);
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v6 = _getErrorEmbeddedNSError<A>(_:)(&v19, v5, &protocol self-conformance witness table for Error);
    if (v6)
    {
      uint64_t v7 = v6;
      outlined consume of Result<_DataTable, Error>(v3, 1);
    }
    else
    {
      uint64_t v7 = swift_allocError(v5, &protocol self-conformance witness table for Error, 0, 0);
      void *v11 = v19;
    }
    outlined consume of Result<_DataTable, Error>(v3, 1);
    char v12 = 1;
  }
  uint64_t result = v21;
  uint64_t *v21 = v7;
  *((unsigned char *)result + 8) = v12;
  return result;
}

char *MLUntypedColumn.prefix(_:)(uint64_t a1)
{
  return MLUntypedColumn.prefix(_:)(a1, specialized handling<A, B, C>(_:_:_:));
}

char *MLUntypedColumn.suffix(_:)(uint64_t a1)
{
  return MLUntypedColumn.prefix(_:)(a1, specialized handling<A, B, C>(_:_:_:));
}

char *MLUntypedColumn.prefix(_:)(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t))
{
  uint64_t v4 = v2;
  if (a1 <= 0)
  {
    uint64_t v9 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v8 = swift_allocError(&type metadata for MLCreateError, v9, 0, 0);
    *(void *)uint64_t v10 = 0xD00000000000002BLL;
    uint64_t result = "Column initialized as invalid" + 0x8000000000000000;
    *(void *)(v10 + 8) = "Column initialized as invalid" + 0x8000000000000000;
    *(_OWORD *)(v10 + 16) = 0;
    *(_OWORD *)(v10 + 32) = 0;
    *(unsigned char *)(v10 + 48) = 0;
LABEL_9:
    char v15 = 1;
    goto LABEL_10;
  }
  uint64_t v5 = *(void *)v3;
  if (*(unsigned char *)(v3 + 8))
  {
    v21[0] = *(void *)v3;
    outlined copy of Result<_DataTable, Error>(v5, 1);
    swift_errorRetain(v5);
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v7 = _getErrorEmbeddedNSError<A>(_:)(v21, v6, &protocol self-conformance witness table for Error);
    if (v7)
    {
      uint64_t v8 = v7;
      outlined consume of Result<_DataTable, Error>(v5, 1);
    }
    else
    {
      uint64_t v8 = swift_allocError(v6, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v14 = v21[0];
    }
    uint64_t result = (char *)outlined consume of Result<_DataTable, Error>(v5, 1);
    goto LABEL_9;
  }
  uint64_t v12 = *(void *)(*(void *)(v5 + 16) + 16);
  outlined copy of Result<_DataTable, Error>(v5, 0);
  uint64_t v13 = a2(v12, a1);
  uint64_t v16 = v13;
  if (!v13) {
    BUG();
  }
  char v15 = 0;
  uint64_t v17 = type metadata accessor for CMLColumn();
  uint64_t v18 = swift_allocObject(v17, 24, 7);
  *(void *)(v18 + 16) = v16;
  uint64_t v19 = v18;
  uint64_t v20 = type metadata accessor for _UntypedColumn();
  uint64_t v8 = swift_allocObject(v20, 24, 7);
  *(void *)(v8 + 16) = v19;
  uint64_t result = (char *)outlined consume of Result<_DataTable, Error>(v5, 0);
LABEL_10:
  *(void *)uint64_t v4 = v8;
  *(unsigned char *)(v4 + 8) = v15;
  return result;
}

uint64_t MLUntypedColumn.sort(byIncreasingOrder:)(char a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = *(void *)v2;
  if (*(unsigned char *)(v2 + 8))
  {
    v18[0] = *(void *)v2;
    outlined copy of Result<_DataTable, Error>(v4, 1);
    swift_errorRetain(v4);
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v6 = _getErrorEmbeddedNSError<A>(_:)(v18, v5, &protocol self-conformance witness table for Error);
    if (v6)
    {
      uint64_t v7 = v6;
      outlined consume of Result<_DataTable, Error>(v4, 1);
    }
    else
    {
      uint64_t v7 = swift_allocError(v5, &protocol self-conformance witness table for Error, 0, 0);
      uint64_t *v10 = v18[0];
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v4, 1);
    char v12 = 1;
  }
  else
  {
    uint64_t v8 = *(void *)(*(void *)(v4 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(*(void *)v2, 0);
    uint64_t v9 = specialized handling<A, B, C>(_:_:_:)(v8, a1);
    uint64_t v13 = v9;
    if (!v9) {
      BUG();
    }
    char v12 = 0;
    uint64_t v14 = type metadata accessor for CMLColumn();
    uint64_t v15 = swift_allocObject(v14, 24, 7);
    *(void *)(v15 + 16) = v13;
    uint64_t v16 = v15;
    uint64_t v17 = type metadata accessor for _UntypedColumn();
    uint64_t v7 = swift_allocObject(v17, 24, 7);
    *(void *)(v7 + 16) = v16;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v4, 0);
  }
  *(void *)uint64_t v3 = v7;
  *(unsigned char *)(v3 + 8) = v12;
  return result;
}

uint64_t MLUntypedColumn.init(ints:)(uint64_t a1)
{
  return MLUntypedColumn.init(doubles:)(a1, 0);
}

uint64_t MLUntypedColumn.init(doubles:)(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  uint64_t v4 = *(void *)a1;
  if (*(unsigned char *)(a1 + 8))
  {
    v17[0] = *(void *)a1;
    swift_errorRetain(v4);
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v6 = _getErrorEmbeddedNSError<A>(_:)(v17, v5, &protocol self-conformance witness table for Error);
    if (v6)
    {
      uint64_t v7 = v6;
      outlined consume of Result<_DataTable, Error>(v4, 1);
    }
    else
    {
      uint64_t v7 = swift_allocError(v5, &protocol self-conformance witness table for Error, 0, 0);
      uint64_t *v9 = v17[0];
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v4, 1);
    char v11 = 1;
  }
  else
  {
    uint64_t v8 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(*(void *)(v4 + 16) + 16), a2, 0);
    uint64_t v12 = v8;
    if (!v8) {
      BUG();
    }
    char v11 = 0;
    uint64_t v13 = type metadata accessor for CMLColumn();
    uint64_t v14 = swift_allocObject(v13, 24, 7);
    *(void *)(v14 + 16) = v12;
    uint64_t v15 = v14;
    uint64_t v16 = type metadata accessor for _UntypedColumn();
    uint64_t v7 = swift_allocObject(v16, 24, 7);
    *(void *)(v7 + 16) = v15;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v4, 0);
  }
  *(void *)uint64_t v3 = v7;
  *(unsigned char *)(v3 + 8) = v11;
  return result;
}

uint64_t MLUntypedColumn.init(strings:)(uint64_t a1)
{
  return MLUntypedColumn.init(doubles:)(a1, 2);
}

uint64_t MLUntypedColumn.init(sequences:)(uint64_t a1)
{
  return MLUntypedColumn.init(doubles:)(a1, 4);
}

uint64_t MLUntypedColumn.init(dictionaries:)(uint64_t a1)
{
  return MLUntypedColumn.init(doubles:)(a1, 5);
}

uint64_t MLUntypedColumn.init(multiArrays:)(uint64_t a1)
{
  return MLUntypedColumn.init(doubles:)(a1, 9);
}

uint64_t MLUntypedColumn.subscript.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v17 = a3;
  uint64_t v18 = a2;
  uint64_t v16 = v3;
  if (*(unsigned char *)(v4 + 8)
    || (uint64_t v5 = *(void *)v4,
        outlined copy of Result<_DataTable, Error>(*(void *)v4, 0),
        uint64_t v6 = CMLColumn.size.getter(),
        outlined consume of Result<_DataTable, Error>(v5, 0),
        v6 < 0))
  {
    BUG();
  }
  v13[0] = 0;
  v13[1] = v6;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Range<Int>);
  uint64_t v8 = lazy protocol witness table accessor for type Range<Int> and conformance <> Range<A>();
  ((void (*)(void *, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))dispatch thunk of RangeExpression.relative<A>(to:))(v13, v7, v8, v18, v17, v9);
  uint64_t v10 = v14;
  uint64_t v11 = v15;
  uint64_t v14 = v5;
  LOBYTE(v15) = 0;
  return MLUntypedColumn.subscript.getter(v10, v11);
}

uint64_t MLUntypedColumn.show()()
{
  uint64_t v2 = v0;
  uint64_t v3 = 0;
  if (!*(unsigned char *)(v1 + 8))
  {
    uint64_t v4 = *(void *)v1;
    uint64_t v5 = *(void *)(*(void *)(*(void *)v1 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(*(void *)v1, 0);
    outlined copy of Result<_DataTable, Error>(v4, 0);
    swift_retain();
    uint64_t v6 = specialized handling<A, B, C, D, E, F>(_:_:_:_:_:_:)(v5, (uint64_t)"", (uint64_t)"", (uint64_t)"", 0);
    if (!v6) {
      BUG();
    }
    uint64_t v7 = type metadata accessor for CMLPlot();
    uint64_t v3 = swift_allocObject(v7, 24, 7);
    *(void *)(v3 + 16) = v6;
    outlined consume of Result<_DataTable, Error>(v4, 0);
    swift_release();
    outlined consume of Result<_DataTable, Error>(v4, 0);
  }
  v2[3] = (uint64_t)&type metadata for ML1DVisualization;
  uint64_t result = lazy protocol witness table accessor for type ML1DVisualization and conformance ML1DVisualization();
  v2[4] = result;
  *uint64_t v2 = v3;
  return result;
}

uint64_t MLUntypedColumn.customMirror.getter()
{
  v19[1] = v0;
  uint64_t v21 = type metadata accessor for Mirror.AncestorRepresentation(0);
  uint64_t v22 = *(void *)(v21 - 8);
  int64_t v2 = *(void *)(v22 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v20 = &v18;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Mirror.DisplayStyle?)
                             - 8)
                 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v8 = *(void *)v1;
  char v9 = *(unsigned char *)(v1 + 8);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
  uint64_t v11 = swift_allocObject(v10, 128, 7);
  *(void *)(v11 + 16) = 2;
  *(void *)(v11 + 24) = 4;
  *(void *)(v11 + 32) = 0x746E756F63;
  *(void *)(v11 + 40) = 0xE500000000000000;
  if (v9)
  {
    uint64_t v12 = -1;
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(v8, 0);
    uint64_t v12 = CMLColumn.size.getter();
    outlined consume of Result<_DataTable, Error>(v8, 0);
  }
  *(void *)(v11 + 72) = &type metadata for Int;
  *(void *)(v11 + 48) = v12;
  *(void *)(v11 + 80) = 1701869940;
  *(void *)(v11 + 88) = 0xE400000000000000;
  *(void *)(v11 + 120) = &type metadata for MLDataValue.ValueType;
  if (v9)
  {
    *(unsigned char *)(v11 + 96) = 6;
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(v8, 0);
    _UntypedColumn.type.getter();
    *(unsigned char *)(v11 + 96) = v23;
    outlined consume of Result<_DataTable, Error>(v8, 0);
  }
  v19[0] = &type metadata for MLUntypedColumn;
  unsigned int v13 = enum case for Mirror.DisplayStyle.dictionary(_:);
  uint64_t v14 = type metadata accessor for Mirror.DisplayStyle(0);
  (*(void (**)(uint64_t *, void, uint64_t))(*(void *)(v14 - 8) + 104))(&v18, v13, v14);
  __swift_storeEnumTagSinglePayload((uint64_t)&v18, 0, 1, v14);
  uint64_t v15 = v20;
  (*(void (**)(uint64_t *, void, uint64_t))(v22 + 104))(v20, enum case for Mirror.AncestorRepresentation.suppressed(_:), v21);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLUntypedColumn.Type);
  return Mirror.init<A>(_:children:displayStyle:ancestorRepresentation:)(v19, v11, &v18, v15, v16);
}

uint64_t protocol witness for CustomReflectable.customMirror.getter in conformance MLUntypedColumn()
{
  return MLUntypedColumn.customMirror.getter();
}

uint64_t MLUntypedColumn.description.getter()
{
  return MLUntypedColumn.description.getter();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  void v5[2];
  uint64_t v6[5];

  uint64_t v1 = *(void *)v0;
  if (*(unsigned char *)(v0 + 8))
  {
    v5[0] = 0;
    v5[1] = 0xE000000000000000;
    v6[0] = v1;
    int64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    _print_unlocked<A, B>(_:_:)(v6, v5, v2, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    return v5[0];
  }
  else
  {
    swift_retain();
    uint64_t v3 = _UntypedColumn.description.getter();
    outlined consume of Result<_DataTable, Error>(v1, 0);
  }
  return v3;
}

uint64_t MLUntypedColumn.debugDescription.getter()
{
  return MLUntypedColumn.description.getter();
}

uint64_t MLUntypedColumn.playgroundDescription.getter()
{
  int64_t v2 = v0;
  uint64_t v3 = *(void *)v1;
  if (*(unsigned char *)(v1 + 8))
  {
    uint64_t v10 = 0;
    unint64_t v11 = 0xE000000000000000;
    v12[0] = v3;
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    _print_unlocked<A, B>(_:_:)(v12, &v10, v4, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    uint64_t v5 = v10;
    char v6 = v11;
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(*(void *)v1, 0);
    uint64_t v5 = _UntypedColumn.description.getter();
    char v6 = v7;
    outlined consume of Result<_DataTable, Error>(v3, 0);
  }
  objc_allocWithZone((Class)NSAttributedString);
  id v8 = @nonobjc NSAttributedString.init(string:attributes:)(v5, v6, 0);
  uint64_t result = type metadata accessor for NSAttributedString();
  v2[3] = result;
  *int64_t v2 = v8;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLUntypedColumn()
{
  return MLUntypedColumn.description.getter();
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLUntypedColumn()
{
  return MLUntypedColumn.playgroundDescription.getter();
}

uint64_t sub_2D1D4A()
{
  swift_release(*(void *)(v0 + 40));
  return swift_deallocObject(v0, 48, 7);
}

uint64_t partial apply for thunk for @escaping @callee_guaranteed (@in_guaranteed MLDataValue) -> (@out A)(uint64_t a1)
{
  return thunk for @escaping @callee_guaranteed (@in_guaranteed MLDataValue) -> (@out A)(a1, *(void (**)(uint64_t))(v1 + 32), *(void *)(v1 + 40), *(void *)(v1 + 16));
}

uint64_t lazy protocol witness table accessor for type Range<Int> and conformance <> Range<A>()
{
  uint64_t result = lazy protocol witness table cache variable for type Range<Int> and conformance <> Range<A>;
  if (!lazy protocol witness table cache variable for type Range<Int> and conformance <> Range<A>)
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for Range<Int>);
    lazy protocol witness table accessor for type Int and conformance Int();
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for <> Range<A>, v1);
    lazy protocol witness table cache variable for type Range<Int> and conformance <> Range<A> = result;
  }
  return result;
}

{
  uint64_t result;
  uint64_t v1;

  uint64_t result = lazy protocol witness table cache variable for type Range<Int> and conformance <> Range<A>;
  if (!lazy protocol witness table cache variable for type Range<Int> and conformance <> Range<A>)
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for Range<Int>);
    lazy protocol witness table accessor for type Int and conformance Int();
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for <> Range<A>, v1);
    lazy protocol witness table cache variable for type Range<Int> and conformance <> Range<A> = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type ML1DVisualization and conformance ML1DVisualization()
{
  uint64_t result = lazy protocol witness table cache variable for type ML1DVisualization and conformance ML1DVisualization;
  if (!lazy protocol witness table cache variable for type ML1DVisualization and conformance ML1DVisualization)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ML1DVisualization, &type metadata for ML1DVisualization);
    lazy protocol witness table cache variable for type ML1DVisualization and conformance ML1DVisualization = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ML1DVisualization and conformance ML1DVisualization;
  if (!lazy protocol witness table cache variable for type ML1DVisualization and conformance ML1DVisualization)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ML1DVisualization, &type metadata for ML1DVisualization);
    lazy protocol witness table cache variable for type ML1DVisualization and conformance ML1DVisualization = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ML1DVisualization and conformance ML1DVisualization;
  if (!lazy protocol witness table cache variable for type ML1DVisualization and conformance ML1DVisualization)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ML1DVisualization, &type metadata for ML1DVisualization);
    lazy protocol witness table cache variable for type ML1DVisualization and conformance ML1DVisualization = result;
  }
  return result;
}

ValueMetadata *type metadata accessor for MLUntypedColumn()
{
  return &type metadata for MLUntypedColumn;
}

uint64_t partial apply for closure #1 in MLUntypedColumn.map<A>(skipUndefined:_:)(uint64_t a1, double a2)
{
  return closure #1 in MLUntypedColumn.map<A>(skipUndefined:_:)(a1, *(void (**)(void *))(v2 + 32), *(void *)(v2 + 40), *(void *)(v2 + 16), *(void *)(v2 + 24), a2);
}

uint64_t sub_2D1E6E()
{
  return sub_2D1D4A();
}

uint64_t specialized MLTrainingSession.resume(job:completion:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v16 = a5;
  uint64_t v17 = a2;
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TaskPriority?)
                             - 8)
                 + 64);
  char v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v11 = type metadata accessor for TaskPriority(0);
  __swift_storeEnumTagSinglePayload((uint64_t)&v15, 1, 1, v11);
  uint64_t v12 = swift_allocObject(a4, 64, 7);
  *(_OWORD *)(v12 + 16) = 0;
  *(void *)(v12 + 32) = v5;
  *(void *)(v12 + 40) = a1;
  *(void *)(v12 + 48) = v17;
  *(void *)(v12 + 56) = a3;
  swift_retain();
  swift_retain();
  swift_retain();
  uint64_t v13 = _sScTss5Error_pRs_rlE8detached8priority9operationScTyxsAA_pGScPSg_xyYaKYAcntFZyt_Tgm5((uint64_t)&v15, v16, v12);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v15, &demangling cache variable for type metadata for TaskPriority?);
  return v13;
}

uint64_t specialized closure #1 in MLTrainingSession.resume(job:completion:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AF0A4);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AF064);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AF024);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AEFE4);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AEFA4);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AEF64);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AEF24);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AEEE4);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AEEA4);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AEE64);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AEE24);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AEDE4);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AED64);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AEDA4);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AED24);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AECE4);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

{
  void *v7;
  uint64_t (*v9)(uint64_t);
  void *v10;

  v7[3] = a7;
  v7[2] = a6;
  char v9 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLTrainingSession.resumeAsync(job:)
                                       + async function pointer to specialized MLTrainingSession.resumeAsync(job:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AECA4);
  v7[4] = v10;
  void *v10 = v7;
  v10[1] = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  return v9(a5);
}

uint64_t specialized closure #1 in MLTrainingSession.resume(job:completion:)()
{
  uint64_t v2 = *(void *)(*(void *)v1 + 32);
  *(void *)(*(void *)v1 + 40) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  }
  else {
    uint64_t v3 = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)(void);

  uint64_t v2 = *(void *)(*(void *)v1 + 32);
  *(void *)(*(void *)v1 + 40) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  }
  else {
    uint64_t v3 = specialized closure #1 in MLTrainingSession.resume(job:completion:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;

  (*(void (**)(void, void))(v0 + 16))(0, 0);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  void (*v2)(uint64_t, uint64_t);

  uint64_t v1 = *(void *)(v0 + 40);
  uint64_t v2 = *(void (**)(uint64_t, uint64_t))(v0 + 16);
  swift_errorRetain(v1);
  v2(v1, 1);
  swift_errorRelease(v1);
  swift_errorRelease(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)();
}

{
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)();
}

uint64_t specialized MLTrainingSession.resumeAsync(job:)(uint64_t a1)
{
  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;

  v2[6] = v1;
  v2[5] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[7] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLCheckpoint(0);
  v2[8] = v4;
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
}

uint64_t specialized MLTrainingSession.resumeAsync(job:)()
{
  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AF0AC);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;

  uint64_t v2 = *v1;
  uint64_t v3 = *(void *)(*v1 + 80);
  uint64_t v4 = *v1;
  swift_task_dealloc(v3);
  if (!v0) {
    return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
  }
  uint64_t v5 = *(void *)(v2 + 56);
  swift_task_dealloc(*(void *)(v2 + 72));
  swift_task_dealloc(v5);
  return (*(uint64_t (**)(void))(v4 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AF06C);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AF02C);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AEFEC);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;

  uint64_t v2 = *v1;
  uint64_t v3 = *(void *)(*v1 + 80);
  uint64_t v4 = *v1;
  swift_task_dealloc(v3);
  if (!v0) {
    return swift_task_switch(specialized MLTrainingSession.resumeAsync(job:), 0, 0);
  }
  uint64_t v5 = *(void *)(v2 + 56);
  swift_task_dealloc(*(void *)(v2 + 72));
  swift_task_dealloc(v5);
  return (*(uint64_t (**)(void))(v4 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;

  if ([*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v1 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v1, 0, 0);
    *(_OWORD *)uint64_t v2 = 0;
    *(_OWORD *)(v2 + 16) = 0;
    *(_OWORD *)(v2 + 32) = 0;
    *(unsigned char *)(v2 + 48) = 4;
    swift_willThrow(&type metadata for MLCreateError, v1, v2, v3, v4, v5);
    uint64_t v6 = *(void *)(v0 + 56);
    swift_task_dealloc(*(void *)(v0 + 72));
    swift_task_dealloc(v6);
  }
  else
  {
    uint64_t v7 = *(void *)(v0 + 56);
    swift_task_dealloc(*(void *)(v0 + 72));
    swift_task_dealloc(v7);
  }
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AEFAC);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AEF6C);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AEF2C);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AEEEC);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AEEAC);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AEE6C);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AEE2C);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AEDEC);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AED6C);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AEDAC);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AED2C);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AECEC);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v3 = *(void *)(**(void **)(v0 + 48) + 112) + *(void *)(v0 + 48);
  swift_beginAccess(v3, v0 + 16, 1, 0);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
  specialized BidirectionalCollection.last.getter(*(void *)(*(int *)(v4 + 44) + v3));
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v5 = *(void *)(v0 + 48);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 56), &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v6 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
    uint64_t v7 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 16))(v6, v7);
  }
  else
  {
    uint64_t v8 = *(void *)(v0 + 48);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 56), *(void *)(v0 + 72), type metadata accessor for MLCheckpoint);
    uint64_t v15 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 24);
    uint64_t v17 = *(void *)(direct field offset for MLTrainingSession.delegate + v8 + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v8), v15);
    uint64_t v18 = v4;
    uint64_t v9 = *(void *)(v3 + *(int *)(v4 + 44));
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v17 + 24);
    swift_bridgeObjectRetain(v9);
    v16(v9, v15, v17);
    uint64_t v10 = *(void *)(v0 + 72);
    uint64_t v11 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(v9);
    *(unsigned char *)(v3 + *(int *)(v18 + 28)) = *(unsigned char *)(v10 + *(int *)(v11 + 20));
    uint64_t v12 = *(void *)(v10 + *(int *)(v11 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLCheckpoint);
    *(void *)(v3 + *(int *)(v18 + 32)) = v12;
  }
  uint64_t v13 = (void *)swift_task_alloc(dword_3AECAC);
  *(void *)(v0 + 80) = v13;
  *uint64_t v13 = v0;
  v13[1] = specialized MLTrainingSession.resumeAsync(job:);
  return specialized MLTrainingSession.execute(job:)(*(void *)(v0 + 40));
}

{
  return specialized MLTrainingSession.resumeAsync(job:)();
}

uint64_t _sScTss5Error_pRs_rlE8detached8priority9operationScTyxsAA_pGScPSg_xyYaKYAcntFZyt_Tgm5(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v22 = a2;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TaskPriority?)
                             - 8)
                 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, (uint64_t)&v19, &demangling cache variable for type metadata for TaskPriority?);
  uint64_t v7 = type metadata accessor for TaskPriority(0);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v19, 1, v7) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v19, &demangling cache variable for type metadata for TaskPriority?);
    uint64_t v9 = 4096;
  }
  else
  {
    unsigned __int8 v10 = TaskPriority.rawValue.getter();
    (*(void (**)(long long *, uint64_t))(*(void *)(v7 - 8) + 8))(&v19, v7);
    uint64_t v9 = v10 | 0x1000;
  }
  uint64_t v11 = *(void *)(a3 + 16);
  if (v11)
  {
    uint64_t v12 = *(void *)(a3 + 24);
    uint64_t ObjectType = swift_getObjectType(*(void *)(a3 + 16));
    swift_unknownObjectRetain(v11);
    uint64_t v14 = dispatch thunk of Actor.unownedExecutor.getter(ObjectType, v12);
    uint64_t v16 = v15;
    swift_unknownObjectRelease(v11);
  }
  else
  {
    uint64_t v14 = 0;
    uint64_t v16 = 0;
  }
  if (v14 | v16)
  {
    uint64_t v17 = &v19;
    long long v19 = 0;
    uint64_t v20 = v14;
    uint64_t v21 = v16;
  }
  else
  {
    uint64_t v17 = 0;
  }
  return swift_task_create(v9, v17, (char *)&type metadata for () + 8, v22, a3, v8, v19, *((void *)&v19 + 1), v20, v21);
}

uint64_t specialized MLTrainingSession.execute(job:)(uint64_t a1)
{
  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.execute(job:), 0, 0);
}

uint64_t specialized MLTrainingSession.execute(job:)()
{
  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 56) = v2;
  *(void *)(v0 + 64) = direct field offset for MLTrainingSession.delegate;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 56)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 64);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AF0C4);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AF0BC);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AF0B4);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AF0C4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AF0BC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AF0B4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AF0C4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AF0BC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AF0B4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AF0C4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AF0BC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AF0B4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 56) = v2;
  *(void *)(v0 + 64) = direct field offset for MLTrainingSession.delegate;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 56)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 64);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AF084);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AF07C);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AF074);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AF084);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AF07C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AF074);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AF084);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AF07C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AF074);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AF084);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AF07C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AF074);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 56) = v2;
  *(void *)(v0 + 64) = direct field offset for MLTrainingSession.delegate;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 56)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 64);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AF044);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AF03C);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AF034);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AF044);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AF03C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AF034);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AF044);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AF03C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AF034);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AF044);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AF03C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AF034);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 56) = v2;
  *(void *)(v0 + 64) = direct field offset for MLTrainingSession.delegate;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 56)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 64);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AF004);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AEFFC);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AEFF4);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)(void);

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)(void);

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)(void);

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AF004);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEFFC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEFF4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;

  static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AF004);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEFFC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEFF4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;

  static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AF004);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEFFC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEFF4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;

  static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 56) = v2;
  *(void *)(v0 + 64) = direct field offset for MLTrainingSession.delegate;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 56)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 64);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AEFC4);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AEFBC);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AEFB4);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEFC4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEFBC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEFB4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEFC4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEFBC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEFB4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEFC4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEFBC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEFB4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 56) = v2;
  *(void *)(v0 + 64) = direct field offset for MLTrainingSession.delegate;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 56)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 64);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AEF84);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AEF7C);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AEF74);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEF84);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEF7C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEF74);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEF84);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEF7C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEF74);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 56) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 56)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 64) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEF84);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEF7C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEF74);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  *(void *)(v0 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 64) = v2;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 64)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 56);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AEF44);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AEF3C);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AEF34);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEF44);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEF3C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEF34);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEF44);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEF3C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEF34);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEF44);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEF3C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEF34);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  *(void *)(v0 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 64) = v2;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 64)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 56);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AEF04);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AEEFC);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AEEF4);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEF04);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEEFC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEEF4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEF04);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEEFC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEEF4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEF04);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEEFC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEEF4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  *(void *)(v0 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 64) = v2;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 64)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 56);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AEEC4);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AEEBC);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AEEB4);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEEC4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEEBC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEEB4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEEC4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEEBC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEEB4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEEC4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEEBC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEEB4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  *(void *)(v0 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 64) = v2;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 64)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 56);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AEE84);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AEE7C);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AEE74);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEE84);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEE7C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEE74);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEE84);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEE7C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEE74);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEE84);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEE7C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEE74);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  *(void *)(v0 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 64) = v2;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 64)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 56);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AEE44);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AEE3C);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AEE34);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEE44);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEE3C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEE34);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEE44);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEE3C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEE34);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEE44);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEE3C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEE34);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  *(void *)(v0 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 64) = v2;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 64)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 56);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AEE04);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AEDFC);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AEDF4);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEE04);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEDFC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEDF4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEE04);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEDFC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEDF4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEE04);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEDFC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEDF4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  *(void *)(v0 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 64) = v2;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 64)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 56);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AED84);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AED7C);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AED74);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AED84);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AED7C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AED74);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AED84);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AED7C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AED74);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AED84);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AED7C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AED74);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  *(void *)(v0 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 64) = v2;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 64)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 56);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AEDC4);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AEDBC);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AEDB4);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEDC4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEDBC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEDB4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEDC4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEDBC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEDB4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AEDC4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AEDBC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AEDB4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  *(void *)(v0 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 64) = v2;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 64)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 56);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AED44);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AED3C);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AED34);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AED44);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AED3C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AED34);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AED44);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AED3C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AED34);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AED44);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AED3C);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AED34);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  *(void *)(v0 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 64) = v2;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 64)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 56);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AED04);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AECFC);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AECF4);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AED04);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AECFC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AECF4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AED04);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AECFC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AECF4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AED04);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AECFC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AECF4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  char v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  uint64_t result;
  void *v14;
  void *v15;
  uint64_t v16;

  *(_DWORD *)(v0 + 120) = static _PowerUtilities.createPowerAssertion()();
  uint64_t v1 = *(void *)(v0 + 48);
  *(void *)(v0 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v2 = *(void *)(*(void *)v1 + 112);
  *(void *)(v0 + 64) = v2;
  swift_beginAccess(v2 + v1, v0 + 16, 0, 0);
  while (2)
  {
    uint64_t v3 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
    uint64_t v5 = *(unsigned __int8 *)(*(int *)(v4 + 28) + v3);
    uint64_t v6 = 0x696C616974696E69;
    unint64_t v7 = 0xEB0000000064657ALL;
    switch(v5)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v6 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v6 = 0x676E696E69617274;
        unint64_t v7 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v6 = 0x697461756C617665;
LABEL_6:
        unint64_t v7 = 0xEA0000000000676ELL;
LABEL_7:
        char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v7, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v7);
        if ((v8 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_15;
        }
        uint64_t v9 = *(void *)(v0 + 48);
        switch(*(unsigned char *)(*(int *)(v4 + 28) + v9 + *(void *)(v0 + 64)))
        {
          case 0:
            uint64_t v10 = *(void *)(v0 + 56);
            specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
            uint64_t v11 = *(void *)(v9 + v10 + 24);
            uint64_t v16 = *(void *)(v9 + v10 + 32);
            __swift_project_boxed_opaque_existential_0Tm((void *)(v10 + v9), v11);
            *(unsigned char *)(v0 + 124) = 1;
            (*(void (**)(uint64_t, uint64_t))(v16 + 40))(v0 + 124, v11);
            continue;
          case 1:
            uint64_t v12 = (void *)swift_task_alloc(dword_3AECC4);
            *(void *)(v0 + 72) = v12;
            *uint64_t v12 = v0;
            v12[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
            break;
          case 2:
            uint64_t v14 = (void *)swift_task_alloc(dword_3AECBC);
            *(void *)(v0 + 88) = v14;
            *uint64_t v14 = v0;
            v14[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
            break;
          case 3:
            uint64_t v15 = (void *)swift_task_alloc(dword_3AECB4);
            *(void *)(v0 + 104) = v15;
            void *v15 = v0;
            v15[1] = specialized MLTrainingSession.execute(job:);
            uint64_t result = specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
            break;
          case 4:
            continue;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_15:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t result = (*(uint64_t (**)(void))(v0 + 8))();
        break;
    }
    return result;
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 72);
  *(void *)(*(void *)v1 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 88);
  *(void *)(*(void *)v1 + 96) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 104);
  *(void *)(*(void *)v1 + 112) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  else {
    uint64_t v3 = specialized MLTrainingSession.execute(job:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 80);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AECC4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AECBC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AECB4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 96);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AECC4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AECBC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AECB4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void *v11;
  void *v13;
  void *v14;
  uint64_t (*v15)(void);
  void *v16;

  uint64_t v1 = *(void *)(v0 + 112);
  while (2)
  {
    uint64_t v2 = *(void *)(v0 + 64) + *(void *)(v0 + 48);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
    uint64_t v4 = *(unsigned __int8 *)(*(int *)(v3 + 28) + v2);
    uint64_t v5 = 0x696C616974696E69;
    uint64_t v6 = 0xEB0000000064657ALL;
    switch(v4)
    {
      case 0:
        goto LABEL_7;
      case 1:
        uint64_t v5 = 0x6974636172747865;
        goto LABEL_6;
      case 2:
        uint64_t v5 = 0x676E696E69617274;
        uint64_t v6 = 0xE800000000000000;
        goto LABEL_7;
      case 3:
        uint64_t v5 = 0x697461756C617665;
LABEL_6:
        uint64_t v6 = 0xEA0000000000676ELL;
LABEL_7:
        unint64_t v7 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, 0x636E657265666E69, 0xEB00000000676E69, 0);
        swift_bridgeObjectRelease(v6);
        if ((v7 & 1) != 0
          || [*(id *)(*(void *)(v0 + 40) + direct field offset for MLJob.progress) isCancelled])
        {
          goto LABEL_16;
        }
        break;
      case 4:
        swift_bridgeObjectRelease(105);
LABEL_16:
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        if (v1) {
          swift_errorRelease(v1);
        }
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
    }
    char v8 = *(void *)(v0 + 48);
    switch(*(unsigned char *)(*(int *)(v3 + 28) + v8 + *(void *)(v0 + 64)))
    {
      case 0:
        uint64_t v16 = (void *)(*(void *)(v0 + 56) + v8);
        specialized MLTrainingSession.transition(to:)(1, &demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
        uint64_t v9 = v16[3];
        uint64_t v10 = v16[4];
        __swift_project_boxed_opaque_existential_0Tm(v16, v9);
        *(unsigned char *)(v0 + 124) = 1;
        (*(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 40))(v0 + 124, v9, v10);
        if (!v1)
        {
          uint64_t v1 = 0;
          continue;
        }
        static _PowerUtilities.endPowerAssertion(from:)(*(_DWORD *)(v0 + 120));
        uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
        return v15();
      case 1:
        uint64_t v11 = (void *)swift_task_alloc(dword_3AECC4);
        *(void *)(v0 + 72) = v11;
        void *v11 = v0;
        v11[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.extractFeatures(job:)(*(void *)(v0 + 40));
      case 2:
        uint64_t v13 = (void *)swift_task_alloc(dword_3AECBC);
        *(void *)(v0 + 88) = v13;
        *uint64_t v13 = v0;
        v13[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.train(job:)(*(void *)(v0 + 40));
      case 3:
        uint64_t v14 = (void *)swift_task_alloc(dword_3AECB4);
        *(void *)(v0 + 104) = v14;
        *uint64_t v14 = v0;
        v14[1] = specialized MLTrainingSession.execute(job:);
        return specialized MLTrainingSession.evaluate(job:)(*(void *)(v0 + 40));
      case 4:
        continue;
    }
  }
}

{
  return specialized MLTrainingSession.execute(job:)();
}

{
  return specialized MLTrainingSession.execute(job:)();
}

{
  return specialized MLTrainingSession.execute(job:)();
}

BOOL MLJob.isCanceled.getter()
{
  return [*(id *)(v0 + direct field offset for MLJob.progress) isCancelled] != 0;
}

uint64_t specialized MLTrainingSession.transition(to:)(int a1, uint64_t *a2)
{
  uint64_t v3 = v2;
  uint64_t v4 = *(void *)(v2 + direct field offset for MLTrainingSession.delegate + 24);
  uint64_t v5 = *(void *)(v2 + direct field offset for MLTrainingSession.delegate + 32);
  uint64_t v11 = __swift_project_boxed_opaque_existential_0Tm((void *)(v3 + direct field offset for MLTrainingSession.delegate), *(void *)(v3 + direct field offset for MLTrainingSession.delegate + 24));
  uint64_t v6 = *(void *)(*(void *)v3 + 112) + v3;
  swift_beginAccess(v6, v10, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(a2);
  char v13 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int v12 = a1;
  v14[0] = a1;
  uint64_t result = (*(uint64_t (**)(char *, unsigned char *, uint64_t, uint64_t))(v5 + 80))(&v13, v14, v4, v5);
  uint64_t v9 = *(int *)(v7 + 28);
  if (result)
  {
    *(unsigned char *)(v6 + v9) = v12;
    uint64_t result = *(int *)(v7 + 32);
    *(void *)(v6 + result) = 0;
  }
  else
  {
    *(unsigned char *)(v6 + v9) = 4;
  }
  return result;
}

uint64_t specialized MLTrainingSession.extractFeatures(job:)(uint64_t a1)
{
  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[10] = v4;
  v2[11] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for URL(0);
  v2[12] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[13] = v6;
  unint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[14] = swift_task_alloc(v7);
  v2[15] = swift_task_alloc(v7);
  uint64_t v8 = type metadata accessor for MLCheckpoint(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[10] = v4;
  v2[11] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for URL(0);
  v2[12] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[13] = v6;
  unint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[14] = swift_task_alloc(v7);
  v2[15] = swift_task_alloc(v7);
  uint64_t v8 = type metadata accessor for MLCheckpoint(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[10] = v4;
  v2[11] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for URL(0);
  v2[12] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[13] = v6;
  unint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[14] = swift_task_alloc(v7);
  v2[15] = swift_task_alloc(v7);
  uint64_t v8 = type metadata accessor for MLCheckpoint(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[10] = v4;
  v2[11] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for URL(0);
  v2[12] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[13] = v6;
  unint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[14] = swift_task_alloc(v7);
  v2[15] = swift_task_alloc(v7);
  uint64_t v8 = type metadata accessor for MLCheckpoint(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[10] = v4;
  v2[11] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for URL(0);
  v2[12] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[13] = v6;
  unint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[14] = swift_task_alloc(v7);
  v2[15] = swift_task_alloc(v7);
  uint64_t v8 = type metadata accessor for MLCheckpoint(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[9] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[10] = v4;
  v2[11] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for URL(0);
  v2[12] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[13] = v6;
  unint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[14] = swift_task_alloc(v7);
  v2[15] = swift_task_alloc(v7);
  uint64_t v8 = type metadata accessor for MLCheckpoint(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = type metadata accessor for MLCheckpoint(0);
  v2[9] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[10] = v4;
  uint64_t v5 = (*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[11] = swift_task_alloc(v5);
  v2[12] = swift_task_alloc(v5);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[13] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v7 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[14] = v7;
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for URL(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = type metadata accessor for MLCheckpoint(0);
  v2[9] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[10] = v4;
  uint64_t v5 = (*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[11] = swift_task_alloc(v5);
  v2[12] = swift_task_alloc(v5);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[13] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v7 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[14] = v7;
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for URL(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = type metadata accessor for MLCheckpoint(0);
  v2[9] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[10] = v4;
  uint64_t v5 = (*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[11] = swift_task_alloc(v5);
  v2[12] = swift_task_alloc(v5);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[13] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v7 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[14] = v7;
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for URL(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = type metadata accessor for MLCheckpoint(0);
  v2[9] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[10] = v4;
  uint64_t v5 = (*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[11] = swift_task_alloc(v5);
  v2[12] = swift_task_alloc(v5);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[13] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v7 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[14] = v7;
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for URL(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = type metadata accessor for MLCheckpoint(0);
  v2[9] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[10] = v4;
  uint64_t v5 = (*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[11] = swift_task_alloc(v5);
  v2[12] = swift_task_alloc(v5);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[13] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v7 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[14] = v7;
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for URL(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = type metadata accessor for MLCheckpoint(0);
  v2[9] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[10] = v4;
  uint64_t v5 = (*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[11] = swift_task_alloc(v5);
  v2[12] = swift_task_alloc(v5);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[13] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v7 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[14] = v7;
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for URL(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = type metadata accessor for MLCheckpoint(0);
  v2[9] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[10] = v4;
  uint64_t v5 = (*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[11] = swift_task_alloc(v5);
  v2[12] = swift_task_alloc(v5);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[13] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v7 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[14] = v7;
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for URL(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = type metadata accessor for MLCheckpoint(0);
  v2[9] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[10] = v4;
  uint64_t v5 = (*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[11] = swift_task_alloc(v5);
  v2[12] = swift_task_alloc(v5);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[13] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v7 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[14] = v7;
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for URL(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = type metadata accessor for MLCheckpoint(0);
  v2[9] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[10] = v4;
  uint64_t v5 = (*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[11] = swift_task_alloc(v5);
  v2[12] = swift_task_alloc(v5);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[13] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v7 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[14] = v7;
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for URL(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = type metadata accessor for MLCheckpoint(0);
  v2[9] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[10] = v4;
  uint64_t v5 = (*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[11] = swift_task_alloc(v5);
  v2[12] = swift_task_alloc(v5);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[13] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v7 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[14] = v7;
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for URL(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unint64_t v11;

  v2[8] = v1;
  v2[7] = a1;
  uint64_t v3 = type metadata accessor for MLCheckpoint(0);
  v2[9] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[10] = v4;
  uint64_t v5 = (*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[11] = swift_task_alloc(v5);
  v2[12] = swift_task_alloc(v5);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[13] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v7 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[14] = v7;
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for URL(0);
  v2[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[17] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[18] = swift_task_alloc(v10);
  v2[19] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v11);
  v2[21] = swift_task_alloc(v11);
  return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
}

uint64_t specialized MLTrainingSession.extractFeatures(job:)()
{
  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (void *)v1[17];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[19];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[19];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[19];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[16];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[16] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[14];
    uint64_t v51 = (void *)v49[9];
    uint64_t v52 = (void *)v49[11];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 80) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 96);
  uint64_t v16 = *(void *)(v1 + 72);
  uint64_t v17 = *(void *)(v1 + 88);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 72), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 104) + 32))(*(void *)(v1 + 120), *(void *)(v1 + 72), *(void *)(v1 + 96));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 112);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 120);
    uint64_t v55 = *(void *)(v1 + 96);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 104) + 8);
    v56(*(void *)(v1 + 112), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 128)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 120);
    uint64_t v64 = *(void *)(v1 + 96);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 104) + 8);
    v65(*(void *)(v1 + 112), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v66 = *(void *)(v1 + 144);
  uint64_t v71 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 112);
  long long v73 = *(void *)(v1 + 104);
  long long v70 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 112);
      uint64_t v71 = *(void *)(v1 + 72);
      uint64_t v72 = *(void *)(v1 + 88);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 112);
  uint64_t v74 = *(uint64_t **)(v1 + 72);
  uint64_t v71 = *(void *)(v1 + 88);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (void *)v1[17];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[19];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[19];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[19];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[16];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[16] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[14];
    uint64_t v51 = (void *)v49[9];
    uint64_t v52 = (void *)v49[11];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 80) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 96);
  uint64_t v16 = *(void *)(v1 + 72);
  uint64_t v17 = *(void *)(v1 + 88);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 72), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 104) + 32))(*(void *)(v1 + 120), *(void *)(v1 + 72), *(void *)(v1 + 96));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 112);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 120);
    uint64_t v55 = *(void *)(v1 + 96);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 104) + 8);
    v56(*(void *)(v1 + 112), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 128)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 120);
    uint64_t v64 = *(void *)(v1 + 96);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 104) + 8);
    v65(*(void *)(v1 + 112), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v66 = *(void *)(v1 + 144);
  uint64_t v71 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 112);
  long long v73 = *(void *)(v1 + 104);
  long long v70 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 112);
      uint64_t v71 = *(void *)(v1 + 72);
      uint64_t v72 = *(void *)(v1 + 88);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 112);
  uint64_t v74 = *(uint64_t **)(v1 + 72);
  uint64_t v71 = *(void *)(v1 + 88);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (void *)v1[17];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[19];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[19];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[19];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[16];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[16] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[14];
    uint64_t v51 = (void *)v49[9];
    uint64_t v52 = (void *)v49[11];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 80) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 96);
  uint64_t v16 = *(void *)(v1 + 72);
  uint64_t v17 = *(void *)(v1 + 88);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 72), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 104) + 32))(*(void *)(v1 + 120), *(void *)(v1 + 72), *(void *)(v1 + 96));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 112);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 120);
    uint64_t v55 = *(void *)(v1 + 96);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 104) + 8);
    v56(*(void *)(v1 + 112), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 128)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 120);
    uint64_t v64 = *(void *)(v1 + 96);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 104) + 8);
    v65(*(void *)(v1 + 112), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v66 = *(void *)(v1 + 144);
  uint64_t v71 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 112);
  long long v73 = *(void *)(v1 + 104);
  long long v70 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 112);
      uint64_t v71 = *(void *)(v1 + 72);
      uint64_t v72 = *(void *)(v1 + 88);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 112);
  uint64_t v74 = *(uint64_t **)(v1 + 72);
  uint64_t v71 = *(void *)(v1 + 88);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (void *)v1[17];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[19];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[19];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[19];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[16];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[16] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[14];
    uint64_t v51 = (void *)v49[9];
    uint64_t v52 = (void *)v49[11];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 80) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 96);
  uint64_t v16 = *(void *)(v1 + 72);
  uint64_t v17 = *(void *)(v1 + 88);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 72), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 104) + 32))(*(void *)(v1 + 120), *(void *)(v1 + 72), *(void *)(v1 + 96));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 112);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 120);
    uint64_t v55 = *(void *)(v1 + 96);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 104) + 8);
    v56(*(void *)(v1 + 112), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 128)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 120);
    uint64_t v64 = *(void *)(v1 + 96);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 104) + 8);
    v65(*(void *)(v1 + 112), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v66 = *(void *)(v1 + 144);
  uint64_t v71 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 112);
  long long v73 = *(void *)(v1 + 104);
  long long v70 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 112);
      uint64_t v71 = *(void *)(v1 + 72);
      uint64_t v72 = *(void *)(v1 + 88);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 112);
  uint64_t v74 = *(uint64_t **)(v1 + 72);
  uint64_t v71 = *(void *)(v1 + 88);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (void *)v1[17];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[19];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[19];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[19];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[16];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[16] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[14];
    uint64_t v51 = (void *)v49[9];
    uint64_t v52 = (void *)v49[11];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 80) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 96);
  uint64_t v16 = *(void *)(v1 + 72);
  uint64_t v17 = *(void *)(v1 + 88);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 72), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 104) + 32))(*(void *)(v1 + 120), *(void *)(v1 + 72), *(void *)(v1 + 96));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 112);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 120);
    uint64_t v55 = *(void *)(v1 + 96);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 104) + 8);
    v56(*(void *)(v1 + 112), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 128)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 120);
    uint64_t v64 = *(void *)(v1 + 96);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 104) + 8);
    v65(*(void *)(v1 + 112), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v66 = *(void *)(v1 + 144);
  uint64_t v71 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 112);
  long long v73 = *(void *)(v1 + 104);
  long long v70 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 112);
      uint64_t v71 = *(void *)(v1 + 72);
      uint64_t v72 = *(void *)(v1 + 88);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 112);
  uint64_t v74 = *(uint64_t **)(v1 + 72);
  uint64_t v71 = *(void *)(v1 + 88);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (void *)v1[17];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[19];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[19];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[19];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[16];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[16] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[14];
    uint64_t v51 = (void *)v49[9];
    uint64_t v52 = (void *)v49[11];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 80) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 96);
  uint64_t v16 = *(void *)(v1 + 72);
  uint64_t v17 = *(void *)(v1 + 88);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 72), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 104) + 32))(*(void *)(v1 + 120), *(void *)(v1 + 72), *(void *)(v1 + 96));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 112);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 120);
    uint64_t v55 = *(void *)(v1 + 96);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 104) + 8);
    v56(*(void *)(v1 + 112), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 128)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 120);
    uint64_t v64 = *(void *)(v1 + 96);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 104) + 8);
    v65(*(void *)(v1 + 112), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v66 = *(void *)(v1 + 144);
  uint64_t v71 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 112);
  long long v73 = *(void *)(v1 + 104);
  long long v70 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 112);
      uint64_t v71 = *(void *)(v1 + 72);
      uint64_t v72 = *(void *)(v1 + 88);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 112);
  uint64_t v74 = *(uint64_t **)(v1 + 72);
  uint64_t v71 = *(void *)(v1 + 88);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[9];
    uint64_t v52 = (void *)v1[10];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[11];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[11];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[11];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[9];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[9] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[13];
    uint64_t v51 = (void *)v49[11];
    uint64_t v52 = (void *)v49[12];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 112) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 128);
  uint64_t v16 = *(void *)(v1 + 104);
  uint64_t v17 = *(void *)(v1 + 120);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 104), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 136) + 32))(*(void *)(v1 + 152), *(void *)(v1 + 104), *(void *)(v1 + 128));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 144);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 152);
    uint64_t v55 = *(void *)(v1 + 128);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v56(*(void *)(v1 + 144), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 72)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 152);
    uint64_t v64 = *(void *)(v1 + 128);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v65(*(void *)(v1 + 144), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v71 = *(void *)(v1 + 152);
  uint64_t v72 = *(void *)(v1 + 144);
  long long v73 = *(void *)(v1 + 136);
  long long v70 = *(void *)(v1 + 128);
  uint64_t v66 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 104);
      uint64_t v71 = *(void *)(v1 + 88);
      uint64_t v72 = *(void *)(v1 + 96);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 104);
  uint64_t v74 = *(uint64_t **)(v1 + 88);
  uint64_t v71 = *(void *)(v1 + 96);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[9];
    uint64_t v52 = (void *)v1[10];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[11];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[11];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[11];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[9];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[9] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[13];
    uint64_t v51 = (void *)v49[11];
    uint64_t v52 = (void *)v49[12];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 112) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 128);
  uint64_t v16 = *(void *)(v1 + 104);
  uint64_t v17 = *(void *)(v1 + 120);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 104), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 136) + 32))(*(void *)(v1 + 152), *(void *)(v1 + 104), *(void *)(v1 + 128));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 144);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 152);
    uint64_t v55 = *(void *)(v1 + 128);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v56(*(void *)(v1 + 144), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 72)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 152);
    uint64_t v64 = *(void *)(v1 + 128);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v65(*(void *)(v1 + 144), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v71 = *(void *)(v1 + 152);
  uint64_t v72 = *(void *)(v1 + 144);
  long long v73 = *(void *)(v1 + 136);
  long long v70 = *(void *)(v1 + 128);
  uint64_t v66 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 104);
      uint64_t v71 = *(void *)(v1 + 88);
      uint64_t v72 = *(void *)(v1 + 96);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 104);
  uint64_t v74 = *(uint64_t **)(v1 + 88);
  uint64_t v71 = *(void *)(v1 + 96);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[9];
    uint64_t v52 = (void *)v1[10];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[11];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[11];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[11];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[9];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[9] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[13];
    uint64_t v51 = (void *)v49[11];
    uint64_t v52 = (void *)v49[12];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 112) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 128);
  uint64_t v16 = *(void *)(v1 + 104);
  uint64_t v17 = *(void *)(v1 + 120);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 104), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 136) + 32))(*(void *)(v1 + 152), *(void *)(v1 + 104), *(void *)(v1 + 128));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 144);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 152);
    uint64_t v55 = *(void *)(v1 + 128);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v56(*(void *)(v1 + 144), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 72)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 152);
    uint64_t v64 = *(void *)(v1 + 128);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v65(*(void *)(v1 + 144), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v71 = *(void *)(v1 + 152);
  uint64_t v72 = *(void *)(v1 + 144);
  long long v73 = *(void *)(v1 + 136);
  long long v70 = *(void *)(v1 + 128);
  uint64_t v66 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 104);
      uint64_t v71 = *(void *)(v1 + 88);
      uint64_t v72 = *(void *)(v1 + 96);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 104);
  uint64_t v74 = *(uint64_t **)(v1 + 88);
  uint64_t v71 = *(void *)(v1 + 96);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[9];
    uint64_t v52 = (void *)v1[10];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[11];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[11];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[11];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[9];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[9] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[13];
    uint64_t v51 = (void *)v49[11];
    uint64_t v52 = (void *)v49[12];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 112) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 128);
  uint64_t v16 = *(void *)(v1 + 104);
  uint64_t v17 = *(void *)(v1 + 120);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 104), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 136) + 32))(*(void *)(v1 + 152), *(void *)(v1 + 104), *(void *)(v1 + 128));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 144);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 152);
    uint64_t v55 = *(void *)(v1 + 128);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v56(*(void *)(v1 + 144), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 72)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 152);
    uint64_t v64 = *(void *)(v1 + 128);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v65(*(void *)(v1 + 144), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v71 = *(void *)(v1 + 152);
  uint64_t v72 = *(void *)(v1 + 144);
  long long v73 = *(void *)(v1 + 136);
  long long v70 = *(void *)(v1 + 128);
  uint64_t v66 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 104);
      uint64_t v71 = *(void *)(v1 + 88);
      uint64_t v72 = *(void *)(v1 + 96);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 104);
  uint64_t v74 = *(uint64_t **)(v1 + 88);
  uint64_t v71 = *(void *)(v1 + 96);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[9];
    uint64_t v52 = (void *)v1[10];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[11];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[11];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[11];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[9];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[9] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[13];
    uint64_t v51 = (void *)v49[11];
    uint64_t v52 = (void *)v49[12];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 112) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 128);
  uint64_t v16 = *(void *)(v1 + 104);
  uint64_t v17 = *(void *)(v1 + 120);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 104), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 136) + 32))(*(void *)(v1 + 152), *(void *)(v1 + 104), *(void *)(v1 + 128));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 144);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 152);
    uint64_t v55 = *(void *)(v1 + 128);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v56(*(void *)(v1 + 144), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 72)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 152);
    uint64_t v64 = *(void *)(v1 + 128);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v65(*(void *)(v1 + 144), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v71 = *(void *)(v1 + 152);
  uint64_t v72 = *(void *)(v1 + 144);
  long long v73 = *(void *)(v1 + 136);
  long long v70 = *(void *)(v1 + 128);
  uint64_t v66 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 104);
      uint64_t v71 = *(void *)(v1 + 88);
      uint64_t v72 = *(void *)(v1 + 96);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 104);
  uint64_t v74 = *(uint64_t **)(v1 + 88);
  uint64_t v71 = *(void *)(v1 + 96);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[9];
    uint64_t v52 = (void *)v1[10];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[11];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[11];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[11];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[9];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[9] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[13];
    uint64_t v51 = (void *)v49[11];
    uint64_t v52 = (void *)v49[12];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 112) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 128);
  uint64_t v16 = *(void *)(v1 + 104);
  uint64_t v17 = *(void *)(v1 + 120);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 104), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 136) + 32))(*(void *)(v1 + 152), *(void *)(v1 + 104), *(void *)(v1 + 128));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 144);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 152);
    uint64_t v55 = *(void *)(v1 + 128);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v56(*(void *)(v1 + 144), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 72)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 152);
    uint64_t v64 = *(void *)(v1 + 128);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v65(*(void *)(v1 + 144), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v71 = *(void *)(v1 + 152);
  uint64_t v72 = *(void *)(v1 + 144);
  long long v73 = *(void *)(v1 + 136);
  long long v70 = *(void *)(v1 + 128);
  uint64_t v66 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 104);
      uint64_t v71 = *(void *)(v1 + 88);
      uint64_t v72 = *(void *)(v1 + 96);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 104);
  uint64_t v74 = *(uint64_t **)(v1 + 88);
  uint64_t v71 = *(void *)(v1 + 96);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[9];
    uint64_t v52 = (void *)v1[10];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[11];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[11];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[11];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[9];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[9] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[13];
    uint64_t v51 = (void *)v49[11];
    uint64_t v52 = (void *)v49[12];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 112) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 128);
  uint64_t v16 = *(void *)(v1 + 104);
  uint64_t v17 = *(void *)(v1 + 120);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 104), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 136) + 32))(*(void *)(v1 + 152), *(void *)(v1 + 104), *(void *)(v1 + 128));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 144);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 152);
    uint64_t v55 = *(void *)(v1 + 128);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v56(*(void *)(v1 + 144), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 72)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 152);
    uint64_t v64 = *(void *)(v1 + 128);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v65(*(void *)(v1 + 144), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v71 = *(void *)(v1 + 152);
  uint64_t v72 = *(void *)(v1 + 144);
  long long v73 = *(void *)(v1 + 136);
  long long v70 = *(void *)(v1 + 128);
  uint64_t v66 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 104);
      uint64_t v71 = *(void *)(v1 + 88);
      uint64_t v72 = *(void *)(v1 + 96);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 104);
  uint64_t v74 = *(uint64_t **)(v1 + 88);
  uint64_t v71 = *(void *)(v1 + 96);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[9];
    uint64_t v52 = (void *)v1[10];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[11];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[11];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[11];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[9];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[9] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[13];
    uint64_t v51 = (void *)v49[11];
    uint64_t v52 = (void *)v49[12];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 112) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 128);
  uint64_t v16 = *(void *)(v1 + 104);
  uint64_t v17 = *(void *)(v1 + 120);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 104), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 136) + 32))(*(void *)(v1 + 152), *(void *)(v1 + 104), *(void *)(v1 + 128));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 144);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 152);
    uint64_t v55 = *(void *)(v1 + 128);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v56(*(void *)(v1 + 144), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 72)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 152);
    uint64_t v64 = *(void *)(v1 + 128);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v65(*(void *)(v1 + 144), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v71 = *(void *)(v1 + 152);
  uint64_t v72 = *(void *)(v1 + 144);
  long long v73 = *(void *)(v1 + 136);
  long long v70 = *(void *)(v1 + 128);
  uint64_t v66 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 104);
      uint64_t v71 = *(void *)(v1 + 88);
      uint64_t v72 = *(void *)(v1 + 96);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 104);
  uint64_t v74 = *(uint64_t **)(v1 + 88);
  uint64_t v71 = *(void *)(v1 + 96);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[9];
    uint64_t v52 = (void *)v1[10];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[11];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[11];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[11];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[9];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[9] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[13];
    uint64_t v51 = (void *)v49[11];
    uint64_t v52 = (void *)v49[12];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 112) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 128);
  uint64_t v16 = *(void *)(v1 + 104);
  uint64_t v17 = *(void *)(v1 + 120);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 104), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 136) + 32))(*(void *)(v1 + 152), *(void *)(v1 + 104), *(void *)(v1 + 128));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 144);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 152);
    uint64_t v55 = *(void *)(v1 + 128);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v56(*(void *)(v1 + 144), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 72)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 152);
    uint64_t v64 = *(void *)(v1 + 128);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v65(*(void *)(v1 + 144), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v71 = *(void *)(v1 + 152);
  uint64_t v72 = *(void *)(v1 + 144);
  long long v73 = *(void *)(v1 + 136);
  long long v70 = *(void *)(v1 + 128);
  uint64_t v66 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 104);
      uint64_t v71 = *(void *)(v1 + 88);
      uint64_t v72 = *(void *)(v1 + 96);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 104);
  uint64_t v74 = *(uint64_t **)(v1 + 88);
  uint64_t v71 = *(void *)(v1 + 96);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[9];
    uint64_t v52 = (void *)v1[10];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[11];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[11];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[11];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[9];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[9] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[13];
    uint64_t v51 = (void *)v49[11];
    uint64_t v52 = (void *)v49[12];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 112) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 128);
  uint64_t v16 = *(void *)(v1 + 104);
  uint64_t v17 = *(void *)(v1 + 120);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 104), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 136) + 32))(*(void *)(v1 + 152), *(void *)(v1 + 104), *(void *)(v1 + 128));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 144);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 152);
    uint64_t v55 = *(void *)(v1 + 128);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v56(*(void *)(v1 + 144), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 72)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 152);
    uint64_t v64 = *(void *)(v1 + 128);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v65(*(void *)(v1 + 144), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v71 = *(void *)(v1 + 152);
  uint64_t v72 = *(void *)(v1 + 144);
  long long v73 = *(void *)(v1 + 136);
  long long v70 = *(void *)(v1 + 128);
  uint64_t v66 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 104);
      uint64_t v71 = *(void *)(v1 + 88);
      uint64_t v72 = *(void *)(v1 + 96);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 104);
  uint64_t v74 = *(uint64_t **)(v1 + 88);
  uint64_t v71 = *(void *)(v1 + 96);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  char v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  char v50;
  void *v51;
  void *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[8];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[22] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
  v1[23] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void *)(*(int *)(v5 + 44) + v4);
  v1[5] = v6;
  uint64_t v7 = *(void *)(v6 + 16);
  uint64_t v49 = v1;
  uint64_t v47 = v5;
  if (v7)
  {
    uint64_t v51 = (void *)v1[9];
    uint64_t v52 = (void *)v1[10];
    uint64_t v53 = v6 + ((*((unsigned __int8 *)v52 + 80) + 32) & ~*((unsigned __int8 *)v52 + 80));
    swift_bridgeObjectRetain(v6);
    uint64_t v48 = v6;
    while (1)
    {
      if (v7 > *(void *)(v6 + 16)) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[11];
      outlined init with copy of MLTrainingSessionParameters(v53 + v7 * v52[9], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *((int *)v51 + 5)))
      {
        case 0:
          unint64_t v9 = 0xEB0000000064657ALL;
          uint64_t v10 = 0x696C616974696E69;
          goto LABEL_9;
        case 1:
          uint64_t v45 = v1[11];
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
          LODWORD(v53) = 0;
          goto LABEL_14;
        case 2:
          unint64_t v9 = 0xE800000000000000;
          uint64_t v10 = 0x676E696E69617274;
          goto LABEL_9;
        case 3:
          unint64_t v9 = 0xEA0000000000676ELL;
          uint64_t v10 = 0x697461756C617665;
          goto LABEL_9;
        case 4:
          unint64_t v9 = 0xEB00000000676E69;
          uint64_t v10 = 0x636E657265666E69;
LABEL_9:
          uint64_t v11 = v1[11];
          char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v10, v9, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v9);
          uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
          if (v12)
          {
            LODWORD(v53) = 0;
            char v14 = v48;
            goto LABEL_16;
          }
          uint64_t v1 = v49;
          uint64_t v6 = v48;
          if (!v7) {
            goto LABEL_13;
          }
          break;
      }
    }
  }
  uint64_t v13 = swift_bridgeObjectRetain(v6);
LABEL_13:
  LOBYTE(v13) = 1;
  LODWORD(v53) = v13;
  uint64_t v7 = 0;
LABEL_14:
  char v14 = v6;
LABEL_16:
  uint64_t v52 = v49 + 6;
  uint64_t v51 = (void *)v49[9];
  uint64_t v15 = v49[21];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v49 + 5;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))partial apply for specialized closure #1 in BidirectionalCollection.last(where:), v16, v7, v53, (uint64_t)v52);
  swift_bridgeObjectRelease(v14);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, (uint64_t)v51);
  uint64_t v18 = v49[21];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v53 = 0;
  }
  else
  {
    uint64_t v53 = *(void *)(v18 + *(int *)(v49[9] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  uint64_t v51 = (void *)v49[7];
  uint64_t v19 = v49[8];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v49[24] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v52 = *(void **)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v50 = *(unsigned char *)(v46 + *(int *)(v47 + 28));
  uint64_t v22 = ((uint64_t (*)(char *, uint64_t))v52[4])(&v50, v21);
  v49[25] = v22;
  *((unsigned char *)v49 + 256) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v52 = *(void **)(v46 + *(int *)(v47 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v47 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  v49[26] = v25;
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v51;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)((uint64_t)v52, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v49[21];
    uint64_t v30 = v49[20];
    uint64_t v31 = v49[19];
    uint64_t v32 = v49[18];
    uint64_t v33 = v49[15];
    uint64_t v53 = v49[13];
    uint64_t v51 = (void *)v49[11];
    uint64_t v52 = (void *)v49[12];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v53);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    return ((uint64_t (*)(void))v49[1])();
  }
  else
  {
    v49[27] = direct field offset for MLTrainingSession.parameters;
    v49[28] = v53;
    uint64_t v35 = v49[8];
    uint64_t v36 = v49[23];
    uint64_t v37 = (void *)(v35 + v49[24]);
    uint64_t v38 = v35 + v49[22];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    uint64_t v51 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 48);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v49[29] = v44;
    *uint64_t v44 = v49;
    v44[1] = specialized MLTrainingSession.extractFeatures(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t *v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void);
  unint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  void *v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  int *v45;
  uint64_t (*v46)(uint64_t, uint64_t, uint64_t);
  void *v47;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  char v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t, uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  uint64_t v67;
  void (*v68)(uint64_t, int64_t);
  char v69;
  int64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t *v74;
  uint64_t v75;
  uint64_t v76;

  char v76 = v0 | 0x1000000000000000;
  uint64_t v75 = v1;
  uint64_t v2 = *(void *)(v1 + 184);
  uint64_t v3 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 240), v5);
  uint64_t v7 = *(void *)(v1 + 240) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v74 = *(uint64_t **)(v1 + 224);
  uint64_t v8 = *(void *)(v1 + 208);
  unint64_t v9 = *(unsigned char *)(v1 + 256);
  uint64_t v72 = *(void *)(v1 + 56);
  long long v70 = *(void *)(v1 + 200);
  *(void *)(v3 + v4) = v7;
  LODWORD(v73) = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v71 = v2;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v73, v70, v9 & 1, v10, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v10);
  uint64_t v11 = *(void *)(v3 + *(int *)(v71 + 32));
  if (__OFSUB__(v11, v74)) {
    BUG();
  }
  char v12 = (uint64_t *)(v1 + 224);
  uint64_t v13 = *(void *)(v1 + 216) + *(void *)(v1 + 64);
  if (v11 - (uint64_t)v74 < *(void *)(*(int *)(*(void *)(v1 + 112) + 24) + v13)
    && (*(unsigned char *)(v1 + 257) & (*(void *)(v1 + 240) > 0)) == 0)
  {
    char v14 = *(uint64_t **)(v1 + 248);
    goto LABEL_9;
  }
  uint64_t v74 = (uint64_t *)(v1 + 224);
  uint64_t v15 = *(void *)(v1 + 128);
  uint64_t v16 = *(void *)(v1 + 104);
  uint64_t v17 = *(void *)(v1 + 120);
  outlined init with copy of MLTrainingSessionParameters(v13, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v1 + 104), &demangling cache variable for type metadata for URL?);
    char v14 = *(uint64_t **)(v1 + 248);
LABEL_8:
    char v12 = v74;
    goto LABEL_9;
  }
  uint64_t v31 = 0xEB0000000064657ALL;
  uint64_t v32 = *(void *)(v1 + 184);
  uint64_t v33 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  (*(void (**)(void, void, void))(*(void *)(v1 + 136) + 32))(*(void *)(v1 + 152), *(void *)(v1 + 104), *(void *)(v1 + 128));
  uint64_t v34 = *(unsigned __int8 *)(*(int *)(v32 + 28) + v33);
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v36 = (void *)swift_allocObject(v35, 112, 7);
  v36[2] = 2;
  void v36[3] = 4;
  switch(v34)
  {
    case 0:
      uint64_t v37 = 0x696C616974696E69;
      goto LABEL_22;
    case 1:
      uint64_t v49 = 0x6974636172747865;
      goto LABEL_20;
    case 2:
      uint64_t v31 = 0xE800000000000000;
      uint64_t v37 = 0x676E696E69617274;
      goto LABEL_22;
    case 3:
      uint64_t v49 = 0x697461756C617665;
LABEL_20:
      long long v73 = v49;
      uint64_t v31 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v31 = 0xEB00000000676E69;
      uint64_t v37 = 0x636E657265666E69;
LABEL_22:
      long long v73 = v37;
      break;
  }
  uint64_t v71 = *(void *)(v1 + 248);
  uint64_t v72 = *(void *)(v1 + 160);
  long long v70 = *(void *)(v1 + 64);
  char v50 = *(void *)(v1 + 144);
  v36[7] = &type metadata for String;
  v36[8] = lazy protocol witness table accessor for type String and conformance String();
  v36[4] = v73;
  v36[5] = v31;
  v36[12] = &type metadata for Int;
  v36[13] = &protocol witness table for Int;
  v36[9] = v11;
  uint64_t v51 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v36);
  uint64_t v53 = v52;
  URL.appendingPathComponent(_:)(v51, v52);
  swift_bridgeObjectRelease(v53);
  specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(v50, &demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata, (void (*)(void))specialized MLTrainingSession.save());
  if (v71)
  {
    uint64_t v74 = (uint64_t *)v71;
    char v54 = *(void *)(v1 + 152);
    uint64_t v55 = *(void *)(v1 + 128);
    uint64_t v56 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v56(*(void *)(v1 + 144), v55);
    v56(v54, v55);
    goto LABEL_25;
  }
  char v62 = *(void *)(v1 + 160);
  if (__swift_getEnumTagSinglePayload(v62, 1, *(void *)(v1 + 72)) == 1)
  {
    uint64_t v63 = *(void *)(v1 + 152);
    uint64_t v64 = *(void *)(v1 + 128);
    uint64_t v65 = *(void (**)(uint64_t, uint64_t))(*(void *)(v1 + 136) + 8);
    v65(*(void *)(v1 + 144), v64);
    v65(v63, v64);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for MLCheckpoint?);
    char v14 = 0;
    goto LABEL_8;
  }
  uint64_t v74 = *(uint64_t **)(v1 + 184);
  uint64_t v71 = *(void *)(v1 + 152);
  uint64_t v72 = *(void *)(v1 + 144);
  long long v73 = *(void *)(v1 + 136);
  long long v70 = *(void *)(v1 + 128);
  uint64_t v66 = *(void *)(v1 + 96);
  uint64_t v67 = *(void *)(v1 + 176) + *(void *)(v1 + 64);
  outlined init with take of MLClassifierMetrics(v62, v66, type metadata accessor for MLCheckpoint);
  PassthroughSubject.send(_:)(v66);
  outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for MLCheckpoint);
  uint64_t v68 = *(void (**)(uint64_t, int64_t))(v73 + 8);
  v68(v72, v70);
  v68(v71, v70);
  char v12 = (uint64_t *)(v67 + *((int *)v74 + 8));
  char v14 = 0;
LABEL_9:
  if (*(unsigned char *)(v1 + 257) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 64);
    uint64_t v19 = *(void *)(v1 + 192);
    uint64_t v74 = v14;
    uint64_t v20 = (void *)(v19 + v18);
    specialized MLTrainingSession.transition(to:)(2, &demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
    uint64_t v21 = *(void *)(v18 + v19 + 24);
    uint64_t v22 = *(void *)(v18 + v19 + 32);
    uint64_t v69 = 2;
    __swift_project_boxed_opaque_existential_0Tm(v20, v21);
    char v23 = v74;
    (*(void (**)(char *, uint64_t, uint64_t))(v22 + 40))(&v69, v21, v22);
    if (v23)
    {
      uint64_t v74 = v23;
LABEL_25:
      uint64_t v57 = *(void *)(v1 + 168);
      uint64_t v58 = *(void *)(v1 + 160);
      Swift::String v59 = *(void *)(v1 + 152);
      uint64_t v60 = *(void *)(v1 + 144);
      uint64_t v61 = *(void *)(v1 + 120);
      long long v70 = *(void *)(v1 + 104);
      uint64_t v71 = *(void *)(v1 + 88);
      uint64_t v72 = *(void *)(v1 + 96);
      swift_task_dealloc(v57);
      swift_task_dealloc(v58);
      swift_task_dealloc(v59);
      swift_task_dealloc(v60);
      swift_task_dealloc(v61);
      swift_task_dealloc(v70);
      swift_task_dealloc(v72);
      swift_task_dealloc(v71);
      uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
      return v30();
    }
  }
  else
  {
    unsigned int v24 = *v12;
    if (![*(id *)(*(void *)(v1 + 56) + direct field offset for MLJob.progress) isCancelled])
    {
      *(void *)(v1 + 224) = v24;
      uint64_t v38 = *(void *)(v1 + 64);
      uint64_t v39 = *(void *)(v1 + 184);
      uint64_t v40 = (void *)(v38 + *(void *)(v1 + 192));
      uint64_t v41 = v38 + *(void *)(v1 + 176);
      uint64_t v42 = v40[3];
      uint64_t v43 = v40[4];
      uint64_t v74 = __swift_project_boxed_opaque_existential_0Tm(v40, v42);
      uint64_t v44 = *(void *)(*(int *)(v39 + 32) + v41);
      uint64_t v45 = *(int **)(v43 + 48);
      uint64_t v46 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v45 + *v45);
      uint64_t v47 = (void *)swift_task_alloc(v45[1]);
      *(void *)(v1 + 232) = v47;
      *uint64_t v47 = v1;
      v47[1] = specialized MLTrainingSession.extractFeatures(job:);
      return v46(v44, v42, v43);
    }
  }
  uint64_t v25 = *(void *)(v1 + 168);
  uint64_t v26 = *(void *)(v1 + 160);
  int64_t v27 = *(void *)(v1 + 152);
  uint64_t v28 = *(void *)(v1 + 144);
  uint64_t v29 = *(void *)(v1 + 120);
  uint64_t v72 = *(void *)(v1 + 104);
  uint64_t v74 = *(uint64_t **)(v1 + 88);
  uint64_t v71 = *(void *)(v1 + 96);
  swift_task_dealloc(v25);
  swift_task_dealloc(v26);
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v72);
  swift_task_dealloc(v71);
  swift_task_dealloc(v74);
  uint64_t v30 = *(uint64_t (**)(void))(v1 + 8);
  return v30();
}

uint64_t specialized MLTrainingSession.extractFeatures(job:)(uint64_t a1, char a2)
{
  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 112);
  uint64_t v10 = *(void *)(v5 + 72);
  uint64_t v8 = *(void *)(v5 + 88);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 112);
  uint64_t v10 = *(void *)(v5 + 72);
  uint64_t v8 = *(void *)(v5 + 88);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 112);
  uint64_t v10 = *(void *)(v5 + 72);
  uint64_t v8 = *(void *)(v5 + 88);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 112);
  uint64_t v10 = *(void *)(v5 + 72);
  uint64_t v8 = *(void *)(v5 + 88);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 112);
  uint64_t v10 = *(void *)(v5 + 72);
  uint64_t v8 = *(void *)(v5 + 88);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 112);
  uint64_t v10 = *(void *)(v5 + 72);
  uint64_t v8 = *(void *)(v5 + 88);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 104);
  uint64_t v10 = *(void *)(v5 + 88);
  uint64_t v8 = *(void *)(v5 + 96);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 104);
  uint64_t v10 = *(void *)(v5 + 88);
  uint64_t v8 = *(void *)(v5 + 96);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 104);
  uint64_t v10 = *(void *)(v5 + 88);
  uint64_t v8 = *(void *)(v5 + 96);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 104);
  uint64_t v10 = *(void *)(v5 + 88);
  uint64_t v8 = *(void *)(v5 + 96);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 104);
  uint64_t v10 = *(void *)(v5 + 88);
  uint64_t v8 = *(void *)(v5 + 96);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 104);
  uint64_t v10 = *(void *)(v5 + 88);
  uint64_t v8 = *(void *)(v5 + 96);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 104);
  uint64_t v10 = *(void *)(v5 + 88);
  uint64_t v8 = *(void *)(v5 + 96);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 104);
  uint64_t v10 = *(void *)(v5 + 88);
  uint64_t v8 = *(void *)(v5 + 96);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 104);
  uint64_t v10 = *(void *)(v5 + 88);
  uint64_t v8 = *(void *)(v5 + 96);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 104);
  uint64_t v10 = *(void *)(v5 + 88);
  uint64_t v8 = *(void *)(v5 + 96);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v4 = *(void *)(*v3 + 232);
  uint64_t v5 = *v3;
  *(void *)(v5 + 240) = a1;
  *(unsigned char *)(v5 + 257) = a2 & 1;
  *(void *)(v5 + 248) = v2;
  swift_task_dealloc(v4);
  if (!v2) {
    return swift_task_switch(specialized MLTrainingSession.extractFeatures(job:), 0, 0);
  }
  uint64_t v6 = *(void *)(v5 + 160);
  uint64_t v7 = *(void *)(v5 + 152);
  uint64_t v13 = *(void *)(v5 + 144);
  uint64_t v12 = *(void *)(v5 + 120);
  uint64_t v11 = *(void *)(v5 + 104);
  uint64_t v10 = *(void *)(v5 + 88);
  uint64_t v8 = *(void *)(v5 + 96);
  swift_task_dealloc(*(void *)(v5 + 168));
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v8);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v5 + 8))();
}

uint64_t specialized MLTrainingSession.train(job:)(uint64_t a1)
{
  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[16] = v6;
  v2[17] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for URL(0);
  v2[18] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  v2[19] = v8;
  unint64_t v9 = (*(void *)(v8 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v9);
  v2[21] = swift_task_alloc(v9);
  v2[22] = swift_task_alloc(v9);
  uint64_t v10 = type metadata accessor for MLCheckpoint(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[16] = v6;
  v2[17] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for URL(0);
  v2[18] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  v2[19] = v8;
  unint64_t v9 = (*(void *)(v8 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v9);
  v2[21] = swift_task_alloc(v9);
  v2[22] = swift_task_alloc(v9);
  uint64_t v10 = type metadata accessor for MLCheckpoint(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[16] = v6;
  v2[17] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for URL(0);
  v2[18] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  v2[19] = v8;
  unint64_t v9 = (*(void *)(v8 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v9);
  v2[21] = swift_task_alloc(v9);
  v2[22] = swift_task_alloc(v9);
  uint64_t v10 = type metadata accessor for MLCheckpoint(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[16] = v6;
  v2[17] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for URL(0);
  v2[18] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  v2[19] = v8;
  unint64_t v9 = (*(void *)(v8 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v9);
  v2[21] = swift_task_alloc(v9);
  v2[22] = swift_task_alloc(v9);
  uint64_t v10 = type metadata accessor for MLCheckpoint(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[16] = v6;
  v2[17] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for URL(0);
  v2[18] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  v2[19] = v8;
  unint64_t v9 = (*(void *)(v8 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v9);
  v2[21] = swift_task_alloc(v9);
  v2[22] = swift_task_alloc(v9);
  uint64_t v10 = type metadata accessor for MLCheckpoint(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  unint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[15] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[16] = v6;
  v2[17] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for URL(0);
  v2[18] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  v2[19] = v8;
  unint64_t v9 = (*(void *)(v8 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[20] = swift_task_alloc(v9);
  v2[21] = swift_task_alloc(v9);
  v2[22] = swift_task_alloc(v9);
  uint64_t v10 = type metadata accessor for MLCheckpoint(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLCheckpoint(0);
  v2[15] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[16] = v6;
  uint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[17] = swift_task_alloc(v7);
  v2[18] = swift_task_alloc(v7);
  v2[19] = swift_task_alloc(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[20] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v9 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[21] = v9;
  v2[22] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for URL(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLCheckpoint(0);
  v2[15] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[16] = v6;
  uint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[17] = swift_task_alloc(v7);
  v2[18] = swift_task_alloc(v7);
  v2[19] = swift_task_alloc(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[20] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v9 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[21] = v9;
  v2[22] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for URL(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLCheckpoint(0);
  v2[15] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[16] = v6;
  uint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[17] = swift_task_alloc(v7);
  v2[18] = swift_task_alloc(v7);
  v2[19] = swift_task_alloc(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[20] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v9 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[21] = v9;
  v2[22] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for URL(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLCheckpoint(0);
  v2[15] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[16] = v6;
  uint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[17] = swift_task_alloc(v7);
  v2[18] = swift_task_alloc(v7);
  v2[19] = swift_task_alloc(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[20] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v9 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[21] = v9;
  v2[22] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for URL(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLCheckpoint(0);
  v2[15] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[16] = v6;
  uint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[17] = swift_task_alloc(v7);
  v2[18] = swift_task_alloc(v7);
  v2[19] = swift_task_alloc(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[20] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v9 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[21] = v9;
  v2[22] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for URL(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLCheckpoint(0);
  v2[15] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[16] = v6;
  uint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[17] = swift_task_alloc(v7);
  v2[18] = swift_task_alloc(v7);
  v2[19] = swift_task_alloc(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[20] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v9 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[21] = v9;
  v2[22] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for URL(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLCheckpoint(0);
  v2[15] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[16] = v6;
  uint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[17] = swift_task_alloc(v7);
  v2[18] = swift_task_alloc(v7);
  v2[19] = swift_task_alloc(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[20] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v9 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[21] = v9;
  v2[22] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for URL(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLCheckpoint(0);
  v2[15] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[16] = v6;
  uint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[17] = swift_task_alloc(v7);
  v2[18] = swift_task_alloc(v7);
  v2[19] = swift_task_alloc(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[20] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v9 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[21] = v9;
  v2[22] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for URL(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLCheckpoint(0);
  v2[15] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[16] = v6;
  uint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[17] = swift_task_alloc(v7);
  v2[18] = swift_task_alloc(v7);
  v2[19] = swift_task_alloc(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[20] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v9 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[21] = v9;
  v2[22] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for URL(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLCheckpoint(0);
  v2[15] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[16] = v6;
  uint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[17] = swift_task_alloc(v7);
  v2[18] = swift_task_alloc(v7);
  v2[19] = swift_task_alloc(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[20] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v9 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[21] = v9;
  v2[22] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for URL(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v12;
  uint64_t v13;

  v2[11] = v1;
  v2[10] = a1;
  uint64_t v3 = type metadata accessor for Date(0);
  v2[12] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[13] = v4;
  v2[14] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLCheckpoint(0);
  v2[15] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[16] = v6;
  uint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[17] = swift_task_alloc(v7);
  v2[18] = swift_task_alloc(v7);
  v2[19] = swift_task_alloc(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v2[20] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v9 = type metadata accessor for MLTrainingSessionParameters(0);
  v2[21] = v9;
  v2[22] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for URL(0);
  v2[23] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[24] = v11;
  unint64_t v12 = (*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[25] = swift_task_alloc(v12);
  v2[26] = swift_task_alloc(v12);
  v2[27] = swift_task_alloc(v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
}

uint64_t specialized MLTrainingSession.train(job:)()
{
  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[23];
    uint64_t v51 = (void *)v1[24];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[27];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[27];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[27];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[23];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[23] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[21];
    uint64_t v52 = (char *)v48[20];
    uint64_t v51 = (void *)v48[17];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[15];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(unsigned char *, uint64_t, uint64_t);
  unsigned char *v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  int *v90;
  uint64_t v91;
  uint64_t v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  void *v99;
  uint64_t v100;
  char v101;
  unint64_t v102;
  uint64_t v103;
  void *v104;
  unsigned char *v105;
  int *v106;
  void *v107;
  char v108;
  uint64_t v109;
  uint64_t v110;

  uint64_t v110 = v0 | 0x1000000000000000;
  uint64_t v109 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 128) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v107 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v107 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 144);
  uint64_t v16 = *(void *)(v1 + 120);
  uint64_t v17 = *(void *)(v1 + 136);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 120);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v106 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 152) + 32))(*(void *)(v1 + 176), *(void *)(v1 + 120), *(void *)(v1 + 144));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v102 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v102 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v102 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v102 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v104 = *(void **)(v1 + 304);
  uint64_t v94 = *(void *)(v1 + 248);
  unint64_t v103 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v97 = *(void *)(v1 + 168);
  uint64_t v99 = (void *)(v53 + v94);
  uint64_t v105 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v102;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v107;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v94 + 24);
  uint64_t v58 = *(void *)(v53 + v94 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v99, v57);
  Swift::String v59 = v103;
  uint64_t v60 = v105;
  *(unsigned char *)(v1 + 312) = v105[*(int *)(v103 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v97, v106, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v104)
  {
    uint64_t v107 = v104;
    char v62 = *(void *)(v1 + 176);
    uint64_t v63 = *(void *)(v1 + 168);
    uint64_t v64 = *(void *)(v1 + 144);
    uint64_t v65 = *(void *)(v1 + 152);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v104 = (void *)(v1 + 40);
    uint64_t v106 = *(int **)(v1 + 240);
    unint64_t v103 = *(void *)(v1 + 208);
    long long v73 = *(void *)(v1 + 200);
    uint64_t v95 = *(void *)(v1 + 192);
    uint64_t v90 = *(int **)(v1 + 184);
    uint64_t v74 = *(void *)(v1 + 168);
    uint64_t v105 = *(unsigned char **)(v1 + 160);
    uint64_t v92 = *(void *)(v1 + 152);
    uint64_t v107 = 0;
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v102 = *(void *)(v1 + 104);
    uint64_t v98 = *(void *)(v1 + 96);
    char v77 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v92 + 16);
    uint64_t v96 = v72;
    v77(v105, v74, v75);
    uint64_t v108 = *(unsigned char *)(v106[7] + v76);
    int64_t v93 = *(void *)(v106[8] + v76);
    v77((unsigned char *)v73, (uint64_t)v105, v75);
    *(unsigned char *)(v73 + v90[5]) = v108;
    *(void *)(v73 + v90[6]) = v93;
    Date.init()(v73);
    uint64_t v78 = v105;
    uint64_t v105 = *(unsigned char **)(v92 + 8);
    ((void (*)(unsigned char *, uint64_t))v105)(v78, v75);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v102 + 32))(v73 + v90[7], v91, v98);
    *(void *)(v73 + v90[8]) = v96;
    outlined init with take of MLClassifierMetrics(v73, v103, type metadata accessor for MLCheckpoint);
    uint64_t v79 = v76;
    swift_beginAccess(v76, v104, 33, 0);
    uint64_t v80 = v106[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v79) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v79);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v103, v82 + ((*(unsigned __int8 *)(v95 + 80) + 32) & ~*(unsigned __int8 *)(v95 + 80)) + *(void *)(v95 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v104);
    uint64_t v25 = *(void *)(v106[8] + v79);
    specialized MLTrainingSession.save()();
    uint64_t v83 = *(void *)(v1 + 208);
    uint64_t v106 = *(int **)(v1 + 176);
    uint64_t v84 = *(void *)(v1 + 144);
    uint64_t v104 = *(void **)(v1 + 168);
    if (v107)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v105)(v104, v84);
      ((void (*)(int *, uint64_t))v105)(v106, v84);
      goto LABEL_29;
    }
    PassthroughSubject.send(_:)(v83);
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v105)(v104, v84);
    ((void (*)(int *, uint64_t))v105)(v106, v84);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 176);
    uint64_t v86 = *(void *)(v1 + 168);
    uint64_t v87 = *(void *)(v1 + 144);
    uint64_t v88 = *(void *)(v1 + 152);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v107 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  uint64_t v101 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v107;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v101, v33, v34);
  if (v35)
  {
    uint64_t v107 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v100 = *(void *)(v1 + 168);
    uint64_t v105 = *(unsigned char **)(v1 + 160);
    unint64_t v103 = *(void *)(v1 + 136);
    uint64_t v106 = *(int **)(v1 + 112);
    uint64_t v104 = *(void **)(v1 + 120);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v100);
    swift_task_dealloc(v105);
    swift_task_dealloc(v103);
    swift_task_dealloc(v104);
    swift_task_dealloc(v106);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v105 = *(unsigned char **)(v1 + 168);
  unint64_t v103 = *(void *)(v1 + 160);
  uint64_t v104 = *(void **)(v1 + 136);
  uint64_t v107 = *(void **)(v1 + 112);
  uint64_t v106 = *(int **)(v1 + 120);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v105);
  swift_task_dealloc(v103);
  swift_task_dealloc(v104);
  swift_task_dealloc(v106);
  swift_task_dealloc(v107);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[23];
    uint64_t v51 = (void *)v1[24];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[27];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[27];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[27];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[23];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[23] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[21];
    uint64_t v52 = (char *)v48[20];
    uint64_t v51 = (void *)v48[17];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[15];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(unsigned char *, uint64_t, uint64_t);
  unsigned char *v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  int *v90;
  uint64_t v91;
  uint64_t v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  void *v99;
  uint64_t v100;
  char v101;
  unint64_t v102;
  uint64_t v103;
  void *v104;
  unsigned char *v105;
  int *v106;
  void *v107;
  char v108;
  uint64_t v109;
  uint64_t v110;

  uint64_t v110 = v0 | 0x1000000000000000;
  uint64_t v109 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 128) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v107 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v107 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 144);
  uint64_t v16 = *(void *)(v1 + 120);
  uint64_t v17 = *(void *)(v1 + 136);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 120);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v106 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 152) + 32))(*(void *)(v1 + 176), *(void *)(v1 + 120), *(void *)(v1 + 144));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v102 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v102 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v102 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v102 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v104 = *(void **)(v1 + 304);
  uint64_t v94 = *(void *)(v1 + 248);
  unint64_t v103 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v97 = *(void *)(v1 + 168);
  uint64_t v99 = (void *)(v53 + v94);
  uint64_t v105 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v102;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v107;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v94 + 24);
  uint64_t v58 = *(void *)(v53 + v94 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v99, v57);
  Swift::String v59 = v103;
  uint64_t v60 = v105;
  *(unsigned char *)(v1 + 312) = v105[*(int *)(v103 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v97, v106, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v104)
  {
    uint64_t v107 = v104;
    char v62 = *(void *)(v1 + 176);
    uint64_t v63 = *(void *)(v1 + 168);
    uint64_t v64 = *(void *)(v1 + 144);
    uint64_t v65 = *(void *)(v1 + 152);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v104 = (void *)(v1 + 40);
    uint64_t v106 = *(int **)(v1 + 240);
    unint64_t v103 = *(void *)(v1 + 208);
    long long v73 = *(void *)(v1 + 200);
    uint64_t v95 = *(void *)(v1 + 192);
    uint64_t v90 = *(int **)(v1 + 184);
    uint64_t v74 = *(void *)(v1 + 168);
    uint64_t v105 = *(unsigned char **)(v1 + 160);
    uint64_t v92 = *(void *)(v1 + 152);
    uint64_t v107 = 0;
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v102 = *(void *)(v1 + 104);
    uint64_t v98 = *(void *)(v1 + 96);
    char v77 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v92 + 16);
    uint64_t v96 = v72;
    v77(v105, v74, v75);
    uint64_t v108 = *(unsigned char *)(v106[7] + v76);
    int64_t v93 = *(void *)(v106[8] + v76);
    v77((unsigned char *)v73, (uint64_t)v105, v75);
    *(unsigned char *)(v73 + v90[5]) = v108;
    *(void *)(v73 + v90[6]) = v93;
    Date.init()(v73);
    uint64_t v78 = v105;
    uint64_t v105 = *(unsigned char **)(v92 + 8);
    ((void (*)(unsigned char *, uint64_t))v105)(v78, v75);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v102 + 32))(v73 + v90[7], v91, v98);
    *(void *)(v73 + v90[8]) = v96;
    outlined init with take of MLClassifierMetrics(v73, v103, type metadata accessor for MLCheckpoint);
    uint64_t v79 = v76;
    swift_beginAccess(v76, v104, 33, 0);
    uint64_t v80 = v106[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v79) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v79);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v103, v82 + ((*(unsigned __int8 *)(v95 + 80) + 32) & ~*(unsigned __int8 *)(v95 + 80)) + *(void *)(v95 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v104);
    uint64_t v25 = *(void *)(v106[8] + v79);
    specialized MLTrainingSession.save()();
    uint64_t v83 = *(void *)(v1 + 208);
    uint64_t v106 = *(int **)(v1 + 176);
    uint64_t v84 = *(void *)(v1 + 144);
    uint64_t v104 = *(void **)(v1 + 168);
    if (v107)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v105)(v104, v84);
      ((void (*)(int *, uint64_t))v105)(v106, v84);
      goto LABEL_29;
    }
    PassthroughSubject.send(_:)(v83);
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v105)(v104, v84);
    ((void (*)(int *, uint64_t))v105)(v106, v84);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 176);
    uint64_t v86 = *(void *)(v1 + 168);
    uint64_t v87 = *(void *)(v1 + 144);
    uint64_t v88 = *(void *)(v1 + 152);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v107 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  uint64_t v101 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v107;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v101, v33, v34);
  if (v35)
  {
    uint64_t v107 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v100 = *(void *)(v1 + 168);
    uint64_t v105 = *(unsigned char **)(v1 + 160);
    unint64_t v103 = *(void *)(v1 + 136);
    uint64_t v106 = *(int **)(v1 + 112);
    uint64_t v104 = *(void **)(v1 + 120);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v100);
    swift_task_dealloc(v105);
    swift_task_dealloc(v103);
    swift_task_dealloc(v104);
    swift_task_dealloc(v106);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v105 = *(unsigned char **)(v1 + 168);
  unint64_t v103 = *(void *)(v1 + 160);
  uint64_t v104 = *(void **)(v1 + 136);
  uint64_t v107 = *(void **)(v1 + 112);
  uint64_t v106 = *(int **)(v1 + 120);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v105);
  swift_task_dealloc(v103);
  swift_task_dealloc(v104);
  swift_task_dealloc(v106);
  swift_task_dealloc(v107);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[23];
    uint64_t v51 = (void *)v1[24];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[27];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[27];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[27];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[23];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[23] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[21];
    uint64_t v52 = (char *)v48[20];
    uint64_t v51 = (void *)v48[17];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[15];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(unsigned char *, uint64_t, uint64_t);
  unsigned char *v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  int *v90;
  uint64_t v91;
  uint64_t v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  void *v99;
  uint64_t v100;
  char v101;
  unint64_t v102;
  uint64_t v103;
  void *v104;
  unsigned char *v105;
  int *v106;
  void *v107;
  char v108;
  uint64_t v109;
  uint64_t v110;

  uint64_t v110 = v0 | 0x1000000000000000;
  uint64_t v109 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 128) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v107 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v107 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 144);
  uint64_t v16 = *(void *)(v1 + 120);
  uint64_t v17 = *(void *)(v1 + 136);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 120);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v106 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 152) + 32))(*(void *)(v1 + 176), *(void *)(v1 + 120), *(void *)(v1 + 144));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v102 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v102 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v102 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v102 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v104 = *(void **)(v1 + 304);
  uint64_t v94 = *(void *)(v1 + 248);
  unint64_t v103 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v97 = *(void *)(v1 + 168);
  uint64_t v99 = (void *)(v53 + v94);
  uint64_t v105 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v102;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v107;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v94 + 24);
  uint64_t v58 = *(void *)(v53 + v94 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v99, v57);
  Swift::String v59 = v103;
  uint64_t v60 = v105;
  *(unsigned char *)(v1 + 312) = v105[*(int *)(v103 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v97, v106, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v104)
  {
    uint64_t v107 = v104;
    char v62 = *(void *)(v1 + 176);
    uint64_t v63 = *(void *)(v1 + 168);
    uint64_t v64 = *(void *)(v1 + 144);
    uint64_t v65 = *(void *)(v1 + 152);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v104 = (void *)(v1 + 40);
    uint64_t v106 = *(int **)(v1 + 240);
    unint64_t v103 = *(void *)(v1 + 208);
    long long v73 = *(void *)(v1 + 200);
    uint64_t v95 = *(void *)(v1 + 192);
    uint64_t v90 = *(int **)(v1 + 184);
    uint64_t v74 = *(void *)(v1 + 168);
    uint64_t v105 = *(unsigned char **)(v1 + 160);
    uint64_t v92 = *(void *)(v1 + 152);
    uint64_t v107 = 0;
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v102 = *(void *)(v1 + 104);
    uint64_t v98 = *(void *)(v1 + 96);
    char v77 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v92 + 16);
    uint64_t v96 = v72;
    v77(v105, v74, v75);
    uint64_t v108 = *(unsigned char *)(v106[7] + v76);
    int64_t v93 = *(void *)(v106[8] + v76);
    v77((unsigned char *)v73, (uint64_t)v105, v75);
    *(unsigned char *)(v73 + v90[5]) = v108;
    *(void *)(v73 + v90[6]) = v93;
    Date.init()(v73);
    uint64_t v78 = v105;
    uint64_t v105 = *(unsigned char **)(v92 + 8);
    ((void (*)(unsigned char *, uint64_t))v105)(v78, v75);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v102 + 32))(v73 + v90[7], v91, v98);
    *(void *)(v73 + v90[8]) = v96;
    outlined init with take of MLClassifierMetrics(v73, v103, type metadata accessor for MLCheckpoint);
    uint64_t v79 = v76;
    swift_beginAccess(v76, v104, 33, 0);
    uint64_t v80 = v106[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v79) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v79);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v103, v82 + ((*(unsigned __int8 *)(v95 + 80) + 32) & ~*(unsigned __int8 *)(v95 + 80)) + *(void *)(v95 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v104);
    uint64_t v25 = *(void *)(v106[8] + v79);
    specialized MLTrainingSession.save()();
    uint64_t v83 = *(void *)(v1 + 208);
    uint64_t v106 = *(int **)(v1 + 176);
    uint64_t v84 = *(void *)(v1 + 144);
    uint64_t v104 = *(void **)(v1 + 168);
    if (v107)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v105)(v104, v84);
      ((void (*)(int *, uint64_t))v105)(v106, v84);
      goto LABEL_29;
    }
    PassthroughSubject.send(_:)(v83);
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v105)(v104, v84);
    ((void (*)(int *, uint64_t))v105)(v106, v84);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 176);
    uint64_t v86 = *(void *)(v1 + 168);
    uint64_t v87 = *(void *)(v1 + 144);
    uint64_t v88 = *(void *)(v1 + 152);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v107 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  uint64_t v101 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v107;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v101, v33, v34);
  if (v35)
  {
    uint64_t v107 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v100 = *(void *)(v1 + 168);
    uint64_t v105 = *(unsigned char **)(v1 + 160);
    unint64_t v103 = *(void *)(v1 + 136);
    uint64_t v106 = *(int **)(v1 + 112);
    uint64_t v104 = *(void **)(v1 + 120);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v100);
    swift_task_dealloc(v105);
    swift_task_dealloc(v103);
    swift_task_dealloc(v104);
    swift_task_dealloc(v106);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v105 = *(unsigned char **)(v1 + 168);
  unint64_t v103 = *(void *)(v1 + 160);
  uint64_t v104 = *(void **)(v1 + 136);
  uint64_t v107 = *(void **)(v1 + 112);
  uint64_t v106 = *(int **)(v1 + 120);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v105);
  swift_task_dealloc(v103);
  swift_task_dealloc(v104);
  swift_task_dealloc(v106);
  swift_task_dealloc(v107);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[23];
    uint64_t v51 = (void *)v1[24];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[27];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[27];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[27];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[23];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[23] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[21];
    uint64_t v52 = (char *)v48[20];
    uint64_t v51 = (void *)v48[17];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[15];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(unsigned char *, uint64_t, uint64_t);
  unsigned char *v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  int *v90;
  uint64_t v91;
  uint64_t v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  void *v99;
  uint64_t v100;
  char v101;
  unint64_t v102;
  uint64_t v103;
  void *v104;
  unsigned char *v105;
  int *v106;
  void *v107;
  char v108;
  uint64_t v109;
  uint64_t v110;

  uint64_t v110 = v0 | 0x1000000000000000;
  uint64_t v109 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 128) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v107 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v107 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 144);
  uint64_t v16 = *(void *)(v1 + 120);
  uint64_t v17 = *(void *)(v1 + 136);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 120);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v106 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 152) + 32))(*(void *)(v1 + 176), *(void *)(v1 + 120), *(void *)(v1 + 144));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v102 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v102 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v102 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v102 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v104 = *(void **)(v1 + 304);
  uint64_t v94 = *(void *)(v1 + 248);
  unint64_t v103 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v97 = *(void *)(v1 + 168);
  uint64_t v99 = (void *)(v53 + v94);
  uint64_t v105 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v102;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v107;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v94 + 24);
  uint64_t v58 = *(void *)(v53 + v94 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v99, v57);
  Swift::String v59 = v103;
  uint64_t v60 = v105;
  *(unsigned char *)(v1 + 312) = v105[*(int *)(v103 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v97, v106, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v104)
  {
    uint64_t v107 = v104;
    char v62 = *(void *)(v1 + 176);
    uint64_t v63 = *(void *)(v1 + 168);
    uint64_t v64 = *(void *)(v1 + 144);
    uint64_t v65 = *(void *)(v1 + 152);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v104 = (void *)(v1 + 40);
    uint64_t v106 = *(int **)(v1 + 240);
    unint64_t v103 = *(void *)(v1 + 208);
    long long v73 = *(void *)(v1 + 200);
    uint64_t v95 = *(void *)(v1 + 192);
    uint64_t v90 = *(int **)(v1 + 184);
    uint64_t v74 = *(void *)(v1 + 168);
    uint64_t v105 = *(unsigned char **)(v1 + 160);
    uint64_t v92 = *(void *)(v1 + 152);
    uint64_t v107 = 0;
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v102 = *(void *)(v1 + 104);
    uint64_t v98 = *(void *)(v1 + 96);
    char v77 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v92 + 16);
    uint64_t v96 = v72;
    v77(v105, v74, v75);
    uint64_t v108 = *(unsigned char *)(v106[7] + v76);
    int64_t v93 = *(void *)(v106[8] + v76);
    v77((unsigned char *)v73, (uint64_t)v105, v75);
    *(unsigned char *)(v73 + v90[5]) = v108;
    *(void *)(v73 + v90[6]) = v93;
    Date.init()(v73);
    uint64_t v78 = v105;
    uint64_t v105 = *(unsigned char **)(v92 + 8);
    ((void (*)(unsigned char *, uint64_t))v105)(v78, v75);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v102 + 32))(v73 + v90[7], v91, v98);
    *(void *)(v73 + v90[8]) = v96;
    outlined init with take of MLClassifierMetrics(v73, v103, type metadata accessor for MLCheckpoint);
    uint64_t v79 = v76;
    swift_beginAccess(v76, v104, 33, 0);
    uint64_t v80 = v106[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v79) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v79);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v103, v82 + ((*(unsigned __int8 *)(v95 + 80) + 32) & ~*(unsigned __int8 *)(v95 + 80)) + *(void *)(v95 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v104);
    uint64_t v25 = *(void *)(v106[8] + v79);
    specialized MLTrainingSession.save()();
    uint64_t v83 = *(void *)(v1 + 208);
    uint64_t v106 = *(int **)(v1 + 176);
    uint64_t v84 = *(void *)(v1 + 144);
    uint64_t v104 = *(void **)(v1 + 168);
    if (v107)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v105)(v104, v84);
      ((void (*)(int *, uint64_t))v105)(v106, v84);
      goto LABEL_29;
    }
    PassthroughSubject.send(_:)(v83);
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v105)(v104, v84);
    ((void (*)(int *, uint64_t))v105)(v106, v84);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 176);
    uint64_t v86 = *(void *)(v1 + 168);
    uint64_t v87 = *(void *)(v1 + 144);
    uint64_t v88 = *(void *)(v1 + 152);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v107 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  uint64_t v101 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v107;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v101, v33, v34);
  if (v35)
  {
    uint64_t v107 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v100 = *(void *)(v1 + 168);
    uint64_t v105 = *(unsigned char **)(v1 + 160);
    unint64_t v103 = *(void *)(v1 + 136);
    uint64_t v106 = *(int **)(v1 + 112);
    uint64_t v104 = *(void **)(v1 + 120);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v100);
    swift_task_dealloc(v105);
    swift_task_dealloc(v103);
    swift_task_dealloc(v104);
    swift_task_dealloc(v106);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v105 = *(unsigned char **)(v1 + 168);
  unint64_t v103 = *(void *)(v1 + 160);
  uint64_t v104 = *(void **)(v1 + 136);
  uint64_t v107 = *(void **)(v1 + 112);
  uint64_t v106 = *(int **)(v1 + 120);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v105);
  swift_task_dealloc(v103);
  swift_task_dealloc(v104);
  swift_task_dealloc(v106);
  swift_task_dealloc(v107);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[23];
    uint64_t v51 = (void *)v1[24];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[27];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[27];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[27];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[23];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[23] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[21];
    uint64_t v52 = (char *)v48[20];
    uint64_t v51 = (void *)v48[17];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[15];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(unsigned char *, uint64_t, uint64_t);
  unsigned char *v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  int *v90;
  uint64_t v91;
  uint64_t v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  void *v99;
  uint64_t v100;
  char v101;
  unint64_t v102;
  uint64_t v103;
  void *v104;
  unsigned char *v105;
  int *v106;
  void *v107;
  char v108;
  uint64_t v109;
  uint64_t v110;

  uint64_t v110 = v0 | 0x1000000000000000;
  uint64_t v109 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 128) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v107 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v107 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 144);
  uint64_t v16 = *(void *)(v1 + 120);
  uint64_t v17 = *(void *)(v1 + 136);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 120);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v106 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 152) + 32))(*(void *)(v1 + 176), *(void *)(v1 + 120), *(void *)(v1 + 144));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v102 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v102 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v102 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v102 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v104 = *(void **)(v1 + 304);
  uint64_t v94 = *(void *)(v1 + 248);
  unint64_t v103 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v97 = *(void *)(v1 + 168);
  uint64_t v99 = (void *)(v53 + v94);
  uint64_t v105 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v102;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v107;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v94 + 24);
  uint64_t v58 = *(void *)(v53 + v94 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v99, v57);
  Swift::String v59 = v103;
  uint64_t v60 = v105;
  *(unsigned char *)(v1 + 312) = v105[*(int *)(v103 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v97, v106, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v104)
  {
    uint64_t v107 = v104;
    char v62 = *(void *)(v1 + 176);
    uint64_t v63 = *(void *)(v1 + 168);
    uint64_t v64 = *(void *)(v1 + 144);
    uint64_t v65 = *(void *)(v1 + 152);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v104 = (void *)(v1 + 40);
    uint64_t v106 = *(int **)(v1 + 240);
    unint64_t v103 = *(void *)(v1 + 208);
    long long v73 = *(void *)(v1 + 200);
    uint64_t v95 = *(void *)(v1 + 192);
    uint64_t v90 = *(int **)(v1 + 184);
    uint64_t v74 = *(void *)(v1 + 168);
    uint64_t v105 = *(unsigned char **)(v1 + 160);
    uint64_t v92 = *(void *)(v1 + 152);
    uint64_t v107 = 0;
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v102 = *(void *)(v1 + 104);
    uint64_t v98 = *(void *)(v1 + 96);
    char v77 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v92 + 16);
    uint64_t v96 = v72;
    v77(v105, v74, v75);
    uint64_t v108 = *(unsigned char *)(v106[7] + v76);
    int64_t v93 = *(void *)(v106[8] + v76);
    v77((unsigned char *)v73, (uint64_t)v105, v75);
    *(unsigned char *)(v73 + v90[5]) = v108;
    *(void *)(v73 + v90[6]) = v93;
    Date.init()(v73);
    uint64_t v78 = v105;
    uint64_t v105 = *(unsigned char **)(v92 + 8);
    ((void (*)(unsigned char *, uint64_t))v105)(v78, v75);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v102 + 32))(v73 + v90[7], v91, v98);
    *(void *)(v73 + v90[8]) = v96;
    outlined init with take of MLClassifierMetrics(v73, v103, type metadata accessor for MLCheckpoint);
    uint64_t v79 = v76;
    swift_beginAccess(v76, v104, 33, 0);
    uint64_t v80 = v106[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v79) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v79);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v103, v82 + ((*(unsigned __int8 *)(v95 + 80) + 32) & ~*(unsigned __int8 *)(v95 + 80)) + *(void *)(v95 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v104);
    uint64_t v25 = *(void *)(v106[8] + v79);
    specialized MLTrainingSession.save()();
    uint64_t v83 = *(void *)(v1 + 208);
    uint64_t v106 = *(int **)(v1 + 176);
    uint64_t v84 = *(void *)(v1 + 144);
    uint64_t v104 = *(void **)(v1 + 168);
    if (v107)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v105)(v104, v84);
      ((void (*)(int *, uint64_t))v105)(v106, v84);
      goto LABEL_29;
    }
    PassthroughSubject.send(_:)(v83);
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v105)(v104, v84);
    ((void (*)(int *, uint64_t))v105)(v106, v84);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 176);
    uint64_t v86 = *(void *)(v1 + 168);
    uint64_t v87 = *(void *)(v1 + 144);
    uint64_t v88 = *(void *)(v1 + 152);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v107 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  uint64_t v101 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v107;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v101, v33, v34);
  if (v35)
  {
    uint64_t v107 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v100 = *(void *)(v1 + 168);
    uint64_t v105 = *(unsigned char **)(v1 + 160);
    unint64_t v103 = *(void *)(v1 + 136);
    uint64_t v106 = *(int **)(v1 + 112);
    uint64_t v104 = *(void **)(v1 + 120);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v100);
    swift_task_dealloc(v105);
    swift_task_dealloc(v103);
    swift_task_dealloc(v104);
    swift_task_dealloc(v106);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v105 = *(unsigned char **)(v1 + 168);
  unint64_t v103 = *(void *)(v1 + 160);
  uint64_t v104 = *(void **)(v1 + 136);
  uint64_t v107 = *(void **)(v1 + 112);
  uint64_t v106 = *(int **)(v1 + 120);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v105);
  swift_task_dealloc(v103);
  swift_task_dealloc(v104);
  swift_task_dealloc(v106);
  swift_task_dealloc(v107);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[23];
    uint64_t v51 = (void *)v1[24];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[27];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[27];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[27];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[23];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[23] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[21];
    uint64_t v52 = (char *)v48[20];
    uint64_t v51 = (void *)v48[17];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[15];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(unsigned char *, uint64_t, uint64_t);
  unsigned char *v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  int *v90;
  uint64_t v91;
  uint64_t v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  void *v99;
  uint64_t v100;
  char v101;
  unint64_t v102;
  uint64_t v103;
  void *v104;
  unsigned char *v105;
  int *v106;
  void *v107;
  char v108;
  uint64_t v109;
  uint64_t v110;

  uint64_t v110 = v0 | 0x1000000000000000;
  uint64_t v109 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 128) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v107 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v107 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 144);
  uint64_t v16 = *(void *)(v1 + 120);
  uint64_t v17 = *(void *)(v1 + 136);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 120);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v106 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 152) + 32))(*(void *)(v1 + 176), *(void *)(v1 + 120), *(void *)(v1 + 144));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v102 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v102 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v102 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v102 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v104 = *(void **)(v1 + 304);
  uint64_t v94 = *(void *)(v1 + 248);
  unint64_t v103 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v97 = *(void *)(v1 + 168);
  uint64_t v99 = (void *)(v53 + v94);
  uint64_t v105 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v102;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v107;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v94 + 24);
  uint64_t v58 = *(void *)(v53 + v94 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v99, v57);
  Swift::String v59 = v103;
  uint64_t v60 = v105;
  *(unsigned char *)(v1 + 312) = v105[*(int *)(v103 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v97, v106, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v104)
  {
    uint64_t v107 = v104;
    char v62 = *(void *)(v1 + 176);
    uint64_t v63 = *(void *)(v1 + 168);
    uint64_t v64 = *(void *)(v1 + 144);
    uint64_t v65 = *(void *)(v1 + 152);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v104 = (void *)(v1 + 40);
    uint64_t v106 = *(int **)(v1 + 240);
    unint64_t v103 = *(void *)(v1 + 208);
    long long v73 = *(void *)(v1 + 200);
    uint64_t v95 = *(void *)(v1 + 192);
    uint64_t v90 = *(int **)(v1 + 184);
    uint64_t v74 = *(void *)(v1 + 168);
    uint64_t v105 = *(unsigned char **)(v1 + 160);
    uint64_t v92 = *(void *)(v1 + 152);
    uint64_t v107 = 0;
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v102 = *(void *)(v1 + 104);
    uint64_t v98 = *(void *)(v1 + 96);
    char v77 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v92 + 16);
    uint64_t v96 = v72;
    v77(v105, v74, v75);
    uint64_t v108 = *(unsigned char *)(v106[7] + v76);
    int64_t v93 = *(void *)(v106[8] + v76);
    v77((unsigned char *)v73, (uint64_t)v105, v75);
    *(unsigned char *)(v73 + v90[5]) = v108;
    *(void *)(v73 + v90[6]) = v93;
    Date.init()(v73);
    uint64_t v78 = v105;
    uint64_t v105 = *(unsigned char **)(v92 + 8);
    ((void (*)(unsigned char *, uint64_t))v105)(v78, v75);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v102 + 32))(v73 + v90[7], v91, v98);
    *(void *)(v73 + v90[8]) = v96;
    outlined init with take of MLClassifierMetrics(v73, v103, type metadata accessor for MLCheckpoint);
    uint64_t v79 = v76;
    swift_beginAccess(v76, v104, 33, 0);
    uint64_t v80 = v106[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v79) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v79);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v103, v82 + ((*(unsigned __int8 *)(v95 + 80) + 32) & ~*(unsigned __int8 *)(v95 + 80)) + *(void *)(v95 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v104);
    uint64_t v25 = *(void *)(v106[8] + v79);
    specialized MLTrainingSession.save()();
    uint64_t v83 = *(void *)(v1 + 208);
    uint64_t v106 = *(int **)(v1 + 176);
    uint64_t v84 = *(void *)(v1 + 144);
    uint64_t v104 = *(void **)(v1 + 168);
    if (v107)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v105)(v104, v84);
      ((void (*)(int *, uint64_t))v105)(v106, v84);
      goto LABEL_29;
    }
    PassthroughSubject.send(_:)(v83);
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v105)(v104, v84);
    ((void (*)(int *, uint64_t))v105)(v106, v84);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 176);
    uint64_t v86 = *(void *)(v1 + 168);
    uint64_t v87 = *(void *)(v1 + 144);
    uint64_t v88 = *(void *)(v1 + 152);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v107 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  uint64_t v101 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v107;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v101, v33, v34);
  if (v35)
  {
    uint64_t v107 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v100 = *(void *)(v1 + 168);
    uint64_t v105 = *(unsigned char **)(v1 + 160);
    unint64_t v103 = *(void *)(v1 + 136);
    uint64_t v106 = *(int **)(v1 + 112);
    uint64_t v104 = *(void **)(v1 + 120);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v100);
    swift_task_dealloc(v105);
    swift_task_dealloc(v103);
    swift_task_dealloc(v104);
    swift_task_dealloc(v106);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v105 = *(unsigned char **)(v1 + 168);
  unint64_t v103 = *(void *)(v1 + 160);
  uint64_t v104 = *(void **)(v1 + 136);
  uint64_t v107 = *(void **)(v1 + 112);
  uint64_t v106 = *(int **)(v1 + 120);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v105);
  swift_task_dealloc(v103);
  swift_task_dealloc(v104);
  swift_task_dealloc(v106);
  swift_task_dealloc(v107);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[15];
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[17];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[17];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[17];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[15];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[15] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[20];
    uint64_t v52 = (char *)v48[19];
    uint64_t v51 = (void *)v48[18];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[17];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  unint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(uint64_t, uint64_t);
  uint64_t v78;
  unsigned char *v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  uint64_t v90;
  uint64_t v91;
  int *v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  uint64_t v102;
  char v103;
  unint64_t v104;
  uint64_t v105;
  void *v106;
  unsigned char *v107;
  int *v108;
  void *v109;
  char v110;
  uint64_t v111;
  uint64_t v112;

  Swift::String v112 = v0 | 0x1000000000000000;
  uint64_t v111 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 168) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v109 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v109 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 184);
  uint64_t v16 = *(void *)(v1 + 160);
  uint64_t v17 = *(void *)(v1 + 176);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 160);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v108 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 192) + 32))(*(void *)(v1 + 216), *(void *)(v1 + 160), *(void *)(v1 + 184));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v104 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v104 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v104 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v104 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v106 = *(void **)(v1 + 304);
  uint64_t v96 = *(void *)(v1 + 248);
  uint64_t v105 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v99 = *(void *)(v1 + 208);
  uint64_t v101 = (void *)(v53 + v96);
  uint64_t v107 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v104;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v109;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v96 + 24);
  uint64_t v58 = *(void *)(v53 + v96 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v101, v57);
  Swift::String v59 = v105;
  uint64_t v60 = v107;
  *(unsigned char *)(v1 + 312) = v107[*(int *)(v105 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v99, v108, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v106)
  {
    uint64_t v109 = v106;
    char v62 = *(void *)(v1 + 216);
    uint64_t v63 = *(void *)(v1 + 208);
    uint64_t v64 = *(void *)(v1 + 184);
    uint64_t v65 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v106 = (void *)(v1 + 40);
    uint64_t v108 = *(int **)(v1 + 240);
    long long v73 = *(void *)(v1 + 208);
    uint64_t v74 = *(void *)(v1 + 200);
    int64_t v93 = *(void *)(v1 + 192);
    uint64_t v107 = *(unsigned char **)(v1 + 184);
    uint64_t v105 = *(void *)(v1 + 152);
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v97 = *(void *)(v1 + 128);
    uint64_t v92 = *(int **)(v1 + 120);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v98 = *(void *)(v1 + 104);
    uint64_t v100 = *(void *)(v1 + 96);
    uint64_t v109 = 0;
    char v77 = *(void (**)(uint64_t, uint64_t))(v93 + 16);
    uint64_t v104 = v72;
    uint64_t v78 = v74;
    uint64_t v94 = v74;
    v77(v74, v73);
    uint64_t v110 = *(unsigned char *)(v108[7] + v76);
    uint64_t v95 = *(void *)(v108[8] + v76);
    ((void (*)(uint64_t, uint64_t, unsigned char *))v77)(v75, v78, v107);
    *(unsigned char *)(v75 + v92[5]) = v110;
    *(void *)(v75 + v92[6]) = v95;
    Date.init()(v75);
    uint64_t v79 = v107;
    uint64_t v107 = *(unsigned char **)(v93 + 8);
    ((void (*)(uint64_t, unsigned char *))v107)(v94, v79);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v98 + 32))(v75 + v92[7], v91, v100);
    *(void *)(v75 + v92[8]) = v104;
    outlined init with take of MLClassifierMetrics(v75, v105, type metadata accessor for MLCheckpoint);
    swift_beginAccess(v76, v106, 33, 0);
    uint64_t v80 = v108[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v76) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v76);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v105, v82 + ((*(unsigned __int8 *)(v97 + 80) + 32) & ~*(unsigned __int8 *)(v97 + 80)) + *(void *)(v97 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v106);
    uint64_t v25 = *(void *)(v108[8] + v76);
    specialized MLTrainingSession.save()();
    uint64_t v108 = *(int **)(v1 + 216);
    uint64_t v106 = *(void **)(v1 + 208);
    uint64_t v83 = *(void *)(v1 + 152);
    uint64_t v84 = *(void *)(v1 + 184);
    if (v109)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v107)(v106, v84);
      ((void (*)(int *, uint64_t))v107)(v108, v84);
      goto LABEL_29;
    }
    uint64_t v90 = *(void *)(v1 + 184);
    PassthroughSubject.send(_:)(*(void *)(v1 + 152));
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v107)(v106, v90);
    ((void (*)(int *, uint64_t))v107)(v108, v90);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 216);
    uint64_t v86 = *(void *)(v1 + 208);
    uint64_t v87 = *(void *)(v1 + 184);
    uint64_t v88 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v109 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  unint64_t v103 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v109;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v103, v33, v34);
  if (v35)
  {
    uint64_t v109 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v102 = *(void *)(v1 + 160);
    uint64_t v107 = *(unsigned char **)(v1 + 152);
    uint64_t v105 = *(void *)(v1 + 144);
    uint64_t v108 = *(int **)(v1 + 112);
    uint64_t v106 = *(void **)(v1 + 136);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v102);
    swift_task_dealloc(v107);
    swift_task_dealloc(v105);
    swift_task_dealloc(v106);
    swift_task_dealloc(v108);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v107 = *(unsigned char **)(v1 + 160);
  uint64_t v105 = *(void *)(v1 + 152);
  uint64_t v106 = *(void **)(v1 + 144);
  uint64_t v109 = *(void **)(v1 + 112);
  uint64_t v108 = *(int **)(v1 + 136);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v107);
  swift_task_dealloc(v105);
  swift_task_dealloc(v106);
  swift_task_dealloc(v108);
  swift_task_dealloc(v109);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[15];
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[17];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[17];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[17];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[15];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[15] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[20];
    uint64_t v52 = (char *)v48[19];
    uint64_t v51 = (void *)v48[18];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[17];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  unint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(uint64_t, uint64_t);
  uint64_t v78;
  unsigned char *v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  uint64_t v90;
  uint64_t v91;
  int *v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  uint64_t v102;
  char v103;
  unint64_t v104;
  uint64_t v105;
  void *v106;
  unsigned char *v107;
  int *v108;
  void *v109;
  char v110;
  uint64_t v111;
  uint64_t v112;

  Swift::String v112 = v0 | 0x1000000000000000;
  uint64_t v111 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 168) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v109 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v109 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 184);
  uint64_t v16 = *(void *)(v1 + 160);
  uint64_t v17 = *(void *)(v1 + 176);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 160);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v108 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 192) + 32))(*(void *)(v1 + 216), *(void *)(v1 + 160), *(void *)(v1 + 184));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v104 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v104 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v104 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v104 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v106 = *(void **)(v1 + 304);
  uint64_t v96 = *(void *)(v1 + 248);
  uint64_t v105 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v99 = *(void *)(v1 + 208);
  uint64_t v101 = (void *)(v53 + v96);
  uint64_t v107 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v104;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v109;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v96 + 24);
  uint64_t v58 = *(void *)(v53 + v96 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v101, v57);
  Swift::String v59 = v105;
  uint64_t v60 = v107;
  *(unsigned char *)(v1 + 312) = v107[*(int *)(v105 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v99, v108, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v106)
  {
    uint64_t v109 = v106;
    char v62 = *(void *)(v1 + 216);
    uint64_t v63 = *(void *)(v1 + 208);
    uint64_t v64 = *(void *)(v1 + 184);
    uint64_t v65 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v106 = (void *)(v1 + 40);
    uint64_t v108 = *(int **)(v1 + 240);
    long long v73 = *(void *)(v1 + 208);
    uint64_t v74 = *(void *)(v1 + 200);
    int64_t v93 = *(void *)(v1 + 192);
    uint64_t v107 = *(unsigned char **)(v1 + 184);
    uint64_t v105 = *(void *)(v1 + 152);
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v97 = *(void *)(v1 + 128);
    uint64_t v92 = *(int **)(v1 + 120);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v98 = *(void *)(v1 + 104);
    uint64_t v100 = *(void *)(v1 + 96);
    uint64_t v109 = 0;
    char v77 = *(void (**)(uint64_t, uint64_t))(v93 + 16);
    uint64_t v104 = v72;
    uint64_t v78 = v74;
    uint64_t v94 = v74;
    v77(v74, v73);
    uint64_t v110 = *(unsigned char *)(v108[7] + v76);
    uint64_t v95 = *(void *)(v108[8] + v76);
    ((void (*)(uint64_t, uint64_t, unsigned char *))v77)(v75, v78, v107);
    *(unsigned char *)(v75 + v92[5]) = v110;
    *(void *)(v75 + v92[6]) = v95;
    Date.init()(v75);
    uint64_t v79 = v107;
    uint64_t v107 = *(unsigned char **)(v93 + 8);
    ((void (*)(uint64_t, unsigned char *))v107)(v94, v79);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v98 + 32))(v75 + v92[7], v91, v100);
    *(void *)(v75 + v92[8]) = v104;
    outlined init with take of MLClassifierMetrics(v75, v105, type metadata accessor for MLCheckpoint);
    swift_beginAccess(v76, v106, 33, 0);
    uint64_t v80 = v108[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v76) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v76);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v105, v82 + ((*(unsigned __int8 *)(v97 + 80) + 32) & ~*(unsigned __int8 *)(v97 + 80)) + *(void *)(v97 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v106);
    uint64_t v25 = *(void *)(v108[8] + v76);
    specialized MLTrainingSession.save()();
    uint64_t v108 = *(int **)(v1 + 216);
    uint64_t v106 = *(void **)(v1 + 208);
    uint64_t v83 = *(void *)(v1 + 152);
    uint64_t v84 = *(void *)(v1 + 184);
    if (v109)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v107)(v106, v84);
      ((void (*)(int *, uint64_t))v107)(v108, v84);
      goto LABEL_29;
    }
    uint64_t v90 = *(void *)(v1 + 184);
    PassthroughSubject.send(_:)(*(void *)(v1 + 152));
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v107)(v106, v90);
    ((void (*)(int *, uint64_t))v107)(v108, v90);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 216);
    uint64_t v86 = *(void *)(v1 + 208);
    uint64_t v87 = *(void *)(v1 + 184);
    uint64_t v88 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v109 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  unint64_t v103 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v109;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v103, v33, v34);
  if (v35)
  {
    uint64_t v109 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v102 = *(void *)(v1 + 160);
    uint64_t v107 = *(unsigned char **)(v1 + 152);
    uint64_t v105 = *(void *)(v1 + 144);
    uint64_t v108 = *(int **)(v1 + 112);
    uint64_t v106 = *(void **)(v1 + 136);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v102);
    swift_task_dealloc(v107);
    swift_task_dealloc(v105);
    swift_task_dealloc(v106);
    swift_task_dealloc(v108);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v107 = *(unsigned char **)(v1 + 160);
  uint64_t v105 = *(void *)(v1 + 152);
  uint64_t v106 = *(void **)(v1 + 144);
  uint64_t v109 = *(void **)(v1 + 112);
  uint64_t v108 = *(int **)(v1 + 136);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v107);
  swift_task_dealloc(v105);
  swift_task_dealloc(v106);
  swift_task_dealloc(v108);
  swift_task_dealloc(v109);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[15];
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[17];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[17];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[17];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[15];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[15] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[20];
    uint64_t v52 = (char *)v48[19];
    uint64_t v51 = (void *)v48[18];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[17];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  unint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(uint64_t, uint64_t);
  uint64_t v78;
  unsigned char *v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  uint64_t v90;
  uint64_t v91;
  int *v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  uint64_t v102;
  char v103;
  unint64_t v104;
  uint64_t v105;
  void *v106;
  unsigned char *v107;
  int *v108;
  void *v109;
  char v110;
  uint64_t v111;
  uint64_t v112;

  Swift::String v112 = v0 | 0x1000000000000000;
  uint64_t v111 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 168) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v109 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v109 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 184);
  uint64_t v16 = *(void *)(v1 + 160);
  uint64_t v17 = *(void *)(v1 + 176);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 160);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v108 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 192) + 32))(*(void *)(v1 + 216), *(void *)(v1 + 160), *(void *)(v1 + 184));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v104 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v104 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v104 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v104 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v106 = *(void **)(v1 + 304);
  uint64_t v96 = *(void *)(v1 + 248);
  uint64_t v105 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v99 = *(void *)(v1 + 208);
  uint64_t v101 = (void *)(v53 + v96);
  uint64_t v107 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v104;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v109;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v96 + 24);
  uint64_t v58 = *(void *)(v53 + v96 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v101, v57);
  Swift::String v59 = v105;
  uint64_t v60 = v107;
  *(unsigned char *)(v1 + 312) = v107[*(int *)(v105 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v99, v108, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v106)
  {
    uint64_t v109 = v106;
    char v62 = *(void *)(v1 + 216);
    uint64_t v63 = *(void *)(v1 + 208);
    uint64_t v64 = *(void *)(v1 + 184);
    uint64_t v65 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v106 = (void *)(v1 + 40);
    uint64_t v108 = *(int **)(v1 + 240);
    long long v73 = *(void *)(v1 + 208);
    uint64_t v74 = *(void *)(v1 + 200);
    int64_t v93 = *(void *)(v1 + 192);
    uint64_t v107 = *(unsigned char **)(v1 + 184);
    uint64_t v105 = *(void *)(v1 + 152);
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v97 = *(void *)(v1 + 128);
    uint64_t v92 = *(int **)(v1 + 120);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v98 = *(void *)(v1 + 104);
    uint64_t v100 = *(void *)(v1 + 96);
    uint64_t v109 = 0;
    char v77 = *(void (**)(uint64_t, uint64_t))(v93 + 16);
    uint64_t v104 = v72;
    uint64_t v78 = v74;
    uint64_t v94 = v74;
    v77(v74, v73);
    uint64_t v110 = *(unsigned char *)(v108[7] + v76);
    uint64_t v95 = *(void *)(v108[8] + v76);
    ((void (*)(uint64_t, uint64_t, unsigned char *))v77)(v75, v78, v107);
    *(unsigned char *)(v75 + v92[5]) = v110;
    *(void *)(v75 + v92[6]) = v95;
    Date.init()(v75);
    uint64_t v79 = v107;
    uint64_t v107 = *(unsigned char **)(v93 + 8);
    ((void (*)(uint64_t, unsigned char *))v107)(v94, v79);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v98 + 32))(v75 + v92[7], v91, v100);
    *(void *)(v75 + v92[8]) = v104;
    outlined init with take of MLClassifierMetrics(v75, v105, type metadata accessor for MLCheckpoint);
    swift_beginAccess(v76, v106, 33, 0);
    uint64_t v80 = v108[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v76) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v76);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v105, v82 + ((*(unsigned __int8 *)(v97 + 80) + 32) & ~*(unsigned __int8 *)(v97 + 80)) + *(void *)(v97 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v106);
    uint64_t v25 = *(void *)(v108[8] + v76);
    specialized MLTrainingSession.save()();
    uint64_t v108 = *(int **)(v1 + 216);
    uint64_t v106 = *(void **)(v1 + 208);
    uint64_t v83 = *(void *)(v1 + 152);
    uint64_t v84 = *(void *)(v1 + 184);
    if (v109)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v107)(v106, v84);
      ((void (*)(int *, uint64_t))v107)(v108, v84);
      goto LABEL_29;
    }
    uint64_t v90 = *(void *)(v1 + 184);
    PassthroughSubject.send(_:)(*(void *)(v1 + 152));
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v107)(v106, v90);
    ((void (*)(int *, uint64_t))v107)(v108, v90);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 216);
    uint64_t v86 = *(void *)(v1 + 208);
    uint64_t v87 = *(void *)(v1 + 184);
    uint64_t v88 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v109 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  unint64_t v103 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v109;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v103, v33, v34);
  if (v35)
  {
    uint64_t v109 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v102 = *(void *)(v1 + 160);
    uint64_t v107 = *(unsigned char **)(v1 + 152);
    uint64_t v105 = *(void *)(v1 + 144);
    uint64_t v108 = *(int **)(v1 + 112);
    uint64_t v106 = *(void **)(v1 + 136);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v102);
    swift_task_dealloc(v107);
    swift_task_dealloc(v105);
    swift_task_dealloc(v106);
    swift_task_dealloc(v108);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v107 = *(unsigned char **)(v1 + 160);
  uint64_t v105 = *(void *)(v1 + 152);
  uint64_t v106 = *(void **)(v1 + 144);
  uint64_t v109 = *(void **)(v1 + 112);
  uint64_t v108 = *(int **)(v1 + 136);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v107);
  swift_task_dealloc(v105);
  swift_task_dealloc(v106);
  swift_task_dealloc(v108);
  swift_task_dealloc(v109);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[15];
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[17];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[17];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[17];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[15];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[15] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[20];
    uint64_t v52 = (char *)v48[19];
    uint64_t v51 = (void *)v48[18];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[17];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  unint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(uint64_t, uint64_t);
  uint64_t v78;
  unsigned char *v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  uint64_t v90;
  uint64_t v91;
  int *v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  uint64_t v102;
  char v103;
  unint64_t v104;
  uint64_t v105;
  void *v106;
  unsigned char *v107;
  int *v108;
  void *v109;
  char v110;
  uint64_t v111;
  uint64_t v112;

  Swift::String v112 = v0 | 0x1000000000000000;
  uint64_t v111 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 168) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v109 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v109 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 184);
  uint64_t v16 = *(void *)(v1 + 160);
  uint64_t v17 = *(void *)(v1 + 176);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 160);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v108 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 192) + 32))(*(void *)(v1 + 216), *(void *)(v1 + 160), *(void *)(v1 + 184));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v104 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v104 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v104 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v104 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v106 = *(void **)(v1 + 304);
  uint64_t v96 = *(void *)(v1 + 248);
  uint64_t v105 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v99 = *(void *)(v1 + 208);
  uint64_t v101 = (void *)(v53 + v96);
  uint64_t v107 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v104;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v109;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v96 + 24);
  uint64_t v58 = *(void *)(v53 + v96 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v101, v57);
  Swift::String v59 = v105;
  uint64_t v60 = v107;
  *(unsigned char *)(v1 + 312) = v107[*(int *)(v105 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v99, v108, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v106)
  {
    uint64_t v109 = v106;
    char v62 = *(void *)(v1 + 216);
    uint64_t v63 = *(void *)(v1 + 208);
    uint64_t v64 = *(void *)(v1 + 184);
    uint64_t v65 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v106 = (void *)(v1 + 40);
    uint64_t v108 = *(int **)(v1 + 240);
    long long v73 = *(void *)(v1 + 208);
    uint64_t v74 = *(void *)(v1 + 200);
    int64_t v93 = *(void *)(v1 + 192);
    uint64_t v107 = *(unsigned char **)(v1 + 184);
    uint64_t v105 = *(void *)(v1 + 152);
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v97 = *(void *)(v1 + 128);
    uint64_t v92 = *(int **)(v1 + 120);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v98 = *(void *)(v1 + 104);
    uint64_t v100 = *(void *)(v1 + 96);
    uint64_t v109 = 0;
    char v77 = *(void (**)(uint64_t, uint64_t))(v93 + 16);
    uint64_t v104 = v72;
    uint64_t v78 = v74;
    uint64_t v94 = v74;
    v77(v74, v73);
    uint64_t v110 = *(unsigned char *)(v108[7] + v76);
    uint64_t v95 = *(void *)(v108[8] + v76);
    ((void (*)(uint64_t, uint64_t, unsigned char *))v77)(v75, v78, v107);
    *(unsigned char *)(v75 + v92[5]) = v110;
    *(void *)(v75 + v92[6]) = v95;
    Date.init()(v75);
    uint64_t v79 = v107;
    uint64_t v107 = *(unsigned char **)(v93 + 8);
    ((void (*)(uint64_t, unsigned char *))v107)(v94, v79);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v98 + 32))(v75 + v92[7], v91, v100);
    *(void *)(v75 + v92[8]) = v104;
    outlined init with take of MLClassifierMetrics(v75, v105, type metadata accessor for MLCheckpoint);
    swift_beginAccess(v76, v106, 33, 0);
    uint64_t v80 = v108[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v76) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v76);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v105, v82 + ((*(unsigned __int8 *)(v97 + 80) + 32) & ~*(unsigned __int8 *)(v97 + 80)) + *(void *)(v97 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v106);
    uint64_t v25 = *(void *)(v108[8] + v76);
    specialized MLTrainingSession.save()();
    uint64_t v108 = *(int **)(v1 + 216);
    uint64_t v106 = *(void **)(v1 + 208);
    uint64_t v83 = *(void *)(v1 + 152);
    uint64_t v84 = *(void *)(v1 + 184);
    if (v109)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v107)(v106, v84);
      ((void (*)(int *, uint64_t))v107)(v108, v84);
      goto LABEL_29;
    }
    uint64_t v90 = *(void *)(v1 + 184);
    PassthroughSubject.send(_:)(*(void *)(v1 + 152));
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v107)(v106, v90);
    ((void (*)(int *, uint64_t))v107)(v108, v90);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 216);
    uint64_t v86 = *(void *)(v1 + 208);
    uint64_t v87 = *(void *)(v1 + 184);
    uint64_t v88 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v109 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  unint64_t v103 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v109;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v103, v33, v34);
  if (v35)
  {
    uint64_t v109 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v102 = *(void *)(v1 + 160);
    uint64_t v107 = *(unsigned char **)(v1 + 152);
    uint64_t v105 = *(void *)(v1 + 144);
    uint64_t v108 = *(int **)(v1 + 112);
    uint64_t v106 = *(void **)(v1 + 136);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v102);
    swift_task_dealloc(v107);
    swift_task_dealloc(v105);
    swift_task_dealloc(v106);
    swift_task_dealloc(v108);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v107 = *(unsigned char **)(v1 + 160);
  uint64_t v105 = *(void *)(v1 + 152);
  uint64_t v106 = *(void **)(v1 + 144);
  uint64_t v109 = *(void **)(v1 + 112);
  uint64_t v108 = *(int **)(v1 + 136);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v107);
  swift_task_dealloc(v105);
  swift_task_dealloc(v106);
  swift_task_dealloc(v108);
  swift_task_dealloc(v109);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[15];
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[17];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[17];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[17];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[15];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[15] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[20];
    uint64_t v52 = (char *)v48[19];
    uint64_t v51 = (void *)v48[18];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[17];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  unint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(uint64_t, uint64_t);
  uint64_t v78;
  unsigned char *v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  uint64_t v90;
  uint64_t v91;
  int *v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  uint64_t v102;
  char v103;
  unint64_t v104;
  uint64_t v105;
  void *v106;
  unsigned char *v107;
  int *v108;
  void *v109;
  char v110;
  uint64_t v111;
  uint64_t v112;

  Swift::String v112 = v0 | 0x1000000000000000;
  uint64_t v111 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 168) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v109 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v109 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 184);
  uint64_t v16 = *(void *)(v1 + 160);
  uint64_t v17 = *(void *)(v1 + 176);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 160);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v108 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 192) + 32))(*(void *)(v1 + 216), *(void *)(v1 + 160), *(void *)(v1 + 184));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v104 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v104 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v104 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v104 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v106 = *(void **)(v1 + 304);
  uint64_t v96 = *(void *)(v1 + 248);
  uint64_t v105 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v99 = *(void *)(v1 + 208);
  uint64_t v101 = (void *)(v53 + v96);
  uint64_t v107 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v104;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v109;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v96 + 24);
  uint64_t v58 = *(void *)(v53 + v96 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v101, v57);
  Swift::String v59 = v105;
  uint64_t v60 = v107;
  *(unsigned char *)(v1 + 312) = v107[*(int *)(v105 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v99, v108, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v106)
  {
    uint64_t v109 = v106;
    char v62 = *(void *)(v1 + 216);
    uint64_t v63 = *(void *)(v1 + 208);
    uint64_t v64 = *(void *)(v1 + 184);
    uint64_t v65 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v106 = (void *)(v1 + 40);
    uint64_t v108 = *(int **)(v1 + 240);
    long long v73 = *(void *)(v1 + 208);
    uint64_t v74 = *(void *)(v1 + 200);
    int64_t v93 = *(void *)(v1 + 192);
    uint64_t v107 = *(unsigned char **)(v1 + 184);
    uint64_t v105 = *(void *)(v1 + 152);
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v97 = *(void *)(v1 + 128);
    uint64_t v92 = *(int **)(v1 + 120);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v98 = *(void *)(v1 + 104);
    uint64_t v100 = *(void *)(v1 + 96);
    uint64_t v109 = 0;
    char v77 = *(void (**)(uint64_t, uint64_t))(v93 + 16);
    uint64_t v104 = v72;
    uint64_t v78 = v74;
    uint64_t v94 = v74;
    v77(v74, v73);
    uint64_t v110 = *(unsigned char *)(v108[7] + v76);
    uint64_t v95 = *(void *)(v108[8] + v76);
    ((void (*)(uint64_t, uint64_t, unsigned char *))v77)(v75, v78, v107);
    *(unsigned char *)(v75 + v92[5]) = v110;
    *(void *)(v75 + v92[6]) = v95;
    Date.init()(v75);
    uint64_t v79 = v107;
    uint64_t v107 = *(unsigned char **)(v93 + 8);
    ((void (*)(uint64_t, unsigned char *))v107)(v94, v79);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v98 + 32))(v75 + v92[7], v91, v100);
    *(void *)(v75 + v92[8]) = v104;
    outlined init with take of MLClassifierMetrics(v75, v105, type metadata accessor for MLCheckpoint);
    swift_beginAccess(v76, v106, 33, 0);
    uint64_t v80 = v108[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v76) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v76);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v105, v82 + ((*(unsigned __int8 *)(v97 + 80) + 32) & ~*(unsigned __int8 *)(v97 + 80)) + *(void *)(v97 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v106);
    uint64_t v25 = *(void *)(v108[8] + v76);
    specialized MLTrainingSession.save()();
    uint64_t v108 = *(int **)(v1 + 216);
    uint64_t v106 = *(void **)(v1 + 208);
    uint64_t v83 = *(void *)(v1 + 152);
    uint64_t v84 = *(void *)(v1 + 184);
    if (v109)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v107)(v106, v84);
      ((void (*)(int *, uint64_t))v107)(v108, v84);
      goto LABEL_29;
    }
    uint64_t v90 = *(void *)(v1 + 184);
    PassthroughSubject.send(_:)(*(void *)(v1 + 152));
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v107)(v106, v90);
    ((void (*)(int *, uint64_t))v107)(v108, v90);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 216);
    uint64_t v86 = *(void *)(v1 + 208);
    uint64_t v87 = *(void *)(v1 + 184);
    uint64_t v88 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v109 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  unint64_t v103 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v109;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v103, v33, v34);
  if (v35)
  {
    uint64_t v109 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v102 = *(void *)(v1 + 160);
    uint64_t v107 = *(unsigned char **)(v1 + 152);
    uint64_t v105 = *(void *)(v1 + 144);
    uint64_t v108 = *(int **)(v1 + 112);
    uint64_t v106 = *(void **)(v1 + 136);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v102);
    swift_task_dealloc(v107);
    swift_task_dealloc(v105);
    swift_task_dealloc(v106);
    swift_task_dealloc(v108);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v107 = *(unsigned char **)(v1 + 160);
  uint64_t v105 = *(void *)(v1 + 152);
  uint64_t v106 = *(void **)(v1 + 144);
  uint64_t v109 = *(void **)(v1 + 112);
  uint64_t v108 = *(int **)(v1 + 136);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v107);
  swift_task_dealloc(v105);
  swift_task_dealloc(v106);
  swift_task_dealloc(v108);
  swift_task_dealloc(v109);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[15];
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[17];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[17];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[17];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[15];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[15] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[20];
    uint64_t v52 = (char *)v48[19];
    uint64_t v51 = (void *)v48[18];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[17];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  unint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(uint64_t, uint64_t);
  uint64_t v78;
  unsigned char *v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  uint64_t v90;
  uint64_t v91;
  int *v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  uint64_t v102;
  char v103;
  unint64_t v104;
  uint64_t v105;
  void *v106;
  unsigned char *v107;
  int *v108;
  void *v109;
  char v110;
  uint64_t v111;
  uint64_t v112;

  Swift::String v112 = v0 | 0x1000000000000000;
  uint64_t v111 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 168) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v109 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v109 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 184);
  uint64_t v16 = *(void *)(v1 + 160);
  uint64_t v17 = *(void *)(v1 + 176);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 160);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v108 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 192) + 32))(*(void *)(v1 + 216), *(void *)(v1 + 160), *(void *)(v1 + 184));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v104 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v104 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v104 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v104 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v106 = *(void **)(v1 + 304);
  uint64_t v96 = *(void *)(v1 + 248);
  uint64_t v105 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v99 = *(void *)(v1 + 208);
  uint64_t v101 = (void *)(v53 + v96);
  uint64_t v107 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v104;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v109;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v96 + 24);
  uint64_t v58 = *(void *)(v53 + v96 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v101, v57);
  Swift::String v59 = v105;
  uint64_t v60 = v107;
  *(unsigned char *)(v1 + 312) = v107[*(int *)(v105 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v99, v108, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v106)
  {
    uint64_t v109 = v106;
    char v62 = *(void *)(v1 + 216);
    uint64_t v63 = *(void *)(v1 + 208);
    uint64_t v64 = *(void *)(v1 + 184);
    uint64_t v65 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v106 = (void *)(v1 + 40);
    uint64_t v108 = *(int **)(v1 + 240);
    long long v73 = *(void *)(v1 + 208);
    uint64_t v74 = *(void *)(v1 + 200);
    int64_t v93 = *(void *)(v1 + 192);
    uint64_t v107 = *(unsigned char **)(v1 + 184);
    uint64_t v105 = *(void *)(v1 + 152);
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v97 = *(void *)(v1 + 128);
    uint64_t v92 = *(int **)(v1 + 120);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v98 = *(void *)(v1 + 104);
    uint64_t v100 = *(void *)(v1 + 96);
    uint64_t v109 = 0;
    char v77 = *(void (**)(uint64_t, uint64_t))(v93 + 16);
    uint64_t v104 = v72;
    uint64_t v78 = v74;
    uint64_t v94 = v74;
    v77(v74, v73);
    uint64_t v110 = *(unsigned char *)(v108[7] + v76);
    uint64_t v95 = *(void *)(v108[8] + v76);
    ((void (*)(uint64_t, uint64_t, unsigned char *))v77)(v75, v78, v107);
    *(unsigned char *)(v75 + v92[5]) = v110;
    *(void *)(v75 + v92[6]) = v95;
    Date.init()(v75);
    uint64_t v79 = v107;
    uint64_t v107 = *(unsigned char **)(v93 + 8);
    ((void (*)(uint64_t, unsigned char *))v107)(v94, v79);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v98 + 32))(v75 + v92[7], v91, v100);
    *(void *)(v75 + v92[8]) = v104;
    outlined init with take of MLClassifierMetrics(v75, v105, type metadata accessor for MLCheckpoint);
    swift_beginAccess(v76, v106, 33, 0);
    uint64_t v80 = v108[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v76) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v76);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v105, v82 + ((*(unsigned __int8 *)(v97 + 80) + 32) & ~*(unsigned __int8 *)(v97 + 80)) + *(void *)(v97 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v106);
    uint64_t v25 = *(void *)(v108[8] + v76);
    specialized MLTrainingSession.save()();
    uint64_t v108 = *(int **)(v1 + 216);
    uint64_t v106 = *(void **)(v1 + 208);
    uint64_t v83 = *(void *)(v1 + 152);
    uint64_t v84 = *(void *)(v1 + 184);
    if (v109)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v107)(v106, v84);
      ((void (*)(int *, uint64_t))v107)(v108, v84);
      goto LABEL_29;
    }
    uint64_t v90 = *(void *)(v1 + 184);
    PassthroughSubject.send(_:)(*(void *)(v1 + 152));
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v107)(v106, v90);
    ((void (*)(int *, uint64_t))v107)(v108, v90);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 216);
    uint64_t v86 = *(void *)(v1 + 208);
    uint64_t v87 = *(void *)(v1 + 184);
    uint64_t v88 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v109 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  unint64_t v103 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v109;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v103, v33, v34);
  if (v35)
  {
    uint64_t v109 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v102 = *(void *)(v1 + 160);
    uint64_t v107 = *(unsigned char **)(v1 + 152);
    uint64_t v105 = *(void *)(v1 + 144);
    uint64_t v108 = *(int **)(v1 + 112);
    uint64_t v106 = *(void **)(v1 + 136);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v102);
    swift_task_dealloc(v107);
    swift_task_dealloc(v105);
    swift_task_dealloc(v106);
    swift_task_dealloc(v108);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v107 = *(unsigned char **)(v1 + 160);
  uint64_t v105 = *(void *)(v1 + 152);
  uint64_t v106 = *(void **)(v1 + 144);
  uint64_t v109 = *(void **)(v1 + 112);
  uint64_t v108 = *(int **)(v1 + 136);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v107);
  swift_task_dealloc(v105);
  swift_task_dealloc(v106);
  swift_task_dealloc(v108);
  swift_task_dealloc(v109);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[15];
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[17];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[17];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[17];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[15];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[15] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[20];
    uint64_t v52 = (char *)v48[19];
    uint64_t v51 = (void *)v48[18];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[17];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  unint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(uint64_t, uint64_t);
  uint64_t v78;
  unsigned char *v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  uint64_t v90;
  uint64_t v91;
  int *v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  uint64_t v102;
  char v103;
  unint64_t v104;
  uint64_t v105;
  void *v106;
  unsigned char *v107;
  int *v108;
  void *v109;
  char v110;
  uint64_t v111;
  uint64_t v112;

  Swift::String v112 = v0 | 0x1000000000000000;
  uint64_t v111 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 168) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v109 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v109 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 184);
  uint64_t v16 = *(void *)(v1 + 160);
  uint64_t v17 = *(void *)(v1 + 176);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 160);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v108 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 192) + 32))(*(void *)(v1 + 216), *(void *)(v1 + 160), *(void *)(v1 + 184));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v104 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v104 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v104 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v104 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v106 = *(void **)(v1 + 304);
  uint64_t v96 = *(void *)(v1 + 248);
  uint64_t v105 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v99 = *(void *)(v1 + 208);
  uint64_t v101 = (void *)(v53 + v96);
  uint64_t v107 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v104;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v109;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v96 + 24);
  uint64_t v58 = *(void *)(v53 + v96 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v101, v57);
  Swift::String v59 = v105;
  uint64_t v60 = v107;
  *(unsigned char *)(v1 + 312) = v107[*(int *)(v105 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v99, v108, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v106)
  {
    uint64_t v109 = v106;
    char v62 = *(void *)(v1 + 216);
    uint64_t v63 = *(void *)(v1 + 208);
    uint64_t v64 = *(void *)(v1 + 184);
    uint64_t v65 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v106 = (void *)(v1 + 40);
    uint64_t v108 = *(int **)(v1 + 240);
    long long v73 = *(void *)(v1 + 208);
    uint64_t v74 = *(void *)(v1 + 200);
    int64_t v93 = *(void *)(v1 + 192);
    uint64_t v107 = *(unsigned char **)(v1 + 184);
    uint64_t v105 = *(void *)(v1 + 152);
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v97 = *(void *)(v1 + 128);
    uint64_t v92 = *(int **)(v1 + 120);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v98 = *(void *)(v1 + 104);
    uint64_t v100 = *(void *)(v1 + 96);
    uint64_t v109 = 0;
    char v77 = *(void (**)(uint64_t, uint64_t))(v93 + 16);
    uint64_t v104 = v72;
    uint64_t v78 = v74;
    uint64_t v94 = v74;
    v77(v74, v73);
    uint64_t v110 = *(unsigned char *)(v108[7] + v76);
    uint64_t v95 = *(void *)(v108[8] + v76);
    ((void (*)(uint64_t, uint64_t, unsigned char *))v77)(v75, v78, v107);
    *(unsigned char *)(v75 + v92[5]) = v110;
    *(void *)(v75 + v92[6]) = v95;
    Date.init()(v75);
    uint64_t v79 = v107;
    uint64_t v107 = *(unsigned char **)(v93 + 8);
    ((void (*)(uint64_t, unsigned char *))v107)(v94, v79);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v98 + 32))(v75 + v92[7], v91, v100);
    *(void *)(v75 + v92[8]) = v104;
    outlined init with take of MLClassifierMetrics(v75, v105, type metadata accessor for MLCheckpoint);
    swift_beginAccess(v76, v106, 33, 0);
    uint64_t v80 = v108[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v76) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v76);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v105, v82 + ((*(unsigned __int8 *)(v97 + 80) + 32) & ~*(unsigned __int8 *)(v97 + 80)) + *(void *)(v97 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v106);
    uint64_t v25 = *(void *)(v108[8] + v76);
    specialized MLTrainingSession.save()();
    uint64_t v108 = *(int **)(v1 + 216);
    uint64_t v106 = *(void **)(v1 + 208);
    uint64_t v83 = *(void *)(v1 + 152);
    uint64_t v84 = *(void *)(v1 + 184);
    if (v109)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v107)(v106, v84);
      ((void (*)(int *, uint64_t))v107)(v108, v84);
      goto LABEL_29;
    }
    uint64_t v90 = *(void *)(v1 + 184);
    PassthroughSubject.send(_:)(*(void *)(v1 + 152));
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v107)(v106, v90);
    ((void (*)(int *, uint64_t))v107)(v108, v90);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 216);
    uint64_t v86 = *(void *)(v1 + 208);
    uint64_t v87 = *(void *)(v1 + 184);
    uint64_t v88 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v109 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  unint64_t v103 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v109;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v103, v33, v34);
  if (v35)
  {
    uint64_t v109 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v102 = *(void *)(v1 + 160);
    uint64_t v107 = *(unsigned char **)(v1 + 152);
    uint64_t v105 = *(void *)(v1 + 144);
    uint64_t v108 = *(int **)(v1 + 112);
    uint64_t v106 = *(void **)(v1 + 136);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v102);
    swift_task_dealloc(v107);
    swift_task_dealloc(v105);
    swift_task_dealloc(v106);
    swift_task_dealloc(v108);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v107 = *(unsigned char **)(v1 + 160);
  uint64_t v105 = *(void *)(v1 + 152);
  uint64_t v106 = *(void **)(v1 + 144);
  uint64_t v109 = *(void **)(v1 + 112);
  uint64_t v108 = *(int **)(v1 + 136);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v107);
  swift_task_dealloc(v105);
  swift_task_dealloc(v106);
  swift_task_dealloc(v108);
  swift_task_dealloc(v109);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[15];
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[17];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[17];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[17];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[15];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[15] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[20];
    uint64_t v52 = (char *)v48[19];
    uint64_t v51 = (void *)v48[18];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[17];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  unint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(uint64_t, uint64_t);
  uint64_t v78;
  unsigned char *v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  uint64_t v90;
  uint64_t v91;
  int *v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  uint64_t v102;
  char v103;
  unint64_t v104;
  uint64_t v105;
  void *v106;
  unsigned char *v107;
  int *v108;
  void *v109;
  char v110;
  uint64_t v111;
  uint64_t v112;

  Swift::String v112 = v0 | 0x1000000000000000;
  uint64_t v111 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 168) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v109 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v109 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 184);
  uint64_t v16 = *(void *)(v1 + 160);
  uint64_t v17 = *(void *)(v1 + 176);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 160);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v108 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 192) + 32))(*(void *)(v1 + 216), *(void *)(v1 + 160), *(void *)(v1 + 184));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v104 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v104 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v104 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v104 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v106 = *(void **)(v1 + 304);
  uint64_t v96 = *(void *)(v1 + 248);
  uint64_t v105 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v99 = *(void *)(v1 + 208);
  uint64_t v101 = (void *)(v53 + v96);
  uint64_t v107 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v104;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v109;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v96 + 24);
  uint64_t v58 = *(void *)(v53 + v96 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v101, v57);
  Swift::String v59 = v105;
  uint64_t v60 = v107;
  *(unsigned char *)(v1 + 312) = v107[*(int *)(v105 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v99, v108, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v106)
  {
    uint64_t v109 = v106;
    char v62 = *(void *)(v1 + 216);
    uint64_t v63 = *(void *)(v1 + 208);
    uint64_t v64 = *(void *)(v1 + 184);
    uint64_t v65 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v106 = (void *)(v1 + 40);
    uint64_t v108 = *(int **)(v1 + 240);
    long long v73 = *(void *)(v1 + 208);
    uint64_t v74 = *(void *)(v1 + 200);
    int64_t v93 = *(void *)(v1 + 192);
    uint64_t v107 = *(unsigned char **)(v1 + 184);
    uint64_t v105 = *(void *)(v1 + 152);
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v97 = *(void *)(v1 + 128);
    uint64_t v92 = *(int **)(v1 + 120);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v98 = *(void *)(v1 + 104);
    uint64_t v100 = *(void *)(v1 + 96);
    uint64_t v109 = 0;
    char v77 = *(void (**)(uint64_t, uint64_t))(v93 + 16);
    uint64_t v104 = v72;
    uint64_t v78 = v74;
    uint64_t v94 = v74;
    v77(v74, v73);
    uint64_t v110 = *(unsigned char *)(v108[7] + v76);
    uint64_t v95 = *(void *)(v108[8] + v76);
    ((void (*)(uint64_t, uint64_t, unsigned char *))v77)(v75, v78, v107);
    *(unsigned char *)(v75 + v92[5]) = v110;
    *(void *)(v75 + v92[6]) = v95;
    Date.init()(v75);
    uint64_t v79 = v107;
    uint64_t v107 = *(unsigned char **)(v93 + 8);
    ((void (*)(uint64_t, unsigned char *))v107)(v94, v79);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v98 + 32))(v75 + v92[7], v91, v100);
    *(void *)(v75 + v92[8]) = v104;
    outlined init with take of MLClassifierMetrics(v75, v105, type metadata accessor for MLCheckpoint);
    swift_beginAccess(v76, v106, 33, 0);
    uint64_t v80 = v108[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v76) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v76);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v105, v82 + ((*(unsigned __int8 *)(v97 + 80) + 32) & ~*(unsigned __int8 *)(v97 + 80)) + *(void *)(v97 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v106);
    uint64_t v25 = *(void *)(v108[8] + v76);
    specialized MLTrainingSession.save()();
    uint64_t v108 = *(int **)(v1 + 216);
    uint64_t v106 = *(void **)(v1 + 208);
    uint64_t v83 = *(void *)(v1 + 152);
    uint64_t v84 = *(void *)(v1 + 184);
    if (v109)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v107)(v106, v84);
      ((void (*)(int *, uint64_t))v107)(v108, v84);
      goto LABEL_29;
    }
    uint64_t v90 = *(void *)(v1 + 184);
    PassthroughSubject.send(_:)(*(void *)(v1 + 152));
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v107)(v106, v90);
    ((void (*)(int *, uint64_t))v107)(v108, v90);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 216);
    uint64_t v86 = *(void *)(v1 + 208);
    uint64_t v87 = *(void *)(v1 + 184);
    uint64_t v88 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v109 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  unint64_t v103 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v109;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v103, v33, v34);
  if (v35)
  {
    uint64_t v109 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v102 = *(void *)(v1 + 160);
    uint64_t v107 = *(unsigned char **)(v1 + 152);
    uint64_t v105 = *(void *)(v1 + 144);
    uint64_t v108 = *(int **)(v1 + 112);
    uint64_t v106 = *(void **)(v1 + 136);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v102);
    swift_task_dealloc(v107);
    swift_task_dealloc(v105);
    swift_task_dealloc(v106);
    swift_task_dealloc(v108);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v107 = *(unsigned char **)(v1 + 160);
  uint64_t v105 = *(void *)(v1 + 152);
  uint64_t v106 = *(void **)(v1 + 144);
  uint64_t v109 = *(void **)(v1 + 112);
  uint64_t v108 = *(int **)(v1 + 136);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v107);
  swift_task_dealloc(v105);
  swift_task_dealloc(v106);
  swift_task_dealloc(v108);
  swift_task_dealloc(v109);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[15];
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[17];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[17];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[17];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[15];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[15] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[20];
    uint64_t v52 = (char *)v48[19];
    uint64_t v51 = (void *)v48[18];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[17];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  unint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(uint64_t, uint64_t);
  uint64_t v78;
  unsigned char *v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  uint64_t v90;
  uint64_t v91;
  int *v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  uint64_t v102;
  char v103;
  unint64_t v104;
  uint64_t v105;
  void *v106;
  unsigned char *v107;
  int *v108;
  void *v109;
  char v110;
  uint64_t v111;
  uint64_t v112;

  Swift::String v112 = v0 | 0x1000000000000000;
  uint64_t v111 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 168) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v109 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v109 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 184);
  uint64_t v16 = *(void *)(v1 + 160);
  uint64_t v17 = *(void *)(v1 + 176);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 160);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v108 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 192) + 32))(*(void *)(v1 + 216), *(void *)(v1 + 160), *(void *)(v1 + 184));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v104 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v104 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v104 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v104 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v106 = *(void **)(v1 + 304);
  uint64_t v96 = *(void *)(v1 + 248);
  uint64_t v105 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v99 = *(void *)(v1 + 208);
  uint64_t v101 = (void *)(v53 + v96);
  uint64_t v107 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v104;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v109;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v96 + 24);
  uint64_t v58 = *(void *)(v53 + v96 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v101, v57);
  Swift::String v59 = v105;
  uint64_t v60 = v107;
  *(unsigned char *)(v1 + 312) = v107[*(int *)(v105 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v99, v108, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v106)
  {
    uint64_t v109 = v106;
    char v62 = *(void *)(v1 + 216);
    uint64_t v63 = *(void *)(v1 + 208);
    uint64_t v64 = *(void *)(v1 + 184);
    uint64_t v65 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v106 = (void *)(v1 + 40);
    uint64_t v108 = *(int **)(v1 + 240);
    long long v73 = *(void *)(v1 + 208);
    uint64_t v74 = *(void *)(v1 + 200);
    int64_t v93 = *(void *)(v1 + 192);
    uint64_t v107 = *(unsigned char **)(v1 + 184);
    uint64_t v105 = *(void *)(v1 + 152);
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v97 = *(void *)(v1 + 128);
    uint64_t v92 = *(int **)(v1 + 120);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v98 = *(void *)(v1 + 104);
    uint64_t v100 = *(void *)(v1 + 96);
    uint64_t v109 = 0;
    char v77 = *(void (**)(uint64_t, uint64_t))(v93 + 16);
    uint64_t v104 = v72;
    uint64_t v78 = v74;
    uint64_t v94 = v74;
    v77(v74, v73);
    uint64_t v110 = *(unsigned char *)(v108[7] + v76);
    uint64_t v95 = *(void *)(v108[8] + v76);
    ((void (*)(uint64_t, uint64_t, unsigned char *))v77)(v75, v78, v107);
    *(unsigned char *)(v75 + v92[5]) = v110;
    *(void *)(v75 + v92[6]) = v95;
    Date.init()(v75);
    uint64_t v79 = v107;
    uint64_t v107 = *(unsigned char **)(v93 + 8);
    ((void (*)(uint64_t, unsigned char *))v107)(v94, v79);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v98 + 32))(v75 + v92[7], v91, v100);
    *(void *)(v75 + v92[8]) = v104;
    outlined init with take of MLClassifierMetrics(v75, v105, type metadata accessor for MLCheckpoint);
    swift_beginAccess(v76, v106, 33, 0);
    uint64_t v80 = v108[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v76) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v76);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v105, v82 + ((*(unsigned __int8 *)(v97 + 80) + 32) & ~*(unsigned __int8 *)(v97 + 80)) + *(void *)(v97 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v106);
    uint64_t v25 = *(void *)(v108[8] + v76);
    specialized MLTrainingSession.save()();
    uint64_t v108 = *(int **)(v1 + 216);
    uint64_t v106 = *(void **)(v1 + 208);
    uint64_t v83 = *(void *)(v1 + 152);
    uint64_t v84 = *(void *)(v1 + 184);
    if (v109)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v107)(v106, v84);
      ((void (*)(int *, uint64_t))v107)(v108, v84);
      goto LABEL_29;
    }
    uint64_t v90 = *(void *)(v1 + 184);
    PassthroughSubject.send(_:)(*(void *)(v1 + 152));
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v107)(v106, v90);
    ((void (*)(int *, uint64_t))v107)(v108, v90);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 216);
    uint64_t v86 = *(void *)(v1 + 208);
    uint64_t v87 = *(void *)(v1 + 184);
    uint64_t v88 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v109 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  unint64_t v103 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v109;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v103, v33, v34);
  if (v35)
  {
    uint64_t v109 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v102 = *(void *)(v1 + 160);
    uint64_t v107 = *(unsigned char **)(v1 + 152);
    uint64_t v105 = *(void *)(v1 + 144);
    uint64_t v108 = *(int **)(v1 + 112);
    uint64_t v106 = *(void **)(v1 + 136);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v102);
    swift_task_dealloc(v107);
    swift_task_dealloc(v105);
    swift_task_dealloc(v106);
    swift_task_dealloc(v108);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v107 = *(unsigned char **)(v1 + 160);
  uint64_t v105 = *(void *)(v1 + 152);
  uint64_t v106 = *(void **)(v1 + 144);
  uint64_t v109 = *(void **)(v1 + 112);
  uint64_t v108 = *(int **)(v1 + 136);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v107);
  swift_task_dealloc(v105);
  swift_task_dealloc(v106);
  swift_task_dealloc(v108);
  swift_task_dealloc(v109);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[15];
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[17];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[17];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[17];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[15];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[15] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[20];
    uint64_t v52 = (char *)v48[19];
    uint64_t v51 = (void *)v48[18];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[17];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  unint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(uint64_t, uint64_t);
  uint64_t v78;
  unsigned char *v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  uint64_t v90;
  uint64_t v91;
  int *v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  uint64_t v102;
  char v103;
  unint64_t v104;
  uint64_t v105;
  void *v106;
  unsigned char *v107;
  int *v108;
  void *v109;
  char v110;
  uint64_t v111;
  uint64_t v112;

  Swift::String v112 = v0 | 0x1000000000000000;
  uint64_t v111 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 168) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v109 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v109 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 184);
  uint64_t v16 = *(void *)(v1 + 160);
  uint64_t v17 = *(void *)(v1 + 176);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 160);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v108 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 192) + 32))(*(void *)(v1 + 216), *(void *)(v1 + 160), *(void *)(v1 + 184));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v104 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v104 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v104 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v104 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v106 = *(void **)(v1 + 304);
  uint64_t v96 = *(void *)(v1 + 248);
  uint64_t v105 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v99 = *(void *)(v1 + 208);
  uint64_t v101 = (void *)(v53 + v96);
  uint64_t v107 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v104;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v109;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v96 + 24);
  uint64_t v58 = *(void *)(v53 + v96 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v101, v57);
  Swift::String v59 = v105;
  uint64_t v60 = v107;
  *(unsigned char *)(v1 + 312) = v107[*(int *)(v105 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v99, v108, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v106)
  {
    uint64_t v109 = v106;
    char v62 = *(void *)(v1 + 216);
    uint64_t v63 = *(void *)(v1 + 208);
    uint64_t v64 = *(void *)(v1 + 184);
    uint64_t v65 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v106 = (void *)(v1 + 40);
    uint64_t v108 = *(int **)(v1 + 240);
    long long v73 = *(void *)(v1 + 208);
    uint64_t v74 = *(void *)(v1 + 200);
    int64_t v93 = *(void *)(v1 + 192);
    uint64_t v107 = *(unsigned char **)(v1 + 184);
    uint64_t v105 = *(void *)(v1 + 152);
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v97 = *(void *)(v1 + 128);
    uint64_t v92 = *(int **)(v1 + 120);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v98 = *(void *)(v1 + 104);
    uint64_t v100 = *(void *)(v1 + 96);
    uint64_t v109 = 0;
    char v77 = *(void (**)(uint64_t, uint64_t))(v93 + 16);
    uint64_t v104 = v72;
    uint64_t v78 = v74;
    uint64_t v94 = v74;
    v77(v74, v73);
    uint64_t v110 = *(unsigned char *)(v108[7] + v76);
    uint64_t v95 = *(void *)(v108[8] + v76);
    ((void (*)(uint64_t, uint64_t, unsigned char *))v77)(v75, v78, v107);
    *(unsigned char *)(v75 + v92[5]) = v110;
    *(void *)(v75 + v92[6]) = v95;
    Date.init()(v75);
    uint64_t v79 = v107;
    uint64_t v107 = *(unsigned char **)(v93 + 8);
    ((void (*)(uint64_t, unsigned char *))v107)(v94, v79);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v98 + 32))(v75 + v92[7], v91, v100);
    *(void *)(v75 + v92[8]) = v104;
    outlined init with take of MLClassifierMetrics(v75, v105, type metadata accessor for MLCheckpoint);
    swift_beginAccess(v76, v106, 33, 0);
    uint64_t v80 = v108[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v76) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v76);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v105, v82 + ((*(unsigned __int8 *)(v97 + 80) + 32) & ~*(unsigned __int8 *)(v97 + 80)) + *(void *)(v97 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v106);
    uint64_t v25 = *(void *)(v108[8] + v76);
    specialized MLTrainingSession.save()();
    uint64_t v108 = *(int **)(v1 + 216);
    uint64_t v106 = *(void **)(v1 + 208);
    uint64_t v83 = *(void *)(v1 + 152);
    uint64_t v84 = *(void *)(v1 + 184);
    if (v109)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v107)(v106, v84);
      ((void (*)(int *, uint64_t))v107)(v108, v84);
      goto LABEL_29;
    }
    uint64_t v90 = *(void *)(v1 + 184);
    PassthroughSubject.send(_:)(*(void *)(v1 + 152));
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v107)(v106, v90);
    ((void (*)(int *, uint64_t))v107)(v108, v90);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 216);
    uint64_t v86 = *(void *)(v1 + 208);
    uint64_t v87 = *(void *)(v1 + 184);
    uint64_t v88 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v109 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  unint64_t v103 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v109;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v103, v33, v34);
  if (v35)
  {
    uint64_t v109 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v102 = *(void *)(v1 + 160);
    uint64_t v107 = *(unsigned char **)(v1 + 152);
    uint64_t v105 = *(void *)(v1 + 144);
    uint64_t v108 = *(int **)(v1 + 112);
    uint64_t v106 = *(void **)(v1 + 136);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v102);
    swift_task_dealloc(v107);
    swift_task_dealloc(v105);
    swift_task_dealloc(v106);
    swift_task_dealloc(v108);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v107 = *(unsigned char **)(v1 + 160);
  uint64_t v105 = *(void *)(v1 + 152);
  uint64_t v106 = *(void **)(v1 + 144);
  uint64_t v109 = *(void **)(v1 + 112);
  uint64_t v108 = *(int **)(v1 + 136);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v107);
  swift_task_dealloc(v105);
  swift_task_dealloc(v106);
  swift_task_dealloc(v108);
  swift_task_dealloc(v109);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumTagSinglePayload;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char v23;
  unsigned int v24;
  uint64_t v25;
  uint64_t v26;
  int64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  void *v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int *v42;
  uint64_t (*v43)(uint64_t, uint64_t, uint64_t);
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *v48;
  char v49;
  void *v50;
  void *v51;
  char *v52;
  uint64_t v53;
  void *v54;
  uint64_t v55;

  uint64_t v55 = v0 | 0x1000000000000000;
  char v54 = v1;
  uint64_t v2 = v1[11];
  uint64_t v3 = *(void *)(*(void *)v2 + 112);
  v1[29] = v3;
  uint64_t v4 = v3 + v2;
  swift_beginAccess(v4, v1 + 2, 1, 0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
  v1[30] = v5;
  uint64_t v46 = v4;
  uint64_t v6 = *(void **)(*(int *)(v5 + 44) + v4);
  v1[8] = v6;
  uint64_t v7 = v6[2];
  uint64_t v48 = v1;
  uint64_t v45 = v5;
  char v50 = v6;
  if (v7)
  {
    uint64_t v53 = v1[15];
    uint64_t v51 = (void *)v1[16];
    uint64_t v52 = (char *)v6 + ((*((unsigned __int8 *)v51 + 80) + 32) & ~*((unsigned __int8 *)v51 + 80));
    swift_bridgeObjectRetain((_BYTE)v6);
    while (1)
    {
      if (v7 > v6[2]) {
        BUG();
      }
      --v7;
      uint64_t v8 = v1[17];
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v52[v7 * v51[9]], v8, type metadata accessor for MLCheckpoint);
      switch(*(unsigned char *)(v8 + *(int *)(v53 + 20)))
      {
        case 0:
          uint64_t v9 = 0x696C616974696E69;
          unint64_t v10 = 0xEB0000000064657ALL;
          break;
        case 1:
          uint64_t v9 = 0x6974636172747865;
          goto LABEL_8;
        case 2:
          uint64_t v14 = v48[17];
          swift_bridgeObjectRelease(0);
          uint64_t v1 = v48;
          outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLCheckpoint);
          LODWORD(v52) = 0;
          goto LABEL_17;
        case 3:
          uint64_t v9 = 0x697461756C617665;
LABEL_8:
          unint64_t v10 = 0xEA0000000000676ELL;
          break;
        case 4:
          unint64_t v10 = 0xEB00000000676E69;
          uint64_t v9 = 0x636E657265666E69;
          break;
      }
      uint64_t v11 = v1[17];
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, 0x676E696E69617274, 0xE800000000000000, 0);
      swift_bridgeObjectRelease(v10);
      uint64_t v13 = outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLCheckpoint);
      if (v12) {
        break;
      }
      uint64_t v1 = v48;
      uint64_t v6 = v50;
      if (!v7) {
        goto LABEL_14;
      }
    }
    LODWORD(v52) = 0;
    uint64_t v1 = v48;
  }
  else
  {
    uint64_t v13 = swift_bridgeObjectRetain((_BYTE)v6);
LABEL_14:
    LOBYTE(v13) = 1;
    LODWORD(v52) = v13;
    uint64_t v7 = 0;
  }
LABEL_17:
  uint64_t v51 = v1 + 9;
  uint64_t v53 = v1[15];
  uint64_t v15 = v1[28];
  uint64_t v16 = swift_task_alloc(32);
  *(void *)(v16 + 16) = v1 + 8;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))closure #1 in BidirectionalCollection.last(where:)specialized partial apply, v16, v7, (char)v52, (uint64_t)v51);
  swift_bridgeObjectRelease((_BYTE)v50);
  swift_task_dealloc(v16);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v15, 1, v53);
  uint64_t v18 = v48[28];
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v51 = 0;
  }
  else
  {
    uint64_t v51 = *(void **)(v18 + *(int *)(v48[15] + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLCheckpoint);
  }
  char v50 = (void *)v48[10];
  uint64_t v19 = v48[11];
  uint64_t v20 = direct field offset for MLTrainingSession.delegate;
  v48[31] = direct field offset for MLTrainingSession.delegate;
  uint64_t v21 = *(void *)(v19 + v20 + 24);
  uint64_t v53 = *(void *)(v19 + v20 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v19 + v20), v21);
  char v49 = *(unsigned char *)(v46 + *(int *)(v45 + 28));
  uint64_t v22 = (*(uint64_t (**)(char *, uint64_t))(v53 + 32))(&v49, v21);
  v48[32] = v22;
  *((unsigned char *)v48 + 313) = v23;
  LOBYTE(v21) = v23 & 1;
  uint64_t v53 = *(void *)(v46 + *(int *)(v45 + 32));
  unsigned int v24 = *(unsigned __int8 *)(v46 + *(int *)(v45 + 28));
  uint64_t v25 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v25);
  int64_t v27 = v22;
  uint64_t v28 = v50;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v53, v24, v27, v21, v26, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v26);
  if ([*(id *)((char *)v28 + direct field offset for MLJob.progress) isCancelled])
  {
    uint64_t v29 = v48[28];
    uint64_t v30 = v48[27];
    uint64_t v31 = v48[26];
    uint64_t v32 = v48[25];
    uint64_t v33 = v48[22];
    uint64_t v47 = v48[20];
    uint64_t v52 = (char *)v48[19];
    uint64_t v51 = (void *)v48[18];
    char v50 = (void *)v48[14];
    uint64_t v53 = v48[17];
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v47);
    swift_task_dealloc(v52);
    swift_task_dealloc(v51);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    return ((uint64_t (*)(void))v48[1])();
  }
  else
  {
    v48[33] = direct field offset for MLTrainingSession.parameters;
    v48[34] = v51;
    uint64_t v35 = v48[11];
    uint64_t v36 = v48[30];
    uint64_t v37 = (void *)(v35 + v48[31]);
    uint64_t v38 = v35 + v48[29];
    uint64_t v39 = v37[3];
    uint64_t v40 = v37[4];
    char v50 = __swift_project_boxed_opaque_existential_0Tm(v37, v39);
    uint64_t v41 = *(void *)(*(int *)(v36 + 32) + v38);
    uint64_t v42 = *(int **)(v40 + 56);
    uint64_t v43 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v42 + *v42);
    uint64_t v44 = (void *)swift_task_alloc(v42[1]);
    v48[35] = v44;
    *uint64_t v44 = v48;
    v44[1] = specialized MLTrainingSession.train(job:);
    return v43(v41, v39, v40);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  unsigned __int8 v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  BOOL v27;
  uint64_t v28;
  unsigned __int8 v29;
  CreateML::ModelType v30;
  Swift::Double v31;
  void *v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t (*v41)(void);
  uint64_t v42;
  uint64_t v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  int *v49;
  uint64_t (*v50)(uint64_t, uint64_t, uint64_t);
  void *v51;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  char v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  unsigned char *v60;
  char v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void (*v66)(uint64_t, uint64_t);
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  unint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void (*v77)(uint64_t, uint64_t);
  uint64_t v78;
  unsigned char *v79;
  uint64_t v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  uint64_t v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  void (*v89)(uint64_t, uint64_t);
  uint64_t v90;
  uint64_t v91;
  int *v92;
  uint64_t v93;
  uint64_t v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  uint64_t v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  uint64_t v102;
  char v103;
  unint64_t v104;
  uint64_t v105;
  void *v106;
  unsigned char *v107;
  int *v108;
  void *v109;
  char v110;
  uint64_t v111;
  uint64_t v112;

  Swift::String v112 = v0 | 0x1000000000000000;
  uint64_t v111 = v1;
  uint64_t v2 = *(void *)(v1 + 240);
  uint64_t v3 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 288), v5);
  uint64_t v7 = *(void *)(v1 + 288) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v8 = *(void *)(v1 + 296);
  uint64_t v9 = *(void *)(v1 + 272);
  unint64_t v10 = *(void *)(v1 + 256);
  uint64_t v11 = *(unsigned char *)(v1 + 313) & 1;
  *(void *)(v3 + v4) = v7;
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, *(unsigned __int8 *)(v3 + *(int *)(v2 + 28)), v10, v11, v8, (uint64_t)specialized MLJob.currentPhase.setter);
  char v12 = *(void *)(v3 + *(int *)(v2 + 32));
  uint64_t v6 = __OFSUB__(v12, v9);
  uint64_t v13 = v12 - v9;
  if (v6) {
    BUG();
  }
  uint64_t v14 = *(void *)(v1 + 264) + *(void *)(v1 + 88);
  if (v13 < *(void *)(*(int *)(*(void *)(v1 + 168) + 24) + v14))
  {
    if (*(uint64_t *)(v1 + 288) <= 0)
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      goto LABEL_11;
    }
    if (!*(unsigned char *)(v1 + 314))
    {
      swift_bridgeObjectRelease(*(void *)(v1 + 296));
      uint64_t v25 = *(void *)(v1 + 272);
LABEL_19:
      if (![*(id *)(*(void *)(v1 + 80) + direct field offset for MLJob.progress) isCancelled])
      {
        *(void *)(v1 + 272) = v25;
        uint64_t v42 = *(void *)(v1 + 88);
        uint64_t v43 = *(void *)(v1 + 240);
        uint64_t v44 = (void *)(v42 + *(void *)(v1 + 248));
        uint64_t v45 = v42 + *(void *)(v1 + 232);
        uint64_t v46 = v44[3];
        uint64_t v47 = v44[4];
        uint64_t v109 = __swift_project_boxed_opaque_existential_0Tm(v44, v46);
        uint64_t v48 = *(void *)(*(int *)(v43 + 32) + v45);
        char v49 = *(int **)(v47 + 56);
        char v50 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v49 + *v49);
        uint64_t v51 = (void *)swift_task_alloc(v49[1]);
        *(void *)(v1 + 280) = v51;
        void *v51 = v1;
        v51[1] = specialized MLTrainingSession.train(job:);
        return v50(v48, v46, v47);
      }
      goto LABEL_20;
    }
  }
  uint64_t v109 = *(void **)(v3 + *(int *)(v2 + 32));
  uint64_t v15 = *(void *)(v1 + 184);
  uint64_t v16 = *(void *)(v1 + 160);
  uint64_t v17 = *(void *)(v1 + 176);
  outlined init with copy of MLTrainingSessionParameters(v14, v17, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v17, v16);
  if (__swift_getEnumTagSinglePayload(v16, 1, v15) == 1)
  {
    uint64_t v18 = *(void *)(v1 + 160);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for URL?);
LABEL_11:
    uint64_t v25 = *(void *)(v1 + 272);
    uint64_t v26 = *(void **)(v1 + 304);
    goto LABEL_12;
  }
  uint64_t v108 = (int *)(v1 + 312);
  uint64_t v19 = *(void *)(v1 + 240);
  uint64_t v20 = *(void *)(v1 + 232) + *(void *)(v1 + 88);
  (*(void (**)(void, void, void))(*(void *)(v1 + 192) + 32))(*(void *)(v1 + 216), *(void *)(v1 + 160), *(void *)(v1 + 184));
  uint64_t v21 = *(unsigned __int8 *)(*(int *)(v19 + 28) + v20);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  char v23 = (void *)swift_allocObject(v22, 112, 7);
  v23[2] = 2;
  v23[3] = 4;
  switch(v21)
  {
    case 0:
      unsigned int v24 = 0x696C616974696E69;
      uint64_t v104 = 0xEB0000000064657ALL;
      break;
    case 1:
      unsigned int v24 = 0x6974636172747865;
      goto LABEL_25;
    case 2:
      uint64_t v104 = 0xE800000000000000;
      unsigned int v24 = 0x676E696E69617274;
      break;
    case 3:
      unsigned int v24 = 0x697461756C617665;
LABEL_25:
      uint64_t v104 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v104 = 0xEB00000000676E69;
      unsigned int v24 = 0x636E657265666E69;
      break;
  }
  uint64_t v106 = *(void **)(v1 + 304);
  uint64_t v96 = *(void *)(v1 + 248);
  uint64_t v105 = *(void *)(v1 + 240);
  uint64_t v53 = *(void *)(v1 + 88);
  uint64_t v99 = *(void *)(v1 + 208);
  uint64_t v101 = (void *)(v53 + v96);
  uint64_t v107 = (unsigned char *)(v53 + *(void *)(v1 + 232));
  v23[7] = &type metadata for String;
  v23[8] = lazy protocol witness table accessor for type String and conformance String();
  v23[4] = v24;
  v23[5] = v104;
  v23[12] = &type metadata for Int;
  v23[13] = &protocol witness table for Int;
  v23[9] = v109;
  char v54 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v23);
  uint64_t v56 = v55;
  URL.appendingPathComponent(_:)(v54, v55);
  swift_bridgeObjectRelease(v56);
  uint64_t v57 = *(void *)(v53 + v96 + 24);
  uint64_t v58 = *(void *)(v53 + v96 + 32);
  __swift_project_boxed_opaque_existential_0Tm(v101, v57);
  Swift::String v59 = v105;
  uint64_t v60 = v107;
  *(unsigned char *)(v1 + 312) = v107[*(int *)(v105 + 28)];
  uint64_t v61 = (*(uint64_t (**)(uint64_t, int *, void, uint64_t, uint64_t))(v58 + 72))(v99, v108, *(void *)&v60[*(int *)(v59 + 32)], v57, v58);
  if (v106)
  {
    uint64_t v109 = v106;
    char v62 = *(void *)(v1 + 216);
    uint64_t v63 = *(void *)(v1 + 208);
    uint64_t v64 = *(void *)(v1 + 184);
    uint64_t v65 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(*(void *)(v1 + 296));
    uint64_t v66 = *(void (**)(uint64_t, uint64_t))(v65 + 8);
    v66(v63, v64);
    v66(v62, v64);
    goto LABEL_29;
  }
  uint64_t v72 = *(void *)(v1 + 296);
  if (v61)
  {
    uint64_t v106 = (void *)(v1 + 40);
    uint64_t v108 = *(int **)(v1 + 240);
    long long v73 = *(void *)(v1 + 208);
    uint64_t v74 = *(void *)(v1 + 200);
    int64_t v93 = *(void *)(v1 + 192);
    uint64_t v107 = *(unsigned char **)(v1 + 184);
    uint64_t v105 = *(void *)(v1 + 152);
    uint64_t v75 = *(void *)(v1 + 144);
    uint64_t v97 = *(void *)(v1 + 128);
    uint64_t v92 = *(int **)(v1 + 120);
    uint64_t v91 = *(void *)(v1 + 112);
    char v76 = *(void *)(v1 + 88) + *(void *)(v1 + 232);
    uint64_t v98 = *(void *)(v1 + 104);
    uint64_t v100 = *(void *)(v1 + 96);
    uint64_t v109 = 0;
    char v77 = *(void (**)(uint64_t, uint64_t))(v93 + 16);
    uint64_t v104 = v72;
    uint64_t v78 = v74;
    uint64_t v94 = v74;
    v77(v74, v73);
    uint64_t v110 = *(unsigned char *)(v108[7] + v76);
    uint64_t v95 = *(void *)(v108[8] + v76);
    ((void (*)(uint64_t, uint64_t, unsigned char *))v77)(v75, v78, v107);
    *(unsigned char *)(v75 + v92[5]) = v110;
    *(void *)(v75 + v92[6]) = v95;
    Date.init()(v75);
    uint64_t v79 = v107;
    uint64_t v107 = *(unsigned char **)(v93 + 8);
    ((void (*)(uint64_t, unsigned char *))v107)(v94, v79);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v98 + 32))(v75 + v92[7], v91, v100);
    *(void *)(v75 + v92[8]) = v104;
    outlined init with take of MLClassifierMetrics(v75, v105, type metadata accessor for MLCheckpoint);
    swift_beginAccess(v76, v106, 33, 0);
    uint64_t v80 = v108[11];
    specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v81 = *(void *)(*(void *)(v80 + v76) + 16);
    specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v81);
    uint64_t v82 = *(void *)(v80 + v76);
    *(void *)(v82 + 16) = v81 + 1;
    outlined init with copy of MLTrainingSessionParameters(v105, v82 + ((*(unsigned __int8 *)(v97 + 80) + 32) & ~*(unsigned __int8 *)(v97 + 80)) + *(void *)(v97 + 72) * v81, type metadata accessor for MLCheckpoint);
    swift_endAccess(v106);
    uint64_t v25 = *(void *)(v108[8] + v76);
    specialized MLTrainingSession.save()();
    uint64_t v108 = *(int **)(v1 + 216);
    uint64_t v106 = *(void **)(v1 + 208);
    uint64_t v83 = *(void *)(v1 + 152);
    uint64_t v84 = *(void *)(v1 + 184);
    if (v109)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
      ((void (*)(void *, uint64_t))v107)(v106, v84);
      ((void (*)(int *, uint64_t))v107)(v108, v84);
      goto LABEL_29;
    }
    uint64_t v90 = *(void *)(v1 + 184);
    PassthroughSubject.send(_:)(*(void *)(v1 + 152));
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for MLCheckpoint);
    ((void (*)(void *, uint64_t))v107)(v106, v90);
    ((void (*)(int *, uint64_t))v107)(v108, v90);
  }
  else
  {
    uint64_t v85 = *(void *)(v1 + 216);
    uint64_t v86 = *(void *)(v1 + 208);
    uint64_t v87 = *(void *)(v1 + 184);
    uint64_t v88 = *(void *)(v1 + 192);
    swift_bridgeObjectRelease(v72);
    uint64_t v89 = *(void (**)(uint64_t, uint64_t))(v88 + 8);
    v89(v86, v87);
    v89(v85, v87);
    uint64_t v25 = *(void *)(v1 + 272);
  }
  uint64_t v26 = 0;
LABEL_12:
  if (*(unsigned char *)(v1 + 314) != 1) {
    goto LABEL_19;
  }
  int64_t v27 = AnalyticsReporter.init()();
  uint64_t v28 = *(void *)(v1 + 88);
  uint64_t v109 = v26;
  if (!v27)
  {
    uint64_t v29 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
    if (v29 != 28)
    {
      uint64_t v30 = *(unsigned char *)(v28 + direct field offset for MLTrainingSession.modelType);
      AnalyticsReporter.reportTemplateUsed(model:mode:)((Swift::String)v29);
      uint64_t v31 = Date.timeIntervalSinceReferenceDate.getter();
      AnalyticsReporter.reportEventDuration(model:task:startTime:)(v30, (Swift::String)__PAIR128__(0xE800000000000000, 0x676E696E69617254), v31);
      uint64_t v28 = *(void *)(v1 + 88);
    }
  }
  uint64_t v32 = (void *)(*(void *)(v1 + 248) + v28);
  specialized MLTrainingSession.transition(to:)(3, &demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
  uint64_t v33 = v32[3];
  uint64_t v34 = v32[4];
  unint64_t v103 = 3;
  __swift_project_boxed_opaque_existential_0Tm(v32, v33);
  uint64_t v35 = v109;
  (*(void (**)(char *, uint64_t, uint64_t))(v34 + 40))(&v103, v33, v34);
  if (v35)
  {
    uint64_t v109 = v35;
LABEL_29:
    uint64_t v67 = *(void *)(v1 + 224);
    uint64_t v68 = *(void *)(v1 + 216);
    uint64_t v69 = *(void *)(v1 + 208);
    long long v70 = *(void *)(v1 + 200);
    uint64_t v71 = *(void *)(v1 + 176);
    uint64_t v102 = *(void *)(v1 + 160);
    uint64_t v107 = *(unsigned char **)(v1 + 152);
    uint64_t v105 = *(void *)(v1 + 144);
    uint64_t v108 = *(int **)(v1 + 112);
    uint64_t v106 = *(void **)(v1 + 136);
    swift_task_dealloc(v67);
    swift_task_dealloc(v68);
    swift_task_dealloc(v69);
    swift_task_dealloc(v70);
    swift_task_dealloc(v71);
    swift_task_dealloc(v102);
    swift_task_dealloc(v107);
    swift_task_dealloc(v105);
    swift_task_dealloc(v106);
    swift_task_dealloc(v108);
    uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
    return v41();
  }
LABEL_20:
  uint64_t v36 = *(void *)(v1 + 224);
  uint64_t v37 = *(void *)(v1 + 216);
  uint64_t v38 = *(void *)(v1 + 208);
  uint64_t v39 = *(void *)(v1 + 200);
  uint64_t v40 = *(void *)(v1 + 176);
  uint64_t v107 = *(unsigned char **)(v1 + 160);
  uint64_t v105 = *(void *)(v1 + 152);
  uint64_t v106 = *(void **)(v1 + 144);
  uint64_t v109 = *(void **)(v1 + 112);
  uint64_t v108 = *(int **)(v1 + 136);
  swift_task_dealloc(v36);
  swift_task_dealloc(v37);
  swift_task_dealloc(v38);
  swift_task_dealloc(v39);
  swift_task_dealloc(v40);
  swift_task_dealloc(v107);
  swift_task_dealloc(v105);
  swift_task_dealloc(v106);
  swift_task_dealloc(v108);
  swift_task_dealloc(v109);
  uint64_t v41 = *(uint64_t (**)(void))(v1 + 8);
  return v41();
}

uint64_t specialized MLTrainingSession.train(job:)(uint64_t a1, uint64_t a2, char a3)
{
  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 168);
  uint64_t v13 = *(void *)(v6 + 160);
  uint64_t v12 = *(void *)(v6 + 136);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 120);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 168);
  uint64_t v13 = *(void *)(v6 + 160);
  uint64_t v12 = *(void *)(v6 + 136);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 120);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 168);
  uint64_t v13 = *(void *)(v6 + 160);
  uint64_t v12 = *(void *)(v6 + 136);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 120);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 168);
  uint64_t v13 = *(void *)(v6 + 160);
  uint64_t v12 = *(void *)(v6 + 136);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 120);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 168);
  uint64_t v13 = *(void *)(v6 + 160);
  uint64_t v12 = *(void *)(v6 + 136);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 120);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 168);
  uint64_t v13 = *(void *)(v6 + 160);
  uint64_t v12 = *(void *)(v6 + 136);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 120);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 160);
  uint64_t v13 = *(void *)(v6 + 152);
  uint64_t v12 = *(void *)(v6 + 144);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 136);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 160);
  uint64_t v13 = *(void *)(v6 + 152);
  uint64_t v12 = *(void *)(v6 + 144);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 136);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 160);
  uint64_t v13 = *(void *)(v6 + 152);
  uint64_t v12 = *(void *)(v6 + 144);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 136);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 160);
  uint64_t v13 = *(void *)(v6 + 152);
  uint64_t v12 = *(void *)(v6 + 144);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 136);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 160);
  uint64_t v13 = *(void *)(v6 + 152);
  uint64_t v12 = *(void *)(v6 + 144);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 136);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 160);
  uint64_t v13 = *(void *)(v6 + 152);
  uint64_t v12 = *(void *)(v6 + 144);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 136);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 160);
  uint64_t v13 = *(void *)(v6 + 152);
  uint64_t v12 = *(void *)(v6 + 144);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 136);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 160);
  uint64_t v13 = *(void *)(v6 + 152);
  uint64_t v12 = *(void *)(v6 + 144);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 136);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 160);
  uint64_t v13 = *(void *)(v6 + 152);
  uint64_t v12 = *(void *)(v6 + 144);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 136);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 160);
  uint64_t v13 = *(void *)(v6 + 152);
  uint64_t v12 = *(void *)(v6 + 144);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 136);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

{
  uint64_t v3;
  uint64_t *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;

  uint64_t v5 = *(void *)(*v4 + 280);
  uint64_t v6 = *v4;
  *(void *)(v6 + 288) = a1;
  *(void *)(v6 + 296) = a2;
  *(unsigned char *)(v6 + 314) = a3 & 1;
  *(void *)(v6 + 304) = v3;
  swift_task_dealloc(v5);
  if (!v3) {
    return swift_task_switch(specialized MLTrainingSession.train(job:), 0, 0);
  }
  uint64_t v7 = *(void *)(v6 + 216);
  uint64_t v8 = *(void *)(v6 + 208);
  uint64_t v16 = *(void *)(v6 + 200);
  uint64_t v15 = *(void *)(v6 + 176);
  uint64_t v14 = *(void *)(v6 + 160);
  uint64_t v13 = *(void *)(v6 + 152);
  uint64_t v12 = *(void *)(v6 + 144);
  uint64_t v11 = *(void *)(v6 + 112);
  uint64_t v9 = *(void *)(v6 + 136);
  swift_task_dealloc(*(void *)(v6 + 224));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

uint64_t specialized MLTrainingSession.evaluate(job:)(uint64_t a1)
{
  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  *(void *)(v2 + 48) = v1;
  *(void *)(v2 + 40) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

uint64_t specialized MLTrainingSession.evaluate(job:)()
{
  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLActivityClassifier>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLHandPoseClassifier>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestRegressor>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLStyleTransfer>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLActionClassifier>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLHandActionClassifier>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLRandomForestClassifier>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeRegressor>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLObjectDetector>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeClassifier>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  char v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  int *v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  char v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v28 = v0 | 0x1000000000000000;
  uint64_t v27 = v1;
  uint64_t v23 = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(v1 + 48);
  uint64_t v3 = direct field offset for MLTrainingSession.delegate;
  *(void *)(v1 + 56) = direct field offset for MLTrainingSession.delegate;
  uint64_t v4 = *(void *)(v2 + v3 + 24);
  uint64_t v24 = *(void *)(v2 + v3 + 32);
  __swift_project_boxed_opaque_existential_0Tm((void *)(v2 + v3), v4);
  uint64_t v5 = *(void *)(*(void *)v2 + 112);
  *(void *)(v1 + 64) = v5;
  uint64_t v6 = v5 + v2;
  swift_beginAccess(v6, v1 + 16, 1, 0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
  *(void *)(v1 + 72) = v7;
  char v26 = *(unsigned char *)(*(int *)(v7 + 28) + v6);
  int64_t v8 = (*(uint64_t (**)(char *, uint64_t))(v24 + 32))(&v26, v4);
  *(void *)(v1 + 80) = v8;
  *(unsigned char *)(v1 + 120) = v9;
  LOBYTE(v4) = v9 & 1;
  uint64_t v25 = *(void *)(*(int *)(v7 + 32) + v6);
  LODWORD(v6) = *(unsigned __int8 *)(*(int *)(v7 + 28) + v6);
  uint64_t v10 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  *(void *)(v1 + 88) = v10;
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v10);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v25, v6, v8, v4, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if ([*(id *)(v23 + direct field offset for MLJob.progress) isCancelled]) {
    return (*(uint64_t (**)(void))(v1 + 8))();
  }
  uint64_t v13 = *(void *)(v1 + 72);
  uint64_t v14 = *(void *)(v1 + 48);
  uint64_t v15 = v14 + *(void *)(v1 + 64);
  uint64_t v16 = (void *)(v14 + *(void *)(v1 + 56));
  uint64_t v17 = v16[3];
  uint64_t v18 = v16[4];
  __swift_project_boxed_opaque_existential_0Tm(v16, v17);
  uint64_t v19 = *(void *)(*(int *)(v13 + 32) + v15);
  uint64_t v20 = *(int **)(v18 + 64);
  uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v20 + *v20);
  uint64_t v22 = (void *)swift_task_alloc(v20[1]);
  *(void *)(v1 + 96) = v22;
  *uint64_t v22 = v1;
  v22[1] = specialized MLTrainingSession.evaluate(job:);
  return v21(v19, v17, v18);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  BOOL v6;
  uint64_t v7;
  uint64_t v8;
  unsigned __int8 v9;
  unsigned int v10;
  uint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int *v24;
  uint64_t (*v25)(uint64_t, uint64_t, uint64_t);
  void *v26;
  int64_t v27;
  char v28;
  uint64_t v29;
  char v30;
  uint64_t v31;
  uint64_t v32;

  uint64_t v32 = v0 | 0x1000000000000000;
  uint64_t v31 = v1;
  uint64_t v2 = *(void *)(v1 + 72);
  uint64_t v3 = *(void *)(v1 + 64) + *(void *)(v1 + 48);
  uint64_t v4 = *(int *)(v2 + 32);
  uint64_t v5 = *(void *)(v4 + v3);
  uint64_t v6 = __OFADD__(*(void *)(v1 + 112), v5);
  uint64_t v7 = *(void *)(v1 + 112) + v5;
  if (v6) {
    BUG();
  }
  uint64_t v28 = *(unsigned char *)(v1 + 121);
  int64_t v8 = *(void *)(v1 + 88);
  uint64_t v27 = *(void *)(v1 + 80);
  char v9 = *(unsigned char *)(v1 + 120) & 1;
  *(void *)(v3 + v4) = v7;
  uint64_t v10 = *(unsigned __int8 *)(v3 + *(int *)(v2 + 28));
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v8);
  specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(v7, v10, v27, v9, v11, (uint64_t)specialized MLJob.currentPhase.setter);
  swift_bridgeObjectRelease(v11);
  if (v28 == 1)
  {
    uint64_t v29 = *(void *)(v1 + 104);
    uint64_t v12 = (void *)(*(void *)(v1 + 56) + *(void *)(v1 + 48));
    specialized MLTrainingSession.transition(to:)(4, &demangling cache variable for type metadata for MLTrainingSession<MLImageClassifier>.Metadata);
    uint64_t v13 = v12[3];
    uint64_t v14 = v12[4];
    uint64_t v30 = 4;
    __swift_project_boxed_opaque_existential_0Tm(v12, v13);
    (*(void (**)(char *, uint64_t, uint64_t))(v14 + 40))(&v30, v13, v14);
    if (v29)
    {
      uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
      return v15();
    }
LABEL_6:
    uint64_t v15 = *(uint64_t (**)(void))(v1 + 8);
    return v15();
  }
  if ([*(id *)(*(void *)(v1 + 40) + direct field offset for MLJob.progress) isCancelled])goto LABEL_6; {
  uint64_t v17 = *(void *)(v1 + 72);
  }
  uint64_t v18 = *(void *)(v1 + 48);
  uint64_t v19 = v18 + *(void *)(v1 + 64);
  uint64_t v20 = (void *)(v18 + *(void *)(v1 + 56));
  uint64_t v21 = v20[3];
  uint64_t v22 = v20[4];
  __swift_project_boxed_opaque_existential_0Tm(v20, v21);
  uint64_t v23 = *(void *)(*(int *)(v17 + 32) + v19);
  uint64_t v24 = *(int **)(v22 + 64);
  uint64_t v25 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)v24 + *v24);
  char v26 = (void *)swift_task_alloc(v24[1]);
  *(void *)(v1 + 96) = v26;
  void *v26 = v1;
  v26[1] = specialized MLTrainingSession.evaluate(job:);
  return v25(v23, v21, v22);
}

uint64_t specialized MLTrainingSession.evaluate(job:)(uint64_t a1, char a2)
{
  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v5 = *(void *)(*v3 + 96);
  uint64_t v6 = *v3;
  *(unsigned char *)(v6 + 121) = a2 & 1;
  *(void *)(v6 + 104) = v2;
  swift_task_dealloc(v5);
  if (v2) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v6 + 112) = a1;
  return swift_task_switch(specialized MLTrainingSession.evaluate(job:), 0, 0);
}

id specialized MLJob.reportProgress(completedUnitCount:phase:phaseUnitCount:metrics:)(uint64_t a1, unsigned int a2, int64_t a3, int a4, uint64_t a5, uint64_t a6)
{
  double v54 = *(double *)&a6;
  LODWORD(v55) = a4;
  int64_t v58 = a3;
  uint64_t v52 = a1;
  uint64_t v53 = type metadata accessor for Date(0);
  uint64_t v50 = *(void *)(v53 - 8);
  int64_t v8 = *(void *)(v50 + 64);
  char v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v51 = v48;
  CurrentValueSubject.value.getter();
  uint64_t v11 = a2;
  char v12 = specialized == infix<A>(_:_:)(a2, v48[0]);
  uint64_t v57 = v6;
  if ((v12 & 1) == 0 || !*(void *)(v6 + direct field offset for MLJob.phaseProgress))
  {
    switch((char)a2)
    {
      case 0:
        break;
      case 1:
      case 3:
      case 4:
        uint64_t v13 = v58 | -(uint64_t)((v55 & 1) != 0);
        uint64_t v56 = *(void *)(v57 + direct field offset for MLJob.progress);
        uint64_t v14 = objc_opt_self(NSProgress);
        uint64_t v47 = 1;
        goto LABEL_6;
      case 2:
        uint64_t v13 = v58 | -(uint64_t)((v55 & 1) != 0);
        uint64_t v56 = *(void *)(v57 + direct field offset for MLJob.progress);
        uint64_t v14 = objc_opt_self(NSProgress);
        uint64_t v47 = 7;
LABEL_6:
        uint64_t v6 = v57;
        id v15 = [v14 progressWithTotalUnitCount:v13 parent:v56 pendingUnitCount:v47];
        id v16 = v15;
        uint64_t v17 = *(void **)(v6 + direct field offset for MLJob.phaseProgress);
        *(void *)(v6 + direct field offset for MLJob.phaseProgress) = v16;

        break;
    }
    uint64_t v11 = a2;
    (*(void (**)(void))&v54)(a2);
  }
  uint64_t v18 = *(void **)(v6 + direct field offset for MLJob.progress);
  uint64_t v19 = v51;
  Date.init()(v11);
  double v54 = Date.timeIntervalSince(_:)(v6 + direct field offset for MLJob.startDate);
  (*(void (**)(void *, uint64_t))(v50 + 8))(v19, v53);
  double v20 = v54;
  v21.super.super.isa = Double._bridgeToObjectiveC()().super.super.isa;
  if (one-time initialization token for elapsedTimeKey != -1) {
    swift_once(&one-time initialization token for elapsedTimeKey, one-time initialization function for elapsedTimeKey);
  }
  [v18 setUserInfoObject:v21.super.super.isa forKey:static MLProgress.elapsedTimeKey];

  LOBYTE(v48[0]) = a2;
  uint64_t v22 = _bridgeAnythingNonVerbatimToObjectiveC<A>(_:)(v48, &type metadata for MLPhase);
  if (one-time initialization token for phaseKey != -1) {
    swift_once(&one-time initialization token for phaseKey, one-time initialization function for phaseKey);
  }
  [v18 setUserInfoObject:v22 forKey:static MLProgress.phaseKey];
  swift_unknownObjectRelease(v22);
  v23.super.super.isa = Int._bridgeToObjectiveC()().super.super.isa;
  if (one-time initialization token for itemCountKey != -1) {
    swift_once(&one-time initialization token for itemCountKey, one-time initialization function for itemCountKey);
  }
  [v18 setUserInfoObject:v23.super.super.isa forKey:static MLProgress.itemCountKey];

  if ((v55 & 1) == 0)
  {
    v24.super.super.isa = Int._bridgeToObjectiveC()().super.super.isa;
    if (one-time initialization token for totalItemCountKey != -1) {
      swift_once(&one-time initialization token for totalItemCountKey, one-time initialization function for totalItemCountKey);
    }
    [v18 setUserInfoObject:v24.super.super.isa forKey:static MLProgress.totalItemCountKey];
  }
  id v55 = v18;
  uint64_t v25 = 1 << *(unsigned char *)(a5 + 32);
  uint64_t v26 = ~(-1 << v25);
  if (v25 >= 64) {
    uint64_t v26 = -1;
  }
  unint64_t v27 = *(void *)(a5 + 64) & v26;
  int64_t v58 = (unint64_t)(v25 + 63) >> 6;
  swift_bridgeObjectRetain(a5);
  int64_t v28 = 0;
  while (1)
  {
    if (v27)
    {
      _BitScanForward64(&v29, v27);
      v27 &= v27 - 1;
      unint64_t v30 = v29 | (v28 << 6);
      goto LABEL_36;
    }
    BOOL v31 = __OFADD__(1, v28);
    int64_t v32 = v28 + 1;
    if (v31) {
      BUG();
    }
    if (v32 >= v58) {
      break;
    }
    unint64_t i = *(void *)(a5 + 8 * v32 + 64);
    if (i)
    {
      int64_t v34 = v32;
    }
    else
    {
      int64_t v34 = v32 + 1;
      if (v32 + 1 >= v58) {
        break;
      }
      unint64_t i = *(void *)(a5 + 8 * v32 + 72);
      if (!i)
      {
        int64_t v34 = v32 + 2;
        if (v32 + 2 >= v58) {
          break;
        }
        unint64_t i = *(void *)(a5 + 8 * v32 + 80);
        if (!i)
        {
          int64_t v34 = v32 + 3;
          if (v32 + 3 >= v58) {
            break;
          }
          unint64_t i = *(void *)(a5 + 8 * v32 + 88);
          if (!i)
          {
            int64_t v34 = v32 + 4;
            if (v32 + 4 >= v58) {
              break;
            }
            unint64_t i = *(void *)(a5 + 8 * v32 + 96);
            if (!i)
            {
              int64_t v34 = v32 + 5;
              if (v32 + 5 >= v58) {
                break;
              }
              for (unint64_t i = *(void *)(a5 + 8 * v32 + 104); !i; unint64_t i = *(void *)(a5 + 8 * v34 + 64))
              {
                BOOL v31 = __OFADD__(1, v34++);
                if (v31) {
                  BUG();
                }
                if (v34 >= v58) {
                  goto LABEL_80;
                }
              }
            }
          }
        }
      }
    }
    _BitScanForward64(&v35, i);
    unint64_t v27 = i & (i - 1);
    unint64_t v30 = v35 + (v34 << 6);
    int64_t v28 = v34;
LABEL_36:
    uint64_t v36 = *(unsigned __int8 *)(*(void *)(a5 + 48) + v30);
    if (*(void *)(a5 + 16))
    {
      unint64_t v37 = specialized __RawDictionaryStorage.find<A>(_:)(*(unsigned char *)(*(void *)(a5 + 48) + v30));
      if (v38)
      {
        uint64_t v39 = *(void *)(a5 + 56) + 32 * v37;
        uint64_t v53 = v27;
        outlined init with copy of Any(v39, (uint64_t)v48);
        uint64_t v40 = v49;
        uint64_t v41 = __swift_project_boxed_opaque_existential_0Tm(v48, v49);
        uint64_t v42 = _bridgeAnythingToObjectiveC<A>(_:)(v41, v40);
        unint64_t v27 = v53;
        __swift_destroy_boxed_opaque_existential_1Tm(v48);
        switch(v36)
        {
          case 0:
            goto LABEL_40;
          case 1:
            goto LABEL_43;
          case 2:
            goto LABEL_46;
          case 3:
            goto LABEL_49;
          case 4:
            goto LABEL_52;
          case 5:
            goto LABEL_55;
          case 6:
            goto LABEL_58;
          case 7:
            goto LABEL_61;
          case 8:
            goto LABEL_64;
          case 9:
            goto LABEL_67;
          case 10:
            goto LABEL_70;
        }
      }
    }
    uint64_t v42 = 0;
    switch(v36)
    {
      case 0:
LABEL_40:
        if (one-time initialization token for lossKey != -1) {
          swift_once(&one-time initialization token for lossKey, one-time initialization function for lossKey);
        }
        uint64_t v43 = &static MLProgress.lossKey;
        break;
      case 1:
LABEL_43:
        if (one-time initialization token for contentLossKey != -1) {
          swift_once(&one-time initialization token for contentLossKey, one-time initialization function for contentLossKey);
        }
        uint64_t v43 = &static MLProgress.contentLossKey;
        break;
      case 2:
LABEL_46:
        if (one-time initialization token for styleLossKey != -1) {
          swift_once(&one-time initialization token for styleLossKey, one-time initialization function for styleLossKey);
        }
        uint64_t v43 = &static MLProgress.styleLossKey;
        break;
      case 3:
LABEL_49:
        if (one-time initialization token for accuracyKey != -1) {
          swift_once(&one-time initialization token for accuracyKey, one-time initialization function for accuracyKey);
        }
        uint64_t v43 = &static MLProgress.accuracyKey;
        break;
      case 4:
LABEL_52:
        if (one-time initialization token for validationLossKey != -1) {
          swift_once(&one-time initialization token for validationLossKey, one-time initialization function for validationLossKey);
        }
        uint64_t v43 = &static MLProgress.validationLossKey;
        break;
      case 5:
LABEL_55:
        if (one-time initialization token for validationAccuracyKey != -1) {
          swift_once(&one-time initialization token for validationAccuracyKey, one-time initialization function for validationAccuracyKey);
        }
        uint64_t v43 = &static MLProgress.validationAccuracyKey;
        break;
      case 6:
LABEL_58:
        if (one-time initialization token for stylizedImageKey != -1) {
          swift_once(&one-time initialization token for stylizedImageKey, one-time initialization function for stylizedImageKey);
        }
        uint64_t v43 = &static MLProgress.stylizedImageKey;
        break;
      case 7:
LABEL_61:
        if (one-time initialization token for rootMeanSquaredErrorKey != -1) {
          swift_once(&one-time initialization token for rootMeanSquaredErrorKey, one-time initialization function for rootMeanSquaredErrorKey);
        }
        uint64_t v43 = &static MLProgress.rootMeanSquaredErrorKey;
        break;
      case 8:
LABEL_64:
        if (one-time initialization token for maximumErrorKey != -1) {
          swift_once(&one-time initialization token for maximumErrorKey, one-time initialization function for maximumErrorKey);
        }
        uint64_t v43 = &static MLProgress.maximumErrorKey;
        break;
      case 9:
LABEL_67:
        if (one-time initialization token for validationRootMeanSquaredErrorKey != -1) {
          swift_once(&one-time initialization token for validationRootMeanSquaredErrorKey, one-time initialization function for validationRootMeanSquaredErrorKey);
        }
        uint64_t v43 = &static MLProgress.validationRootMeanSquaredErrorKey;
        break;
      case 10:
LABEL_70:
        if (one-time initialization token for validationMaximumErrorKey != -1) {
          swift_once(&one-time initialization token for validationMaximumErrorKey, one-time initialization function for validationMaximumErrorKey);
        }
        uint64_t v43 = &static MLProgress.validationMaximumErrorKey;
        break;
    }
    id v44 = (id)*v43;
    [v55 setUserInfoObject:v42 forKey:v44];
    swift_unknownObjectRelease(v42);
  }
LABEL_80:
  swift_release();
  id result = (id)direct field offset for MLJob.phaseProgress;
  uint64_t v46 = *(void **)(v57 + direct field offset for MLJob.phaseProgress);
  if (v46) {
    return [v46 setCompletedUnitCount:v52];
  }
  return result;
}

{
  uint64_t v6;
  int64_t v7;
  void *v8;
  void *v9;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  id v13;
  id v14;
  void *v15;
  void *v16;
  double v17;
  NSNumber v18;
  uint64_t v19;
  NSNumber v20;
  uint64_t v21;
  NSNumber v22;
  uint64_t v23;
  uint64_t v24;
  unint64_t v25;
  int64_t v26;
  unint64_t v27;
  unint64_t v28;
  BOOL v29;
  int64_t v30;
  unint64_t i;
  int64_t v32;
  unint64_t v33;
  uint64_t v34;
  unint64_t v35;
  char v36;
  uint64_t v37;
  void *v38;
  uint64_t v39;
  uint64_t *v40;
  id v41;
  id v42;
  id result;
  void *v44;
  uint64_t v45;
  void v46[3];
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  double v52;
  uint64_t v53;
  uint64_t v54;
  int64_t v55;
  id v56;

  uint64_t v52 = *(double *)&a6;
  uint64_t v50 = a5;
  LODWORD(v56) = a4;
  id v55 = a3;
  uint64_t v51 = a1;
  uint64_t v48 = type metadata accessor for Date(0);
  uint64_t v49 = *(void *)(v48 - 8);
  uint64_t v7 = *(void *)(v49 + 64);
  int64_t v8 = alloca(v7);
  char v9 = alloca(v7);
  CurrentValueSubject.value.getter();
  uint64_t v10 = a2;
  double v54 = v6;
  if ((specialized == infix<A>(_:_:)(a2, v46[0]) & 1) == 0
    || !*(void *)(v6 + direct field offset for MLJob.phaseProgress))
  {
    switch((char)a2)
    {
      case 0:
        break;
      case 1:
      case 3:
      case 4:
        uint64_t v11 = v55 | -(uint64_t)((v56 & 1) != 0);
        uint64_t v53 = *(void *)(v54 + direct field offset for MLJob.progress);
        char v12 = objc_opt_self(NSProgress);
        uint64_t v45 = 1;
        goto LABEL_6;
      case 2:
        uint64_t v11 = v55 | -(uint64_t)((v56 & 1) != 0);
        uint64_t v53 = *(void *)(v54 + direct field offset for MLJob.progress);
        char v12 = objc_opt_self(NSProgress);
        uint64_t v45 = 7;
LABEL_6:
        uint64_t v6 = v54;
        uint64_t v13 = [v12 progressWithTotalUnitCount:v11 parent:v53 pendingUnitCount:v45];
        uint64_t v14 = v13;
        id v15 = *(void **)(v54 + direct field offset for MLJob.phaseProgress);
        *(void *)(v54 + direct field offset for MLJob.phaseProgress) = v14;

        break;
    }
    uint64_t v10 = a2;
    (*(void (**)(void))&v52)(a2);
  }
  id v16 = *(void **)(v6 + direct field offset for MLJob.progress);
  Date.init()(v10);
  uint64_t v52 = Date.timeIntervalSince(_:)(v6 + direct field offset for MLJob.startDate);
  (*(void (**)(void *, uint64_t))(v49 + 8))(v46, v48);
  uint64_t v17 = v52;
  v18.super.super.isa = Double._bridgeToObjectiveC()().super.super.isa;
  if (one-time initialization token for elapsedTimeKey != -1) {
    swift_once(&one-time initialization token for elapsedTimeKey, one-time initialization function for elapsedTimeKey);
  }
  [v16 setUserInfoObject:v18.super.super.isa forKey:static MLProgress.elapsedTimeKey];

  LOBYTE(v46[0]) = a2;
  uint64_t v19 = _bridgeAnythingNonVerbatimToObjectiveC<A>(_:)(v46, &type metadata for MLPhase);
  if (one-time initialization token for phaseKey != -1) {
    swift_once(&one-time initialization token for phaseKey, one-time initialization function for phaseKey);
  }
  [v16 setUserInfoObject:v19 forKey:static MLProgress.phaseKey];
  swift_unknownObjectRelease(v19);
  v20.super.super.isa = Int._bridgeToObjectiveC()().super.super.isa;
  NSNumber v21 = v50;
  if (one-time initialization token for itemCountKey != -1) {
    swift_once(&one-time initialization token for itemCountKey, one-time initialization function for itemCountKey);
  }
  [v16 setUserInfoObject:v20.super.super.isa forKey:static MLProgress.itemCountKey];

  if ((v56 & 1) == 0)
  {
    v22.super.super.isa = Int._bridgeToObjectiveC()().super.super.isa;
    if (one-time initialization token for totalItemCountKey != -1) {
      swift_once(&one-time initialization token for totalItemCountKey, one-time initialization function for totalItemCountKey);
    }
    [v16 setUserInfoObject:v22.super.super.isa forKey:static MLProgress.totalItemCountKey];
  }
  NSNumber v23 = 1 << *(unsigned char *)(v21 + 32);
  NSNumber v24 = ~(-1 << v23);
  if (v23 >= 64) {
    NSNumber v24 = -1;
  }
  uint64_t v25 = *(void *)(v21 + 64) & v24;
  id v55 = (unint64_t)(v23 + 63) >> 6;
  swift_bridgeObjectRetain(v21);
  uint64_t v26 = 0;
  uint64_t v56 = v16;
  while (1)
  {
    if (v25)
    {
      _BitScanForward64(&v27, v25);
      v25 &= v25 - 1;
      int64_t v28 = v27 | (v26 << 6);
      goto LABEL_38;
    }
    unint64_t v29 = __OFADD__(1, v26);
    unint64_t v30 = v26 + 1;
    if (v29) {
      BUG();
    }
    if (v30 >= v55) {
      break;
    }
    unint64_t i = *(void *)(v21 + 8 * v30 + 64);
    if (i)
    {
      int64_t v32 = v30;
    }
    else
    {
      int64_t v32 = v30 + 1;
      if (v30 + 1 >= v55) {
        break;
      }
      unint64_t i = *(void *)(v21 + 8 * v30 + 72);
      if (!i)
      {
        int64_t v32 = v30 + 2;
        if (v30 + 2 >= v55) {
          break;
        }
        unint64_t i = *(void *)(v21 + 8 * v30 + 80);
        if (!i)
        {
          int64_t v32 = v30 + 3;
          if (v30 + 3 >= v55) {
            break;
          }
          unint64_t i = *(void *)(v21 + 8 * v30 + 88);
          if (!i)
          {
            int64_t v32 = v30 + 4;
            if (v30 + 4 >= v55) {
              break;
            }
            unint64_t i = *(void *)(v21 + 8 * v30 + 96);
            if (!i)
            {
              int64_t v32 = v30 + 5;
              if (v30 + 5 >= v55) {
                break;
              }
              unint64_t i = *(void *)(v21 + 8 * v30 + 104);
              if (!i)
              {
                int64_t v32 = v30 + 6;
                if (v30 + 6 >= v55) {
                  break;
                }
                for (unint64_t i = *(void *)(v21 + 8 * v30 + 112); !i; unint64_t i = *(void *)(v21 + 8 * v32 + 64))
                {
                  unint64_t v29 = __OFADD__(1, v32++);
                  if (v29) {
                    BUG();
                  }
                  if (v32 >= v55) {
                    goto LABEL_82;
                  }
                }
              }
            }
          }
        }
      }
    }
    _BitScanForward64(&v33, i);
    uint64_t v25 = i & (i - 1);
    int64_t v28 = v33 + (v32 << 6);
    uint64_t v26 = v32;
LABEL_38:
    int64_t v34 = *(unsigned __int8 *)(*(void *)(v21 + 48) + v28);
    if (*(void *)(v21 + 16))
    {
      unint64_t v35 = specialized __RawDictionaryStorage.find<A>(_:)(*(unsigned char *)(*(void *)(v21 + 48) + v28));
      if (v36)
      {
        outlined init with copy of Any(*(void *)(v21 + 56) + 32 * v35, (uint64_t)v46);
        unint64_t v37 = v47;
        char v38 = __swift_project_boxed_opaque_existential_0Tm(v46, v47);
        uint64_t v39 = _bridgeAnythingToObjectiveC<A>(_:)(v38, v37);
        __swift_destroy_boxed_opaque_existential_1Tm(v46);
        switch(v34)
        {
          case 0:
            goto LABEL_42;
          case 1:
            goto LABEL_45;
          case 2:
            goto LABEL_48;
          case 3:
            goto LABEL_51;
          case 4:
            goto LABEL_54;
          case 5:
            goto LABEL_57;
          case 6:
            goto LABEL_60;
          case 7:
            goto LABEL_63;
          case 8:
            goto LABEL_66;
          case 9:
            goto LABEL_69;
          case 10:
            goto LABEL_72;
        }
      }
    }
    uint64_t v39 = 0;
    switch(v34)
    {
      case 0:
LABEL_42:
        if (one-time initialization token for lossKey != -1) {
          swift_once(&one-time initialization token for lossKey, one-time initialization function for lossKey);
        }
        uint64_t v40 = &static MLProgress.lossKey;
        break;
      case 1:
LABEL_45:
        if (one-time initialization token for contentLossKey != -1) {
          swift_once(&one-time initialization token for contentLossKey, one-time initialization function for contentLossKey);
        }
        uint64_t v40 = &static MLProgress.contentLossKey;
        break;
      case 2:
LABEL_48:
        if (one-time initialization token for styleLossKey != -1) {
          swift_once(&one-time initialization token for styleLossKey, one-time initialization function for styleLossKey);
        }
        uint64_t v40 = &static MLProgress.styleLossKey;
        break;
      case 3:
LABEL_51:
        if (one-time initialization token for accuracyKey != -1) {
          swift_once(&one-time initialization token for accuracyKey, one-time initialization function for accuracyKey);
        }
        uint64_t v40 = &static MLProgress.accuracyKey;
        break;
      case 4:
LABEL_54:
        if (one-time initialization token for validationLossKey != -1) {
          swift_once(&one-time initialization token for validationLossKey, one-time initialization function for validationLossKey);
        }
        uint64_t v40 = &static MLProgress.validationLossKey;
        break;
      case 5:
LABEL_57:
        if (one-time initialization token for validationAccuracyKey != -1) {
          swift_once(&one-time initialization token for validationAccuracyKey, one-time initialization function for validationAccuracyKey);
        }
        uint64_t v40 = &static MLProgress.validationAccuracyKey;
        break;
      case 6:
LABEL_60:
        if (one-time initialization token for stylizedImageKey != -1) {
          swift_once(&one-time initialization token for stylizedImageKey, one-time initialization function for stylizedImageKey);
        }
        uint64_t v40 = &static MLProgress.stylizedImageKey;
        break;
      case 7:
LABEL_63:
        if (one-time initialization token for rootMeanSquaredErrorKey != -1) {
          swift_once(&one-time initialization token for rootMeanSquaredErrorKey, one-time initialization function for rootMeanSquaredErrorKey);
        }
        uint64_t v40 = &static MLProgress.rootMeanSquaredErrorKey;
        break;
      case 8:
LABEL_66:
        if (one-time initialization token for maximumErrorKey != -1) {
          swift_once(&one-time initialization token for maximumErrorKey, one-time initialization function for maximumErrorKey);
        }
        uint64_t v40 = &static MLProgress.maximumErrorKey;
        break;
      case 9:
LABEL_69:
        if (one-time initialization token for validationRootMeanSquaredErrorKey != -1) {
          swift_once(&one-time initialization token for validationRootMeanSquaredErrorKey, one-time initialization function for validationRootMeanSquaredErrorKey);
        }
        uint64_t v40 = &static MLProgress.validationRootMeanSquaredErrorKey;
        break;
      case 10:
LABEL_72:
        if (one-time initialization token for validationMaximumErrorKey != -1) {
          swift_once(&one-time initialization token for validationMaximumErrorKey, one-time initialization function for validationMaximumErrorKey);
        }
        uint64_t v40 = &static MLProgress.validationMaximumErrorKey;
        break;
    }
    uint64_t v41 = v56;
    uint64_t v42 = (id)*v40;
    [v41 setUserInfoObject:v39 forKey:v42];
    swift_unknownObjectRelease(v39);

    NSNumber v21 = v50;
  }
LABEL_82:
  swift_release();
  id result = (id)direct field offset for MLJob.phaseProgress;
  id v44 = *(void **)(v54 + direct field offset for MLJob.phaseProgress);
  if (v44) {
    return [v44 setCompletedUnitCount:v51];
  }
  return result;
}

NSURL *specialized MLTrainingSession.saveFeatureExtractionCheckpoint(to:)(uint64_t a1, uint64_t *a2, void (*a3)(void))
{
  uint64_t v91 = a3;
  uint64_t v95 = v4;
  uint64_t v94 = a1;
  uint64_t v85 = v3;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                             - 8)
                 + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v78 = &v77;
  uint64_t v80 = type metadata accessor for Date(0);
  uint64_t v79 = *(void *)(v80 - 8);
  int64_t v9 = *(void *)(v79 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v81 = &v77;
  uint64_t v77 = type metadata accessor for URL(0);
  uint64_t v83 = *(void *)(v77 - 8);
  int64_t v12 = *(void *)(v83 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v84 = &v77;
  uint64_t v89 = (int *)type metadata accessor for MLCheckpoint(0);
  uint64_t v93 = *((void *)v89 - 1);
  int64_t v15 = *(void *)(v93 + 64);
  id v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v86 = &v77;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  uint64_t v82 = &v77;
  double v20 = alloca(v15);
  NSNumber v21 = alloca(v15);
  uint64_t v90 = &v77;
  uint64_t v22 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 24);
  uint64_t v87 = *(void *)(direct field offset for MLTrainingSession.delegate + v5 + 32);
  uint64_t v88 = __swift_project_boxed_opaque_existential_0Tm((void *)(direct field offset for MLTrainingSession.delegate + v5), v22);
  uint64_t v23 = *(void *)(*(void *)v5 + 112);
  uint64_t v92 = v5;
  uint64_t v24 = v5 + v23;
  swift_beginAccess(v24, v99, 0, 0);
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(a2);
  LOBYTE(v98[0]) = *(unsigned char *)(*(int *)(v25 + 28) + v24);
  uint64_t v26 = v95;
  char v27 = (*(uint64_t (**)(uint64_t, id *, void, uint64_t))(v87 + 72))(v94, v98, *(void *)(*(int *)(v25 + 32) + v24), v22);
  if (!v26)
  {
    uint64_t v97 = (int *)v25;
    uint64_t v96 = v24;
    if (v27)
    {
      uint64_t v95 = 0;
      int64_t v28 = *(void (**)(uint64_t *, uint64_t))(v83 + 16);
      unint64_t v29 = v84;
      uint64_t v30 = v77;
      v28(v84, v94);
      LOBYTE(v87) = *(unsigned char *)(v96 + v97[7]);
      uint64_t v88 = *(void **)(v96 + v97[8]);
      uint64_t v31 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
      uint64_t v94 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v31);
      int64_t v32 = v82;
      uint64_t v33 = v82;
      int64_t v34 = v29;
      uint64_t v35 = v30;
      ((void (*)(uint64_t *, uint64_t *, uint64_t))v28)(v82, v34, v30);
      uint64_t v36 = v89;
      *((unsigned char *)v32 + v89[5]) = v87;
      *(uint64_t *)((char *)v32 + v36[6]) = (uint64_t)v88;
      unint64_t v37 = v81;
      Date.init()(v33);
      (*(void (**)(uint64_t *, uint64_t))(v83 + 8))(v84, v35);
      (*(void (**)(char *, uint64_t *, uint64_t))(v79 + 32))((char *)v32 + v36[7], v37, v80);
      *(uint64_t *)((char *)v32 + v36[8]) = v94;
      uint64_t v38 = (uint64_t)v32;
      uint64_t v39 = v97;
      outlined init with take of MLClassifierMetrics(v38, (uint64_t)v90, type metadata accessor for MLCheckpoint);
      uint64_t v40 = (uint64_t)v78;
      specialized BidirectionalCollection.last.getter(*(void *)(v96 + v39[11]));
      if (__swift_getEnumTagSinglePayload(v40, 1, (uint64_t)v36) == 1)
      {
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v40, &demangling cache variable for type metadata for MLCheckpoint?);
LABEL_16:
        uint64_t v55 = v96;
        swift_beginAccess(v96, v98, 33, 0);
        uint64_t v56 = v39[11];
        specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
        uint64_t v57 = *(void *)(*(void *)(v55 + v56) + 16);
        specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v57);
        uint64_t v58 = *(void *)(v55 + v56);
        *(void *)(v58 + 16) = v57 + 1;
        uint64_t v59 = (uint64_t)v90;
        outlined init with copy of MLTrainingSessionParameters((uint64_t)v90, v58 + ((*(unsigned __int8 *)(v93 + 80) + 32) & ~*(unsigned __int8 *)(v93 + 80)) + *(void *)(v93 + 72) * v57, type metadata accessor for MLCheckpoint);
        swift_endAccess(v98);
        uint64_t v60 = v91;
      }
      else
      {
        unint64_t v43 = 0xEB0000000064657ALL;
        uint64_t v44 = v40;
        uint64_t v45 = (uint64_t)v86;
        outlined init with take of MLClassifierMetrics(v44, (uint64_t)v86, type metadata accessor for MLCheckpoint);
        switch(*(unsigned char *)(v45 + v36[5]))
        {
          case 0:
            uint64_t v46 = 0x696C616974696E69;
            goto LABEL_12;
          case 1:
            swift_bridgeObjectRelease(110);
            goto LABEL_13;
          case 2:
            uint64_t v46 = 0x676E696E69617274;
            unint64_t v43 = 0xE800000000000000;
            goto LABEL_12;
          case 3:
            uint64_t v46 = 0x697461756C617665;
            unint64_t v43 = 0xEA0000000000676ELL;
            goto LABEL_12;
          case 4:
            unint64_t v43 = 0xEB00000000676E69;
            uint64_t v46 = 0x636E657265666E69;
LABEL_12:
            char v47 = _stringCompareWithSmolCheck(_:_:expecting:)(v46, v43, 0x6974636172747865, 0xEA0000000000676ELL, 0);
            swift_bridgeObjectRelease(v43);
            if ((v47 & 1) == 0)
            {
              outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLCheckpoint);
              uint64_t v39 = v97;
              goto LABEL_16;
            }
LABEL_13:
            uint64_t v48 = objc_opt_self(NSFileManager);
            id v49 = [v48 defaultManager];
            uint64_t v50 = (NSURL *)v49;
            URL._bridgeToObjectiveC()(v50);
            uint64_t v52 = v51;
            v98[0] = 0;
            unsigned __int8 v53 = [(NSURL *)v50 removeItemAtURL:v51 error:v98];

            id v54 = v98[0];
            if (v53)
            {
              v98[0];
            }
            else
            {
              id v61 = v98[0];
              uint64_t v62 = _convertNSErrorToError(_:)(v54);

              swift_willThrow(v61, "removeItemAtURL:error:", v63, v64, v65, v66);
              uint64_t v95 = 0;
              swift_errorRelease(v62);
            }
            uint64_t v67 = v97;
            uint64_t v68 = v96;
            unint64_t v69 = *(void *)(*(void *)(v96 + v97[11]) + 16);
            swift_beginAccess(v96, v98, 33, 0);
            uint64_t v70 = v67[11];
            uint64_t v71 = *(void **)(v68 + v70);
            char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v71);
            *(void *)(v68 + v70) = v71;
            if (!isUniquelyReferenced_nonNull_native)
            {
              uint64_t v71 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v71);
              *(void *)(v68 + v70) = v71;
            }
            uint64_t v60 = v91;
            if (!v69) {
              BUG();
            }
            if (v69 > v71[2]) {
              BUG();
            }
            uint64_t v73 = (uint64_t)v71
                + ((*(unsigned __int8 *)(v93 + 80) + 32) & ~*(unsigned __int8 *)(v93 + 80))
                + *(void *)(v93 + 72) * (v69 - 1);
            uint64_t v59 = (uint64_t)v90;
            outlined assign with copy of MLCheckpoint((uint64_t)v90, v73);
            swift_endAccess(v98);
            outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v86, type metadata accessor for MLCheckpoint);
            break;
        }
      }
      uint64_t v74 = v95;
      v60();
      if (v74)
      {
        outlined destroy of MLActivityClassifier.ModelParameters(v59, type metadata accessor for MLCheckpoint);
        return __stack_chk_guard;
      }
      uint64_t v75 = v59;
      uint64_t v42 = v85;
      outlined init with take of MLClassifierMetrics(v75, v85, type metadata accessor for MLCheckpoint);
      uint64_t v41 = 0;
    }
    else
    {
      uint64_t v41 = 1;
      uint64_t v42 = v85;
    }
    __swift_storeEnumTagSinglePayload(v42, v41, 1, (uint64_t)v89);
  }
  return __stack_chk_guard;
}

uint64_t MLJob.startDate.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = direct field offset for MLJob.startDate + v1;
  uint64_t v4 = type metadata accessor for Date(0);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(v2, v3, v4);
}

id MLJob.progress.getter()
{
  return *(id *)(v0 + direct field offset for MLJob.progress);
}

uint64_t MLJob.checkpoints.getter()
{
  uint64_t v0 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  uint64_t v1 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type PassthroughSubject<MLCheckpoint, Never> and conformance PassthroughSubject<A, B>, &demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>, (uint64_t)&protocol conformance descriptor for PassthroughSubject<A, B>);
  return Publisher.eraseToAnyPublisher()(v0, v1);
}

uint64_t MLJob.result.getter()
{
  v15[1] = v0;
  uint64_t v1 = *(void *)(*v0 + 80);
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for Error);
  uint64_t v3 = type metadata accessor for PassthroughSubject(255, v1, v2, &protocol self-conformance witness table for Error);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for PassthroughSubject<A, B>, v3);
  uint64_t Connectable = type metadata accessor for Publishers.MakeConnectable(0, v3, WitnessTable);
  uint64_t v16 = *(void *)(Connectable - 8);
  int64_t v6 = *(void *)(v16 + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  v15[0] = v0[3];
  swift_retain();
  Publishers.MakeConnectable.init(upstream:)(v15, v3, WitnessTable);
  uint64_t v9 = swift_getWitnessTable(&protocol conformance descriptor for Publishers.MakeConnectable<A>, Connectable);
  uint64_t v10 = ConnectablePublisher.autoconnect()(Connectable, v9);
  (*(void (**)(void *, uint64_t))(v16 + 8))(v15, Connectable);
  v15[0] = v10;
  uint64_t v11 = type metadata accessor for Publishers.Autoconnect(0, Connectable, v9);
  uint64_t v12 = swift_getWitnessTable(&protocol conformance descriptor for Publishers.Autoconnect<A>, v11);
  uint64_t v13 = Publisher.eraseToAnyPublisher()(v11, v12);
  swift_release();
  return v13;
}

uint64_t MLJob.phase.getter()
{
  uint64_t v0 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  uint64_t v1 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type CurrentValueSubject<MLPhase, Never> and conformance CurrentValueSubject<A, B>, &demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>, (uint64_t)&protocol conformance descriptor for CurrentValueSubject<A, B>);
  return Publisher.eraseToAnyPublisher()(v0, v1);
}

uint64_t specialized MLJob.currentPhase.setter(char a1)
{
  v2[0] = a1;
  return CurrentValueSubject.value.setter(v2);
}

{
  return specialized MLJob.currentPhase.setter(a1);
}

{
  return specialized MLJob.currentPhase.setter(a1);
}

Swift::Void __swiftcall MLJob.cancel()()
{
  [*(id *)(v0 + direct field offset for MLJob.progress) cancel];
}

void *specialized MLJob.init(_:)(void *a1, uint64_t a2)
{
  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLActivityClassifier, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39DD08, 40, 7);
  v10[2] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[3] = a1;
  v10[4] = a2;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLActivityClassifier.resume(_:), (uint64_t)v10, (uint64_t)&unk_39DD30, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLHandPoseClassifier, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39DCB8, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLHandPoseClassifier.resume(_:), (uint64_t)v10, (uint64_t)&unk_39DCE0, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLRandomForestRegressor, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39DC68, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLRandomForestRegressor.resume(_:), (uint64_t)v10, (uint64_t)&unk_39DC90, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLStyleTransfer, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39DC18, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLStyleTransfer.resume(_:), (uint64_t)v10, (uint64_t)&unk_39DC40, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLLogisticRegressionClassifier, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39DBC8, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLLogisticRegressionClassifier.resume(_:), (uint64_t)v10, (uint64_t)&unk_39DBF0, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLDecisionTreeRegressor, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39DB78, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLDecisionTreeRegressor.resume(_:), (uint64_t)v10, (uint64_t)&unk_39DBA0, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLActionClassifier, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39DB28, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLActionClassifier.resume(_:), (uint64_t)v10, (uint64_t)&unk_39DB50, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLHandActionClassifier, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39DAD8, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLHandActionClassifier.resume(_:), (uint64_t)v10, (uint64_t)&unk_39DB00, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLRandomForestClassifier, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39DA88, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLRandomForestClassifier.resume(_:), (uint64_t)v10, (uint64_t)&unk_39DAB0, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLBoostedTreeRegressor, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39DA38, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLBoostedTreeRegressor.resume(_:), (uint64_t)v10, (uint64_t)&unk_39DA60, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLObjectDetector, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39D9E8, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLObjectDetector.resume(_:), (uint64_t)v10, (uint64_t)&unk_39DA10, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLDecisionTreeClassifier, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39D998, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLDecisionTreeClassifier.resume(_:), (uint64_t)v10, (uint64_t)&unk_39D9C0, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLSoundClassifier, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39D948, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLSoundClassifier.resume(_:), (uint64_t)v10, (uint64_t)&unk_39D970, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLBoostedTreeClassifier, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39D8A8, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLBoostedTreeClassifier.resume(_:), (uint64_t)v10, (uint64_t)&unk_39D8D0, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLLinearRegressor, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39D858, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLLinearRegressor.resume(_:), (uint64_t)v10, (uint64_t)&unk_39D880, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

{
  uint64_t v2;
  uint64_t v4;
  void *v5;
  id v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  unsigned char v12[41];

  v12[0] = HIBYTE(v2);
  Date.init()(a1);
  uint64_t v4 = direct field offset for MLJob.progress;
  uint64_t v5 = objc_opt_self(NSProgress);
  id v6 = [v5 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v4) = v6;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  a1[2] = PassthroughSubject.init()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLImageClassifier, Error>);
  swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
  a1[3] = PassthroughSubject.init()(v8);
  v12[0] = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v12);
  uint64_t v10 = (void *)swift_allocObject(&unk_39D808, 40, 7);
  v10[2] = a2;
  v10[3] = partial apply for specialized closure #1 in MLJob.init(_:);
  v10[4] = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLImageClassifier.resume(_:), (uint64_t)v10, (uint64_t)&unk_39D830, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

void *specialized MLJob.init(_:)(void *a1, uint64_t a2, uint64_t a3)
{
  v15[0] = HIBYTE(v3);
  Date.init()(a1);
  uint64_t v6 = direct field offset for MLJob.progress;
  uint64_t v7 = objc_opt_self(NSProgress);
  id v8 = [v7 progressWithTotalUnitCount:10];
  *(void *)((char *)a1 + v6) = v8;
  *(void *)((char *)a1 + direct field offset for MLJob.phaseProgress) = 0;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLCheckpoint, Never>);
  swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
  a1[2] = PassthroughSubject.init()(v9);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PassthroughSubject<MLSoundClassifier.DataSource, Error>);
  swift_allocObject(v10, *(unsigned int *)(v10 + 48), *(unsigned __int16 *)(v10 + 52));
  a1[3] = PassthroughSubject.init()(v10);
  v15[0] = 0;
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CurrentValueSubject<MLPhase, Never>);
  swift_allocObject(v11, *(unsigned int *)(v11 + 48), *(unsigned __int16 *)(v11 + 52));
  a1[4] = CurrentValueSubject.init(_:)(v15);
  uint64_t v12 = swift_allocObject(&unk_39D8F8, 80, 7);
  *(void *)(v12 + 16) = a2;
  long long v13 = *(_OWORD *)(a3 + 16);
  *(_OWORD *)(v12 + 24) = *(_OWORD *)a3;
  *(_OWORD *)(v12 + 40) = v13;
  *(unsigned char *)(v12 + 56) = *(unsigned char *)(a3 + 32);
  *(void *)(v12 + 64) = partial apply for specialized closure #1 in MLJob.init(_:);
  *(void *)(v12 + 72) = a1;
  swift_retain_n(a1);
  swift_retain();
  specialized MLTrainingSession.resume(job:completion:)((uint64_t)a1, (uint64_t)partial apply for closure #1 in closure #1 in static MLSoundClassifier.extractFeatures(trainingData:parameters:sessionParameters:), v12, (uint64_t)&unk_39D920, (uint64_t)&async function pointer to partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:));
  swift_release();
  swift_release();
  swift_release();
  swift_release();
  return a1;
}

uint64_t specialized closure #1 in MLJob.init(_:)(uint64_t a1, uint64_t a2, uint64_t (*a3)(void), uint64_t *a4)
{
  uint64_t v17 = a2;
  uint64_t v16 = a3;
  int64_t v5 = *(void *)(*(void *)(a3(0) - 8) + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(a4);
  int64_t v9 = *(void *)(*(void *)(v8 - 8) + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, (uint64_t)&v15, a4);
  if (swift_getEnumCaseMultiPayload(&v15, v8) == 1)
  {
    uint64_t v12 = v15;
    swift_errorRetain(v15);
    PassthroughSubject.send(completion:)(&v15);
    swift_errorRelease(v12);
    return swift_errorRelease(v12);
  }
  else
  {
    uint64_t v14 = v16;
    outlined init with take of MLClassifierMetrics((uint64_t)&v15, (uint64_t)&v15, v16);
    PassthroughSubject.send(_:)(&v15);
    uint64_t v15 = 0;
    PassthroughSubject.send(completion:)(&v15);
    return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v15, v14);
  }
}

void *MLJob.deinit()
{
  swift_release(v0[2]);
  swift_release(v0[3]);
  swift_release(v0[4]);
  uint64_t v1 = (char *)v0 + direct field offset for MLJob.startDate;
  uint64_t v2 = type metadata accessor for Date(0);
  (*(void (**)(char *, uint64_t))(*(void *)(v2 - 8) + 8))(v1, v2);

  return v0;
}

uint64_t MLJob.__deallocating_deinit()
{
  MLJob.deinit();
  return swift_deallocClassInstance(v0, *(unsigned int *)(*(void *)v0 + 48), *(unsigned __int16 *)(*(void *)v0 + 52));
}

void protocol witness for Cancellable.cancel() in conformance MLJob<A>()
{
}

uint64_t type metadata completion function for MLJob(uint64_t a1)
{
  v3[0] = (char *)&value witness table for Builtin.NativeObject + 64;
  v3[1] = (char *)&value witness table for Builtin.NativeObject + 64;
  v3[2] = (char *)&value witness table for Builtin.NativeObject + 64;
  uint64_t result = type metadata accessor for Date(319);
  if (v2 <= 0x3F)
  {
    void v3[3] = *(void *)(result - 8) + 64;
    v3[4] = (char *)&value witness table for Builtin.UnknownObject + 64;
    v3[5] = "\b";
    uint64_t result = swift_initClassMetadata2(a1, 0, 6, v3, a1 + 88);
    if (!result) {
      return 0;
    }
  }
  return result;
}

uint64_t type metadata accessor for MLJob(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for MLJob);
}

uint64_t method lookup function for MLJob(uint64_t a1, uint64_t a2)
{
  return swift_lookUpClassMethod(a1, a2, &nominal type descriptor for MLJob);
}

uint64_t partial apply for specialized closure #1 in MLJob.init(_:)(uint64_t a1)
{
  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLImageClassifier, &demangling cache variable for type metadata for Result<MLImageClassifier, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLLinearRegressor, &demangling cache variable for type metadata for Result<MLLinearRegressor, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLBoostedTreeClassifier, &demangling cache variable for type metadata for Result<MLBoostedTreeClassifier, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLSoundClassifier.DataSource, &demangling cache variable for type metadata for Result<MLSoundClassifier.DataSource, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLSoundClassifier, &demangling cache variable for type metadata for Result<MLSoundClassifier, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLDecisionTreeClassifier, &demangling cache variable for type metadata for Result<MLDecisionTreeClassifier, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLObjectDetector, &demangling cache variable for type metadata for Result<MLObjectDetector, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLBoostedTreeRegressor, &demangling cache variable for type metadata for Result<MLBoostedTreeRegressor, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLRandomForestClassifier, &demangling cache variable for type metadata for Result<MLRandomForestClassifier, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLHandActionClassifier, &demangling cache variable for type metadata for Result<MLHandActionClassifier, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLActionClassifier, &demangling cache variable for type metadata for Result<MLActionClassifier, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLDecisionTreeRegressor, &demangling cache variable for type metadata for Result<MLDecisionTreeRegressor, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLLogisticRegressionClassifier, &demangling cache variable for type metadata for Result<MLLogisticRegressionClassifier, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLStyleTransfer, &demangling cache variable for type metadata for Result<MLStyleTransfer, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLRandomForestRegressor, &demangling cache variable for type metadata for Result<MLRandomForestRegressor, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLHandPoseClassifier, &demangling cache variable for type metadata for Result<MLHandPoseClassifier, Error>);
}

{
  uint64_t v1;

  return specialized closure #1 in MLJob.init(_:)(a1, v1, type metadata accessor for MLActivityClassifier, &demangling cache variable for type metadata for Result<MLActivityClassifier, Error>);
}

uint64_t sub_30CB9F()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLImageClassifier.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLImageClassifier.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30CBD6()
{
  return objectdestroy_2Tm();
}

uint64_t partial apply for specialized closure #1 in MLTrainingSession.resume(job:completion:)(uint64_t a1)
{
  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AEC94);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AECD4);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AED14);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AED54);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AED94);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AEDD4);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AEE14);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AEE54);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AEE94);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AEED4);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AEF14);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AEF54);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AEF94);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AEFD4);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AF014);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AF054);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

{
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v10 = v1[6];
  uint64_t v5 = v1[7];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AF094);
  *(void *)(v2 + 16) = v6;
  *uint64_t v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return specialized closure #1 in MLTrainingSession.resume(job:completion:)(a1, v3, v4, v8, v9, v10, v5);
}

uint64_t outlined assign with copy of MLCheckpoint(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLCheckpoint(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 24))(a2, a1, v2);
  return a2;
}

uint64_t sub_30CCD0()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLLinearRegressor.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLLinearRegressor.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30CCF8()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30CDB0()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLBoostedTreeClassifier.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLBoostedTreeClassifier.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30CDD8()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30CE90()
{
  swift_release(*(void *)(v0 + 16));
  swift_release(*(void *)(v0 + 72));
  return swift_deallocObject(v0, 80, 7);
}

uint64_t partial apply for closure #1 in closure #1 in static MLSoundClassifier.extractFeatures(trainingData:parameters:sessionParameters:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLSoundClassifier.extractFeatures(trainingData:parameters:sessionParameters:)(a1, a2 & 1, *(void *)(v2 + 16), v2 + 24, *(void (**)(uint64_t *))(v2 + 64), *(void *)(v2 + 72));
}

uint64_t sub_30CED7()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30CF8F()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLSoundClassifier.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLSoundClassifier.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30CFB7()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30D06F()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLDecisionTreeClassifier.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLDecisionTreeClassifier.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30D097()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30D14F()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLObjectDetector.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLObjectDetector.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(void *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30D177()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30D22F()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLBoostedTreeRegressor.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLBoostedTreeRegressor.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30D257()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30D30F()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLRandomForestClassifier.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLRandomForestClassifier.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30D337()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30D3EF()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLHandActionClassifier.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLHandActionClassifier.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30D417()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30D4CF()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLActionClassifier.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLActionClassifier.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30D4F7()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30D5AF()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLDecisionTreeRegressor.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLDecisionTreeRegressor.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30D5D7()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30D68F()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLLogisticRegressionClassifier.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLLogisticRegressionClassifier.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(void *))(v2 + 24));
}

uint64_t sub_30D6B7()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30D76F()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLStyleTransfer.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLStyleTransfer.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30D797()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30D854()
{
  return objectdestroyTm_8();
}

uint64_t partial apply for closure #1 in closure #1 in static MLRandomForestRegressor.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLRandomForestRegressor.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30D87C()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30D934()
{
  return objectdestroyTm_8();
}

uint64_t objectdestroyTm_8()
{
  swift_release(*(void *)(v0 + 16));
  swift_release(*(void *)(v0 + 32));
  return swift_deallocObject(v0, 40, 7);
}

uint64_t partial apply for closure #1 in closure #1 in static MLHandPoseClassifier.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLHandPoseClassifier.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16), *(void (**)(uint64_t *))(v2 + 24), *(void *)(v2 + 32));
}

uint64_t sub_30D981()
{
  return objectdestroy_2Tm();
}

uint64_t sub_30DA39()
{
  swift_release(*(void *)(v0 + 24));
  swift_release(*(void *)(v0 + 32));
  return swift_deallocObject(v0, 40, 7);
}

uint64_t partial apply for closure #1 in closure #1 in static MLActivityClassifier.resume(_:)(uint64_t a1, char a2)
{
  return closure #1 in closure #1 in static MLActivityClassifier.resume(_:)(a1, a2 & 1, *(void *)(v2 + 16));
}

uint64_t sub_30DA7C()
{
  return objectdestroy_2Tm();
}

uint64_t objectdestroy_2Tm()
{
  swift_unknownObjectRelease(v0[2]);
  swift_release(v0[4]);
  swift_release(v0[5]);
  swift_release(v0[7]);
  return swift_deallocObject(v0, 64, 7);
}

uint64_t closure #1 in BidirectionalCollection.last(where:)specialized partial apply(uint64_t *a1)
{
  return partial apply for specialized closure #1 in BidirectionalCollection.last(where:)(a1);
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> MLImageClassifier.ModelParameters.ModelAlgorithmType.validate()()
{
  uint64_t v11 = v0;
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLImageClassifier.FeatureExtractorType(0) - 8) + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0) - 8)
                 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  outlined init with copy of MLImageClassifier.ModelParameters.ModelAlgorithmType(v1, (uint64_t)&v10);
  uint64_t v8 = *(uint64_t *)((char *)&v10
                  + *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType))
                           + 48));
  outlined init with take of MLImageClassifier.FeatureExtractorType((uint64_t)&v10, (uint64_t)&v10);
  MLImageClassifier.FeatureExtractorType.validate()();
  if (!v9)
  {
    uint64_t v10 = v8;
    MLImageClassifier.ModelParameters.ClassifierType.validate()();
  }
  outlined destroy of MLImageClassifier.FeatureExtractorType((uint64_t)&v10);
  swift_bridgeObjectRelease(v8);
}

uint64_t MLImageClassifier.ModelParameters.ModelAlgorithmType.description.getter()
{
  v20._uint64_t countAndFlagsBits = 0xD000000000000012;
  int64_t v1 = *(void *)(*(void *)(type metadata accessor for MLImageClassifier.FeatureExtractorType(0) - 8) + 64);
  int64_t v2 = alloca(v1);
  uint64_t v3 = alloca(v1);
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0) - 8)
                 + 64);
  int64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  outlined init with copy of MLImageClassifier.ModelParameters.ModelAlgorithmType(v0, (uint64_t)&v18);
  uint64_t v7 = *(uint64_t *)((char *)&v18
                  + *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType))
                           + 48));
  outlined init with take of MLImageClassifier.FeatureExtractorType((uint64_t)&v18, (uint64_t)&v18);
  uint64_t v8 = MLImageClassifier.FeatureExtractorType.description.getter();
  char v10 = v9;
  uint64_t v18 = v8;
  uint64_t v19 = v9;
  swift_bridgeObjectRetain(v9);
  v11._char object = (void *)0xE300000000000000;
  v11._uint64_t countAndFlagsBits = (uint64_t)&loc_202D20;
  String.append(_:)(v11);
  swift_bridgeObjectRelease(v10);
  uint64_t v12 = v18;
  uint64_t v13 = v19;
  if (v7)
  {
    swift_bridgeObjectRelease(v7);
    uint64_t v14 = "Feature Extractor: " + 0x8000000000000000;
    v20._countAndFlagsBits += 3;
  }
  else
  {
    uint64_t v14 = "Multilayer Perceptron" + 0x8000000000000000;
  }
  uint64_t v18 = v12;
  uint64_t v19 = v13;
  swift_bridgeObjectRetain(v13);
  v15._uint64_t countAndFlagsBits = v20._countAndFlagsBits;
  v15._char object = v14;
  String.append(_:)(v15);
  swift_bridgeObjectRelease(v13);
  swift_bridgeObjectRelease((_BYTE)v14);
  uint64_t v16 = v18;
  outlined destroy of MLImageClassifier.FeatureExtractorType((uint64_t)&v18);
  return v16;
}

uint64_t type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLImageClassifier.ModelParameters.ModelAlgorithmType;
  if (!type metadata singleton initialization cache for MLImageClassifier.ModelParameters.ModelAlgorithmType) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  }
  return result;
}

uint64_t outlined init with copy of MLImageClassifier.ModelParameters.ModelAlgorithmType(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined init with take of MLImageClassifier.FeatureExtractorType(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLImageClassifier.ModelParameters.ModelAlgorithmType(uint64_t a1)
{
  return MLImageClassifier.ModelParameters.ModelAlgorithmType.description.getter(a1);
}

void *initializeBufferWithCopyOfBuffer for MLImageClassifier.ModelParameters.ModelAlgorithmType(char *__dst, char *__src, uint64_t a3)
{
  uint64_t v3 = __dst;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v9 = *(void *)__src;
    void *v3 = *(void *)__src;
    uint64_t v3 = (void *)(v9 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    uint64_t v5 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
    if (swift_getEnumCaseMultiPayload(__src, v5) == 1)
    {
      uint64_t v6 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16))(__dst, __src, v6);
      uint64_t v7 = *(int *)(type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0) + 20);
      *(void *)&__dst[v7] = *(void *)&__src[v7];
      uint64_t v8 = *(void *)&__src[v7 + 8];
      *(void *)((char *)v3 + v7 + 8) = v8;
      swift_bridgeObjectRetain(v8);
      swift_storeEnumTagMultiPayload(v3, v5, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
    }
    uint64_t v10 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType))
                 + 48);
    uint64_t v11 = *(void *)&__src[v10];
    *(void *)((char *)v3 + v10) = v11;
    swift_bridgeObjectRetain(v11);
  }
  return v3;
}

uint64_t destroy for MLImageClassifier.ModelParameters.ModelAlgorithmType(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  if (swift_getEnumCaseMultiPayload(a1, v1) == 1)
  {
    uint64_t v2 = type metadata accessor for URL(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
    uint64_t v3 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
    swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(v3 + 20) + 8));
  }
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType));
  return swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(v4 + 48)));
}

char *initializeWithCopy for MLImageClassifier.ModelParameters.ModelAlgorithmType(char *__dst, char *__src)
{
  uint64_t v3 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  if (swift_getEnumCaseMultiPayload(__src, v3) == 1)
  {
    uint64_t v4 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 16))(__dst, __src, v4);
    uint64_t v5 = *(int *)(type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0) + 20);
    *(void *)&__dst[v5] = *(void *)&__src[v5];
    uint64_t v6 = *(void *)&__src[v5 + 8];
    *(void *)&__dst[v5 + 8] = v6;
    swift_bridgeObjectRetain(v6);
    swift_storeEnumTagMultiPayload(__dst, v3, 1);
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v3 - 8) + 64));
  }
  uint64_t v7 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType))
              + 48);
  uint64_t v8 = *(void *)&__src[v7];
  *(void *)&__dst[v7] = v8;
  swift_bridgeObjectRetain(v8);
  return __dst;
}

char *assignWithCopy for MLImageClassifier.ModelParameters.ModelAlgorithmType(char *__dst, char *__src)
{
  if (__dst != __src)
  {
    outlined destroy of MLImageClassifier.FeatureExtractorType((uint64_t)__dst);
    uint64_t v3 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
    if (swift_getEnumCaseMultiPayload(__src, v3) == 1)
    {
      uint64_t v4 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 16))(__dst, __src, v4);
      uint64_t v5 = *(int *)(type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0) + 20);
      *(void *)&__dst[v5] = *(void *)&__src[v5];
      uint64_t v6 = *(void *)&__src[v5 + 8];
      *(void *)&__dst[v5 + 8] = v6;
      swift_bridgeObjectRetain(v6);
      swift_storeEnumTagMultiPayload(__dst, v3, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v3 - 8) + 64));
    }
  }
  uint64_t v7 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType))
              + 48);
  uint64_t v8 = *(void *)&__src[v7];
  uint64_t v9 = *(void *)&__dst[v7];
  *(void *)&__dst[v7] = v8;
  swift_bridgeObjectRetain(v8);
  swift_bridgeObjectRelease(v9);
  return __dst;
}

char *initializeWithTake for MLImageClassifier.ModelParameters.ModelAlgorithmType(char *__dst, char *__src)
{
  uint64_t v2 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  if (swift_getEnumCaseMultiPayload(__src, v2) == 1)
  {
    uint64_t v3 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v3 - 8) + 32))(__dst, __src, v3);
    uint64_t v4 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
    *(_OWORD *)&__dst[*(int *)(v4 + 20)] = *(_OWORD *)&__src[*(int *)(v4 + 20)];
    swift_storeEnumTagMultiPayload(__dst, v2, 1);
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v2 - 8) + 64));
  }
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType));
  *(void *)&__dst[*(int *)(v5 + 48)] = *(void *)&__src[*(int *)(v5 + 48)];
  return __dst;
}

char *assignWithTake for MLImageClassifier.ModelParameters.ModelAlgorithmType(char *__dst, char *__src)
{
  if (__dst != __src)
  {
    outlined destroy of MLImageClassifier.FeatureExtractorType((uint64_t)__dst);
    uint64_t v3 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
    if (swift_getEnumCaseMultiPayload(__src, v3) == 1)
    {
      uint64_t v4 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 32))(__dst, __src, v4);
      uint64_t v5 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
      *(_OWORD *)&__dst[*(int *)(v5 + 20)] = *(_OWORD *)&__src[*(int *)(v5 + 20)];
      swift_storeEnumTagMultiPayload(__dst, v3, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v3 - 8) + 64));
    }
  }
  uint64_t v6 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType))
              + 48);
  uint64_t v7 = *(void *)&__dst[v6];
  *(void *)&__dst[v6] = *(void *)&__src[v6];
  swift_bridgeObjectRelease(v7);
  return __dst;
}

uint64_t getEnumTagSinglePayload for MLImageClassifier.ModelParameters.ModelAlgorithmType(uint64_t a1, unsigned int a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType));
  return __swift_getEnumTagSinglePayload(a1, a2, v2);
}

uint64_t storeEnumTagSinglePayload for MLImageClassifier.ModelParameters.ModelAlgorithmType(uint64_t a1, unsigned int a2, unsigned int a3)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType));
  return __swift_storeEnumTagSinglePayload(a1, a2, a3, v4);
}

uint64_t type metadata completion function for MLImageClassifier.ModelParameters.ModelAlgorithmType(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLImageClassifier.FeatureExtractorType(319);
  if (v2 <= 0x3F)
  {
    swift_getTupleTypeLayout2(v3, *(void *)(result - 8) + 64);
    swift_initEnumMetadataSingleCase(a1, 256, v3);
    *(_DWORD *)(*(void *)(a1 - 8) + 84) = v4;
    return 0;
  }
  return result;
}

unint64_t MLWordTaggerMetrics.description.getter()
{
  return MLClassifierMetrics.description.getter();
}

uint64_t MLWordTaggerMetrics.isValid.getter()
{
  v7[0] = v0;
  uint64_t v2 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int64_t v3 = *(void *)(*(void *)(v2 - 8) + 64);
  int v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  outlined init with copy of MLClassifierMetrics.Contents(v1, (uint64_t)v7);
  LOBYTE(v2) = swift_getEnumCaseMultiPayload(v7, v2) < 2;
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v7, type metadata accessor for MLClassifierMetrics.Contents);
  return v2;
}

uint64_t outlined init with copy of MLClassifierMetrics.Contents(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLClassifierMetrics.Contents(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t MLWordTaggerMetrics.error.getter()
{
  uint64_t v1 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int64_t v2 = *(void *)(*(void *)(v1 - 8) + 64);
  int64_t v3 = alloca(v2);
  int v4 = alloca(v2);
  outlined init with copy of MLClassifierMetrics.Contents(v0, (uint64_t)v6);
  if (swift_getEnumCaseMultiPayload(v6, v1) == 2) {
    return v6[0];
  }
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v6, type metadata accessor for MLClassifierMetrics.Contents);
  return 0;
}

double MLWordTaggerMetrics.taggingError.getter()
{
  v16[0] = v0;
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLClassifierMetrics.Precomputed(0) - 8) + 64);
  int64_t v3 = alloca(v2);
  int v4 = alloca(v2);
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for AnyClassificationMetrics(0) - 8) + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v8 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int64_t v9 = *(void *)(*(void *)(v8 - 8) + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  outlined init with copy of MLClassifierMetrics.Contents(v1, (uint64_t)v16);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v16, v8);
  if (EnumCaseMultiPayload)
  {
    if (EnumCaseMultiPayload != 1)
    {
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v16, type metadata accessor for MLClassifierMetrics.Contents);
      double v14 = 0.0;
      return 1.0 - v14;
    }
    outlined init with take of MLClassifierMetrics((uint64_t)v16, (uint64_t)v16, type metadata accessor for MLClassifierMetrics.Precomputed);
    v16[0] = 1.0 - v16[0];
    uint64_t v13 = type metadata accessor for MLClassifierMetrics.Precomputed;
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)v16, (uint64_t)v16, type metadata accessor for AnyClassificationMetrics);
    v16[0] = AnyClassificationMetrics.accuracy.getter();
    uint64_t v13 = type metadata accessor for AnyClassificationMetrics;
  }
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v16, v13);
  double v14 = v16[0];
  return 1.0 - v14;
}

uint64_t MLWordTaggerMetrics.confusion.getter(__m128 a1)
{
  return MLClassifierMetrics.confusion.getter(a1);
}

uint64_t MLWordTaggerMetrics.confusionDataFrame.getter()
{
  return MLClassifierMetrics.confusionDataFrame.getter();
}

uint64_t MLWordTaggerMetrics.precisionRecall.getter(__m128 a1)
{
  uint64_t v6 = v1;
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for DataFrame(0) - 8) + 64);
  int64_t v3 = alloca(v2);
  int v4 = alloca(v2);
  *(double *)a1.i64 = MLClassifierMetrics.precisionRecallDataFrame.getter(0);
  return MLDataTable.init(_:convertArraysToShapedArrays:)((uint64_t)&v6, 0, a1);
}

double MLWordTaggerMetrics.precisionRecallDataFrame.getter(uint64_t a1)
{
  return MLClassifierMetrics.precisionRecallDataFrame.getter(a1);
}

unint64_t MLWordTaggerMetrics.debugDescription.getter()
{
  return MLClassifierMetrics.accuracyDescription.getter();
}

uint64_t MLWordTaggerMetrics.playgroundDescription.getter()
{
  uint64_t v1 = v0;
  unint64_t v2 = MLClassifierMetrics.accuracyDescription.getter();
  char v4 = v3;
  objc_allocWithZone((Class)NSAttributedString);
  id v5 = @nonobjc NSAttributedString.init(string:attributes:)(v2, v4, 0);
  uint64_t result = type metadata accessor for NSAttributedString();
  v1[3] = result;
  void *v1 = v5;
  return result;
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLWordTaggerMetrics()
{
  return MLWordTaggerMetrics.description.getter();
}

unint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLWordTaggerMetrics()
{
  return MLWordTaggerMetrics.debugDescription.getter();
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLWordTaggerMetrics()
{
  return MLWordTaggerMetrics.playgroundDescription.getter();
}

char *assignWithCopy for MLWordTaggerMetrics(char *a1, char *a2)
{
  unint64_t v2 = a1;
  if (a1 != a2)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)a1, type metadata accessor for MLClassifierMetrics.Contents);
    uint64_t v3 = type metadata accessor for MLClassifierMetrics.Contents(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, v3);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v10 = v3;
      uint64_t v11 = *(void *)a2;
      swift_errorRetain(*(void *)a2);
      *(void *)a1 = v11;
      uint64_t v8 = 2;
      uint64_t v9 = v10;
    }
    else if (EnumCaseMultiPayload == 1)
    {
      *(void *)a1 = *(void *)a2;
      uint64_t v19 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v5 = *(int *)(v19 + 20);
      uint64_t v18 = v3;
      uint64_t v6 = type metadata accessor for DataFrame(0);
      uint64_t v7 = *(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16);
      v7(&a1[v5], &a2[v5], v6);
      v7(&a1[*(int *)(v19 + 24)], &a2[*(int *)(v19 + 24)], v6);
      uint64_t v8 = 1;
      uint64_t v9 = v18;
    }
    else
    {
      uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      int v13 = swift_getEnumCaseMultiPayload(a2, v12);
      BOOL v14 = v13 == 1;
      Swift::String v15 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      if (v13 == 1) {
        Swift::String v15 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(v15);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(v2, a2, v16);
      swift_storeEnumTagMultiPayload(v2, v12, v14);
      a1 = v2;
      uint64_t v9 = v3;
      uint64_t v8 = 0;
    }
    swift_storeEnumTagMultiPayload(a1, v9, v8);
  }
  return v2;
}

char *assignWithTake for MLWordTaggerMetrics(char *__dst, char *__src)
{
  unint64_t v2 = __dst;
  if (__dst != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)__dst, type metadata accessor for MLClassifierMetrics.Contents);
    uint64_t v3 = type metadata accessor for MLClassifierMetrics.Contents(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v3);
    if (EnumCaseMultiPayload == 1)
    {
      *(void *)__dst = *(void *)__src;
      uint64_t v17 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v12 = *(int *)(v17 + 20);
      uint64_t v13 = type metadata accessor for DataFrame(0);
      uint64_t v16 = v3;
      BOOL v14 = *(void (**)(char *, char *, uint64_t))(*(void *)(v13 - 8) + 32);
      v14(&__dst[v12], &__src[v12], v13);
      v14(&__dst[*(int *)(v17 + 24)], &__src[*(int *)(v17 + 24)], v13);
      uint64_t v11 = 1;
      uint64_t v10 = v16;
    }
    else
    {
      if (EnumCaseMultiPayload)
      {
        memcpy(__dst, __src, *(void *)(*(void *)(v3 - 8) + 64));
        return v2;
      }
      uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      int v6 = swift_getEnumCaseMultiPayload(__src, v5);
      BOOL v7 = v6 == 1;
      uint64_t v8 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      if (v6 == 1) {
        uint64_t v8 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(v8);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(v2, __src, v9);
      swift_storeEnumTagMultiPayload(v2, v5, v7);
      __dst = v2;
      uint64_t v10 = v3;
      uint64_t v11 = 0;
    }
    swift_storeEnumTagMultiPayload(__dst, v10, v11);
  }
  return v2;
}

uint64_t getEnumTagSinglePayload for MLWordTaggerMetrics(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_30E9F1);
}

uint64_t sub_30E9F1(uint64_t a1, unsigned int a2)
{
  uint64_t v2 = type metadata accessor for MLClassifierMetrics(0);
  return __swift_getEnumTagSinglePayload(a1, a2, v2);
}

uint64_t storeEnumTagSinglePayload for MLWordTaggerMetrics(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_30EA35);
}

uint64_t sub_30EA35(uint64_t a1, unsigned int a2)
{
  uint64_t v2 = type metadata accessor for MLClassifierMetrics(0);
  return __swift_storeEnumTagSinglePayload(a1, a2, a2, v2);
}

uint64_t type metadata accessor for MLWordTaggerMetrics(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLWordTaggerMetrics;
  if (!type metadata singleton initialization cache for MLWordTaggerMetrics) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLWordTaggerMetrics);
  }
  return result;
}

uint64_t type metadata completion function for MLWordTaggerMetrics(uint64_t a1)
{
  uint64_t v4 = v1;
  uint64_t result = type metadata accessor for MLClassifierMetrics.Contents(319);
  if (v3 <= 0x3F)
  {
    uint64_t v4 = *(void *)(result - 8) + 64;
    swift_initStructMetadata(a1, 256, 1, &v4, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t specialized DefaultStringInterpolation.appendInterpolation<A>(_:)(char a1)
{
  switch(a1)
  {
    case 0:
      unint64_t v1 = 0xE300000000000000;
      v2._uint64_t countAndFlagsBits = 7630409;
      break;
    case 1:
      v2._uint64_t countAndFlagsBits = 0x656C62756F44;
      goto LABEL_5;
    case 2:
      v2._uint64_t countAndFlagsBits = 0x676E69727453;
LABEL_5:
      unint64_t v1 = 0xE600000000000000;
      break;
    case 3:
      unint64_t v1 = 0xE800000000000000;
      v2._uint64_t countAndFlagsBits = 0x65636E6575716553;
      break;
    case 4:
      unint64_t v1 = 0xEA00000000007972;
      v2._uint64_t countAndFlagsBits = 0x616E6F6974636944;
      break;
    case 5:
      v2._uint64_t countAndFlagsBits = 0x72724169746C754DLL;
      unint64_t v1 = 0xEA00000000007961;
      break;
    case 6:
      unint64_t v1 = 0xE700000000000000;
      v2._uint64_t countAndFlagsBits = 0x676E697373694DLL;
      break;
  }
  v2._char object = (void *)v1;
  String.append(_:)(v2);
  return swift_bridgeObjectRelease(v1);
}

uint64_t _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML10_DataTableC_s5Error_pTgm503_s8c10ML11MLDataf74V4pack12columnsNamed2to4type7fillingACSSd_SSAC8PackTypeOAA0C5ValueOtFAA05_E10D0CyKXEfU_AgE11CMLSequenceCSSAE0jS0O0sP0OAMTf1c_n(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4, char a5, void *a6, double a7, void *a8, char a9)
{
  char v10 = a4;
  closure #1 in MLDataTable.pack(columnsNamed:to:type:filling:)(a1, a2, a3, a4, a5, (uint64_t)a6, a7, (uint64_t)a8, a9, v13);
  swift_release();
  swift_bridgeObjectRelease(v10);
  outlined consume of MLDataValue(a6, a8, a9);
  return v12;
}

uint64_t specialized Array<A>.featureSequence.getter(uint64_t a1)
{
  uint64_t v1 = tc_v1_flex_list_create(0);
  if (!v1) {
    BUG();
  }
  uint64_t v2 = v1;
  uint64_t v3 = type metadata accessor for CMLSequence();
  uint64_t v4 = swift_allocObject(v3, 25, 7);
  *(void *)(v4 + 16) = v2;
  uint64_t v22 = v4;
  *(unsigned char *)(v4 + 24) = 1;
  uint64_t v5 = *(void *)(a1 + 16);
  if (v5)
  {
    uint64_t v23 = 0;
    uint64_t v20 = type metadata accessor for CMLFeatureValue();
    swift_bridgeObjectRetain(a1);
    uint64_t v21 = a1;
    int v6 = (uint64_t *)(a1 + 40);
    do
    {
      uint64_t v18 = v5;
      uint64_t v7 = *(v6 - 1);
      uint64_t v8 = *v6;
      v17[3] = &type metadata for String;
      void v17[4] = &protocol witness table for String;
      v17[0] = v7;
      v17[1] = v8;
      uint64_t v9 = __swift_project_boxed_opaque_existential_0Tm(v17, (uint64_t)&type metadata for String);
      uint64_t v10 = *v9;
      uint64_t v11 = v9[1];
      uint64_t v19 = v8;
      swift_bridgeObjectRetain_n(v8, 2);
      swift_bridgeObjectRetain(v11);
      uint64_t v12 = v10;
      uint64_t v13 = v23;
      uint64_t v14 = CMLFeatureValue.__allocating_init(_:)(v12, v11);
      if (v13)
      {
        swift_unexpectedError(v13, "CreateML/MLDataValueConvertible.swift", 37, 1, 170);
        BUG();
      }
      uint64_t v15 = v14;
      __swift_destroy_boxed_opaque_existential_1Tm(v17);
      CMLSequence.append(_:)(v15);
      swift_release();
      uint64_t v23 = 0;
      swift_bridgeObjectRelease(v19);
      v6 += 2;
      uint64_t v5 = v18 - 1;
    }
    while (v18 != 1);
    swift_bridgeObjectRelease(v21);
  }
  return v22;
}

uint64_t MLDataTable.pack(columnsNamed:to:type:filling:)(uint64_t a1, uint64_t a2, uint64_t a3, char *a4, uint64_t a5, double a6)
{
  uint64_t v8 = *(void *)v7;
  if (*(unsigned char *)(v7 + 8))
  {
    *(void *)uint64_t v6 = v8;
    *(unsigned char *)(v6 + 8) = 1;
    return swift_errorRetain(v8);
  }
  else
  {
    uint64_t v27 = a2;
    uint64_t v26 = a3;
    uint64_t v25 = (uint64_t *)v6;
    char v32 = *a4;
    uint64_t v11 = *(void **)a5;
    uint64_t v12 = *(void **)(a5 + 8);
    unsigned __int8 v33 = *(unsigned char *)(a5 + 16);
    swift_retain();
    uint64_t v13 = tc_v1_flex_list_create(0);
    if (!v13) {
      BUG();
    }
    uint64_t v14 = v13;
    unint64_t v29 = v11;
    int64_t v28 = v12;
    uint64_t v15 = type metadata accessor for CMLSequence();
    uint64_t inited = swift_initStackObject(v15, v24);
    *(void *)(inited + 16) = v14;
    *(unsigned char *)(inited + 24) = 1;
    if (*(void *)(a1 + 16))
    {
      uint64_t v17 = specialized Array<A>.featureSequence.getter(a1);
      swift_release();
    }
    else
    {
      _DataTable.columnNames.getter(v15);
      swift_release();
      uint64_t v17 = v31;
    }
    uint64_t v30 = v17;
    uint64_t v31 = v17;
    uint64_t v18 = v26;
    swift_bridgeObjectRetain(v26);
    char v19 = v33;
    uint64_t v20 = v29;
    uint64_t v21 = v28;
    outlined copy of MLDataValue(v29, v28, v33);
    uint64_t v22 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML10_DataTableC_s5Error_pTgm503_s8c10ML11MLDataf74V4pack12columnsNamed2to4type7fillingACSSd_SSAC8PackTypeOAA0C5ValueOtFAA05_E10D0CyKXEfU_AgE11CMLSequenceCSSAE0jS0O0sP0OAMTf1c_n(v8, &v31, v27, v18, (v32 & 1u) + 3, v20, a6, v21, v19);
    LOBYTE(v21) = v23;
    swift_release();
    uint64_t result = (uint64_t)v25;
    *uint64_t v25 = v22;
    *(unsigned char *)(result + 8) = v21 & 1;
  }
  return result;
}

char static MLDataTable.PackType.== infix(_:_:)(unsigned char *a1, unsigned char *a2)
{
  return *a2 ^ *a1 ^ 1;
}

void *closure #1 in MLDataTable.pack(columnsNamed:to:type:filling:)(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4, char a5, uint64_t a6, double a7, uint64_t a8, char a9, void *a10)
{
  uint64_t v26 = a4;
  uint64_t v27 = a3;
  uint64_t v30 = v10;
  uint64_t v28 = v11;
  unint64_t v12 = 0x5060403020100uLL >> (8 * a5);
  uint64_t v13 = *(void *)(a1 + 16);
  uint64_t v14 = *a2;
  uint64_t v23 = a6;
  uint64_t v24 = a8;
  char v25 = a9;
  swift_retain();
  unint64_t v29 = v18;
  uint64_t v19 = v13;
  uint64_t v20 = v14;
  char v21 = v12;
  uint64_t v22 = MLDataValue.featureValue.getter(a7);
  uint64_t v15 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.pack(columnNames:newColumnName:type:value:), (uint64_t)v18, v27, v26);
  swift_release();
  swift_release();
  if (v11)
  {
    uint64_t result = a10;
    *a10 = v11;
  }
  else
  {
    uint64_t v17 = type metadata accessor for _DataTable();
    swift_allocObject(v17, 40, 7);
    uint64_t result = (void *)_DataTable.init(impl:)(v15);
    void *v30 = result;
  }
  return result;
}

uint64_t MLDataTable.unpack(columnNamed:valueTypes:indexSubset:keySubset:)(uint64_t a1, void *a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v9 = *(void *)v6;
  if (*(unsigned char *)(v6 + 8))
  {
    *(void *)uint64_t v5 = v9;
    v5[8] = 1;
    return outlined copy of Result<_DataTable, Error>(v9, 1);
  }
  uint64_t v70 = a5;
  *(void *)&long long v76 = a3;
  v77._uint64_t countAndFlagsBits = a1;
  uint64_t v78 = a2;
  v77._char object = v5;
  uint64_t v80 = v9;
  outlined copy of Result<_DataTable, Error>(v9, 0);
  uint64_t v11 = tc_v1_flex_list_create(0);
  if (!v11) {
    BUG();
  }
  uint64_t v12 = v11;
  uint64_t v13 = type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject(v13, v62);
  *(void *)(inited + 16) = v12;
  *(unsigned char *)(inited + 24) = 1;
  if (a4)
  {
    uint64_t v69 = a4;
    uint64_t v73 = inited;
    uint64_t v15 = v80;
    uint64_t v74 = v80;
    char v75 = 0;
    outlined copy of Result<_DataTable, Error>(v80, 0);
    v16._uint64_t countAndFlagsBits = v77._countAndFlagsBits;
    v16._char object = v78;
    MLDataTable.subscript.getter(v16);
    outlined consume of Result<_DataTable, Error>(v15, 0);
    uint64_t v17 = v66;
    if (BYTE8(v66) == 1)
    {
      outlined consume of Result<_DataTable, Error>(v66, 1);
      goto LABEL_15;
    }
    swift_retain();
    _UntypedColumn.type.getter();
    outlined consume of Result<_DataTable, Error>(v17, 0);
    outlined consume of Result<_DataTable, Error>(v17, 0);
    if ((_BYTE)v74 != 3)
    {
LABEL_15:
      *(void *)&long long v66 = 0;
      *((void *)&v66 + 1) = 0xE000000000000000;
      _StringGuts.grow(_:)(80);
      v28._char object = "ionary typed column. Column '" + 0x8000000000000000;
      v28._uint64_t countAndFlagsBits = 0xD00000000000003DLL;
      String.append(_:)(v28);
      uint64_t countAndFlagsBits = v77._countAndFlagsBits;
      v28._uint64_t countAndFlagsBits = v77._countAndFlagsBits;
      uint64_t v30 = v78;
      v28._char object = v78;
      String.append(_:)(v28);
      v28._uint64_t countAndFlagsBits = 0x20666F2073692027;
      v28._char object = (void *)0xEE00272065707974;
      String.append(_:)(v28);
      uint64_t v31 = v80;
      uint64_t v71 = v80;
      char v72 = 0;
      outlined copy of Result<_DataTable, Error>(v80, 0);
      v28._uint64_t countAndFlagsBits = countAndFlagsBits;
      v28._char object = v30;
      MLDataTable.subscript.getter(v28);
      outlined consume of Result<_DataTable, Error>(v31, 0);
      uint64_t v32 = v74;
      if (!v75) {
        goto LABEL_34;
      }
      goto LABEL_31;
    }
    uint64_t v19 = tc_v1_flex_list_create(0);
    if (!v19) {
      BUG();
    }
    uint64_t v20 = v19;
    uint64_t v18 = swift_allocObject(v13, 25, 7);
    *(void *)(v18 + 16) = v20;
    *(unsigned char *)(v18 + 24) = 1;
    uint64_t v21 = v69;
    uint64_t v65 = *(void *)(v69 + 16);
    if (v65)
    {
      uint64_t v79 = v18;
      swift_bridgeObjectRetain(v69);
      uint64_t v22 = 0;
      do
      {
        uint64_t v23 = *(void *)(v21 + 8 * v22 + 32);
        uint64_t v67 = &type metadata for Int;
        uint64_t v68 = &protocol witness table for Int;
        *(void *)&long long v66 = v23;
        uint64_t v24 = __swift_project_boxed_opaque_existential_0Tm(&v66, (uint64_t)&type metadata for Int);
        uint64_t v25 = specialized handling<A, B>(_:_:)(*v24);
        if (!v25) {
          BUG();
        }
        uint64_t v26 = type metadata accessor for CMLFeatureValue();
        swift_initStackObject(v26, v63);
        uint64_t v27 = CMLFeatureValue.init(rawValue:ownsValue:)(v25, 1);
        __swift_destroy_boxed_opaque_existential_1Tm(&v66);
        CMLSequence.append(_:)(v27);
        swift_release();
        ++v22;
        uint64_t v21 = v69;
      }
      while (v65 != v22);
      swift_release();
      swift_bridgeObjectRelease(v21);
      uint64_t v18 = v79;
    }
    else
    {
      swift_release();
    }
  }
  else
  {
    uint64_t v18 = inited;
  }
  unsigned __int8 v33 = v78;
  if (v70)
  {
    uint64_t v79 = v18;
    uint64_t v34 = v80;
    uint64_t v74 = v80;
    char v75 = 0;
    outlined copy of Result<_DataTable, Error>(v80, 0);
    v35._uint64_t countAndFlagsBits = v77._countAndFlagsBits;
    v35._char object = v33;
    MLDataTable.subscript.getter(v35);
    outlined consume of Result<_DataTable, Error>(v34, 0);
    uint64_t v36 = v66;
    if (BYTE8(v66) == 1)
    {
      outlined consume of Result<_DataTable, Error>(v66, 1);
      goto LABEL_30;
    }
    swift_retain();
    _UntypedColumn.type.getter();
    outlined consume of Result<_DataTable, Error>(v36, 0);
    outlined consume of Result<_DataTable, Error>(v36, 0);
    if ((_BYTE)v74 != 4)
    {
LABEL_30:
      *(void *)&long long v66 = 0;
      *((void *)&v66 + 1) = 0xE000000000000000;
      _StringGuts.grow(_:)(80);
      v47._char object = "CreateML/MLDataTable+Pack.swift" + 0x8000000000000000;
      v47._uint64_t countAndFlagsBits = 0xD00000000000003DLL;
      String.append(_:)(v47);
      uint64_t v48 = v77._countAndFlagsBits;
      v47._uint64_t countAndFlagsBits = v77._countAndFlagsBits;
      v47._char object = v33;
      String.append(_:)(v47);
      v47._uint64_t countAndFlagsBits = 0x20666F2073692027;
      v47._char object = (void *)0xEE00272065707974;
      String.append(_:)(v47);
      uint64_t v31 = v80;
      uint64_t v71 = v80;
      char v72 = 0;
      outlined copy of Result<_DataTable, Error>(v80, 0);
      v47._uint64_t countAndFlagsBits = v48;
      v47._char object = v33;
      MLDataTable.subscript.getter(v47);
      outlined consume of Result<_DataTable, Error>(v31, 0);
      uint64_t v32 = v74;
      if (!v75)
      {
LABEL_34:
        swift_retain();
        _UntypedColumn.type.getter();
        outlined consume of Result<_DataTable, Error>(v32, 0);
        outlined consume of Result<_DataTable, Error>(v32, 0);
        char v49 = v71;
        goto LABEL_35;
      }
LABEL_31:
      outlined consume of Result<_DataTable, Error>(v74, 1);
      char v49 = 6;
LABEL_35:
      char object = v77._object;
      specialized DefaultStringInterpolation.appendInterpolation<A>(_:)(v49);
      v54._uint64_t countAndFlagsBits = 39;
      v54._char object = (void *)0xE100000000000000;
      String.append(_:)(v54);
      long long v76 = v66;
      uint64_t v55 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      uint64_t v56 = swift_allocError(&type metadata for MLCreateError, v55, 0, 0);
      *(_OWORD *)uint64_t v57 = v76;
      *(_OWORD *)(v57 + 16) = 0;
      *(_OWORD *)(v57 + 32) = 0;
      *(unsigned char *)(v57 + 48) = 1;
      outlined consume of Result<_DataTable, Error>(v31, 0);
      uint64_t result = swift_release();
      *(void *)char object = v56;
      object[8] = 1;
      return result;
    }
    uint64_t v18 = specialized Array<A>.featureSequence.getter(v70);
    swift_release();
  }
  uint64_t v37 = tc_v1_flex_enum_list_create(0);
  if (!v37) {
    BUG();
  }
  uint64_t v38 = v37;
  uint64_t v39 = type metadata accessor for CMLFVTypeSequence();
  uint64_t v40 = swift_initStackObject(v39, v64);
  uint64_t v41 = v40;
  *(void *)(v40 + 16) = v38;
  uint64_t v79 = v18;
  if ((void)v76 && (uint64_t v42 = *(void *)(v76 + 16)) != 0)
  {
    swift_bridgeObjectRetain(v76);
    uint64_t v43 = v76;
    for (uint64_t i = 0; i != v42; ++i)
    {
      uint64_t v45 = v41;
      CMLFVTypeSequence.append(_:)((CreateML::CMLFeatureValueType)(0x5060403020100uLL >> (8 * *(unsigned char *)(v43 + i + 32))));
      if (v46)
      {
        swift_unexpectedError(v46, "CreateML/MLDataTable+Pack.swift", 31, 1);
        BUG();
      }
      uint64_t v43 = v76;
    }
    swift_bridgeObjectRelease(v76);
  }
  else
  {
    uint64_t v45 = v40;
  }
  *(void *)&long long v76 = v61;
  uint64_t v50 = alloca(40);
  uint64_t v51 = alloca(48);
  v62[0] = *(void *)(v80 + 16);
  v62[1] = v45;
  v62[2] = v79;
  uint64_t v52 = (uint64_t)v78;
  swift_bridgeObjectRetain((_BYTE)v78);
  swift_retain();
  swift_retain();
  uint64_t v58 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.unpack(columnName:types:limit:), (uint64_t)v61, v77._countAndFlagsBits, v52);
  swift_release();
  uint64_t v59 = type metadata accessor for _DataTable();
  swift_allocObject(v59, 40, 7);
  uint64_t v60 = _DataTable.init(impl:)(v58);
  outlined consume of Result<_DataTable, Error>(v80, 0);
  swift_release();
  swift_bridgeObjectRelease((_BYTE)v78);
  swift_setDeallocating(v45);
  tc_v1_release(*(void *)(v45 + 16));
  swift_release();
  uint64_t result = (uint64_t)v77._object;
  *(void *)v77._char object = v60;
  *(unsigned char *)(result + 8) = 0;
  return result;
}

uint64_t partial apply for closure #1 in CMLTable.unpack(columnName:types:limit:)(uint64_t a1)
{
  return closure #1 in CMLTable.unpack(columnName:types:limit:)(a1, v1[2], v1[3], v1[4]);
}

void MLDataTable.PackType.hash(into:)()
{
  Hasher._combine(_:)(*v0);
}

Swift::Int MLDataTable.PackType.hashValue.getter()
{
  Swift::UInt v1 = *v0;
  Hasher.init(_seed:)(0);
  Hasher._combine(_:)(v1);
  return Hasher._finalize()();
}

char protocol witness for static Equatable.== infix(_:_:) in conformance MLDataTable.PackType(unsigned char *a1, unsigned char *a2)
{
  return static MLDataTable.PackType.== infix(_:_:)(a1, a2);
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLDataTable.PackType()
{
  return MLDataTable.PackType.hashValue.getter();
}

void protocol witness for Hashable.hash(into:) in conformance MLDataTable.PackType()
{
}

uint64_t base witness table accessor for Equatable in MLDataTable.PackType()
{
  return lazy protocol witness table accessor for type MLDataTable.PackType and conformance MLDataTable.PackType();
}

uint64_t lazy protocol witness table accessor for type MLDataTable.PackType and conformance MLDataTable.PackType()
{
  uint64_t result = lazy protocol witness table cache variable for type MLDataTable.PackType and conformance MLDataTable.PackType;
  if (!lazy protocol witness table cache variable for type MLDataTable.PackType and conformance MLDataTable.PackType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLDataTable.PackType, &type metadata for MLDataTable.PackType);
    lazy protocol witness table cache variable for type MLDataTable.PackType and conformance MLDataTable.PackType = result;
  }
  return result;
}

ValueMetadata *type metadata accessor for MLDataTable.PackType()
{
  return &type metadata for MLDataTable.PackType;
}

uint64_t partial apply for closure #1 in CMLTable.pack(columnNames:newColumnName:type:value:)(uint64_t a1)
{
  return closure #1 in CMLTable.pack(columnNames:newColumnName:type:value:)(a1, *(void *)(v1 + 16), *(void *)(v1 + 24), *(_DWORD *)(v1 + 32), *(void *)(v1 + 40));
}

double MLObjectDetector.ModelParameters.gridSize.getter()
{
  return (double)(int)*(void *)(v0 + *(int *)(type metadata accessor for MLObjectDetector.ModelParameters(0) + 28));
}

uint64_t type metadata accessor for MLObjectDetector.ModelParameters(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLObjectDetector.ModelParameters;
  if (!type metadata singleton initialization cache for MLObjectDetector.ModelParameters) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLObjectDetector.ModelParameters);
  }
  return result;
}

char MLObjectDetector.ModelParameters.algorithm.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLObjectDetector.ModelParameters(0);
  outlined init with copy of Any?(v1 + *(int *)(v3 + 40), (uint64_t)v7);
  if (!v8)
  {
    outlined destroy of Any?((uint64_t)v7);
    goto LABEL_5;
  }
  if (!swift_dynamicCast(&v9, v7, (char *)&type metadata for Any + 8, &type metadata for MLObjectDetector.ModelParameters.ModelAlgorithmType, 6))
  {
LABEL_5:
    char v5 = 1;
    uint64_t v4 = 0;
    goto LABEL_6;
  }
  uint64_t v4 = v9;
  char v5 = v10;
LABEL_6:
  *(void *)uint64_t v2 = v4;
  char result = v5 & 1;
  *(unsigned char *)(v2 + 8) = result;
  return result;
}

uint64_t MLObjectDetector.ModelParameters.init(validation:batchSize:maxIterations:gridSize:algorithm:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, char a5, uint64_t *a6, double a7, double a8)
{
  uint64_t v21 = a4;
  uint64_t v10 = v8;
  uint64_t v22 = a2;
  double v25 = a8;
  double v23 = a7;
  uint64_t v29 = a1;
  uint64_t v27 = *a6;
  char v30 = *((unsigned char *)a6 + 8);
  uint64_t v12 = (int *)type metadata accessor for MLObjectDetector.ModelParameters(0);
  uint64_t v13 = v12[5];
  uint64_t v24 = v12[6];
  uint64_t v26 = v12[7];
  *(void *)(v10 + v26) = 13;
  uint64_t v28 = v12[8];
  *(void *)(v10 + v28) = 13;
  *(unsigned char *)(v10 + v12[9]) = 0;
  uint64_t v14 = v12[10];
  *(_OWORD *)(v10 + v14 + 16) = 0;
  *(_OWORD *)(v10 + v14) = 0;
  outlined init with copy of MLObjectDetector.ModelParameters.ValidationData(v29, v10);
  double v15 = v23;
  *(void *)(v10 + v13) = v22;
  *(unsigned char *)(v10 + v13 + 8) = a3 & 1;
  uint64_t v16 = v24;
  *(void *)(v10 + v24) = v21;
  *(unsigned char *)(v10 + v16 + 8) = a5 & 1;
  if ((~*(void *)&v15 & 0x7FF0000000000000) == 0) {
    BUG();
  }
  if (v15 <= -9.223372036854778e18) {
    BUG();
  }
  if (v15 >= 9.223372036854776e18) {
    BUG();
  }
  *(void *)(v10 + v26) = (int)v15;
  if ((~*(void *)&v25 & 0x7FF0000000000000) == 0) {
    BUG();
  }
  if (v25 <= -9.223372036854778e18) {
    BUG();
  }
  if (v25 >= 9.223372036854776e18) {
    BUG();
  }
  *(void *)(v10 + v28) = (int)v25;
  uint64_t v20 = &type metadata for MLObjectDetector.ModelParameters.ModelAlgorithmType;
  uint64_t v18 = v27;
  char v19 = v30 & 1;
  outlined assign with take of Any?((uint64_t)&v18, v10 + v14);
  return outlined destroy of MLObjectDetector.ModelParameters.ValidationData(v29);
}

uint64_t MLObjectDetector.ModelParameters.init(validation:batchSize:maxIterations:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, char a5)
{
  uint64_t v8 = v5;
  uint64_t v9 = (int *)type metadata accessor for MLObjectDetector.ModelParameters(0);
  uint64_t v10 = v9[5];
  uint64_t v11 = v9[6];
  *(void *)(v8 + v9[7]) = 13;
  *(void *)(v8 + v9[8]) = 13;
  *(unsigned char *)(v8 + v9[9]) = 0;
  uint64_t v12 = v9[10];
  *(_OWORD *)(v8 + v12 + 16) = 0;
  *(_OWORD *)(v8 + v12) = 0;
  outlined init with take of MLClassifierMetrics(a1, v8, type metadata accessor for MLObjectDetector.ModelParameters.ValidationData);
  *(void *)(v8 + v10) = a2;
  *(unsigned char *)(v8 + v10 + 8) = a3 & 1;
  uint64_t result = a4;
  *(void *)(v8 + v11) = a4;
  *(unsigned char *)(v8 + v11 + 8) = a5 & 1;
  return result;
}

unint64_t MLObjectDetector.ModelParameters.debugDescription.getter()
{
  return MLObjectDetector.ModelParameters.description.getter();
}

uint64_t MLObjectDetector.ModelParameters.validation.getter()
{
  return outlined init with copy of MLObjectDetector.ModelParameters.ValidationData(v1, v0);
}

uint64_t MLObjectDetector.ModelParameters.validation.setter(uint64_t a1)
{
  return outlined assign with take of MLObjectDetector.ModelParameters.ValidationData(a1, v1);
}

void (*MLObjectDetector.ModelParameters.validation.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLObjectDetector.ModelParameters.batchSize.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLObjectDetector.ModelParameters(0) + 20));
}

uint64_t MLObjectDetector.ModelParameters.batchSize.setter(uint64_t a1, char a2)
{
  uint64_t result = *(int *)(type metadata accessor for MLObjectDetector.ModelParameters(0) + 20);
  *(void *)(v2 + result) = a1;
  *(unsigned char *)(v2 + result + 8) = a2 & 1;
  return result;
}

void (*MLObjectDetector.ModelParameters.batchSize.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLObjectDetector.ModelParameters.maxIterations.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLObjectDetector.ModelParameters(0) + 24));
}

uint64_t MLObjectDetector.ModelParameters.maxIterations.setter(uint64_t a1, char a2)
{
  uint64_t result = *(int *)(type metadata accessor for MLObjectDetector.ModelParameters(0) + 24);
  *(void *)(v2 + result) = a1;
  *(unsigned char *)(v2 + result + 8) = a2 & 1;
  return result;
}

void (*MLObjectDetector.ModelParameters.maxIterations.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t key path setter for MLObjectDetector.ModelParameters.gridSize : MLObjectDetector.ModelParameters(double *a1)
{
  return MLObjectDetector.ModelParameters.gridSize.setter(*a1, a1[1]);
}

uint64_t MLObjectDetector.ModelParameters.gridSize.setter(double a1, double a2)
{
  if ((~*(void *)&a1 & 0x7FF0000000000000) == 0) {
    BUG();
  }
  if (a1 <= -9.223372036854778e18) {
    BUG();
  }
  if (a1 >= 9.223372036854776e18) {
    BUG();
  }
  uint64_t v3 = type metadata accessor for MLObjectDetector.ModelParameters(0);
  *(void *)(v2 + *(int *)(v3 + 28)) = (int)a1;
  if ((~*(void *)&a2 & 0x7FF0000000000000) == 0) {
    BUG();
  }
  if (a2 <= -9.223372036854778e18) {
    BUG();
  }
  if (a2 >= 9.223372036854776e18) {
    BUG();
  }
  uint64_t result = *(int *)(v3 + 32);
  *(void *)(v2 + result) = (int)a2;
  return result;
}

uint64_t (*MLObjectDetector.ModelParameters.gridSize.modify(uint64_t a1))(double *a1)
{
  *(void *)(a1 + 16) = v1;
  uint64_t v2 = type metadata accessor for MLObjectDetector.ModelParameters(0);
  double v3 = (double)(int)*(void *)(v1 + *(int *)(v2 + 32));
  *(double *)a1 = (double)(int)*(void *)(v1 + *(int *)(v2 + 28));
  *(double *)(a1 + 8) = v3;
  return MLObjectDetector.ModelParameters.gridSize.modify;
}

uint64_t MLObjectDetector.ModelParameters.gridSize.modify(double *a1)
{
  return MLObjectDetector.ModelParameters.gridSize.setter(*a1, a1[1]);
}

uint64_t key path getter for MLObjectDetector.ModelParameters.algorithm : MLObjectDetector.ModelParameters()
{
  uint64_t v1 = v0;
  MLObjectDetector.ModelParameters.algorithm.getter();
  uint64_t result = v3;
  *(void *)uint64_t v1 = v3;
  *(unsigned char *)(v1 + 8) = v4;
  return result;
}

uint64_t key path setter for MLObjectDetector.ModelParameters.algorithm : MLObjectDetector.ModelParameters(uint64_t a1)
{
  char v1 = *(unsigned char *)(a1 + 8);
  uint64_t v3 = *(void *)a1;
  char v4 = v1;
  return MLObjectDetector.ModelParameters.algorithm.setter(&v3);
}

uint64_t MLObjectDetector.ModelParameters.algorithm.setter(uint64_t *a1)
{
  uint64_t v2 = *a1;
  char v3 = *((unsigned char *)a1 + 8);
  uint64_t v8 = &type metadata for MLObjectDetector.ModelParameters.ModelAlgorithmType;
  uint64_t v6 = v2;
  char v7 = v3;
  uint64_t v4 = type metadata accessor for MLObjectDetector.ModelParameters(0);
  return outlined assign with take of Any?((uint64_t)&v6, v1 + *(int *)(v4 + 40));
}

uint64_t outlined destroy of MLObjectDetector.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

void (*MLObjectDetector.ModelParameters.algorithm.modify(void *a1))(uint64_t a1)
{
  uint64_t v2 = (char *)malloc(0x48uLL);
  *a1 = v2;
  *((void *)v2 + 8) = v1;
  uint64_t v3 = *(int *)(type metadata accessor for MLObjectDetector.ModelParameters(0) + 40);
  *((_DWORD *)v2 + 11) = v3;
  outlined init with copy of Any?(v1 + v3, (uint64_t)v2);
  if (!*((void *)v2 + 3))
  {
    outlined destroy of Any?((uint64_t)v2);
    goto LABEL_5;
  }
  if (!swift_dynamicCast(v2 + 48, v2, (char *)&type metadata for Any + 8, &type metadata for MLObjectDetector.ModelParameters.ModelAlgorithmType, 6))
  {
LABEL_5:
    char v5 = 1;
    uint64_t v4 = 0;
    goto LABEL_6;
  }
  uint64_t v4 = *((void *)v2 + 6);
  char v5 = v2[56];
LABEL_6:
  *((void *)v2 + 4) = v4;
  v2[40] = v5 & 1;
  return MLObjectDetector.ModelParameters.algorithm.modify;
}

void MLObjectDetector.ModelParameters.algorithm.modify(uint64_t a1)
{
  uint64_t v1 = *(void **)a1;
  uint64_t v2 = *(void *)(*(void *)a1 + 32);
  char v3 = *(unsigned char *)(*(void *)a1 + 40);
  uint64_t v4 = *(void *)(*(void *)a1 + 64) + *(int *)(*(void *)a1 + 44);
  v1[3] = &type metadata for MLObjectDetector.ModelParameters.ModelAlgorithmType;
  void *v1 = v2;
  *((unsigned char *)v1 + 8) = v3;
  outlined assign with take of Any?((uint64_t)v1, v4);
  free(v1);
}

uint64_t MLObjectDetector.ModelParameters.init(validationData:batchSize:maxIterations:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, char a5)
{
  uint64_t v8 = v5;
  uint64_t v9 = (int *)type metadata accessor for MLObjectDetector.ModelParameters(0);
  uint64_t v10 = v9[5];
  uint64_t v15 = v9[6];
  *(void *)(v8 + v9[7]) = 13;
  *(void *)(v8 + v9[8]) = 13;
  *(unsigned char *)(v8 + v9[9]) = 0;
  uint64_t v11 = v9[10];
  *(_OWORD *)(v8 + v11 + 16) = 0;
  *(_OWORD *)(v8 + v11) = 0;
  outlined init with take of MLClassifierMetrics(a1, v8, type metadata accessor for MLObjectDetector.DataSource);
  uint64_t v12 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  swift_storeEnumTagMultiPayload(v8, v12, 1);
  *(void *)(v8 + v10) = a2;
  *(unsigned char *)(v8 + v10 + 8) = a3 & 1;
  uint64_t result = a4;
  *(void *)(v8 + v15) = a4;
  *(unsigned char *)(v8 + v15 + 8) = a5 & 1;
  return result;
}

unint64_t MLObjectDetector.ModelParameters.description.getter()
{
  _StringGuts.grow(_:)(19);
  swift_bridgeObjectRelease(0);
  unint64_t v16 = 0xD000000000000010;
  uint64_t v17 = "ansformer have different types." + 0x8000000000000000;
  uint64_t v18 = type metadata accessor for MLObjectDetector.ModelParameters(0);
  uint64_t v1 = *(int *)(v18 + 24);
  char v2 = *(unsigned char *)(v0 + v1 + 8);
  v15._uint64_t countAndFlagsBits = *(void *)(v0 + v1);
  LOBYTE(v15._object) = v2;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Int?);
  v4._uint64_t countAndFlagsBits = String.init<A>(describing:)(&v15, v3);
  char object = (char)v4._object;
  String.append(_:)(v4);
  swift_bridgeObjectRelease(object);
  v6._char object = (void *)0xE100000000000000;
  v6._uint64_t countAndFlagsBits = 10;
  String.append(_:)(v6);
  strcpy((char *)&v15, "Batch Size: ");
  BYTE5(v15._object) = 0;
  HIWORD(v15._object) = -5120;
  uint64_t v7 = *(int *)(v18 + 20);
  uint64_t v8 = *(void *)(v0 + v7);
  LOBYTE(v7) = *(unsigned char *)(v0 + v7 + 8);
  uint64_t v13 = v8;
  char v14 = v7;
  v9._uint64_t countAndFlagsBits = String.init<A>(describing:)(&v13, v3);
  char v10 = (char)v9._object;
  String.append(_:)(v9);
  swift_bridgeObjectRelease(v10);
  v6._uint64_t countAndFlagsBits = 10;
  v6._char object = (void *)0xE100000000000000;
  String.append(_:)(v6);
  char v11 = (char)v15._object;
  String.append(_:)(v15);
  swift_bridgeObjectRelease(v11);
  return v16;
}

uint64_t outlined assign with take of MLObjectDetector.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 40))(a2, a1, v2);
  return a2;
}

unint64_t MLObjectDetector.ModelParameters.playgroundDescription.getter()
{
  uint64_t v1 = v0;
  unint64_t result = MLObjectDetector.ModelParameters.description.getter();
  v1[3] = (unint64_t)&type metadata for String;
  unint64_t *v1 = result;
  v1[1] = v3;
  return result;
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLObjectDetector.ModelParameters()
{
  return MLObjectDetector.ModelParameters.description.getter();
}

unint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLObjectDetector.ModelParameters()
{
  return MLObjectDetector.ModelParameters.debugDescription.getter();
}

unint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLObjectDetector.ModelParameters()
{
  return MLObjectDetector.ModelParameters.playgroundDescription.getter();
}

void sub_310298(double a1, double a2)
{
  unint64_t v3 = v2;
  *uint64_t v2 = MLObjectDetector.ModelParameters.gridSize.getter();
  v3[1] = a2;
}

uint64_t sub_3102B8(double *a1)
{
  return key path setter for MLObjectDetector.ModelParameters.gridSize : MLObjectDetector.ModelParameters(a1);
}

uint64_t sub_3102C2()
{
  return key path getter for MLObjectDetector.ModelParameters.algorithm : MLObjectDetector.ModelParameters();
}

uint64_t sub_3102CC(uint64_t a1)
{
  return key path setter for MLObjectDetector.ModelParameters.algorithm : MLObjectDetector.ModelParameters(a1);
}

void *initializeBufferWithCopyOfBuffer for MLObjectDetector.ModelParameters(char *__dst, char *__src, int *a3)
{
  Swift::String v4 = __dst;
  int v5 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v13 = *(void *)__src;
    *Swift::String v4 = *(void *)__src;
    Swift::String v4 = (void *)(v13 + ((v5 + 16) & ~v5));
    swift_retain();
    return v4;
  }
  uint64_t v7 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v7);
  switch(EnumCaseMultiPayload)
  {
    case 3:
      uint64_t v14 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 16))(__dst, __src, v14);
      uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
      uint64_t v16 = *(int *)(v15 + 48);
      *(void *)&__dst[v16] = *(void *)&__src[v16];
      uint64_t v17 = *(void *)&__src[v16 + 8];
      *(void *)((char *)v4 + v16 + 8) = v17;
      uint64_t v18 = *(int *)(v15 + 64);
      *(void *)((char *)v4 + v18) = *(void *)&__src[v18];
      uint64_t v19 = v7;
      uint64_t v20 = *(void *)&__src[v18 + 8];
      *(void *)((char *)v4 + v18 + 8) = v20;
      swift_bridgeObjectRetain(v17);
      swift_bridgeObjectRetain(v20);
      uint64_t v21 = 3;
      uint64_t v22 = v4;
      uint64_t v23 = v19;
      break;
    case 2:
      uint64_t v24 = *(void *)__src;
      uint64_t v49 = v7;
      char v25 = __src[8];
      outlined copy of Result<_DataTable, Error>(*(void *)__src, v25);
      *(void *)__dst = v24;
      __dst[8] = v25;
      *((void *)__dst + 2) = *((void *)__src + 2);
      uint64_t v26 = *((void *)__src + 3);
      v4[3] = v26;
      v4[4] = *((void *)__src + 4);
      uint64_t v27 = *((void *)__src + 5);
      v4[5] = v27;
      swift_bridgeObjectRetain(v26);
      swift_bridgeObjectRetain(v27);
      uint64_t v21 = 2;
      uint64_t v22 = v4;
      uint64_t v23 = v49;
      break;
    case 1:
      uint64_t v9 = type metadata accessor for MLObjectDetector.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v9))
      {
        case 0u:
          uint64_t v10 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 16))(__dst, __src, v10);
          uint64_t v11 = v9;
          uint64_t v12 = 0;
          goto LABEL_15;
        case 1u:
          uint64_t v52 = v9;
          uint64_t v28 = type metadata accessor for URL(0);
          uint64_t v50 = v7;
          uint64_t v29 = *(void (**)(char *, char *, uint64_t))(*(void *)(v28 - 8) + 16);
          v29(__dst, __src, v28);
          uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL));
          v29(&__dst[*(int *)(v30 + 48)], &__src[*(int *)(v30 + 48)], v28);
          uint64_t v7 = v50;
          uint64_t v48 = 1;
          goto LABEL_14;
        case 2u:
          uint64_t v52 = v9;
          uint64_t v31 = *(void *)__src;
          char v51 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v51);
          *(void *)__dst = v31;
          __dst[8] = v51;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v32 = *((void *)__src + 3);
          v4[3] = v32;
          v4[4] = *((void *)__src + 4);
          uint64_t v33 = *((void *)__src + 5);
          v4[5] = v33;
          swift_bridgeObjectRetain(v32);
          swift_bridgeObjectRetain(v33);
          uint64_t v48 = 2;
          goto LABEL_14;
        case 3u:
          uint64_t v34 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v34 - 8) + 16))(__dst, __src, v34);
          uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
          uint64_t v36 = *(int *)(v35 + 48);
          *(void *)&__dst[v36] = *(void *)&__src[v36];
          uint64_t v37 = *(void *)&__src[v36 + 8];
          *(void *)((char *)v4 + v36 + 8) = v37;
          uint64_t v38 = *(int *)(v35 + 64);
          *(void *)((char *)v4 + v38) = *(void *)&__src[v38];
          uint64_t v52 = v9;
          uint64_t v39 = *(void *)&__src[v38 + 8];
          *(void *)((char *)v4 + v38 + 8) = v39;
          swift_bridgeObjectRetain(v37);
          swift_bridgeObjectRetain(v39);
          uint64_t v48 = 3;
LABEL_14:
          uint64_t v12 = v48;
          __dst = (char *)v4;
          uint64_t v11 = v52;
LABEL_15:
          swift_storeEnumTagMultiPayload(__dst, v11, v12);
          uint64_t v21 = 1;
          uint64_t v22 = v4;
          uint64_t v23 = v7;
          break;
      }
      break;
    default:
      memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
      goto LABEL_17;
  }
  swift_storeEnumTagMultiPayload(v22, v23, v21);
LABEL_17:
  uint64_t v40 = a3[5];
  *((unsigned char *)v4 + v40 + 8) = __src[v40 + 8];
  *(void *)((char *)v4 + v40) = *(void *)&__src[v40];
  uint64_t v41 = a3[6];
  *(void *)((char *)v4 + v41) = *(void *)&__src[v41];
  *((unsigned char *)v4 + v41 + 8) = __src[v41 + 8];
  *(void *)((char *)v4 + a3[7]) = *(void *)&__src[a3[7]];
  *(void *)((char *)v4 + a3[8]) = *(void *)&__src[a3[8]];
  *((unsigned char *)v4 + a3[9]) = __src[a3[9]];
  uint64_t v42 = a3[10];
  uint64_t v43 = (char *)v4 + v42;
  uint64_t v44 = &__src[v42];
  uint64_t v45 = *(void *)&__src[v42 + 24];
  if (v45)
  {
    *((void *)v43 + 3) = v45;
    (**(void (***)(char *, char *))(v45 - 8))(v43, v44);
  }
  else
  {
    long long v46 = *(_OWORD *)v44;
    *((_OWORD *)v43 + 1) = *((_OWORD *)v44 + 1);
    *(_OWORD *)uint64_t v43 = v46;
  }
  return v4;
}

uint64_t destroy for MLObjectDetector.ModelParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a1, v3);
  switch(EnumCaseMultiPayload)
  {
    case 3:
LABEL_7:
      uint64_t v8 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v8 - 8) + 8))(a1, v8);
      uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
      swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(v9 + 48) + 8));
      uint64_t v7 = *(void *)(a1 + *(int *)(v9 + 64) + 8);
      goto LABEL_8;
    case 2:
LABEL_6:
      outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + 24));
      uint64_t v7 = *(void *)(a1 + 40);
LABEL_8:
      swift_bridgeObjectRelease(v7);
      break;
    case 1:
      uint64_t v5 = type metadata accessor for MLObjectDetector.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(a1, v5))
      {
        case 0u:
          uint64_t v6 = type metadata accessor for URL(0);
          (*(void (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8))(a1, v6);
          break;
        case 1u:
          uint64_t v11 = type metadata accessor for URL(0);
          uint64_t v12 = *(void (**)(uint64_t, uint64_t))(*(void *)(v11 - 8) + 8);
          v12(a1, v11);
          uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL));
          v12(a1 + *(int *)(v13 + 48), v11);
          break;
        case 2u:
          goto LABEL_6;
        case 3u:
          goto LABEL_7;
        default:
          goto LABEL_9;
      }
      break;
  }
LABEL_9:
  uint64_t result = *(int *)(a2 + 40);
  if (*(void *)(a1 + result + 24)) {
    return __swift_destroy_boxed_opaque_existential_1Tm((void *)(result + a1));
  }
  return result;
}

void *initializeWithCopy for MLObjectDetector.ModelParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v5 = __dst;
  uint64_t v6 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v6);
  switch(EnumCaseMultiPayload)
  {
    case 3:
      uint64_t v12 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 16))(__dst, __src, v12);
      uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
      uint64_t v14 = *(int *)(v13 + 48);
      *(void *)&__dst[v14] = *(void *)&__src[v14];
      uint64_t v15 = *(void *)&__src[v14 + 8];
      *(void *)((char *)v5 + v14 + 8) = v15;
      uint64_t v16 = *(int *)(v13 + 64);
      *(void *)((char *)v5 + v16) = *(void *)&__src[v16];
      uint64_t v17 = v6;
      uint64_t v18 = *(void *)&__src[v16 + 8];
      *(void *)((char *)v5 + v16 + 8) = v18;
      swift_bridgeObjectRetain(v15);
      swift_bridgeObjectRetain(v18);
      uint64_t v19 = 3;
      uint64_t v20 = v5;
      uint64_t v21 = v17;
      break;
    case 2:
      uint64_t v22 = *(void *)__src;
      uint64_t v47 = v6;
      char v23 = __src[8];
      outlined copy of Result<_DataTable, Error>(*(void *)__src, v23);
      *(void *)__dst = v22;
      __dst[8] = v23;
      *((void *)__dst + 2) = *((void *)__src + 2);
      uint64_t v24 = *((void *)__src + 3);
      v5[3] = v24;
      v5[4] = *((void *)__src + 4);
      uint64_t v25 = *((void *)__src + 5);
      v5[5] = v25;
      swift_bridgeObjectRetain(v24);
      swift_bridgeObjectRetain(v25);
      uint64_t v19 = 2;
      uint64_t v20 = v5;
      uint64_t v21 = v47;
      break;
    case 1:
      uint64_t v8 = type metadata accessor for MLObjectDetector.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v8))
      {
        case 0u:
          uint64_t v9 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))(__dst, __src, v9);
          uint64_t v10 = v8;
          uint64_t v11 = 0;
          goto LABEL_13;
        case 1u:
          uint64_t v50 = v8;
          uint64_t v26 = type metadata accessor for URL(0);
          uint64_t v48 = v6;
          uint64_t v27 = *(void (**)(char *, char *, uint64_t))(*(void *)(v26 - 8) + 16);
          v27(__dst, __src, v26);
          uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL));
          v27(&__dst[*(int *)(v28 + 48)], &__src[*(int *)(v28 + 48)], v26);
          uint64_t v6 = v48;
          uint64_t v46 = 1;
          goto LABEL_12;
        case 2u:
          uint64_t v50 = v8;
          uint64_t v29 = *(void *)__src;
          char v49 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v49);
          *(void *)__dst = v29;
          __dst[8] = v49;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v30 = *((void *)__src + 3);
          v5[3] = v30;
          v5[4] = *((void *)__src + 4);
          uint64_t v31 = *((void *)__src + 5);
          v5[5] = v31;
          swift_bridgeObjectRetain(v30);
          swift_bridgeObjectRetain(v31);
          uint64_t v46 = 2;
          goto LABEL_12;
        case 3u:
          uint64_t v32 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v32 - 8) + 16))(__dst, __src, v32);
          uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
          uint64_t v34 = *(int *)(v33 + 48);
          *(void *)&__dst[v34] = *(void *)&__src[v34];
          uint64_t v35 = *(void *)&__src[v34 + 8];
          *(void *)((char *)v5 + v34 + 8) = v35;
          uint64_t v36 = *(int *)(v33 + 64);
          *(void *)((char *)v5 + v36) = *(void *)&__src[v36];
          uint64_t v50 = v8;
          uint64_t v37 = *(void *)&__src[v36 + 8];
          *(void *)((char *)v5 + v36 + 8) = v37;
          swift_bridgeObjectRetain(v35);
          swift_bridgeObjectRetain(v37);
          uint64_t v46 = 3;
LABEL_12:
          uint64_t v11 = v46;
          __dst = (char *)v5;
          uint64_t v10 = v50;
LABEL_13:
          swift_storeEnumTagMultiPayload(__dst, v10, v11);
          uint64_t v19 = 1;
          uint64_t v20 = v5;
          uint64_t v21 = v6;
          break;
      }
      break;
    default:
      memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
      goto LABEL_15;
  }
  swift_storeEnumTagMultiPayload(v20, v21, v19);
LABEL_15:
  uint64_t v38 = a3[5];
  *((unsigned char *)v5 + v38 + 8) = __src[v38 + 8];
  *(void *)((char *)v5 + v38) = *(void *)&__src[v38];
  uint64_t v39 = a3[6];
  *(void *)((char *)v5 + v39) = *(void *)&__src[v39];
  *((unsigned char *)v5 + v39 + 8) = __src[v39 + 8];
  *(void *)((char *)v5 + a3[7]) = *(void *)&__src[a3[7]];
  *(void *)((char *)v5 + a3[8]) = *(void *)&__src[a3[8]];
  *((unsigned char *)v5 + a3[9]) = __src[a3[9]];
  uint64_t v40 = a3[10];
  uint64_t v41 = (char *)v5 + v40;
  uint64_t v42 = &__src[v40];
  uint64_t v43 = *(void *)&__src[v40 + 24];
  if (v43)
  {
    *((void *)v41 + 3) = v43;
    (**(void (***)(char *, char *))(v43 - 8))(v41, v42);
  }
  else
  {
    long long v44 = *(_OWORD *)v42;
    *((_OWORD *)v41 + 1) = *((_OWORD *)v42 + 1);
    *(_OWORD *)uint64_t v41 = v44;
  }
  return v5;
}

void *assignWithCopy for MLObjectDetector.ModelParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v5 = __dst;
  if (__dst != __src)
  {
    outlined destroy of MLObjectDetector.ModelParameters.ValidationData((uint64_t)__dst);
    uint64_t v6 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v6);
    switch(EnumCaseMultiPayload)
    {
      case 3:
        uint64_t v12 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 16))(__dst, __src, v12);
        uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
        uint64_t v14 = *(int *)(v13 + 48);
        *(void *)&__dst[v14] = *(void *)&__src[v14];
        uint64_t v15 = *(void *)&__src[v14 + 8];
        *(void *)((char *)v5 + v14 + 8) = v15;
        uint64_t v16 = *(int *)(v13 + 64);
        *(void *)((char *)v5 + v16) = *(void *)&__src[v16];
        uint64_t v17 = v6;
        uint64_t v18 = *(void *)&__src[v16 + 8];
        *(void *)((char *)v5 + v16 + 8) = v18;
        swift_bridgeObjectRetain(v15);
        swift_bridgeObjectRetain(v18);
        uint64_t v19 = 3;
        uint64_t v20 = v5;
        uint64_t v21 = v17;
        break;
      case 2:
        uint64_t v22 = *(void *)__src;
        uint64_t v47 = v6;
        char v23 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v23);
        *(void *)__dst = v22;
        __dst[8] = v23;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v24 = *((void *)__src + 3);
        v5[3] = v24;
        v5[4] = *((void *)__src + 4);
        uint64_t v25 = *((void *)__src + 5);
        v5[5] = v25;
        swift_bridgeObjectRetain(v24);
        swift_bridgeObjectRetain(v25);
        uint64_t v19 = 2;
        uint64_t v20 = v5;
        uint64_t v21 = v47;
        break;
      case 1:
        uint64_t v8 = type metadata accessor for MLObjectDetector.DataSource(0);
        switch(swift_getEnumCaseMultiPayload(__src, v8))
        {
          case 0u:
            uint64_t v9 = type metadata accessor for URL(0);
            (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))(__dst, __src, v9);
            uint64_t v10 = v8;
            uint64_t v11 = 0;
            goto LABEL_14;
          case 1u:
            uint64_t v50 = v8;
            uint64_t v26 = type metadata accessor for URL(0);
            uint64_t v48 = v6;
            uint64_t v27 = *(void (**)(char *, char *, uint64_t))(*(void *)(v26 - 8) + 16);
            v27(__dst, __src, v26);
            uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL));
            v27(&__dst[*(int *)(v28 + 48)], &__src[*(int *)(v28 + 48)], v26);
            uint64_t v6 = v48;
            uint64_t v46 = 1;
            goto LABEL_13;
          case 2u:
            uint64_t v50 = v8;
            uint64_t v29 = *(void *)__src;
            char v49 = __src[8];
            outlined copy of Result<_DataTable, Error>(*(void *)__src, v49);
            *(void *)__dst = v29;
            __dst[8] = v49;
            *((void *)__dst + 2) = *((void *)__src + 2);
            uint64_t v30 = *((void *)__src + 3);
            v5[3] = v30;
            v5[4] = *((void *)__src + 4);
            uint64_t v31 = *((void *)__src + 5);
            v5[5] = v31;
            swift_bridgeObjectRetain(v30);
            swift_bridgeObjectRetain(v31);
            uint64_t v46 = 2;
            goto LABEL_13;
          case 3u:
            uint64_t v32 = type metadata accessor for DataFrame(0);
            (*(void (**)(char *, char *, uint64_t))(*(void *)(v32 - 8) + 16))(__dst, __src, v32);
            uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
            uint64_t v34 = *(int *)(v33 + 48);
            *(void *)&__dst[v34] = *(void *)&__src[v34];
            uint64_t v35 = *(void *)&__src[v34 + 8];
            *(void *)((char *)v5 + v34 + 8) = v35;
            uint64_t v36 = *(int *)(v33 + 64);
            *(void *)((char *)v5 + v36) = *(void *)&__src[v36];
            uint64_t v50 = v8;
            uint64_t v37 = *(void *)&__src[v36 + 8];
            *(void *)((char *)v5 + v36 + 8) = v37;
            swift_bridgeObjectRetain(v35);
            swift_bridgeObjectRetain(v37);
            uint64_t v46 = 3;
LABEL_13:
            uint64_t v11 = v46;
            __dst = (char *)v5;
            uint64_t v10 = v50;
LABEL_14:
            swift_storeEnumTagMultiPayload(__dst, v10, v11);
            uint64_t v19 = 1;
            uint64_t v20 = v5;
            uint64_t v21 = v6;
            break;
        }
        break;
      default:
        memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
        goto LABEL_16;
    }
    swift_storeEnumTagMultiPayload(v20, v21, v19);
  }
LABEL_16:
  uint64_t v38 = a3[5];
  *((unsigned char *)v5 + v38 + 8) = __src[v38 + 8];
  *(void *)((char *)v5 + v38) = *(void *)&__src[v38];
  uint64_t v39 = a3[6];
  *(void *)((char *)v5 + v39) = *(void *)&__src[v39];
  *((unsigned char *)v5 + v39 + 8) = __src[v39 + 8];
  *(void *)((char *)v5 + a3[7]) = *(void *)&__src[a3[7]];
  *(void *)((char *)v5 + a3[8]) = *(void *)&__src[a3[8]];
  *((unsigned char *)v5 + a3[9]) = __src[a3[9]];
  uint64_t v40 = a3[10];
  uint64_t v41 = (char *)v5 + v40;
  uint64_t v42 = &__src[v40];
  uint64_t v43 = *(void *)&__src[v40 + 24];
  if (!*(void *)((char *)v5 + v40 + 24))
  {
    if (v43)
    {
      *((void *)v41 + 3) = v43;
      (**(void (***)(char *, char *))(v43 - 8))(v41, v42);
      return v5;
    }
LABEL_22:
    long long v44 = *(_OWORD *)v42;
    *((_OWORD *)v41 + 1) = *((_OWORD *)v42 + 1);
    *(_OWORD *)uint64_t v41 = v44;
    return v5;
  }
  if (!v43)
  {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)((char *)v5 + v40));
    goto LABEL_22;
  }
  __swift_assign_boxed_opaque_existential_0((void *)((char *)v5 + v40), (uint64_t *)&__src[v40]);
  return v5;
}

char *initializeWithTake for MLObjectDetector.ModelParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v5 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v5);
  if (EnumCaseMultiPayload == 3)
  {
    uint64_t v12 = type metadata accessor for DataFrame(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
    uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
    *(_OWORD *)&__dst[*(int *)(v13 + 48)] = *(_OWORD *)&__src[*(int *)(v13 + 48)];
    *(_OWORD *)&__dst[*(int *)(v13 + 64)] = *(_OWORD *)&__src[*(int *)(v13 + 64)];
    swift_storeEnumTagMultiPayload(__dst, v5, 3);
  }
  else
  {
    if (EnumCaseMultiPayload == 1)
    {
      uint64_t v7 = type metadata accessor for MLObjectDetector.DataSource(0);
      int v8 = swift_getEnumCaseMultiPayload(__src, v7);
      if (v8 == 3)
      {
        uint64_t v14 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 32))(__dst, __src, v14);
        uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
        *(_OWORD *)&__dst[*(int *)(v15 + 48)] = *(_OWORD *)&__src[*(int *)(v15 + 48)];
        *(_OWORD *)&__dst[*(int *)(v15 + 64)] = *(_OWORD *)&__src[*(int *)(v15 + 64)];
        uint64_t v22 = 3;
      }
      else
      {
        if (v8 != 1)
        {
          if (v8)
          {
            memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
            goto LABEL_14;
          }
          uint64_t v9 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
          uint64_t v10 = v7;
          uint64_t v11 = 0;
LABEL_12:
          swift_storeEnumTagMultiPayload(__dst, v10, v11);
LABEL_14:
          swift_storeEnumTagMultiPayload(__dst, v5, 1);
          goto LABEL_15;
        }
        uint64_t v23 = type metadata accessor for URL(0);
        uint64_t v24 = *(void (**)(char *, char *, uint64_t))(*(void *)(v23 - 8) + 32);
        v24(__dst, __src, v23);
        uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL));
        v24(&__dst[*(int *)(v16 + 48)], &__src[*(int *)(v16 + 48)], v23);
        uint64_t v22 = 1;
      }
      uint64_t v11 = v22;
      uint64_t v10 = v7;
      goto LABEL_12;
    }
    memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
  }
LABEL_15:
  uint64_t v17 = a3[5];
  __dst[v17 + 8] = __src[v17 + 8];
  *(void *)&__dst[v17] = *(void *)&__src[v17];
  uint64_t v18 = a3[6];
  *(void *)&__dst[v18] = *(void *)&__src[v18];
  __dst[v18 + 8] = __src[v18 + 8];
  *(void *)&__dst[a3[7]] = *(void *)&__src[a3[7]];
  *(void *)&__dst[a3[8]] = *(void *)&__src[a3[8]];
  __dst[a3[9]] = __src[a3[9]];
  uint64_t v19 = a3[10];
  long long v20 = *(_OWORD *)&__src[v19];
  *(_OWORD *)&__dst[v19 + 16] = *(_OWORD *)&__src[v19 + 16];
  *(_OWORD *)&__dst[v19] = v20;
  return __dst;
}

char *assignWithTake for MLObjectDetector.ModelParameters(char *__dst, char *__src, int *a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLObjectDetector.ModelParameters.ValidationData((uint64_t)__dst);
    uint64_t v5 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v5);
    if (EnumCaseMultiPayload == 3)
    {
      uint64_t v12 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
      uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
      *(_OWORD *)&__dst[*(int *)(v13 + 48)] = *(_OWORD *)&__src[*(int *)(v13 + 48)];
      *(_OWORD *)&__dst[*(int *)(v13 + 64)] = *(_OWORD *)&__src[*(int *)(v13 + 64)];
      swift_storeEnumTagMultiPayload(__dst, v5, 3);
      goto LABEL_16;
    }
    if (EnumCaseMultiPayload != 1)
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
      goto LABEL_16;
    }
    uint64_t v7 = type metadata accessor for MLObjectDetector.DataSource(0);
    int v8 = swift_getEnumCaseMultiPayload(__src, v7);
    if (v8 == 3)
    {
      uint64_t v14 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 32))(__dst, __src, v14);
      uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
      *(_OWORD *)&__dst[*(int *)(v15 + 48)] = *(_OWORD *)&__src[*(int *)(v15 + 48)];
      *(_OWORD *)&__dst[*(int *)(v15 + 64)] = *(_OWORD *)&__src[*(int *)(v15 + 64)];
      uint64_t v23 = 3;
    }
    else
    {
      if (v8 != 1)
      {
        if (v8)
        {
          memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
          goto LABEL_15;
        }
        uint64_t v9 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
        uint64_t v10 = v7;
        uint64_t v11 = 0;
LABEL_13:
        swift_storeEnumTagMultiPayload(__dst, v10, v11);
LABEL_15:
        swift_storeEnumTagMultiPayload(__dst, v5, 1);
        goto LABEL_16;
      }
      uint64_t v24 = type metadata accessor for URL(0);
      uint64_t v25 = *(void (**)(char *, char *, uint64_t))(*(void *)(v24 - 8) + 32);
      v25(__dst, __src, v24);
      uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL));
      v25(&__dst[*(int *)(v16 + 48)], &__src[*(int *)(v16 + 48)], v24);
      uint64_t v23 = 1;
    }
    uint64_t v11 = v23;
    uint64_t v10 = v7;
    goto LABEL_13;
  }
LABEL_16:
  uint64_t v17 = a3[5];
  __dst[v17 + 8] = __src[v17 + 8];
  *(void *)&__dst[v17] = *(void *)&__src[v17];
  uint64_t v18 = a3[6];
  *(void *)&__dst[v18] = *(void *)&__src[v18];
  __dst[v18 + 8] = __src[v18 + 8];
  *(void *)&__dst[a3[7]] = *(void *)&__src[a3[7]];
  *(void *)&__dst[a3[8]] = *(void *)&__src[a3[8]];
  __dst[a3[9]] = __src[a3[9]];
  uint64_t v19 = a3[10];
  long long v20 = &__dst[v19];
  if (*(void *)&__dst[v19 + 24]) {
    __swift_destroy_boxed_opaque_existential_1Tm(&__dst[v19]);
  }
  long long v21 = *(_OWORD *)&__src[v19];
  *((_OWORD *)v20 + 1) = *(_OWORD *)&__src[v19 + 16];
  *(_OWORD *)long long v20 = v21;
  return __dst;
}

uint64_t getEnumTagSinglePayload for MLObjectDetector.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_31126D);
}

uint64_t sub_31126D(uint64_t a1, unsigned int a2, uint64_t a3)
{
  unsigned int v4 = 0;
  uint64_t v5 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(a1, a2, v5);
  }
  int v7 = -1;
  if ((int)((*(void *)(a1 + *(int *)(a3 + 40) + 24) >> 1) - 1) >= 0) {
    int v7 = (*(void *)(a1 + *(int *)(a3 + 40) + 24) >> 1) - 1;
  }
  unsigned int v8 = v7 + 1;
  if ((*(void *)(a1 + *(int *)(a3 + 40) + 24) & 0xFFFFFFFF00000001) == 0) {
    return v8;
  }
  return v4;
}

uint64_t storeEnumTagSinglePayload for MLObjectDetector.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_3112F3);
}

uint64_t sub_3112F3(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  if (*(_DWORD *)(*(void *)(v6 - 8) + 84) == a3) {
    return __swift_storeEnumTagSinglePayload(a1, a2, a2, v6);
  }
  uint64_t result = *(int *)(a4 + 40);
  *(void *)(a1 + result + 24) = 2 * a2;
  return result;
}

uint64_t type metadata completion function for MLObjectDetector.ModelParameters(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(319);
  if (v2 <= 0x3F)
  {
    v3[0] = *(void *)(result - 8) + 64;
    v3[1] = "\t";
    v3[2] = "\t";
    void v3[3] = (char *)&value witness table for Builtin.Int64 + 64;
    v3[4] = (char *)&value witness table for Builtin.Int64 + 64;
    v3[5] = &unk_352188;
    v3[6] = &unk_3521A0;
    swift_initStructMetadata(a1, 256, 7, v3, a1 + 16);
    return 0;
  }
  return result;
}

void *static _AudioUtilities.validateAudioURLs(from:)(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for URL(0);
  uint64_t v2 = *(void *)(v1 - 8);
  int64_t v3 = *(void *)(v2 + 64);
  unsigned int v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v47 = &v40;
  uint64_t v6 = alloca(v3);
  int v7 = alloca(v3);
  char v49 = &v40;
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  unsigned __int8 v53 = &v40;
  uint64_t v11 = *(void *)(a1 + 16);
  uint64_t v50 = a1;
  if (v11)
  {
    uint64_t v42 = v11;
    uint64_t v43 = (*(unsigned __int8 *)(v2 + 80) + 32) & ~*(unsigned __int8 *)(v2 + 80);
    uint64_t v12 = a1 + v43;
    uint64_t v46 = *(void (**)(uint64_t, uint64_t, uint64_t))(v2 + 16);
    uint64_t v54 = *(void *)(v2 + 72);
    swift_bridgeObjectRetain(a1);
    uint64_t v55 = _swiftEmptyArrayStorage;
    long long v44 = "quence typed column. Column '" + 0x8000000000000000;
    uint64_t v48 = v1;
    uint64_t v13 = (uint64_t)v49;
    uint64_t v14 = (uint64_t)v53;
    uint64_t v41 = v2;
    while (1)
    {
      uint64_t v45 = v12;
      v46(v14, v12, v1);
      __swift_storeEnumTagSinglePayload(v14, 0, 1, v1);
      if (__swift_getEnumTagSinglePayload(v14, 1, v1) == 1) {
        break;
      }
      uint64_t v15 = *(double (**)(uint64_t, uint64_t, uint64_t))(v2 + 32);
      double v16 = v15(v13, v14, v1);
      if (static _AudioUtilities.validateOneAudioURL(from:)(v13, v16))
      {
        v46((uint64_t)v47, v13, v1);
        uint64_t v17 = v55;
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v55);
        uint64_t v19 = v45;
        if (!isUniquelyReferenced_nonNull_native) {
          uint64_t v17 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v17[2] + 1, 1, (uint64_t)v17);
        }
        unint64_t v20 = v17[2];
        uint64_t v21 = v54;
        if (v17[3] >> 1 <= v20)
        {
          uint64_t v37 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v17[3] >= 2uLL, v20 + 1, 1, (uint64_t)v17);
          uint64_t v21 = v54;
          uint64_t v17 = v37;
        }
        double v17[2] = v20 + 1;
        uint64_t v55 = v17;
        uint64_t v22 = (char *)v17 + v43 + v21 * v20;
        uint64_t v1 = v48;
        uint64_t v23 = v21;
        v15((uint64_t)v22, (uint64_t)v47, v48);
        uint64_t v13 = (uint64_t)v49;
      }
      else
      {
        unint64_t v51 = 0;
        unint64_t v52 = 0xE000000000000000;
        _StringGuts.grow(_:)(35);
        unint64_t v24 = v52;
        swift_bridgeObjectRelease(v52);
        unint64_t v51 = 0xD000000000000020;
        unint64_t v52 = (unint64_t)v44;
        v25._uint64_t countAndFlagsBits = URL.path.getter(v24);
        char object = (char)v25._object;
        String.append(_:)(v25);
        swift_bridgeObjectRelease(object);
        v27._uint64_t countAndFlagsBits = 46;
        v27._char object = (void *)0xE100000000000000;
        String.append(_:)(v27);
        unint64_t v28 = v51;
        unint64_t v29 = v52;
        unsigned __int8 v56 = static os_log_type_t.info.getter();
        uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
        uint64_t v31 = (void *)swift_allocObject(v30, 64, 7);
        v31[2] = 1;
        v31[3] = 2;
        v31[7] = &type metadata for String;
        v31[4] = v28;
        unint64_t v32 = v28;
        v31[5] = v29;
        swift_bridgeObjectRetain(v29);
        print(_:separator:terminator:)(v31, 32, 0xE100000000000000, 10, 0xE100000000000000);
        swift_bridgeObjectRelease((_BYTE)v31);
        type metadata accessor for OS_os_log();
        uint64_t v33 = (void *)static OS_os_log.default.getter(0);
        uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
        uint64_t v35 = (void *)swift_allocObject(v34, 72, 7);
        long long v35[2] = 1;
        v35[3] = 2;
        v35[7] = &type metadata for String;
        v35[8] = lazy protocol witness table accessor for type String and conformance String();
        v35[4] = v32;
        v35[5] = v29;
        swift_bridgeObjectRetain(v29);
        os_log(_:dso:log:type:_:)("%@\n", 3, 2, &dword_0, v33, v56, v35);
        LOBYTE(v27._countAndFlagsBits) = v29;
        uint64_t v1 = v48;
        swift_bridgeObjectRelease(v27._countAndFlagsBits);

        swift_bridgeObjectRelease((_BYTE)v35);
        uint64_t v23 = v54;
        uint64_t v19 = v45;
      }
      uint64_t v2 = v41;
      (*(void (**)(uint64_t, uint64_t))(v41 + 8))(v13, v1);
      uint64_t v12 = v23 + v19;
      BOOL v36 = v42-- == 1;
      uint64_t v14 = (uint64_t)v53;
      if (v36) {
        goto LABEL_14;
      }
    }
  }
  else
  {
    swift_bridgeObjectRetain(a1);
    uint64_t v55 = _swiftEmptyArrayStorage;
    uint64_t v14 = (uint64_t)v53;
LABEL_14:
    __swift_storeEnumTagSinglePayload(v14, 1, 1, v1);
  }
  uint64_t v38 = v55;
  swift_bridgeObjectRelease(v50);
  return v38;
}

char static _AudioUtilities.validateOneAudioURL(from:)(uint64_t a1, double a2)
{
  uint64_t v2 = type metadata accessor for URL(0);
  uint64_t v3 = *(void *)(v2 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v3 + 16))(&v22, a1, v2);
  objc_allocWithZone((Class)AVAudioFile);
  id v7 = @nonobjc AVAudioFile.init(forReading:)((uint64_t)&v22);
  id v8 = [v7 fileFormat];
  id v9 = v8;
  [v9 sampleRate];
  double v25 = a2;

  if (v25 <= 0.0)
  {
    uint64_t v23 = 0;
    unint64_t v24 = 0xE000000000000000;
    _StringGuts.grow(_:)(64);
    double v11 = *(double *)&v23;
    v12._uint64_t countAndFlagsBits = 0xD00000000000002BLL;
    v12._char object = "tted audio file " + 0x8000000000000000;
    String.append(_:)(v12);
    uint64_t v13 = lazy protocol witness table accessor for type URL and conformance URL();
    uint64_t v14 = dispatch thunk of CustomStringConvertible.description.getter(v2, v13);
    char v16 = (char)v15;
    v12._uint64_t countAndFlagsBits = v14;
    v12._char object = v15;
    String.append(_:)(v12);
    swift_bridgeObjectRelease(v16);
    v12._char object = "s to be greater than zero, " + 0x8000000000000000;
    v12._uint64_t countAndFlagsBits = 0xD000000000000010;
    String.append(_:)(v12);
    id v17 = [v7 fileFormat];
    id v18 = v17;
    [v18 sampleRate];
    double v25 = v11;

    Double.write<A>(to:)(&v23, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    v12._uint64_t countAndFlagsBits = 46;
    v12._char object = (void *)0xE100000000000000;
    String.append(_:)(v12);
    uint64_t v19 = v23;
    unint64_t v20 = (void *)v24;
    os_log_type_t v21 = static os_log_type_t.default.getter(46);
    v12._uint64_t countAndFlagsBits = v19;
    v12._char object = v20;
    log(_:type:)(v12, v21);
    swift_bridgeObjectRelease((_BYTE)v20);

    return 0;
  }
  else
  {

    return 1;
  }
}

unsigned char *assignWithCopy for MLSupportVectorClassifier.ModelParameters.ValidationData(unsigned char *__dst, unsigned char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLSupportVectorClassifier.ModelParameters.ValidationData((uint64_t)__dst);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v7 = type metadata accessor for DataFrame(0);
      (*(void (**)(unsigned char *, unsigned char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v5 = *(void *)__src;
      char v6 = __src[8];
      outlined copy of Result<_DataTable, Error>(*(void *)__src, v6);
      *(void *)__dst = v5;
      __dst[8] = v6;
      swift_storeEnumTagMultiPayload(__dst, a3, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLSupportVectorClassifier.ModelParameters.ValidationData;
  if (!type metadata singleton initialization cache for MLSupportVectorClassifier.ModelParameters.ValidationData) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLSupportVectorClassifier.ModelParameters.ValidationData);
  }
  return result;
}

void *assignWithTake for MLSupportVectorClassifier.ModelParameters.ValidationData(void *__dst, void *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLSupportVectorClassifier.ModelParameters.ValidationData((uint64_t)__dst);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 2)
    {
      uint64_t v4 = type metadata accessor for DataFrame(0);
      (*(void (**)(void *, void *, uint64_t))(*(void *)(v4 - 8) + 32))(__dst, __src, v4);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLSupportVectorClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  v5[0] = &unk_3521C8;
  v5[1] = &unk_3521E0;
  uint64_t result = type metadata accessor for DataFrame(319);
  if (v4 <= 0x3F)
  {
    v5[2] = *(void *)(result - 8) + 64;
    swift_initEnumMetadataMultiPayload(a1, 256, 3, v5, v2, v3);
    return 0;
  }
  return result;
}

uint64_t MLSupportVectorClassifier.ModelParameters.ValidationData.asTable()(__m128 a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = type metadata accessor for DataFrame(0);
  uint64_t v27 = *(void *)(v4 - 8);
  int64_t v5 = *(void *)(v27 + 64);
  char v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  unint64_t v29 = &v25;
  id v8 = alloca(v5);
  id v9 = alloca(v5);
  unint64_t v28 = &v25;
  uint64_t v10 = type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData(0);
  int64_t v11 = *(void *)(*(void *)(v10 - 8) + 64);
  Swift::String v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  outlined init with copy of MLSupportVectorClassifier.ModelParameters.ValidationData(v2, (uint64_t)&v25);
  uint64_t result = swift_getEnumCaseMultiPayload(&v25, v10);
  switch((int)result)
  {
    case 0:
      *(void *)uint64_t v3 = 0;
      *(unsigned char *)(v3 + 8) = -1;
      break;
    case 1:
      uint64_t result = v25;
      char v15 = v26;
      goto LABEL_7;
    case 2:
      char v16 = v28;
      uint64_t v17 = v27;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v27 + 32))(v28, &v25, v4);
      uint64_t v18 = (uint64_t)v29;
      *(double *)a1.i64 = (*(double (**)(uint64_t *, uint64_t *, uint64_t))(v17 + 16))(v29, v16, v4);
      MLDataTable.init(_:convertArraysToShapedArrays:)(v18, 1, a1);
      (*(void (**)(uint64_t *, uint64_t))(v17 + 8))(v16, v4);
      uint64_t result = v30;
      char v15 = v31;
LABEL_7:
      *(void *)uint64_t v3 = result;
      *(unsigned char *)(v3 + 8) = v15;
      break;
    case 3:
      uint64_t v19 = v3;
      uint64_t empty = tc_v1_sframe_create_empty(0);
      if (!empty) {
        BUG();
      }
      uint64_t v21 = empty;
      uint64_t v22 = type metadata accessor for CMLTable();
      uint64_t v23 = swift_allocObject(v22, 24, 7);
      *(void *)(v23 + 16) = v21;
      uint64_t v24 = type metadata accessor for _DataTable();
      swift_allocObject(v24, 40, 7);
      uint64_t result = _DataTable.init(impl:)(v23);
      *(void *)uint64_t v19 = result;
      *(unsigned char *)(v19 + 8) = 0;
      break;
  }
  return result;
}

uint64_t MLSupportVectorClassifier.ModelParameters.ValidationData.generateDataFrames(trainingData:)(uint64_t a1, uint64_t a2, void (*a3)(uint64_t *, uint64_t, uint64_t))
{
  uint64_t v55 = v3;
  uint64_t v57 = a3;
  unsigned __int8 v56 = (uint64_t *)a2;
  uint64_t v54 = a1;
  uint64_t v5 = type metadata accessor for DataFrame(0);
  uint64_t v58 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v58 + 64);
  uint64_t v7 = alloca(v6);
  id v8 = alloca(v6);
  uint64_t v50 = &v44;
  uint64_t v46 = type metadata accessor for DataFrame.Slice(0);
  uint64_t v51 = *(void *)(v46 - 8);
  int64_t v9 = *(void *)(v51 + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v48 = &v44;
  Swift::String v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  unsigned __int8 v53 = &v44;
  uint64_t v14 = alloca(v9);
  char v15 = alloca(v9);
  unint64_t v52 = &v44;
  int64_t v16 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame.Slice?)
                              - 8)
                  + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v47 = &v44;
  uint64_t v19 = alloca(v16);
  unint64_t v20 = alloca(v16);
  char v49 = &v44;
  uint64_t v21 = type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData(0);
  int64_t v22 = *(void *)(*(void *)(v21 - 8) + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  outlined init with copy of MLSupportVectorClassifier.ModelParameters.ValidationData(v4, (uint64_t)&v44);
  switch(swift_getEnumCaseMultiPayload(&v44, v21))
  {
    case 0u:
      uint64_t v58 = v5;
      uint64_t v25 = (uint64_t)v49;
      uint64_t v26 = (uint64_t)v52;
      DataFrame.randomSplit(strategy:)((uint64_t)v49, (uint64_t)v52, (uint64_t)&v44);
      uint64_t v27 = v53;
      uint64_t v28 = v46;
      uint64_t v57 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 16);
      v57(v53, v26, v46);
      DataFrame.init(_:)(v27);
      uint64_t v29 = (uint64_t)v47;
      outlined init with copy of DataFrame.Slice?(v25, (uint64_t)v47);
      if (__swift_getEnumTagSinglePayload(v29, 1, v28) == 1)
      {
        __swift_storeEnumTagSinglePayload((uint64_t)v56, 1, 1, v58);
        uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v51 + 8);
      }
      else
      {
        uint64_t v40 = v53;
        uint64_t v41 = v51;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 32))(v53, v29, v28);
        uint64_t v42 = v48;
        v57(v48, (uint64_t)v40, v28);
        uint64_t v43 = (uint64_t)v56;
        DataFrame.init(_:)(v42);
        uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v41 + 8);
        v30(v53, v28);
        __swift_storeEnumTagSinglePayload(v43, 0, 1, v58);
      }
      v30(v52, v28);
      return outlined destroy of DataFrame.Slice?((uint64_t)v49);
    case 1u:
      uint64_t v35 = v44;
      char v36 = v45;
      (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
      uint64_t v44 = v35;
      char v45 = v36;
      uint64_t v37 = (uint64_t)v56;
      DataFrame.init(_:)((uint64_t)&v44);
      uint64_t v33 = v37;
      goto LABEL_10;
    case 2u:
      char v31 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v58 + 32);
      v31(v50, &v44, v5);
      if (DataFrameProtocol.isEmpty.getter(v5, &protocol witness table for DataFrame))
      {
        uint64_t v32 = v58;
        (*(void (**)(uint64_t *, uint64_t))(v58 + 8))(v50, v5);
        (*(void (**)(uint64_t, void, uint64_t))(v32 + 16))(v54, v57, v5);
LABEL_7:
        uint64_t v33 = (uint64_t)v56;
        uint64_t v34 = 1;
      }
      else
      {
        (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
        uint64_t v38 = (uint64_t)v56;
        v31(v56, v50, v5);
        uint64_t v33 = v38;
LABEL_10:
        uint64_t v34 = 0;
      }
      return __swift_storeEnumTagSinglePayload(v33, v34, 1, v5);
    case 3u:
      (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
      goto LABEL_7;
  }
}

uint64_t outlined init with copy of MLSupportVectorClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t specialized MLImageClassifier.Classifier.fitted<A>(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v5[6] = v4;
  v5[5] = a4;
  void v5[4] = a3;
  v5[3] = a1;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v5[7] = v6;
  uint64_t v7 = *(void *)(v6 - 8);
  v5[8] = v7;
  v5[9] = swift_task_alloc((*(void *)(v7 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  v5[10] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v5[11] = v9;
  v5[12] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v5[13] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v5[14] = v11;
  v5[15] = swift_task_alloc((*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  v5[16] = v12;
  uint64_t v13 = *(void *)(v12 - 8);
  v5[17] = v13;
  v5[18] = swift_task_alloc((*(void *)(v13 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  v5[19] = v14;
  v5[20] = swift_task_alloc((*(void *)(*(void *)(v14 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  v5[2] = a2;
  return swift_task_switch(specialized MLImageClassifier.Classifier.fitted<A>(to:eventHandler:), 0, 0);
}

uint64_t specialized MLImageClassifier.Classifier.fitted<A>(to:eventHandler:)()
{
  uint64_t v12 = v0 + 2;
  uint64_t v1 = v0[20];
  uint64_t v2 = v0[19];
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0[6], v1, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v1, v2);
  uint64_t v4 = v0[20];
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(v0[11] + 32))(v0[12], v4, v0[10]);
    uint64_t v5 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifier.fitted<A>(to:eventHandler:)[1]);
    v0[23] = v5;
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    uint64_t v7 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>], (uint64_t)&protocol conformance descriptor for [A]);
    *uint64_t v5 = v0;
    v5[1] = specialized MLImageClassifier.Classifier.fitted<A>(to:eventHandler:);
    return FullyConnectedNetworkClassifier.fitted<A>(to:eventHandler:)(v0[9], v12, v0[4], v0[5], v0[10], v6, v7);
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(v0[17] + 32))(v0[18], v4, v0[16]);
    uint64_t v9 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifier.fitted<A>(to:eventHandler:)[1]);
    v0[21] = v9;
    uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    uint64_t v11 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>], (uint64_t)&protocol conformance descriptor for [A]);
    void *v9 = v0;
    v9[1] = specialized MLImageClassifier.Classifier.fitted<A>(to:eventHandler:);
    return LogisticRegressionClassifier.fitted<A>(to:eventHandler:)(v0[15], v12, v0[4], v0[5], v0[16], v10, v11);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 168);
  *(void *)(*(void *)v1 + 176) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
  }
  else {
    uint64_t v3 = specialized MLImageClassifier.Classifier.fitted<A>(to:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 184);
  *(void *)(*(void *)v1 + 192) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
  }
  else {
    uint64_t v3 = specialized MLImageClassifier.Classifier.fitted<A>(to:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v10 = *(void *)(v0 + 144);
  uint64_t v1 = *(void *)(v0 + 120);
  uint64_t v2 = *(void *)(v0 + 112);
  uint64_t v3 = *(void *)(v0 + 104);
  uint64_t v9 = *(void *)(v0 + 160);
  uint64_t v8 = *(void *)(v0 + 96);
  uint64_t v4 = *(void *)(v0 + 24);
  uint64_t v7 = *(void *)(v0 + 72);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 136) + 8))(v10, *(void *)(v0 + 128));
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v2 + 32))(v4, v1, v3);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload(v4, v5, 0);
  swift_task_dealloc(v9);
  swift_task_dealloc(v10);
  swift_task_dealloc(v1);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v7 = *(void *)(v0 + 96);
  uint64_t v1 = *(void *)(v0 + 72);
  uint64_t v2 = *(void *)(v0 + 64);
  uint64_t v3 = *(void *)(v0 + 24);
  uint64_t v4 = *(void *)(v0 + 56);
  uint64_t v10 = *(void *)(v0 + 160);
  uint64_t v9 = *(void *)(v0 + 144);
  uint64_t v8 = *(void *)(v0 + 120);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 88) + 8))(v7, *(void *)(v0 + 80));
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v2 + 32))(v3, v1, v4);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload(v3, v5, 1);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t specialized MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  v6[7] = v5;
  v6[6] = a5;
  v6[5] = a4;
  void v6[4] = a1;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  void v6[8] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v6[9] = v9;
  v6[10] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  v6[11] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v6[12] = v11;
  v6[13] = swift_task_alloc((*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v6[14] = v12;
  uint64_t v13 = *(void *)(v12 - 8);
  v6[15] = v13;
  v6[16] = swift_task_alloc((*(void *)(v13 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  v6[17] = v14;
  uint64_t v15 = *(void *)(v14 - 8);
  v6[18] = v15;
  v6[19] = swift_task_alloc((*(void *)(v15 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  v6[20] = v16;
  v6[21] = swift_task_alloc((*(void *)(*(void *)(v16 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  void v6[2] = a2;
  v6[3] = a3;
  return swift_task_switch(specialized MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:), 0, 0);
}

uint64_t specialized MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)()
{
  uint64_t v11 = v0 + 2;
  uint64_t v10 = v0 + 3;
  uint64_t v1 = v0[21];
  uint64_t v2 = v0[20];
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0[7], v1, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v1, v2);
  uint64_t v4 = v0[21];
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(v0[12] + 32))(v0[13], v4, v0[11]);
    uint64_t v5 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifier.fitted<A, B>(to:validateOn:eventHandler:)[1]);
    v0[24] = v5;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    uint64_t v6 = (void *)lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>], (uint64_t)&protocol conformance descriptor for [A]);
    *uint64_t v5 = v0;
    v5[1] = specialized MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
    retaddr = v6;
    return FullyConnectedNetworkClassifier.fitted<A, B>(to:validateOn:eventHandler:)(v0[10], v11, v10, v0[5], v0[6], v0[11]);
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(v0[18] + 32))(v0[19], v4, v0[17]);
    uint64_t v8 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifier.fitted<A, B>(to:validateOn:eventHandler:)[1]);
    v0[22] = v8;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    uint64_t v9 = (void *)lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>], (uint64_t)&protocol conformance descriptor for [A]);
    void *v8 = v0;
    v8[1] = specialized MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
    retaddr = v9;
    return LogisticRegressionClassifier.fitted<A, B>(to:validateOn:eventHandler:)(v0[16], v11, v10, v0[5], v0[6], v0[17]);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 176);
  *(void *)(*(void *)v1 + 184) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  }
  else {
    uint64_t v3 = specialized MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 192);
  *(void *)(*(void *)v1 + 200) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  }
  else {
    uint64_t v3 = specialized MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v10 = *(void *)(v0 + 152);
  uint64_t v1 = *(void *)(v0 + 128);
  uint64_t v2 = *(void *)(v0 + 120);
  uint64_t v3 = *(void *)(v0 + 112);
  uint64_t v9 = *(void *)(v0 + 168);
  uint64_t v8 = *(void *)(v0 + 104);
  uint64_t v4 = *(void *)(v0 + 32);
  uint64_t v7 = *(void *)(v0 + 80);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 144) + 8))(v10, *(void *)(v0 + 136));
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v2 + 32))(v4, v1, v3);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload(v4, v5, 0);
  swift_task_dealloc(v9);
  swift_task_dealloc(v10);
  swift_task_dealloc(v1);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v7 = *(void *)(v0 + 104);
  uint64_t v1 = *(void *)(v0 + 80);
  uint64_t v2 = *(void *)(v0 + 72);
  uint64_t v3 = *(void *)(v0 + 32);
  uint64_t v4 = *(void *)(v0 + 64);
  uint64_t v10 = *(void *)(v0 + 168);
  uint64_t v9 = *(void *)(v0 + 152);
  uint64_t v8 = *(void *)(v0 + 128);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 96) + 8))(v7, *(void *)(v0 + 88));
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v2 + 32))(v3, v1, v4);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload(v3, v5, 1);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t specialized AnnotatedFeatureStore.init<A>(_:)(uint64_t a1)
{
  uint64_t v2 = a1;
  uint64_t v3 = v1;
  uint64_t v36 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  uint64_t v37 = *(void *)(v36 - 8);
  int64_t v4 = *(void *)(v37 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v43 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
  uint64_t v44 = *(void *)(v43 - 8);
  int64_t v7 = *(void *)(v44 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  char v45 = &v28;
  BlobsFile.init()();
  uint64_t v34 = a1;
  uint64_t v10 = *(void *)(a1 + 16);
  if (v10)
  {
    uint64_t v41 = v3;
    uint64_t v11 = a1 + ((*(unsigned __int8 *)(v44 + 80) + 32) & ~*(unsigned __int8 *)(v44 + 80));
    uint64_t v38 = *(void (**)(long long *, uint64_t, uint64_t))(v44 + 16);
    uint64_t v39 = *(void *)(v44 + 72);
    uint64_t v42 = a1;
    swift_bridgeObjectRetain_n(a1, 2);
    uint64_t v40 = &v28;
    uint64_t v12 = v43;
    uint64_t v13 = v45;
    uint64_t v14 = v36;
    do
    {
      uint64_t v35 = v10;
      v38(v13, v11, v12);
      uint64_t v15 = v40;
      AnnotatedFeature.feature.getter(v12);
      uint64_t v16 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
      v17._rawValue = (void *)MLShapedArrayProtocol.scalars.getter(v14, v16);
      uint64_t v18 = v15;
      uint64_t v19 = v35;
      (*(void (**)(long long *, uint64_t))(v37 + 8))(v18, v14);
      BlobsFile.appendBlob(_:)(v17);
      uint64_t v13 = v45;
      LOBYTE(v18) = v17._rawValue;
      uint64_t v12 = v43;
      swift_bridgeObjectRelease((_BYTE)v18);
      (*(void (**)(long long *, uint64_t))(v44 + 8))(v13, v12);
      v11 += v39;
      uint64_t v10 = v19 - 1;
    }
    while (v10);
    swift_bridgeObjectRelease_n(v42, 2, v20, v21, v22);
    uint64_t v2 = v34;
    uint64_t v3 = v41;
  }
  long long v23 = v33;
  uint64_t result = v29;
  long long v25 = v30;
  long long v26 = v31;
  long long v27 = v32;
  *(_OWORD *)uint64_t v3 = v28;
  *(void *)(v3 + 16) = result;
  *(_OWORD *)(v3 + 24) = v25;
  *(_OWORD *)(v3 + 40) = v26;
  *(_OWORD *)(v3 + 56) = v27;
  *(_OWORD *)(v3 + 72) = v23;
  *(void *)(v3 + 88) = v2;
  return result;
}

uint64_t specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v3[39] = a3;
  v3[38] = a2;
  v3[37] = a1;
  v3[35] = a1;
  return swift_task_switch(specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:), 0, 0);
}

uint64_t specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  if (*(void *)(v0 + 312) && (uint64_t v1 = *(void *)(v0 + 304)) != 0)
  {
    uint64_t v2 = *(void *)(v0 + 296);
    uint64_t v32 = *(void *)(v0 + 312);
    uint64_t v3 = swift_allocEmptyBox();
    *(void *)(v0 + 320) = v3;
    uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Augmenter<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0, SystemRandomNumberGenerator>);
    *(void *)(v0 + 328) = v33;
    uint64_t v4 = *(void *)(v33 - 8);
    *(void *)(v0 + 336) = v4;
    *(void *)(v0 + 344) = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
    uint64_t v47 = swift_allocObject(&unk_39DEE8, 32, 7);
    *(void *)(v47 + 16) = v1;
    *(void *)(v47 + 24) = v3;
    swift_bridgeObjectRetain(v2);
    swift_retain();
    uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
    uint64_t v5 = type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for CIImage, CIImage_ptr);
    uint64_t v35 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
    uint64_t v36 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
    uint64_t v37 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
    uint64_t v38 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
    uint64_t v39 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
    uint64_t v40 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
    uint64_t v41 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
    uint64_t v42 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
    uint64_t v43 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
    uint64_t v44 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
    uint64_t v8 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>, (uint64_t)&protocol conformance descriptor for ApplyRandomly<A>);
    *(void *)(v0 + 256) = v5;
    *(void *)(v0 + 264) = v7;
    *(void *)(v0 + 272) = v8;
    uint64_t OpaqueTypeConformance2 = swift_getOpaqueTypeConformance2(v0 + 256, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>, 1);
    uint64_t v10 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>, (uint64_t)&protocol conformance descriptor for ApplyRandomly<A>);
    *(void *)(v0 + 16) = v5;
    *(void *)(v0 + 24) = v44;
    *(void *)(v0 + 32) = v6;
    *(void *)(v0 + 40) = OpaqueTypeConformance2;
    *(void *)(v0 + 48) = v10;
    uint64_t v11 = swift_getOpaqueTypeConformance2(v0 + 16, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>, 1);
    *(void *)(v0 + 56) = v5;
    *(void *)(v0 + 64) = v43;
    *(void *)(v0 + 72) = v6;
    *(void *)(v0 + 80) = v11;
    *(void *)(v0 + 88) = v10;
    uint64_t v12 = swift_getOpaqueTypeConformance2(v0 + 56, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>, 1);
    uint64_t v13 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>, (uint64_t)&protocol conformance descriptor for ApplyRandomly<A>);
    *(void *)(v0 + 96) = v5;
    *(void *)(v0 + 104) = v41;
    *(void *)(v0 + 112) = v42;
    *(void *)(v0 + 120) = v12;
    *(void *)(v0 + 128) = v13;
    uint64_t v14 = swift_getOpaqueTypeConformance2(v0 + 96, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>, 1);
    uint64_t v15 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>, (uint64_t)&protocol conformance descriptor for ApplyRandomly<A>);
    *(void *)(v0 + 136) = v5;
    *(void *)(v0 + 144) = v39;
    *(void *)(v0 + 152) = v40;
    *(void *)(v0 + 160) = v14;
    *(void *)(v0 + 168) = v15;
    uint64_t v16 = swift_getOpaqueTypeConformance2(v0 + 136, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>, 1);
    uint64_t v17 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>, (uint64_t)&protocol conformance descriptor for ApplyRandomly<A>);
    *(void *)(v0 + 176) = v5;
    *(void *)(v0 + 184) = v37;
    *(void *)(v0 + 192) = v38;
    *(void *)(v0 + 200) = v16;
    *(void *)(v0 + 208) = v17;
    uint64_t v18 = swift_getOpaqueTypeConformance2(v0 + 176, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>, 1);
    uint64_t v19 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>, (uint64_t)&protocol conformance descriptor for ApplyRandomly<A>);
    *(void *)(v0 + 216) = v5;
    *(void *)(v0 + 224) = v35;
    *(void *)(v0 + 232) = v36;
    *(void *)(v0 + 240) = v18;
    *(void *)(v0 + 248) = v19;
    uint64_t v20 = swift_getOpaqueTypeConformance2(v0 + 216, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>, 1);
    Augmenter.init<A>(generator:_:)(v20, partial apply for closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:), v47, v34, &type metadata for SystemRandomNumberGenerator, v5, v20, &protocol witness table for SystemRandomNumberGenerator);
    uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for UpsampledAugmentationSequence<[AnnotatedFeature<CIImage, String>], <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0, SystemRandomNumberGenerator, String>.AsyncIterator);
    *(void *)(v0 + 352) = v45;
    uint64_t v21 = *(void *)(v45 - 8);
    *(void *)(v0 + 360) = v21;
    *(void *)(v0 + 368) = swift_task_alloc((*(void *)(v21 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
    uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for UpsampledAugmentationSequence<[AnnotatedFeature<CIImage, String>], <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0, SystemRandomNumberGenerator, String>);
    uint64_t v46 = *(void *)(v22 - 8);
    uint64_t v23 = swift_task_alloc((*(void *)(v46 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
    uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<CIImage, String>]);
    uint64_t v25 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<CIImage, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<CIImage, String>], (uint64_t)&protocol conformance descriptor for [A]);
    Augmenter.applied<A, B>(to:upsampledBy:)(v0 + 280, v32, v33, v24, &type metadata for String, v25, &protocol witness table for String);
    UpsampledAugmentationSequence.makeAsyncIterator()(v22);
    (*(void (**)(uint64_t, uint64_t))(v46 + 8))(v23, v22);
    swift_task_dealloc(v23);
    uint64_t v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>?);
    uint64_t v27 = swift_task_alloc((*(void *)(*(void *)(v26 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
    *(void *)(v0 + 376) = v27;
    uint64_t v28 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type UpsampledAugmentationSequence<[AnnotatedFeature<CIImage, String>], <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0, SystemRandomNumberGenerator, String>.AsyncIterator and conformance UpsampledAugmentationSequence<A, B, C, D>.AsyncIterator, &demangling cache variable for type metadata for UpsampledAugmentationSequence<[AnnotatedFeature<CIImage, String>], <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0, SystemRandomNumberGenerator, String>.AsyncIterator, (uint64_t)&protocol conformance descriptor for UpsampledAugmentationSequence<A, B, C, D>.AsyncIterator);
    *(void *)(v0 + 384) = v28;
    uint64_t v29 = (void *)swift_task_alloc(async function pointer to dispatch thunk of AsyncIteratorProtocol.next()[1]);
    *(void *)(v0 + 392) = v29;
    *uint64_t v29 = v0;
    v29[1] = specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:);
    return dispatch thunk of AsyncIteratorProtocol.next()(v27, v45, v28);
  }
  else
  {
    uint64_t v31 = *(void *)(v0 + 296);
    swift_bridgeObjectRetain(v31);
    return (*(uint64_t (**)(uint64_t))(v0 + 8))(v31);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t (*v4)();

  uint64_t v2 = *(void **)v1;
  swift_task_dealloc(*(void *)(*(void *)v1 + 392));
  uint64_t v3 = v2[37];
  if (v0)
  {
    v2[52] = v0;
    v2[51] = v3;
    uint64_t v4 = specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:);
  }
  else
  {
    v2[50] = v3;
    uint64_t v4 = specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:);
  }
  return swift_task_switch(v4, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;
  uint64_t v8;
  char isUniquelyReferenced_nonNull_native;
  void *v10;
  unint64_t v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  void (*v15)(uint64_t, uint64_t, uint64_t);

  uint64_t v1 = *(void *)(v0 + 376);
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>);
  if (__swift_getEnumTagSinglePayload(v1, 1, v2) == 1)
  {
    uint64_t v3 = *(void *)(v0 + 368);
    uint64_t v4 = *(void *)(v0 + 344);
    uint64_t v14 = *(void *)(v0 + 336);
    uint64_t v5 = *(void *)(v0 + 328);
    (*(void (**)(uint64_t, void))(*(void *)(v0 + 360) + 8))(v3, *(void *)(v0 + 352));
    (*(void (**)(uint64_t, uint64_t))(v14 + 8))(v4, v5);
    swift_release();
    swift_task_dealloc(v1);
    swift_task_dealloc(v3);
    swift_task_dealloc(v4);
    return (*(uint64_t (**)(void))(v0 + 8))(*(void *)(v0 + 400));
  }
  else
  {
    uint64_t v7 = *(void *)(v0 + 400);
    uint64_t v8 = *(void *)(v2 - 8);
    uint64_t v13 = swift_task_alloc((*(void *)(v8 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
    uint64_t v15 = *(void (**)(uint64_t, uint64_t, uint64_t))(v8 + 32);
    v15(v13, v1, v2);
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v7);
    uint64_t v10 = *(void **)(v0 + 400);
    if (!isUniquelyReferenced_nonNull_native) {
      uint64_t v10 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v10[2] + 1, 1, *(void *)(v0 + 400));
    }
    uint64_t v11 = v10[2];
    if (v10[3] >> 1 <= v11) {
      uint64_t v10 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v10[3] >= 2uLL, v11 + 1, 1, (uint64_t)v10);
    }
    *(void *)(v0 + 424) = v10;
    v10[2] = v11 + 1;
    v15((uint64_t)v10+ ((*(unsigned __int8 *)(v8 + 80) + 32) & ~*(unsigned __int8 *)(v8 + 80))+ *(void *)(v8 + 72) * v11, v13, v2);
    swift_task_dealloc(v13);
    uint64_t v12 = (void *)swift_task_alloc(async function pointer to dispatch thunk of AsyncIteratorProtocol.next()[1]);
    *(void *)(v0 + 432) = v12;
    *uint64_t v12 = v0;
    v12[1] = specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:);
    return dispatch thunk of AsyncIteratorProtocol.next()(*(void *)(v0 + 376), *(void *)(v0 + 352), *(void *)(v0 + 384));
  }
}

{
  void *v0;
  uint64_t v1;

  v0[36] = v0[52];
  if (_stdlib_isOSVersionAtLeastOrVariantVersionAtLeast(_:_:_:_:_:_:)(0xFuLL, 0, 0, 0x12uLL, 0, 0))
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    swift_willThrowTypedImpl(v0 + 36, v1, &protocol self-conformance witness table for Error);
  }
  swift_bridgeObjectRelease(v0[51]);
  return swift_task_switch(specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:), 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;

  uint64_t v6 = *(void *)(v0 + 376);
  uint64_t v1 = *(void *)(v0 + 368);
  uint64_t v2 = *(void *)(v0 + 344);
  uint64_t v3 = *(void *)(v0 + 336);
  uint64_t v7 = *(void *)(v0 + 320);
  uint64_t v4 = *(void *)(v0 + 328);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 360) + 8))(v1, *(void *)(v0 + 352));
  (*(void (**)(uint64_t, uint64_t))(v3 + 8))(v2, v4);
  swift_release(v7);
  swift_task_dealloc(v6);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t (*v4)();

  uint64_t v2 = *(void **)v1;
  swift_task_dealloc(*(void *)(*(void *)v1 + 432));
  uint64_t v3 = v2[53];
  if (v0)
  {
    v2[52] = v0;
    v2[51] = v3;
    uint64_t v4 = specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:);
  }
  else
  {
    v2[50] = v3;
    uint64_t v4 = specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:);
  }
  return swift_task_switch(v4, 0, 0);
}

void *specialized Collection.randomSplit<A, B>(strategy:)(uint64_t a1, uint64_t a2, __int16 a3, uint64_t a4)
{
  if ((a3 & 0x100) != 0)
  {
    unint64_t v6 = *(void *)(a4 + 16);
    if (v6 < 0x32)
    {
LABEL_7:
      swift_bridgeObjectRetain(a4);
      return _swiftEmptyArrayStorage;
    }
    double v5 = dbl_348EB0[v6 < 0xC8];
    uint64_t v4 = 1;
  }
  else
  {
    uint64_t v4 = 1;
    if ((a3 & 1) == 0) {
      uint64_t v4 = a2;
    }
    double v5 = *(double *)&a1;
    if (*(double *)&a1 == 0.0) {
      goto LABEL_7;
    }
  }
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  uint64_t v10 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>], (uint64_t)&protocol conformance descriptor for [A]);
  return (void *)Sequence.randomSplit<A, B>(by:seed:)(v4, 0, v8, v9, &type metadata for String, v10, v5, &protocol witness table for String, a4);
}

{
  uint64_t v4;
  double v5;
  unint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  if ((a3 & 0x100) != 0)
  {
    unint64_t v6 = *(void *)(a4 + 16);
    if (v6 < 0x32)
    {
LABEL_7:
      swift_bridgeObjectRetain(a4);
      return _swiftEmptyArrayStorage;
    }
    double v5 = dbl_348EB0[v6 < 0xC8];
    uint64_t v4 = 1;
  }
  else
  {
    uint64_t v4 = 1;
    if ((a3 & 1) == 0) {
      uint64_t v4 = a2;
    }
    double v5 = *(double *)&a1;
    if (*(double *)&a1 == 0.0) {
      goto LABEL_7;
    }
  }
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<URL, String>]);
  uint64_t v9 = type metadata accessor for URL(0);
  uint64_t v10 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<URL, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<URL, String>], (uint64_t)&protocol conformance descriptor for [A]);
  return (void *)Sequence.randomSplit<A, B>(by:seed:)(v4, 0, v8, v9, &type metadata for String, v10, v5, &protocol witness table for String, a4);
}

uint64_t specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:)(uint64_t a1)
{
  *(void *)(v2 + 24) = v1;
  *(void *)(v2 + 16) = a1;
  return swift_task_switch(specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:), 0, 0);
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  uint64_t (*v6)();

  double v5 = *(void *)(*v2 + 32);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 40) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    unint64_t v6 = specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:);
  }
  else
  {
    *(void *)(v4 + 48) = a1;
    unint64_t v6 = specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:);
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:)()
{
  uint64_t v1 = *(void **)(v0 + 24);
  uint64_t v2 = v1[3];
  __swift_project_boxed_opaque_existential_0Tm(v1, v2);
  uint64_t v3 = (void *)swift_task_alloc(async function pointer to Transformer.applied<A, B>(to:eventHandler:)[1]);
  *(void *)(v0 + 32) = v3;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<CIImage, String>]);
  double v5 = (void *)lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<CIImage, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<CIImage, String>], (uint64_t)&protocol conformance descriptor for [A]);
  void *v3 = v0;
  v3[1] = specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:);
  retaddr = v5;
  return Transformer.applied<A, B>(to:eventHandler:)(v0 + 16, 0, 0, v2, v4, &type metadata for String);
}

{
  uint64_t v0;

  return (*(uint64_t (**)(void))(v0 + 8))(*(void *)(v0 + 48));
}

{
  uint64_t v0;

  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t specialized Transformer.applied<A, B>(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v7[12] = v6;
  v7[11] = a6;
  v7[10] = a5;
  v7[9] = a4;
  v7[8] = a3;
  v7[7] = a2;
  v7[6] = a1;
  uint64_t v8 = type metadata accessor for ImageReader(0);
  v7[13] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v7[14] = v9;
  v7[15] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = type metadata accessor for Event(0, a2, v10);
  v7[16] = v11;
  uint64_t v12 = *(void *)(v11 - 8);
  v7[17] = v12;
  v7[18] = swift_task_alloc((*(void *)(v12 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>);
  v7[19] = v13;
  uint64_t v14 = *(void *)(v13 - 8);
  v7[20] = v14;
  v7[21] = swift_task_alloc((*(void *)(v14 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v15 = type metadata accessor for URL(0);
  v7[22] = v15;
  uint64_t v16 = *(void *)(v15 - 8);
  v7[23] = v16;
  unsigned char v7[24] = swift_task_alloc((*(void *)(v16 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  v7[25] = v17;
  uint64_t v18 = *(void *)(v17 - 8);
  v7[26] = v18;
  v7[27] = swift_task_alloc((*(void *)(v18 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized Transformer.applied<A, B>(to:eventHandler:), 0, 0);
}

uint64_t specialized Transformer.applied<A, B>(to:eventHandler:)()
{
  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 72) >> 1;
  int64_t v3 = v2 - v1;
  *(void *)(v0 + 224) = v2 - v1;
  if (__OFSUB__(v2, v1)) {
    BUG();
  }
  if (v3 <= 0) {
    int64_t v3 = 0;
  }
  uint64_t v4 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3, 0, (uint64_t)_swiftEmptyArrayStorage);
  if (v2 == v1)
  {
    uint64_t v5 = *(void *)(v0 + 192);
    uint64_t v6 = *(void *)(v0 + 168);
    uint64_t v15 = v4;
    uint64_t v7 = *(void *)(v0 + 120);
    uint64_t v8 = *(void *)(v0 + 144);
    swift_task_dealloc(*(void *)(v0 + 216));
    swift_task_dealloc(v5);
    swift_task_dealloc(v6);
    swift_task_dealloc(v8);
    swift_task_dealloc(v7);
    return (*(uint64_t (**)(void *))(v0 + 8))(v15);
  }
  else
  {
    uint64_t v9 = *(void *)(v0 + 208);
    uint64_t v10 = *(void *)(v0 + 48);
    uint64_t v11 = *(void *)(v0 + 64);
    *(void *)(v0 + 240) = v4;
    *(void *)(v0 + 232) = v11;
    uint64_t v12 = *(void *)(v0 + 72) >> 1;
    swift_unknownObjectRetain(v10);
    if (v11 >= v12) {
      BUG();
    }
    (*(void (**)(void, uint64_t, void))(v9 + 16))(*(void *)(v0 + 216), *(void *)(v0 + 56) + *(void *)(v9 + 72) * v11, *(void *)(v0 + 200));
    static Task<>.checkCancellation()();
    AnnotatedFeature.feature.getter(*(void *)(v0 + 200));
    uint64_t v14 = (void *)swift_task_alloc(async function pointer to dispatch thunk of Transformer.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 248) = v14;
    *uint64_t v14 = v0;
    v14[1] = specialized Transformer.applied<A, B>(to:eventHandler:);
    return dispatch thunk of Transformer.applied(to:eventHandler:)(v0 + 32, *(void *)(v0 + 192), *(void *)(v0 + 80), *(void *)(v0 + 88), *(void *)(v0 + 104), &protocol witness table for ImageReader);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t (*v5)();

  int64_t v3 = *(void *)(*(void *)v1 + 248);
  uint64_t v2 = *(void **)v1;
  *(void *)(*(void *)v1 + 256) = v0;
  swift_task_dealloc(v3);
  if (v0)
  {
    uint64_t v4 = v2[30];
    (*(void (**)(void, void))(v2[23] + 8))(v2[24], v2[22]);
    swift_bridgeObjectRelease(v4);
    uint64_t v5 = specialized Transformer.applied<A, B>(to:eventHandler:);
  }
  else
  {
    (*(void (**)(void, void))(v2[23] + 8))(v2[24], v2[22]);
    uint64_t v5 = specialized Transformer.applied<A, B>(to:eventHandler:);
  }
  return swift_task_switch(v5, 0, 0);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  unint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  char *v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  void *v21;
  uint64_t v22;
  uint64_t v23;
  unint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void *);
  void *v31;
  uint64_t v32;
  unint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  void *v40;
  uint64_t v41;
  void (*v42)(uint64_t);
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;
  id v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  void *v51;
  void *v52;

  uint64_t v1 = v0[30];
  uint64_t v2 = v0[25];
  int64_t v3 = (void *)v0[4];
  v0[5] = v3;
  uint64_t v47 = v3;
  AnnotatedFeature.annotation.getter(v2);
  uint64_t v4 = type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for CIImage, CIImage_ptr);
  AnnotatedFeature.init(feature:annotation:)(v0 + 5, v0 + 2, v4, &type metadata for String);
  uint64_t v5 = *(void *)(v1 + 16);
  uint64_t v6 = (void *)v0[30];
  if (*(void *)(v1 + 24) >> 1 <= v5) {
    uint64_t v6 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*(void *)(v1 + 24) >= 2uLL, v5 + 1, 1, v0[30]);
  }
  uint64_t v7 = v0[21];
  uint64_t v8 = v0[19];
  uint64_t v9 = v0[20];
  uint64_t v10 = v0[10];
  void v6[2] = v5 + 1;
  uint64_t v11 = (char *)v6 + ((*(unsigned __int8 *)(v9 + 80) + 32) & ~*(unsigned __int8 *)(v9 + 80)) + *(void *)(v9 + 72) * v5;
  uint64_t v12 = v6;
  (*(void (**)(char *, uint64_t, uint64_t))(v9 + 32))(v11, v7, v8);
  uint64_t v51 = v12;
  if (v10)
  {
    uint64_t v41 = v0[28];
    uint64_t v43 = v0[18];
    char v49 = v0[17];
    uint64_t v48 = v0[16];
    uint64_t v13 = v0[15];
    uint64_t v14 = v0[13];
    uint64_t v42 = (void (*)(uint64_t))v0[10];
    uint64_t v15 = v0[11];
    (*(void (**)(uint64_t, void, uint64_t))(v0[14] + 16))(v13, v0[12], v14);
    swift_retain();
    uint64_t v44 = String.init<A>(describing:)(v13, v14);
    uint64_t v45 = v16;
    uint64_t v46 = v12[2];
    uint64_t v17 = type metadata accessor for MetricsKey(0);
    uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    uint64_t v19 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, (uint64_t (*)(uint64_t))&type metadata accessor for MetricsKey, (uint64_t)&protocol conformance descriptor for MetricsKey);
    uint64_t v20 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, v17, v18, v19);
    Event.init(origin:itemCount:totalItemCount:metrics:)(v44, v45, v46, v41, 0, v20);
    v42(v43);
    _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v42, v15);
    (*(void (**)(uint64_t, uint64_t))(v49 + 8))(v43, v48);
    uint64_t v21 = (void *)v0[4];
  }
  else
  {
    uint64_t v21 = v47;
  }
  uint64_t v22 = v0[29];
  uint64_t v23 = v0[27];
  uint64_t v50 = v0[26];
  uint64_t v24 = v0[9];
  uint64_t v25 = v0[25];

  (*(void (**)(uint64_t, uint64_t))(v50 + 8))(v23, v25);
  if (v22 + 1 == v24 >> 1)
  {
    swift_unknownObjectRelease(v0[6]);
    uint64_t v26 = v0[24];
    uint64_t v27 = v0[21];
    uint64_t v28 = v0[15];
    uint64_t v29 = v0[18];
    swift_task_dealloc(v0[27]);
    swift_task_dealloc(v26);
    swift_task_dealloc(v27);
    swift_task_dealloc(v29);
    swift_task_dealloc(v28);
    long long v30 = (uint64_t (*)(void *))v0[1];
    uint64_t v31 = v51;
    return v30(v31);
  }
  uint64_t v32 = v0[32];
  uint64_t v33 = v0[9];
  uint64_t v34 = v0[29] + 1;
  v0[30] = v51;
  v0[29] = v34;
  if (v34 >= (uint64_t)(v33 >> 1)) {
    BUG();
  }
  (*(void (**)(void, uint64_t, void))(v0[26] + 16))(v0[27], v0[7] + *(void *)(v0[26] + 72) * v34, v0[25]);
  static Task<>.checkCancellation()();
  if (v32)
  {
    uint64_t v35 = v0[6];
    (*(void (**)(void, void))(v0[26] + 8))(v0[27], v0[25]);
    swift_unknownObjectRelease(v35);
    swift_bridgeObjectRelease((_BYTE)v51);
    uint64_t v36 = v0[24];
    uint64_t v37 = v0[21];
    unint64_t v52 = (void *)v0[15];
    uint64_t v38 = v0[18];
    swift_task_dealloc(v0[27]);
    swift_task_dealloc(v36);
    swift_task_dealloc(v37);
    swift_task_dealloc(v38);
    uint64_t v31 = v52;
    swift_task_dealloc(v52);
    long long v30 = (uint64_t (*)(void *))v0[1];
    return v30(v31);
  }
  AnnotatedFeature.feature.getter(v0[25]);
  uint64_t v40 = (void *)swift_task_alloc(async function pointer to dispatch thunk of Transformer.applied(to:eventHandler:)[1]);
  v0[31] = v40;
  long long *v40 = v0;
  v40[1] = specialized Transformer.applied<A, B>(to:eventHandler:);
  return dispatch thunk of Transformer.applied(to:eventHandler:)(v0 + 4, v0[24], v0[10], v0[11], v0[13], &protocol witness table for ImageReader);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;

  uint64_t v1 = *(void *)(v0 + 48);
  (*(void (**)(void, void))(*(void *)(v0 + 208) + 8))(*(void *)(v0 + 216), *(void *)(v0 + 200));
  swift_unknownObjectRelease(v1);
  uint64_t v2 = *(void *)(v0 + 192);
  int64_t v3 = *(void *)(v0 + 168);
  uint64_t v4 = *(void *)(v0 + 120);
  uint64_t v5 = *(void *)(v0 + 144);
  swift_task_dealloc(*(void *)(v0 + 216));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v5);
  swift_task_dealloc(v4);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  int64_t v1;
  void *v2;
  uint64_t v3;
  int v4;
  void (*v5)(uint64_t, uint64_t, uint64_t);
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  void *v13;
  uint64_t v15;

  uint64_t v1 = *(void *)(*(void *)(v0 + 48) + 16);
  *(void *)(v0 + 200) = v1;
  uint64_t v2 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0, (uint64_t)_swiftEmptyArrayStorage);
  if (v1)
  {
    int64_t v3 = *(void *)(v0 + 184);
    uint64_t v4 = *(_DWORD *)(v3 + 80);
    *(_DWORD *)(v0 + 256) = v4;
    uint64_t v5 = *(void (**)(uint64_t, uint64_t, uint64_t))(v3 + 16);
    *(void *)(v0 + 208) = *(void *)(v3 + 72);
    *(void *)(v0 + 216) = v5;
    *(void *)(v0 + 232) = v2;
    *(void *)(v0 + 224) = 0;
    uint64_t v6 = *(void *)(v0 + 192);
    uint64_t v7 = *(void *)(v0 + 48);
    uint64_t v8 = *(void *)(v0 + 176);
    uint64_t v9 = v7 + ((v4 + 32) & ~v4);
    swift_bridgeObjectRetain(v7);
    v5(v6, v9, v8);
    static Task<>.checkCancellation()();
    AnnotatedFeature.feature.getter(*(void *)(v0 + 176));
    uint64_t v13 = (void *)swift_task_alloc(async function pointer to dispatch thunk of Transformer.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 240) = v13;
    *uint64_t v13 = v0;
    v13[1] = specialized Transformer.applied<A, B>(to:eventHandler:);
    return dispatch thunk of Transformer.applied(to:eventHandler:)(v0 + 32, *(void *)(v0 + 168), *(void *)(v0 + 56), *(void *)(v0 + 64), *(void *)(v0 + 80), &protocol witness table for ImageReader);
  }
  else
  {
    uint64_t v10 = *(void *)(v0 + 168);
    uint64_t v11 = *(void *)(v0 + 144);
    uint64_t v15 = *(void *)(v0 + 96);
    uint64_t v12 = *(void *)(v0 + 120);
    swift_task_dealloc(*(void *)(v0 + 192));
    swift_task_dealloc(v10);
    swift_task_dealloc(v11);
    swift_task_dealloc(v12);
    swift_task_dealloc(v15);
    return (*(uint64_t (**)(void))(v0 + 8))();
  }
}

{
  uint64_t v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t (*v5)();

  int64_t v3 = *(void *)(*(void *)v1 + 240);
  uint64_t v2 = *(void **)v1;
  *(void *)(*(void *)v1 + 248) = v0;
  swift_task_dealloc(v3);
  if (v0)
  {
    uint64_t v4 = v2[29];
    (*(void (**)(void, void))(v2[20] + 8))(v2[21], v2[19]);
    swift_bridgeObjectRelease(v4);
    uint64_t v5 = specialized Transformer.applied<A, B>(to:eventHandler:);
  }
  else
  {
    (*(void (**)(void, void))(v2[20] + 8))(v2[21], v2[19]);
    uint64_t v5 = specialized Transformer.applied<A, B>(to:eventHandler:);
  }
  return swift_task_switch(v5, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  unint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  char *v11;
  void *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  void *v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t (*v30)(void *);
  void *v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  void *v39;
  uint64_t v40;
  void (*v41)(uint64_t);
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  id v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  void *v50;
  void *v51;

  uint64_t v1 = *(void *)(v0 + 232);
  uint64_t v2 = *(void *)(v0 + 176);
  int64_t v3 = *(void **)(v0 + 32);
  *(void *)(v0 + 40) = v3;
  uint64_t v46 = v3;
  AnnotatedFeature.annotation.getter(v2);
  uint64_t v4 = type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for CIImage, CIImage_ptr);
  AnnotatedFeature.init(feature:annotation:)(v0 + 40, v0 + 16, v4, &type metadata for String);
  uint64_t v5 = *(void *)(v1 + 16);
  uint64_t v6 = *(void **)(v0 + 232);
  if (*(void *)(v1 + 24) >> 1 <= v5) {
    uint64_t v6 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*(void *)(v1 + 24) >= 2uLL, v5 + 1, 1, *(void *)(v0 + 232));
  }
  uint64_t v7 = *(void *)(v0 + 144);
  uint64_t v8 = *(void *)(v0 + 128);
  uint64_t v9 = *(void *)(v0 + 136);
  uint64_t v10 = *(void *)(v0 + 56);
  void v6[2] = v5 + 1;
  uint64_t v11 = (char *)v6 + ((*(unsigned __int8 *)(v9 + 80) + 32) & ~*(unsigned __int8 *)(v9 + 80)) + *(void *)(v9 + 72) * v5;
  uint64_t v12 = v6;
  (*(void (**)(char *, uint64_t, uint64_t))(v9 + 32))(v11, v7, v8);
  uint64_t v50 = v12;
  if (v10)
  {
    uint64_t v40 = *(void *)(v0 + 200);
    uint64_t v42 = *(void *)(v0 + 120);
    uint64_t v48 = *(void *)(v0 + 112);
    uint64_t v47 = *(void *)(v0 + 104);
    uint64_t v13 = *(void *)(v0 + 96);
    uint64_t v14 = *(void *)(v0 + 80);
    uint64_t v41 = *(void (**)(uint64_t))(v0 + 56);
    uint64_t v15 = *(void *)(v0 + 64);
    (*(void (**)(uint64_t, void, uint64_t))(*(void *)(v0 + 88) + 16))(v13, *(void *)(v0 + 72), v14);
    swift_retain();
    uint64_t v43 = String.init<A>(describing:)(v13, v14);
    uint64_t v44 = v16;
    uint64_t v45 = v12[2];
    uint64_t v17 = type metadata accessor for MetricsKey(0);
    uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    uint64_t v19 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, (uint64_t (*)(uint64_t))&type metadata accessor for MetricsKey, (uint64_t)&protocol conformance descriptor for MetricsKey);
    uint64_t v20 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, v17, v18, v19);
    Event.init(origin:itemCount:totalItemCount:metrics:)(v43, v44, v45, v40, 0, v20);
    v41(v42);
    _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v41, v15);
    (*(void (**)(uint64_t, uint64_t))(v48 + 8))(v42, v47);
    uint64_t v21 = *(void **)(v0 + 32);
  }
  else
  {
    uint64_t v21 = v46;
  }
  uint64_t v22 = *(void *)(v0 + 224);
  uint64_t v23 = *(void *)(v0 + 192);
  uint64_t v24 = *(void *)(v0 + 176);
  uint64_t v25 = *(void *)(v0 + 184);
  char v49 = *(void *)(v0 + 200);

  (*(void (**)(uint64_t, uint64_t))(v25 + 8))(v23, v24);
  if (v22 + 1 == v49)
  {
    swift_bridgeObjectRelease(*(void *)(v0 + 48));
    uint64_t v26 = *(void *)(v0 + 168);
    uint64_t v27 = *(void *)(v0 + 144);
    uint64_t v28 = *(void *)(v0 + 96);
    uint64_t v29 = *(void *)(v0 + 120);
    swift_task_dealloc(*(void *)(v0 + 192));
    swift_task_dealloc(v26);
    swift_task_dealloc(v27);
    swift_task_dealloc(v29);
    swift_task_dealloc(v28);
    long long v30 = *(uint64_t (**)(void *))(v0 + 8);
    uint64_t v31 = v50;
    return v30(v31);
  }
  uint64_t v32 = *(void *)(v0 + 248);
  uint64_t v33 = *(void *)(v0 + 224) + 1;
  *(void *)(v0 + 232) = v50;
  *(void *)(v0 + 224) = v33;
  (*(void (**)(void, uint64_t, void))(v0 + 216))(*(void *)(v0 + 192), *(void *)(v0 + 48)+ ((*(unsigned __int8 *)(v0 + 256) + 32) & ~*(unsigned __int8 *)(v0 + 256))+ *(void *)(v0 + 208) * v33, *(void *)(v0 + 176));
  static Task<>.checkCancellation()();
  if (v32)
  {
    uint64_t v34 = *(void *)(v0 + 48);
    (*(void (**)(void, void))(*(void *)(v0 + 184) + 8))(*(void *)(v0 + 192), *(void *)(v0 + 176));
    swift_bridgeObjectRelease(v34);
    swift_bridgeObjectRelease((_BYTE)v50);
    uint64_t v35 = *(void *)(v0 + 168);
    uint64_t v36 = *(void *)(v0 + 144);
    uint64_t v51 = *(void **)(v0 + 96);
    uint64_t v37 = *(void *)(v0 + 120);
    swift_task_dealloc(*(void *)(v0 + 192));
    swift_task_dealloc(v35);
    swift_task_dealloc(v36);
    swift_task_dealloc(v37);
    uint64_t v31 = v51;
    swift_task_dealloc(v51);
    long long v30 = *(uint64_t (**)(void *))(v0 + 8);
    return v30(v31);
  }
  AnnotatedFeature.feature.getter(*(void *)(v0 + 176));
  uint64_t v39 = (void *)swift_task_alloc(async function pointer to dispatch thunk of Transformer.applied(to:eventHandler:)[1]);
  *(void *)(v0 + 240) = v39;
  int *v39 = v0;
  v39[1] = specialized Transformer.applied<A, B>(to:eventHandler:);
  return dispatch thunk of Transformer.applied(to:eventHandler:)(v0 + 32, *(void *)(v0 + 168), *(void *)(v0 + 56), *(void *)(v0 + 64), *(void *)(v0 + 80), &protocol witness table for ImageReader);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;

  uint64_t v1 = *(void *)(v0 + 48);
  (*(void (**)(void, void))(*(void *)(v0 + 184) + 8))(*(void *)(v0 + 192), *(void *)(v0 + 176));
  swift_bridgeObjectRelease(v1);
  uint64_t v2 = *(void *)(v0 + 168);
  int64_t v3 = *(void *)(v0 + 144);
  uint64_t v4 = *(void *)(v0 + 96);
  uint64_t v5 = *(void *)(v0 + 120);
  swift_task_dealloc(*(void *)(v0 + 192));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v5);
  swift_task_dealloc(v4);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t specialized Transformer.applied<A, B>(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v4[9] = v3;
  v4[8] = a3;
  v4[7] = a2;
  v4[6] = a1;
  uint64_t v5 = type metadata accessor for ImageReader(0);
  v4[10] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v4[11] = v6;
  v4[12] = swift_task_alloc((*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for Event(0, a2, v7);
  v4[13] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v4[14] = v9;
  v4[15] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>);
  v4[16] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v4[17] = v11;
  v4[18] = swift_task_alloc((*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = type metadata accessor for URL(0);
  v4[19] = v12;
  uint64_t v13 = *(void *)(v12 - 8);
  v4[20] = v13;
  v4[21] = swift_task_alloc((*(void *)(v13 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  v4[22] = v14;
  uint64_t v15 = *(void *)(v14 - 8);
  v4[23] = v15;
  v4[24] = swift_task_alloc((*(void *)(v15 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized Transformer.applied<A, B>(to:eventHandler:), 0, 0);
}

uint64_t ImageClassifierTrainingSessionDelegate.init(sessionParameters:)(uint64_t a1)
{
  uint64_t v2 = v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters;
  uint64_t v3 = type metadata accessor for MLImageClassifier.PersistentParameters(0);
  __swift_storeEnumTagSinglePayload(v2, 1, 1, v3);
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFiles) = _swiftEmptyArrayStorage;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFiles) = _swiftEmptyArrayStorage;
  uint64_t v4 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore;
  BlobsFile.init()();
  *(_OWORD *)(v1 + v4) = v21;
  *(void *)(v1 + v4 + 16) = v22;
  *(_OWORD *)(v1 + v4 + 24) = v23;
  *(_OWORD *)(v1 + v4 + 40) = v24;
  *(_OWORD *)(v1 + v4 + 56) = v25;
  *(_OWORD *)(v1 + v4 + 72) = v26;
  *(void *)(v1 + v4 + 88) = _swiftEmptyArrayStorage;
  uint64_t v5 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore;
  BlobsFile.init()();
  *(_OWORD *)(v1 + v5) = v15;
  *(void *)(v1 + v5 + 16) = v16;
  *(_OWORD *)(v1 + v5 + 24) = v17;
  *(_OWORD *)(v1 + v5 + 40) = v18;
  *(_OWORD *)(v1 + v5 + 56) = v19;
  *(_OWORD *)(v1 + v5 + 72) = v20;
  *(void *)(v1 + v5 + 88) = _swiftEmptyArrayStorage;
  uint64_t v6 = v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier;
  uint64_t v7 = type metadata accessor for MLImageClassifier.Classifier(0);
  __swift_storeEnumTagSinglePayload(v6, 1, 1, v7);
  uint64_t v8 = v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model;
  uint64_t v9 = type metadata accessor for MLImageClassifier.Model(0);
  __swift_storeEnumTagSinglePayload(v8, 1, 1, v9);
  uint64_t v10 = v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingMetrics;
  uint64_t v11 = type metadata accessor for MLClassifierMetrics(0);
  __swift_storeEnumTagSinglePayload(v10, 1, 1, v11);
  __swift_storeEnumTagSinglePayload(v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationMetrics, 1, 1, v11);
  uint64_t v12 = v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_tablePrinter;
  uint64_t v13 = type metadata accessor for TrainingTablePrinter(0);
  __swift_storeEnumTagSinglePayload(v12, 1, 1, v13);
  outlined init with take of MLClassifierMetrics(a1, v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  return v1;
}

uint64_t ImageClassifierTrainingSessionDelegate.init(filesByLabel:modelParameters:sessionParameters:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v37 = a3;
  uint64_t v41 = a2;
  uint64_t v38 = a1;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v40 = &v24;
  uint64_t v7 = v3 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters;
  uint64_t v39 = v3 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters;
  uint64_t v42 = type metadata accessor for MLImageClassifier.PersistentParameters(0);
  __swift_storeEnumTagSinglePayload(v7, 1, 1, v42);
  *(void *)(v3 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFiles) = _swiftEmptyArrayStorage;
  *(void *)(v3 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFiles) = _swiftEmptyArrayStorage;
  uint64_t v8 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore;
  BlobsFile.init()();
  long long v9 = v35;
  *(_OWORD *)(v3 + v8) = v30;
  *(void *)(v3 + v8 + 16) = v31;
  *(_OWORD *)(v3 + v8 + 24) = v32;
  *(_OWORD *)(v3 + v8 + 40) = v33;
  *(_OWORD *)(v3 + v8 + 56) = v34;
  *(_OWORD *)(v3 + v8 + 72) = v9;
  *(void *)(v3 + v8 + 88) = _swiftEmptyArrayStorage;
  uint64_t v10 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore;
  BlobsFile.init()();
  long long v11 = v29;
  *(_OWORD *)(v3 + v10) = v24;
  *(void *)(v3 + v10 + 16) = v25;
  *(_OWORD *)(v3 + v10 + 24) = v26;
  *(_OWORD *)(v3 + v10 + 40) = v27;
  *(_OWORD *)(v3 + v10 + 56) = v28;
  *(_OWORD *)(v3 + v10 + 72) = v11;
  *(void *)(v3 + v10 + 88) = _swiftEmptyArrayStorage;
  uint64_t v12 = v3 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier;
  uint64_t v13 = type metadata accessor for MLImageClassifier.Classifier(0);
  __swift_storeEnumTagSinglePayload(v12, 1, 1, v13);
  uint64_t v14 = v3 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model;
  uint64_t v15 = type metadata accessor for MLImageClassifier.Model(0);
  __swift_storeEnumTagSinglePayload(v14, 1, 1, v15);
  uint64_t v16 = v3 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingMetrics;
  uint64_t v17 = type metadata accessor for MLClassifierMetrics(0);
  __swift_storeEnumTagSinglePayload(v16, 1, 1, v17);
  __swift_storeEnumTagSinglePayload(v3 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationMetrics, 1, 1, v17);
  uint64_t v18 = v3 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_tablePrinter;
  uint64_t v19 = type metadata accessor for TrainingTablePrinter(0);
  __swift_storeEnumTagSinglePayload(v18, 1, 1, v19);
  uint64_t v20 = v41;
  outlined init with copy of MLImageClassifier.ModelParameters(v41, (uint64_t)v36);
  uint64_t v21 = (uint64_t)v40;
  MLImageClassifier.PersistentParameters.init(trainingData:modelParameters:)(v38, v36);
  outlined destroy of MLImageClassifier.ModelParameters(v20);
  __swift_storeEnumTagSinglePayload(v21, 0, 1, v42);
  uint64_t v22 = v39;
  swift_beginAccess(v39, v36, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v21, v22, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  swift_endAccess(v36);
  outlined init with take of MLClassifierMetrics(v37, v3 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  return v3;
}

Swift::OpaquePointer ImageClassifierTrainingSessionDelegate.populateFiles(parameters:)(Swift::OpaquePointer *a1)
{
  uint64_t v2 = v1;
  type metadata accessor for MLImageClassifier.PersistentParameters(0);
  Swift::tuple_training_OpaquePointer_validation_OpaquePointer v3 = MLImageClassifier.ModelParameters.ValidationData.extractFilesByLabel(trainingFiles:)((Swift::OpaquePointer)a1->_rawValue);
  if (!v4)
  {
    char rawValue = (char)v3.training._rawValue;
    uint64_t v6 = v3.validation._rawValue;
    uint64_t v7 = specialized Sequence.flatMap<A>(_:)((uint64_t)v3.training._rawValue);
    swift_bridgeObjectRelease(rawValue);
    uint64_t v8 = *(void *)(v2 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFiles);
    *(void *)(v2 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFiles) = v7;
    swift_bridgeObjectRelease(v8);
    long long v9 = specialized Sequence.flatMap<A>(_:)((uint64_t)v6);
    swift_bridgeObjectRelease((_BYTE)v6);
    uint64_t v10 = *(void *)(v2 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFiles);
    *(void *)(v2 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFiles) = v9;
    v3.training._char rawValue = (void *)swift_bridgeObjectRelease(v10);
  }
  return v3.training;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> ImageClassifierTrainingSessionDelegate.setUp()()
{
  uint64_t v95 = v0;
  uint64_t v2 = v1;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.Model?)
                             - 8)
                 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v88 = &v60;
  uint64_t v82 = type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0);
  int64_t v6 = *(void *)(*(void *)(v82 - 8) + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v83 = &v60;
  long long v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  uint64_t v91 = &v60;
  uint64_t v85 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  int64_t v11 = *(void *)(*(void *)(v85 - 8) + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v86 = &v60;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  uint64_t v93 = &v60;
  int64_t v16 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.Classifier?)
                              - 8)
                  + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v81 = &v60;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v84 = &v60;
  int64_t v21 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  uint64_t v22 = alloca(v21);
  long long v23 = alloca(v21);
  uint64_t v24 = type metadata accessor for MLImageClassifier.PersistentParameters(0);
  int64_t v25 = *(void *)(*(void *)(v24 - 8) + 64);
  long long v26 = alloca(v25);
  long long v27 = alloca(v25);
  uint64_t v94 = (Swift::OpaquePointer *)&v60;
  uint64_t v28 = v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters, v72, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v28, (uint64_t)&v60, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  uint64_t v87 = (int *)v24;
  if (__swift_getEnumTagSinglePayload((uint64_t)&v60, 1, v24) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v60, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000002CLL, "SessionDelegate.swift" + 0x8000000000000000, "CreateML/ImageClassifierTrainingSessionDelegate.swift", 53, 2, 68, 0);
    BUG();
  }
  long long v29 = v94;
  outlined init with take of MLClassifierMetrics((uint64_t)&v60, (uint64_t)v94, type metadata accessor for MLImageClassifier.PersistentParameters);
  uint64_t v30 = v95;
  ImageClassifierTrainingSessionDelegate.populateFiles(parameters:)(v29);
  if (v30)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v94, type metadata accessor for MLImageClassifier.PersistentParameters);
  }
  else
  {
    BlobsFile.init()();
    long long v92 = v71;
    uint64_t v95 = 0;
    uint64_t v31 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore;
    swift_beginAccess(v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore, v73, 1, 0);
    uint64_t v32 = *(void *)(v1 + v31);
    unint64_t v33 = *(void *)(v1 + v31 + 8);
    uint64_t v96 = *(void *)(v1 + v31 + 80);
    uint64_t v34 = *(void *)(v1 + v31 + 88);
    *(_OWORD *)(v2 + v31) = v66;
    *(void *)(v2 + v31 + 16) = v67;
    *(_OWORD *)(v2 + v31 + 24) = v68;
    *(_OWORD *)(v2 + v31 + 40) = v69;
    *(_OWORD *)(v2 + v31 + 56) = v70;
    *(_OWORD *)(v2 + v31 + 72) = v92;
    *(void *)(v2 + v31 + 88) = _swiftEmptyArrayStorage;
    outlined consume of Data._Representation(v32, v33);
    swift_bridgeObjectRelease(v34);
    swift_bridgeObjectRelease(v96);
    BlobsFile.init()();
    long long v92 = v65;
    uint64_t v35 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore;
    swift_beginAccess(v2 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore, v74, 1, 0);
    uint64_t v36 = *(void *)(v2 + v35);
    unint64_t v37 = *(void *)(v2 + v35 + 8);
    uint64_t v96 = *(void *)(v2 + v35 + 80);
    uint64_t v38 = *(void *)(v2 + v35 + 88);
    *(_OWORD *)(v2 + v35) = v60;
    *(void *)(v2 + v35 + 16) = v61;
    *(_OWORD *)(v2 + v35 + 24) = v62;
    *(_OWORD *)(v2 + v35 + 40) = v63;
    *(_OWORD *)(v2 + v35 + 56) = v64;
    *(_OWORD *)(v2 + v35 + 72) = v92;
    *(void *)(v2 + v35 + 88) = _swiftEmptyArrayStorage;
    outlined consume of Data._Representation(v36, v37);
    swift_bridgeObjectRelease(v38);
    swift_bridgeObjectRelease(v96);
    uint64_t v39 = *(void *)(v2 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFiles);
    swift_bridgeObjectRetain(v39);
    uint64_t v40 = v95;
    MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v39, (uint64_t)v78, &demangling cache variable for type metadata for AnnotatedFeature<URL, String>, (uint64_t)&unk_352308);
    uint64_t v95 = v40;
    swift_bridgeObjectRelease(v39);
    *(void *)&long long v92 = specialized Set.init<A>(_:)((uint64_t)MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm);
    uint64_t v42 = v87;
    uint64_t v43 = (uint64_t)v94;
    outlined init with copy of MLTrainingSessionParameters((uint64_t)v94 + v87[5], (uint64_t)v93, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
    uint64_t v96 = *(void *)(v43 + v42[8]);
    uint64_t v89 = *(void *)(v43 + v42[9]);
    uint64_t v90 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType))
                 + 48);
    uint64_t v44 = (uint64_t)v91;
    outlined init with copy of MLTrainingSessionParameters(v43 + v42[6], (uint64_t)v91, type metadata accessor for MLImageClassifier.FeatureExtractorType);
    uint64_t v45 = *(void *)(v43 + v42[7]);
    uint64_t v46 = v45;
    if (v45 == 2) {
      uint64_t v46 = 0;
    }
    *(void *)(v44 + v90) = v46;
    memset(v77, 0, sizeof(v77));
    memset(v76, 0, sizeof(v76));
    v75[0] = v96;
    v75[1] = v89;
    uint64_t v47 = (uint64_t)v86;
    outlined init with copy of MLTrainingSessionParameters((uint64_t)v93, (uint64_t)v86, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
    uint64_t v80 = v85;
    boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v79);
    outlined init with take of MLClassifierMetrics(v47, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
    outlined copy of MLImageClassifier.ModelParameters.ClassifierType?(v45);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v79, (uint64_t)v76, &demangling cache variable for type metadata for Any?);
    uint64_t v49 = (uint64_t)v91;
    uint64_t v50 = (uint64_t)v83;
    outlined init with copy of MLTrainingSessionParameters((uint64_t)v91, (uint64_t)v83, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
    uint64_t v80 = v82;
    uint64_t v51 = __swift_allocate_boxed_opaque_existential_1(v79);
    outlined init with take of MLClassifierMetrics(v50, (uint64_t)v51, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v79, (uint64_t)v77, &demangling cache variable for type metadata for Any?);
    outlined destroy of MLActivityClassifier.ModelParameters(v49, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v93, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
    uint64_t v52 = (uint64_t)v84;
    MLImageClassifier.Classifier.init(labels:parameters:)(v92, v75);
    uint64_t v53 = type metadata accessor for MLImageClassifier.Classifier(0);
    __swift_storeEnumTagSinglePayload(v52, 0, 1, v53);
    uint64_t v54 = v2 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier;
    swift_beginAccess(v2 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier, v75, 33, 0);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v52, v54, &demangling cache variable for type metadata for MLImageClassifier.Classifier?);
    swift_endAccess(v75);
    uint64_t v55 = v54;
    uint64_t v56 = (uint64_t)v81;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v55, (uint64_t)v81, &demangling cache variable for type metadata for MLImageClassifier.Classifier?);
    if (__swift_getEnumTagSinglePayload(v56, 1, v53) == 1) {
      BUG();
    }
    uint64_t v57 = (uint64_t)v88;
    MLImageClassifier.Classifier.makeTransformer()();
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v94, type metadata accessor for MLImageClassifier.PersistentParameters);
    outlined destroy of MLActivityClassifier.ModelParameters(v56, type metadata accessor for MLImageClassifier.Classifier);
    uint64_t v58 = type metadata accessor for MLImageClassifier.Model(0);
    __swift_storeEnumTagSinglePayload(v57, 0, 1, v58);
    uint64_t v59 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model + v2;
    swift_beginAccess(v59, v75, 33, 0);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v57, v59, &demangling cache variable for type metadata for MLImageClassifier.Model?);
    swift_endAccess(v75);
  }
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> ImageClassifierTrainingSessionDelegate.resume(from:)(Swift::OpaquePointer from)
{
  uint64_t v158 = v1;
  uint64_t v184 = v2;
  uint64_t rawValue = (uint64_t)from._rawValue;
  uint64_t v177 = type metadata accessor for MLImageClassifier.Classifier(0);
  int64_t v6 = *(void *)(*(void *)(v177 - 8) + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  char v166 = v146;
  int64_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.Model?)
                             - 8)
                 + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  unint64_t v165 = v146;
  uint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v167 = v146;
  uint64_t v170 = type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0);
  int64_t v14 = *(void *)(*(void *)(v170 - 8) + 64);
  uint64_t v15 = alloca(v14);
  int64_t v16 = alloca(v14);
  unint64_t v171 = v146;
  uint64_t v17 = alloca(v14);
  uint64_t v18 = alloca(v14);
  char v169 = v146;
  uint64_t v173 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  int64_t v19 = *(void *)(*(void *)(v173 - 8) + 64);
  uint64_t v20 = alloca(v19);
  int64_t v21 = alloca(v19);
  uint64_t v174 = v146;
  uint64_t v22 = alloca(v19);
  long long v23 = alloca(v19);
  char v179 = v146;
  int64_t v24 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.Classifier?)
                              - 8)
                  + 64);
  int64_t v25 = alloca(v24);
  long long v26 = alloca(v24);
  uint64_t v161 = v146;
  long long v27 = alloca(v24);
  uint64_t v28 = alloca(v24);
  uint64_t v168 = v146;
  long long v29 = alloca(v24);
  uint64_t v30 = alloca(v24);
  uint64_t v172 = v146;
  uint64_t v178 = type metadata accessor for URL(0);
  uint64_t v162 = *(void *)(v178 - 8);
  int64_t v31 = *(void *)(v162 + 64);
  uint64_t v32 = alloca(v31);
  unint64_t v33 = alloca(v31);
  v163 = v146;
  uint64_t v34 = alloca(v31);
  uint64_t v35 = alloca(v31);
  char v183 = v146;
  uint64_t v36 = alloca(v31);
  unint64_t v37 = alloca(v31);
  uint64_t v164 = v146;
  uint64_t v38 = alloca(v31);
  uint64_t v39 = alloca(v31);
  unint64_t v160 = v146;
  int64_t v40 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                              - 8)
                  + 64);
  uint64_t v41 = alloca(v40);
  uint64_t v42 = alloca(v40);
  Swift::String v159 = v146;
  uint64_t v43 = alloca(v40);
  uint64_t v44 = alloca(v40);
  char v188 = v146;
  uint64_t v186 = type metadata accessor for MLCheckpoint(0);
  uint64_t v176 = *(void *)(v186 - 8);
  int64_t v45 = *(void *)(v176 + 64);
  uint64_t v46 = alloca(v45);
  uint64_t v47 = alloca(v45);
  uint64_t v180 = v146;
  uint64_t v48 = alloca(v45);
  uint64_t v49 = alloca(v45);
  unint64_t v182 = v146;
  uint64_t v50 = alloca(v45);
  uint64_t v51 = alloca(v45);
  unint64_t v185 = v146;
  int64_t v52 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  uint64_t v53 = alloca(v52);
  uint64_t v54 = alloca(v52);
  uint64_t v55 = type metadata accessor for MLImageClassifier.PersistentParameters(0);
  int64_t v56 = *(void *)(*(void *)(v55 - 8) + 64);
  uint64_t v57 = alloca(v56);
  uint64_t v58 = alloca(v56);
  uint64_t v59 = v184 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v184 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters, v148, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v59, (uint64_t)v146, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  unint64_t v175 = (int *)v55;
  if (__swift_getEnumTagSinglePayload((uint64_t)v146, 1, v55) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v146, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000002CLL, "SessionDelegate.swift" + 0x8000000000000000, "CreateML/ImageClassifierTrainingSessionDelegate.swift", 53, 2, 87, 0);
    BUG();
  }
  outlined init with take of MLClassifierMetrics((uint64_t)v146, (uint64_t)v146, type metadata accessor for MLImageClassifier.PersistentParameters);
  uint64_t v60 = (uint64_t)v188;
  uint64_t v61 = rawValue;
  specialized BidirectionalCollection.last.getter(rawValue);
  long long v62 = v146;
  if (__swift_getEnumTagSinglePayload(v60, 1, v186) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v60, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v63 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v63, 0, 0);
    *(void *)uint64_t v64 = 0xD00000000000001DLL;
    *(void *)(v64 + 8) = "reated." + 0x8000000000000000;
    *(_OWORD *)(v64 + 16) = 0;
    *(_OWORD *)(v64 + 32) = 0;
    *(unsigned char *)(v64 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v63, v64, v65, v66, v67);
LABEL_26:
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v62, type metadata accessor for MLImageClassifier.PersistentParameters);
    return;
  }
  uint64_t v68 = (uint64_t)v185;
  outlined init with take of MLClassifierMetrics(v60, (uint64_t)v185, type metadata accessor for MLCheckpoint);
  unint64_t v187 = v146;
  long long v69 = v158;
  ImageClassifierTrainingSessionDelegate.populateFiles(parameters:)(v146);
  char v188 = v69;
  if (v69)
  {
    uint64_t v70 = v68;
    goto LABEL_25;
  }
  int v71 = *(unsigned __int8 *)(v68 + *(int *)(v186 + 20));
  if (v71 != 2)
  {
    if (v71 == 1)
    {
      uint64_t v72 = (uint64_t)v160;
      URL.appendingPathComponent(_:isDirectory:)(0x676E696E69617274, 0xE800000000000000, 1);
      uint64_t v73 = v188;
      AnnotatedFeatureStore.init(contentsOf:)(v72, v3, v4, v5);
      if (!v73)
      {
        uint64_t v74 = v184;
        uint64_t v75 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore;
        long long v76 = (void *)(v184 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore);
        swift_beginAccess(v184 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore, v149, 1, 0);
        uint64_t v77 = *(void *)(v74 + v75);
        unint64_t v78 = *(void *)(v74 + v75 + 8);
        uint64_t v186 = *(void *)(v74 + v75 + 80);
        uint64_t v79 = *(void *)(v74 + v75 + 88);
        qmemcpy(v76, v147, 0x60uLL);
        outlined consume of Data._Representation(v77, v78);
        swift_bridgeObjectRelease(v79);
        swift_bridgeObjectRelease(v186);
        uint64_t v80 = (uint64_t)v164;
        URL.appendingPathComponent(_:isDirectory:)(0x69746164696C6176, 0xEA00000000006E6FLL, 1);
        AnnotatedFeatureStore.init(contentsOf:)(v80, v3, v4, v5);
        uint64_t v81 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore;
        uint64_t v82 = v184;
        uint64_t v83 = (Swift::OpaquePointer *)(v184
                                     + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore);
        swift_beginAccess(v184 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore, v150, 1, 0);
        uint64_t v84 = *(void *)(v82 + v81);
        unint64_t v85 = *(void *)(v82 + v81 + 8);
        uint64_t v186 = *(void *)(v82 + v81 + 80);
        uint64_t v86 = *(void *)(v82 + v81 + 88);
        qmemcpy(v83, v146, 0x60uLL);
        outlined consume of Data._Representation(v84, v85);
        swift_bridgeObjectRelease(v86);
        swift_bridgeObjectRelease(v186);
        uint64_t v87 = *(void *)(v82 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFiles);
        swift_bridgeObjectRetain(v87);
        MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v87, (uint64_t)v152, &demangling cache variable for type metadata for AnnotatedFeature<URL, String>, (uint64_t)&unk_352308);
        char v188 = 0;
        swift_bridgeObjectRelease(v87);
        uint64_t v186 = specialized Set.init<A>(_:)((uint64_t)MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm);
        uint64_t v89 = v175;
        uint64_t v90 = (uint64_t)v187;
        outlined init with copy of MLTrainingSessionParameters((uint64_t)v187 + v175[5], (uint64_t)v179, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
        uint64_t v180 = *(Swift::OpaquePointer **)(v90 + v89[8]);
        uint64_t rawValue = *(void *)(v90 + v89[9]);
        uint64_t v91 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType))
                     + 48);
        uint64_t v92 = (uint64_t)v169;
        outlined init with copy of MLTrainingSessionParameters(v90 + v89[6], (uint64_t)v169, type metadata accessor for MLImageClassifier.FeatureExtractorType);
        uint64_t v93 = *(void *)(v90 + v89[7]);
        uint64_t v94 = v93;
        if (v93 == 2) {
          uint64_t v94 = 0;
        }
        *(void *)(v92 + v91) = v94;
        memset(v155, 0, sizeof(v155));
        memset(v154, 0, sizeof(v154));
        v153[0] = v180;
        v153[1] = rawValue;
        uint64_t v95 = (uint64_t)v174;
        outlined init with copy of MLTrainingSessionParameters((uint64_t)v179, (uint64_t)v174, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
        uint64_t v157 = v173;
        boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v156);
        outlined init with take of MLClassifierMetrics(v95, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
        outlined copy of MLImageClassifier.ModelParameters.ClassifierType?(v93);
        outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v156, (uint64_t)v154, &demangling cache variable for type metadata for Any?);
        uint64_t v97 = (uint64_t)v171;
        outlined init with copy of MLTrainingSessionParameters(v92, (uint64_t)v171, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
        uint64_t v157 = v170;
        uint64_t v98 = __swift_allocate_boxed_opaque_existential_1(v156);
        outlined init with take of MLClassifierMetrics(v97, (uint64_t)v98, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
        outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v156, (uint64_t)v155, &demangling cache variable for type metadata for Any?);
        outlined destroy of MLActivityClassifier.ModelParameters(v92, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v179, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
        uint64_t v99 = (uint64_t)v172;
        MLImageClassifier.Classifier.init(labels:parameters:)(v186, v153);
        uint64_t v100 = v177;
        __swift_storeEnumTagSinglePayload(v99, 0, 1, v177);
        uint64_t v101 = v184 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier;
        swift_beginAccess(v184 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier, v153, 33, 0);
        outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v99, v101, &demangling cache variable for type metadata for MLImageClassifier.Classifier?);
        swift_endAccess(v153);
        uint64_t v102 = (uint64_t)v168;
        outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v101, (uint64_t)v168, &demangling cache variable for type metadata for MLImageClassifier.Classifier?);
        if (__swift_getEnumTagSinglePayload(v102, 1, v100) == 1) {
          BUG();
        }
        uint64_t v103 = (uint64_t)v167;
        MLImageClassifier.Classifier.makeTransformer()();
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v185, type metadata accessor for MLCheckpoint);
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v187, type metadata accessor for MLImageClassifier.PersistentParameters);
        outlined destroy of MLActivityClassifier.ModelParameters(v102, type metadata accessor for MLImageClassifier.Classifier);
        uint64_t v104 = type metadata accessor for MLImageClassifier.Model(0);
        __swift_storeEnumTagSinglePayload(v103, 0, 1, v104);
        uint64_t v105 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model + v184;
        swift_beginAccess(OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model + v184, v153, 33, 0);
        outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v103, v105, &demangling cache variable for type metadata for MLImageClassifier.Model?);
        swift_endAccess(v153);
        return;
      }
    }
    else
    {
      uint64_t v117 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v117, 0, 0);
      *(void *)uint64_t v118 = 0xD00000000000003ELL;
      *(void *)(v118 + 8) = "No checkpoints to be resumed." + 0x8000000000000000;
      *(_OWORD *)(v118 + 16) = 0;
      *(_OWORD *)(v118 + 32) = 0;
      *(unsigned char *)(v118 + 48) = 0;
      swift_willThrow(&type metadata for MLCreateError, v117, v118, v119, v120, v121);
    }
    uint64_t v70 = v68;
    goto LABEL_25;
  }
  v153[0] = v61;
  uint64_t v106 = *(void *)(v61 + 16);
  char v107 = 1;
  if (!v106)
  {
    uint64_t v108 = 0;
    goto LABEL_29;
  }
  uint64_t v108 = v106 - 1;
  uint64_t v109 = v108 * *(void *)(v176 + 72)
       + ((*(unsigned __int8 *)(v176 + 80) + 32) & ~*(unsigned __int8 *)(v176 + 80))
       + v61;
  uint64_t rawValue = -*(void *)(v176 + 72);
  uint64_t v110 = (uint64_t)v182;
  while (2)
  {
    uint64_t v111 = (uint64_t)v180;
    outlined init with copy of MLTrainingSessionParameters(v109, (uint64_t)v180, type metadata accessor for MLCheckpoint);
    switch(*(unsigned char *)(v111 + *(int *)(v186 + 20)))
    {
      case 0:
        uint64_t v112 = v109;
        unint64_t v113 = 0xEB0000000064657ALL;
        uint64_t v114 = 0x696C616974696E69;
        goto LABEL_20;
      case 1:
        swift_bridgeObjectRelease(110);
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v180, type metadata accessor for MLCheckpoint);
        char v107 = 0;
        goto LABEL_30;
      case 2:
        uint64_t v112 = v109;
        unint64_t v113 = 0xE800000000000000;
        uint64_t v114 = 0x676E696E69617274;
        goto LABEL_20;
      case 3:
        uint64_t v112 = v109;
        unint64_t v113 = 0xEA0000000000676ELL;
        uint64_t v114 = 0x697461756C617665;
        goto LABEL_20;
      case 4:
        uint64_t v112 = v109;
        unint64_t v113 = 0xEB00000000676E69;
        uint64_t v114 = 0x636E657265666E69;
LABEL_20:
        char v115 = _stringCompareWithSmolCheck(_:_:expecting:)(v114, v113, 0x6974636172747865, 0xEA0000000000676ELL, 0);
        swift_bridgeObjectRelease(v113);
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v180, type metadata accessor for MLCheckpoint);
        if ((v115 & 1) == 0)
        {
          uint64_t v109 = rawValue + v112;
          BOOL v116 = v108-- != 0;
          uint64_t v110 = (uint64_t)v182;
          if (!v116)
          {
            uint64_t v108 = 0;
            char v107 = 1;
            goto LABEL_30;
          }
          continue;
        }
        char v107 = 0;
LABEL_29:
        uint64_t v110 = (uint64_t)v182;
LABEL_30:
        uint64_t v122 = alloca(24);
        char v123 = alloca(32);
        v146[2]._uint64_t rawValue = v153;
        uint64_t v124 = (uint64_t)v159;
        uint64_t v125 = v188;
        _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))partial apply for specialized closure #1 in BidirectionalCollection.last(where:), (uint64_t)v146, v108, v107, (uint64_t)v151);
        if (__swift_getEnumTagSinglePayload(v124, 1, v186) == 1)
        {
          char v188 = v125;
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v124, &demangling cache variable for type metadata for MLCheckpoint?);
          goto LABEL_35;
        }
        outlined init with take of MLClassifierMetrics(v124, v110, type metadata accessor for MLCheckpoint);
        uint64_t v126 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLCheckpoint>);
        uint64_t v127 = *(unsigned __int8 *)(v176 + 80);
        uint64_t v128 = v110;
        uint64_t v129 = ((int)v127 + 32) & ~*(unsigned __int8 *)(v176 + 80);
        v130._uint64_t rawValue = (void *)swift_allocObject(v126, v129 + *(void *)(v176 + 72), v127 | 7);
        *((void *)v130._rawValue + 2) = 1;
        *((void *)v130._rawValue + 3) = 2;
        outlined init with copy of MLTrainingSessionParameters(v128, (uint64_t)v130._rawValue + v129, type metadata accessor for MLCheckpoint);
        ImageClassifierTrainingSessionDelegate.resume(from:)(v130);
        char v188 = v131;
        if (v131)
        {
          swift_setDeallocating(v130._rawValue);
          specialized _ContiguousArrayStorage.__deallocating_deinit();
          outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v182, type metadata accessor for MLCheckpoint);
          uint64_t v70 = (uint64_t)v185;
          goto LABEL_25;
        }
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v182, type metadata accessor for MLCheckpoint);
        swift_setDeallocating(v130._rawValue);
        specialized _ContiguousArrayStorage.__deallocating_deinit();
LABEL_35:
        uint64_t v132 = v163;
        URL.appendingPathComponent(_:)(0x6C65646F6DLL, 0xE500000000000000);
        URL.appendingPathExtension(_:)(6777712, 0xE300000000000000);
        uint64_t v133 = v132;
        uint64_t v134 = *(void (**)(Swift::OpaquePointer *, uint64_t))(v162 + 8);
        uint64_t v135 = v178;
        v134(v133, v178);
        uint64_t v136 = v184 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier;
        swift_beginAccess(v184 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier, v153, 0, 0);
        uint64_t v137 = v136;
        uint64_t v138 = (uint64_t)v161;
        outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v137, (uint64_t)v161, &demangling cache variable for type metadata for MLImageClassifier.Classifier?);
        uint64_t v139 = v177;
        if (__swift_getEnumTagSinglePayload(v138, 1, v177) == 1)
        {
          v134(v183, v135);
          outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v185, type metadata accessor for MLCheckpoint);
          outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v187, type metadata accessor for MLImageClassifier.PersistentParameters);
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v138, &demangling cache variable for type metadata for MLImageClassifier.Classifier?);
          return;
        }
        uint64_t v140 = (uint64_t)v166;
        outlined init with take of MLClassifierMetrics(v138, (uint64_t)v166, type metadata accessor for MLImageClassifier.Classifier);
        uint64_t v141 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLImageClassifier.Classifier and conformance MLImageClassifier.Classifier, type metadata accessor for MLImageClassifier.Classifier, (uint64_t)&protocol conformance descriptor for MLImageClassifier.Classifier);
        uint64_t v142 = (uint64_t)v165;
        uint64_t v143 = v188;
        UpdatableSupervisedEstimator.readWithOptimizer(from:)(v183, v139, v141);
        if (v143)
        {
          outlined destroy of MLActivityClassifier.ModelParameters(v140, type metadata accessor for MLImageClassifier.Classifier);
          v134(v183, v178);
          uint64_t v70 = (uint64_t)v185;
LABEL_25:
          outlined destroy of MLActivityClassifier.ModelParameters(v70, type metadata accessor for MLCheckpoint);
          long long v62 = v187;
          goto LABEL_26;
        }
        outlined destroy of MLActivityClassifier.ModelParameters(v140, type metadata accessor for MLImageClassifier.Classifier);
        v134(v183, v178);
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v185, type metadata accessor for MLCheckpoint);
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v187, type metadata accessor for MLImageClassifier.PersistentParameters);
        uint64_t v144 = type metadata accessor for MLImageClassifier.Model(0);
        __swift_storeEnumTagSinglePayload(v142, 0, 1, v144);
        uint64_t v145 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model + v184;
        swift_beginAccess(OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model + v184, v156, 33, 0);
        outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v142, v145, &demangling cache variable for type metadata for MLImageClassifier.Model?);
        swift_endAccess(v156);
        return;
    }
  }
}

Swift::Int_optional __swiftcall ImageClassifierTrainingSessionDelegate.itemCount(phase:)(CreateML::MLPhase phase)
{
  switch(*(unsigned char *)phase)
  {
    case 0:
    case 4:
      char v2 = 1;
      v3.value = 0;
      break;
    case 1:
      uint64_t v4 = *(void *)(*(void *)(v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFiles)
                     + 16);
      uint64_t v5 = *(void *)(v1 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFiles);
      BOOL v6 = __OFADD__(*(void *)(v5 + 16), v4);
      v3.value = *(void *)(v5 + 16) + v4;
      if (v6) {
        BUG();
      }
      goto LABEL_7;
    case 2:
      uint64_t v7 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_sessionParameters + v1;
      char v2 = 0;
      v3.value = *(void *)(*(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 28) + v7);
      break;
    case 3:
      v3.value = 0;
LABEL_7:
      char v2 = 0;
      break;
  }
  v3.is_nil = v2;
  return v3;
}

uint64_t ImageClassifierTrainingSessionDelegate.extractFeatures(from:)(uint64_t a1)
{
  v2[35] = v1;
  v2[34] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  v2[36] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[37] = v4;
  v2[38] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for ImageReader(0);
  v2[39] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[40] = v6;
  v2[41] = swift_task_alloc((*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  v2[42] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0);
  v2[43] = v8;
  unint64_t v9 = (*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[44] = swift_task_alloc(v9);
  v2[45] = swift_task_alloc(v9);
  uint64_t v10 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  v2[46] = v10;
  unint64_t v11 = (*(void *)(*(void *)(v10 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[47] = swift_task_alloc(v11);
  v2[48] = swift_task_alloc(v11);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  v2[49] = swift_task_alloc((*(void *)(*(void *)(v12 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v13 = type metadata accessor for MLImageClassifier.PersistentParameters(0);
  v2[50] = v13;
  v2[51] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(ImageClassifierTrainingSessionDelegate.extractFeatures(from:), 0, 0);
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t (*v9)(uint64_t, uint64_t, uint64_t);
  void *v10;

  uint64_t v4 = *(void *)(*v2 + 456);
  uint64_t v5 = *(void *)(*v2 + 472);
  uint64_t v6 = *v2;
  *(void *)(v6 + 480) = a1;
  *(void *)(v6 + 488) = v1;
  swift_task_dealloc(v5);
  swift_bridgeObjectRelease(v4);
  if (v1) {
    return swift_task_switch(ImageClassifierTrainingSessionDelegate.extractFeatures(from:), 0, 0);
  }
  uint64_t v8 = *(void *)(*(void *)(v6 + 408) + *(int *)(v6 + 608));
  unint64_t v9 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)&async function pointer to specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)
                                                         + async function pointer to specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:));
  uint64_t v10 = (void *)swift_task_alloc(dword_3AF4CC);
  *(void *)(v6 + 496) = v10;
  void *v10 = v6;
  v10[1] = ImageClassifierTrainingSessionDelegate.extractFeatures(from:);
  return v9(a1, v8, 1);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v4;
  void *v5;
  uint64_t (*v7)(uint64_t);
  void *v8;

  uint64_t v4 = *(void *)(*(void *)v2 + 496);
  uint64_t v5 = *(void **)v2;
  v5[63] = a1;
  v5[64] = v1;
  swift_task_dealloc(v4);
  if (v1) {
    return swift_task_switch(ImageClassifierTrainingSessionDelegate.extractFeatures(from:), 0, 0);
  }
  swift_bridgeObjectRelease(v5[60]);
  uint64_t v7 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:)
                                       + async function pointer to specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:));
  uint64_t v8 = (void *)swift_task_alloc(dword_3AF484);
  v5[65] = v8;
  void *v8 = v5;
  v8[1] = ImageClassifierTrainingSessionDelegate.extractFeatures(from:);
  return v7(a1);
}

{
  uint64_t v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  uint64_t (*v5)();

  uint64_t v4 = *(void *)(*(void *)v2 + 520);
  uint64_t v3 = *(void **)v2;
  v3[66] = a1;
  v3[67] = v1;
  swift_task_dealloc(v4);
  if (v1)
  {
    uint64_t v5 = ImageClassifierTrainingSessionDelegate.extractFeatures(from:);
  }
  else
  {
    swift_bridgeObjectRelease(v3[63]);
    uint64_t v5 = ImageClassifierTrainingSessionDelegate.extractFeatures(from:);
  }
  return swift_task_switch(v5, 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v4;
  uint64_t v5;
  void *v6;
  uint64_t (*v8)(uint64_t);
  void *v9;

  uint64_t v4 = *(void *)(*(void *)v2 + 552);
  uint64_t v5 = *(void *)(*(void *)v2 + 560);
  uint64_t v6 = *(void **)v2;
  v6[71] = a1;
  v6[72] = v1;
  swift_task_dealloc(v5);
  swift_bridgeObjectRelease(v4);
  if (v1) {
    return swift_task_switch(ImageClassifierTrainingSessionDelegate.extractFeatures(from:), 0, 0);
  }
  uint64_t v8 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:)
                                       + async function pointer to specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:));
  unint64_t v9 = (void *)swift_task_alloc(dword_3AF484);
  v6[73] = v9;
  void *v9 = v6;
  v9[1] = ImageClassifierTrainingSessionDelegate.extractFeatures(from:);
  return v8(a1);
}

{
  uint64_t v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  uint64_t (*v5)();

  uint64_t v4 = *(void *)(*(void *)v2 + 584);
  uint64_t v3 = *(void **)v2;
  v3[74] = a1;
  v3[75] = v1;
  swift_task_dealloc(v4);
  if (v1)
  {
    uint64_t v5 = ImageClassifierTrainingSessionDelegate.extractFeatures(from:);
  }
  else
  {
    swift_bridgeObjectRelease(v3[71]);
    uint64_t v5 = ImageClassifierTrainingSessionDelegate.extractFeatures(from:);
  }
  return swift_task_switch(v5, 0, 0);
}

uint64_t ImageClassifierTrainingSessionDelegate.extractFeatures(from:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v8 = *(void *)(v7 + 400);
  uint64_t v9 = *(void *)(v7 + 392);
  uint64_t v10 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters + *(void *)(v7 + 280);
  swift_beginAccess(v10, v7 + 200, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, v9, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload(v9, 1, v8) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v7 + 392), &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
    return _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000002CLL, "SessionDelegate.swift" + 0x8000000000000000, "CreateML/ImageClassifierTrainingSessionDelegate.swift", 53, 2, 145, 0);
  }
  else
  {
    uint64_t v12 = *(void *)(v7 + 280);
    outlined init with take of MLClassifierMetrics(*(void *)(v7 + 392), *(void *)(v7 + 408), type metadata accessor for MLImageClassifier.PersistentParameters);
    uint64_t v13 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFiles;
    *(void *)(v7 + 416) = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFiles;
    uint64_t v14 = *(void *)(*(void *)(v12 + v13) + 16);
    uint64_t v15 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFiles;
    *(void *)(v7 + 424) = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFiles;
    uint64_t v16 = *(void *)(v12 + v15);
    BOOL v17 = __OFADD__(*(void *)(v16 + 16), v14);
    uint64_t v18 = *(void *)(v16 + 16) + v14;
    *(void *)(v7 + 432) = v18;
    if (v17) {
      BUG();
    }
    if (v18 <= *(void *)(v7 + 272))
    {
      outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v7 + 408), type metadata accessor for MLImageClassifier.PersistentParameters);
      uint64_t v29 = *(void *)(v7 + 392);
      uint64_t v30 = *(void *)(v7 + 384);
      uint64_t v31 = *(void *)(v7 + 376);
      uint64_t v32 = *(void *)(v7 + 360);
      uint64_t v46 = *(void *)(v7 + 352);
      uint64_t v45 = *(void *)(v7 + 336);
      uint64_t v48 = *(void *)(v7 + 304);
      uint64_t v43 = *(void *)(v7 + 328);
      swift_task_dealloc(*(void *)(v7 + 408));
      swift_task_dealloc(v29);
      swift_task_dealloc(v30);
      swift_task_dealloc(v31);
      swift_task_dealloc(v32);
      swift_task_dealloc(v46);
      swift_task_dealloc(v45);
      swift_task_dealloc(v43);
      swift_task_dealloc(v48);
      return (*(uint64_t (**)(void, uint64_t, uint64_t))(v7 + 8))(0, 1, v33);
    }
    else
    {
      uint64_t v34 = (void *)(v7 + 168);
      uint64_t v38 = (void *)(v7 + 136);
      uint64_t v19 = *(void *)(v7 + 408);
      uint64_t v20 = *(int **)(v7 + 400);
      uint64_t v47 = *(void *)(v7 + 384);
      uint64_t v40 = *(void *)(v7 + 376);
      uint64_t v39 = *(void *)(v7 + 368);
      uint64_t v21 = *(void *)(v7 + 360);
      uint64_t v36 = *(void *)(v7 + 352);
      uint64_t v44 = *(void *)(v7 + 336);
      uint64_t v37 = *(void *)(v7 + 344);
      outlined init with copy of MLTrainingSessionParameters(v19 + v20[5], v47, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
      uint64_t v41 = *(void *)(v19 + v20[8]);
      uint64_t v22 = v20[9];
      *(_DWORD *)(v7 + 608) = v22;
      uint64_t v42 = *(void *)(v19 + v22);
      uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType));
      uint64_t v23 = *(int *)(v35 + 48);
      outlined init with copy of MLTrainingSessionParameters(v19 + v20[6], v21, type metadata accessor for MLImageClassifier.FeatureExtractorType);
      uint64_t v24 = *(void *)(v19 + v20[7]);
      uint64_t v25 = 0;
      if (v24 != 2) {
        uint64_t v25 = v24;
      }
      *(void *)(v21 + v23) = v25;
      *(_OWORD *)(v7 + 80) = 0;
      *(_OWORD *)(v7 + 64) = 0;
      *(_OWORD *)(v7 + 48) = 0;
      *(_OWORD *)(v7 + 32) = 0;
      *(void *)(v7 + 16) = v41;
      *(void *)(v7 + 24) = v42;
      outlined init with copy of MLTrainingSessionParameters(v47, v40, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
      *(void *)(v7 + 160) = v39;
      boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v38);
      outlined init with take of MLClassifierMetrics(v40, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
      outlined copy of MLImageClassifier.ModelParameters.ClassifierType?(v24);
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v38, v7 + 32, &demangling cache variable for type metadata for Any?);
      outlined init with copy of MLTrainingSessionParameters(v21, v36, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
      *(void *)(v7 + 192) = v37;
      long long v27 = __swift_allocate_boxed_opaque_existential_1(v34);
      outlined init with take of MLClassifierMetrics(v36, (uint64_t)v27, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v34, v7 + 64, &demangling cache variable for type metadata for Any?);
      outlined destroy of MLActivityClassifier.ModelParameters(v21, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
      outlined destroy of MLActivityClassifier.ModelParameters(v47, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
      MLImageClassifier.ModelParameters.algorithm.getter(v47);
      swift_bridgeObjectRelease(*(void *)(v36 + *(int *)(v35 + 48)));
      outlined init with take of MLClassifierMetrics(v36, v44, type metadata accessor for MLImageClassifier.FeatureExtractorType);
      outlined destroy of MLImageClassifier.ModelParameters(v7 + 16);
      uint64_t v28 = (void *)swift_task_alloc(dword_3AEB5C);
      *(void *)(v7 + 440) = v28;
      void *v28 = v7;
      v28[1] = ImageClassifierTrainingSessionDelegate.extractFeatures(from:);
      return MLImageClassifier.FeatureExtractor.init(type:)(v7 + 96, *(void *)(v7 + 336));
    }
  }
}

uint64_t ImageClassifierTrainingSessionDelegate.extractFeatures(from:)()
{
  uint64_t v2 = *(void *)(*(void *)v1 + 440);
  *(void *)(*(void *)v1 + 448) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = ImageClassifierTrainingSessionDelegate.extractFeatures(from:);
  }
  else {
    uint64_t v3 = ImageClassifierTrainingSessionDelegate.extractFeatures(from:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  BOOL v8;
  uint64_t v9;
  uint64_t v10;
  int v11;
  uint64_t v12;
  void *v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t (*v18)(uint64_t, uint64_t, uint64_t, uint64_t, void, void);
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  unint64_t v23;
  int v24;
  uint64_t v25;
  void *v26;
  char *v28;
  uint64_t v29;
  uint64_t v30;
  char *v31;

  uint64_t v1 = v0[52];
  uint64_t v2 = v0[34];
  uint64_t v3 = v0[35];
  ImageReader.init()();
  uint64_t v4 = *(void *)(v3 + v1);
  v0[57] = v4;
  uint64_t v29 = v4;
  uint64_t v5 = *(void *)(v4 + 16);
  uint64_t v6 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_sessionParameters + v3;
  uint64_t v7 = *(void *)(*(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 20) + v6);
  uint64_t v8 = __OFADD__(v2, v7);
  uint64_t v9 = v2 + v7;
  if (v5 <= v2)
  {
    if (v8) {
      BUG();
    }
    uint64_t v19 = v0[34];
    if (v0[54] < v9) {
      uint64_t v9 = v0[54];
    }
    v0[68] = v9;
    uint64_t v8 = __OFSUB__(v9, v5);
    uint64_t v20 = v9 - v5;
    if (v8) {
      BUG();
    }
    uint64_t v21 = v19 - v5;
    if (v20 < v21) {
      BUG();
    }
    uint64_t v22 = *(void *)(v0[35] + v0[53]);
    v0[69] = v22;
    if (v21 < 0) {
      BUG();
    }
    uint64_t v23 = *(void *)(v22 + 16);
    if (v23 < v21 || (uint64_t)v23 < v20) {
      BUG();
    }
    uint64_t v24 = *(unsigned __int8 *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>)
                                         - 8)
                             + 80);
    uint64_t v30 = 2 * v20 + 1;
    uint64_t v31 = (char *)&async function pointer to specialized Transformer.applied<A, B>(to:eventHandler:)
        + async function pointer to specialized Transformer.applied<A, B>(to:eventHandler:);
    uint64_t v25 = dword_3AF4C4;
    swift_bridgeObjectRetain(v22);
    long long v26 = (void *)swift_task_alloc(v25);
    v0[70] = v26;
    void *v26 = v0;
    v26[1] = ImageClassifierTrainingSessionDelegate.extractFeatures(from:);
    uint64_t v15 = v22;
    uint64_t v16 = v22 + ((v24 + 32) & ~v24);
    uint64_t v14 = v21;
    BOOL v17 = v30;
    uint64_t v18 = (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, void, void))v31;
  }
  else
  {
    if (v8) {
      BUG();
    }
    uint64_t v10 = v0[34];
    if (v5 < v9) {
      uint64_t v9 = v5;
    }
    v0[58] = v9;
    if (v9 < v10) {
      BUG();
    }
    if (v10 < 0) {
      BUG();
    }
    unint64_t v11 = *(unsigned __int8 *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>)
                                         - 8)
                             + 80);
    uint64_t v28 = (char *)&async function pointer to specialized Transformer.applied<A, B>(to:eventHandler:)
        + async function pointer to specialized Transformer.applied<A, B>(to:eventHandler:);
    uint64_t v12 = dword_3AF4C4;
    swift_bridgeObjectRetain(v29);
    uint64_t v13 = (void *)swift_task_alloc(v12);
    v0[59] = v13;
    *uint64_t v13 = v0;
    v13[1] = ImageClassifierTrainingSessionDelegate.extractFeatures(from:);
    uint64_t v14 = v0[34];
    uint64_t v15 = v29;
    uint64_t v16 = v29 + ((v11 + 32) & ~v11);
    BOOL v17 = 2 * v9 + 1;
    uint64_t v18 = (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, void, void))v28;
  }
  return v18(v15, v16, v14, v17, 0, 0);
}

{
  void *v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  Swift::OpaquePointer v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  BOOL v16;
  uint64_t v17;
  uint64_t v18;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  void *v32;

  uint64_t v30 = (uint64_t)(v0 + 12);
  uint64_t v1 = v0 + 31;
  uint64_t v32 = v0;
  uint64_t v2 = v0[66];
  swift_beginAccess(v0[35] + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore, v0 + 31, 33, 0);
  swift_bridgeObjectRetain(v2);
  specialized Array.append<A>(contentsOf:)(v2);
  uint64_t v3 = *(void *)(v2 + 16);
  if (v3)
  {
    uint64_t v20 = v0 + 31;
    uint64_t v24 = v0[37];
    uint64_t v4 = v0[66];
    long long v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
    uint64_t v5 = *(void *)(v26 - 8);
    uint64_t v6 = v4 + ((*(unsigned __int8 *)(v5 + 80) + 32) & ~*(unsigned __int8 *)(v5 + 80));
    uint64_t v28 = *(void *)(v5 + 72);
    swift_bridgeObjectRetain(v4);
    do
    {
      uint64_t v21 = v3;
      uint64_t v7 = v32[36];
      uint64_t v8 = v32[38];
      AnnotatedFeature.feature.getter(v26);
      uint64_t v9 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
      v10._uint64_t rawValue = (void *)MLShapedArrayProtocol.scalars.getter(v7, v9);
      (*(void (**)(uint64_t, uint64_t))(v24 + 8))(v8, v7);
      BlobsFile.appendBlob(_:)(v10);
      swift_bridgeObjectRelease(v10._rawValue);
      v6 += v28;
      uint64_t v3 = v21 - 1;
    }
    while (v21 != 1);
    swift_bridgeObjectRelease(v32[66]);
    uint64_t v1 = v20;
  }
  swift_endAccess(v1);
  unint64_t v11 = v32[66];
  uint64_t v12 = v32[58];
  uint64_t v13 = v32[51];
  uint64_t v14 = v32[34];
  (*(void (**)(void, void))(v32[40] + 8))(v32[41], v32[39]);
  outlined destroy of MLImageClassifier.FeatureExtractor(v30);
  outlined destroy of MLActivityClassifier.ModelParameters(v13, type metadata accessor for MLImageClassifier.PersistentParameters);
  swift_bridgeObjectRelease(v11);
  uint64_t v15 = v12 - v14;
  if (__OFSUB__(v12, v14)) {
    BUG();
  }
  uint64_t v16 = v12 >= v32[54];
  BOOL v17 = v32[49];
  uint64_t v18 = v32[48];
  uint64_t v31 = v32[47];
  uint64_t v29 = v32[45];
  long long v27 = v32[44];
  uint64_t v25 = v32[42];
  uint64_t v22 = v32[38];
  uint64_t v23 = v32[41];
  swift_task_dealloc(v32[51]);
  swift_task_dealloc(v17);
  swift_task_dealloc(v18);
  swift_task_dealloc(v31);
  swift_task_dealloc(v29);
  swift_task_dealloc(v27);
  swift_task_dealloc(v25);
  swift_task_dealloc(v23);
  swift_task_dealloc(v22);
  return ((uint64_t (*)(uint64_t, BOOL))v32[1])(v15, v16);
}

{
  void *v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  Swift::OpaquePointer v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  BOOL v16;
  uint64_t v17;
  uint64_t v18;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  void *v32;

  uint64_t v30 = (uint64_t)(v0 + 12);
  uint64_t v1 = v0 + 28;
  uint64_t v32 = v0;
  uint64_t v2 = v0[74];
  swift_beginAccess(v0[35] + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore, v0 + 28, 33, 0);
  swift_bridgeObjectRetain(v2);
  specialized Array.append<A>(contentsOf:)(v2);
  uint64_t v3 = *(void *)(v2 + 16);
  if (v3)
  {
    uint64_t v20 = v0 + 28;
    uint64_t v24 = v0[37];
    uint64_t v4 = v0[74];
    long long v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
    uint64_t v5 = *(void *)(v26 - 8);
    uint64_t v6 = v4 + ((*(unsigned __int8 *)(v5 + 80) + 32) & ~*(unsigned __int8 *)(v5 + 80));
    uint64_t v28 = *(void *)(v5 + 72);
    swift_bridgeObjectRetain(v4);
    do
    {
      uint64_t v21 = v3;
      uint64_t v7 = v32[36];
      uint64_t v8 = v32[38];
      AnnotatedFeature.feature.getter(v26);
      uint64_t v9 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
      v10._uint64_t rawValue = (void *)MLShapedArrayProtocol.scalars.getter(v7, v9);
      (*(void (**)(uint64_t, uint64_t))(v24 + 8))(v8, v7);
      BlobsFile.appendBlob(_:)(v10);
      swift_bridgeObjectRelease(v10._rawValue);
      v6 += v28;
      uint64_t v3 = v21 - 1;
    }
    while (v21 != 1);
    swift_bridgeObjectRelease(v32[74]);
    uint64_t v1 = v20;
  }
  swift_endAccess(v1);
  unint64_t v11 = v32[74];
  uint64_t v12 = v32[68];
  uint64_t v13 = v32[51];
  uint64_t v14 = v32[34];
  (*(void (**)(void, void))(v32[40] + 8))(v32[41], v32[39]);
  outlined destroy of MLImageClassifier.FeatureExtractor(v30);
  outlined destroy of MLActivityClassifier.ModelParameters(v13, type metadata accessor for MLImageClassifier.PersistentParameters);
  swift_bridgeObjectRelease(v11);
  uint64_t v15 = v12 - v14;
  if (__OFSUB__(v12, v14)) {
    BUG();
  }
  uint64_t v16 = v12 >= v32[54];
  BOOL v17 = v32[49];
  uint64_t v18 = v32[48];
  uint64_t v31 = v32[47];
  uint64_t v29 = v32[45];
  long long v27 = v32[44];
  uint64_t v25 = v32[42];
  uint64_t v22 = v32[38];
  uint64_t v23 = v32[41];
  swift_task_dealloc(v32[51]);
  swift_task_dealloc(v17);
  swift_task_dealloc(v18);
  swift_task_dealloc(v31);
  swift_task_dealloc(v29);
  swift_task_dealloc(v27);
  swift_task_dealloc(v25);
  swift_task_dealloc(v23);
  swift_task_dealloc(v22);
  return ((uint64_t (*)(uint64_t, BOOL))v32[1])(v15, v16);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;

  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 408), type metadata accessor for MLImageClassifier.PersistentParameters);
  uint64_t v1 = *(void *)(v0 + 392);
  uint64_t v2 = *(void *)(v0 + 384);
  uint64_t v3 = *(void *)(v0 + 376);
  uint64_t v4 = *(void *)(v0 + 360);
  uint64_t v9 = *(void *)(v0 + 352);
  uint64_t v8 = *(void *)(v0 + 336);
  uint64_t v6 = *(void *)(v0 + 304);
  uint64_t v7 = *(void *)(v0 + 328);
  swift_task_dealloc(*(void *)(v0 + 408));
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v1 = *(void *)(v0 + 408);
  (*(void (**)(void, void))(*(void *)(v0 + 320) + 8))(*(void *)(v0 + 328), *(void *)(v0 + 312));
  outlined destroy of MLImageClassifier.FeatureExtractor(v0 + 96);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLImageClassifier.PersistentParameters);
  uint64_t v2 = *(void *)(v0 + 392);
  uint64_t v3 = *(void *)(v0 + 384);
  uint64_t v4 = *(void *)(v0 + 376);
  uint64_t v5 = *(void *)(v0 + 360);
  uint64_t v10 = *(void *)(v0 + 352);
  uint64_t v9 = *(void *)(v0 + 336);
  uint64_t v7 = *(void *)(v0 + 304);
  uint64_t v8 = *(void *)(v0 + 328);
  swift_task_dealloc(*(void *)(v0 + 408));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v5);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;

  uint64_t v1 = *(void *)(v0 + 480);
  uint64_t v2 = *(void *)(v0 + 408);
  (*(void (**)(void, void))(*(void *)(v0 + 320) + 8))(*(void *)(v0 + 328), *(void *)(v0 + 312));
  outlined destroy of MLImageClassifier.FeatureExtractor(v0 + 96);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.PersistentParameters);
  swift_bridgeObjectRelease(v1);
  uint64_t v3 = *(void *)(v0 + 392);
  uint64_t v4 = *(void *)(v0 + 384);
  uint64_t v5 = *(void *)(v0 + 376);
  uint64_t v6 = *(void *)(v0 + 360);
  unint64_t v11 = *(void *)(v0 + 352);
  uint64_t v10 = *(void *)(v0 + 336);
  uint64_t v8 = *(void *)(v0 + 304);
  uint64_t v9 = *(void *)(v0 + 328);
  swift_task_dealloc(*(void *)(v0 + 408));
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;

  uint64_t v1 = *(void *)(v0 + 504);
  uint64_t v2 = *(void *)(v0 + 408);
  (*(void (**)(void, void))(*(void *)(v0 + 320) + 8))(*(void *)(v0 + 328), *(void *)(v0 + 312));
  outlined destroy of MLImageClassifier.FeatureExtractor(v0 + 96);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.PersistentParameters);
  swift_bridgeObjectRelease(v1);
  uint64_t v3 = *(void *)(v0 + 392);
  uint64_t v4 = *(void *)(v0 + 384);
  uint64_t v5 = *(void *)(v0 + 376);
  uint64_t v6 = *(void *)(v0 + 360);
  unint64_t v11 = *(void *)(v0 + 352);
  uint64_t v10 = *(void *)(v0 + 336);
  uint64_t v8 = *(void *)(v0 + 304);
  uint64_t v9 = *(void *)(v0 + 328);
  swift_task_dealloc(*(void *)(v0 + 408));
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;

  uint64_t v1 = *(void *)(v0 + 408);
  (*(void (**)(void, void))(*(void *)(v0 + 320) + 8))(*(void *)(v0 + 328), *(void *)(v0 + 312));
  outlined destroy of MLImageClassifier.FeatureExtractor(v0 + 96);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLImageClassifier.PersistentParameters);
  uint64_t v2 = *(void *)(v0 + 392);
  uint64_t v3 = *(void *)(v0 + 384);
  uint64_t v4 = *(void *)(v0 + 376);
  uint64_t v5 = *(void *)(v0 + 360);
  uint64_t v10 = *(void *)(v0 + 352);
  uint64_t v9 = *(void *)(v0 + 336);
  uint64_t v7 = *(void *)(v0 + 304);
  uint64_t v8 = *(void *)(v0 + 328);
  swift_task_dealloc(*(void *)(v0 + 408));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v5);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;

  uint64_t v1 = *(void *)(v0 + 568);
  uint64_t v2 = *(void *)(v0 + 408);
  (*(void (**)(void, void))(*(void *)(v0 + 320) + 8))(*(void *)(v0 + 328), *(void *)(v0 + 312));
  outlined destroy of MLImageClassifier.FeatureExtractor(v0 + 96);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.PersistentParameters);
  swift_bridgeObjectRelease(v1);
  uint64_t v3 = *(void *)(v0 + 392);
  uint64_t v4 = *(void *)(v0 + 384);
  uint64_t v5 = *(void *)(v0 + 376);
  uint64_t v6 = *(void *)(v0 + 360);
  unint64_t v11 = *(void *)(v0 + 352);
  uint64_t v10 = *(void *)(v0 + 336);
  uint64_t v8 = *(void *)(v0 + 304);
  uint64_t v9 = *(void *)(v0 + 328);
  swift_task_dealloc(*(void *)(v0 + 408));
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> ImageClassifierTrainingSessionDelegate.transitionTo(phase:)(CreateML::MLPhase phase)
{
  uint64_t v2 = type metadata accessor for TrainingTablePrinter(0);
  int64_t v3 = *(void *)(*(void *)(v2 - 8) + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  if (*(unsigned char *)phase == 3)
  {
    uint64_t v6 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_tablePrinter + v1;
    swift_beginAccess(v6, v10, 0, 0);
    if (!__swift_getEnumTagSinglePayload(v6, 1, v2))
    {
      outlined init with copy of MLTrainingSessionParameters(v6, (uint64_t)v9, type metadata accessor for TrainingTablePrinter);
      uint64_t v11 = *(void *)&v9[*(int *)(v2 + 20)];
      static os_log_type_t.info.getter();
      uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
      uint64_t v8 = (void *)swift_allocObject(v7, 72, 7);
      v8[2] = 1;
      v8[3] = 2;
      v8[7] = &type metadata for Int;
      v8[8] = &protocol witness table for Int;
      v8[4] = 3;
      os_log(_:dso:log:type:_:)("event: %lu", 10);
      swift_bridgeObjectRelease((_BYTE)v8);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v9, type metadata accessor for TrainingTablePrinter);
    }
  }
}

uint64_t ImageClassifierTrainingSessionDelegate.train(from:)()
{
  v1[53] = v0;
  unint64_t v2 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.Classifier?)
                              - 8)
                  + 64)
      + 15) & 0xFFFFFFFFFFFFFFF0;
  v1[54] = swift_task_alloc(v2);
  v1[55] = swift_task_alloc(v2);
  unint64_t v3 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.Model?)
                              - 8)
                  + 64)
      + 15) & 0xFFFFFFFFFFFFFFF0;
  v1[56] = swift_task_alloc(v3);
  v1[57] = swift_task_alloc(v3);
  unint64_t v4 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingTablePrinter?)
                              - 8)
                  + 64)
      + 15) & 0xFFFFFFFFFFFFFFF0;
  v1[58] = swift_task_alloc(v4);
  v1[59] = swift_task_alloc(v4);
  v1[60] = swift_task_alloc(v4);
  uint64_t v5 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  v1[61] = v5;
  v1[62] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  v1[63] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for MLImageClassifier.PersistentParameters(0);
  v1[64] = v7;
  v1[65] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(ImageClassifierTrainingSessionDelegate.train(from:), 0, 0);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t (*v5)();

  unint64_t v3 = *(void *)(*v1 + 560);
  unint64_t v4 = *(void *)(*v1 + 536);
  unint64_t v2 = *v1;
  *(void *)(*v1 + 568) = v0;
  swift_task_dealloc(v3);
  swift_release();
  swift_bridgeObjectRelease(v4);
  if (v0)
  {
    uint64_t v5 = ImageClassifierTrainingSessionDelegate.train(from:);
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v2 + 440), type metadata accessor for MLImageClassifier.Classifier);
    uint64_t v5 = ImageClassifierTrainingSessionDelegate.train(from:);
  }
  return swift_task_switch(v5, 0, 0);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  void *v5;

  uint64_t v1 = v0[53];
  unint64_t v2 = v0[57];
  unint64_t v3 = type metadata accessor for MLImageClassifier.Model(0);
  __swift_storeEnumTagSinglePayload(v2, 0, 1, v3);
  unint64_t v4 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model + v1;
  swift_beginAccess(v4, v0 + 50, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v2, v4, &demangling cache variable for type metadata for MLImageClassifier.Model?);
  swift_endAccess(v0 + 50);
  uint64_t v5 = (void *)swift_task_alloc(dword_3AF4AC);
  v0[75] = v5;
  *uint64_t v5 = v0;
  v5[1] = ImageClassifierTrainingSessionDelegate.train(from:);
  return SoundClassifierTrainingSessionDelegate.buildMetrics(eventCollector:)(v0[68]);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t (*v5)();
  uint64_t v7;

  unint64_t v3 = *(void *)(*v1 + 584);
  unint64_t v4 = *(void *)(*v1 + 528);
  uint64_t v7 = *(void *)(*v1 + 536);
  unint64_t v2 = *v1;
  *(void *)(*v1 + 592) = v0;
  swift_task_dealloc(v3);
  swift_release();
  swift_bridgeObjectRelease(v4);
  swift_bridgeObjectRelease(v7);
  if (v0)
  {
    uint64_t v5 = ImageClassifierTrainingSessionDelegate.train(from:);
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v2 + 432), type metadata accessor for MLImageClassifier.Classifier);
    uint64_t v5 = ImageClassifierTrainingSessionDelegate.train(from:);
  }
  return swift_task_switch(v5, 0, 0);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  void *v5;

  uint64_t v1 = v0[53];
  unint64_t v2 = v0[56];
  unint64_t v3 = type metadata accessor for MLImageClassifier.Model(0);
  __swift_storeEnumTagSinglePayload(v2, 0, 1, v3);
  unint64_t v4 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model + v1;
  swift_beginAccess(v4, v0 + 44, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v2, v4, &demangling cache variable for type metadata for MLImageClassifier.Model?);
  swift_endAccess(v0 + 44);
  uint64_t v5 = (void *)swift_task_alloc(dword_3AF4AC);
  v0[75] = v5;
  *uint64_t v5 = v0;
  v5[1] = ImageClassifierTrainingSessionDelegate.train(from:);
  return SoundClassifierTrainingSessionDelegate.buildMetrics(eventCollector:)(v0[68]);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;

  uint64_t v1 = *(void *)(v0 + 608);
  unint64_t v2 = *(void *)(v0 + 520);
  unint64_t v3 = *(void *)(v0 + 504);
  uint64_t v14 = *(void *)(v0 + 496);
  uint64_t v13 = *(void *)(v0 + 480);
  uint64_t v12 = *(void *)(v0 + 472);
  uint64_t v11 = *(void *)(v0 + 464);
  uint64_t v10 = *(void *)(v0 + 456);
  uint64_t v8 = *(void *)(v0 + 448);
  uint64_t v7 = *(void *)(v0 + 432);
  uint64_t v5 = *(void *)(v2 + *(int *)(*(void *)(v0 + 512) + 32));
  uint64_t v9 = *(void *)(v0 + 440);
  uint64_t v6 = specialized _dictionaryUpCast<A, B, C, D>(_:)(v1);
  swift_bridgeObjectRelease(v1);
  swift_release();
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.PersistentParameters);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v7);
  return (*(uint64_t (**)(uint64_t, void *, uint64_t))(v0 + 8))(v5, v6, 1);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;

  uint64_t v6 = *(void *)(v0 + 432);
  uint64_t v1 = *(void *)(v0 + 440);
  unint64_t v2 = *(void *)(v0 + 520);
  unint64_t v3 = *(void *)(v0 + 504);
  unint64_t v4 = *(void *)(v0 + 496);
  uint64_t v11 = *(void *)(v0 + 480);
  uint64_t v10 = *(void *)(v0 + 472);
  uint64_t v9 = *(void *)(v0 + 464);
  uint64_t v8 = *(void *)(v0 + 456);
  uint64_t v7 = *(void *)(v0 + 448);
  swift_release();
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.PersistentParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLImageClassifier.Classifier);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v1);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;

  uint64_t v1 = *(void *)(v0 + 520);
  unint64_t v2 = *(void *)(v0 + 504);
  unint64_t v3 = *(void *)(v0 + 496);
  uint64_t v11 = *(void *)(v0 + 480);
  uint64_t v10 = *(void *)(v0 + 472);
  uint64_t v9 = *(void *)(v0 + 464);
  uint64_t v8 = *(void *)(v0 + 456);
  uint64_t v7 = *(void *)(v0 + 448);
  unint64_t v4 = *(void *)(v0 + 432);
  uint64_t v6 = *(void *)(v0 + 440);
  swift_release();
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLImageClassifier.PersistentParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v4, type metadata accessor for MLImageClassifier.Classifier);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  swift_task_dealloc(v4);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t ImageClassifierTrainingSessionDelegate.train(from:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v8 = v7[64];
  uint64_t v9 = v7[63];
  uint64_t v10 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters + v7[53];
  swift_beginAccess(v10, v7 + 26, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, v9, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload(v9, 1, v8) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v7[63], &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
    return _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000002CLL, "SessionDelegate.swift" + 0x8000000000000000, "CreateML/ImageClassifierTrainingSessionDelegate.swift", 53, 2, 192, 0);
  }
  else
  {
    uint64_t v12 = v7[53];
    outlined init with take of MLClassifierMetrics(v7[63], v7[65], type metadata accessor for MLImageClassifier.PersistentParameters);
    uint64_t v13 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore;
    long long v62 = (uint64_t *)(v12 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore);
    swift_beginAccess(v12 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore, v7 + 29, 1, 0);
    uint64_t v14 = *(void *)(v12 + v13 + 88);
    uint64_t v15 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore;
    uint64_t v16 = (uint64_t *)(v12 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore);
    swift_beginAccess(v12 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore, v7 + 32, 1, 0);
    BOOL v17 = *(void **)(v12 + v15 + 88);
    if (v17[2])
    {
      swift_bridgeObjectRetain(v14);
      swift_bridgeObjectRetain((_BYTE)v17);
    }
    else
    {
      uint64_t v64 = v16;
      uint64_t v18 = v7[61];
      uint64_t v19 = v7[62];
      outlined init with copy of MLTrainingSessionParameters(v7[65] + *(int *)(v7[64] + 20), v19, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
      int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v19, v18);
      uint64_t v21 = v7[62];
      if (EnumCaseMultiPayload)
      {
        swift_bridgeObjectRetain(v14);
        swift_bridgeObjectRetain((_BYTE)v17);
        outlined destroy of MLActivityClassifier.ModelParameters(v21, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
      }
      else
      {
        uint64_t v22 = *(void *)v21;
        uint64_t v68 = *(void *)(v21 + 8);
        __int16 v23 = *(unsigned __int8 *)(v21 + 16);
        unsigned __int8 v24 = *(unsigned char *)(v21 + 17);
        swift_bridgeObjectRetain(v14);
        long long v69 = specialized Collection.randomSplit<A, B>(strategy:)(v22, v68, v23 | (unsigned __int16)(v24 << 8), v14);
        uint64_t v26 = v25;
        swift_bridgeObjectRelease(v14);
        uint64_t v61 = v26;
        swift_bridgeObjectRetain(v26);
        specialized AnnotatedFeatureStore.init<A>(_:)(v26);
        uint64_t v27 = *v62;
        unint64_t v28 = v62[1];
        uint64_t v29 = v62[10];
        uint64_t v30 = v62[11];
        qmemcpy(v62, v7 + 14, 0x60uLL);
        outlined consume of Data._Representation(v27, v28);
        swift_bridgeObjectRelease(v29);
        swift_bridgeObjectRelease(v30);
        swift_bridgeObjectRetain((_BYTE)v69);
        specialized AnnotatedFeatureStore.init<A>(_:)((uint64_t)v69);
        uint64_t v31 = *v64;
        unint64_t v32 = v64[1];
        uint64_t v33 = v64[10];
        uint64_t v34 = v64[11];
        qmemcpy(v64, v7 + 2, 0x60uLL);
        outlined consume of Data._Representation(v31, v32);
        char v35 = v33;
        BOOL v17 = v69;
        swift_bridgeObjectRelease(v35);
        swift_bridgeObjectRelease(v34);
        uint64_t v14 = v61;
      }
    }
    uint64_t v63 = v14;
    v7[67] = v14;
    uint64_t v70 = v17;
    v7[66] = v17;
    uint64_t v36 = v7[53];
    uint64_t v37 = v7[60];
    uint64_t v38 = type metadata accessor for EventCollector();
    swift_allocObject(v38, 32, 7);
    uint64_t v65 = EventCollector.init()();
    v7[68] = v65;
    uint64_t v39 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_tablePrinter + v36;
    swift_beginAccess(v39, v7 + 35, 0, 0);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v39, v37, &demangling cache variable for type metadata for TrainingTablePrinter?);
    uint64_t v40 = type metadata accessor for TrainingTablePrinter(0);
    int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v37, 1, v40);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v37, &demangling cache variable for type metadata for TrainingTablePrinter?);
    if (EnumTagSinglePayload == 1)
    {
      uint64_t v42 = v7[59];
      uint64_t v66 = v7[58];
      ImageClassifierTrainingSessionDelegate.createTablePrinter()();
      __swift_storeEnumTagSinglePayload(v42, 0, 1, v40);
      swift_beginAccess(v39, v7 + 38, 33, 0);
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v42, v39, &demangling cache variable for type metadata for TrainingTablePrinter?);
      swift_endAccess(v7 + 38);
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v39, v66, &demangling cache variable for type metadata for TrainingTablePrinter?);
      if (__swift_getEnumTagSinglePayload(v66, 1, v40) == 1) {
        BUG();
      }
      uint64_t v43 = v7[58];
      TrainingTablePrinter.beginTable()();
      outlined destroy of MLActivityClassifier.ModelParameters(v43, type metadata accessor for TrainingTablePrinter);
    }
    uint64_t v44 = v7[53];
    if (v70[2])
    {
      uint64_t v45 = v7[54];
      uint64_t v46 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier + v44;
      swift_beginAccess(v46, v7 + 41, 0, 0);
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v46, v45, &demangling cache variable for type metadata for MLImageClassifier.Classifier?);
      uint64_t v47 = type metadata accessor for MLImageClassifier.Classifier(0);
      if (__swift_getEnumTagSinglePayload(v45, 1, v47) == 1) {
        BUG();
      }
      uint64_t v48 = v7[53];
      uint64_t v49 = swift_allocObject(&unk_39DE98, 32, 7);
      v7[72] = v49;
      *(void *)(v49 + 16) = v65;
      *(void *)(v49 + 24) = v48;
      uint64_t v67 = (char *)&async function pointer to specialized MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)
          + async function pointer to specialized MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
      uint64_t v50 = dword_3AF4A4;
      swift_retain();
      swift_retain();
      uint64_t v51 = (void *)swift_task_alloc(v50);
      v7[73] = v51;
      void *v51 = v7;
      v51[1] = ImageClassifierTrainingSessionDelegate.train(from:);
      return ((uint64_t (*)(void, uint64_t, void *, uint64_t (*)(uint64_t, __m128), uint64_t, uint64_t))v67)(v7[56], v63, v70, partial apply for closure #2 in ImageClassifierTrainingSessionDelegate.train(from:), v49, v52);
    }
    else
    {
      uint64_t v53 = v7[55];
      swift_bridgeObjectRelease((_BYTE)v70);
      uint64_t v54 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier + v44;
      swift_beginAccess(v54, v7 + 47, 0, 0);
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v54, v53, &demangling cache variable for type metadata for MLImageClassifier.Classifier?);
      uint64_t v55 = type metadata accessor for MLImageClassifier.Classifier(0);
      if (__swift_getEnumTagSinglePayload(v53, 1, v55) == 1) {
        BUG();
      }
      uint64_t v56 = v7[53];
      uint64_t v57 = swift_allocObject(&unk_39DEC0, 32, 7);
      v7[69] = v57;
      *(void *)(v57 + 16) = v65;
      *(void *)(v57 + 24) = v56;
      int v71 = (char *)&async function pointer to specialized MLImageClassifier.Classifier.fitted<A>(to:eventHandler:)
          + async function pointer to specialized MLImageClassifier.Classifier.fitted<A>(to:eventHandler:);
      uint64_t v58 = dword_3AF4B4;
      swift_retain();
      swift_retain();
      uint64_t v59 = (void *)swift_task_alloc(v58);
      v7[70] = v59;
      void *v59 = v7;
      v59[1] = ImageClassifierTrainingSessionDelegate.train(from:);
      return ((uint64_t (*)(void, uint64_t, uint64_t (*)(uint64_t, __m128), uint64_t, uint64_t))v71)(v7[57], v63, partial apply for closure #1 in ImageClassifierTrainingSessionDelegate.train(from:), v57, v60);
    }
  }
}

uint64_t ImageClassifierTrainingSessionDelegate.train(from:)(uint64_t a1)
{
  uint64_t v2 = *(void *)(*(void *)v1 + 600);
  *(void *)(*(void *)v1 + 608) = a1;
  swift_task_dealloc(v2);
  return swift_task_switch(ImageClassifierTrainingSessionDelegate.train(from:), 0, 0);
}

uint64_t ImageClassifierTrainingSessionDelegate.createTablePrinter()()
{
  uint64_t v20 = v0;
  int64_t v2 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MetricsKey?)
                             - 8)
                 + 64);
  unint64_t v3 = alloca(v2);
  unint64_t v4 = alloca(v2);
  uint64_t v21 = &v17;
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MetricsKey)>);
  uint64_t v6 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, MetricsKey))
                 - 8);
  uint64_t v7 = *(unsigned __int8 *)(v6 + 80);
  uint64_t v8 = ((int)v7 + 32) & ~*(unsigned __int8 *)(v6 + 80);
  uint64_t v9 = swift_allocObject(v5, v8 + *(void *)(v6 + 72), v7 | 7);
  *(void *)(v9 + 16) = 1;
  *(void *)(v9 + 24) = 2;
  *(void *)(v9 + v8) = 0xD000000000000011;
  *(void *)(v9 + v8 + 8) = "eature extractor should be " + 0x8000000000000000;
  static MetricsKey.trainingAccuracy.getter();
  uint64_t v10 = type metadata accessor for MetricsKey(0);
  uint64_t v11 = Dictionary.init(dictionaryLiteral:)(v9, &type metadata for String, v10, &protocol witness table for String);
  uint64_t v19 = v11;
  uint64_t v12 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore;
  swift_beginAccess(OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore + v1, v18, 0, 0);
  if (*(void *)(*(void *)(v1 + v12 + 88) + 16))
  {
    uint64_t v13 = (uint64_t)v21;
    static MetricsKey.validationAccuracy.getter();
    __swift_storeEnumTagSinglePayload(v13, 0, 1, v10);
    specialized Dictionary.subscript.setter(v13, 0xD000000000000013, (uint64_t)("Swift/Array.swift" + 0x8000000000000000));
    uint64_t v11 = v19;
  }
  uint64_t v14 = type metadata accessor for TrainingTablePrinter(0);
  uint64_t v15 = v20;
  *(void *)(v20 + *(int *)(v14 + 24)) = v11;
  type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for OS_os_log, OS_os_log_ptr);
  *(void *)(v15 + *(int *)(v14 + 20)) = OS_os_log.init(subsystem:category:)(0x6C7070612E6D6F63, 0xEE00697275742E65, 0x72705F656C626174, 0xED00007265746E69);
  return Date.init()(0x6C7070612E6D6F63);
}

uint64_t closure #1 in ImageClassifierTrainingSessionDelegate.train(from:)(uint64_t a1, __m128 a2, uint64_t a3, uint64_t a4)
{
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingTablePrinter?)
                             - 8)
                 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  EventCollector.add(_:)();
  uint64_t v8 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_tablePrinter + a4;
  swift_beginAccess(v8, v11, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v8, (uint64_t)v11, &demangling cache variable for type metadata for TrainingTablePrinter?);
  uint64_t v9 = type metadata accessor for TrainingTablePrinter(0);
  if (__swift_getEnumTagSinglePayload((uint64_t)v11, 1, v9) == 1) {
    BUG();
  }
  TrainingTablePrinter.print(_:)(a1, a2);
  return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v11, type metadata accessor for TrainingTablePrinter);
}

uint64_t ImageClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)(uint64_t *a1, unsigned __int8 *a2)
{
  uint64_t v50 = v2;
  uint64_t v46 = v3;
  uint64_t v48 = a1;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.Model?)
                             - 8)
                 + 64);
  int64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v47 = &v40;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.Classifier?)
                             - 8)
                 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v49 = &v40;
  unsigned int v10 = 0;
  uint64_t v51 = type metadata accessor for URL(0);
  uint64_t v11 = *(void *)(v51 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v15 = alloca(v12);
  uint64_t v16 = alloca(v12);
  uint64_t v17 = alloca(v12);
  uint64_t v18 = alloca(v12);
  uint64_t v19 = alloca(v12);
  uint64_t v20 = alloca(v12);
  int v21 = *a2;
  if (v21 == 2)
  {
    URL.appendingPathComponent(_:)(0x6C65646F6DLL, 0xE500000000000000);
    uint64_t v48 = &v40;
    URL.appendingPathExtension(_:)(6777712, 0xE300000000000000);
    uint64_t v45 = *(void (**)(uint64_t *, uint64_t))(v11 + 8);
    v45(&v40, v51);
    uint64_t v24 = v46;
    uint64_t v25 = v46 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier;
    swift_beginAccess(v46 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier, v43, 0, 0);
    uint64_t v26 = (uint64_t)v49;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v25, (uint64_t)v49, &demangling cache variable for type metadata for MLImageClassifier.Classifier?);
    uint64_t v27 = type metadata accessor for MLImageClassifier.Classifier(0);
    if (__swift_getEnumTagSinglePayload(v26, 1, v27) == 1) {
      BUG();
    }
    uint64_t v28 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model + v24;
    swift_beginAccess(v28, v44, 0, 0);
    uint64_t v29 = v28;
    uint64_t v30 = (uint64_t)v47;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v29, (uint64_t)v47, &demangling cache variable for type metadata for MLImageClassifier.Model?);
    uint64_t v31 = type metadata accessor for MLImageClassifier.Model(0);
    if (__swift_getEnumTagSinglePayload(v30, 1, v31) == 1) {
      BUG();
    }
    uint64_t v32 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLImageClassifier.Classifier and conformance MLImageClassifier.Classifier, type metadata accessor for MLImageClassifier.Classifier, (uint64_t)&protocol conformance descriptor for MLImageClassifier.Classifier);
    uint64_t v33 = v48;
    uint64_t v34 = v27;
    unsigned int v10 = v30;
    uint64_t v35 = (uint64_t)v49;
    uint64_t v36 = v50;
    UpdatableSupervisedEstimator.writeWithOptimizer(_:to:overwrite:)(v30, v48, 1, v34, v32);
    if (v36)
    {
      v45(v33, v51);
      outlined destroy of MLActivityClassifier.ModelParameters(v30, type metadata accessor for MLImageClassifier.Model);
      outlined destroy of MLActivityClassifier.ModelParameters(v35, type metadata accessor for MLImageClassifier.Classifier);
      return v10;
    }
    v45(v33, v51);
    outlined destroy of MLActivityClassifier.ModelParameters(v30, type metadata accessor for MLImageClassifier.Model);
    outlined destroy of MLActivityClassifier.ModelParameters(v35, type metadata accessor for MLImageClassifier.Classifier);
LABEL_12:
    LOBYTE(v10) = 1;
    return v10;
  }
  if (v21 != 1) {
    return v10;
  }
  uint64_t v49 = *(uint64_t **)(v51 - 8);
  uint64_t v47 = &v40;
  uint64_t v22 = (const void *)(v46 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore);
  swift_beginAccess(v46 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore, v43, 0, 0);
  qmemcpy(v41, v22, sizeof(v41));
  outlined retain of AnnotatedFeatureStore(v41);
  unsigned int v10 = v48;
  URL.appendingPathComponent(_:isDirectory:)(0x676E696E69617274, 0xE800000000000000, 1);
  __int16 v23 = v50;
  AnnotatedFeatureStore.write(to:)((uint64_t)&v40);
  if (!v23)
  {
    uint64_t v50 = (void (*)(void, void))v49[1];
    v50(&v40, v51);
    outlined release of AnnotatedFeatureStore(v41);
    uint64_t v37 = (const void *)(OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore + v46);
    swift_beginAccess(OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore + v46, v44, 0, 0);
    qmemcpy(v42, v37, sizeof(v42));
    outlined retain of AnnotatedFeatureStore(v42);
    uint64_t v38 = (uint64_t)v47;
    URL.appendingPathComponent(_:isDirectory:)(0x69746164696C6176, 0xEA00000000006E6FLL, 1);
    AnnotatedFeatureStore.write(to:)(v38);
    v50(v38, v51);
    outlined release of AnnotatedFeatureStore(v42);
    goto LABEL_12;
  }
  ((void (*)(uint64_t *, uint64_t))v49[1])(&v40, v51);
  outlined release of AnnotatedFeatureStore(v41);
  return v10;
}

uint64_t ImageClassifierTrainingSessionDelegate.save(to:)(uint64_t a1)
{
  uint64_t v19 = v1;
  uint64_t v20 = a1;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  int64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  uint64_t v6 = type metadata accessor for MLImageClassifier.PersistentParameters(0);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters + v2;
  swift_beginAccess(v10, v18, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, (uint64_t)&v17, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v17, 1, v6) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v17, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
    uint64_t v11 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v11, 0, 0);
    *(void *)uint64_t v12 = 0xD000000000000031;
    *(void *)(v12 + 8) = "Selected features" + 0x8000000000000000;
    *(_OWORD *)(v12 + 16) = 0;
    *(_OWORD *)(v12 + 32) = 0;
    *(unsigned char *)(v12 + 48) = 2;
    return swift_willThrow(&type metadata for MLCreateError, v11, v12, v13, v14, v15);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)&v17, (uint64_t)&v17, type metadata accessor for MLImageClassifier.PersistentParameters);
    MLImageClassifier.PersistentParameters.save(toSessionDirectory:)(v20);
    return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v17, type metadata accessor for MLImageClassifier.PersistentParameters);
  }
}

NSURL *ImageClassifierTrainingSessionDelegate.restore(from:phase:)(uint64_t a1, unsigned char *a2)
{
  uint64_t v28 = v2;
  uint64_t v30 = v3;
  uint64_t v35 = a2;
  uint64_t v29 = a1;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  int64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v32 = v26;
  int64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  uint64_t v31 = v26;
  uint64_t v9 = type metadata accessor for URL(0);
  uint64_t v10 = *(void *)(v9 - 8);
  int64_t v11 = *(void *)(v10 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v34 = type metadata accessor for MLImageClassifier.PersistentParameters(0);
  int64_t v14 = *(void *)(*(void *)(v34 - 8) + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v33 = v26;
  uint64_t v17 = alloca(v14);
  uint64_t v18 = alloca(v14);
  LOBYTE(v35) = *v35;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v10 + 16))(v26, v29, v9);
  uint64_t v19 = v28;
  uint64_t result = MLImageClassifier.PersistentParameters.init(sessionDirectory:)((uint64_t)v26);
  if (!v19)
  {
    uint64_t v21 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters + v30;
    swift_beginAccess(OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters + v30, v26, 0, 0);
    uint64_t v22 = (uint64_t)v31;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v21, (uint64_t)v31, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
    if (__swift_getEnumTagSinglePayload(v22, 1, v34) == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v22, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
      uint64_t v23 = (uint64_t)v32;
      outlined init with take of MLClassifierMetrics((uint64_t)v26, (uint64_t)v32, type metadata accessor for MLImageClassifier.PersistentParameters);
      __swift_storeEnumTagSinglePayload(v23, 0, 1, v34);
      swift_beginAccess(v21, v27, 33, 0);
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v23, v21, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
      return (NSURL *)swift_endAccess(v27);
    }
    else
    {
      uint64_t v24 = v22;
      uint64_t v25 = (uint64_t)v33;
      outlined init with take of MLClassifierMetrics(v24, (uint64_t)v33, type metadata accessor for MLImageClassifier.PersistentParameters);
      v27[0] = v35;
      ImageClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:phase:)(v26, v25, v27);
      outlined destroy of MLActivityClassifier.ModelParameters(v25, type metadata accessor for MLImageClassifier.PersistentParameters);
      return (NSURL *)outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v26, type metadata accessor for MLImageClassifier.PersistentParameters);
    }
  }
  return result;
}

char ImageClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:phase:)(uint64_t *a1, uint64_t a2, unsigned __int8 *a3)
{
  uint64_t v89 = v3;
  uint64_t v96 = a2;
  uint64_t v88 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
  int64_t v5 = *(void *)(*(void *)(v88 - 8) + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v87 = v82;
  uint64_t v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v86 = v82;
  uint64_t v10 = alloca(v5);
  int64_t v11 = alloca(v5);
  uint64_t v95 = v82;
  uint64_t v12 = alloca(v5);
  uint64_t v13 = alloca(v5);
  uint64_t v94 = v82;
  uint64_t v93 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  int64_t v14 = *(void *)(*(void *)(v93 - 8) + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v84 = v82;
  uint64_t v17 = alloca(v14);
  uint64_t v18 = alloca(v14);
  unint64_t v85 = v82;
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLImageClassifier.FeatureExtractorType, MLImageClassifier.FeatureExtractorType));
  int64_t v20 = *(void *)(*(void *)(v19 - 8) + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  int v92 = *a3;
  uint64_t v90 = (int *)type metadata accessor for MLImageClassifier.PersistentParameters(0);
  uint64_t v23 = v90[6];
  uint64_t v91 = a1;
  uint64_t v24 = (uint64_t)a1 + v23;
  uint64_t v25 = v96 + v23;
  uint64_t v26 = &v82[*(int *)(v19 + 48)];
  outlined init with copy of MLTrainingSessionParameters(v24, (uint64_t)v82, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v27 = v25;
  uint64_t v28 = v93;
  outlined init with copy of MLTrainingSessionParameters(v27, (uint64_t)v26, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v97 = v82;
  if (swift_getEnumCaseMultiPayload(v82, v28) == 1)
  {
    uint64_t v29 = (uint64_t)v84;
    outlined init with copy of MLTrainingSessionParameters((uint64_t)v97, (uint64_t)v84, type metadata accessor for MLImageClassifier.FeatureExtractorType);
    if (swift_getEnumCaseMultiPayload(v26, v28) == 1)
    {
      uint64_t v30 = v29;
      uint64_t v31 = (uint64_t)v94;
      outlined init with take of MLClassifierMetrics(v30, (uint64_t)v94, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
      uint64_t v32 = (uint64_t)v95;
      outlined init with take of MLClassifierMetrics((uint64_t)v26, (uint64_t)v95, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
      uint64_t v33 = type metadata accessor for URL(0);
      uint64_t v34 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type URL and conformance URL, (uint64_t (*)(uint64_t))&type metadata accessor for URL, (uint64_t)&protocol conformance descriptor for URL);
      char v35 = dispatch thunk of static Equatable.== infix(_:_:)(v31, v32, v33, v34);
      uint64_t v36 = (uint64_t)v86;
      outlined init with copy of MLTrainingSessionParameters(v31, (uint64_t)v86, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
      uint64_t v37 = v32;
      uint64_t v38 = (uint64_t)v87;
      outlined init with copy of MLTrainingSessionParameters(v37, (uint64_t)v87, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
      if (v35)
      {
        uint64_t v39 = *(int *)(v88 + 20);
        uint64_t v40 = *(void *)(v36 + v39 + 8);
        uint64_t v41 = *(void *)(v38 + v39 + 8);
        if (v40)
        {
          if (v41)
          {
            uint64_t v42 = *(void *)(v36 + v39);
            uint64_t v43 = *(void *)(v38 + v39);
            if (v42 == v43 && v40 == v41)
            {
              swift_bridgeObjectRetain(*(void *)(v36 + v39 + 8));
              outlined destroy of MLActivityClassifier.ModelParameters(v38, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
              outlined destroy of MLActivityClassifier.ModelParameters(v36, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
              swift_bridgeObjectRelease(v40);
LABEL_25:
              outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v95, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
              outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v94, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
              goto LABEL_26;
            }
            char v64 = _stringCompareWithSmolCheck(_:_:expecting:)(v42, *(void *)(v36 + v39 + 8), v43, *(void *)(v38 + v39 + 8), 0);
            swift_bridgeObjectRetain(v40);
            outlined destroy of MLActivityClassifier.ModelParameters(v38, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
            outlined destroy of MLActivityClassifier.ModelParameters(v36, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
            swift_bridgeObjectRelease(v40);
            if (v64) {
              goto LABEL_25;
            }
            goto LABEL_22;
          }
          swift_bridgeObjectRetain(*(void *)(v36 + v39 + 8));
          outlined destroy of MLActivityClassifier.ModelParameters(v38, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
          outlined destroy of MLActivityClassifier.ModelParameters(v36, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
          char v58 = v40;
        }
        else
        {
          swift_bridgeObjectRetain(*(void *)(v38 + v39 + 8));
          outlined destroy of MLActivityClassifier.ModelParameters(v38, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
          outlined destroy of MLActivityClassifier.ModelParameters(v36, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
          if (!v41) {
            goto LABEL_25;
          }
          char v58 = v41;
        }
        swift_bridgeObjectRelease(v58);
      }
      else
      {
        outlined destroy of MLActivityClassifier.ModelParameters(v38, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
        outlined destroy of MLActivityClassifier.ModelParameters(v36, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
      }
LABEL_22:
      uint64_t v59 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v59, 0, 0);
      *(void *)uint64_t v60 = 0xD000000000000032;
      *(void *)(v60 + 8) = "ers should be loaded by now." + 0x8000000000000000;
      *(_OWORD *)(v60 + 16) = 0;
      *(_OWORD *)(v60 + 32) = 0;
      *(unsigned char *)(v60 + 48) = 0;
      swift_willThrow(&type metadata for MLCreateError, v59, v60, v61, v62, v63);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v95, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v94, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
      return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v97, type metadata accessor for MLImageClassifier.FeatureExtractorType);
    }
    outlined destroy of MLActivityClassifier.ModelParameters(v29, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
LABEL_14:
    uint64_t v47 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v47, 0, 0);
    *(void *)uint64_t v48 = 0xD000000000000032;
    *(void *)(v48 + 8) = "ers should be loaded by now." + 0x8000000000000000;
    *(_OWORD *)(v48 + 16) = 0;
    *(_OWORD *)(v48 + 32) = 0;
    *(unsigned char *)(v48 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v47, v48, v49, v50, v51);
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v97, &demangling cache variable for type metadata for (MLImageClassifier.FeatureExtractorType, MLImageClassifier.FeatureExtractorType));
  }
  uint64_t v44 = (uint64_t)v85;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v97, (uint64_t)v85, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v45 = *(void *)v44;
  if (swift_getEnumCaseMultiPayload(v26, v28) == 1) {
    goto LABEL_14;
  }
  char v46 = v26[8];
  if (*(unsigned char *)(v44 + 8))
  {
    if (v46) {
      goto LABEL_26;
    }
    goto LABEL_17;
  }
  if ((v45 != *(void *)v26) | v46 & 1)
  {
LABEL_17:
    uint64_t v53 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v53, 0, 0);
    *(void *)uint64_t v54 = 0xD000000000000032;
    *(void *)(v54 + 8) = "ers should be loaded by now." + 0x8000000000000000;
    *(_OWORD *)(v54 + 16) = 0;
    *(_OWORD *)(v54 + 32) = 0;
    *(unsigned char *)(v54 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v53, v54, v55, v56, v57);
    return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v97, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  }
LABEL_26:
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v97, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v65 = v90[8];
  uint64_t v66 = v91;
  uint64_t v67 = *(unsigned char **)((char *)v91 + v65);
  uint64_t v68 = (uint64_t *)v96;
  uint64_t v97 = *(unsigned char **)(v96 + v65);
  if (v67 == v97) {
    goto LABEL_34;
  }
  unint64_t v69 = 0xEB0000000064657ALL;
  switch(v92)
  {
    case 0:
      uint64_t v70 = 0x696C616974696E69;
      break;
    case 1:
      swift_bridgeObjectRelease(110);
      goto LABEL_34;
    case 2:
      uint64_t v70 = 0x676E696E69617274;
      unint64_t v69 = 0xE800000000000000;
      break;
    case 3:
      uint64_t v70 = 0x697461756C617665;
      unint64_t v69 = 0xEA0000000000676ELL;
      break;
    case 4:
      unint64_t v69 = 0xEB00000000676E69;
      uint64_t v70 = 0x636E657265666E69;
      break;
  }
  char v71 = _stringCompareWithSmolCheck(_:_:expecting:)(v70, v69, 0x6974636172747865, 0xEA0000000000676ELL, 0);
  swift_bridgeObjectRelease(v69);
  BOOL v72 = (v71 & 1) == 0;
  uint64_t v66 = v91;
  if (v72)
  {
    uint64_t v83 = (uint64_t)v67;
    uint64_t v96 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    uint64_t v93 = v78;
    uint64_t v83 = (uint64_t)v97;
    uint64_t v79 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    uint64_t v81 = v80;
    uint64_t v73 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v73, 0, 0);
    *(void *)uint64_t v74 = 0x657449202E78614DLL;
    *(void *)(v74 + 8) = 0xEF736E6F69746172;
    *(void *)(v74 + 16) = v96;
    *(void *)(v74 + 24) = v93;
    *(void *)(v74 + 32) = v79;
    *(void *)(v74 + 40) = v81;
    *(unsigned char *)(v74 + 48) = 3;
  }
  else
  {
LABEL_34:
    if (*(uint64_t *)((char *)v66 + v90[9]) == *(uint64_t *)((char *)v68 + v90[9]))
    {
      char result = specialized static Dictionary<>.== infix(_:_:)(*v66, *v68);
      if (result) {
        return result;
      }
      uint64_t v73 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v73, 0, 0);
      *(void *)uint64_t v74 = 1;
      *(_OWORD *)(v74 + 8) = 0;
      *(_OWORD *)(v74 + 24) = 0;
      *(void *)(v74 + 40) = 0;
      *(unsigned char *)(v74 + 48) = 4;
    }
    else
    {
      uint64_t v73 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v73, 0, 0);
      *(void *)uint64_t v74 = 0xD000000000000035;
      *(void *)(v74 + 8) = "extractor changed." + 0x8000000000000000;
      *(_OWORD *)(v74 + 16) = 0;
      *(_OWORD *)(v74 + 32) = 0;
      *(unsigned char *)(v74 + 48) = 0;
    }
  }
  return swift_willThrow(&type metadata for MLCreateError, v73, v74, v75, v76, v77);
}

uint64_t ImageClassifierTrainingSessionDelegate.evaluate(from:)()
{
  v1[69] = v0;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationMetrics<String>);
  v1[70] = v2;
  uint64_t v3 = *(void *)(v2 - 8);
  v1[71] = v3;
  v1[72] = swift_task_alloc((*(void *)(v3 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  v1[73] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0);
  v1[74] = v5;
  unint64_t v6 = (*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v1[75] = swift_task_alloc(v6);
  v1[76] = swift_task_alloc(v6);
  uint64_t v7 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  v1[77] = v7;
  unint64_t v8 = (*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v1[78] = swift_task_alloc(v8);
  v1[79] = swift_task_alloc(v8);
  uint64_t v9 = type metadata accessor for ImageReader(0);
  v1[80] = v9;
  uint64_t v10 = *(void *)(v9 - 8);
  v1[81] = v10;
  v1[82] = swift_task_alloc((*(void *)(v10 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLClassifierMetrics?);
  v1[83] = swift_task_alloc((*(void *)(*(void *)(v11 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  v1[84] = swift_task_alloc((*(void *)(*(void *)(v12 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v13 = type metadata accessor for MLImageClassifier.PersistentParameters(0);
  v1[85] = v13;
  v1[86] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.Model?);
  v1[87] = swift_task_alloc((*(void *)(*(void *)(v14 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v15 = type metadata accessor for MLImageClassifier.Model(0);
  v1[88] = v15;
  v1[89] = swift_task_alloc((*(void *)(*(void *)(v15 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(ImageClassifierTrainingSessionDelegate.evaluate(from:), 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  char *v19;
  uint64_t v20;
  void *v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v1 = *(void *)(v0 + 704);
  uint64_t v2 = *(void *)(v0 + 696);
  uint64_t v3 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model + *(void *)(v0 + 552);
  swift_beginAccess(v3, v0 + 296, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v3, v2, &demangling cache variable for type metadata for MLImageClassifier.Model?);
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    uint64_t v4 = *(void *)(v0 + 696);
    uint64_t v5 = &demangling cache variable for type metadata for MLImageClassifier.Model?;
LABEL_5:
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v4, v5);
    uint64_t v11 = *(void *)(v0 + 696);
    uint64_t v12 = *(void *)(v0 + 688);
    uint64_t v13 = *(void *)(v0 + 672);
    uint64_t v14 = *(void *)(v0 + 664);
    uint64_t v28 = *(void *)(v0 + 656);
    uint64_t v27 = *(void *)(v0 + 632);
    uint64_t v26 = *(void *)(v0 + 624);
    uint64_t v25 = *(void *)(v0 + 608);
    uint64_t v24 = *(void *)(v0 + 600);
    uint64_t v22 = *(void *)(v0 + 576);
    uint64_t v23 = *(void *)(v0 + 584);
    swift_task_dealloc(*(void *)(v0 + 712));
    swift_task_dealloc(v11);
    swift_task_dealloc(v12);
    swift_task_dealloc(v13);
    swift_task_dealloc(v14);
    swift_task_dealloc(v28);
    swift_task_dealloc(v27);
    swift_task_dealloc(v26);
    swift_task_dealloc(v25);
    swift_task_dealloc(v24);
    swift_task_dealloc(v23);
    swift_task_dealloc(v22);
    return (*(uint64_t (**)(void, uint64_t))(v0 + 8))(0, 1);
  }
  unint64_t v6 = *(void *)(v0 + 680);
  uint64_t v7 = *(void *)(v0 + 552);
  unint64_t v8 = *(void *)(v0 + 672);
  outlined init with take of MLClassifierMetrics(*(void *)(v0 + 696), *(void *)(v0 + 712), type metadata accessor for MLImageClassifier.Model);
  uint64_t v9 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters + v7;
  swift_beginAccess(v9, v0 + 320, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v9, v8, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload(v8, 1, v6) == 1)
  {
    uint64_t v10 = *(void *)(v0 + 672);
    outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 712), type metadata accessor for MLImageClassifier.Model);
    uint64_t v5 = &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?;
    uint64_t v4 = v10;
    goto LABEL_5;
  }
  uint64_t v16 = *(void *)(v0 + 552);
  outlined init with take of MLClassifierMetrics(*(void *)(v0 + 672), *(void *)(v0 + 688), type metadata accessor for MLImageClassifier.PersistentParameters);
  uint64_t v17 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore;
  *(void *)(v0 + 720) = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore;
  swift_beginAccess(v16 + v17, v0 + 344, 0, 0);
  uint64_t v18 = *(void *)(v16 + v17 + 88);
  *(void *)(v0 + 728) = v18;
  uint64_t v19 = (char *)&async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:)
      + async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:);
  int64_t v20 = dword_3A74E4;
  swift_bridgeObjectRetain(v18);
  uint64_t v21 = (void *)swift_task_alloc(v20);
  *(void *)(v0 + 736) = v21;
  void *v21 = v0;
  v21[1] = ImageClassifierTrainingSessionDelegate.evaluate(from:);
  return ((uint64_t (*)(uint64_t, void, void))v19)(v18, 0, 0);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  void *MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  char *v14;
  uint64_t v15;
  void *v16;
  uint64_t v18;
  uint64_t v19;

  uint64_t v1 = v0[94];
  uint64_t v19 = v0[90];
  uint64_t v18 = v0[83];
  uint64_t v2 = v0[69];
  MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v1, (uint64_t)(v0 + 61), &demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>, (uint64_t)&unk_3522A8);
  swift_bridgeObjectRelease(v1);
  v0[62] = MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
  uint64_t v4 = *(void *)(v2 + v19 + 88);
  swift_bridgeObjectRetain(v4);
  uint64_t v5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v4, (uint64_t)(v0 + 63), &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>, (uint64_t)&unk_352270);
  swift_bridgeObjectRelease(v4);
  v0[64] = v5;
  unint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  v0[95] = v6;
  uint64_t v7 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [String] and conformance [A], &demangling cache variable for type metadata for [String], (uint64_t)&protocol conformance descriptor for [A]);
  v0[96] = v7;
  ClassificationMetrics.init<A, B>(_:_:)(v0 + 62, v0 + 64, &type metadata for String, v6, v6, &protocol witness table for String, v7, v7);
  unint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
  v0[97] = v8;
  swift_storeEnumTagMultiPayload(v18, v8, 0);
  uint64_t v9 = type metadata accessor for MLClassifierMetrics.Contents(0);
  v0[98] = v9;
  swift_storeEnumTagMultiPayload(v18, v9, 0);
  uint64_t v10 = type metadata accessor for MLClassifierMetrics(0);
  v0[99] = v10;
  __swift_storeEnumTagSinglePayload(v18, 0, 1, v10);
  uint64_t v11 = v2 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingMetrics;
  swift_beginAccess(v2 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingMetrics, v0 + 46, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v18, v11, &demangling cache variable for type metadata for MLClassifierMetrics?);
  swift_endAccess(v0 + 46);
  ImageReader.init()();
  uint64_t v12 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFiles;
  v0[100] = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFiles;
  uint64_t v13 = *(void *)(v2 + v12);
  v0[101] = v13;
  uint64_t v14 = (char *)&async function pointer to specialized Transformer.applied<A, B>(to:eventHandler:)
      + async function pointer to specialized Transformer.applied<A, B>(to:eventHandler:);
  uint64_t v15 = dword_3AF47C;
  swift_bridgeObjectRetain(v13);
  uint64_t v16 = (void *)swift_task_alloc(v15);
  v0[102] = v16;
  *uint64_t v16 = v0;
  v16[1] = ImageClassifierTrainingSessionDelegate.evaluate(from:);
  return ((uint64_t (*)(uint64_t, void, void))v14)(v13, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  char *v5;
  uint64_t v6;
  void *v7;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  int *v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  void *boxed_opaque_existential_1;
  void *v25;
  void *v26;
  uint64_t v27;
  void *v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  void *v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;

  uint64_t v1 = *(void *)(v0 + 552);
  if (!*(void *)(*(void *)(v1 + *(void *)(v0 + 800)) + 16)) {
    goto LABEL_4;
  }
  uint64_t v2 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore;
  *(void *)(v0 + 840) = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore;
  swift_beginAccess(v1 + v2, v0 + 392, 1, 0);
  if (*(void *)(*(void *)(v1 + v2 + 88) + 16))
  {
    uint64_t v1 = *(void *)(v0 + 552);
LABEL_4:
    swift_bridgeObjectRelease(*(void *)(v0 + 824));
    uint64_t v3 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore;
    *(void *)(v0 + 888) = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore;
    swift_beginAccess(v1 + v3, v0 + 416, 0, 0);
    uint64_t v4 = *(void *)(v1 + v3 + 88);
    *(void *)(v0 + 896) = v4;
    if (*(void *)(v4 + 16))
    {
      uint64_t v5 = (char *)&async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:)
         + async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:);
      unint64_t v6 = dword_3A74E4;
      swift_bridgeObjectRetain(v4);
      uint64_t v7 = (void *)swift_task_alloc(v6);
      *(void *)(v0 + 904) = v7;
      *uint64_t v7 = v0;
      v7[1] = ImageClassifierTrainingSessionDelegate.evaluate(from:);
      return ((uint64_t (*)(uint64_t, void, void))v5)(v4, 0, 0);
    }
    else
    {
      uint64_t v9 = *(void *)(v0 + 792);
      uint64_t v10 = *(void *)(v0 + 712);
      uint64_t v11 = *(void *)(v0 + 552);
      uint64_t v12 = *(void *)(v0 + 664);
      outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 688), type metadata accessor for MLImageClassifier.PersistentParameters);
      outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLImageClassifier.Model);
      __swift_storeEnumTagSinglePayload(v12, 1, 1, v9);
      uint64_t v13 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationMetrics + v11;
      swift_beginAccess(v13, v0 + 464, 33, 0);
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v12, v13, &demangling cache variable for type metadata for MLClassifierMetrics?);
      swift_endAccess(v0 + 464);
      uint64_t v14 = *(void *)(v0 + 696);
      uint64_t v15 = *(void *)(v0 + 688);
      uint64_t v16 = *(void *)(v0 + 672);
      uint64_t v17 = *(void *)(v0 + 664);
      uint64_t v41 = *(void *)(v0 + 656);
      uint64_t v39 = *(void *)(v0 + 632);
      uint64_t v37 = *(void *)(v0 + 624);
      uint64_t v36 = *(void *)(v0 + 608);
      uint64_t v34 = *(void *)(v0 + 600);
      uint64_t v43 = *(void *)(v0 + 576);
      uint64_t v33 = *(void *)(v0 + 584);
      swift_task_dealloc(*(void *)(v0 + 712));
      swift_task_dealloc(v14);
      swift_task_dealloc(v15);
      swift_task_dealloc(v16);
      swift_task_dealloc(v17);
      swift_task_dealloc(v41);
      swift_task_dealloc(v39);
      swift_task_dealloc(v37);
      swift_task_dealloc(v36);
      swift_task_dealloc(v34);
      swift_task_dealloc(v33);
      swift_task_dealloc(v43);
      return (*(uint64_t (**)(uint64_t, uint64_t))(v0 + 8))(1, 1);
    }
  }
  uint64_t v38 = (void *)(v0 + 264);
  uint64_t v28 = (void *)(v0 + 232);
  uint64_t v18 = *(void *)(v0 + 688);
  uint64_t v19 = *(int **)(v0 + 680);
  uint64_t v44 = *(void *)(v0 + 632);
  uint64_t v30 = *(void *)(v0 + 624);
  uint64_t v29 = *(void *)(v0 + 616);
  int64_t v20 = *(void *)(v0 + 608);
  uint64_t v42 = *(void *)(v0 + 600);
  char v35 = *(void *)(v0 + 584);
  uint64_t v27 = *(void *)(v0 + 592);
  outlined init with copy of MLTrainingSessionParameters(v18 + v19[5], v44, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  uint64_t v31 = *(void *)(v18 + v19[8]);
  uint64_t v32 = *(void *)(v18 + v19[9]);
  uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType));
  uint64_t v21 = *(int *)(v40 + 48);
  outlined init with copy of MLTrainingSessionParameters(v18 + v19[6], v20, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v22 = *(void *)(v18 + v19[7]);
  uint64_t v23 = 0;
  if (v22 != 2) {
    uint64_t v23 = v22;
  }
  *(void *)(v20 + v21) = v23;
  *(_OWORD *)(v0 + 176) = 0;
  *(_OWORD *)(v0 + 160) = 0;
  *(_OWORD *)(v0 + 144) = 0;
  *(_OWORD *)(v0 + 128) = 0;
  *(void *)(v0 + 112) = v31;
  *(void *)(v0 + 120) = v32;
  outlined init with copy of MLTrainingSessionParameters(v44, v30, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  *(void *)(v0 + 256) = v29;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v28);
  outlined init with take of MLClassifierMetrics(v30, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined copy of MLImageClassifier.ModelParameters.ClassifierType?(v22);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v28, v0 + 128, &demangling cache variable for type metadata for Any?);
  outlined init with copy of MLTrainingSessionParameters(v20, v42, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  *(void *)(v0 + 288) = v27;
  uint64_t v25 = __swift_allocate_boxed_opaque_existential_1(v38);
  outlined init with take of MLClassifierMetrics(v42, (uint64_t)v25, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v38, v0 + 160, &demangling cache variable for type metadata for Any?);
  outlined destroy of MLActivityClassifier.ModelParameters(v20, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  outlined destroy of MLActivityClassifier.ModelParameters(v44, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  MLImageClassifier.ModelParameters.algorithm.getter(v44);
  swift_bridgeObjectRelease(*(void *)(v42 + *(int *)(v40 + 48)));
  outlined init with take of MLClassifierMetrics(v42, v35, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  outlined destroy of MLImageClassifier.ModelParameters(v0 + 112);
  uint64_t v26 = (void *)swift_task_alloc(dword_3AEB5C);
  *(void *)(v0 + 848) = v26;
  unsigned char *v26 = v0;
  v26[1] = ImageClassifierTrainingSessionDelegate.evaluate(from:);
  return MLImageClassifier.FeatureExtractor.init(type:)(v0 + 192, *(void *)(v0 + 584));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  void *v3;
  uint64_t (*v5)(void);
  void *v6;

  uint64_t v2 = *(void *)(*(void *)v1 + 848);
  uint64_t v3 = *(void **)v1;
  v3[107] = v0;
  swift_task_dealloc(v2);
  if (v0)
  {
    swift_bridgeObjectRelease(v3[103]);
    return swift_task_switch(ImageClassifierTrainingSessionDelegate.evaluate(from:), 0, 0);
  }
  else
  {
    uint64_t v5 = (uint64_t (*)(void))((char *)&async function pointer to specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:)
                                        + async function pointer to specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:));
    unint64_t v6 = (void *)swift_task_alloc(dword_3AF484);
    v3[108] = v6;
    *unint64_t v6 = v3;
    v6[1] = ImageClassifierTrainingSessionDelegate.evaluate(from:);
    return v5(v3[103]);
  }
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  unint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  char *v8;
  uint64_t v9;
  void *v10;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;

  uint64_t v1 = (uint64_t *)(*(void *)(v0 + 840) + *(void *)(v0 + 552));
  specialized AnnotatedFeatureStore.init<A>(_:)(*(void *)(v0 + 880));
  uint64_t v2 = *v1;
  uint64_t v3 = v1[1];
  uint64_t v26 = v1[10];
  uint64_t v4 = v1[11];
  qmemcpy(v1, (const void *)(v0 + 16), 0x60uLL);
  outlined consume of Data._Representation(v2, v3);
  swift_bridgeObjectRelease(v4);
  uint64_t v5 = *(void *)(v0 + 552);
  swift_bridgeObjectRelease(v26);
  unint64_t v6 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore;
  *(void *)(v0 + 888) = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore;
  swift_beginAccess(v6 + v5, v0 + 416, 0, 0);
  uint64_t v7 = *(void *)(v5 + v6 + 88);
  *(void *)(v0 + 896) = v7;
  if (*(void *)(v7 + 16))
  {
    unint64_t v8 = (char *)&async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:)
       + async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:);
    uint64_t v9 = dword_3A74E4;
    swift_bridgeObjectRetain(v7);
    uint64_t v10 = (void *)swift_task_alloc(v9);
    *(void *)(v0 + 904) = v10;
    void *v10 = v0;
    v10[1] = ImageClassifierTrainingSessionDelegate.evaluate(from:);
    return ((uint64_t (*)(uint64_t, void, void))v8)(v7, 0, 0);
  }
  else
  {
    uint64_t v12 = *(void *)(v0 + 792);
    uint64_t v13 = *(void *)(v0 + 712);
    uint64_t v14 = *(void *)(v0 + 552);
    uint64_t v15 = *(void *)(v0 + 664);
    outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 688), type metadata accessor for MLImageClassifier.PersistentParameters);
    outlined destroy of MLActivityClassifier.ModelParameters(v13, type metadata accessor for MLImageClassifier.Model);
    __swift_storeEnumTagSinglePayload(v15, 1, 1, v12);
    uint64_t v16 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationMetrics + v14;
    swift_beginAccess(v16, v0 + 464, 33, 0);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v15, v16, &demangling cache variable for type metadata for MLClassifierMetrics?);
    swift_endAccess(v0 + 464);
    uint64_t v17 = *(void *)(v0 + 696);
    uint64_t v18 = *(void *)(v0 + 688);
    uint64_t v19 = *(void *)(v0 + 672);
    int64_t v20 = *(void *)(v0 + 664);
    uint64_t v25 = *(void *)(v0 + 656);
    uint64_t v24 = *(void *)(v0 + 632);
    uint64_t v23 = *(void *)(v0 + 624);
    uint64_t v22 = *(void *)(v0 + 608);
    uint64_t v21 = *(void *)(v0 + 600);
    uint64_t v28 = *(void *)(v0 + 576);
    uint64_t v27 = *(void *)(v0 + 584);
    swift_task_dealloc(*(void *)(v0 + 712));
    swift_task_dealloc(v17);
    swift_task_dealloc(v18);
    swift_task_dealloc(v19);
    swift_task_dealloc(v20);
    swift_task_dealloc(v25);
    swift_task_dealloc(v24);
    swift_task_dealloc(v23);
    swift_task_dealloc(v22);
    swift_task_dealloc(v21);
    swift_task_dealloc(v27);
    swift_task_dealloc(v28);
    return (*(uint64_t (**)(uint64_t, uint64_t))(v0 + 8))(1, 1);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  void *MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;

  uint64_t v1 = *(void *)(v0 + 920);
  uint64_t v17 = *(void *)(v0 + 888);
  uint64_t v19 = *(void *)(v0 + 792);
  uint64_t v21 = *(void *)(v0 + 784);
  uint64_t v23 = *(void *)(v0 + 776);
  uint64_t v14 = *(void *)(v0 + 768);
  uint64_t v15 = *(void *)(v0 + 760);
  uint64_t v12 = *(void *)(v0 + 712);
  uint64_t v13 = *(void *)(v0 + 688);
  uint64_t v27 = *(void *)(v0 + 664);
  uint64_t v16 = *(void *)(v0 + 576);
  uint64_t v25 = *(void *)(v0 + 568);
  uint64_t v2 = *(void *)(v0 + 552);
  uint64_t v29 = *(void *)(v0 + 560);
  MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v1, v0 + 520, &demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>, (uint64_t)&unk_3522A8);
  swift_bridgeObjectRelease(v1);
  *(void *)(v0 + 528) = MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
  uint64_t v4 = *(void *)(v2 + v17 + 88);
  swift_bridgeObjectRetain(v4);
  uint64_t v5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v4, v0 + 536, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>, (uint64_t)&unk_352270);
  swift_bridgeObjectRelease(v4);
  *(void *)(v0 + 544) = v5;
  ClassificationMetrics.init<A, B>(_:_:)(v0 + 528, v0 + 544, &type metadata for String, v15, v15, &protocol witness table for String, v14, v14);
  outlined destroy of MLActivityClassifier.ModelParameters(v13, type metadata accessor for MLImageClassifier.PersistentParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v12, type metadata accessor for MLImageClassifier.Model);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v25 + 32))(v27, v16, v29);
  swift_storeEnumTagMultiPayload(v27, v23, 0);
  swift_storeEnumTagMultiPayload(v27, v21, 0);
  __swift_storeEnumTagSinglePayload(v27, 0, 1, v19);
  unint64_t v6 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationMetrics + v2;
  swift_beginAccess(v6, v0 + 440, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v27, v6, &demangling cache variable for type metadata for MLClassifierMetrics?);
  swift_endAccess(v0 + 440);
  uint64_t v7 = *(void *)(v0 + 696);
  unint64_t v8 = *(void *)(v0 + 688);
  uint64_t v9 = *(void *)(v0 + 672);
  uint64_t v10 = *(void *)(v0 + 664);
  uint64_t v30 = *(void *)(v0 + 656);
  uint64_t v28 = *(void *)(v0 + 632);
  uint64_t v26 = *(void *)(v0 + 624);
  uint64_t v24 = *(void *)(v0 + 608);
  uint64_t v22 = *(void *)(v0 + 600);
  uint64_t v18 = *(void *)(v0 + 576);
  int64_t v20 = *(void *)(v0 + 584);
  swift_task_dealloc(*(void *)(v0 + 712));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v10);
  swift_task_dealloc(v30);
  swift_task_dealloc(v28);
  swift_task_dealloc(v26);
  swift_task_dealloc(v24);
  swift_task_dealloc(v22);
  swift_task_dealloc(v20);
  swift_task_dealloc(v18);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v0 + 8))(1, 1);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v1 = *(void *)(v0 + 712);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 688), type metadata accessor for MLImageClassifier.PersistentParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLImageClassifier.Model);
  uint64_t v2 = *(void *)(v0 + 696);
  uint64_t v3 = *(void *)(v0 + 688);
  uint64_t v4 = *(void *)(v0 + 672);
  uint64_t v5 = *(void *)(v0 + 664);
  uint64_t v13 = *(void *)(v0 + 656);
  uint64_t v12 = *(void *)(v0 + 632);
  uint64_t v11 = *(void *)(v0 + 624);
  uint64_t v10 = *(void *)(v0 + 608);
  uint64_t v9 = *(void *)(v0 + 600);
  uint64_t v7 = *(void *)(v0 + 576);
  unint64_t v8 = *(void *)(v0 + 584);
  swift_task_dealloc(*(void *)(v0 + 712));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v5);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v1 = *(void *)(v0 + 712);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 688), type metadata accessor for MLImageClassifier.PersistentParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLImageClassifier.Model);
  uint64_t v2 = *(void *)(v0 + 696);
  uint64_t v3 = *(void *)(v0 + 688);
  uint64_t v4 = *(void *)(v0 + 672);
  uint64_t v5 = *(void *)(v0 + 664);
  uint64_t v13 = *(void *)(v0 + 656);
  uint64_t v12 = *(void *)(v0 + 632);
  uint64_t v11 = *(void *)(v0 + 624);
  uint64_t v10 = *(void *)(v0 + 608);
  uint64_t v9 = *(void *)(v0 + 600);
  uint64_t v7 = *(void *)(v0 + 576);
  unint64_t v8 = *(void *)(v0 + 584);
  swift_task_dealloc(*(void *)(v0 + 712));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v5);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v1 = *(void *)(v0 + 712);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 688), type metadata accessor for MLImageClassifier.PersistentParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLImageClassifier.Model);
  uint64_t v2 = *(void *)(v0 + 696);
  uint64_t v3 = *(void *)(v0 + 688);
  uint64_t v4 = *(void *)(v0 + 672);
  uint64_t v5 = *(void *)(v0 + 664);
  uint64_t v13 = *(void *)(v0 + 656);
  uint64_t v12 = *(void *)(v0 + 632);
  uint64_t v11 = *(void *)(v0 + 624);
  uint64_t v10 = *(void *)(v0 + 608);
  uint64_t v9 = *(void *)(v0 + 600);
  uint64_t v7 = *(void *)(v0 + 576);
  unint64_t v8 = *(void *)(v0 + 584);
  swift_task_dealloc(*(void *)(v0 + 712));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v5);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;

  uint64_t v1 = *(void *)(v0 + 824);
  uint64_t v2 = *(void *)(v0 + 712);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 688), type metadata accessor for MLImageClassifier.PersistentParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.Model);
  swift_bridgeObjectRelease(v1);
  uint64_t v3 = *(void *)(v0 + 696);
  uint64_t v4 = *(void *)(v0 + 688);
  uint64_t v5 = *(void *)(v0 + 672);
  unint64_t v6 = *(void *)(v0 + 664);
  uint64_t v14 = *(void *)(v0 + 656);
  uint64_t v13 = *(void *)(v0 + 632);
  uint64_t v12 = *(void *)(v0 + 624);
  uint64_t v11 = *(void *)(v0 + 608);
  uint64_t v10 = *(void *)(v0 + 600);
  unint64_t v8 = *(void *)(v0 + 576);
  uint64_t v9 = *(void *)(v0 + 584);
  swift_task_dealloc(*(void *)(v0 + 712));
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v1 = *(void *)(v0 + 712);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 688), type metadata accessor for MLImageClassifier.PersistentParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLImageClassifier.Model);
  uint64_t v2 = *(void *)(v0 + 696);
  uint64_t v3 = *(void *)(v0 + 688);
  uint64_t v4 = *(void *)(v0 + 672);
  uint64_t v5 = *(void *)(v0 + 664);
  uint64_t v13 = *(void *)(v0 + 656);
  uint64_t v12 = *(void *)(v0 + 632);
  uint64_t v11 = *(void *)(v0 + 624);
  uint64_t v10 = *(void *)(v0 + 608);
  uint64_t v9 = *(void *)(v0 + 600);
  uint64_t v7 = *(void *)(v0 + 576);
  unint64_t v8 = *(void *)(v0 + 584);
  swift_task_dealloc(*(void *)(v0 + 712));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v5);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t ImageClassifierTrainingSessionDelegate.evaluate(from:)(uint64_t a1)
{
  uint64_t v5 = *(void *)(*(void *)v2 + 736);
  uint64_t v4 = *(void **)v2;
  v4[93] = v1;
  swift_task_dealloc(v5);
  swift_bridgeObjectRelease(v4[91]);
  if (v1)
  {
    unint64_t v6 = ImageClassifierTrainingSessionDelegate.evaluate(from:);
  }
  else
  {
    v4[94] = a1;
    unint64_t v6 = ImageClassifierTrainingSessionDelegate.evaluate(from:);
  }
  return swift_task_switch(v6, 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t (*v7)();
  void *v9;

  uint64_t v3 = *(void *)(*(void *)v2 + 816);
  uint64_t v9 = *(void **)v2;
  v9[103] = a1;
  v9[104] = v1;
  swift_task_dealloc(v3);
  uint64_t v4 = v9[82];
  uint64_t v5 = v9[80];
  unint64_t v6 = v9[81];
  swift_bridgeObjectRelease(v9[101]);
  (*(void (**)(uint64_t, uint64_t))(v6 + 8))(v4, v5);
  if (v1) {
    uint64_t v7 = ImageClassifierTrainingSessionDelegate.evaluate(from:);
  }
  else {
    uint64_t v7 = ImageClassifierTrainingSessionDelegate.evaluate(from:);
  }
  return swift_task_switch(v7, 0, 0);
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t (*v7)();
  uint64_t v8;

  uint64_t v5 = *v2 + 192;
  unint64_t v6 = *(void *)(*v2 + 864);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 872) = v1;
  swift_task_dealloc(v6);
  if (v1)
  {
    outlined destroy of MLImageClassifier.FeatureExtractor(v5);
    uint64_t v7 = ImageClassifierTrainingSessionDelegate.evaluate(from:);
  }
  else
  {
    unint64_t v8 = *(void *)(v4 + 824);
    *(void *)(v4 + 880) = a1;
    outlined destroy of MLImageClassifier.FeatureExtractor(v5);
    swift_bridgeObjectRelease(v8);
    uint64_t v7 = ImageClassifierTrainingSessionDelegate.evaluate(from:);
  }
  return swift_task_switch(v7, 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;
  void *v4;
  uint64_t v5;
  uint64_t (*v6)();

  uint64_t v5 = *(void *)(*(void *)v2 + 904);
  uint64_t v4 = *(void **)v2;
  v4[114] = v1;
  swift_task_dealloc(v5);
  swift_bridgeObjectRelease(v4[112]);
  if (v1)
  {
    unint64_t v6 = ImageClassifierTrainingSessionDelegate.evaluate(from:);
  }
  else
  {
    v4[115] = a1;
    unint64_t v6 = ImageClassifierTrainingSessionDelegate.evaluate(from:);
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t ImageClassifierTrainingSessionDelegate.deinit()
{
  outlined destroy of MLActivityClassifier.ModelParameters(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  swift_bridgeObjectRelease(*(void *)(v0
                                      + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFiles));
  swift_bridgeObjectRelease(*(void *)(v0
                                      + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFiles));
  uint64_t v1 = *(void *)(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore + 80);
  uint64_t v2 = *(void *)(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore + 88);
  outlined consume of Data._Representation(*(void *)(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore), *(void *)(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingFeatureStore + 8));
  swift_bridgeObjectRelease(v2);
  swift_bridgeObjectRelease(v1);
  uint64_t v3 = *(void *)(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore + 80);
  uint64_t v4 = *(void *)(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore + 88);
  outlined consume of Data._Representation(*(void *)(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore), *(void *)(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationFeatureStore + 8));
  swift_bridgeObjectRelease(v4);
  swift_bridgeObjectRelease(v3);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_classifier, &demangling cache variable for type metadata for MLImageClassifier.Classifier?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model, &demangling cache variable for type metadata for MLImageClassifier.Model?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingMetrics, &demangling cache variable for type metadata for MLClassifierMetrics?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationMetrics, &demangling cache variable for type metadata for MLClassifierMetrics?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_tablePrinter, &demangling cache variable for type metadata for TrainingTablePrinter?);
  return v0;
}

uint64_t ImageClassifierTrainingSessionDelegate.__deallocating_deinit()
{
  ImageClassifierTrainingSessionDelegate.deinit();
  return swift_deallocClassInstance(v0, *(unsigned int *)(*(void *)v0 + 48), *(unsigned __int16 *)(*(void *)v0 + 52));
}

uint64_t ObjC metadata update function for ImageClassifierTrainingSessionDelegate()
{
  return type metadata accessor for ImageClassifierTrainingSessionDelegate(0);
}

uint64_t type metadata accessor for ImageClassifierTrainingSessionDelegate(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for ImageClassifierTrainingSessionDelegate;
  if (!type metadata singleton initialization cache for ImageClassifierTrainingSessionDelegate) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for ImageClassifierTrainingSessionDelegate);
  }
  return result;
}

uint64_t type metadata completion function for ImageClassifierTrainingSessionDelegate(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLTrainingSessionParameters(319);
  if (v2 <= 0x3F)
  {
    v8[0] = *(void *)(result - 8) + 64;
    uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLImageClassifier.PersistentParameters?, type metadata accessor for MLImageClassifier.PersistentParameters);
    if (v3 <= 0x3F)
    {
      v8[1] = *(void *)(result - 8) + 64;
      v8[2] = (char *)&value witness table for Builtin.BridgeObject + 64;
      v8[3] = (char *)&value witness table for Builtin.BridgeObject + 64;
      uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLImageClassifier.Classifier?, type metadata accessor for MLImageClassifier.Classifier);
      if (v4 <= 0x3F)
      {
        v8[6] = *(void *)(result - 8) + 64;
        uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLImageClassifier.Model?, type metadata accessor for MLImageClassifier.Model);
        if (v5 <= 0x3F)
        {
          v8[7] = *(void *)(result - 8) + 64;
          uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLClassifierMetrics?, type metadata accessor for MLClassifierMetrics);
          if (v6 <= 0x3F)
          {
            uint64_t v9 = *(void *)(result - 8) + 64;
            uint64_t v10 = v9;
            uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for TrainingTablePrinter?, type metadata accessor for TrainingTablePrinter);
            if (v7 <= 0x3F)
            {
              uint64_t v11 = *(void *)(result - 8) + 64;
              uint64_t result = swift_updateClassMetadata2(a1, 256, 11, v8, a1 + 80);
              if (!result) {
                return 0;
              }
            }
          }
        }
      }
    }
  }
  return result;
}

void protocol witness for TrainingSessionDelegate.setUp() in conformance ImageClassifierTrainingSessionDelegate()
{
}

void protocol witness for TrainingSessionDelegate.resume(from:) in conformance ImageClassifierTrainingSessionDelegate(Swift::OpaquePointer a1)
{
}

unint64_t protocol witness for TrainingSessionDelegate.itemCount(phase:) in conformance ImageClassifierTrainingSessionDelegate(CreateML::MLPhase a1)
{
  return (unint64_t)ImageClassifierTrainingSessionDelegate.itemCount(phase:)(a1);
}

void protocol witness for TrainingSessionDelegate.transitionTo(phase:) in conformance ImageClassifierTrainingSessionDelegate(CreateML::MLPhase a1)
{
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance ImageClassifierTrainingSessionDelegate(uint64_t a1)
{
  unint64_t v2 = (void *)swift_task_alloc(dword_3AF4BC);
  *(void *)(v1 + 16) = v2;
  *unint64_t v2 = v1;
  v2[1] = protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance SoundClassifierTrainingSessionDelegate;
  return ImageClassifierTrainingSessionDelegate.extractFeatures(from:)(a1);
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance ImageClassifierTrainingSessionDelegate()
{
  uint64_t v1 = (void *)swift_task_alloc(dword_3AF49C);
  *(void *)(v0 + 16) = v1;
  void *v1 = v0;
  v1[1] = protocol witness for TrainingSessionDelegate.train(from:) in conformance SoundClassifierTrainingSessionDelegate;
  return ImageClassifierTrainingSessionDelegate.train(from:)();
}

uint64_t protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance ImageClassifierTrainingSessionDelegate()
{
  uint64_t v1 = (void *)swift_task_alloc(dword_3AF474);
  *(void *)(v0 + 16) = v1;
  void *v1 = v0;
  v1[1] = protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance TreeClassifierTrainingSessionDelegate;
  return ImageClassifierTrainingSessionDelegate.evaluate(from:)();
}

uint64_t protocol witness for TrainingSessionDelegate.saveCheckpoint(to:phase:iteration:) in conformance ImageClassifierTrainingSessionDelegate(uint64_t *a1, unsigned __int8 *a2)
{
  return ImageClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)(a1, a2);
}

uint64_t protocol witness for TrainingSessionCodable.save(to:) in conformance ImageClassifierTrainingSessionDelegate(uint64_t a1)
{
  return ImageClassifierTrainingSessionDelegate.save(to:)(a1);
}

NSURL *protocol witness for TrainingSessionCodable.restore(from:phase:) in conformance ImageClassifierTrainingSessionDelegate(uint64_t a1, unsigned char *a2)
{
  return ImageClassifierTrainingSessionDelegate.restore(from:phase:)(a1, a2);
}

uint64_t sub_31C711(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3);
}

uint64_t sub_31C71B(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, a4);
}

uint64_t sub_31C725()
{
  return key path getter for AnnotatedPrediction.prediction : AnnotatedPrediction<ClassificationDistribution<String>, String>();
}

uint64_t sub_31C72F(uint64_t a1)
{
  return key path setter for AnnotatedPrediction.prediction : AnnotatedPrediction<ClassificationDistribution<String>, String>(a1);
}

uint64_t sub_31C746()
{
  return key path getter for ClassificationDistribution.mostLikelyLabel : ClassificationDistribution<String>();
}

uint64_t sub_31C754()
{
  return objectdestroyTm_9();
}

uint64_t partial apply for closure #2 in ImageClassifierTrainingSessionDelegate.train(from:)(uint64_t a1, __m128 a2)
{
  return closure #1 in ImageClassifierTrainingSessionDelegate.train(from:)(a1, a2, *(void *)(v2 + 16), *(void *)(v2 + 24));
}

uint64_t sub_31C771()
{
  return objectdestroyTm_9();
}

uint64_t objectdestroyTm_9()
{
  swift_release(*(void *)(v0 + 16));
  swift_release(*(void *)(v0 + 24));
  return swift_deallocObject(v0, 32, 7);
}

uint64_t sub_31C7AA()
{
  swift_release(*(void *)(v0 + 24));
  return swift_deallocObject(v0, 32, 7);
}

uint64_t partial apply for closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(*(void *)(v0 + 16));
}

uint64_t sub_31C7E6(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return key path getter for AnnotatedFeature.annotation : AnnotatedFeature<URL, String>(a1, a2, a3);
}

uint64_t sub_31C7F0(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for AnnotatedFeature.annotation : AnnotatedFeature<URL, String>(a1, a2, a3, a4);
}

uint64_t outlined init with copy of MLImageClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  return a2;
}

uint64_t partial apply for closure #1 in ImageClassifierTrainingSessionDelegate.train(from:)(uint64_t a1, __m128 a2)
{
  return partial apply for closure #2 in ImageClassifierTrainingSessionDelegate.train(from:)(a1, a2);
}

char *initializeBufferWithCopyOfBuffer for MLSoundClassifier.Model(char *__dst, char *__src, uint64_t a3)
{
  unint64_t v4 = __dst;
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v13 = *(void *)__src;
    *(void *)unint64_t v4 = *(void *)__src;
    unint64_t v4 = (char *)(v13 + ((v5 + 16) & ~v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v7);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v14 = *(void *)__src;
      *(void *)unint64_t v4 = *(void *)__src;
      swift_bridgeObjectRetain(v14);
      swift_storeEnumTagMultiPayload(v4, v7, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v9 = type metadata accessor for MLSoundClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v9))
      {
        case 0u:
          uint64_t v10 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 16))(__dst, __src, v10);
          uint64_t v11 = v9;
          uint64_t v12 = 0;
          goto LABEL_15;
        case 1u:
          uint64_t v15 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 16))(__dst, __src, v15);
          uint64_t v46 = 1;
          goto LABEL_11;
        case 2u:
          uint64_t v16 = *(void *)__src;
          *(void *)unint64_t v4 = *(void *)__src;
          swift_bridgeObjectRetain(v16);
          uint64_t v46 = 2;
LABEL_11:
          uint64_t v12 = v46;
          __dst = v4;
          uint64_t v11 = v9;
          goto LABEL_15;
        case 3u:
          uint64_t v49 = v9;
          uint64_t v17 = *(void *)__src;
          char v48 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v48);
          *(void *)__dst = v17;
          __dst[8] = v48;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v18 = *((void *)__src + 3);
          *((void *)v4 + 3) = v18;
          *((void *)v4 + 4) = *((void *)__src + 4);
          uint64_t v19 = *((void *)__src + 5);
          *((void *)v4 + 5) = v19;
          long long v20 = *((_OWORD *)__src + 4);
          *((_OWORD *)v4 + 3) = *((_OWORD *)__src + 3);
          *((_OWORD *)v4 + 4) = v20;
          v4[80] = __src[80];
          swift_bridgeObjectRetain(v18);
          swift_bridgeObjectRetain(v19);
          uint64_t v47 = 3;
          goto LABEL_14;
        case 4u:
          uint64_t v21 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v21 - 8) + 16))(__dst, __src, v21);
          uint64_t v22 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
          uint64_t v23 = v22[12];
          *(void *)&__dst[v23] = *(void *)&__src[v23];
          uint64_t v24 = *(void *)&__src[v23 + 8];
          *(void *)&v4[v23 + 8] = v24;
          uint64_t v25 = v22[16];
          *(void *)&v4[v25] = *(void *)&__src[v25];
          uint64_t v49 = v9;
          uint64_t v26 = *(void *)&__src[v25 + 8];
          *(void *)&v4[v25 + 8] = v26;
          uint64_t v27 = v22[20];
          v4[v27 + 32] = __src[v27 + 32];
          long long v28 = *(_OWORD *)&__src[v27];
          *(_OWORD *)&v4[v27 + 16] = *(_OWORD *)&__src[v27 + 16];
          *(_OWORD *)&v4[v27] = v28;
          swift_bridgeObjectRetain(v24);
          swift_bridgeObjectRetain(v26);
          uint64_t v47 = 4;
LABEL_14:
          uint64_t v12 = v47;
          __dst = v4;
          uint64_t v11 = v49;
LABEL_15:
          swift_storeEnumTagMultiPayload(__dst, v11, v12);
          swift_storeEnumTagMultiPayload(v4, v7, 1);
          break;
      }
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
    }
    uint64_t v29 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
    *(void *)&v4[v29[5]] = *(void *)&__src[v29[5]];
    *(void *)&v4[v29[6]] = *(void *)&__src[v29[6]];
    uint64_t v30 = v29[7];
    uint64_t v31 = &v4[v30];
    uint64_t v32 = &__src[v30];
    uint64_t v33 = *(void *)&__src[v30 + 24];
    if (v33)
    {
      *((void *)v31 + 3) = v33;
      (**(void (***)(char *, char *))(v33 - 8))(v31, v32);
    }
    else
    {
      long long v34 = *(_OWORD *)v32;
      *((_OWORD *)v31 + 1) = *((_OWORD *)v32 + 1);
      *(_OWORD *)uint64_t v31 = v34;
    }
    uint64_t v35 = v29[8];
    v4[v35 + 8] = __src[v35 + 8];
    *(void *)&v4[v35] = *(void *)&__src[v35];
    *(void *)&v4[v29[9]] = *(void *)&__src[v29[9]];
    uint64_t v36 = *(int *)(a3 + 20);
    uint64_t v37 = &v4[v36];
    uint64_t v38 = &__src[v36];
    uint64_t v39 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    if (swift_getEnumCaseMultiPayload(v38, v39) == 1)
    {
      uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v40 - 8) + 16))(v37, v38, v40);
      uint64_t v41 = 1;
      uint64_t v42 = v37;
      uint64_t v43 = v39;
    }
    else
    {
      uint64_t v44 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v44 - 8) + 16))(v37, v38, v44);
      uint64_t v42 = v37;
      uint64_t v43 = v39;
      uint64_t v41 = 0;
    }
    swift_storeEnumTagMultiPayload(v42, v43, v41);
  }
  return v4;
}

uint64_t destroy for MLSoundClassifier.Model(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a1, v3);
  if (EnumCaseMultiPayload == 2)
  {
LABEL_5:
    uint64_t v7 = *(void *)a1;
LABEL_6:
    swift_bridgeObjectRelease(v7);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v5 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(a1, v5))
    {
      case 0u:
      case 1u:
        uint64_t v6 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8))(a1, v6);
        break;
      case 2u:
        goto LABEL_5;
      case 3u:
        outlined consume of Result<_DataTable, Error>(*(void *)a1, *(unsigned char *)(a1 + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + 24));
        uint64_t v7 = *(void *)(a1 + 40);
        goto LABEL_6;
      case 4u:
        uint64_t v14 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v14 - 8) + 8))(a1, v14);
        uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(v15 + 48) + 8));
        uint64_t v7 = *(void *)(a1 + *(int *)(v15 + 64) + 8);
        goto LABEL_6;
      default:
        break;
    }
  }
  uint64_t v8 = *(int *)(type metadata accessor for MLSoundClassifier.ModelParameters(0) + 28);
  if (*(void *)(a1 + v8 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + v8));
  }
  uint64_t v9 = *(int *)(a2 + 20) + a1;
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  uint64_t v11 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (swift_getEnumCaseMultiPayload(v9, v10) == 1) {
    uint64_t v11 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(v11);
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v12 - 8) + 8))(v9, v12);
}

char *initializeWithCopy for MLSoundClassifier.Model(char *__dst, char *__src, uint64_t a3)
{
  uint64_t v5 = __dst;
  uint64_t v6 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v6);
  if (EnumCaseMultiPayload == 2)
  {
    uint64_t v12 = *(void *)__src;
    *(void *)uint64_t v5 = *(void *)__src;
    swift_bridgeObjectRetain(v12);
    swift_storeEnumTagMultiPayload(v5, v6, 2);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v8 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(__src, v8))
    {
      case 0u:
        uint64_t v9 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))(__dst, __src, v9);
        uint64_t v10 = v8;
        uint64_t v11 = 0;
        goto LABEL_13;
      case 1u:
        uint64_t v13 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v13 - 8) + 16))(__dst, __src, v13);
        uint64_t v43 = 1;
        goto LABEL_9;
      case 2u:
        uint64_t v14 = *(void *)__src;
        *(void *)uint64_t v5 = *(void *)__src;
        swift_bridgeObjectRetain(v14);
        uint64_t v43 = 2;
LABEL_9:
        uint64_t v11 = v43;
        __dst = v5;
        uint64_t v10 = v8;
        goto LABEL_13;
      case 3u:
        uint64_t v46 = v8;
        uint64_t v15 = *(void *)__src;
        char v45 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v45);
        *(void *)__dst = v15;
        __dst[8] = v45;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v16 = *((void *)__src + 3);
        *((void *)v5 + 3) = v16;
        *((void *)v5 + 4) = *((void *)__src + 4);
        uint64_t v17 = *((void *)__src + 5);
        *((void *)v5 + 5) = v17;
        long long v18 = *((_OWORD *)__src + 4);
        *((_OWORD *)v5 + 3) = *((_OWORD *)__src + 3);
        *((_OWORD *)v5 + 4) = v18;
        v5[80] = __src[80];
        swift_bridgeObjectRetain(v16);
        swift_bridgeObjectRetain(v17);
        uint64_t v44 = 3;
        goto LABEL_12;
      case 4u:
        uint64_t v19 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16))(__dst, __src, v19);
        long long v20 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        uint64_t v21 = v20[12];
        *(void *)&__dst[v21] = *(void *)&__src[v21];
        uint64_t v22 = *(void *)&__src[v21 + 8];
        *(void *)&v5[v21 + 8] = v22;
        uint64_t v23 = v20[16];
        *(void *)&v5[v23] = *(void *)&__src[v23];
        uint64_t v46 = v8;
        uint64_t v24 = *(void *)&__src[v23 + 8];
        *(void *)&v5[v23 + 8] = v24;
        uint64_t v25 = v20[20];
        v5[v25 + 32] = __src[v25 + 32];
        long long v26 = *(_OWORD *)&__src[v25];
        *(_OWORD *)&v5[v25 + 16] = *(_OWORD *)&__src[v25 + 16];
        *(_OWORD *)&v5[v25] = v26;
        swift_bridgeObjectRetain(v22);
        swift_bridgeObjectRetain(v24);
        uint64_t v44 = 4;
LABEL_12:
        uint64_t v11 = v44;
        __dst = v5;
        uint64_t v10 = v46;
LABEL_13:
        swift_storeEnumTagMultiPayload(__dst, v10, v11);
        swift_storeEnumTagMultiPayload(v5, v6, 1);
        break;
    }
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
  }
  uint64_t v27 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  *(void *)&v5[v27[5]] = *(void *)&__src[v27[5]];
  *(void *)&v5[v27[6]] = *(void *)&__src[v27[6]];
  uint64_t v28 = v27[7];
  uint64_t v29 = &v5[v28];
  uint64_t v30 = &__src[v28];
  uint64_t v31 = *(void *)&__src[v28 + 24];
  if (v31)
  {
    *((void *)v29 + 3) = v31;
    (**(void (***)(char *, char *))(v31 - 8))(v29, v30);
  }
  else
  {
    long long v32 = *(_OWORD *)v30;
    *((_OWORD *)v29 + 1) = *((_OWORD *)v30 + 1);
    *(_OWORD *)uint64_t v29 = v32;
  }
  uint64_t v33 = v27[8];
  v5[v33 + 8] = __src[v33 + 8];
  *(void *)&v5[v33] = *(void *)&__src[v33];
  *(void *)&v5[v27[9]] = *(void *)&__src[v27[9]];
  uint64_t v34 = *(int *)(a3 + 20);
  uint64_t v35 = &v5[v34];
  uint64_t v36 = &__src[v34];
  uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int v38 = swift_getEnumCaseMultiPayload(v36, v37);
  BOOL v39 = v38 == 1;
  uint64_t v40 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (v38 == 1) {
    uint64_t v40 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(v40);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v41 - 8) + 16))(v35, v36, v41);
  swift_storeEnumTagMultiPayload(v35, v37, v39);
  return v5;
}

char *assignWithCopy for MLSoundClassifier.Model(char *__dst, char *__src, uint64_t a3)
{
  unint64_t v4 = __dst;
  if (__dst != __src)
  {
    outlined destroy of MLSoundClassifier.ModelParameters.ValidationData((uint64_t)__dst);
    uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v5);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v11 = *(void *)__src;
      *(void *)unint64_t v4 = *(void *)__src;
      swift_bridgeObjectRetain(v11);
      swift_storeEnumTagMultiPayload(v4, v5, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v7 = type metadata accessor for MLSoundClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v7))
      {
        case 0u:
          uint64_t v8 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 16))(__dst, __src, v8);
          uint64_t v9 = v7;
          uint64_t v10 = 0;
          goto LABEL_13;
        case 1u:
          uint64_t v12 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 16))(__dst, __src, v12);
          uint64_t v43 = 1;
          goto LABEL_12;
        case 2u:
          uint64_t v13 = *(void *)__src;
          *(void *)unint64_t v4 = *(void *)__src;
          swift_bridgeObjectRetain(v13);
          uint64_t v43 = 2;
          goto LABEL_12;
        case 3u:
          uint64_t v14 = *(void *)__src;
          uint64_t v45 = v7;
          char v15 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v15);
          *(void *)__dst = v14;
          __dst[8] = v15;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v16 = *((void *)__src + 3);
          *((void *)v4 + 3) = v16;
          *((void *)v4 + 4) = *((void *)__src + 4);
          uint64_t v17 = *((void *)__src + 5);
          *((void *)v4 + 5) = v17;
          long long v18 = *((_OWORD *)__src + 4);
          *((_OWORD *)v4 + 3) = *((_OWORD *)__src + 3);
          *((_OWORD *)v4 + 4) = v18;
          v4[80] = __src[80];
          swift_bridgeObjectRetain(v16);
          swift_bridgeObjectRetain(v17);
          uint64_t v10 = 3;
          __dst = v4;
          uint64_t v9 = v45;
          goto LABEL_13;
        case 4u:
          uint64_t v19 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16))(__dst, __src, v19);
          long long v20 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
          uint64_t v21 = v20[12];
          *(void *)&__dst[v21] = *(void *)&__src[v21];
          uint64_t v22 = *(void *)&__src[v21 + 8];
          *(void *)&v4[v21 + 8] = v22;
          uint64_t v23 = v20[16];
          *(void *)&v4[v23] = *(void *)&__src[v23];
          uint64_t v24 = *(void *)&__src[v23 + 8];
          *(void *)&v4[v23 + 8] = v24;
          uint64_t v25 = v20[20];
          v4[v25 + 32] = __src[v25 + 32];
          long long v26 = *(_OWORD *)&__src[v25];
          *(_OWORD *)&v4[v25 + 16] = *(_OWORD *)&__src[v25 + 16];
          *(_OWORD *)&v4[v25] = v26;
          swift_bridgeObjectRetain(v22);
          swift_bridgeObjectRetain(v24);
          uint64_t v43 = 4;
LABEL_12:
          uint64_t v10 = v43;
          __dst = v4;
          uint64_t v9 = v7;
LABEL_13:
          swift_storeEnumTagMultiPayload(__dst, v9, v10);
          swift_storeEnumTagMultiPayload(v4, v5, 1);
          break;
      }
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
    }
  }
  uint64_t v27 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  *(void *)&v4[v27[5]] = *(void *)&__src[v27[5]];
  *(void *)&v4[v27[6]] = *(void *)&__src[v27[6]];
  uint64_t v28 = v27[7];
  uint64_t v29 = &v4[v28];
  uint64_t v30 = &__src[v28];
  uint64_t v31 = *(void *)&__src[v28 + 24];
  if (*(void *)&v4[v28 + 24])
  {
    if (v31)
    {
      __swift_assign_boxed_opaque_existential_0((uint64_t *)&v4[v28], (uint64_t *)&__src[v28]);
      goto LABEL_21;
    }
    __swift_destroy_boxed_opaque_existential_1Tm(&v4[v28]);
  }
  else if (v31)
  {
    *((void *)v29 + 3) = v31;
    (**(void (***)(char *, char *))(v31 - 8))(v29, v30);
    goto LABEL_21;
  }
  long long v32 = *(_OWORD *)v30;
  *((_OWORD *)v29 + 1) = *((_OWORD *)v30 + 1);
  *(_OWORD *)uint64_t v29 = v32;
LABEL_21:
  uint64_t v33 = v27[8];
  v4[v33 + 8] = __src[v33 + 8];
  *(void *)&v4[v33] = *(void *)&__src[v33];
  *(void *)&v4[v27[9]] = *(void *)&__src[v27[9]];
  if (v4 != __src)
  {
    uint64_t v34 = *(int *)(a3 + 20);
    uint64_t v35 = &__src[v34];
    uint64_t v36 = (uint64_t)&v4[v34];
    outlined destroy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(v36);
    uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    int v38 = swift_getEnumCaseMultiPayload(v35, v37);
    BOOL v39 = v38 == 1;
    uint64_t v40 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
    if (v38 == 1) {
      uint64_t v40 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
    }
    uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(v40);
    (*(void (**)(uint64_t, char *, uint64_t))(*(void *)(v41 - 8) + 16))(v36, v35, v41);
    swift_storeEnumTagMultiPayload(v36, v37, v39);
  }
  return v4;
}

uint64_t outlined destroy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

char *initializeWithTake for MLSoundClassifier.Model(char *__dst, char *__src, uint64_t a3)
{
  uint64_t v6 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  if (swift_getEnumCaseMultiPayload(__src, v6) != 1)
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
    goto LABEL_13;
  }
  uint64_t v7 = type metadata accessor for MLSoundClassifier.DataSource(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v7);
  if (EnumCaseMultiPayload == 4)
  {
    uint64_t v12 = type metadata accessor for DataFrame(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
    uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
    *(_OWORD *)&__dst[v13[12]] = *(_OWORD *)&__src[v13[12]];
    *(_OWORD *)&__dst[v13[16]] = *(_OWORD *)&__src[v13[16]];
    uint64_t v14 = v13[20];
    long long v15 = *(_OWORD *)&__src[v14 + 16];
    *(_OWORD *)&__dst[v14] = *(_OWORD *)&__src[v14];
    *(_OWORD *)&__dst[v14 + 16] = v15;
    __dst[v14 + 32] = __src[v14 + 32];
    uint64_t v30 = 4;
LABEL_9:
    uint64_t v11 = v30;
    uint64_t v10 = v7;
    goto LABEL_10;
  }
  if (EnumCaseMultiPayload == 1)
  {
    uint64_t v16 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 32))(__dst, __src, v16);
    uint64_t v30 = 1;
    goto LABEL_9;
  }
  if (EnumCaseMultiPayload)
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
    goto LABEL_12;
  }
  uint64_t v9 = type metadata accessor for URL(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
  uint64_t v10 = v7;
  uint64_t v11 = 0;
LABEL_10:
  swift_storeEnumTagMultiPayload(__dst, v10, v11);
LABEL_12:
  swift_storeEnumTagMultiPayload(__dst, v6, 1);
LABEL_13:
  uint64_t v17 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  *(void *)&__dst[v17[5]] = *(void *)&__src[v17[5]];
  *(void *)&__dst[v17[6]] = *(void *)&__src[v17[6]];
  uint64_t v18 = v17[7];
  long long v19 = *(_OWORD *)&__src[v18];
  *(_OWORD *)&__dst[v18 + 16] = *(_OWORD *)&__src[v18 + 16];
  *(_OWORD *)&__dst[v18] = v19;
  uint64_t v20 = v17[8];
  *(void *)&__dst[v20] = *(void *)&__src[v20];
  __dst[v20 + 8] = __src[v20 + 8];
  *(void *)&__dst[v17[9]] = *(void *)&__src[v17[9]];
  uint64_t v21 = *(int *)(a3 + 20);
  uint64_t v22 = &__dst[v21];
  uint64_t v23 = &__src[v21];
  uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int v25 = swift_getEnumCaseMultiPayload(v23, v24);
  BOOL v26 = v25 == 1;
  uint64_t v27 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (v25 == 1) {
    uint64_t v27 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(v27);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v28 - 8) + 32))(v22, v23, v28);
  swift_storeEnumTagMultiPayload(v22, v24, v26);
  return __dst;
}

char *assignWithTake for MLSoundClassifier.Model(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLSoundClassifier.ModelParameters.ValidationData((uint64_t)__dst);
    uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
    if (swift_getEnumCaseMultiPayload(__src, v5) != 1)
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
      goto LABEL_14;
    }
    uint64_t v6 = type metadata accessor for MLSoundClassifier.DataSource(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v6);
    if (EnumCaseMultiPayload == 4)
    {
      uint64_t v11 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 32))(__dst, __src, v11);
      uint64_t v12 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
      *(_OWORD *)&__dst[v12[12]] = *(_OWORD *)&__src[v12[12]];
      *(_OWORD *)&__dst[v12[16]] = *(_OWORD *)&__src[v12[16]];
      uint64_t v13 = v12[20];
      long long v14 = *(_OWORD *)&__src[v13 + 16];
      *(_OWORD *)&__dst[v13] = *(_OWORD *)&__src[v13];
      *(_OWORD *)&__dst[v13 + 16] = v14;
      __dst[v13 + 32] = __src[v13 + 32];
      uint64_t v31 = 4;
    }
    else
    {
      if (EnumCaseMultiPayload != 1)
      {
        if (EnumCaseMultiPayload)
        {
          memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
          goto LABEL_13;
        }
        uint64_t v8 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
        uint64_t v9 = v6;
        uint64_t v10 = 0;
LABEL_11:
        swift_storeEnumTagMultiPayload(__dst, v9, v10);
LABEL_13:
        swift_storeEnumTagMultiPayload(__dst, v5, 1);
        goto LABEL_14;
      }
      uint64_t v15 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 32))(__dst, __src, v15);
      uint64_t v31 = 1;
    }
    uint64_t v10 = v31;
    uint64_t v9 = v6;
    goto LABEL_11;
  }
LABEL_14:
  uint64_t v16 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  *(void *)&__dst[v16[5]] = *(void *)&__src[v16[5]];
  *(void *)&__dst[v16[6]] = *(void *)&__src[v16[6]];
  uint64_t v17 = v16[7];
  uint64_t v18 = &__dst[v17];
  long long v19 = &__src[v17];
  if (*(void *)&__dst[v17 + 24]) {
    __swift_destroy_boxed_opaque_existential_1Tm(&__dst[v17]);
  }
  long long v20 = *(_OWORD *)v19;
  *((_OWORD *)v18 + 1) = *((_OWORD *)v19 + 1);
  *(_OWORD *)uint64_t v18 = v20;
  uint64_t v21 = v16[8];
  *(void *)&__dst[v21] = *(void *)&__src[v21];
  __dst[v21 + 8] = __src[v21 + 8];
  *(void *)&__dst[v16[9]] = *(void *)&__src[v16[9]];
  if (__dst != __src)
  {
    uint64_t v22 = *(int *)(a3 + 20);
    uint64_t v23 = &__src[v22];
    uint64_t v24 = &__dst[v22];
    outlined destroy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>((uint64_t)v24);
    uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    int v26 = swift_getEnumCaseMultiPayload(v23, v25);
    BOOL v27 = v26 == 1;
    uint64_t v28 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
    if (v26 == 1) {
      uint64_t v28 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
    }
    uint64_t v29 = __swift_instantiateConcreteTypeFromMangledName(v28);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v29 - 8) + 32))(v24, v23, v29);
    swift_storeEnumTagMultiPayload(v24, v25, v27);
  }
  return __dst;
}

uint64_t getEnumTagSinglePayload for MLSoundClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_31D7A6);
}

uint64_t sub_31D7A6(uint64_t a1, unsigned int a2, uint64_t a3)
{
  uint64_t v4 = a1;
  uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) != a2)
  {
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    uint64_t v4 = *(int *)(a3 + 20) + a1;
  }
  return __swift_getEnumTagSinglePayload(v4, a2, v5);
}

uint64_t storeEnumTagSinglePayload for MLSoundClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_31D806);
}

uint64_t sub_31D806(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = a1;
  uint64_t v7 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  if (*(_DWORD *)(*(void *)(v7 - 8) + 84) != a3)
  {
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    uint64_t v6 = *(int *)(a4 + 20) + a1;
  }
  return __swift_storeEnumTagSinglePayload(v6, a2, a2, v7);
}

uint64_t type metadata accessor for MLSoundClassifier.Model(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLSoundClassifier.Model;
  if (!type metadata singleton initialization cache for MLSoundClassifier.Model) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLSoundClassifier.Model);
  }
  return result;
}

uint64_t type metadata completion function for MLSoundClassifier.Model(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLSoundClassifier.ModelParameters(319);
  if (v2 <= 0x3F)
  {
    v4[0] = *(void *)(result - 8) + 64;
    uint64_t result = type metadata accessor for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(319);
    if (v3 <= 0x3F)
    {
      v4[1] = *(void *)(result - 8) + 64;
      swift_initStructMetadata(a1, 256, 2, v4, a1 + 16);
      return 0;
    }
  }
  return result;
}

uint64_t MLSoundClassifier.Model.applied(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v5[6] = v4;
  v5[5] = a4;
  void v5[4] = a3;
  v5[3] = a2;
  v5[2] = a1;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v5[7] = v6;
  uint64_t v7 = *(void *)(v6 - 8);
  v5[8] = v7;
  v5[9] = swift_task_alloc((*(void *)(v7 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v5[10] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v5[11] = v9;
  v5[12] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  v5[13] = v10;
  v5[14] = swift_task_alloc((*(void *)(*(void *)(v10 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLSoundClassifier.Model.applied(to:eventHandler:), 0, 0);
}

uint64_t MLSoundClassifier.Model.applied(to:eventHandler:)()
{
  uint64_t v1 = v0[14];
  uint64_t v2 = v0[6];
  uint64_t v3 = v0[13];
  uint64_t v4 = type metadata accessor for MLSoundClassifier.Model(0);
  outlined init with copy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(v2 + *(int *)(v4 + 20), v1);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v1, v3);
  uint64_t v6 = v0[14];
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(v0[8] + 32))(v0[9], v6, v0[7]);
    uint64_t v7 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)[1]);
    v0[17] = v7;
    *uint64_t v7 = v0;
    v7[1] = MLImageClassifier.Model.applied(to:eventHandler:);
    return FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)(v0[2], v0[3], v0[4], v0[5], v0[7]);
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(v0[11] + 32))(v0[12], v6, v0[10]);
    uint64_t v9 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifierModel.applied(to:eventHandler:)[1]);
    v0[15] = v9;
    void *v9 = v0;
    v9[1] = MLImageClassifier.Model.applied(to:eventHandler:);
    return LogisticRegressionClassifierModel.applied(to:eventHandler:)(v0[2], v0[3], v0[4], v0[5], v0[10]);
  }
}

uint64_t protocol witness for Transformer.applied(to:eventHandler:) in conformance MLSoundClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v7 = (void *)swift_task_alloc(dword_3AF5BC);
  *(void *)(v4 + 16) = v7;
  *uint64_t v7 = v4;
  v7[1] = protocol witness for SupervisedEstimator.fitted<A, B>(to:validateOn:eventHandler:) in conformance MLImageClassifier.Classifier;
  return MLSoundClassifier.Model.applied(to:eventHandler:)(a1, a2, a3, a4);
}

uint64_t base witness table accessor for Transformer in MLSoundClassifier.Model()
{
  return lazy protocol witness table accessor for type MLSoundClassifier.Model and conformance MLSoundClassifier.Model();
}

uint64_t lazy protocol witness table accessor for type MLSoundClassifier.Model and conformance MLSoundClassifier.Model()
{
  uint64_t result = lazy protocol witness table cache variable for type MLSoundClassifier.Model and conformance MLSoundClassifier.Model;
  if (!lazy protocol witness table cache variable for type MLSoundClassifier.Model and conformance MLSoundClassifier.Model)
  {
    uint64_t v1 = type metadata accessor for MLSoundClassifier.Model(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLSoundClassifier.Model, v1);
    lazy protocol witness table cache variable for type MLSoundClassifier.Model and conformance MLSoundClassifier.Model = result;
  }
  return result;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lF8CreateML11MLDataTableV11ColumnNamesV_AF09MLUntypedH0Vs5NeverOTB503_s8d4ML24fg30VisualizationVyAcA0cD0VcfcAA15jH8VSSXEfU_AHTf1cn_n(uint64_t a1, uint64_t a2, char a3)
{
  uint64_t v4 = v3;
  swift_retain();
  uint64_t v5 = CMLSequence.size.getter();
  int64_t v6 = specialized RandomAccessCollection<>.distance(from:to:)(0, v5);
  swift_release();
  swift_retain();
  uint64_t v7 = CMLSequence.size.getter();
  uint64_t v8 = specialized RandomAccessCollection<>.distance(from:to:)(0, v7);
  swift_release();
  if (v8 < 0) {
    BUG();
  }
  swift_retain();
  uint64_t v9 = CMLSequence.size.getter();
  uint64_t v10 = specialized RandomAccessCollection<>.distance(from:to:)(0, v9);
  swift_release();
  if (v6 < 0 || v10 < v6) {
    BUG();
  }
  if (v6)
  {
    uint64_t v11 = 0;
    int64_t v30 = v6;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v6, 0);
    int64_t v12 = v6;
    uint64_t v33 = _swiftEmptyArrayStorage;
    char v32 = a3;
    char v35 = a3 & 1;
    do
    {
      if (v12 == v11) {
        BUG();
      }
      CMLSequence.value(at:)(v11);
      if (v4)
      {
        swift_unexpectedError(v4, "CreateML/SequenceType.swift", 27, 1);
        BUG();
      }
      uint64_t v29 = v11;
      Swift::String v13 = CMLFeatureValue.stringValue()();
      if (v14)
      {
        swift_errorRelease(v14);
        swift_release();
        _StringGuts.grow(_:)(37);
        swift_bridgeObjectRelease(0);
        v24._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
        char object = (char)v24._object;
        String.append(_:)(v24);
        swift_bridgeObjectRelease(object);
        v26._uint64_t countAndFlagsBits = 46;
        v26._char object = (void *)0xE100000000000000;
        String.append(_:)(v26);
        outlined consume of Result<_DataTable, Error>(a2, v35);
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000022, "able.ColumnNames.swift" + 0x8000000000000000, "CreateML/MLDataTable.ColumnNames.swift", 38, 2, 17, 0);
        BUG();
      }
      uint64_t countAndFlagsBits = v13._countAndFlagsBits;
      uint64_t v16 = v13._object;
      swift_release();
      outlined copy of Result<_DataTable, Error>(a2, v32);
      MLDataTable.subscript.getter((Swift::String)__PAIR128__((unint64_t)v16, countAndFlagsBits));
      outlined consume of Result<_DataTable, Error>(a2, v32);
      swift_bridgeObjectRelease((_BYTE)v16);
      uint64_t v17 = v33;
      unint64_t v18 = v33[2];
      int64_t v19 = v18 + 1;
      if (v33[3] >> 1 <= v18)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v33[3] >= 2uLL, v19, 1);
        int64_t v19 = v18 + 1;
        uint64_t v17 = v33;
      }
      double v17[2] = v19;
      uint64_t v20 = 2 * v18;
      v17[v20 + 4] = v27;
      uint64_t v33 = v17;
      LOBYTE(v17[v20 + 5]) = v28 & 1;
      swift_retain();
      uint64_t v21 = CMLSequence.size.getter();
      uint64_t v22 = specialized RandomAccessCollection<>.distance(from:to:)(0, v21);
      swift_release();
      if (v11 >= v22) {
        BUG();
      }
      ++v11;
      int64_t v12 = v30;
      uint64_t v4 = 0;
    }
    while (v30 != v29 + 1);
    outlined consume of Result<_DataTable, Error>(a2, v35);
    return v33;
  }
  else
  {
    outlined consume of Result<_DataTable, Error>(a2, a3 & 1);
    return _swiftEmptyArrayStorage;
  }
}

void *MLDataTableVisualization.init(_:)(uint64_t a1)
{
  uint64_t v1 = *(void *)a1;
  char v2 = *(unsigned char *)(a1 + 8);
  if (v2)
  {
    outlined copy of Result<_DataTable, Error>(*(void *)a1, 1);
    uint64_t v3 = tc_v1_flex_list_create(0);
    if (!v3) {
      BUG();
    }
    uint64_t v4 = v3;
    uint64_t v5 = type metadata accessor for CMLSequence();
    uint64_t v6 = swift_allocObject(v5, 25, 7);
    *(void *)(v6 + 16) = v4;
    *(unsigned char *)(v6 + 24) = 1;
    outlined consume of Result<_DataTable, Error>(v1, 1);
  }
  else
  {
    uint64_t v7 = *(void *)a1;
    outlined copy of Result<_DataTable, Error>(v7, 0);
    _DataTable.columnNames.getter(v7);
    outlined consume of Result<_DataTable, Error>(v1, 0);
    uint64_t v6 = v20;
  }
  char v8 = v2;
  outlined copy of Result<_DataTable, Error>(v1, v2);
  ML11MLDataTableV11ColumnNamesV_AF09MLUntypedH0Vs5NeverOTB503_s8d4ML24fg30VisualizationVyAcA0cD0VcfcAA15jH8VSSXEfU_AHTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lF8CreateML11MLDataTableV11ColumnNamesV_AF09MLUntypedH0Vs5NeverOTB503_s8d4ML24fg30VisualizationVyAcA0cD0VcfcAA15jH8VSSXEfU_AHTf1cn_n(v6, v1, v2);
  outlined consume of Result<_DataTable, Error>(v1, v8);
  swift_release();
  uint64_t v10 = ML11MLDataTableV11ColumnNamesV_AF09MLUntypedH0Vs5NeverOTB503_s8d4ML24fg30VisualizationVyAcA0cD0VcfcAA15jH8VSSXEfU_AHTf1cn_n[2];
  if (v10)
  {
    uint64_t v11 = ML11MLDataTableV11ColumnNamesV_AF09MLUntypedH0Vs5NeverOTB503_s8d4ML24fg30VisualizationVyAcA0cD0VcfcAA15jH8VSSXEfU_AHTf1cn_n[2];
    specialized ContiguousArray.reserveCapacity(_:)(v10);
    char v19 = (char)ML11MLDataTableV11ColumnNamesV_AF09MLUntypedH0Vs5NeverOTB503_s8d4ML24fg30VisualizationVyAcA0cD0VcfcAA15jH8VSSXEfU_AHTf1cn_n;
    int64_t v12 = ML11MLDataTableV11ColumnNamesV_AF09MLUntypedH0Vs5NeverOTB503_s8d4ML24fg30VisualizationVyAcA0cD0VcfcAA15jH8VSSXEfU_AHTf1cn_n
        + 5;
    do
    {
      if (!*v12)
      {
        uint64_t v13 = *((void *)v12 - 1);
        uint64_t v14 = *(void *)(*(void *)(v13 + 16) + 16);
        outlined copy of Result<_DataTable, Error>(v13, 0);
        swift_retain();
        uint64_t v18 = specialized handling<A, B, C, D, E, F>(_:_:_:_:_:_:)(v14, (uint64_t)"", (uint64_t)"", (uint64_t)"", 0);
        if (!v18) {
          BUG();
        }
        uint64_t v15 = type metadata accessor for CMLPlot();
        *(void *)(swift_allocObject(v15, 24, 7) + 16) = v18;
        swift_release();
        uint64_t v11 = v13;
        outlined consume of Result<_DataTable, Error>(v13, 0);
      }
      specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()(v11);
      uint64_t v16 = _swiftEmptyArrayStorage[2];
      specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)(v16);
      uint64_t v11 = v16;
      specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)(v16);
      specialized ContiguousArray._endMutation()(v16);
      v12 += 16;
      --v10;
    }
    while (v10);
    swift_bridgeObjectRelease(v19);
  }
  else
  {
    swift_bridgeObjectRelease((_BYTE)ML11MLDataTableV11ColumnNamesV_AF09MLUntypedH0Vs5NeverOTB503_s8d4ML24fg30VisualizationVyAcA0cD0VcfcAA15jH8VSSXEfU_AHTf1cn_n);
  }
  return _swiftEmptyArrayStorage;
}

CGImageRef_optional ML1DVisualization.cgImage.getter(uint64_t a1)
{
  if (a1) {
    return CMLPlot.toImage()();
  }
  else {
    return 0;
  }
}

Swift::Void __swiftcall ML1DVisualization.nextIteration()()
{
  if (*v0) {
    CMLPlot.nextIteration()();
  }
}

BOOL ML1DVisualization.hasFinishedStreaming.getter(uint64_t a1)
{
  return !a1 || CMLPlot.finishedStreaming()();
}

void protocol witness for MLStreamingVisualizable.nextIteration() in conformance ML1DVisualization()
{
}

BOOL protocol witness for MLStreamingVisualizable.hasFinishedStreaming.getter in conformance ML1DVisualization()
{
  return ML1DVisualization.hasFinishedStreaming.getter(*v0);
}

CGImageRef_optional protocol witness for MLVisualizable.cgImage.getter in conformance ML1DVisualization()
{
  return ML1DVisualization.cgImage.getter(*v0);
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance ML1DVisualization()
{
  return ML1DVisualization.playgroundDescription.getter(*v0);
}

uint64_t ML2DVisualization.init(_:_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)a1;
  uint64_t v3 = *(void *)a2;
  char v4 = *(unsigned char *)(a2 + 8);
  if (*(unsigned char *)(a1 + 8) == 1)
  {
    outlined consume of Result<_DataTable, Error>(v3, v4);
    outlined consume of Result<_DataTable, Error>(v2, 1);
    return 0;
  }
  else
  {
    if (v4)
    {
      outlined consume of Result<_DataTable, Error>(v3, 1);
      uint64_t v5 = 0;
    }
    else
    {
      uint64_t v6 = *(void *)(*(void *)(v2 + 16) + 16);
      uint64_t v11 = *(void *)(*(void *)(v3 + 16) + 16);
      outlined copy of Result<_DataTable, Error>(v2, 0);
      outlined copy of Result<_DataTable, Error>(v3, 0);
      swift_retain();
      swift_retain();
      uint64_t v7 = specialized handling<A, B, C, D, E, F, G>(_:_:_:_:_:_:_:)(v6, v11, (uint64_t)"", (uint64_t)"", (uint64_t)"", 0);
      if (!v7) {
        BUG();
      }
      uint64_t v8 = v7;
      outlined consume of Result<_DataTable, Error>(v3, 0);
      outlined consume of Result<_DataTable, Error>(v2, 0);
      swift_release();
      uint64_t v9 = type metadata accessor for CMLPlot();
      uint64_t v5 = swift_allocObject(v9, 24, 7);
      *(void *)(v5 + 16) = v8;
      swift_release();
      outlined consume of Result<_DataTable, Error>(v3, 0);
    }
    outlined consume of Result<_DataTable, Error>(v2, 0);
  }
  return v5;
}

uint64_t ML1DVisualization.playgroundDescription.getter(uint64_t a1)
{
  uint64_t v2 = v1;
  if (a1) {
    v3.value = CMLPlot.toImage()().value;
  }
  else {
    v3.value = 0;
  }
  uint64_t result = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CGImageRef?);
  v2[3].value = (CGImageRef)result;
  v2->value = v3.value;
  return result;
}

uint64_t MLDataTableVisualization.playgroundDescription.getter(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t v3 = *(void *)(a1 + 16);
  if (v3)
  {
    uint64_t v9 = v1;
    swift_bridgeObjectRetain(a1);
    uint64_t v4 = v3;
    specialized ContiguousArray.reserveCapacity(_:)(v3);
    uint64_t v5 = 0;
    do
    {
      uint64_t v6 = *(void *)(a1 + 8 * v5 + 32);
      if (v6)
      {
        swift_retain();
        CMLPlot.toImage()();
        uint64_t v4 = v6;
        swift_release();
      }
      ++v5;
      specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()(v4);
      uint64_t v7 = _swiftEmptyArrayStorage[2];
      specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)(v7);
      uint64_t v4 = v7;
      specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)(v7);
      specialized ContiguousArray._endMutation()(v7);
    }
    while (v3 != v5);
    swift_bridgeObjectRelease(a1);
    uint64_t v2 = v9;
  }
  uint64_t result = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [CGImageRef?]);
  v2[3] = result;
  *uint64_t v2 = _swiftEmptyArrayStorage;
  return result;
}

CGImageRef MLDataTableVisualization.cgImage.getter(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 16);
  uint64_t v52 = v1;
  if (v1)
  {
    uint64_t v2 = a1;
    swift_bridgeObjectRetain(a1);
    uint64_t v3 = v1;
    specialized ContiguousArray.reserveCapacity(_:)(v1);
    uint64_t v4 = 0;
    do
    {
      uint64_t v5 = *(void *)(v2 + 8 * v4 + 32);
      if (v5)
      {
        swift_retain();
        CMLPlot.toImage()();
        uint64_t v3 = v5;
        swift_release();
      }
      ++v4;
      specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()(v3);
      uint64_t v6 = _swiftEmptyArrayStorage[2];
      specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)(v6);
      uint64_t v3 = v6;
      specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)(v6);
      specialized ContiguousArray._endMutation()(v6);
      uint64_t v2 = a1;
    }
    while (v52 != v4);
    swift_bridgeObjectRelease(a1);
  }
  int64_t v7 = _swiftEmptyArrayStorage[2];
  if (v7)
  {
    uint64_t v8 = 0;
    CGContextRef context = (CGContextRef)_swiftEmptyArrayStorage[2];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v7, 0);
    CGContextRef v9 = context;
    do
    {
      uint64_t v10 = _swiftEmptyArrayStorage[(void)v8 + 4];
      if (v10)
      {
        size_t Width = CGImageGetWidth((CGImageRef)_swiftEmptyArrayStorage[(void)v8 + 4]);
        CGContextRef v9 = context;
      }
      else
      {
        size_t Width = 0;
      }
      unint64_t v12 = _swiftEmptyArrayStorage[2];
      int64_t v13 = v12 + 1;
      if (_swiftEmptyArrayStorage[3] >> 1 <= v12)
      {
        size_t v50 = Width;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v13, 1);
        size_t Width = v50;
        CGContextRef v9 = context;
      }
      uint64_t v8 = (CGContext *)((char *)v8 + 1);
      uint64_t v14 = 2 * v12;
      _swiftEmptyArrayStorage[2] = v13;
      _swiftEmptyArrayStorage[v14 + 4] = Width;
      LOBYTE(_swiftEmptyArrayStorage[v14 + 5]) = v10 == 0;
    }
    while (v9 != v8);
  }
  swift_bridgeObjectRelease(_swiftEmptyArrayStorage);
  uint64_t v15 = _swiftEmptyArrayStorage[2];
  if (!v15)
  {
    swift_bridgeObjectRelease(_swiftEmptyArrayStorage);
    return 0;
  }
  uint64_t v16 = &_swiftEmptyArrayStorage[5];
  int64_t v17 = 0;
  do
  {
    if (*v16) {
      int64_t v18 = 0;
    }
    else {
      int64_t v18 = *((void *)v16 - 1);
    }
    if (v18 > v17) {
      int64_t v17 = v18;
    }
    v16 += 16;
    --v15;
  }
  while (v15);
  swift_bridgeObjectRelease(_swiftEmptyArrayStorage);
  if (!v17) {
    return 0;
  }
  if (v52)
  {
    swift_bridgeObjectRetain(a1);
    uint64_t v19 = v52;
    specialized ContiguousArray.reserveCapacity(_:)(v52);
    uint64_t v20 = 0;
    do
    {
      uint64_t v21 = *(void *)(a1 + 8 * v20 + 32);
      if (v21)
      {
        swift_retain();
        CMLPlot.toImage()();
        uint64_t v19 = v21;
        swift_release();
      }
      ++v20;
      specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()(v19);
      uint64_t v22 = _swiftEmptyArrayStorage[2];
      specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)(v22);
      uint64_t v19 = v22;
      specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)(v22);
      specialized ContiguousArray._endMutation()(v22);
    }
    while (v52 != v20);
    swift_bridgeObjectRelease(a1);
  }
  int64_t v23 = _swiftEmptyArrayStorage[2];
  if (v23)
  {
    Swift::String v24 = 0;
    CGContextRef contexta = (CGContextRef)_swiftEmptyArrayStorage[2];
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v23, 0);
    CGContextRef v25 = contexta;
    do
    {
      uint64_t v26 = _swiftEmptyArrayStorage[(void)v24 + 4];
      if (v26)
      {
        size_t Height = CGImageGetHeight((CGImageRef)_swiftEmptyArrayStorage[(void)v24 + 4]);
        CGContextRef v25 = contexta;
      }
      else
      {
        size_t Height = 0;
      }
      unint64_t v28 = _swiftEmptyArrayStorage[2];
      int64_t v29 = v28 + 1;
      if (_swiftEmptyArrayStorage[3] >> 1 <= v28)
      {
        size_t v51 = Height;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v29, 1);
        int64_t v29 = v28 + 1;
        size_t Height = v51;
        CGContextRef v25 = contexta;
      }
      Swift::String v24 = (CGContext *)((char *)v24 + 1);
      uint64_t v30 = 2 * v28;
      _swiftEmptyArrayStorage[2] = v29;
      _swiftEmptyArrayStorage[v30 + 4] = Height;
      LOBYTE(_swiftEmptyArrayStorage[v30 + 5]) = v26 == 0;
    }
    while (v25 != v24);
  }
  swift_bridgeObjectRelease(_swiftEmptyArrayStorage);
  uint64_t v31 = _swiftEmptyArrayStorage[2];
  if (v31)
  {
    char v32 = &_swiftEmptyArrayStorage[5];
    size_t v33 = 0;
    do
    {
      if (*v32) {
        uint64_t v34 = 0;
      }
      else {
        uint64_t v34 = *((void *)v32 - 1);
      }
      BOOL v35 = __OFADD__(v34, v33);
      v33 += v34;
      if (v35) {
        BUG();
      }
      v32 += 16;
      --v31;
    }
    while (v31);
  }
  else
  {
    size_t v33 = 0;
  }
  swift_bridgeObjectRelease(_swiftEmptyArrayStorage);
  DeviceRGB = CGColorSpaceCreateDeviceRGB();
  contextb = CGBitmapContextCreate(0, v17, v33, 8uLL, 0, DeviceRGB, 1u);
  if (!contextb)
  {

    return 0;
  }
  uint64_t v55 = DeviceRGB;
  if (v52)
  {
    swift_bridgeObjectRetain(a1);
    uint64_t v37 = v52;
    specialized ContiguousArray.reserveCapacity(_:)(v52);
    uint64_t v38 = 0;
    do
    {
      uint64_t v39 = *(void *)(a1 + 8 * v38 + 32);
      if (v39)
      {
        swift_retain();
        CMLPlot.toImage()();
        uint64_t v37 = v39;
        swift_release();
      }
      ++v38;
      specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()(v37);
      uint64_t v40 = _swiftEmptyArrayStorage[2];
      specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)(v40);
      uint64_t v37 = v40;
      specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)(v40);
      specialized ContiguousArray._endMutation()(v40);
    }
    while (v52 != v38);
    swift_bridgeObjectRelease(a1);
  }
  uint64_t v54 = _swiftEmptyArrayStorage[2];
  if (v54)
  {
    uint64_t v42 = 0;
    for (uint64_t i = 0; i != v54; ++i)
    {
      uint64_t v44 = (void *)_swiftEmptyArrayStorage[i + 4];
      if (v44)
      {
        uint64_t v45 = v44;
        int v46 = CGImageGetWidth(v45);
        int v47 = CGImageGetHeight(v45);
        CGContextRef.draw(_:in:byTiling:)(v45, 0, 0.0, (double)(int)v42, (double)v46, (double)v47);
        size_t v48 = CGImageGetHeight(v45);

        BOOL v35 = __OFADD__(v48, v42);
        v42 += v48;
        if (v35) {
          BUG();
        }
      }
    }
  }
  swift_bridgeObjectRelease(_swiftEmptyArrayStorage);
  CGImageRef Image = CGBitmapContextCreateImage(contextb);

  return Image;
}

Swift::Void __swiftcall MLDataTableVisualization.nextIteration()()
{
  uint64_t v1 = *v0;
  uint64_t v2 = *(void *)(*v0 + 16);
  if (v2)
  {
    swift_bridgeObjectRetain(*v0);
    for (uint64_t i = 0; i != v2; ++i)
    {
      if (*(void *)(v1 + 8 * i + 32))
      {
        swift_retain();
        CMLPlot.nextIteration()();
        swift_release();
      }
    }
    swift_bridgeObjectRelease(v1);
  }
}

uint64_t MLDataTableVisualization.hasFinishedStreaming.getter(uint64_t a1)
{
  uint64_t v2 = *(void *)(a1 + 16);
  if (v2)
  {
    swift_bridgeObjectRetain(a1);
    uint64_t v3 = v2 - 1;
    uint64_t v4 = 0;
    while (1)
    {
      if (*(void *)(a1 + 8 * v4 + 32))
      {
        swift_retain();
        LOBYTE(v5) = CMLPlot.finishedStreaming()();
        unsigned int v1 = v5;
        swift_release();
        if ((v1 & 1) == 0) {
          break;
        }
      }
      if (v3 == v4)
      {
        LOBYTE(v1) = 1;
        goto LABEL_11;
      }
      if (__OFADD__(1, ++v4)) {
        BUG();
      }
    }
    unsigned int v1 = 0;
LABEL_11:
    swift_bridgeObjectRelease(a1);
  }
  else
  {
    LOBYTE(v1) = 1;
  }
  return v1;
}

void protocol witness for MLStreamingVisualizable.nextIteration() in conformance MLDataTableVisualization()
{
}

uint64_t protocol witness for MLStreamingVisualizable.hasFinishedStreaming.getter in conformance MLDataTableVisualization()
{
  return MLDataTableVisualization.hasFinishedStreaming.getter(*v0);
}

CGImageRef protocol witness for MLVisualizable.cgImage.getter in conformance MLDataTableVisualization()
{
  return MLDataTableVisualization.cgImage.getter(*v0);
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLDataTableVisualization()
{
  return MLDataTableVisualization.playgroundDescription.getter(*v0);
}

uint64_t show(_:_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  uint64_t v4 = *(void *)a2;
  char v5 = *(unsigned char *)(a1 + 8);
  char v6 = *(unsigned char *)(a2 + 8);
  uint64_t v9 = *(void *)a1;
  char v10 = v5;
  uint64_t v11 = v4;
  char v12 = v6;
  outlined copy of Result<_DataTable, Error>(v9, v5);
  outlined copy of Result<_DataTable, Error>(v4, v6);
  uint64_t v7 = ML2DVisualization.init(_:_:)((uint64_t)&v9, (uint64_t)&v11);
  void v3[3] = (uint64_t)&type metadata for ML2DVisualization;
  uint64_t result = lazy protocol witness table accessor for type ML2DVisualization and conformance ML2DVisualization();
  v3[4] = result;
  uint64_t *v3 = v7;
  return result;
}

uint64_t lazy protocol witness table accessor for type ML2DVisualization and conformance ML2DVisualization()
{
  uint64_t result = lazy protocol witness table cache variable for type ML2DVisualization and conformance ML2DVisualization;
  if (!lazy protocol witness table cache variable for type ML2DVisualization and conformance ML2DVisualization)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ML2DVisualization, &type metadata for ML2DVisualization);
    lazy protocol witness table cache variable for type ML2DVisualization and conformance ML2DVisualization = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ML2DVisualization and conformance ML2DVisualization;
  if (!lazy protocol witness table cache variable for type ML2DVisualization and conformance ML2DVisualization)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ML2DVisualization, &type metadata for ML2DVisualization);
    lazy protocol witness table cache variable for type ML2DVisualization and conformance ML2DVisualization = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ML2DVisualization and conformance ML2DVisualization;
  if (!lazy protocol witness table cache variable for type ML2DVisualization and conformance ML2DVisualization)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ML2DVisualization, &type metadata for ML2DVisualization);
    lazy protocol witness table cache variable for type ML2DVisualization and conformance ML2DVisualization = result;
  }
  return result;
}

uint64_t show<A, B>(_:_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  uint64_t v5 = *(void *)a2;
  char v6 = *(unsigned char *)(a1 + 8);
  char v7 = *(unsigned char *)(a2 + 8);
  uint64_t v9 = *(void *)a1;
  uint64_t v4 = v9;
  char v10 = v6;
  uint64_t v11 = v5;
  char v12 = v7;
  outlined copy of Result<_DataTable, Error>(v9, v6);
  outlined copy of Result<_DataTable, Error>(v5, v7);
  outlined copy of Result<_DataTable, Error>(v9, v6);
  outlined copy of Result<_DataTable, Error>(v5, v7);
  uint64_t v13 = ML2DVisualization.init(_:_:)((uint64_t)&v9, (uint64_t)&v11);
  void v3[3] = (uint64_t)&type metadata for ML2DVisualization;
  v3[4] = lazy protocol witness table accessor for type ML2DVisualization and conformance ML2DVisualization();
  outlined consume of Result<_DataTable, Error>(v5, v7);
  outlined consume of Result<_DataTable, Error>(v4, v6);
  uint64_t result = v13;
  uint64_t *v3 = v13;
  return result;
}

uint64_t show(_:)(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t v3 = 0;
  if (!*(unsigned char *)(a1 + 8))
  {
    uint64_t v4 = *(void *)a1;
    uint64_t v5 = *(void *)(*(void *)(*(void *)a1 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(*(void *)a1, 0);
    outlined copy of Result<_DataTable, Error>(v4, 0);
    swift_retain();
    uint64_t v6 = specialized handling<A, B, C, D, E, F>(_:_:_:_:_:_:)(v5, (uint64_t)"", (uint64_t)"", (uint64_t)"", 0);
    if (!v6) {
      BUG();
    }
    uint64_t v7 = type metadata accessor for CMLPlot();
    uint64_t v3 = swift_allocObject(v7, 24, 7);
    *(void *)(v3 + 16) = v6;
    outlined consume of Result<_DataTable, Error>(v4, 0);
    swift_release();
    outlined consume of Result<_DataTable, Error>(v4, 0);
  }
  v2[3] = (uint64_t)&type metadata for ML1DVisualization;
  uint64_t result = lazy protocol witness table accessor for type ML1DVisualization and conformance ML1DVisualization();
  v2[4] = result;
  *uint64_t v2 = v3;
  return result;
}

{
  void *v1;
  void *v2;
  char v3;
  void *v4;
  uint64_t result;
  uint64_t v6;
  char v7;

  uint64_t v2 = v1;
  uint64_t v3 = *(unsigned char *)(a1 + 8);
  uint64_t v6 = *(void *)a1;
  uint64_t v7 = v3;
  outlined copy of Result<_DataTable, Error>(v6, v3);
  uint64_t v4 = MLDataTableVisualization.init(_:)((uint64_t)&v6);
  v2[3] = &type metadata for MLDataTableVisualization;
  uint64_t result = lazy protocol witness table accessor for type MLDataTableVisualization and conformance MLDataTableVisualization();
  v2[4] = result;
  *uint64_t v2 = v4;
  return result;
}

uint64_t show<A>(_:)(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t v3 = *(void *)a1;
  char v4 = *(unsigned char *)(a1 + 8);
  if (v4 == 1)
  {
    outlined copy of Result<_DataTable, Error>(*(void *)a1, 1);
    uint64_t v5 = 0;
  }
  else
  {
    uint64_t v6 = *(void *)(v3 + 16);
    outlined copy of Result<_DataTable, Error>(*(void *)a1, 0);
    uint64_t v7 = *(void *)(v6 + 16);
    outlined copy of Result<_DataTable, Error>(v3, 0);
    outlined copy of Result<_DataTable, Error>(v3, 0);
    swift_retain();
    uint64_t v10 = specialized handling<A, B, C, D, E, F>(_:_:_:_:_:_:)(v7, (uint64_t)"", (uint64_t)"", (uint64_t)"", 0);
    if (!v10) {
      BUG();
    }
    uint64_t v8 = type metadata accessor for CMLPlot();
    uint64_t v5 = swift_allocObject(v8, 24, 7);
    *(void *)(v5 + 16) = v10;
    outlined consume of Result<_DataTable, Error>(v3, 0);
    swift_release();
    outlined consume of Result<_DataTable, Error>(v3, 0);
  }
  v2[3] = (uint64_t)&type metadata for ML1DVisualization;
  v2[4] = lazy protocol witness table accessor for type ML1DVisualization and conformance ML1DVisualization();
  uint64_t result = outlined consume of Result<_DataTable, Error>(v3, v4);
  *uint64_t v2 = v5;
  return result;
}

uint64_t dispatch thunk of MLVisualizable.cgImage.getter(uint64_t a1, uint64_t a2)
{
  return (*(uint64_t (**)(void))(a2 + 16))();
}

uint64_t dispatch thunk of MLStreamingVisualizable.nextIteration()(uint64_t a1, uint64_t a2)
{
  return (*(uint64_t (**)(void))(a2 + 16))();
}

uint64_t dispatch thunk of MLStreamingVisualizable.hasFinishedStreaming.getter(uint64_t a1, uint64_t a2)
{
  return (*(uint64_t (**)(void))(a2 + 24))();
}

uint64_t getEnumTagSinglePayload for ML2DVisualization(uint64_t a1, unsigned int a2)
{
  return getEnumTagSinglePayload for MLGazetteer.ModelParameters(a1, a2);
}

uint64_t storeEnumTagSinglePayload for ML2DVisualization(uint64_t a1, unsigned int a2, unsigned int a3)
{
  return storeEnumTagSinglePayload for MLGazetteer.ModelParameters(a1, a2, a3);
}

ValueMetadata *type metadata accessor for ML2DVisualization()
{
  return &type metadata for ML2DVisualization;
}

ValueMetadata *type metadata accessor for MLDataTableVisualization()
{
  return &type metadata for MLDataTableVisualization;
}

uint64_t *initializeBufferWithCopyOfBuffer for ML1DVisualization(uint64_t *a1, uint64_t *a2)
{
  uint64_t v3 = *a2;
  *a1 = *a2;
  swift_retain(v3);
  return a1;
}

uint64_t destroy for ML1DVisualization(void *a1)
{
  return swift_release(*a1);
}

uint64_t *assignWithCopy for ML1DVisualization(uint64_t *a1, uint64_t *a2)
{
  uint64_t v3 = *a1;
  uint64_t v4 = *a2;
  *a1 = *a2;
  swift_retain(v4);
  swift_release(v3);
  return a1;
}

uint64_t *assignWithTake for ML1DVisualization(uint64_t *a1, uint64_t *a2)
{
  uint64_t v3 = *a1;
  *a1 = *a2;
  swift_release(v3);
  return a1;
}

ValueMetadata *type metadata accessor for ML1DVisualization()
{
  return &type metadata for ML1DVisualization;
}

uint64_t instantiation function for generic protocol witness table for ML1DVisualization(uint64_t a1)
{
  uint64_t result = lazy protocol witness table accessor for type ML1DVisualization and conformance ML1DVisualization();
  *(void *)(a1 + 8) = result;
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table accessor for type ML1DVisualization and conformance ML1DVisualization();
  *(void *)(a1 + 8) = result;
  return result;
}

uint64_t instantiation function for generic protocol witness table for MLDataTableVisualization(uint64_t a1)
{
  uint64_t result = lazy protocol witness table accessor for type MLDataTableVisualization and conformance MLDataTableVisualization();
  *(void *)(a1 + 8) = result;
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table accessor for type MLDataTableVisualization and conformance MLDataTableVisualization();
  *(void *)(a1 + 8) = result;
  return result;
}

uint64_t instantiation function for generic protocol witness table for ML2DVisualization(uint64_t a1)
{
  uint64_t result = lazy protocol witness table accessor for type ML2DVisualization and conformance ML2DVisualization();
  *(void *)(a1 + 8) = result;
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table accessor for type ML2DVisualization and conformance ML2DVisualization();
  *(void *)(a1 + 8) = result;
  return result;
}

uint64_t destroy for ML2DVisualization(void *a1)
{
  return destroy for ML1DVisualization(a1);
}

uint64_t *assignWithCopy for ML2DVisualization(uint64_t *a1, uint64_t *a2)
{
  return assignWithCopy for ML1DVisualization(a1, a2);
}

uint64_t *initializeWithCopy for ML2DVisualization(uint64_t *a1, uint64_t *a2)
{
  return initializeBufferWithCopyOfBuffer for ML1DVisualization(a1, a2);
}

uint64_t *assignWithTake for ML2DVisualization(uint64_t *a1, uint64_t *a2)
{
  return assignWithTake for ML1DVisualization(a1, a2);
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance ML2DVisualization()
{
  return protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance ML1DVisualization();
}

CGImageRef_optional protocol witness for MLVisualizable.cgImage.getter in conformance ML2DVisualization()
{
  return protocol witness for MLVisualizable.cgImage.getter in conformance ML1DVisualization();
}

BOOL protocol witness for MLStreamingVisualizable.hasFinishedStreaming.getter in conformance ML2DVisualization()
{
  return protocol witness for MLStreamingVisualizable.hasFinishedStreaming.getter in conformance ML1DVisualization();
}

uint64_t InterspersedSequence.base.getter(uint64_t a1)
{
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(*(void *)(a1 + 16) - 8) + 16))(v1, v2);
}

uint64_t InterspersedSequence.separator.getter(uint64_t a1)
{
  return InterspersedSequence.separator.getter(a1);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t AssociatedTypeWitness;

  uint64_t v3 = v1;
  uint64_t v4 = v2 + *(int *)(a1 + 36);
  AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a1 + 24), *(void *)(a1 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 16))(v3, v4, AssociatedTypeWitness);
}

uint64_t InterspersedSequence.init(base:separator:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v7 = v4;
  (*(void (**)(uint64_t, uint64_t))(*(void *)(a3 - 8) + 32))(v4, a1);
  uint64_t v9 = v7 + *(int *)(type metadata accessor for InterspersedSequence(0, a3, a4, v8) + 36);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a4, a3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 32))(v9, a2, AssociatedTypeWitness);
}

uint64_t type metadata accessor for InterspersedSequence(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for InterspersedSequence);
}

uint64_t InterspersedSequence.Iterator.iterator.getter(uint64_t a1)
{
  uint64_t v3 = v1;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a1 + 24), *(void *)(a1 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 16))(v3, v2, AssociatedTypeWitness);
}

uint64_t InterspersedSequence.Iterator.iterator.setter(uint64_t a1, uint64_t a2)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a2 + 24), *(void *)(a2 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 40))(v2, a1, AssociatedTypeWitness);
}

void (*InterspersedSequence.Iterator.iterator.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t InterspersedSequence.Iterator.separator.getter(uint64_t a1)
{
  return InterspersedSequence.separator.getter(a1);
}

uint64_t variable initialization expression of InterspersedSequence.Iterator.state(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a2, a1, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  return __swift_storeEnumTagSinglePayload(v3, 1, 2, AssociatedTypeWitness);
}

uint64_t InterspersedSequence.Iterator.state.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v6 = v4;
  uint64_t v7 = v5 + *(int *)(a1 + 40);
  uint64_t v8 = type metadata accessor for InterspersedSequence.Iterator.State(0, *(void *)(a1 + 16), *(void *)(a1 + 24), a4);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v8 - 8) + 16))(v6, v7, v8);
}

uint64_t type metadata accessor for InterspersedSequence.Iterator.State(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for InterspersedSequence.Iterator.State);
}

uint64_t InterspersedSequence.Iterator.state.setter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v5 = v4 + *(int *)(a2 + 40);
  uint64_t v6 = type metadata accessor for InterspersedSequence.Iterator.State(0, *(void *)(a2 + 16), *(void *)(a2 + 24), a4);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 40))(v5, a1, v6);
}

void (*InterspersedSequence.Iterator.state.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t InterspersedSequence.Iterator.init(iterator:separator:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v7 = v4;
  uint64_t v12 = type metadata accessor for InterspersedSequence.Iterator(0, a3, a4, a4);
  uint64_t v8 = v7 + *(int *)(v12 + 40);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a4, a3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  __swift_storeEnumTagSinglePayload(v8, 1, 2, AssociatedTypeWitness);
  uint64_t v10 = swift_getAssociatedTypeWitness(0, a4, a3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v10 - 8) + 32))(v7, a1, v10);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 32))(v7 + *(int *)(v12 + 36), a2, AssociatedTypeWitness);
}

uint64_t type metadata accessor for InterspersedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for InterspersedSequence.Iterator);
}

uint64_t InterspersedSequence.Iterator.next()(uint64_t a1)
{
  uint64_t v3 = v2;
  uint64_t v51 = v1;
  uint64_t v4 = *(void *)(a1 + 16);
  uint64_t v5 = *(void *)(a1 + 24);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(255, v5, v4, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v44 = type metadata accessor for Optional(0, AssociatedTypeWitness);
  uint64_t v43 = *(void *)(v44 - 8);
  int64_t v7 = *(void *)(v43 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v41 = &v40;
  uint64_t v50 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v10 = *(void *)(v50 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v52 = &v40;
  uint64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  uint64_t v49 = &v40;
  uint64_t v47 = v4;
  uint64_t v48 = v5;
  uint64_t v15 = type metadata accessor for InterspersedSequence.Iterator.State(0, v4, v5, v10);
  uint64_t v16 = *(void *)(v15 - 8);
  int64_t v17 = *(void *)(v16 + 64);
  int64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v42 = a1;
  uint64_t v20 = *(int *)(a1 + 40);
  uint64_t v46 = v3;
  uint64_t v21 = v3 + v20;
  uint64_t v22 = v16;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v16 + 16))(&v40, v21, v15);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)&v40, 2, AssociatedTypeWitness);
  if (!EnumTagSinglePayload)
  {
    int64_t v29 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v50 + 32);
    v29(v52, &v40, AssociatedTypeWitness);
    (*(void (**)(uint64_t, uint64_t))(v22 + 8))(v21, v15);
    __swift_storeEnumTagSinglePayload(v21, 2, 2, AssociatedTypeWitness);
    uint64_t v30 = v51;
    v29((uint64_t *)v51, v52, AssociatedTypeWitness);
LABEL_8:
    uint64_t v36 = v30;
    uint64_t v37 = 0;
    return __swift_storeEnumTagSinglePayload(v36, v37, 1, AssociatedTypeWitness);
  }
  if (EnumTagSinglePayload == 1)
  {
    (*(void (**)(uint64_t, uint64_t))(v22 + 8))(v21, v15);
    __swift_storeEnumTagSinglePayload(v21, 2, 2, AssociatedTypeWitness);
    uint64_t v24 = v48;
    uint64_t v25 = v47;
    uint64_t v26 = swift_getAssociatedTypeWitness(0, v48, v47, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
    uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v24, v25, v26, &protocol requirements base descriptor for Sequence, &associated conformance descriptor for Sequence.Sequence.Iterator: IteratorProtocol);
    return dispatch thunk of IteratorProtocol.next()(v26, AssociatedConformanceWitness);
  }
  uint64_t v45 = v22;
  uint64_t v31 = v48;
  uint64_t v32 = v47;
  uint64_t v52 = (uint64_t *)swift_getAssociatedTypeWitness(0, v48, v47, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v33 = swift_getAssociatedConformanceWitness(v31, v32, v52, &protocol requirements base descriptor for Sequence, &associated conformance descriptor for Sequence.Sequence.Iterator: IteratorProtocol);
  uint64_t v34 = (uint64_t)v41;
  uint64_t v35 = v46;
  dispatch thunk of IteratorProtocol.next()(v52, v33);
  if (__swift_getEnumTagSinglePayload(v34, 1, AssociatedTypeWitness) != 1)
  {
    uint64_t v38 = v34;
    uint64_t v39 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v50 + 32);
    v39(v49, v38, AssociatedTypeWitness);
    (*(void (**)(uint64_t, uint64_t))(v45 + 8))(v21, v15);
    v39((uint64_t *)v21, (uint64_t)v49, AssociatedTypeWitness);
    __swift_storeEnumTagSinglePayload(v21, 0, 2, AssociatedTypeWitness);
    uint64_t v30 = v51;
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v50 + 16))(v51, *(int *)(v42 + 36) + v35, AssociatedTypeWitness);
    goto LABEL_8;
  }
  (*(void (**)(uint64_t, uint64_t))(v43 + 8))(v34, v44);
  uint64_t v36 = v51;
  uint64_t v37 = 1;
  return __swift_storeEnumTagSinglePayload(v36, v37, 1, AssociatedTypeWitness);
}

uint64_t protocol witness for IteratorProtocol.next() in conformance InterspersedSequence<A>.Iterator(uint64_t a1)
{
  return InterspersedSequence.Iterator.next()(a1);
}

uint64_t InterspersedSequence.makeIterator()(uint64_t a1)
{
  uint64_t v21 = v2;
  uint64_t v19 = v1;
  uint64_t v20 = a1;
  uint64_t v3 = *(void *)(a1 + 16);
  uint64_t v25 = *(void *)(a1 + 24);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v25, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v23 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v4 = *(void *)(v23 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v24 = &v19;
  uint64_t v7 = *(void *)(v3 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  int64_t v11 = *(void *)(*(void *)(swift_getAssociatedTypeWitness(0, v25, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator)- 8)+ 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = v21;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v7 + 16))(&v19, v21, v3);
  uint64_t v15 = v25;
  dispatch thunk of Sequence.makeIterator()(v3, v25);
  uint64_t v16 = v14 + *(int *)(v20 + 36);
  uint64_t v17 = (uint64_t)v24;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v23 + 16))(v24, v16, AssociatedTypeWitness);
  return InterspersedSequence.Iterator.init(iterator:separator:)((uint64_t)&v19, v17, v3, v15);
}

uint64_t protocol witness for Sequence.makeIterator() in conformance InterspersedSequence<A>(uint64_t a1, uint64_t a2)
{
  return protocol witness for Sequence.makeIterator() in conformance InterspersedSequence<A>(a1, a2, (void (*)(uint64_t))InterspersedSequence.makeIterator());
}

uint64_t protocol witness for Sequence.underestimatedCount.getter in conformance InterspersedSequence<A>()
{
  return Sequence.underestimatedCount.getter();
}

uint64_t protocol witness for Sequence._copyToContiguousArray() in conformance InterspersedSequence<A>()
{
  return Sequence._copyToContiguousArray()();
}

uint64_t protocol witness for Sequence._copyContents(initializing:) in conformance InterspersedSequence<A>()
{
  return Sequence._copyContents(initializing:)();
}

uint64_t static InterspersedSequence<>.Index.Representation.__derived_enum_equals(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v36 = a2;
  uint64_t v37 = a1;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a4, a3, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v47 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v6 = *(void *)(v47 + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v42 = v35;
  uint64_t v9 = alloca(v6);
  int64_t v10 = alloca(v6);
  uint64_t v43 = v35;
  uint64_t v40 = a3;
  uint64_t v41 = a4;
  uint64_t v11 = type metadata accessor for InterspersedSequence<>.Index.Representation(0, a3, a4, v6);
  uint64_t v12 = *(void *)(v11 - 8);
  int64_t v13 = *(void *)(v12 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v45 = v35;
  uint64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v46 = v35;
  TupleTypeMetadata2 = swift_getTupleTypeMetadata2(0, v11, v11, 0, 0);
  uint64_t v38 = *(void *)(TupleTypeMetadata2 - 8);
  int64_t v19 = *(void *)(v38 + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  uint64_t v22 = &v35[*(int *)(TupleTypeMetadata2 + 48)];
  uint64_t v39 = v12;
  uint64_t v23 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v12 + 16);
  v23(v35, v37, v11);
  v23(v22, v36, v11);
  if (swift_getEnumCaseMultiPayload(v35, v11) == 1)
  {
    v23(v45, (uint64_t)v35, v11);
    if (swift_getEnumCaseMultiPayload(v22, v11) == 1)
    {
      uint64_t v24 = v42;
      uint64_t v25 = AssociatedTypeWitness;
      (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v47 + 32))(v42, v22, AssociatedTypeWitness);
      uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v41, v40, v25, &protocol requirements base descriptor for Collection, &associated conformance descriptor for Collection.Collection.Index: Comparable);
      unsigned int v27 = dispatch thunk of static Equatable.== infix(_:_:)(v45, v24, v25, *(void *)(AssociatedConformanceWitness + 8));
      unint64_t v28 = *(void (**)(unsigned char *, uint64_t))(v47 + 8);
      v28(v42, v25);
      int64_t v29 = v45;
LABEL_9:
      v28(v29, v25);
      uint64_t v31 = v39;
      goto LABEL_10;
    }
    uint64_t v30 = v45;
  }
  else
  {
    v23(v46, (uint64_t)v35, v11);
    if (swift_getEnumCaseMultiPayload(v22, v11) != 1)
    {
      uint64_t v32 = v43;
      uint64_t v25 = AssociatedTypeWitness;
      (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v47 + 32))(v43, v22, AssociatedTypeWitness);
      uint64_t v33 = swift_getAssociatedConformanceWitness(v41, v40, v25, &protocol requirements base descriptor for Collection, &associated conformance descriptor for Collection.Collection.Index: Comparable);
      unsigned int v27 = dispatch thunk of static Equatable.== infix(_:_:)(v46, v32, v25, *(void *)(v33 + 8));
      unint64_t v28 = *(void (**)(unsigned char *, uint64_t))(v47 + 8);
      v28(v43, v25);
      int64_t v29 = v46;
      goto LABEL_9;
    }
    uint64_t v30 = v46;
  }
  (*(void (**)(unsigned char *, uint64_t))(v47 + 8))(v30, AssociatedTypeWitness);
  unsigned int v27 = 0;
  uint64_t v11 = TupleTypeMetadata2;
  uint64_t v31 = v38;
LABEL_10:
  (*(void (**)(unsigned char *, uint64_t))(v31 + 8))(v35, v11);
  return v27;
}

uint64_t type metadata accessor for InterspersedSequence<>.Index.Representation(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for InterspersedSequence<>.Index.Representation);
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance InterspersedSequence<A><>.Index.Representation(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return static InterspersedSequence<>.Index.Representation.__derived_enum_equals(_:_:)(a1, a2, *(void *)(a3 + 16), *(void *)(a3 + 24));
}

uint64_t InterspersedSequence<>.Index.representation.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v6 = v4;
  uint64_t v7 = type metadata accessor for InterspersedSequence<>.Index.Representation(0, *(void *)(a1 + 16), *(void *)(a1 + 24), a4);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v7 - 8) + 16))(v6, v5, v7);
}

uint64_t InterspersedSequence<>.Index.init(representation:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v5 = v4;
  uint64_t v6 = type metadata accessor for InterspersedSequence<>.Index.Representation(0, a2, a3, a4);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 32))(v5, a1, v6);
}

uint64_t static InterspersedSequence<>.Index.< infix(_:_:)(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4)
{
  uint64_t v43 = a2;
  uint64_t v35 = a1;
  uint64_t v6 = type metadata accessor for InterspersedSequence<>.Index.Representation(255, a3, a4, a4);
  TupleTypeMetadata2 = swift_getTupleTypeMetadata2(0, v6, v6, 0, 0);
  int64_t v8 = *(void *)(*(void *)(TupleTypeMetadata2 - 8) + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  uint64_t v41 = a4;
  uint64_t v40 = a3;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a4, a3, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v42 = *(void **)(AssociatedTypeWitness - 8);
  int64_t v12 = v42[8];
  int64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v36 = &v35;
  uint64_t v15 = alloca(v12);
  uint64_t v16 = alloca(v12);
  uint64_t v37 = &v35;
  uint64_t v17 = alloca(v12);
  int64_t v18 = alloca(v12);
  uint64_t v38 = &v35;
  int64_t v19 = alloca(v12);
  uint64_t v20 = alloca(v12);
  uint64_t v39 = &v35;
  uint64_t v21 = (char *)&v35 + *(int *)(TupleTypeMetadata2 + 48);
  uint64_t v22 = *(void (**)(uint64_t *, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16);
  v22(&v35, v35, v6);
  v22((uint64_t *)v21, (uint64_t)v43, v6);
  uint64_t v43 = &v35;
  LODWORD(v22) = swift_getEnumCaseMultiPayload(&v35, v6);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v21, v6);
  uint64_t v24 = (void (*)(uint64_t *, uint64_t *, uint64_t))v42[4];
  if (v22 != 1 || EnumCaseMultiPayload == 1)
  {
    uint64_t v30 = v39;
    v24(v39, v43, AssociatedTypeWitness);
    uint64_t v26 = v38;
    v24(v38, (uint64_t *)v21, AssociatedTypeWitness);
    uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v41, v40, AssociatedTypeWitness, &protocol requirements base descriptor for Collection, &associated conformance descriptor for Collection.Collection.Index: Comparable);
    unint64_t v28 = v30;
    unsigned int v29 = dispatch thunk of static Comparable.< infix(_:_:)(v30, v26, AssociatedTypeWitness, AssociatedConformanceWitness);
  }
  else
  {
    uint64_t v25 = v37;
    v24(v37, v43, AssociatedTypeWitness);
    uint64_t v26 = v36;
    v24(v36, (uint64_t *)v21, AssociatedTypeWitness);
    uint64_t v27 = swift_getAssociatedConformanceWitness(v41, v40, AssociatedTypeWitness, &protocol requirements base descriptor for Collection, &associated conformance descriptor for Collection.Collection.Index: Comparable);
    unint64_t v28 = v25;
    unsigned int v29 = dispatch thunk of static Comparable.<= infix(_:_:)(v25, v26, AssociatedTypeWitness, v27);
  }
  unsigned int v32 = v29;
  uint64_t v33 = (void (*)(uint64_t *, uint64_t))v42[1];
  v33(v26, AssociatedTypeWitness);
  v33(v28, AssociatedTypeWitness);
  return v32;
}

uint64_t static InterspersedSequence<>.Index.element(_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return static InterspersedSequence<>.Index.element(_:)(a1, a2, a3, 0);
}

uint64_t static InterspersedSequence<>.Index.separator(next:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return static InterspersedSequence<>.Index.element(_:)(a1, a2, a3, 1);
}

uint64_t static InterspersedSequence<>.Index.element(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  unsigned int v14 = a4;
  v13[1] = v4;
  uint64_t v6 = type metadata accessor for InterspersedSequence<>.Index.Representation(0, a2, a3, a4);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, a2, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  (*(void (**)(void *, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 16))(v13, a1, AssociatedTypeWitness);
  swift_storeEnumTagMultiPayload(v13, v6, v14);
  return InterspersedSequence<>.Index.init(representation:)((uint64_t)v13, a2, a3, v11);
}

uint64_t static InterspersedSequence<>.Index.__derived_struct_equals(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static InterspersedSequence<>.Index.Representation.__derived_enum_equals(_:_:)(a1, a2, a3, a4);
}

uint64_t protocol witness for static Comparable.< infix(_:_:) in conformance InterspersedSequence<A><>.Index(uint64_t a1, uint64_t *a2, uint64_t a3)
{
  return static InterspersedSequence<>.Index.< infix(_:_:)(a1, a2, *(void *)(a3 + 16), *(void *)(a3 + 24));
}

uint64_t protocol witness for static Comparable.<= infix(_:_:) in conformance InterspersedSequence<A><>.Index()
{
  return static Comparable.<= infix(_:_:)();
}

uint64_t protocol witness for static Comparable.>= infix(_:_:) in conformance InterspersedSequence<A><>.Index()
{
  return static Comparable.>= infix(_:_:)();
}

uint64_t protocol witness for static Comparable.> infix(_:_:) in conformance InterspersedSequence<A><>.Index()
{
  return static Comparable.> infix(_:_:)();
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance InterspersedSequence<A><>.Index(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return static InterspersedSequence<>.Index.__derived_struct_equals(_:_:)(a1, a2, *(void *)(a3 + 16), *(void *)(a3 + 24));
}

uint64_t InterspersedSequence<>.startIndex.getter(uint64_t a1, uint64_t a2)
{
  uint64_t v21 = v2;
  uint64_t v19 = a1;
  uint64_t v4 = *(void *)(a1 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a2, v4, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v17 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v5 = *(void *)(v17 + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  int64_t v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  dispatch thunk of Collection.startIndex.getter(v4, a2);
  uint64_t v22 = v3;
  dispatch thunk of Collection.endIndex.getter(v4, a2);
  uint64_t v20 = a2;
  uint64_t v23 = v4;
  uint64_t v10 = AssociatedTypeWitness;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(a2, v4, AssociatedTypeWitness, &protocol requirements base descriptor for Collection, &associated conformance descriptor for Collection.Collection.Index: Comparable);
  uint64_t v12 = v10;
  char v13 = dispatch thunk of static Equatable.== infix(_:_:)(&v17, &v17, v10, *(void *)(AssociatedConformanceWitness + 8));
  unsigned int v14 = *(void (**)(uint64_t *, uint64_t))(v17 + 8);
  v14(&v17, v12);
  v14(&v17, v12);
  if (v13) {
    return InterspersedSequence<>.endIndex.getter(v19, v20);
  }
  uint64_t v16 = v20;
  dispatch thunk of Collection.startIndex.getter(v23, v20);
  static InterspersedSequence<>.Index.element(_:)((uint64_t)&v17, v23, v16);
  return ((uint64_t (*)(uint64_t *, uint64_t))v14)(&v17, v12);
}

uint64_t InterspersedSequence<>.endIndex.getter(uint64_t a1, uint64_t a2)
{
  uint64_t v9 = v2;
  uint64_t v3 = *(void *)(a1 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a2, v3, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v10 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v5 = *(void *)(v10 + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  dispatch thunk of Collection.endIndex.getter(v3, a2);
  static InterspersedSequence<>.Index.separator(next:)((uint64_t)&v9, v3, a2);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v10 + 8))(&v9, AssociatedTypeWitness);
}

uint64_t InterspersedSequence<>.index(after:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v53 = v4;
  uint64_t v52 = a1;
  uint64_t v55 = v3;
  uint64_t v7 = *(void *)(a2 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, v7, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v58 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v8 = *(void *)(v58 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v50 = &v42;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v54 = &v42;
  uint64_t v57 = v7;
  uint64_t v56 = a3;
  uint64_t v47 = type metadata accessor for InterspersedSequence<>.Index.Representation(0, v7, a3, v8);
  uint64_t v49 = *(void *)(v47 - 8);
  int64_t v13 = *(void *)(v49 + 64);
  unsigned int v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v48 = &v42;
  uint64_t v51 = *(void *)(a2 - 8);
  int64_t v16 = *(void *)(v51 + 64);
  uint64_t v17 = alloca(v16);
  int64_t v18 = alloca(v16);
  uint64_t v20 = type metadata accessor for InterspersedSequence<>.Index(0, v7, a3, v19);
  uint64_t v21 = *(void *)(v20 - 8);
  uint64_t v42 = v20;
  int64_t v22 = *(void *)(v21 + 64);
  uint64_t v43 = v21;
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  uint64_t v25 = alloca(v22);
  uint64_t v26 = alloca(v22);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v21 + 16))(&v42, v52, v20);
  uint64_t v45 = &v42;
  uint64_t v44 = a2;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 16))(&v42, v53, a2);
  uint64_t v27 = a2;
  uint64_t v28 = v56;
  InterspersedSequence<>.endIndex.getter(v27, v56);
  char v29 = static InterspersedSequence<>.Index.Representation.__derived_enum_equals(_:_:)((uint64_t)&v42, (uint64_t)&v42, v57, v28);
  uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v43 + 8);
  uint64_t v31 = v42;
  v30(&v42, v42);
  (*(void (**)(uint64_t *, uint64_t))(v51 + 8))(v45, v44);
  v30(&v42, v31);
  if (v29) {
    BUG();
  }
  unsigned int v32 = v48;
  uint64_t v33 = v47;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v49 + 16))(v48, v52, v47);
  LODWORD(v33) = swift_getEnumCaseMultiPayload(v32, v33);
  uint64_t v34 = (uint64_t)v54;
  uint64_t v35 = AssociatedTypeWitness;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v58 + 32))(v54, v32, AssociatedTypeWitness);
  if (v33 == 1)
  {
    static InterspersedSequence<>.Index.element(_:)(v34, v57, v56);
    return (*(uint64_t (**)(uint64_t, uint64_t))(v58 + 8))(v34, v35);
  }
  else
  {
    uint64_t v37 = (uint64_t)v50;
    uint64_t v38 = v34;
    uint64_t v39 = v57;
    uint64_t v40 = v56;
    dispatch thunk of Collection.index(after:)(v38, v57, v56);
    uint64_t v41 = *(void (**)(uint64_t *, uint64_t))(v58 + 8);
    v41(v54, v35);
    static InterspersedSequence<>.Index.separator(next:)(v37, v39, v40);
    return ((uint64_t (*)(uint64_t, uint64_t))v41)(v37, v35);
  }
}

uint64_t type metadata accessor for InterspersedSequence<>.Index(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for InterspersedSequence<>.Index);
}

uint64_t InterspersedSequence<>.subscript.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v32 = v4;
  uint64_t v27 = a1;
  uint64_t v31 = v3;
  uint64_t v6 = *(void *)(a2 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, v6, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v30 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v7 = *(void *)(v30 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v28 = &v25;
  uint64_t v11 = type metadata accessor for InterspersedSequence<>.Index.Representation(0, v6, a3, v10);
  uint64_t v12 = *(void *)(v11 - 8);
  int64_t v13 = *(void *)(v12 + 64);
  unsigned int v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  int64_t v16 = &v25;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v12 + 16))(&v25, v27, v11);
  if (swift_getEnumCaseMultiPayload(&v25, v11) == 1)
  {
    uint64_t v17 = *(int *)(a2 + 36) + v32;
    uint64_t v18 = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 8), v6, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v18 - 8) + 16))(v31, v17, v18);
  }
  else
  {
    uint64_t v19 = v28;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v30 + 32))(v28, &v25, AssociatedTypeWitness);
    uint64_t v20 = (void (*)(unsigned char *, void))dispatch thunk of Collection.subscript.read(v26, v19, v6, a3);
    uint64_t v22 = v21;
    uint64_t v23 = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 8), v6, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v23 - 8) + 16))(v31, v22, v23);
    v20(v26, 0);
    int64_t v16 = v19;
  }
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v30 + 8))(v16, AssociatedTypeWitness);
}

uint64_t InterspersedSequence<>.distance(from:to:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v51 = v4;
  uint64_t v55 = a2;
  uint64_t v45 = a1;
  uint64_t v49 = 0x4000000000000000;
  uint64_t v6 = *(void *)(a3 + 16);
  uint64_t v7 = type metadata accessor for InterspersedSequence<>.Index.Representation(255, v6, a4, a4);
  TupleTypeMetadata2 = swift_getTupleTypeMetadata2(0, v7, v7, 0, 0);
  int64_t v9 = *(void *)(*(void *)(TupleTypeMetadata2 - 8) + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v50 = a4;
  uint64_t v52 = v6;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a4, v6, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v12 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v13 = *(void *)(v12 + 64);
  unsigned int v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v48 = &v45;
  int64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v54 = &v45;
  uint64_t v18 = alloca(v13);
  uint64_t v19 = alloca(v13);
  uint64_t v46 = &v45;
  uint64_t v20 = alloca(v13);
  uint64_t v21 = alloca(v13);
  uint64_t v47 = &v45;
  uint64_t v22 = (char *)&v45 + *(int *)(TupleTypeMetadata2 + 48);
  uint64_t v23 = *(void (**)(uint64_t *, uint64_t, uint64_t))(*(void *)(v7 - 8) + 16);
  v23(&v45, v45, v7);
  v23((uint64_t *)v22, v55, v7);
  LODWORD(v23) = swift_getEnumCaseMultiPayload(&v45, v7);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v22, v7);
  uint64_t v55 = v12;
  uint64_t v25 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v12 + 32);
  if (v23 == 1)
  {
    if (EnumCaseMultiPayload != 1)
    {
      uint64_t v26 = v54;
      uint64_t v27 = AssociatedTypeWitness;
      v25(v54, &v45, AssociatedTypeWitness);
      uint64_t v28 = v48;
      v25(v48, (uint64_t *)v22, v27);
      uint64_t v29 = dispatch thunk of Collection.distance(from:to:)(v26, v28, v52, v50);
      uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v55 + 8);
      v30(v28, v27);
      v30(v54, v27);
      v49 += v29;
      if (v49 < 0) {
        BUG();
      }
      return 2 * v29 + 1;
    }
    goto LABEL_9;
  }
  if (EnumCaseMultiPayload != 1)
  {
LABEL_9:
    uint64_t v39 = v47;
    uint64_t v40 = AssociatedTypeWitness;
    v25(v47, &v45, AssociatedTypeWitness);
    uint64_t v41 = v46;
    v25(v46, (uint64_t *)v22, v40);
    uint64_t v42 = dispatch thunk of Collection.distance(from:to:)(v39, v41, v52, v50);
    uint64_t v43 = *(void (**)(uint64_t *, uint64_t))(v55 + 8);
    v43(v41, v40);
    v43(v47, v40);
    v49 += v42;
    if (v49 < 0) {
      BUG();
    }
    return 2 * v42;
  }
  uint64_t v32 = v54;
  uint64_t v33 = AssociatedTypeWitness;
  v25(v54, &v45, AssociatedTypeWitness);
  uint64_t v34 = v48;
  v25(v48, (uint64_t *)v22, v33);
  uint64_t v35 = dispatch thunk of Collection.distance(from:to:)(v32, v34, v52, v50);
  uint64_t v36 = *(void (**)(uint64_t *, uint64_t))(v55 + 8);
  v36(v34, v33);
  v36(v54, v33);
  v49 += v35;
  if (v49 < 0) {
    BUG();
  }
  uint64_t v37 = 2 * v35;
  BOOL v38 = __OFSUB__(v37, 1);
  uint64_t v31 = v37 - 1;
  if (v38) {
    BUG();
  }
  return v31;
}

uint64_t InterspersedSequence<>.index(_:offsetBy:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a2 >= 0) {
    return InterspersedSequence<>.offsetForward(_:by:)(a1, a2, a3, a4);
  }
  uint64_t v5 = -a2;
  if (__OFSUB__(v5, 1)) {
    BUG();
  }
  return InterspersedSequence<>.offsetBackward(_:by:)(a1, v5, a3, a4);
}

uint64_t InterspersedSequence<>.offsetForward(_:by:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedSequence<>.offsetForward(_:by:)(a1, a2, a3, a4, (void (*)(uint64_t, uint64_t))InterspersedSequence<>.endIndex.getter, (void (*)(uint64_t, uint64_t, uint64_t *, uint64_t, uint64_t))InterspersedSequence<>.offsetForward(_:by:limitedBy:), 193);
}

uint64_t InterspersedSequence<>.offsetBackward(_:by:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedSequence<>.offsetForward(_:by:)(a1, a2, a3, a4, (void (*)(uint64_t, uint64_t))InterspersedSequence<>.startIndex.getter, (void (*)(uint64_t, uint64_t, uint64_t *, uint64_t, uint64_t))InterspersedSequence<>.offsetBackward(_:by:limitedBy:), 200);
}

uint64_t InterspersedSequence<>.offsetForward(_:by:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void (*a5)(uint64_t, uint64_t), void (*a6)(uint64_t, uint64_t, uint64_t *, uint64_t, uint64_t), uint64_t a7)
{
  uint64_t v27 = a4;
  uint64_t v21 = v7;
  uint64_t v23 = a2;
  uint64_t v22 = a6;
  uint64_t v26 = a5;
  uint64_t v24 = a1;
  uint64_t v9 = *(void *)(a3 + 16);
  uint64_t v28 = a3;
  uint64_t v10 = type metadata accessor for InterspersedSequence<>.Index(0, v9, a4, a4);
  uint64_t v25 = *(void *)(v10 - 8);
  int64_t v11 = *(void *)(v25 + 64);
  uint64_t v12 = alloca(v11);
  int64_t v13 = alloca(v11);
  uint64_t v30 = type metadata accessor for Optional(0, v10);
  uint64_t v29 = *(void *)(v30 - 8);
  int64_t v14 = *(void *)(v29 + 64);
  uint64_t v15 = alloca(v14);
  int64_t v16 = alloca(v14);
  uint64_t v17 = a3;
  uint64_t v18 = v27;
  v26(v17, v27);
  v22(v24, v23, &v21, v28, v18);
  uint64_t v19 = v25;
  (*(void (**)(uint64_t *, uint64_t))(v25 + 8))(&v21, v10);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v21, 1, v10) == 1)
  {
    (*(void (**)(uint64_t *, uint64_t))(v29 + 8))(&v21, v30);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000016, "Algorithms/Intersperse.swift" + 0x8000000000000000, "Algorithms/Intersperse.swift", 28, 2, a7, 0);
    BUG();
  }
  return (*(uint64_t (**)(uint64_t, uint64_t *, uint64_t))(v19 + 32))(v21, &v21, v10);
}

uint64_t InterspersedSequence<>.index(_:offsetBy:limitedBy:)(uint64_t a1, uint64_t a2, unsigned char *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v14 = v5;
  uint64_t v7 = type metadata accessor for InterspersedSequence<>.Index(0, *(void *)(a4 + 16), a5, a4);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for InterspersedSequence<A><>.Index, v7);
  if (a2 >= 0)
  {
    if (static Comparable.>= infix(_:_:)(a3, a1, v7, WitnessTable)) {
      return InterspersedSequence<>.offsetForward(_:by:limitedBy:)(a1, a2, a3, a4, a5);
    }
    uint64_t v13 = v14;
    InterspersedSequence<>.offsetForward(_:by:)(a1, a2, a4, a5);
    return __swift_storeEnumTagSinglePayload(v13, 0, 1, v7);
  }
  char v10 = static Comparable.<= infix(_:_:)(a3, a1, v7, WitnessTable);
  uint64_t v11 = -a2;
  BOOL v12 = __OFSUB__(-a2, 1);
  if ((v10 & 1) == 0)
  {
    if (v12) {
      BUG();
    }
    uint64_t v13 = v14;
    InterspersedSequence<>.offsetBackward(_:by:)(a1, v11, a4, a5);
    return __swift_storeEnumTagSinglePayload(v13, 0, 1, v7);
  }
  if (v12) {
    BUG();
  }
  return InterspersedSequence<>.offsetBackward(_:by:limitedBy:)(a1, v11, a3, a4, a5);
}

uint64_t InterspersedSequence<>.offsetForward(_:by:limitedBy:)(uint64_t a1, uint64_t a2, unsigned char *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v94 = a3;
  uint64_t v86 = v5;
  uint64_t v79 = a2;
  uint64_t v89 = v6;
  uint64_t v80 = a1;
  uint64_t v8 = *(void *)(a4 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(255, a5, v8, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v85 = type metadata accessor for Optional(0, AssociatedTypeWitness);
  uint64_t v84 = *(void *)(v85 - 8);
  int64_t v10 = *(void *)(v84 + 64);
  uint64_t v11 = alloca(v10);
  BOOL v12 = alloca(v10);
  uint64_t v93 = v78;
  uint64_t v88 = v8;
  uint64_t v87 = a5;
  uint64_t v14 = type metadata accessor for InterspersedSequence<>.Index.Representation(255, v8, a5, v13);
  TupleTypeMetadata3 = swift_getTupleTypeMetadata3(0, v14, v14, &type metadata for Bool, 0, 0);
  int64_t v16 = *(void *)(*(void *)(TupleTypeMetadata3 - 8) + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v96 = AssociatedTypeWitness;
  int v92 = *(void **)(AssociatedTypeWitness - 8);
  int64_t v19 = v92[8];
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  uint64_t v82 = v78;
  uint64_t v22 = alloca(v19);
  uint64_t v23 = alloca(v19);
  uint64_t v90 = v78;
  uint64_t v24 = alloca(v19);
  uint64_t v25 = alloca(v19);
  uint64_t v81 = v78;
  uint64_t v26 = alloca(v19);
  uint64_t v27 = alloca(v19);
  uint64_t v95 = v78;
  uint64_t v28 = alloca(v19);
  uint64_t v29 = alloca(v19);
  uint64_t v83 = v78;
  uint64_t v30 = alloca(v19);
  uint64_t v31 = alloca(v19);
  uint64_t v91 = v78;
  uint64_t v32 = &v78[*(int *)(TupleTypeMetadata3 + 48)];
  uint64_t v33 = *(int *)(TupleTypeMetadata3 + 64);
  uint64_t v34 = *(void (**)(unsigned char *, uint64_t, uint64_t))(*(void *)(v14 - 8) + 16);
  v34(v78, v80, v14);
  v34(v32, (uint64_t)v94, v14);
  uint64_t v35 = v79;
  v78[v33] = (v79 & 1) == 0;
  LODWORD(v33) = swift_getEnumCaseMultiPayload(v78, v14);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v32, v14);
  uint64_t v37 = (void (*)(unsigned char *, unsigned char *, uint64_t))v92[4];
  if (v33 != 1)
  {
    uint64_t v38 = v35;
    if (EnumCaseMultiPayload == 1)
    {
      uint64_t v39 = v96;
      uint64_t v40 = v95;
      if ((v38 & 1) == 0) {
        goto LABEL_7;
      }
    }
    else
    {
      uint64_t v39 = v96;
      uint64_t v40 = v95;
      if ((v38 & 1) == 0) {
        goto LABEL_9;
      }
    }
LABEL_11:
    v37(v40, v78, v39);
    char v64 = v81;
    v37(v81, v32, v39);
    BOOL v65 = __OFADD__(1, v38);
    uint64_t v66 = v38 + 1;
    if (v65) {
      BUG();
    }
    uint64_t v67 = v66 / 2;
    uint64_t v68 = v93;
    uint64_t v69 = v88;
    uint64_t v70 = v87;
    dispatch thunk of Collection.index(_:offsetBy:limitedBy:)(v95, v67, v64, v88, v87);
    uint64_t v94 = v78;
    char v71 = alloca(32);
    BOOL v72 = alloca(32);
    uint64_t v80 = v69;
    uint64_t v81 = (unsigned char *)v70;
    uint64_t v74 = type metadata accessor for InterspersedSequence<>.Index(0, v69, v70, v73);
    uint64_t v75 = v85;
    _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF((void (*)(uint64_t *, uint64_t *))partial apply for closure #2 in InterspersedSequence<>.offsetForward(_:by:limitedBy:), (uint64_t)v78, v85, (uint64_t)&type metadata for Never, v74, (uint64_t)&protocol witness table for Never, v77);
    (*(void (**)(unsigned char *, uint64_t))(v84 + 8))(v68, v75);
    uint64_t v50 = (void (*)(unsigned char *, uint64_t))v92[1];
    uint64_t v51 = v96;
    v50(v81, v96);
    uint64_t v52 = v95;
    goto LABEL_13;
  }
  uint64_t v38 = v35;
  if (EnumCaseMultiPayload == 1)
  {
    uint64_t v39 = v96;
    uint64_t v40 = v95;
    if ((v38 & 1) == 0) {
      goto LABEL_11;
    }
LABEL_7:
    v37(v90, v78, v39);
    uint64_t v41 = v82;
    v37(v82, v32, v39);
    uint64_t v42 = v88;
    uint64_t v43 = v87;
    dispatch thunk of Collection.index(_:offsetBy:limitedBy:)(v90, v38 / 2, v41, v88, v87);
    uint64_t v94 = v78;
    uint64_t v44 = alloca(40);
    uint64_t v45 = alloca(48);
    uint64_t v80 = v42;
    uint64_t v81 = (unsigned char *)v43;
    uint64_t v82 = v41;
    uint64_t v47 = type metadata accessor for InterspersedSequence<>.Index(0, v42, v43, v46);
    uint64_t v48 = v85;
    uint64_t v49 = v93;
    _sSq7flatMapyqd_0_SgABxqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF((uint64_t)partial apply for closure #3 in InterspersedSequence<>.offsetForward(_:by:limitedBy:), (uint64_t)v78, v85, (uint64_t)&type metadata for Never, v47, (uint64_t)&protocol witness table for Never, v77);
    (*(void (**)(unsigned char *, uint64_t))(v84 + 8))(v49, v48);
    uint64_t v50 = (void (*)(unsigned char *, uint64_t))v92[1];
    uint64_t v51 = v96;
    v50(v90, v96);
    uint64_t v52 = v82;
LABEL_13:
    uint64_t v63 = v51;
    return ((uint64_t (*)(unsigned char *, uint64_t))v50)(v52, v63);
  }
  uint64_t v39 = v96;
  uint64_t v40 = v95;
  if ((v38 & 1) == 0) {
    goto LABEL_11;
  }
LABEL_9:
  v37(v91, v78, v39);
  uint64_t v53 = v83;
  v37(v83, v32, v39);
  uint64_t v54 = v38 / 2;
  uint64_t v55 = v88;
  uint64_t v56 = v87;
  dispatch thunk of Collection.index(_:offsetBy:limitedBy:)(v91, v54, v53, v88, v87);
  uint64_t v94 = v78;
  uint64_t v57 = alloca(32);
  uint64_t v58 = alloca(32);
  uint64_t v80 = v55;
  uint64_t v81 = (unsigned char *)v56;
  uint64_t v60 = type metadata accessor for InterspersedSequence<>.Index(0, v55, v56, v59);
  uint64_t v61 = v85;
  uint64_t v62 = v93;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF((void (*)(uint64_t *, uint64_t *))partial apply for closure #1 in InterspersedSequence<>.offsetForward(_:by:limitedBy:), (uint64_t)v78, v85, (uint64_t)&type metadata for Never, v60, (uint64_t)&protocol witness table for Never, v77);
  (*(void (**)(unsigned char *, uint64_t))(v84 + 8))(v62, v61);
  uint64_t v50 = (void (*)(unsigned char *, uint64_t))v92[1];
  v50(v83, v39);
  uint64_t v52 = v91;
  uint64_t v63 = v39;
  return ((uint64_t (*)(unsigned char *, uint64_t))v50)(v52, v63);
}

uint64_t InterspersedSequence<>.offsetBackward(_:by:limitedBy:)(uint64_t a1, uint64_t a2, unsigned char *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v95 = a3;
  uint64_t v86 = v5;
  uint64_t v80 = a2;
  uint64_t v89 = v6;
  uint64_t v81 = a1;
  uint64_t v8 = *(void *)(a4 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(255, a5, v8, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v85 = type metadata accessor for Optional(0, AssociatedTypeWitness);
  uint64_t v84 = *(void *)(v85 - 8);
  int64_t v10 = *(void *)(v84 + 64);
  uint64_t v11 = alloca(v10);
  BOOL v12 = alloca(v10);
  uint64_t v94 = v79;
  uint64_t v88 = v8;
  uint64_t v87 = a5;
  uint64_t v14 = type metadata accessor for InterspersedSequence<>.Index.Representation(255, v8, a5, v13);
  TupleTypeMetadata3 = swift_getTupleTypeMetadata3(0, v14, v14, &type metadata for Bool, 0, 0);
  int64_t v16 = *(void *)(*(void *)(TupleTypeMetadata3 - 8) + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v97 = AssociatedTypeWitness;
  uint64_t v93 = *(void **)(AssociatedTypeWitness - 8);
  int64_t v19 = v93[8];
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  uint64_t v90 = v79;
  uint64_t v22 = alloca(v19);
  uint64_t v23 = alloca(v19);
  uint64_t v91 = v79;
  uint64_t v24 = alloca(v19);
  uint64_t v25 = alloca(v19);
  uint64_t v83 = v79;
  uint64_t v26 = alloca(v19);
  uint64_t v27 = alloca(v19);
  int v92 = v79;
  uint64_t v28 = alloca(v19);
  uint64_t v29 = alloca(v19);
  uint64_t v82 = v79;
  uint64_t v30 = alloca(v19);
  uint64_t v31 = alloca(v19);
  uint64_t v96 = v79;
  uint64_t v32 = &v79[*(int *)(TupleTypeMetadata3 + 48)];
  uint64_t v33 = *(int *)(TupleTypeMetadata3 + 64);
  uint64_t v34 = *(void (**)(unsigned char *, uint64_t, uint64_t))(*(void *)(v14 - 8) + 16);
  v34(v79, v81, v14);
  v34(v32, (uint64_t)v95, v14);
  uint64_t v35 = v80;
  v79[v33] = (v80 & 1) == 0;
  LODWORD(v33) = swift_getEnumCaseMultiPayload(v79, v14);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v32, v14);
  uint64_t v37 = (void (*)(unsigned char *, unsigned char *, uint64_t))v93[4];
  if (v33 != 1)
  {
    uint64_t v38 = v35;
    if (EnumCaseMultiPayload == 1)
    {
      uint64_t v39 = v97;
      uint64_t v40 = v96;
      if (v38) {
        goto LABEL_7;
      }
LABEL_9:
      v37(v40, v79, v39);
      uint64_t v54 = v82;
      v37(v82, v32, v39);
      BOOL v55 = __OFADD__(1, v38);
      uint64_t v56 = v38 + 1;
      if (v55) {
        BUG();
      }
      uint64_t v57 = v56 / -2;
      uint64_t v58 = v94;
      uint64_t v59 = v88;
      uint64_t v60 = v87;
      dispatch thunk of Collection.index(_:offsetBy:limitedBy:)(v96, v57, v54, v88, v87);
      uint64_t v95 = v79;
      uint64_t v61 = alloca(32);
      uint64_t v62 = alloca(32);
      uint64_t v81 = v59;
      uint64_t v82 = (unsigned char *)v60;
      uint64_t v64 = type metadata accessor for InterspersedSequence<>.Index(0, v59, v60, v63);
      uint64_t v65 = v85;
      _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF((void (*)(uint64_t *, uint64_t *))partial apply for closure #1 in InterspersedSequence<>.offsetBackward(_:by:limitedBy:), (uint64_t)v79, v85, (uint64_t)&type metadata for Never, v64, (uint64_t)&protocol witness table for Never, v78);
      (*(void (**)(unsigned char *, uint64_t))(v84 + 8))(v58, v65);
      uint64_t v51 = (void (*)(unsigned char *, uint64_t))v93[1];
      uint64_t v52 = v97;
      v51(v82, v97);
      uint64_t v53 = v96;
      goto LABEL_11;
    }
    uint64_t v39 = v97;
    uint64_t v40 = v96;
    if ((v38 & 1) == 0) {
      goto LABEL_9;
    }
LABEL_13:
    v37(v91, v79, v39);
    uint64_t v67 = v90;
    v37(v90, v32, v39);
    uint64_t v68 = v38 / -2;
    uint64_t v69 = v88;
    uint64_t v70 = v87;
    dispatch thunk of Collection.index(_:offsetBy:limitedBy:)(v91, v68, v67, v88, v87);
    uint64_t v95 = v79;
    char v71 = alloca(40);
    BOOL v72 = alloca(48);
    uint64_t v81 = v69;
    uint64_t v82 = (unsigned char *)v70;
    uint64_t v83 = v90;
    uint64_t v74 = type metadata accessor for InterspersedSequence<>.Index(0, v69, v70, v73);
    uint64_t v75 = v85;
    uint64_t v76 = v94;
    _sSq7flatMapyqd_0_SgABxqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF((uint64_t)partial apply for closure #3 in InterspersedSequence<>.offsetBackward(_:by:limitedBy:), (uint64_t)v79, v85, (uint64_t)&type metadata for Never, v74, (uint64_t)&protocol witness table for Never, v78);
    (*(void (**)(unsigned char *, uint64_t))(v84 + 8))(v76, v75);
    uint64_t v51 = (void (*)(unsigned char *, uint64_t))v93[1];
    v51(v91, v39);
    uint64_t v53 = v90;
    uint64_t v66 = v39;
    return ((uint64_t (*)(unsigned char *, uint64_t))v51)(v53, v66);
  }
  uint64_t v38 = v35;
  if (EnumCaseMultiPayload != 1)
  {
    uint64_t v39 = v97;
    uint64_t v40 = v96;
    if (v38) {
      goto LABEL_9;
    }
    goto LABEL_13;
  }
  uint64_t v39 = v97;
  uint64_t v40 = v96;
  if (v38) {
    goto LABEL_9;
  }
LABEL_7:
  v37(v92, v79, v39);
  uint64_t v41 = v83;
  v37(v83, v32, v39);
  uint64_t v42 = v38 / -2;
  uint64_t v43 = v94;
  uint64_t v44 = v88;
  uint64_t v45 = v87;
  dispatch thunk of Collection.index(_:offsetBy:limitedBy:)(v92, v42, v41, v88, v87);
  uint64_t v95 = v79;
  uint64_t v46 = alloca(32);
  uint64_t v47 = alloca(32);
  uint64_t v81 = v44;
  uint64_t v82 = (unsigned char *)v45;
  uint64_t v49 = type metadata accessor for InterspersedSequence<>.Index(0, v44, v45, v48);
  uint64_t v50 = v85;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF((void (*)(uint64_t *, uint64_t *))partial apply for closure #2 in InterspersedSequence<>.offsetBackward(_:by:limitedBy:), (uint64_t)v79, v85, (uint64_t)&type metadata for Never, v49, (uint64_t)&protocol witness table for Never, v78);
  (*(void (**)(unsigned char *, uint64_t))(v84 + 8))(v43, v50);
  uint64_t v51 = (void (*)(unsigned char *, uint64_t))v93[1];
  uint64_t v52 = v97;
  v51(v83, v97);
  uint64_t v53 = v92;
LABEL_11:
  uint64_t v66 = v52;
  return ((uint64_t (*)(unsigned char *, uint64_t))v51)(v53, v66);
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF(void (*a1)(uint64_t *, uint64_t *), uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v32 = v7;
  uint64_t v29 = a2;
  uint64_t v33 = v8;
  uint64_t v27 = a5;
  uint64_t v28 = a1;
  uint64_t v30 = a4;
  uint64_t v31 = *(void *)(a4 - 8);
  int64_t v10 = *(void *)(v31 + 64);
  uint64_t v11 = alloca(v10);
  BOOL v12 = alloca(v10);
  uint64_t v35 = &v26;
  uint64_t v13 = *(void *)(a3 + 16);
  uint64_t v34 = *(void *)(v13 - 8);
  int64_t v14 = *(void *)(v34 + 64);
  uint64_t v15 = alloca(v14);
  int64_t v16 = alloca(v14);
  uint64_t v17 = *(void *)(a3 - 8);
  int64_t v18 = *(void *)(v17 + 64);
  int64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  (*(void (**)(uint64_t *, uint64_t))(v17 + 16))(&v26, v9);
  unsigned int v21 = 1;
  if (__swift_getEnumTagSinglePayload((uint64_t)&v26, 1, v13) == 1)
  {
    uint64_t v22 = v32;
  }
  else
  {
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v34 + 32))(&v26, &v26, v13);
    uint64_t v23 = v32;
    uint64_t v24 = v33;
    v28(&v26, v35);
    (*(void (**)(uint64_t *, uint64_t))(v34 + 8))(&v26, v13);
    if (v24) {
      return (*(uint64_t (**)(uint64_t, uint64_t *, uint64_t))(v31 + 32))(a7, v35, v30);
    }
    uint64_t v22 = v23;
    unsigned int v21 = 0;
  }
  return __swift_storeEnumTagSinglePayload(v22, v21, 1, v27);
}

uint64_t partial apply for closure #3 in InterspersedSequence<>.offsetForward(_:by:limitedBy:)(uint64_t a1, uint64_t a2)
{
  return closure #3 in InterspersedSequence<>.offsetForward(_:by:limitedBy:)(a1, v2[4], v2[2], v2[3], a2, (void (*)(uint64_t, uint64_t, uint64_t))static InterspersedSequence<>.Index.element(_:));
}

uint64_t _sSq7flatMapyqd_0_SgABxqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v29 = v7;
  v24[1] = a2;
  uint64_t v28 = v8;
  uint64_t v25 = a5;
  v24[0] = a1;
  uint64_t v26 = a4;
  uint64_t v27 = *(void *)(a4 - 8);
  int64_t v10 = *(void *)(v27 + 64);
  uint64_t v11 = alloca(v10);
  BOOL v12 = alloca(v10);
  uint64_t v30 = v24;
  uint64_t v13 = *(void *)(a3 + 16);
  uint64_t v14 = *(void *)(v13 - 8);
  int64_t v15 = *(void *)(v14 + 64);
  int64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v18 = *(void *)(a3 - 8);
  int64_t v19 = *(void *)(v18 + 64);
  uint64_t v20 = alloca(v19);
  unsigned int v21 = alloca(v19);
  (*(void (**)(void *, uint64_t))(v18 + 16))(v24, v9);
  if (__swift_getEnumTagSinglePayload((uint64_t)v24, 1, v13) == 1) {
    return __swift_storeEnumTagSinglePayload(v29, 1, 1, v25);
  }
  (*(void (**)(void *, void *, uint64_t))(v14 + 32))(v24, v24, v13);
  uint64_t v23 = v28;
  ((void (*)(void *, void *))v24[0])(v24, v30);
  uint64_t result = (*(uint64_t (**)(void *, uint64_t))(v14 + 8))(v24, v13);
  if (v23) {
    return (*(uint64_t (**)(uint64_t, void *, uint64_t))(v27 + 32))(a7, v30, v26);
  }
  return result;
}

uint64_t partial apply for closure #2 in InterspersedSequence<>.offsetForward(_:by:limitedBy:)(uint64_t a1)
{
  return static InterspersedSequence<>.Index.separator(next:)(a1, *(void *)(v1 + 16), *(void *)(v1 + 24));
}

uint64_t partial apply for closure #1 in InterspersedSequence<>.offsetForward(_:by:limitedBy:)(uint64_t a1)
{
  return static InterspersedSequence<>.Index.element(_:)(a1, *(void *)(v1 + 16), *(void *)(v1 + 24));
}

uint64_t closure #3 in InterspersedSequence<>.offsetForward(_:by:limitedBy:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, void (*a6)(uint64_t, uint64_t, uint64_t))
{
  uint64_t v17 = v6;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a4, a3, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(a4, a3, AssociatedTypeWitness, &protocol requirements base descriptor for Collection, &associated conformance descriptor for Collection.Collection.Index: Comparable);
  if (dispatch thunk of static Equatable.== infix(_:_:)(a1, a2, AssociatedTypeWitness, *(void *)(AssociatedConformanceWitness + 8)))
  {
    unsigned int v12 = 1;
    uint64_t v13 = v17;
  }
  else
  {
    a6(a1, a3, a4);
    uint64_t v13 = v17;
    unsigned int v12 = 0;
  }
  uint64_t v14 = type metadata accessor for InterspersedSequence<>.Index(0, a3, a4, v11);
  return __swift_storeEnumTagSinglePayload(v13, v12, 1, v14);
}

uint64_t partial apply for closure #3 in InterspersedSequence<>.offsetBackward(_:by:limitedBy:)(uint64_t a1, uint64_t a2)
{
  return closure #3 in InterspersedSequence<>.offsetForward(_:by:limitedBy:)(a1, v2[4], v2[2], v2[3], a2, (void (*)(uint64_t, uint64_t, uint64_t))static InterspersedSequence<>.Index.separator(next:));
}

uint64_t protocol witness for Collection.startIndex.getter in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2)
{
  return InterspersedSequence<>.startIndex.getter(a1, *(void *)(a2 - 8));
}

uint64_t protocol witness for Collection.endIndex.getter in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2)
{
  return InterspersedSequence<>.endIndex.getter(a1, *(void *)(a2 - 8));
}

void (*protocol witness for Collection.subscript.read in conformance <> InterspersedSequence<A>(uint64_t **a1, uint64_t a2, uint64_t a3, uint64_t a4))(void (***a1)(void))
{
  uint64_t v5 = (uint64_t *)malloc(0x28uLL);
  *a1 = v5;
  void v5[4] = (uint64_t)InterspersedSequence<>.subscript.read(v5, a2, a3, *(void *)(a4 - 8));
  return protocol witness for Collection.subscript.read in conformance <> InterspersedSequence<A>;
}

void protocol witness for Collection.subscript.read in conformance <> InterspersedSequence<A>(void (***a1)(void))
{
}

{
  void (**v1)(void);

  uint64_t v1 = *a1;
  v1[4](v1);
  free(v1);
}

void (*InterspersedSequence<>.subscript.read(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4))(void *a1)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a4 + 8), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  *a1 = AssociatedTypeWitness;
  uint64_t v7 = *(void *)(AssociatedTypeWitness - 8);
  a1[1] = v7;
  a1[2] = (uint64_t)malloc(*(void *)(v7 + 64));
  InterspersedSequence<>.subscript.getter(a2, a3, a4);
  return InterspersedSequence<>.subscript.read;
}

void InterspersedSequence<>.subscript.read(void *a1)
{
}

{
  void *v1;

  uint64_t v1 = (void *)a1[2];
  (*(void (**)(void *, void))(a1[1] + 8))(v1, *a1);
  free(v1);
}

uint64_t protocol witness for Collection.subscript.getter in conformance <> InterspersedSequence<A>()
{
  return Collection<>.subscript.getter();
}

uint64_t protocol witness for Collection.indices.getter in conformance <> InterspersedSequence<A>()
{
  return Collection<>.indices.getter();
}

uint64_t protocol witness for Collection.isEmpty.getter in conformance <> InterspersedSequence<A>()
{
  return Collection.isEmpty.getter();
}

uint64_t protocol witness for Collection.count.getter in conformance <> InterspersedSequence<A>()
{
  return Collection.count.getter();
}

uint64_t protocol witness for Collection._customIndexOfEquatableElement(_:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return protocol witness for Collection._customIndexOfEquatableElement(_:) in conformance <> InterspersedSequence<A>(a1, a2, a3, a4);
}

{
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;

  uint64_t v5 = v4;
  uint64_t v6 = type metadata accessor for InterspersedSequence<>.Index(255, *(void *)(a2 + 16), *(void *)(a3 - 8), a4);
  uint64_t v7 = type metadata accessor for Optional(0, v6);
  return __swift_storeEnumTagSinglePayload(v5, 1, 1, v7);
}

uint64_t protocol witness for Collection.index(_:offsetBy:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedSequence<>.index(_:offsetBy:)(a1, a2, a3, *(void *)(a4 - 8));
}

uint64_t protocol witness for Collection.index(_:offsetBy:limitedBy:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, unsigned char *a3, uint64_t a4, uint64_t a5)
{
  return InterspersedSequence<>.index(_:offsetBy:limitedBy:)(a1, a2, a3, a4, *(void *)(a5 - 8));
}

uint64_t protocol witness for Collection.distance(from:to:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedSequence<>.distance(from:to:)(a1, a2, a3, *(void *)(a4 - 8));
}

uint64_t protocol witness for Collection._failEarlyRangeCheck(_:bounds:) in conformance <> InterspersedSequence<A>()
{
  return Collection._failEarlyRangeCheck(_:bounds:)();
}

{
  return Collection._failEarlyRangeCheck(_:bounds:)();
}

{
  return Collection._failEarlyRangeCheck(_:bounds:)();
}

uint64_t protocol witness for Collection.index(after:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return InterspersedSequence<>.index(after:)(a1, a2, *(void *)(a3 - 8));
}

uint64_t protocol witness for Collection.formIndex(after:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v12[2] = a2;
  v12[1] = v4;
  uint64_t v5 = *(void *)(a3 - 8);
  uint64_t v6 = type metadata accessor for InterspersedSequence<>.Index(0, *(void *)(a2 + 16), v5, a4);
  uint64_t v7 = *(void *)(v6 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  InterspersedSequence<>.index(after:)(a1, a2, v5);
  (*(void (**)(uint64_t, uint64_t))(v7 + 8))(a1, v6);
  return (*(uint64_t (**)(uint64_t, void *, uint64_t))(v7 + 32))(a1, v12, v6);
}

uint64_t InterspersedSequence<>.index(before:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v57 = v4;
  uint64_t v56 = a1;
  uint64_t v59 = v3;
  uint64_t v53 = a3;
  uint64_t v6 = *(void *)(a3 + 8);
  uint64_t v7 = *(void *)(a2 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v6, v7, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v49 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v8 = *(void *)(v49 + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  uint64_t v54 = &v43;
  uint64_t v11 = alloca(v8);
  unsigned int v12 = alloca(v8);
  uint64_t v58 = &v43;
  uint64_t v61 = v7;
  uint64_t v60 = v6;
  uint64_t v50 = type metadata accessor for InterspersedSequence<>.Index.Representation(0, v7, v6, v8);
  uint64_t v52 = *(void *)(v50 - 8);
  int64_t v13 = *(void *)(v52 + 64);
  uint64_t v14 = alloca(v13);
  int64_t v15 = alloca(v13);
  uint64_t v51 = &v43;
  uint64_t v55 = *(void *)(a2 - 8);
  int64_t v16 = *(void *)(v55 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v20 = type metadata accessor for InterspersedSequence<>.Index(0, v7, v6, v19);
  uint64_t v21 = *(void *)(v20 - 8);
  uint64_t v44 = v20;
  int64_t v22 = *(void *)(v21 + 64);
  uint64_t v45 = v21;
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  uint64_t v25 = alloca(v22);
  uint64_t v26 = alloca(v22);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v21 + 16))(&v43, v56, v20);
  uint64_t v47 = &v43;
  uint64_t v46 = a2;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v55 + 16))(&v43, v57, a2);
  uint64_t v27 = a2;
  uint64_t v28 = v60;
  InterspersedSequence<>.startIndex.getter(v27, v60);
  char v29 = static InterspersedSequence<>.Index.Representation.__derived_enum_equals(_:_:)((uint64_t)&v43, (uint64_t)&v43, v61, v28);
  uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v45 + 8);
  uint64_t v31 = v44;
  v30(&v43, v44);
  (*(void (**)(uint64_t *, uint64_t))(v55 + 8))(v47, v46);
  v30(&v43, v31);
  if (v29) {
    BUG();
  }
  uint64_t v32 = v51;
  uint64_t v33 = v50;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v52 + 16))(v51, v56, v50);
  LODWORD(v33) = swift_getEnumCaseMultiPayload(v32, v33);
  uint64_t v34 = (uint64_t)v58;
  uint64_t v35 = v32;
  uint64_t v36 = AssociatedTypeWitness;
  uint64_t v37 = v49;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v49 + 32))(v58, v35, AssociatedTypeWitness);
  if (v33 == 1)
  {
    uint64_t v38 = (uint64_t)v54;
    uint64_t v39 = v34;
    uint64_t v40 = v61;
    dispatch thunk of BidirectionalCollection.index(before:)(v39, v61, v53);
    uint64_t v41 = *(void (**)(uint64_t *, uint64_t))(v37 + 8);
    v41(v58, v36);
    static InterspersedSequence<>.Index.element(_:)(v38, v40, v60);
    return ((uint64_t (*)(uint64_t, uint64_t))v41)(v38, v36);
  }
  else
  {
    static InterspersedSequence<>.Index.separator(next:)(v34, v61, v60);
    return (*(uint64_t (**)(uint64_t, uint64_t))(v37 + 8))(v34, v36);
  }
}

uint64_t protocol witness for BidirectionalCollection.index(before:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return InterspersedSequence<>.index(before:)(a1, a2, *(void *)(a3 - 8));
}

uint64_t protocol witness for BidirectionalCollection.formIndex(before:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v12[2] = a2;
  v12[1] = v4;
  uint64_t v5 = *(void *)(a3 - 8);
  uint64_t v6 = type metadata accessor for InterspersedSequence<>.Index(0, *(void *)(a2 + 16), *(void *)(v5 + 8), a4);
  uint64_t v7 = *(void *)(v6 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  InterspersedSequence<>.index(before:)(a1, a2, v5);
  (*(void (**)(uint64_t, uint64_t))(v7 + 8))(a1, v6);
  return (*(uint64_t (**)(uint64_t, void *, uint64_t))(v7 + 32))(a1, v12, v6);
}

uint64_t protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedSequence<>.index(_:offsetBy:)(a1, a2, a3, *(void *)(*(void *)(a4 - 8) + 8));
}

uint64_t protocol witness for BidirectionalCollection.index(_:offsetBy:limitedBy:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, unsigned char *a3, uint64_t a4, uint64_t a5)
{
  return InterspersedSequence<>.index(_:offsetBy:limitedBy:)(a1, a2, a3, a4, *(void *)(*(void *)(a5 - 8) + 8));
}

uint64_t protocol witness for BidirectionalCollection.distance(from:to:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedSequence<>.distance(from:to:)(a1, a2, a3, *(void *)(*(void *)(a4 - 8) + 8));
}

uint64_t protocol witness for RandomAccessCollection.index(_:offsetBy:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedSequence<>.index(_:offsetBy:)(a1, a2, a3, *(void *)(*(void *)(*(void *)(a4 - 8) + 8) + 8));
}

uint64_t protocol witness for RandomAccessCollection.index(_:offsetBy:limitedBy:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, unsigned char *a3, uint64_t a4, uint64_t a5)
{
  return InterspersedSequence<>.index(_:offsetBy:limitedBy:)(a1, a2, a3, a4, *(void *)(*(void *)(*(void *)(a5 - 8) + 8) + 8));
}

uint64_t protocol witness for RandomAccessCollection.distance(from:to:) in conformance <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedSequence<>.distance(from:to:)(a1, a2, a3, *(void *)(*(void *)(*(void *)(a4 - 8) + 8) + 8));
}

uint64_t protocol witness for LazySequenceProtocol.elements.getter in conformance <> InterspersedSequence<A>()
{
  return LazySequenceProtocol<>.elements.getter();
}

uint64_t InterspersedMapSequence.transform.getter(uint64_t a1)
{
  return InterspersedMapSequence.transform.getter(a1);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v2 = *(int *)(a1 + 44);
  uint64_t v3 = *(void *)(v1 + v2);
  swift_retain(*(void *)(v1 + v2 + 8));
  return v3;
}

uint64_t InterspersedMapSequence.separator.getter(uint64_t a1)
{
  return InterspersedMapSequence.separator.getter(a1);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v2 = *(int *)(a1 + 48);
  uint64_t v3 = *(void *)(v1 + v2);
  swift_retain(*(void *)(v1 + v2 + 8));
  return v3;
}

uint64_t InterspersedMapSequence.init(base:transform:separator:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  uint64_t v10 = v8;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(a6 - 8) + 32))(v8, a1, a6);
  uint64_t v13 = type metadata accessor for InterspersedMapSequence(0, a6, a7, a8);
  uint64_t v14 = *(int *)(v13 + 44);
  *(void *)(v10 + v14) = a2;
  *(void *)(v10 + v14 + 8) = a3;
  uint64_t result = *(int *)(v13 + 48);
  *(void *)(v10 + result) = a4;
  *(void *)(v10 + result + 8) = a5;
  return result;
}

uint64_t InterspersedMapSequence.Iterator.base.getter(uint64_t a1)
{
  uint64_t v3 = v1;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a1 + 32), *(void *)(a1 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 16))(v3, v2, AssociatedTypeWitness);
}

uint64_t InterspersedMapSequence.Iterator.base.setter(uint64_t a1, uint64_t a2)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a2 + 32), *(void *)(a2 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 40))(v2, a1, AssociatedTypeWitness);
}

void (*InterspersedMapSequence.Iterator.base.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t InterspersedMapSequence.Iterator.transform.getter(uint64_t a1)
{
  return InterspersedMapSequence.transform.getter(a1);
}

uint64_t InterspersedMapSequence.Iterator.separator.getter(uint64_t a1)
{
  return InterspersedMapSequence.separator.getter(a1);
}

uint64_t variable initialization expression of InterspersedMapSequence.Iterator.state(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  uint64_t v5 = type metadata accessor for InterspersedMapSequence.Iterator.State(0, a1, a2, a3);
  return swift_storeEnumTagMultiPayload(v4, v5, 2);
}

uint64_t type metadata accessor for InterspersedMapSequence.Iterator.State(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for InterspersedMapSequence.Iterator.State);
}

uint64_t InterspersedMapSequence.Iterator.state.getter(uint64_t a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = v2 + *(int *)(a1 + 52);
  uint64_t v5 = type metadata accessor for InterspersedMapSequence.Iterator.State(0, *(void *)(a1 + 16), *(void *)(a1 + 24), *(void *)(a1 + 32));
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16))(v3, v4, v5);
}

uint64_t InterspersedMapSequence.Iterator.state.setter(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2 + *(int *)(a2 + 52);
  uint64_t v4 = type metadata accessor for InterspersedMapSequence.Iterator.State(0, *(void *)(a2 + 16), *(void *)(a2 + 24), *(void *)(a2 + 32));
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 40))(v3, a1, v4);
}

void (*InterspersedMapSequence.Iterator.state.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t InterspersedMapSequence.Iterator.init(base:transform:separator:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  uint64_t v9 = v8;
  uint64_t v11 = (int *)type metadata accessor for InterspersedMapSequence.Iterator(0, a6, a7, a8);
  uint64_t v12 = v9 + v11[13];
  uint64_t v13 = type metadata accessor for InterspersedMapSequence.Iterator.State(0, a6, a7, a8);
  swift_storeEnumTagMultiPayload(v12, v13, 2);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a8, a6, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 32))(v9, a1, AssociatedTypeWitness);
  uint64_t v15 = v11[11];
  *(void *)(v9 + v15) = a2;
  *(void *)(v9 + v15 + 8) = a3;
  uint64_t result = v11[12];
  *(void *)(v9 + result) = a4;
  *(void *)(v9 + result + 8) = a5;
  return result;
}

uint64_t type metadata accessor for InterspersedMapSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for InterspersedMapSequence.Iterator);
}

uint64_t InterspersedMapSequence.Iterator.next()(uint64_t a1)
{
  uint64_t v71 = v1;
  uint64_t v3 = *(void *)(a1 + 16);
  uint64_t v4 = *(void *)(a1 + 32);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(255, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v64 = type metadata accessor for Optional(0, AssociatedTypeWitness);
  uint64_t v63 = *(void *)(v64 - 8);
  int64_t v6 = *(void *)(v63 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v59 = &v57;
  uint64_t v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  uint64_t v69 = &v57;
  uint64_t v72 = AssociatedTypeWitness;
  uint64_t v73 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v11 = *(void *)(v73 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v60 = &v57;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  uint64_t v61 = &v57;
  int64_t v16 = alloca(v11);
  uint64_t v17 = alloca(v11);
  uint64_t v68 = &v57;
  uint64_t v18 = alloca(v11);
  uint64_t v19 = alloca(v11);
  uint64_t v65 = &v57;
  uint64_t v20 = *(void *)(a1 + 24);
  uint64_t v62 = v3;
  uint64_t v58 = v20;
  uint64_t v21 = type metadata accessor for InterspersedMapSequence.Iterator.State(0, v3, v20, v4);
  uint64_t v22 = *(void *)(v21 - 8);
  int64_t v23 = *(void *)(v22 + 64);
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  uint64_t v66 = a1;
  uint64_t v26 = *(int *)(a1 + 52);
  uint64_t v70 = v2;
  uint64_t v27 = v2 + v26;
  uint64_t v67 = v22;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v22 + 16))(&v57, v27, v21);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v57, v21);
  if (!EnumCaseMultiPayload)
  {
    uint64_t v36 = v60;
    uint64_t v37 = v72;
    uint64_t v38 = v73;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v73 + 32))(v60, &v57, v72);
    (*(void (**)(uint64_t, uint64_t))(v67 + 8))(v27, v21);
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v38 + 16))(v27, v36, v37);
    swift_storeEnumTagMultiPayload(v27, v21, 1);
    uint64_t v39 = v71;
    (*(void (**)(uint64_t *))(v70 + *(int *)(v66 + 44)))(v36);
    uint64_t v40 = v36;
    uint64_t v41 = v72;
LABEL_11:
    (*(void (**)(uint64_t *, uint64_t))(v73 + 8))(v40, v41);
    goto LABEL_12;
  }
  if (EnumCaseMultiPayload != 1)
  {
    uint64_t v42 = v62;
    uint64_t v43 = swift_getAssociatedTypeWitness(0, v4, v62, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
    uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v4, v42, v43, &protocol requirements base descriptor for Sequence, &associated conformance descriptor for Sequence.Sequence.Iterator: IteratorProtocol);
    uint64_t v45 = v69;
    dispatch thunk of IteratorProtocol.next()(v43, AssociatedConformanceWitness);
    uint64_t v46 = v45;
    uint64_t v47 = (uint64_t)v45;
    uint64_t v48 = v72;
    if (__swift_getEnumTagSinglePayload(v47, 1, v72) == 1)
    {
      (*(void (**)(uint64_t *, uint64_t))(v63 + 8))(v46, v64);
      uint64_t v35 = 1;
      goto LABEL_8;
    }
    uint64_t v54 = v73;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v73 + 32))(v65, v46, v48);
    (*(void (**)(uint64_t, uint64_t))(v67 + 8))(v27, v21);
    uint64_t v55 = v65;
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v54 + 16))(v27, v65, v48);
    swift_storeEnumTagMultiPayload(v27, v21, 1);
    uint64_t v39 = v71;
    (*(void (**)(uint64_t *))(v70 + *(int *)(v66 + 44)))(v55);
    uint64_t v40 = v55;
    uint64_t v41 = v48;
    goto LABEL_11;
  }
  uint64_t v69 = *(uint64_t **)(v73 + 32);
  ((void (*)(uint64_t *, uint64_t *, uint64_t))v69)(v68, &v57, v72);
  uint64_t v29 = v62;
  uint64_t v30 = swift_getAssociatedTypeWitness(0, v4, v62, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v31 = swift_getAssociatedConformanceWitness(v4, v29, v30, &protocol requirements base descriptor for Sequence, &associated conformance descriptor for Sequence.Sequence.Iterator: IteratorProtocol);
  uint64_t v32 = (uint64_t)v59;
  dispatch thunk of IteratorProtocol.next()(v30, v31);
  uint64_t v33 = v32;
  uint64_t v34 = v72;
  if (__swift_getEnumTagSinglePayload(v32, 1, v72) != 1)
  {
    uint64_t v49 = v61;
    ((void (*)(uint64_t *, uint64_t, uint64_t))v69)(v61, v33, v34);
    (*(void (**)(uint64_t, uint64_t))(v67 + 8))(v27, v21);
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v73 + 16))(v27, v49, v34);
    swift_storeEnumTagMultiPayload(v27, v21, 0);
    uint64_t v39 = v71;
    uint64_t v50 = v68;
    (*(void (**)(uint64_t *, uint64_t *))(v70 + *(int *)(v66 + 48)))(v68, v49);
    uint64_t v51 = *(void (**)(uint64_t *, uint64_t))(v73 + 8);
    uint64_t v52 = v49;
    uint64_t v53 = v72;
    v51(v52, v72);
    v51(v50, v53);
LABEL_12:
    uint64_t v35 = 0;
    return __swift_storeEnumTagSinglePayload(v39, v35, 1, v58);
  }
  (*(void (**)(uint64_t *, uint64_t))(v73 + 8))(v68, v34);
  (*(void (**)(uint64_t, uint64_t))(v63 + 8))(v32, v64);
  uint64_t v35 = 1;
LABEL_8:
  uint64_t v39 = v71;
  return __swift_storeEnumTagSinglePayload(v39, v35, 1, v58);
}

uint64_t protocol witness for IteratorProtocol.next() in conformance InterspersedMapSequence<A, B>.Iterator(uint64_t a1)
{
  return InterspersedMapSequence.Iterator.next()(a1);
}

uint64_t InterspersedMapSequence.makeIterator()(uint64_t a1)
{
  v12[1] = v1;
  uint64_t v3 = *(void *)(a1 + 16);
  uint64_t v13 = *(void *)(v3 - 8);
  int64_t v4 = *(void *)(v13 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v14 = *(void *)(a1 + 32);
  int64_t v7 = *(void *)(*(void *)(swift_getAssociatedTypeWitness(0, v14, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator)- 8)+ 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v15 = v12;
  (*(void (**)(void *, uint64_t, uint64_t))(v13 + 16))(v12, v2, v3);
  uint64_t v10 = v14;
  dispatch thunk of Sequence.makeIterator()(v3, v14);
  InterspersedMapSequence.Iterator.init(base:transform:separator:)((uint64_t)v15, *(void *)(v2 + *(int *)(a1 + 44)), *(void *)(v2 + *(int *)(a1 + 44) + 8), *(void *)(v2 + *(int *)(a1 + 48)), *(void *)(v2 + *(int *)(a1 + 48) + 8), v3, *(void *)(a1 + 24), v10);
  swift_retain();
  return swift_retain();
}

uint64_t protocol witness for Sequence.makeIterator() in conformance InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2)
{
  return protocol witness for Sequence.makeIterator() in conformance InterspersedSequence<A>(a1, a2, (void (*)(uint64_t))InterspersedMapSequence.makeIterator());
}

uint64_t protocol witness for Sequence.makeIterator() in conformance InterspersedSequence<A>(uint64_t a1, uint64_t a2, void (*a3)(uint64_t a1))
{
  a3(a1);
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(a1 - 8) + 8))(v3, a1);
}

uint64_t InterspersedMapSequence<>.Index.representation.getter(uint64_t *a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(0, a1[2], a1[3], a1[4]);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(v3, v2, v4);
}

uint64_t type metadata accessor for InterspersedMapSequence<>.Index.Representation(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for InterspersedMapSequence<>.Index.Representation);
}

uint64_t InterspersedMapSequence<>.Index.init(representation:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v5 = v4;
  uint64_t v6 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(0, a2, a3, a4);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 32))(v5, a1, v6);
}

uint64_t static InterspersedMapSequence<>.Index.element(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v14 = a1;
  v13[1] = v4;
  uint64_t v7 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(0, a2, a3, a4);
  int64_t v8 = *(void *)(*(void *)(v7 - 8) + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a4, a2, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  (*(void (**)(void *, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 16))(v13, v14, AssociatedTypeWitness);
  swift_storeEnumTagMultiPayload(v13, v7, 0);
  return InterspersedMapSequence<>.Index.init(representation:)((uint64_t)v13, a2, a3, a4);
}

uint64_t static InterspersedMapSequence<>.Index.separator(previous:next:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v17 = a4;
  uint64_t v18 = a2;
  uint64_t v20 = a1;
  uint64_t v16 = v5;
  uint64_t v21 = a5;
  uint64_t v19 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(0, a3, a4, a5);
  int64_t v8 = *(void *)(*(void *)(v19 - 8) + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(255, a5, a3, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v12 = &v15[*(int *)(swift_getTupleTypeMetadata2(0, AssociatedTypeWitness, AssociatedTypeWitness, "previous next ", 0)+ 48)];
  uint64_t v13 = *(void (**)(unsigned char *, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 16);
  v13(v15, v20, AssociatedTypeWitness);
  v13(v12, v18, AssociatedTypeWitness);
  swift_storeEnumTagMultiPayload(v15, v19, 1);
  return InterspersedMapSequence<>.Index.init(representation:)((uint64_t)v15, a3, v17, v21);
}

uint64_t static InterspersedMapSequence<>.Index.== infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v37 = a2;
  uint64_t v38 = a1;
  uint64_t v7 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(255, a3, a4, a5);
  TupleTypeMetadata2 = swift_getTupleTypeMetadata2(0, v7, v7, 0, 0);
  int64_t v9 = *(void *)(*(void *)(TupleTypeMetadata2 - 8) + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v45 = (char *)&v37;
  uint64_t v39 = a5;
  uint64_t v40 = a3;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a5, a3, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v44 = *(void **)(AssociatedTypeWitness - 8);
  int64_t v13 = v44[8];
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v42 = &v37;
  uint64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v43 = &v37;
  uint64_t v18 = (char *)&v37 + *(int *)(TupleTypeMetadata2 + 48);
  uint64_t v41 = *(void *)(v7 - 8);
  uint64_t v19 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v41 + 16);
  v19(&v37, v38, v7);
  v19((uint64_t *)v18, v37, v7);
  if (swift_getEnumCaseMultiPayload(&v37, v7) == 1)
  {
    uint64_t v20 = *(int *)(swift_getTupleTypeMetadata2(0, AssociatedTypeWitness, AssociatedTypeWitness, "previous next ", 0)
                 + 48);
    uint64_t v21 = (char *)&v37 + v20;
    if (swift_getEnumCaseMultiPayload(v18, v7) != 1)
    {
      (*(void (**)(char *, uint64_t))(v41 + 8))(v18, v7);
      uint64_t v31 = (void (*)(char *, uint64_t))v44[1];
      v31(v21, AssociatedTypeWitness);
      v31(v45, AssociatedTypeWitness);
      return 0;
    }
    uint64_t v22 = v44;
    int64_t v23 = (void (*)(uint64_t *, char *, uint64_t))v44[4];
    v23(v43, (char *)&v37 + v20, AssociatedTypeWitness);
    uint64_t v24 = &v18[v20];
    uint64_t v25 = v22;
    uint64_t v26 = v42;
    v23(v42, v24, AssociatedTypeWitness);
    uint64_t v27 = (void (*)(char *, uint64_t))v25[1];
    v27(v18, AssociatedTypeWitness);
    v27(v45, AssociatedTypeWitness);
  }
  else
  {
    if (swift_getEnumCaseMultiPayload(v18, v7) == 1)
    {
      unsigned int v28 = 0;
      uint64_t v29 = swift_getTupleTypeMetadata2(0, AssociatedTypeWitness, AssociatedTypeWitness, "previous next ", 0);
      uint64_t v30 = (void (*)(char *, uint64_t))v44[1];
      v30(&v18[*(int *)(v29 + 48)], AssociatedTypeWitness);
      v30(v18, AssociatedTypeWitness);
      v30(v45, AssociatedTypeWitness);
      return v28;
    }
    uint64_t v25 = v44;
    uint64_t v32 = (void (*)(uint64_t *, char *, uint64_t))v44[4];
    v32(v43, v45, AssociatedTypeWitness);
    uint64_t v26 = v42;
    v32(v42, v18, AssociatedTypeWitness);
  }
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v39, v40, AssociatedTypeWitness, &protocol requirements base descriptor for Collection, &associated conformance descriptor for Collection.Collection.Index: Comparable);
  uint64_t v34 = v43;
  unsigned int v28 = dispatch thunk of static Equatable.== infix(_:_:)(v43, v26, AssociatedTypeWitness, *(void *)(AssociatedConformanceWitness + 8));
  uint64_t v35 = (void (*)(uint64_t *, uint64_t))v25[1];
  v35(v26, AssociatedTypeWitness);
  v35(v34, AssociatedTypeWitness);
  return v28;
}

uint64_t static InterspersedMapSequence<>.Index.< infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v46 = a2;
  uint64_t v47 = a1;
  uint64_t v7 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(255, a3, a4, a5);
  TupleTypeMetadata2 = swift_getTupleTypeMetadata2(0, v7, v7, 0, 0);
  int64_t v9 = *(void *)(*(void *)(TupleTypeMetadata2 - 8) + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v50 = v43;
  uint64_t v44 = a5;
  uint64_t v45 = a3;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a5, a3, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v48 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v13 = *(void *)(v48 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v49 = v43;
  uint64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v51 = v43;
  uint64_t v18 = &v43[*(int *)(TupleTypeMetadata2 + 48)];
  uint64_t v19 = *(void (**)(unsigned char *, uint64_t, uint64_t))(*(void *)(v7 - 8) + 16);
  v19(v43, v47, v7);
  v19(v18, v46, v7);
  if (swift_getEnumCaseMultiPayload(v43, v7) == 1)
  {
    uint64_t v20 = *(int *)(swift_getTupleTypeMetadata2(0, AssociatedTypeWitness, AssociatedTypeWitness, "previous next ", 0)
                 + 48);
    uint64_t v21 = &v43[v20];
    if (swift_getEnumCaseMultiPayload(v18, v7) == 1)
    {
      uint64_t v22 = v48;
      int64_t v23 = *(void (**)(unsigned char *, unsigned char *, uint64_t))(v48 + 32);
      v23(v51, &v43[v20], AssociatedTypeWitness);
      uint64_t v24 = &v18[v20];
      uint64_t v25 = v22;
      uint64_t v26 = v49;
      v23(v49, v24, AssociatedTypeWitness);
      uint64_t v27 = *(void (**)(unsigned char *, uint64_t))(v25 + 8);
      v27(v18, AssociatedTypeWitness);
      v27(v50, AssociatedTypeWitness);
LABEL_9:
      uint64_t v33 = v25;
      goto LABEL_10;
    }
    uint64_t v29 = v48;
    uint64_t v35 = *(void (**)(unsigned char *, unsigned char *, uint64_t))(v48 + 32);
    v35(v51, v50, AssociatedTypeWitness);
    uint64_t v36 = v35;
    uint64_t v26 = v49;
    v36(v49, v18, AssociatedTypeWitness);
    uint64_t v34 = v21;
    uint64_t v33 = v29;
  }
  else
  {
    if (swift_getEnumCaseMultiPayload(v18, v7) != 1)
    {
      uint64_t v25 = v48;
      uint64_t v37 = *(void (**)(unsigned char *, unsigned char *, uint64_t))(v48 + 32);
      v37(v51, v50, AssociatedTypeWitness);
      uint64_t v26 = v49;
      v37(v49, v18, AssociatedTypeWitness);
      goto LABEL_9;
    }
    unsigned int v28 = &v18[*(int *)(swift_getTupleTypeMetadata2(0, AssociatedTypeWitness, AssociatedTypeWitness, "previous next ", 0)+ 48)];
    uint64_t v29 = v48;
    uint64_t v30 = *(void (**)(unsigned char *, unsigned char *, uint64_t))(v48 + 32);
    v30(v51, v50, AssociatedTypeWitness);
    uint64_t v31 = v30;
    uint64_t v26 = v49;
    uint64_t v32 = v28;
    uint64_t v33 = v29;
    v31(v49, v32, AssociatedTypeWitness);
    uint64_t v34 = v18;
  }
  (*(void (**)(unsigned char *, uint64_t))(v29 + 8))(v34, AssociatedTypeWitness);
LABEL_10:
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v44, v45, AssociatedTypeWitness, &protocol requirements base descriptor for Collection, &associated conformance descriptor for Collection.Collection.Index: Comparable);
  uint64_t v39 = v51;
  unsigned int v40 = dispatch thunk of static Comparable.< infix(_:_:)(v51, v26, AssociatedTypeWitness, AssociatedConformanceWitness);
  uint64_t v41 = *(void (**)(unsigned char *, uint64_t))(v33 + 8);
  v41(v26, AssociatedTypeWitness);
  v41(v39, AssociatedTypeWitness);
  return v40;
}

uint64_t protocol witness for static Comparable.< infix(_:_:) in conformance InterspersedMapSequence<A, B><>.Index(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  return static InterspersedMapSequence<>.Index.< infix(_:_:)(a1, a2, a3[2], a3[3], a3[4]);
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance InterspersedMapSequence<A, B><>.Index(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  return static InterspersedMapSequence<>.Index.== infix(_:_:)(a1, a2, a3[2], a3[3], a3[4]);
}

uint64_t InterspersedMapSequence<>.startIndex.getter(uint64_t a1, uint64_t a2)
{
  uint64_t v11 = v2;
  uint64_t v3 = *(void *)(a1 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a2, v3, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v9 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v4 = *(void *)(v9 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  if (dispatch thunk of Collection.isEmpty.getter(v3, a2)) {
    return InterspersedMapSequence<>.endIndex.getter(a1, a2);
  }
  dispatch thunk of Collection.startIndex.getter(v3, a2);
  static InterspersedMapSequence<>.Index.element(_:)((uint64_t)&v8, v3, *(void *)(a1 + 24), a2);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v9 + 8))(&v8, AssociatedTypeWitness);
}

uint64_t InterspersedMapSequence<>.endIndex.getter(uint64_t a1, uint64_t a2)
{
  uint64_t v13 = a1;
  uint64_t v12 = v2;
  uint64_t v3 = *(void *)(a1 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a2, v3, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v15 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v4 = *(void *)(v15 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  dispatch thunk of Collection.endIndex.getter(v3, a2);
  dispatch thunk of Collection.endIndex.getter(v3, a2);
  static InterspersedMapSequence<>.Index.separator(previous:next:)((uint64_t)&v12, (uint64_t)&v12, v3, *(void *)(v13 + 24), a2);
  uint64_t v9 = *(void (**)(uint64_t *, uint64_t))(v15 + 8);
  uint64_t v10 = AssociatedTypeWitness;
  v9(&v12, AssociatedTypeWitness);
  return ((uint64_t (*)(uint64_t *, uint64_t))v9)(&v12, v10);
}

uint64_t InterspersedMapSequence<>.index(after:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v28[1] = v4;
  v28[0] = a1;
  uint64_t v32 = v3;
  uint64_t v6 = *(void *)(a2 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, v6, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v35 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v8 = *(void *)(v35 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v29 = v28;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v13 = *(void *)(a2 + 24);
  uint64_t v33 = v6;
  uint64_t v34 = v13;
  uint64_t v31 = a3;
  uint64_t v14 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(0, v6, v13, a3);
  uint64_t v15 = *(void *)(v14 - 8);
  int64_t v16 = *(void *)(v15 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  (*(void (**)(void *, void, uint64_t))(v15 + 16))(v28, v28[0], v14);
  if (swift_getEnumCaseMultiPayload(v28, v14) == 1)
  {
    TupleTypeMetadata2 = swift_getTupleTypeMetadata2(0, AssociatedTypeWitness, AssociatedTypeWitness, "previous next ", 0);
    uint64_t v20 = v35;
    (*(void (**)(void *, char *, uint64_t))(v35 + 32))(v28, (char *)v28 + *(int *)(TupleTypeMetadata2 + 48), AssociatedTypeWitness);
    static InterspersedMapSequence<>.Index.element(_:)((uint64_t)v28, v33, v34, v31);
    uint64_t v21 = *(void (**)(void *, uint64_t))(v20 + 8);
    v21(v28, AssociatedTypeWitness);
    return ((uint64_t (*)(void *, uint64_t))v21)(v28, AssociatedTypeWitness);
  }
  else
  {
    uint64_t v30 = AssociatedTypeWitness;
    (*(void (**)(void *, void *, uint64_t))(v35 + 32))(v28, v28, AssociatedTypeWitness);
    uint64_t v23 = (uint64_t)v29;
    uint64_t v24 = v33;
    uint64_t v25 = v31;
    dispatch thunk of Collection.index(after:)(v28, v33, v31);
    static InterspersedMapSequence<>.Index.separator(previous:next:)((uint64_t)v28, v23, v24, v34, v25);
    uint64_t v26 = *(void (**)(uint64_t, uint64_t))(v35 + 8);
    uint64_t v27 = v30;
    v26(v23, v30);
    return ((uint64_t (*)(void *, uint64_t))v26)(v28, v27);
  }
}

uint64_t InterspersedMapSequence<>.subscript.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v64 = v4;
  uint64_t v70 = a1;
  uint64_t v62 = v3;
  uint64_t v6 = *(void *)(a2 + 16);
  uint64_t v71 = *(void *)(v6 - 8);
  int64_t v7 = *(void *)(v71 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  uint64_t v57 = v55;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 8), v6, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v67 = *(void **)(AssociatedTypeWitness - 8);
  int64_t v12 = v67[8];
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v56 = v55;
  uint64_t v15 = alloca(v12);
  int64_t v16 = alloca(v12);
  uint64_t v68 = v55;
  uint64_t v17 = swift_getAssociatedTypeWitness(0, a3, v6, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v72 = *(void **)(v17 - 8);
  int64_t v18 = v72[8];
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v73 = (void (*)(unsigned char *))v55;
  uint64_t v21 = alloca(v18);
  uint64_t v22 = alloca(v18);
  uint64_t v66 = v55;
  uint64_t v74 = a2;
  uint64_t v23 = *(void *)(a2 + 24);
  uint64_t v69 = a3;
  uint64_t v24 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(0, v6, v23, a3);
  uint64_t v25 = *(void *)(v24 - 8);
  int64_t v26 = *(void *)(v25 + 64);
  uint64_t v27 = alloca(v26);
  unsigned int v28 = alloca(v26);
  (*(void (**)(unsigned char *, uint64_t, uint64_t))(v25 + 16))(v55, v70, v24);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v55, v24);
  uint64_t v61 = v17;
  if (EnumCaseMultiPayload == 1)
  {
    uint64_t v30 = &v55[*(int *)(swift_getTupleTypeMetadata2(0, v17, v17, "previous next ", 0) + 48)];
    uint64_t v31 = v17;
    uint64_t v32 = (void (*)(void (*)(unsigned char *), unsigned char *, uint64_t))v72[4];
    uint64_t v65 = v55;
    uint64_t v33 = v66;
    uint64_t v34 = v31;
    v32((void (*)(unsigned char *))v66, v55, v31);
    v32(v73, v30, v34);
    uint64_t v35 = *(int *)(v74 + 48);
    uint64_t v36 = v64;
    uint64_t v74 = *(void *)(v64 + v35);
    uint64_t v70 = *(void *)(v64 + v35 + 8);
    uint64_t v37 = v71;
    uint64_t v58 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v71 + 16);
    uint64_t v38 = v57;
    v58(v57, v64, v6);
    uint64_t v60 = (void (*)(unsigned char *, void))dispatch thunk of Collection.subscript.read(v55, v33, v6, v69);
    uint64_t v59 = (void (*)(unsigned char *, uint64_t, uint64_t))v67[2];
    uint64_t v39 = AssociatedTypeWitness;
    v59(v68, v40, AssociatedTypeWitness);
    v60(v55, 0);
    uint64_t v71 = *(void *)(v37 + 8);
    ((void (*)(unsigned char *, uint64_t))v71)(v38, v6);
    v58(v65, v36, v6);
    uint64_t v41 = (void (*)(unsigned char *, void))dispatch thunk of Collection.subscript.read(v55, v73, v6, v69);
    uint64_t v42 = v56;
    v59(v56, v43, v39);
    v41(v55, 0);
    ((void (*)(unsigned char *, uint64_t))v71)(v65, v6);
    uint64_t v44 = v68;
    ((void (*)(unsigned char *, unsigned char *))v74)(v68, v42);
    uint64_t v45 = (void (*)(unsigned char *, uint64_t))v67[1];
    v45(v42, v39);
    v45(v44, v39);
    uint64_t v46 = (void (*)(void (*)(void), uint64_t))v72[1];
    v46((void (*)(void))v73, v61);
    return ((uint64_t (*)(unsigned char *, uint64_t))v46)(v66, v61);
  }
  else
  {
    uint64_t v48 = v66;
    ((void (*)(unsigned char *, unsigned char *, uint64_t))v72[4])(v66, v55, v17);
    uint64_t v49 = *(int *)(v74 + 44);
    uint64_t v50 = AssociatedTypeWitness;
    uint64_t v73 = *(void (**)(unsigned char *))(v64 + v49);
    uint64_t v74 = *(void *)(v64 + v49 + 8);
    uint64_t v51 = (void (*)(unsigned char *, void))dispatch thunk of Collection.subscript.read(v55, v48, v6, v69);
    uint64_t v52 = v68;
    uint64_t v53 = v67;
    ((void (*)(unsigned char *, uint64_t, uint64_t))v67[2])(v68, v54, v50);
    v51(v55, 0);
    v73(v52);
    ((void (*)(unsigned char *, uint64_t))v53[1])(v52, v50);
    return ((uint64_t (*)(unsigned char *, uint64_t))v72[1])(v66, v61);
  }
}

uint64_t InterspersedMapSequence<>.distance(from:to:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v55 = v4;
  uint64_t v50 = a2;
  uint64_t v51 = a1;
  uint64_t v53 = 0x4000000000000000;
  uint64_t v6 = *(void *)(a3 + 16);
  uint64_t v7 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(255, v6, *(void *)(a3 + 24), a4);
  TupleTypeMetadata2 = swift_getTupleTypeMetadata2(0, v7, v7, 0, 0);
  int64_t v9 = *(void *)(*(void *)(TupleTypeMetadata2 - 8) + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v59 = v49;
  uint64_t v54 = a4;
  uint64_t v56 = v6;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a4, v6, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v61 = *(void **)(AssociatedTypeWitness - 8);
  int64_t v13 = v61[8];
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v52 = v49;
  int64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v60 = v49;
  int64_t v18 = alloca(v13);
  uint64_t v19 = alloca(v13);
  uint64_t v57 = v49;
  uint64_t v20 = alloca(v13);
  uint64_t v21 = alloca(v13);
  uint64_t v58 = v49;
  uint64_t v22 = &v49[*(int *)(TupleTypeMetadata2 + 48)];
  uint64_t v23 = *(void (**)(unsigned char *, uint64_t, uint64_t))(*(void *)(v7 - 8) + 16);
  v23(v49, v51, v7);
  v23(v22, v50, v7);
  if (swift_getEnumCaseMultiPayload(v49, v7) == 1)
  {
    uint64_t v24 = *(int *)(swift_getTupleTypeMetadata2(0, AssociatedTypeWitness, AssociatedTypeWitness, "previous next ", 0)
                 + 48);
    uint64_t v25 = &v49[v24];
    if (swift_getEnumCaseMultiPayload(v22, v7) == 1)
    {
      int64_t v26 = (void (*)(unsigned char *, unsigned char *, uint64_t))v61[4];
      uint64_t v27 = v61;
      v26(v58, &v49[v24], AssociatedTypeWitness);
      unsigned int v28 = &v22[v24];
      uint64_t v29 = v57;
      v26(v57, v28, AssociatedTypeWitness);
      uint64_t v30 = (void (*)(unsigned char *, uint64_t))v27[1];
      v30(v22, AssociatedTypeWitness);
      v30(v59, AssociatedTypeWitness);
LABEL_11:
      uint64_t v45 = v58;
      uint64_t v46 = dispatch thunk of Collection.distance(from:to:)(v58, v29, v56, v54);
      uint64_t v47 = (void (*)(unsigned char *, uint64_t))v27[1];
      v47(v57, AssociatedTypeWitness);
      v47(v45, AssociatedTypeWitness);
      v53 += v46;
      if (v53 < 0) {
        BUG();
      }
      return 2 * v46;
    }
    uint64_t v39 = (void (*)(unsigned char *, unsigned char *, uint64_t))v61[4];
    uint64_t v40 = v60;
    v39(v60, v22, AssociatedTypeWitness);
    uint64_t v41 = v52;
    v39(v52, v25, AssociatedTypeWitness);
    uint64_t v42 = dispatch thunk of Collection.distance(from:to:)(v41, v40, v56, v54);
    uint64_t v43 = (void (*)(unsigned char *, uint64_t))v61[1];
    v43(v41, AssociatedTypeWitness);
    v43(v60, AssociatedTypeWitness);
    v53 += v42;
    if (v53 < 0) {
      BUG();
    }
    uint64_t v38 = 2 * v42 + 1;
    v43(v59, AssociatedTypeWitness);
  }
  else
  {
    if (swift_getEnumCaseMultiPayload(v22, v7) != 1)
    {
      uint64_t v27 = v61;
      uint64_t v44 = (void (*)(unsigned char *, unsigned char *, uint64_t))v61[4];
      v44(v58, v59, AssociatedTypeWitness);
      uint64_t v29 = v57;
      v44(v57, v22, AssociatedTypeWitness);
      goto LABEL_11;
    }
    uint64_t v31 = &v22[*(int *)(swift_getTupleTypeMetadata2(0, AssociatedTypeWitness, AssociatedTypeWitness, "previous next ", 0)+ 48)];
    uint64_t v32 = (void (*)(unsigned char *, unsigned char *, uint64_t))v61[4];
    v32(v60, v59, AssociatedTypeWitness);
    uint64_t v33 = v52;
    v32(v52, v31, AssociatedTypeWitness);
    uint64_t v34 = dispatch thunk of Collection.distance(from:to:)(v60, v33, v56, v54);
    uint64_t v35 = (void (*)(unsigned char *, uint64_t))v61[1];
    v35(v33, AssociatedTypeWitness);
    v35(v60, AssociatedTypeWitness);
    v53 += v34;
    if (v53 < 0) {
      BUG();
    }
    uint64_t v36 = 2 * v34;
    BOOL v37 = __OFSUB__(v36, 1);
    uint64_t v38 = v36 - 1;
    if (v37) {
      BUG();
    }
    v35(v22, AssociatedTypeWitness);
  }
  return v38;
}

uint64_t InterspersedMapSequence<>.index(_:offsetBy:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v5 = v4;
  if (a2)
  {
    if (a2 <= 0)
    {
      uint64_t v8 = -a2;
      if (__OFSUB__(v8, 1)) {
        BUG();
      }
      return InterspersedMapSequence<>.offsetBackward(_:by:)(a1, v8, a3, a4);
    }
    else
    {
      return InterspersedMapSequence<>.offsetForward(_:by:)(a1, a2, a3, a4);
    }
  }
  else
  {
    uint64_t v7 = type metadata accessor for InterspersedMapSequence<>.Index(0, *(void *)(a3 + 16), *(void *)(a3 + 24), a4);
    return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v7 - 8) + 16))(v5, a1, v7);
  }
}

uint64_t InterspersedMapSequence<>.offsetForward(_:by:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedMapSequence<>.offsetForward(_:by:)(a1, a2, a3, a4, (void (*)(uint64_t, uint64_t))InterspersedMapSequence<>.endIndex.getter, (void (*)(uint64_t, uint64_t, uint64_t *, uint64_t, uint64_t))InterspersedMapSequence<>.offsetForward(_:by:limitedBy:), 488);
}

uint64_t InterspersedMapSequence<>.offsetBackward(_:by:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedMapSequence<>.offsetForward(_:by:)(a1, a2, a3, a4, (void (*)(uint64_t, uint64_t))InterspersedMapSequence<>.startIndex.getter, (void (*)(uint64_t, uint64_t, uint64_t *, uint64_t, uint64_t))InterspersedMapSequence<>.offsetBackward(_:by:limitedBy:), 495);
}

uint64_t InterspersedMapSequence<>.offsetForward(_:by:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void (*a5)(uint64_t, uint64_t), void (*a6)(uint64_t, uint64_t, uint64_t *, uint64_t, uint64_t), uint64_t a7)
{
  uint64_t v28 = a4;
  uint64_t v22 = v7;
  uint64_t v24 = a2;
  uint64_t v23 = a6;
  uint64_t v27 = a5;
  uint64_t v25 = a1;
  uint64_t v9 = *(void *)(a3 + 16);
  uint64_t v10 = *(void *)(a3 + 24);
  uint64_t v29 = a3;
  uint64_t v11 = type metadata accessor for InterspersedMapSequence<>.Index(0, v9, v10, a4);
  uint64_t v26 = *(void *)(v11 - 8);
  int64_t v12 = *(void *)(v26 + 64);
  int64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v31 = type metadata accessor for Optional(0, v11);
  uint64_t v30 = *(void *)(v31 - 8);
  int64_t v15 = *(void *)(v30 + 64);
  int64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v18 = a3;
  uint64_t v19 = v28;
  v27(v18, v28);
  v23(v25, v24, &v22, v29, v19);
  uint64_t v20 = v26;
  (*(void (**)(uint64_t *, uint64_t))(v26 + 8))(&v22, v11);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v22, 1, v11) == 1)
  {
    (*(void (**)(uint64_t *, uint64_t))(v30 + 8))(&v22, v31);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000016, "Algorithms/Intersperse.swift" + 0x8000000000000000, "Algorithms/Intersperse.swift", 28, 2, a7, 0);
    BUG();
  }
  return (*(uint64_t (**)(uint64_t, uint64_t *, uint64_t))(v20 + 32))(v22, &v22, v11);
}

uint64_t type metadata accessor for InterspersedMapSequence<>.Index(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for InterspersedMapSequence<>.Index);
}

uint64_t InterspersedMapSequence<>.index(_:offsetBy:limitedBy:)(uint64_t a1, uint64_t a2, void (*a3)(unsigned char *, unsigned char *, uint64_t), uint64_t a4, uint64_t a5)
{
  uint64_t v7 = v5;
  if (!a2)
  {
    uint64_t v11 = type metadata accessor for InterspersedMapSequence<>.Index(0, *(void *)(a4 + 16), *(void *)(a4 + 24), a5);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v11 - 8) + 16))(v7, a1, v11);
    return __swift_storeEnumTagSinglePayload(v7, 0, 1, v11);
  }
  uint64_t v17 = v5;
  uint64_t v8 = type metadata accessor for InterspersedMapSequence<>.Index(0, *(void *)(a4 + 16), *(void *)(a4 + 24), a5);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for InterspersedMapSequence<A, B><>.Index, v8);
  if (a2 > 0)
  {
    if (static Comparable.>= infix(_:_:)(a3, a1, v8, WitnessTable)) {
      return InterspersedMapSequence<>.offsetForward(_:by:limitedBy:)(a1, (unsigned char *)a2, a3, a4, a5);
    }
    InterspersedMapSequence<>.offsetForward(_:by:)(a1, a2, a4, a5);
    return __swift_storeEnumTagSinglePayload(v17, 0, 1, v8);
  }
  char v12 = static Comparable.<= infix(_:_:)(a3, a1, v8, WitnessTable);
  uint64_t v13 = -a2;
  BOOL v14 = __OFSUB__(-a2, 1);
  if ((v12 & 1) == 0)
  {
    if (v14) {
      BUG();
    }
    InterspersedMapSequence<>.offsetBackward(_:by:)(a1, v13, a4, a5);
    return __swift_storeEnumTagSinglePayload(v17, 0, 1, v8);
  }
  if (v14) {
    BUG();
  }
  return InterspersedMapSequence<>.offsetBackward(_:by:limitedBy:)(a1, (unsigned char *)v13, a3, a4, a5);
}

uint64_t InterspersedMapSequence<>.offsetForward(_:by:limitedBy:)(uint64_t a1, unsigned char *a2, void (*a3)(unsigned char *, unsigned char *, uint64_t), uint64_t a4, uint64_t a5)
{
  uint64_t v118 = a3;
  uint64_t v105 = v5;
  uint64_t v121 = a2;
  uint64_t v109 = v6;
  uint64_t v102 = a1;
  uint64_t v9 = *(void *)(a4 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(255, a5, v9, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v104 = type metadata accessor for Optional(0, AssociatedTypeWitness);
  uint64_t v103 = *(void *)(v104 - 8);
  int64_t v11 = *(void *)(v103 + 64);
  char v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  char v115 = v101;
  uint64_t v14 = *(void *)(a4 + 24);
  uint64_t v107 = v9;
  uint64_t v108 = v14;
  uint64_t v106 = a5;
  uint64_t v15 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(255, v9, v14, a5);
  TupleTypeMetadata3 = swift_getTupleTypeMetadata3(0, v15, v15, &type metadata for Bool, 0, 0);
  int64_t v17 = *(void *)(*(void *)(TupleTypeMetadata3 - 8) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v119 = v101;
  uint64_t v111 = AssociatedTypeWitness;
  uint64_t v120 = *(void **)(AssociatedTypeWitness - 8);
  int64_t v20 = v120[8];
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v110 = v101;
  uint64_t v23 = alloca(v20);
  uint64_t v24 = alloca(v20);
  uint64_t v112 = v101;
  uint64_t v25 = alloca(v20);
  uint64_t v26 = alloca(v20);
  BOOL v116 = v101;
  uint64_t v27 = alloca(v20);
  uint64_t v28 = alloca(v20);
  uint64_t v117 = v101;
  uint64_t v29 = alloca(v20);
  uint64_t v30 = alloca(v20);
  unint64_t v113 = v101;
  uint64_t v31 = alloca(v20);
  uint64_t v32 = alloca(v20);
  uint64_t v114 = v101;
  uint64_t v33 = &v101[*(int *)(TupleTypeMetadata3 + 48)];
  uint64_t v34 = *(int *)(TupleTypeMetadata3 + 64);
  uint64_t v35 = *(void (**)(unsigned char *, uint64_t, uint64_t))(*(void *)(v15 - 8) + 16);
  v35(v101, v102, v15);
  v35(v33, (uint64_t)v118, v15);
  v101[v34] = (v121 & 1) == 0;
  if (swift_getEnumCaseMultiPayload(v101, v15) != 1)
  {
    uint64_t v49 = v111;
    if (swift_getEnumCaseMultiPayload(v33, v15) == 1)
    {
      uint64_t v50 = v49;
      uint64_t v51 = &v33[*(int *)(swift_getTupleTypeMetadata2(0, v49, v49, "previous next ", 0) + 48)];
      uint64_t v52 = v120;
      uint64_t v48 = (uint64_t)v121;
      uint64_t v118 = (void (*)(unsigned char *, unsigned char *, uint64_t))v120[4];
      if ((v121 & 1) == 0)
      {
        v118(v112, v119, v50);
        uint64_t v53 = v51;
        uint64_t v54 = v110;
        v118(v110, v53, v50);
        uint64_t v120 = (void *)v52[1];
        ((void (*)(unsigned char *, uint64_t))v120)(v33, v50);
        goto LABEL_13;
      }
      v118(v117, v119, v50);
      v118(v116, v51, v50);
      uint64_t v58 = v33;
      uint64_t v59 = v50;
LABEL_15:
      ((void (*)(unsigned char *, uint64_t))v52[1])(v58, v59);
      goto LABEL_19;
    }
    uint64_t v60 = (void (*)(unsigned char *, unsigned char *, uint64_t))v120[4];
    uint64_t v48 = (uint64_t)v121;
    if (v121)
    {
      v60(v117, v119, v49);
      v60(v116, v33, v49);
      goto LABEL_19;
    }
    v60(v114, v119, v49);
    v60(v113, v33, v49);
LABEL_17:
    uint64_t v78 = v48 / 2;
    uint64_t v79 = v115;
    uint64_t v80 = v107;
    uint64_t v81 = v106;
    dispatch thunk of Collection.index(_:offsetBy:limitedBy:)(v114, v78, v113, v107, v106);
    uint64_t v121 = v101;
    uint64_t v82 = alloca(40);
    uint64_t v83 = alloca(48);
    uint64_t v103 = v80;
    uint64_t v104 = v108;
    uint64_t v105 = v81;
    uint64_t v84 = type metadata accessor for InterspersedMapSequence<>.Index(0, v80, v108, v81);
    uint64_t v85 = v104;
    _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF((void (*)(uint64_t *, uint64_t *))partial apply for closure #1 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:), (uint64_t)v101, v104, (uint64_t)&type metadata for Never, v84, (uint64_t)&protocol witness table for Never, v100);
    (*(void (**)(unsigned char *, uint64_t))(v103 + 8))(v79, v85);
    uint64_t v73 = (void (*)(unsigned char *, uint64_t))v120[1];
    uint64_t v86 = v111;
    v73(v113, v111);
    uint64_t v74 = v114;
LABEL_21:
    uint64_t v75 = v86;
    return ((uint64_t (*)(unsigned char *, uint64_t))v73)(v74, v75);
  }
  uint64_t v36 = v111;
  uint64_t v37 = *(int *)(swift_getTupleTypeMetadata2(0, v111, v111, "previous next ", 0) + 48);
  uint64_t v38 = &v101[v37];
  BOOL v39 = swift_getEnumCaseMultiPayload(v33, v15) == 1;
  uint64_t v40 = v36;
  if (!v39)
  {
    uint64_t v52 = v120;
    uint64_t v55 = (void (*)(unsigned char *, unsigned char *, uint64_t))v120[4];
    uint64_t v48 = (uint64_t)v121;
    if ((v121 & 1) == 0)
    {
      uint64_t v56 = v38;
      uint64_t v57 = v40;
      v55(v117, v56, v40);
      v55(v116, v33, v57);
      uint64_t v58 = v119;
      uint64_t v59 = v57;
      goto LABEL_15;
    }
    uint64_t v76 = v38;
    uint64_t v77 = v40;
    v55(v114, v76, v40);
    v55(v113, v33, v77);
    ((void (*)(unsigned char *, uint64_t))v52[1])(v119, v77);
    goto LABEL_17;
  }
  uint64_t v41 = &v33[v37];
  uint64_t v42 = v120;
  uint64_t v43 = (void (*)(unsigned char *, unsigned char *, uint64_t))v120[4];
  if ((v121 & 1) == 0)
  {
    uint64_t v44 = v38;
    uint64_t v45 = v40;
    uint64_t v46 = (void (*)(unsigned char *, unsigned char *, uint64_t))v120[4];
    v43(v117, v44, v40);
    v46(v116, v41, v45);
    uint64_t v47 = (void (*)(unsigned char *, uint64_t))v120[1];
    v47(v33, v45);
    v47(v119, v45);
    uint64_t v48 = (uint64_t)v121;
LABEL_19:
    BOOL v87 = __OFSUB__(v48, 1);
    uint64_t v88 = v48 - 1;
    if (v87) {
      BUG();
    }
    uint64_t v89 = v88 / 2;
    uint64_t v90 = v116;
    uint64_t v91 = v109;
    uint64_t v92 = v107;
    uint64_t v93 = v106;
    dispatch thunk of Collection.index(_:offsetBy:limitedBy:)(v117, v89, v116, v107, v106);
    uint64_t v121 = v101;
    uint64_t v94 = alloca(56);
    uint64_t v95 = alloca(64);
    uint64_t v103 = v92;
    uint64_t v104 = v108;
    uint64_t v105 = v93;
    uint64_t v106 = (uint64_t)v90;
    uint64_t v107 = v91;
    uint64_t v96 = type metadata accessor for InterspersedMapSequence<>.Index(0, v92, v108, v93);
    uint64_t v97 = v104;
    uint64_t v98 = v115;
    _sSq7flatMapyqd_0_SgABxqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF((uint64_t)partial apply for closure #2 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:), (uint64_t)v101, v104, (uint64_t)&type metadata for Never, v96, (uint64_t)&protocol witness table for Never, v100);
    (*(void (**)(unsigned char *, uint64_t))(v103 + 8))(v98, v97);
    uint64_t v86 = v111;
    uint64_t v73 = (void (*)(unsigned char *, uint64_t))v120[1];
    v73(v117, v111);
    uint64_t v74 = v90;
    goto LABEL_21;
  }
  uint64_t v61 = v38;
  uint64_t v50 = v40;
  uint64_t v62 = (void (*)(unsigned char *, unsigned char *, uint64_t))v120[4];
  v43(v112, v61, v40);
  uint64_t v63 = v62;
  uint64_t v54 = v110;
  v63(v110, v41, v50);
  uint64_t v64 = (void *)v42[1];
  ((void (*)(unsigned char *, uint64_t))v64)(v33, v50);
  uint64_t v120 = v64;
  ((void (*)(unsigned char *, uint64_t))v64)(v119, v50);
  uint64_t v48 = (uint64_t)v121;
LABEL_13:
  uint64_t v65 = v48 / 2;
  uint64_t v66 = v107;
  uint64_t v67 = v106;
  dispatch thunk of Collection.index(_:offsetBy:limitedBy:)(v112, v65, v54, v107, v106);
  uint64_t v121 = v101;
  uint64_t v68 = alloca(48);
  uint64_t v69 = alloca(48);
  uint64_t v103 = v66;
  uint64_t v104 = v108;
  uint64_t v105 = v67;
  uint64_t v106 = (uint64_t)v54;
  uint64_t v70 = type metadata accessor for InterspersedMapSequence<>.Index(0, v66, v108, v67);
  uint64_t v71 = v104;
  uint64_t v72 = v115;
  _sSq7flatMapyqd_0_SgABxqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF((uint64_t)partial apply for closure #3 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:), (uint64_t)v101, v104, (uint64_t)&type metadata for Never, v70, (uint64_t)&protocol witness table for Never, v100);
  (*(void (**)(unsigned char *, uint64_t))(v103 + 8))(v72, v71);
  uint64_t v73 = (void (*)(unsigned char *, uint64_t))v120;
  ((void (*)(unsigned char *, uint64_t))v120)(v112, v50);
  uint64_t v74 = v110;
  uint64_t v75 = v50;
  return ((uint64_t (*)(unsigned char *, uint64_t))v73)(v74, v75);
}

uint64_t InterspersedMapSequence<>.offsetBackward(_:by:limitedBy:)(uint64_t a1, unsigned char *a2, void (*a3)(unsigned char *, unsigned char *, uint64_t), uint64_t a4, uint64_t a5)
{
  uint64_t v119 = a3;
  uint64_t v106 = v5;
  uint64_t v122 = a2;
  uint64_t v110 = v6;
  uint64_t v103 = a1;
  uint64_t v9 = *(void *)(a4 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(255, a5, v9, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v105 = type metadata accessor for Optional(0, AssociatedTypeWitness);
  uint64_t v104 = *(void *)(v105 - 8);
  int64_t v11 = *(void *)(v104 + 64);
  char v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  BOOL v116 = v102;
  uint64_t v14 = *(void *)(a4 + 24);
  uint64_t v108 = v9;
  uint64_t v109 = v14;
  uint64_t v107 = a5;
  uint64_t v15 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(255, v9, v14, a5);
  TupleTypeMetadata3 = swift_getTupleTypeMetadata3(0, v15, v15, &type metadata for Bool, 0, 0);
  int64_t v17 = *(void *)(*(void *)(TupleTypeMetadata3 - 8) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v120 = v102;
  uint64_t v113 = AssociatedTypeWitness;
  uint64_t v121 = *(void **)(AssociatedTypeWitness - 8);
  int64_t v20 = v121[8];
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v112 = v102;
  uint64_t v23 = alloca(v20);
  uint64_t v24 = alloca(v20);
  char v115 = v102;
  uint64_t v25 = alloca(v20);
  uint64_t v26 = alloca(v20);
  uint64_t v111 = v102;
  uint64_t v27 = alloca(v20);
  uint64_t v28 = alloca(v20);
  uint64_t v114 = v102;
  uint64_t v29 = alloca(v20);
  uint64_t v30 = alloca(v20);
  uint64_t v117 = v102;
  uint64_t v31 = alloca(v20);
  uint64_t v32 = alloca(v20);
  uint64_t v118 = v102;
  uint64_t v33 = &v102[*(int *)(TupleTypeMetadata3 + 48)];
  uint64_t v34 = *(int *)(TupleTypeMetadata3 + 64);
  uint64_t v35 = *(void (**)(unsigned char *, uint64_t, uint64_t))(*(void *)(v15 - 8) + 16);
  v35(v102, v103, v15);
  v35(v33, (uint64_t)v119, v15);
  v102[v34] = (v122 & 1) == 0;
  if (swift_getEnumCaseMultiPayload(v102, v15) != 1)
  {
    uint64_t v51 = v113;
    if (swift_getEnumCaseMultiPayload(v33, v15) != 1)
    {
      uint64_t v59 = (void (*)(unsigned char *, unsigned char *, uint64_t))v121[4];
      uint64_t v50 = (uint64_t)v122;
      if ((v122 & 1) == 0)
      {
        v59(v118, v120, v51);
        v59(v117, v33, v51);
LABEL_17:
        BOOL v79 = __OFADD__(1, v50);
        uint64_t v80 = v50 + 1;
        if (v79) {
          BUG();
        }
        uint64_t v81 = v80 / -2;
        uint64_t v82 = v116;
        uint64_t v83 = v108;
        uint64_t v84 = v107;
        dispatch thunk of Collection.index(_:offsetBy:limitedBy:)(v118, v81, v117, v108, v107);
        uint64_t v122 = v102;
        uint64_t v85 = alloca(40);
        uint64_t v86 = alloca(48);
        uint64_t v104 = v83;
        uint64_t v105 = v109;
        uint64_t v106 = v84;
        uint64_t v87 = type metadata accessor for InterspersedMapSequence<>.Index(0, v83, v109, v84);
        uint64_t v88 = v105;
        _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF((void (*)(uint64_t *, uint64_t *))partial apply for closure #1 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:), (uint64_t)v102, v105, (uint64_t)&type metadata for Never, v87, (uint64_t)&protocol witness table for Never, v101);
        (*(void (**)(unsigned char *, uint64_t))(v104 + 8))(v82, v88);
        uint64_t v89 = v113;
        uint64_t v74 = (void (*)(unsigned char *, uint64_t))v121[1];
        v74(v117, v113);
        uint64_t v75 = v118;
        goto LABEL_21;
      }
      v59(v115, v120, v51);
      v59(v112, v33, v51);
LABEL_20:
      uint64_t v90 = v50 / -2;
      uint64_t v91 = v112;
      uint64_t v92 = v110;
      uint64_t v93 = v108;
      uint64_t v94 = v107;
      dispatch thunk of Collection.index(_:offsetBy:limitedBy:)(v115, v90, v112, v108, v107);
      uint64_t v122 = v102;
      uint64_t v95 = alloca(56);
      uint64_t v96 = alloca(64);
      uint64_t v104 = v93;
      uint64_t v105 = v109;
      uint64_t v106 = v94;
      uint64_t v107 = (uint64_t)v91;
      uint64_t v108 = v92;
      uint64_t v97 = type metadata accessor for InterspersedMapSequence<>.Index(0, v93, v109, v94);
      uint64_t v98 = v105;
      uint64_t v99 = v116;
      _sSq7flatMapyqd_0_SgABxqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF((uint64_t)partial apply for closure #3 in InterspersedMapSequence<>.offsetBackward(_:by:limitedBy:), (uint64_t)v102, v105, (uint64_t)&type metadata for Never, v97, (uint64_t)&protocol witness table for Never, v101);
      (*(void (**)(unsigned char *, uint64_t))(v104 + 8))(v99, v98);
      uint64_t v74 = (void (*)(unsigned char *, uint64_t))v121[1];
      uint64_t v89 = v113;
      v74(v115, v113);
      uint64_t v75 = v91;
LABEL_21:
      uint64_t v76 = v89;
      return ((uint64_t (*)(unsigned char *, uint64_t))v74)(v75, v76);
    }
    uint64_t v45 = v51;
    uint64_t v52 = &v33[*(int *)(swift_getTupleTypeMetadata2(0, v51, v51, "previous next ", 0) + 48)];
    uint64_t v53 = v121;
    uint64_t v50 = (uint64_t)v122;
    uint64_t v119 = (void (*)(unsigned char *, unsigned char *, uint64_t))v121[4];
    if (v122)
    {
      v119(v114, v120, v45);
      uint64_t v64 = v52;
      uint64_t v48 = v111;
      v119(v111, v64, v45);
      uint64_t v121 = (void *)v53[1];
      ((void (*)(unsigned char *, uint64_t))v121)(v33, v45);
      goto LABEL_14;
    }
    v119(v118, v120, v45);
    v119(v117, v52, v45);
    uint64_t v54 = v33;
    uint64_t v55 = v45;
LABEL_16:
    ((void (*)(unsigned char *, uint64_t))v53[1])(v54, v55);
    goto LABEL_17;
  }
  uint64_t v36 = v113;
  uint64_t v37 = *(int *)(swift_getTupleTypeMetadata2(0, v113, v113, "previous next ", 0) + 48);
  uint64_t v38 = &v102[v37];
  BOOL v39 = swift_getEnumCaseMultiPayload(v33, v15) == 1;
  uint64_t v40 = v36;
  if (!v39)
  {
    uint64_t v53 = v121;
    uint64_t v56 = (void (*)(unsigned char *, unsigned char *, uint64_t))v121[4];
    uint64_t v50 = (uint64_t)v122;
    if ((v122 & 1) == 0)
    {
      uint64_t v57 = v38;
      uint64_t v58 = v40;
      v56(v115, v57, v40);
      v56(v112, v33, v58);
      ((void (*)(unsigned char *, uint64_t))v53[1])(v120, v58);
      goto LABEL_20;
    }
    uint64_t v77 = v38;
    uint64_t v78 = v40;
    v56(v118, v77, v40);
    v56(v117, v33, v78);
    uint64_t v54 = v120;
    uint64_t v55 = v78;
    goto LABEL_16;
  }
  uint64_t v41 = &v33[v37];
  uint64_t v42 = v121;
  uint64_t v43 = (void (*)(unsigned char *, unsigned char *, uint64_t))v121[4];
  if (v122)
  {
    uint64_t v60 = v38;
    uint64_t v61 = v40;
    uint64_t v62 = (void (*)(unsigned char *, unsigned char *, uint64_t))v121[4];
    v43(v118, v60, v40);
    v62(v117, v41, v61);
    uint64_t v63 = (void (*)(unsigned char *, uint64_t))v121[1];
    v63(v33, v61);
    v63(v120, v61);
    uint64_t v50 = (uint64_t)v122;
    goto LABEL_17;
  }
  uint64_t v44 = v38;
  uint64_t v45 = v40;
  uint64_t v46 = (void (*)(unsigned char *, unsigned char *, uint64_t))v121[4];
  v43(v114, v44, v40);
  uint64_t v47 = v46;
  uint64_t v48 = v111;
  v47(v111, v41, v45);
  uint64_t v49 = (void *)v42[1];
  ((void (*)(unsigned char *, uint64_t))v49)(v33, v45);
  uint64_t v121 = v49;
  ((void (*)(unsigned char *, uint64_t))v49)(v120, v45);
  uint64_t v50 = (uint64_t)v122;
LABEL_14:
  uint64_t v65 = v50 / -2;
  uint64_t v66 = v110;
  uint64_t v67 = v108;
  uint64_t v68 = v107;
  dispatch thunk of Collection.index(_:offsetBy:limitedBy:)(v114, v65, v48, v108, v107);
  uint64_t v122 = v102;
  uint64_t v69 = alloca(48);
  uint64_t v70 = alloca(48);
  uint64_t v104 = v67;
  uint64_t v105 = v109;
  uint64_t v106 = v68;
  uint64_t v107 = v66;
  uint64_t v71 = type metadata accessor for InterspersedMapSequence<>.Index(0, v67, v109, v68);
  uint64_t v72 = v105;
  uint64_t v73 = v116;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF((void (*)(uint64_t *, uint64_t *))partial apply for closure #2 in InterspersedMapSequence<>.offsetBackward(_:by:limitedBy:), (uint64_t)v102, v105, (uint64_t)&type metadata for Never, v71, (uint64_t)&protocol witness table for Never, v101);
  (*(void (**)(unsigned char *, uint64_t))(v104 + 8))(v73, v72);
  uint64_t v74 = (void (*)(unsigned char *, uint64_t))v121;
  ((void (*)(unsigned char *, uint64_t))v121)(v111, v45);
  uint64_t v75 = v114;
  uint64_t v76 = v45;
  return ((uint64_t (*)(unsigned char *, uint64_t))v74)(v75, v76);
}

uint64_t closure #2 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v31 = a3;
  uint64_t v36 = v6;
  uint64_t v37 = a2;
  uint64_t v33 = a5;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a6, a4, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v34 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v10 = *(void *)(v34 + 64);
  int64_t v11 = alloca(v10);
  char v12 = alloca(v10);
  uint64_t v29 = &v28;
  uint64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  uint64_t v35 = &v28;
  uint64_t v38 = a4;
  uint64_t v15 = *(void *)(swift_getAssociatedConformanceWitness(a6, a4, AssociatedTypeWitness, &protocol requirements base descriptor for Collection, &associated conformance descriptor for Collection.Collection.Index: Comparable)+ 8);
  uint64_t v32 = a1;
  if (dispatch thunk of static Equatable.== infix(_:_:)(a1, v37, AssociatedTypeWitness, v15))
  {
    uint64_t v16 = type metadata accessor for InterspersedMapSequence<>.Index(0, v38, v33, a6);
    uint64_t v17 = v36;
    uint64_t v18 = 1;
  }
  else
  {
    uint64_t v37 = a6;
    uint64_t v19 = v38;
    dispatch thunk of Collection.index(after:)(v32, v38, v37);
    uint64_t v30 = v15;
    int64_t v20 = v29;
    uint64_t v21 = v19;
    uint64_t v22 = v37;
    dispatch thunk of Collection.endIndex.getter(v21, v37);
    char v23 = dispatch thunk of static Equatable.== infix(_:_:)(v35, v20, AssociatedTypeWitness, v30);
    uint64_t v34 = *(void *)(v34 + 8);
    ((void (*)(uint64_t *, uint64_t))v34)(v20, AssociatedTypeWitness);
    if (v23)
    {
      uint64_t v24 = v33;
      uint64_t v25 = type metadata accessor for InterspersedMapSequence(0, v38, v33, *(void *)(v22 + 8));
      InterspersedMapSequence<>.endIndex.getter(v25, v22);
      uint64_t v26 = v36;
    }
    else
    {
      uint64_t v26 = v36;
      uint64_t v24 = v33;
      static InterspersedMapSequence<>.Index.separator(previous:next:)(v32, (uint64_t)v35, v38, v33, v22);
    }
    ((void (*)(uint64_t *, uint64_t))v34)(v35, AssociatedTypeWitness);
    uint64_t v16 = type metadata accessor for InterspersedMapSequence<>.Index(0, v38, v24, v22);
    uint64_t v17 = v26;
    uint64_t v18 = 0;
  }
  return __swift_storeEnumTagSinglePayload(v17, v18, 1, v16);
}

uint64_t closure #3 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v16 = v5;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a5, a3, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(a5, a3, AssociatedTypeWitness, &protocol requirements base descriptor for Collection, &associated conformance descriptor for Collection.Collection.Index: Comparable);
  if (dispatch thunk of static Equatable.== infix(_:_:)(a1, a2, AssociatedTypeWitness, *(void *)(AssociatedConformanceWitness + 8)))
  {
    unsigned int v10 = 1;
    uint64_t v11 = v16;
    uint64_t v12 = a4;
  }
  else
  {
    uint64_t v11 = v16;
    static InterspersedMapSequence<>.Index.element(_:)(a1, a3, a4, a5);
    uint64_t v12 = a4;
    unsigned int v10 = 0;
  }
  uint64_t v13 = type metadata accessor for InterspersedMapSequence<>.Index(0, a3, v12, a5);
  return __swift_storeEnumTagSinglePayload(v11, v10, 1, v13);
}

uint64_t partial apply for closure #3 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:)(uint64_t a1)
{
  return closure #3 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:)(a1, v1[5], v1[2], v1[3], v1[4]);
}

uint64_t partial apply for closure #2 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:)(uint64_t a1, uint64_t a2)
{
  return partial apply for closure #2 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:)(a1, a2, (uint64_t (*)(uint64_t, void, void, void, void, void, uint64_t))closure #2 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:));
}

uint64_t partial apply for closure #1 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:)(uint64_t a1)
{
  return partial apply for closure #1 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:)(a1);
}

{
  uint64_t *v1;

  return static InterspersedMapSequence<>.Index.element(_:)(a1, v1[2], v1[3], v1[4]);
}

uint64_t closure #2 in InterspersedMapSequence<>.offsetBackward(_:by:limitedBy:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v18 = a5;
  uint64_t v14 = a4;
  uint64_t v15 = v5;
  uint64_t v19 = a3;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a5, a3, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v17 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v7 = *(void *)(v17 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = a3;
  uint64_t v11 = v18;
  dispatch thunk of Collection.index(_:offsetBy:)(a1, -1, v10, v18);
  static InterspersedMapSequence<>.Index.separator(previous:next:)((uint64_t)&v13, a1, v19, v14, v11);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v17 + 8))(&v13, AssociatedTypeWitness);
}

uint64_t partial apply for closure #2 in InterspersedMapSequence<>.offsetBackward(_:by:limitedBy:)(uint64_t a1)
{
  return closure #2 in InterspersedMapSequence<>.offsetBackward(_:by:limitedBy:)(a1, v1[5], v1[2], v1[3], v1[4]);
}

uint64_t closure #3 in InterspersedMapSequence<>.offsetBackward(_:by:limitedBy:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v23 = a3;
  uint64_t v28 = v6;
  uint64_t v21 = a2;
  uint64_t v25 = a5;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a6, a4, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v22 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v10 = *(void *)(v22 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v24 = &v21;
  uint64_t v27 = a6;
  uint64_t v29 = a4;
  uint64_t v13 = *(void *)(swift_getAssociatedConformanceWitness(a6, a4, AssociatedTypeWitness, &protocol requirements base descriptor for Collection, &associated conformance descriptor for Collection.Collection.Index: Comparable)+ 8);
  uint64_t v26 = a1;
  if (dispatch thunk of static Equatable.== infix(_:_:)(a1, v21, AssociatedTypeWitness, v13))
  {
    uint64_t v14 = type metadata accessor for InterspersedMapSequence<>.Index(0, v29, v25, v27);
    uint64_t v15 = v28;
    uint64_t v16 = 1;
  }
  else
  {
    uint64_t v17 = (uint64_t)v24;
    uint64_t v18 = v27;
    dispatch thunk of Collection.index(_:offsetBy:)(v26, -1, v29, v27);
    uint64_t v19 = v25;
    static InterspersedMapSequence<>.Index.separator(previous:next:)(v17, v26, v29, v25, v18);
    (*(void (**)(uint64_t, uint64_t))(v22 + 8))(v17, AssociatedTypeWitness);
    uint64_t v14 = type metadata accessor for InterspersedMapSequence<>.Index(0, v29, v19, v18);
    uint64_t v15 = v28;
    uint64_t v16 = 0;
  }
  return __swift_storeEnumTagSinglePayload(v15, v16, 1, v14);
}

uint64_t partial apply for closure #3 in InterspersedMapSequence<>.offsetBackward(_:by:limitedBy:)(uint64_t a1, uint64_t a2)
{
  return partial apply for closure #2 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:)(a1, a2, (uint64_t (*)(uint64_t, void, void, void, void, void, uint64_t))closure #3 in InterspersedMapSequence<>.offsetBackward(_:by:limitedBy:));
}

uint64_t partial apply for closure #2 in InterspersedMapSequence<>.offsetForward(_:by:limitedBy:)(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t, void, void, void, void, void, uint64_t))
{
  return a3(a1, v3[5], v3[6], v3[2], v3[3], v3[4], a2);
}

uint64_t protocol witness for Collection.startIndex.getter in conformance <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2)
{
  return InterspersedMapSequence<>.startIndex.getter(a1, *(void *)(a2 - 8));
}

uint64_t protocol witness for Collection.endIndex.getter in conformance <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2)
{
  return InterspersedMapSequence<>.endIndex.getter(a1, *(void *)(a2 - 8));
}

void (*protocol witness for Collection.subscript.read in conformance <> InterspersedMapSequence<A, B>(void *a1, uint64_t a2, uint64_t a3, uint64_t a4))(void (***a1)(void))
{
  uint64_t v5 = malloc(0x28uLL);
  *a1 = v5;
  void v5[4] = InterspersedMapSequence<>.subscript.read(v5, a2, a3, *(void *)(a4 - 8));
  return protocol witness for Collection.subscript.read in conformance <> InterspersedSequence<A>;
}

void (*InterspersedMapSequence<>.subscript.read(void *a1, uint64_t a2, uint64_t a3, uint64_t a4))(void *a1)
{
  uint64_t v6 = *(void *)(a3 + 24);
  *a1 = v6;
  uint64_t v7 = *(void *)(v6 - 8);
  a1[1] = v7;
  a1[2] = malloc(*(void *)(v7 + 64));
  InterspersedMapSequence<>.subscript.getter(a2, a3, a4);
  return InterspersedSequence<>.subscript.read;
}

uint64_t protocol witness for Collection._customIndexOfEquatableElement(_:) in conformance <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return protocol witness for Collection._customIndexOfEquatableElement(_:) in conformance <> InterspersedMapSequence<A, B>(a1, a2, a3);
}

{
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;

  uint64_t v4 = v3;
  uint64_t v5 = type metadata accessor for InterspersedMapSequence<>.Index(255, *(void *)(a2 + 16), *(void *)(a2 + 24), *(void *)(a3 - 8));
  uint64_t v6 = type metadata accessor for Optional(0, v5);
  return __swift_storeEnumTagSinglePayload(v4, 1, 1, v6);
}

uint64_t protocol witness for Collection.index(_:offsetBy:) in conformance <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedMapSequence<>.index(_:offsetBy:)(a1, a2, a3, *(void *)(a4 - 8));
}

uint64_t protocol witness for Collection.index(_:offsetBy:limitedBy:) in conformance <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2, void (*a3)(unsigned char *, unsigned char *, uint64_t), uint64_t a4, uint64_t a5)
{
  return InterspersedMapSequence<>.index(_:offsetBy:limitedBy:)(a1, a2, a3, a4, *(void *)(a5 - 8));
}

uint64_t protocol witness for Collection.distance(from:to:) in conformance <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedMapSequence<>.distance(from:to:)(a1, a2, a3, *(void *)(a4 - 8));
}

uint64_t protocol witness for Collection.index(after:) in conformance <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return InterspersedMapSequence<>.index(after:)(a1, a2, *(void *)(a3 - 8));
}

uint64_t protocol witness for Collection.formIndex(after:) in conformance <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v11[1] = v3;
  uint64_t v4 = *(void *)(a3 - 8);
  uint64_t v5 = type metadata accessor for InterspersedMapSequence<>.Index(0, *(void *)(a2 + 16), *(void *)(a2 + 24), v4);
  uint64_t v6 = *(void *)(v5 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v12 = v11;
  InterspersedMapSequence<>.index(after:)(a1, a2, v4);
  (*(void (**)(uint64_t, uint64_t))(v6 + 8))(a1, v5);
  return (*(uint64_t (**)(uint64_t, void *, uint64_t))(v6 + 32))(a1, v12, v5);
}

uint64_t InterspersedMapSequence<>.index(before:)(void (*a1)(uint64_t, uint64_t *, uint64_t), uint64_t a2, uint64_t a3)
{
  uint64_t v49 = v4;
  uint64_t v52 = a1;
  uint64_t v50 = v3;
  uint64_t v46 = a3;
  uint64_t v5 = *(void *)(a3 + 8);
  uint64_t v6 = *(void *)(a2 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v5, v6, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v53 = *(void **)(AssociatedTypeWitness - 8);
  int64_t v8 = v53[8];
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  uint64_t v47 = &v42;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v54 = &v42;
  uint64_t v13 = alloca(v8);
  uint64_t v14 = alloca(v8);
  uint64_t v51 = &v42;
  uint64_t v15 = alloca(v8);
  uint64_t v16 = alloca(v8);
  uint64_t v42 = (uint64_t)&v42;
  uint64_t v17 = alloca(v8);
  uint64_t v18 = alloca(v8);
  uint64_t v45 = &v42;
  uint64_t v19 = *(void *)(a2 + 24);
  uint64_t v43 = v6;
  uint64_t v48 = v5;
  uint64_t v20 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(0, v6, v19, v5);
  uint64_t v21 = *(void *)(v20 - 8);
  int64_t v22 = *(void *)(v21 + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  (*(void (**)(uint64_t *, void, uint64_t))(v21 + 16))(&v42, v52, v20);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v42, v20);
  uint64_t v44 = v19;
  if (EnumCaseMultiPayload == 1)
  {
    uint64_t v26 = (char *)&v42
        + *(int *)(swift_getTupleTypeMetadata2(0, AssociatedTypeWitness, AssociatedTypeWitness, "previous next ", 0)
                 + 48);
    uint64_t v27 = (void (*)(uint64_t *, uint64_t *, uint64_t))v53[4];
    v27(v51, &v42, AssociatedTypeWitness);
    uint64_t v52 = (void (*)(uint64_t, uint64_t *, uint64_t))v27;
    v27(v54, (uint64_t *)v26, AssociatedTypeWitness);
    uint64_t v28 = v45;
    uint64_t v29 = v43;
    uint64_t v30 = v48;
    dispatch thunk of Collection.endIndex.getter(v43, v48);
    uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v30, v29, AssociatedTypeWitness, &protocol requirements base descriptor for Collection, &associated conformance descriptor for Collection.Collection.Index: Comparable);
    char v32 = dispatch thunk of static Equatable.== infix(_:_:)(v54, v28, AssociatedTypeWitness, *(void *)(AssociatedConformanceWitness + 8));
    uint64_t v33 = (void (*)(uint64_t *, uint64_t))v53[1];
    v33(v28, AssociatedTypeWitness);
    BOOL v34 = (v32 & 1) == 0;
    uint64_t v35 = (uint64_t)v47;
    if (v34)
    {
      v33(v54, AssociatedTypeWitness);
      v52(v35, v51, AssociatedTypeWitness);
    }
    else
    {
      uint64_t v36 = v54;
      dispatch thunk of BidirectionalCollection.index(before:)(v54, v29, v46);
      uint64_t v35 = (uint64_t)v47;
      v33(v36, AssociatedTypeWitness);
      v33(v51, AssociatedTypeWitness);
    }
    static InterspersedMapSequence<>.Index.element(_:)(v35, v29, v44, v48);
    return ((uint64_t (*)(uint64_t, uint64_t))v33)(v35, AssociatedTypeWitness);
  }
  else
  {
    uint64_t v37 = (uint64_t)v45;
    ((void (*)(uint64_t *, uint64_t *, uint64_t))v53[4])(v45, &v42, AssociatedTypeWitness);
    uint64_t v38 = v42;
    uint64_t v39 = v43;
    dispatch thunk of BidirectionalCollection.index(before:)(v37, v43, v46);
    static InterspersedMapSequence<>.Index.separator(previous:next:)(v38, v37, v39, v44, v48);
    uint64_t v40 = (void (*)(uint64_t, uint64_t))v53[1];
    v40(v38, AssociatedTypeWitness);
    return ((uint64_t (*)(uint64_t, uint64_t))v40)(v37, AssociatedTypeWitness);
  }
}

uint64_t protocol witness for BidirectionalCollection.index(before:) in conformance <> InterspersedMapSequence<A, B>(void (*a1)(uint64_t, uint64_t *, uint64_t), uint64_t a2, uint64_t a3)
{
  return InterspersedMapSequence<>.index(before:)(a1, a2, *(void *)(a3 - 8));
}

uint64_t protocol witness for BidirectionalCollection.formIndex(before:) in conformance <> InterspersedMapSequence<A, B>(void (*a1)(uint64_t, uint64_t *, uint64_t), uint64_t a2, uint64_t a3)
{
  v11[1] = v3;
  uint64_t v4 = *(void *)(a3 - 8);
  uint64_t v5 = type metadata accessor for InterspersedMapSequence<>.Index(0, *(void *)(a2 + 16), *(void *)(a2 + 24), *(void *)(v4 + 8));
  uint64_t v6 = *(void *)(v5 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v12 = v11;
  InterspersedMapSequence<>.index(before:)(a1, a2, v4);
  (*(void (**)(void (*)(uint64_t, uint64_t *, uint64_t), uint64_t))(v6 + 8))(a1, v5);
  return (*(uint64_t (**)(void, void *, uint64_t))(v6 + 32))(a1, v12, v5);
}

uint64_t protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedMapSequence<>.index(_:offsetBy:)(a1, a2, a3, *(void *)(*(void *)(a4 - 8) + 8));
}

uint64_t protocol witness for BidirectionalCollection.index(_:offsetBy:limitedBy:) in conformance <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2, void (*a3)(unsigned char *, unsigned char *, uint64_t), uint64_t a4, uint64_t a5)
{
  return InterspersedMapSequence<>.index(_:offsetBy:limitedBy:)(a1, a2, a3, a4, *(void *)(*(void *)(a5 - 8) + 8));
}

uint64_t protocol witness for BidirectionalCollection.distance(from:to:) in conformance <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return InterspersedMapSequence<>.distance(from:to:)(a1, a2, a3, *(void *)(*(void *)(a4 - 8) + 8));
}

uint64_t InterspersedMapSequence<>.Index<>.hash(into:)(uint64_t a1, void *a2, uint64_t a3)
{
  uint64_t v23 = v3;
  uint64_t v24 = a3;
  uint64_t v25 = a1;
  uint64_t v4 = a2[2];
  uint64_t v5 = a2[4];
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v5, v4, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v26 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v7 = *(void *)(v26 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(0, v4, a2[3], v5);
  uint64_t v11 = *(void *)(v10 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  (*(void (**)(unsigned char *, uint64_t, uint64_t))(v11 + 16))(v22, v23, v10);
  if (swift_getEnumCaseMultiPayload(v22, v10) == 1)
  {
    TupleTypeMetadata2 = swift_getTupleTypeMetadata2(0, AssociatedTypeWitness, AssociatedTypeWitness, "previous next ", 0);
    uint64_t v16 = v26;
    (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v26 + 32))(v22, &v22[*(int *)(TupleTypeMetadata2 + 48)], AssociatedTypeWitness);
    uint64_t v17 = v25;
    Hasher._combine(_:)(1u);
    dispatch thunk of Hashable.hash(into:)(v17, AssociatedTypeWitness, v24);
    uint64_t v18 = *(void (**)(unsigned char *, uint64_t))(v16 + 8);
    v18(v22, AssociatedTypeWitness);
    return ((uint64_t (*)(unsigned char *, uint64_t))v18)(v22, AssociatedTypeWitness);
  }
  else
  {
    uint64_t v20 = v26;
    (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v26 + 32))(v22, v22, AssociatedTypeWitness);
    uint64_t v21 = v25;
    Hasher._combine(_:)(0);
    dispatch thunk of Hashable.hash(into:)(v21, AssociatedTypeWitness, v24);
    return (*(uint64_t (**)(unsigned char *, uint64_t))(v20 + 8))(v22, AssociatedTypeWitness);
  }
}

Swift::Int InterspersedMapSequence<>.Index<>.hashValue.getter(void *a1, uint64_t a2)
{
  Hasher.init(_seed:)(0);
  InterspersedMapSequence<>.Index<>.hash(into:)((uint64_t)v3, a1, a2);
  return Hasher._finalize()();
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance <> InterspersedMapSequence<A, B><>.Index(void *a1, uint64_t a2)
{
  return InterspersedMapSequence<>.Index<>.hashValue.getter(a1, *(void *)(a2 - 8));
}

uint64_t protocol witness for Hashable.hash(into:) in conformance <> InterspersedMapSequence<A, B><>.Index(uint64_t a1, void *a2, uint64_t a3)
{
  return InterspersedMapSequence<>.Index<>.hash(into:)(a1, a2, *(void *)(a3 - 8));
}

Swift::Int protocol witness for Hashable._rawHashValue(seed:) in conformance <> InterspersedMapSequence<A, B><>.Index(uint64_t a1, void *a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 - 8);
  Hasher.init(_seed:)(a1);
  InterspersedMapSequence<>.Index<>.hash(into:)((uint64_t)v5, a2, v3);
  return Hasher._finalize()();
}

uint64_t Sequence.interspersed(with:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v18 = v4;
  uint64_t v16 = a3;
  uint64_t v17 = a1;
  v15[1] = v3;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, a2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v7 = *(void *)(v6 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = *(void *)(a2 - 8);
  int64_t v11 = *(void *)(v10 + 64);
  int64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  (*(void (**)(void *, uint64_t, uint64_t))(v10 + 16))(v15, v4, a2);
  (*(void (**)(void *, uint64_t, uint64_t))(v6 + 16))(v15, v17, AssociatedTypeWitness);
  return InterspersedSequence.init(base:separator:)((uint64_t)v15, (uint64_t)v15, a2, v16);
}

uint64_t LazySequenceProtocol.interspersedMap<A>(_:with:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v15 = a4;
  uint64_t v16 = a3;
  uint64_t v18 = v7;
  uint64_t v20 = a2;
  uint64_t v17 = a6;
  uint64_t v19 = a1;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a7, a5, &protocol requirements base descriptor for LazySequenceProtocol, &associated type descriptor for LazySequenceProtocol.Elements);
  int64_t v10 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  int64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  dispatch thunk of LazySequenceProtocol.elements.getter(a5, a7);
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(a7, a5, AssociatedTypeWitness, &protocol requirements base descriptor for LazySequenceProtocol, &associated conformance descriptor for LazySequenceProtocol.LazySequenceProtocol.Elements: Sequence);
  InterspersedMapSequence.init(base:transform:separator:)((uint64_t)&v15, v19, v20, v16, v15, AssociatedTypeWitness, v17, AssociatedConformanceWitness);
  swift_retain();
  return swift_retain();
}

uint64_t variable initialization expression of AdjacentPairsSequence.Iterator.previousElement(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a2, a1, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  return __swift_storeEnumTagSinglePayload(v3, 1, 1, AssociatedTypeWitness);
}

char variable initialization expression of UniquePermutationsSequence.Iterator.initial()
{
  return 1;
}

uint64_t variable initialization expression of ExclusiveReductionsSequence.Iterator.current(uint64_t a1, uint64_t a2)
{
  return __swift_storeEnumTagSinglePayload(v2, 1, 1, a2);
}

uint64_t variable initialization expression of WindowsOfCountCollection.endOfFirstWindow(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a2, a1, &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  return __swift_storeEnumTagSinglePayload(v3, 1, 1, AssociatedTypeWitness);
}

uint64_t variable initialization expression of EitherSequence.Iterator.left(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, a1, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  return __swift_storeEnumTagSinglePayload(v4, 1, 1, AssociatedTypeWitness);
}

uint64_t variable initialization expression of EitherSequence.Iterator.right(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v5 = v4;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a4, a2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  return __swift_storeEnumTagSinglePayload(v5, 1, 1, AssociatedTypeWitness);
}

void *variable initialization expression of UniquedSequence.Iterator.seen(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v5 = static Array._allocateUninitialized(_:)(0, a2);
  if (Array._getCount()()) {
    return Set.init(_nonEmptyArrayLiteral:)(v5, a2, a4);
  }
  swift_bridgeObjectRelease(v5);
  return &_swiftEmptySetSingleton;
}

uint64_t variable initialization expression of Product2Sequence.Iterator.element1(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, a1, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  return __swift_storeEnumTagSinglePayload(v4, 1, 1, AssociatedTypeWitness);
}

uint64_t variable initialization expression of SplitSequence.Iterator.splitCount()
{
  return 0;
}

uint64_t variable initialization expression of SplitSequence.Iterator.sequenceLength()
{
  return 0;
}

uint64_t variable initialization expression of StridingSequence.Iterator.striding()
{
  return 0;
}

void *Set.init(_nonEmptyArrayLiteral:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = a2;
  uint64_t v5 = a1;
  uint64_t v51 = *(void *)(a2 - 8);
  int64_t v6 = *(void *)(v51 + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v39 = &v36;
  uint64_t v9 = alloca(v6);
  int64_t v10 = alloca(v6);
  uint64_t v50 = &v36;
  int64_t v43 = v6;
  int64_t v11 = alloca(v6);
  int64_t v12 = alloca(v6);
  uint64_t v49 = &v36;
  uint64_t v13 = Array.count.getter();
  uint64_t v46 = a3;
  if (v13)
  {
    uint64_t v14 = v13;
    type metadata accessor for _SetStorage(0, a2, a3);
    uint64_t v15 = (void *)static _SetStorage.allocate(capacity:)(v14);
  }
  else
  {
    uint64_t v15 = &_swiftEmptySetSingleton;
  }
  Swift::Int v41 = Array._getCount()();
  if (v41)
  {
    uint64_t v16 = 0;
    uint64_t v42 = a1;
    uint64_t v48 = a2;
    do
    {
      BOOL IsNativeType = Array._hoistableIsNativeTypeChecked()();
      Array._checkSubscript(_:wasNativeTypeChecked:)(v16, IsNativeType, v5, v4);
      if (IsNativeType)
      {
        uint64_t v18 = v5
            + ((*(unsigned __int8 *)(v51 + 80) + 32) & ~*(unsigned __int8 *)(v51 + 80))
            + v16 * *(void *)(v51 + 72);
        uint64_t v45 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 16);
        v45(v49, v18, v4);
      }
      else
      {
        uint64_t v33 = _ArrayBuffer._getElementSlowPath(_:)(v16, v5, v4);
        if (v43 != 8) {
          BUG();
        }
        uint64_t v34 = v33;
        uint64_t v37 = v33;
        uint64_t v45 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 16);
        v45(v49, (uint64_t)&v37, v4);
        swift_unknownObjectRelease(v34);
      }
      BOOL v19 = __OFADD__(1, v16);
      uint64_t v20 = v16 + 1;
      if (v19) {
        BUG();
      }
      uint64_t v47 = v20;
      uint64_t v40 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v51 + 32);
      v40(v50, v49, v4);
      uint64_t v21 = v46;
      uint64_t v22 = dispatch thunk of Hashable._rawHashValue(seed:)(v15[5], v4, v46);
      uint64_t v38 = ~(-1 << *((unsigned char *)v15 + 32));
      unint64_t v23 = v38 & v22;
      uint64_t v24 = 1 << (v38 & v22);
      unint64_t v25 = (v38 & (unint64_t)v22) >> 6;
      uint64_t v26 = v15[v25 + 7];
      unsigned __int8 v27 = _bittest64(&v26, v23);
      uint64_t v44 = *(void *)(v51 + 72);
      if (v27)
      {
        while (1)
        {
          uint64_t v28 = v39;
          uint64_t v29 = v48;
          v45(v39, v15[6] + v23 * v44, v48);
          char v52 = dispatch thunk of static Equatable.== infix(_:_:)(v28, v50, v29, *(void *)(v21 + 8));
          uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v51 + 8);
          v30(v28, v29);
          if (v52) {
            break;
          }
          unint64_t v23 = v38 & (v23 + 1);
          unint64_t v25 = v23 >> 6;
          uint64_t v26 = v15[(v23 >> 6) + 7];
          uint64_t v24 = 1 << v23;
          uint64_t v21 = v46;
          if (!_bittest64(&v26, v23)) {
            goto LABEL_12;
          }
        }
        uint64_t v4 = v48;
        v30(v50, v48);
        uint64_t v16 = v47;
      }
      else
      {
LABEL_12:
        v15[v25 + 7] = v26 | v24;
        uint64_t v4 = v48;
        v40((uint64_t *)(v15[6] + v23 * v44), v50, v48);
        uint64_t v31 = v15[2];
        BOOL v19 = __OFADD__(1, v31);
        uint64_t v32 = v31 + 1;
        uint64_t v16 = v47;
        if (v19) {
          BUG();
        }
        void v15[2] = v32;
      }
      uint64_t v5 = v42;
    }
    while (v16 != v41);
  }
  swift_bridgeObjectRelease(v5);
  return v15;
}

uint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in InterspersedSequence<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for InterspersedSequence<A>.Iterator, a1);
}

uint64_t base witness table accessor for Equatable in InterspersedSequence<A><>.Index(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for InterspersedSequence<A><>.Index, a1);
}

uint64_t base witness table accessor for Sequence in <> InterspersedSequence<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for InterspersedSequence<A>, a1);
}

uint64_t associated type witness table accessor for Collection.Index : Comparable in <> InterspersedSequence<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for InterspersedSequence<A><>.Index, a1);
}

uint64_t associated type witness table accessor for Collection.Indices : Collection in <> InterspersedSequence<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for DefaultIndices<A>, a1);
}

uint64_t associated type witness table accessor for Collection.SubSequence : Collection in <> InterspersedSequence<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for Slice<A>, a1);
}

uint64_t base witness table accessor for Collection in <> InterspersedSequence<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for <> InterspersedSequence<A>, a1);
}

{
  return associated type witness table accessor for LazySequenceProtocol.Elements : Collection in <> InterspersedSequence<A>(a1);
}

uint64_t associated type witness table accessor for Collection.Indices : BidirectionalCollection in <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return associated type witness table accessor for Collection.Indices : BidirectionalCollection in <> InterspersedSequence<A>(a1, a2, a3, (uint64_t)&protocol conformance descriptor for <> InterspersedSequence<A>, (uint64_t)&protocol conformance descriptor for <> DefaultIndices<A>);
}

uint64_t associated type witness table accessor for Collection.SubSequence : BidirectionalCollection in <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return associated type witness table accessor for Collection.Indices : BidirectionalCollection in <> InterspersedSequence<A>(a1, a2, a3, (uint64_t)&protocol conformance descriptor for <> InterspersedSequence<A>, (uint64_t)&protocol conformance descriptor for <> Slice<A>);
}

uint64_t base witness table accessor for BidirectionalCollection in <> InterspersedSequence<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for <> InterspersedSequence<A>, a1);
}

uint64_t associated type witness table accessor for Collection.Indices : RandomAccessCollection in <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return associated type witness table accessor for Collection.Indices : BidirectionalCollection in <> InterspersedSequence<A>(a1, a2, a3, (uint64_t)&protocol conformance descriptor for <> InterspersedSequence<A>, (uint64_t)&protocol conformance descriptor for <> DefaultIndices<A>);
}

uint64_t associated type witness table accessor for Collection.SubSequence : RandomAccessCollection in <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return associated type witness table accessor for Collection.Indices : BidirectionalCollection in <> InterspersedSequence<A>(a1, a2, a3, (uint64_t)&protocol conformance descriptor for <> InterspersedSequence<A>, (uint64_t)&protocol conformance descriptor for <> Slice<A>);
}

uint64_t base witness table accessor for LazySequenceProtocol in <> InterspersedSequence<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for <> InterspersedSequence<A>, a1);
}

uint64_t associated type witness table accessor for LazySequenceProtocol.Elements : Collection in <> InterspersedSequence<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for <> InterspersedSequence<A>, a1);
}

uint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in InterspersedMapSequence<A, B>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for InterspersedMapSequence<A, B>.Iterator, a1);
}

uint64_t base witness table accessor for Equatable in InterspersedMapSequence<A, B><>.Index(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for InterspersedMapSequence<A, B><>.Index, a1);
}

uint64_t base witness table accessor for Sequence in <> InterspersedMapSequence<A, B>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for InterspersedMapSequence<A, B>, a1);
}

uint64_t associated type witness table accessor for Collection.Index : Comparable in <> InterspersedMapSequence<A, B>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for InterspersedMapSequence<A, B><>.Index, a1);
}

uint64_t base witness table accessor for Collection in <> InterspersedMapSequence<A, B>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for <> InterspersedMapSequence<A, B>, a1);
}

{
  return associated type witness table accessor for LazySequenceProtocol.Elements : Collection in <> InterspersedMapSequence<A, B>(a1);
}

uint64_t associated type witness table accessor for Collection.Indices : BidirectionalCollection in <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return associated type witness table accessor for Collection.Indices : BidirectionalCollection in <> InterspersedSequence<A>(a1, a2, a3, (uint64_t)&protocol conformance descriptor for <> InterspersedMapSequence<A, B>, (uint64_t)&protocol conformance descriptor for <> DefaultIndices<A>);
}

uint64_t associated type witness table accessor for Collection.SubSequence : BidirectionalCollection in <> InterspersedMapSequence<A, B>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return associated type witness table accessor for Collection.Indices : BidirectionalCollection in <> InterspersedSequence<A>(a1, a2, a3, (uint64_t)&protocol conformance descriptor for <> InterspersedMapSequence<A, B>, (uint64_t)&protocol conformance descriptor for <> Slice<A>);
}

uint64_t associated type witness table accessor for Collection.Indices : BidirectionalCollection in <> InterspersedSequence<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return swift_getWitnessTable(a5, a1);
}

uint64_t base witness table accessor for LazySequenceProtocol in <> InterspersedMapSequence<A, B>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for InterspersedMapSequence<A, B>, a1);
}

uint64_t associated type witness table accessor for LazySequenceProtocol.Elements : Collection in <> InterspersedMapSequence<A, B>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for <> InterspersedMapSequence<A, B>, a1);
}

uint64_t type metadata completion function for InterspersedSequence(uint64_t a1)
{
  uint64_t v1 = swift_checkMetadataState(319, *(void *)(a1 + 16));
  uint64_t AssociatedTypeWitness = v1;
  if (v3 <= 0x3F)
  {
    v6[0] = *(void *)(v1 - 8) + 64;
    uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(319, *(void *)(a1 + 24), v1, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
    if (v4 <= 0x3F)
    {
      v6[1] = *(void *)(AssociatedTypeWitness - 8) + 64;
      uint64_t AssociatedTypeWitness = 0;
      swift_initStructMetadata(a1, 0, 2, v6, a1 + 32);
    }
  }
  return AssociatedTypeWitness;
}

uint64_t *initializeBufferWithCopyOfBuffer for InterspersedSequence(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 16);
  uint64_t v4 = *(void *)(v3 - 8);
  uint64_t v5 = *(void *)(v4 + 64);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v7 = *(void *)(AssociatedTypeWitness - 8);
  int v8 = *(_DWORD *)(v7 + 80);
  unsigned int v9 = (v8 | *(unsigned char *)(v4 + 80));
  if (v9 > 7
    || ((v8 | *(_DWORD *)(v4 + 80)) & 0x100000) != 0
    || (uint64_t v10 = v8 + v5,
        unint64_t v11 = ~(unint64_t)v8,
        *(void *)(v7 + 64) + (v11 & v10) > 0x18))
  {
    uint64_t v13 = *a2;
    *a1 = *a2;
    int64_t v12 = (uint64_t *)(v13 + ((v9 + 16) & ~v9));
    swift_retain(v13);
  }
  else
  {
    int64_t v12 = a1;
    uint64_t v15 = AssociatedTypeWitness;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v4 + 16))(a1, a2, v3);
    (*(void (**)(unint64_t, unint64_t, uint64_t))(v7 + 16))(v11 & ((unint64_t)a1 + v10), v11 & ((unint64_t)a2 + v10), v15);
  }
  return v12;
}

uint64_t destroy for InterspersedSequence(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 16);
  uint64_t v3 = *(void *)(v2 - 8);
  (*(void (**)(uint64_t, uint64_t))(v3 + 8))(a1, v2);
  uint64_t v4 = *(void *)(v3 + 64) + a1;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a2 + 24), v2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  return (*(uint64_t (**)(unint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 8))((*(unsigned __int8 *)(*(void *)(AssociatedTypeWitness - 8) + 80) + v4) & ~(unint64_t)*(unsigned __int8 *)(*(void *)(AssociatedTypeWitness - 8) + 80), AssociatedTypeWitness);
}

uint64_t initializeWithCopy for InterspersedSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(a3 + 16);
  uint64_t v5 = *(void *)(v4 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v5 + 16))(a1, a2, v4);
  uint64_t v6 = *(void *)(v5 + 64);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), v4, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v8 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(unint64_t, unint64_t, uint64_t))(v8 + 16))(~(unint64_t)*(unsigned __int8 *)(v8 + 80) & (*(unsigned __int8 *)(v8 + 80) + v6 + a1), ~(unint64_t)*(unsigned __int8 *)(v8 + 80) & (a2 + *(unsigned __int8 *)(v8 + 80) + v6), AssociatedTypeWitness);
  return a1;
}

uint64_t assignWithCopy for InterspersedSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(a3 + 16);
  uint64_t v5 = *(void *)(v4 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v5 + 24))(a1, a2, v4);
  uint64_t v6 = *(void *)(v5 + 64);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), v4, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v8 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(unint64_t, unint64_t, uint64_t))(v8 + 24))(~(unint64_t)*(unsigned __int8 *)(v8 + 80) & (*(unsigned __int8 *)(v8 + 80) + v6 + a1), ~(unint64_t)*(unsigned __int8 *)(v8 + 80) & (a2 + *(unsigned __int8 *)(v8 + 80) + v6), AssociatedTypeWitness);
  return a1;
}

uint64_t initializeWithTake for InterspersedSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(a3 + 16);
  uint64_t v5 = *(void *)(v4 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v5 + 32))(a1, a2, v4);
  uint64_t v6 = *(void *)(v5 + 64);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), v4, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v8 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(unint64_t, unint64_t, uint64_t))(v8 + 32))(~(unint64_t)*(unsigned __int8 *)(v8 + 80) & (*(unsigned __int8 *)(v8 + 80) + v6 + a1), ~(unint64_t)*(unsigned __int8 *)(v8 + 80) & (a2 + *(unsigned __int8 *)(v8 + 80) + v6), AssociatedTypeWitness);
  return a1;
}

uint64_t assignWithTake for InterspersedSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(a3 + 16);
  uint64_t v5 = *(void *)(v4 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v5 + 40))(a1, a2, v4);
  uint64_t v6 = *(void *)(v5 + 64);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), v4, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v8 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(unint64_t, unint64_t, uint64_t))(v8 + 40))(~(unint64_t)*(unsigned __int8 *)(v8 + 80) & (*(unsigned __int8 *)(v8 + 80) + v6 + a1), ~(unint64_t)*(unsigned __int8 *)(v8 + 80) & (a2 + *(unsigned __int8 *)(v8 + 80) + v6), AssociatedTypeWitness);
  return a1;
}

uint64_t getEnumTagSinglePayload for InterspersedSequence(unsigned __int8 *a1, unsigned int a2, uint64_t a3)
{
  uint64_t v5 = *(void *)(a3 + 16);
  uint64_t v6 = *(void *)(v5 - 8);
  unsigned int v7 = *(_DWORD *)(v6 + 84);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), v5, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v9 = *(void *)(AssociatedTypeWitness - 8);
  uint64_t v10 = *(unsigned int *)(v9 + 84);
  unsigned int v11 = v7;
  if (v10 > v7) {
    unsigned int v11 = *(_DWORD *)(v9 + 84);
  }
  if (!a2) {
    return 0;
  }
  unint64_t v12 = ~(unint64_t)*(unsigned __int8 *)(v9 + 80);
  uint64_t v13 = *(void *)(v6 + 64) + *(unsigned __int8 *)(v9 + 80);
  BOOL v14 = a2 <= v11;
  unsigned int v15 = a2 - v11;
  if (!v14)
  {
    unint64_t v16 = *(void *)(v9 + 64) + (v12 & v13);
    if (v16 > 3)
    {
LABEL_6:
      int v17 = a1[v16];
      goto LABEL_14;
    }
    unsigned int v19 = ((~(-1 << (8 * v16)) + v15) >> (8 * v16)) + 1;
    if (v19 > 0xFFFF)
    {
      int v17 = *(_DWORD *)&a1[v16];
    }
    else
    {
      if (v19 <= 0xFF)
      {
        if (v19 < 2) {
          goto LABEL_22;
        }
        goto LABEL_6;
      }
      int v17 = *(unsigned __int16 *)&a1[v16];
    }
LABEL_14:
    if (v17)
    {
      int v20 = (v17 - 1) << (8 * v16);
      int v21 = 0;
      if (v16 >= 4) {
        int v20 = 0;
      }
      if (v16)
      {
        int v22 = 4;
        if (v16 < 4) {
          int v22 = *(_DWORD *)(v9 + 64) + (v12 & v13);
        }
        switch(v22)
        {
          case 1:
            int v21 = *a1;
            break;
          case 2:
            int v21 = *(unsigned __int16 *)a1;
            break;
          case 3:
            int v21 = *(unsigned __int16 *)a1 | (a1[2] << 16);
            break;
          case 4:
            int v21 = *(_DWORD *)a1;
            break;
        }
      }
      return v11 + (v20 | v21) + 1;
    }
  }
LABEL_22:
  unsigned int v18 = 0;
  if (!v11) {
    return v18;
  }
  if (v7 >= v10)
  {
    uint64_t v23 = (uint64_t)a1;
    uint64_t v10 = v7;
    uint64_t v24 = v5;
  }
  else
  {
    uint64_t v23 = v12 & (unint64_t)&a1[v13];
    uint64_t v24 = AssociatedTypeWitness;
  }
  return __swift_getEnumTagSinglePayload(v23, v10, v24);
}

uint64_t storeEnumTagSinglePayload for InterspersedSequence(uint64_t a1, unsigned int a2, unsigned int a3, uint64_t a4)
{
  uint64_t v5 = *(void *)(a4 + 16);
  uint64_t v6 = *(void *)(v5 - 8);
  unsigned int v7 = *(_DWORD *)(v6 + 84);
  unsigned int v28 = 0;
  uint64_t result = swift_getAssociatedTypeWitness(0, *(void *)(a4 + 24), v5, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v9 = *(void *)(result - 8);
  uint64_t v10 = *(unsigned int *)(v9 + 84);
  unsigned int v11 = v7;
  if (v10 > v7) {
    unsigned int v11 = *(_DWORD *)(v9 + 84);
  }
  unint64_t v12 = ~(unint64_t)*(unsigned __int8 *)(v9 + 80);
  uint64_t v13 = *(void *)(v6 + 64) + *(unsigned __int8 *)(v9 + 80);
  unint64_t v14 = *(void *)(v9 + 64) + (v12 & v13);
  BOOL v15 = a3 <= v11;
  unsigned int v16 = a3 - v11;
  if (!v15)
  {
    if (v14 > 3)
    {
      int v25 = 1;
LABEL_11:
      unsigned int v28 = v25;
      goto LABEL_12;
    }
    unsigned int v17 = ((~(-1 << (8 * v14)) + v16) >> (8 * v14)) + 1;
    if (v17 > 0xFFFF)
    {
      int v25 = 4;
      goto LABEL_11;
    }
    int v18 = 2;
    if (v17 < 0x100) {
      int v18 = v17 >= 2;
    }
    unsigned int v28 = v18;
  }
LABEL_12:
  if (v11 < a2)
  {
    unsigned int v19 = a2 + ~v11;
    if (v14 >= 4)
    {
      int v20 = 1;
      __bzero(a1, v14);
      *(_DWORD *)a1 = v19;
      uint64_t v21 = a1;
      uint64_t result = v28;
      switch(v28)
      {
        case 0u:
          return result;
        case 1u:
          goto LABEL_31;
        case 2u:
          goto LABEL_32;
        case 3u:
          goto LABEL_35;
        case 4u:
          goto LABEL_33;
        case 5u:
          goto jpt_3266EB;
      }
    }
    int v20 = (v19 >> (8 * v14)) + 1;
    if (v14)
    {
      int v22 = ~(-1 << (8 * v14)) & v19;
      __bzero(a1, v14);
      if (v14 != 3)
      {
        if (v14 == 2)
        {
          uint64_t v21 = a1;
          *(_WORD *)a1 = v22;
          uint64_t result = v28;
          switch(v28)
          {
            case 0u:
              return result;
            case 1u:
              goto LABEL_31;
            case 2u:
              goto LABEL_32;
            case 3u:
              goto LABEL_35;
            case 4u:
              goto LABEL_33;
            case 5u:
              goto jpt_3266EB;
          }
        }
        uint64_t v21 = a1;
        *(unsigned char *)a1 = v22;
        uint64_t result = v28;
        switch(v28)
        {
          case 0u:
            return result;
          case 1u:
            goto LABEL_31;
          case 2u:
            goto LABEL_32;
          case 3u:
            goto LABEL_35;
          case 4u:
            goto LABEL_33;
          case 5u:
            goto jpt_3266EB;
        }
      }
      uint64_t v21 = a1;
      *(_WORD *)a1 = v22;
      *(unsigned char *)(a1 + 2) = BYTE2(v22);
      uint64_t result = v28;
      switch(v28)
      {
        case 0u:
          return result;
        case 1u:
          goto LABEL_31;
        case 2u:
          goto LABEL_32;
        case 3u:
          goto LABEL_35;
        case 4u:
          goto LABEL_33;
        case 5u:
          goto jpt_3266EB;
      }
    }
    uint64_t result = v28;
    uint64_t v21 = a1;
    switch(v28)
    {
      case 0u:
        return result;
      case 1u:
LABEL_31:
        *(unsigned char *)(v21 + v14) = v20;
        return result;
      case 2u:
LABEL_32:
        *(_WORD *)(v21 + v14) = v20;
        return result;
      case 3u:
        goto LABEL_35;
      case 4u:
LABEL_33:
        *(_DWORD *)(v21 + v14) = v20;
        return result;
      case 5u:
jpt_3266EB:
        JUMPOUT(0x326810);
    }
  }
  switch(v28)
  {
    case 0u:
      break;
    case 1u:
      *(unsigned char *)(a1 + v14) = 0;
      break;
    case 2u:
      *(_WORD *)(a1 + v14) = 0;
      break;
    case 3u:
LABEL_35:
      BUG();
    case 4u:
      *(_DWORD *)(a1 + v14) = 0;
      break;
  }
  if (a2)
  {
    if (v7 >= v10)
    {
      uint64_t v23 = a1;
      uint64_t v10 = v7;
      uint64_t v24 = v5;
    }
    else
    {
      uint64_t v23 = v12 & (a1 + v13);
      uint64_t v24 = result;
    }
    return __swift_storeEnumTagSinglePayload(v23, a2, v10, v24);
  }
  return result;
}

uint64_t type metadata completion function for InterspersedSequence.Iterator(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 16);
  uint64_t v2 = *(void *)(a1 + 24);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(319, v2, v1, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v4 = AssociatedTypeWitness;
  if (v5 <= 0x3F)
  {
    v11[0] = *(void *)(AssociatedTypeWitness - 8) + 64;
    uint64_t v6 = swift_getAssociatedTypeWitness(319, v2, v1, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
    uint64_t v4 = v6;
    if (v8 <= 0x3F)
    {
      v11[1] = *(void *)(v6 - 8) + 64;
      uint64_t v4 = type metadata accessor for InterspersedSequence.Iterator.State(319, v1, v2, v7);
      if (v9 <= 0x3F)
      {
        void v11[2] = *(void *)(v4 - 8) + 64;
        uint64_t v4 = 0;
        swift_initStructMetadata(a1, 0, 3, v11, a1 + 32);
      }
    }
  }
  return v4;
}

uint64_t *initializeBufferWithCopyOfBuffer for InterspersedSequence.Iterator(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 16);
  uint64_t v4 = *(void *)(a3 + 24);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v5 = *(void *)(AssociatedTypeWitness - 8);
  uint64_t v6 = *(void *)(v5 + 64);
  uint64_t v7 = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v8 = *(void *)(v7 - 8);
  int v9 = *(_DWORD *)(v8 + 80);
  size_t v10 = *(void *)(v8 + 64);
  unsigned int v11 = *(_DWORD *)(v8 + 84);
  size_t v12 = v10;
  if (v11 <= 1)
  {
    if (v10 <= 3)
    {
      unsigned int v13 = (~(-1 << (8 * v10)) - v11 + 2) >> (8 * v10);
      if (v13 <= 0xFFFE)
      {
        uint64_t v14 = v13 != 0;
        if (v13 >= 0xFF) {
          uint64_t v14 = 2;
        }
        goto LABEL_10;
      }
      uint64_t v32 = 4;
    }
    else
    {
      uint64_t v32 = 1;
    }
    uint64_t v14 = v32;
LABEL_10:
    size_t v12 = v10 + v14;
  }
  uint64_t v15 = v5;
  int v16 = v9 | *(_DWORD *)(v5 + 80);
  unsigned int v17 = (v9 | *(unsigned char *)(v5 + 80));
  if (v17 > 7
    || (unint64_t v18 = ~(unint64_t)v9,
        uint64_t v19 = v9 + v6,
        size_t v20 = v10 + v9,
        (v18 & (v20 + (v18 & v19))) + v12 > 0x18)
    || (v16 & 0x100000) != 0)
  {
    uint64_t v28 = *a2;
    *a1 = *a2;
    swift_retain();
    return (uint64_t *)(v28 + ((v17 + 16) & ~v17));
  }
  else
  {
    unsigned int v35 = *(_DWORD *)(v8 + 84);
    uint64_t v34 = *(void *)(v8 + 64);
    uint64_t v21 = AssociatedTypeWitness;
    uint64_t v37 = v7;
    uint64_t v33 = *(void *)(v7 - 8);
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v15 + 16))(a1, a2, v21);
    unint64_t v22 = v18 & ((unint64_t)a1 + v19);
    unint64_t v23 = v18 & ((unint64_t)a2 + v19);
    uint64_t v39 = *(void (**)(unint64_t, unint64_t, uint64_t))(v33 + 16);
    v39(v22, v23, v37);
    uint64_t v24 = (void *)(v18 & (v20 + v22));
    int v25 = (const void *)(v18 & (v20 + v23));
    if (__swift_getEnumTagSinglePayload((uint64_t)v25, 2, v37))
    {
      if (v35 <= 1)
      {
        if (v10 <= 3)
        {
          unsigned int v30 = (~(-1 << (8 * v10)) - v35 + 2) >> (8 * v10);
          uint64_t v26 = a1;
          if (v30 > 0xFFFE)
          {
            uint64_t v29 = 4;
          }
          else
          {
            uint64_t v29 = 2;
            if (v30 < 0xFF) {
              uint64_t v29 = v30 != 0;
            }
          }
        }
        else
        {
          uint64_t v29 = 1;
          uint64_t v26 = a1;
        }
        size_t v27 = v29 + v34;
      }
      else
      {
        uint64_t v26 = a1;
        size_t v27 = v10;
      }
      memcpy(v24, v25, v27);
    }
    else
    {
      v39((unint64_t)v24, (unint64_t)v25, v37);
      __swift_storeEnumTagSinglePayload((uint64_t)v24, 0, 2, v37);
      return a1;
    }
  }
  return v26;
}

uint64_t destroy for InterspersedSequence.Iterator(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 16);
  uint64_t v3 = *(void *)(a2 + 24);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v3, v2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v5 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t))(v5 + 8))(a1, AssociatedTypeWitness);
  uint64_t v6 = *(void *)(v5 + 64) + a1;
  uint64_t v7 = swift_getAssociatedTypeWitness(0, v3, v2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v8 = *(void *)(v7 - 8);
  uint64_t v9 = *(unsigned __int8 *)(v8 + 80);
  uint64_t v10 = ~v9 & (v9 + v6);
  unsigned int v13 = *(uint64_t (**)(uint64_t, uint64_t))(v8 + 8);
  v13(v10, v7);
  uint64_t v11 = ~v9 & (v10 + *(void *)(v8 + 64) + v9);
  uint64_t result = __swift_getEnumTagSinglePayload(v11, 2, v7);
  if (!result) {
    return v13(v11, v7);
  }
  return result;
}

uint64_t initializeWithCopy for InterspersedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 16);
  uint64_t v4 = *(void *)(a3 + 24);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 16))(a1, a2, AssociatedTypeWitness);
  uint64_t v7 = *(void *)(v6 + 64);
  uint64_t v8 = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v9 = *(void *)(v8 - 8);
  uint64_t v26 = v8;
  uint64_t v10 = *(unsigned __int8 *)(v9 + 80);
  uint64_t v11 = v10 + v7;
  uint64_t v12 = ~v10;
  uint64_t v13 = ~v10 & (v11 + a1);
  uint64_t v14 = ~v10 & (a2 + v11);
  size_t v27 = *(void (**)(uint64_t, uint64_t, uint64_t))(v9 + 16);
  v27(v13, v14, v8);
  size_t v28 = *(void *)(v9 + 64);
  size_t v15 = v28 + v10;
  int v16 = (void *)(v12 & (v15 + v13));
  unsigned int v17 = (const void *)(v12 & (v14 + v15));
  if (__swift_getEnumTagSinglePayload((uint64_t)v17, 2, v26))
  {
    unsigned int v18 = *(_DWORD *)(v9 + 84);
    if (v18 > 1)
    {
      size_t v19 = v28;
LABEL_14:
      memcpy(v16, v17, v19);
      return a1;
    }
    if (v28 <= 3)
    {
      unsigned int v20 = ((1 << (8 * v28)) - v18 + 1) >> (8 * v28);
      if (v20 <= 0xFFFE)
      {
        BOOL v21 = v20 != 0;
        BOOL v22 = v20 < 0xFF;
        uint64_t v23 = 2;
        if (v22) {
          uint64_t v23 = v21;
        }
        goto LABEL_13;
      }
      uint64_t v25 = 4;
    }
    else
    {
      uint64_t v25 = 1;
    }
    uint64_t v23 = v25;
LABEL_13:
    size_t v19 = v23 + v28;
    goto LABEL_14;
  }
  v27((uint64_t)v16, (uint64_t)v17, v26);
  __swift_storeEnumTagSinglePayload((uint64_t)v16, 0, 2, v26);
  return a1;
}

uint64_t assignWithCopy for InterspersedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 16);
  uint64_t v4 = *(void *)(a3 + 24);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 24))(a1, a2, AssociatedTypeWitness);
  uint64_t v7 = *(void *)(v6 + 64);
  uint64_t v8 = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v9 = *(void *)(v8 - 8);
  uint64_t v32 = v8;
  uint64_t v10 = *(unsigned __int8 *)(v9 + 80);
  uint64_t v11 = v10 + v7;
  uint64_t v12 = ~v10 & (v11 + a1);
  uint64_t v13 = ~v10 & (a2 + v11);
  uint64_t v33 = *(void (**)(uint64_t, uint64_t, uint64_t))(v9 + 24);
  v33(v12, v13, v8);
  uint64_t v35 = v9;
  size_t v34 = *(void *)(v9 + 64);
  uint64_t v14 = (const void *)(~v10 & (v13 + v34 + v10));
  size_t v15 = (void *)(~v10 & (v34 + v10 + v12));
  LODWORD(v12) = __swift_getEnumTagSinglePayload((uint64_t)v15, 2, v32);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v14, 2, v32);
  if (!v12)
  {
    if (!EnumTagSinglePayload)
    {
      v33((uint64_t)v15, (uint64_t)v14, v32);
      return a1;
    }
    (*(void (**)(void *, uint64_t, uint64_t, void (*)(uint64_t, uint64_t, uint64_t)))(v35 + 8))(v15, v32, v17, v33);
    unsigned int v21 = *(_DWORD *)(v35 + 84);
    if (v21 > 1) {
      goto LABEL_8;
    }
    size_t v19 = v34;
    if (v34 <= 3)
    {
      unsigned int v27 = ((1 << (8 * v34)) - v21 + 1) >> (8 * v34);
      if (v27 <= 0xFFFE)
      {
        BOOL v28 = v27 != 0;
        BOOL v25 = v27 < 0xFF;
        uint64_t v26 = 2;
        if (v25) {
          uint64_t v26 = v28;
        }
        goto LABEL_26;
      }
      uint64_t v31 = 4;
    }
    else
    {
      uint64_t v31 = 1;
    }
    uint64_t v26 = v31;
LABEL_26:
    uint64_t v20 = a1;
    goto LABEL_27;
  }
  if (EnumTagSinglePayload)
  {
    unsigned int v18 = *(_DWORD *)(v35 + 84);
    if (v18 <= 1)
    {
      size_t v19 = v34;
      uint64_t v20 = a1;
      if (v34 <= 3)
      {
        unsigned int v23 = ((1 << (8 * v34)) - v18 + 1) >> (8 * v34);
        if (v23 <= 0xFFFE)
        {
          BOOL v24 = v23 != 0;
          BOOL v25 = v23 < 0xFF;
          uint64_t v26 = 2;
          if (v25) {
            uint64_t v26 = v24;
          }
          goto LABEL_27;
        }
        uint64_t v30 = 4;
      }
      else
      {
        uint64_t v30 = 1;
      }
      uint64_t v26 = v30;
LABEL_27:
      size_t v22 = v26 + v19;
      goto LABEL_28;
    }
LABEL_8:
    uint64_t v20 = a1;
    size_t v22 = v34;
LABEL_28:
    memcpy(v15, v14, v22);
    return v20;
  }
  (*(void (**)(void *, const void *, uint64_t))(v35 + 16))(v15, v14, v32);
  __swift_storeEnumTagSinglePayload((uint64_t)v15, 0, 2, v32);
  return a1;
}

uint64_t initializeWithTake for InterspersedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 16);
  uint64_t v4 = *(void *)(a3 + 24);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 32))(a1, a2, AssociatedTypeWitness);
  uint64_t v7 = *(void *)(v6 + 64);
  uint64_t v8 = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v9 = *(void *)(v8 - 8);
  uint64_t v26 = v8;
  uint64_t v10 = *(unsigned __int8 *)(v9 + 80);
  uint64_t v11 = v10 + v7;
  uint64_t v12 = ~v10;
  uint64_t v13 = ~v10 & (v11 + a1);
  uint64_t v14 = ~v10 & (a2 + v11);
  unsigned int v27 = *(void (**)(uint64_t, uint64_t, uint64_t))(v9 + 32);
  v27(v13, v14, v8);
  size_t v28 = *(void *)(v9 + 64);
  size_t v15 = v28 + v10;
  int v16 = (void *)(v12 & (v15 + v13));
  uint64_t v17 = (const void *)(v12 & (v14 + v15));
  if (__swift_getEnumTagSinglePayload((uint64_t)v17, 2, v26))
  {
    unsigned int v18 = *(_DWORD *)(v9 + 84);
    if (v18 > 1)
    {
      size_t v19 = v28;
LABEL_14:
      memcpy(v16, v17, v19);
      return a1;
    }
    if (v28 <= 3)
    {
      unsigned int v20 = ((1 << (8 * v28)) - v18 + 1) >> (8 * v28);
      if (v20 <= 0xFFFE)
      {
        BOOL v21 = v20 != 0;
        BOOL v22 = v20 < 0xFF;
        uint64_t v23 = 2;
        if (v22) {
          uint64_t v23 = v21;
        }
        goto LABEL_13;
      }
      uint64_t v25 = 4;
    }
    else
    {
      uint64_t v25 = 1;
    }
    uint64_t v23 = v25;
LABEL_13:
    size_t v19 = v23 + v28;
    goto LABEL_14;
  }
  v27((uint64_t)v16, (uint64_t)v17, v26);
  __swift_storeEnumTagSinglePayload((uint64_t)v16, 0, 2, v26);
  return a1;
}

uint64_t assignWithTake for InterspersedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 16);
  uint64_t v4 = *(void *)(a3 + 24);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 40))(a1, a2, AssociatedTypeWitness);
  uint64_t v7 = *(void *)(v6 + 64);
  uint64_t v8 = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v9 = *(void *)(v8 - 8);
  uint64_t v32 = v8;
  uint64_t v10 = *(unsigned __int8 *)(v9 + 80);
  uint64_t v11 = v10 + v7;
  uint64_t v12 = ~v10 & (v11 + a1);
  uint64_t v13 = ~v10 & (a2 + v11);
  uint64_t v33 = *(void (**)(uint64_t, uint64_t, uint64_t))(v9 + 40);
  v33(v12, v13, v8);
  uint64_t v35 = v9;
  size_t v34 = *(void *)(v9 + 64);
  uint64_t v14 = (const void *)(~v10 & (v13 + v34 + v10));
  size_t v15 = (void *)(~v10 & (v34 + v10 + v12));
  LODWORD(v12) = __swift_getEnumTagSinglePayload((uint64_t)v15, 2, v32);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v14, 2, v32);
  if (!v12)
  {
    if (!EnumTagSinglePayload)
    {
      v33((uint64_t)v15, (uint64_t)v14, v32);
      return a1;
    }
    (*(void (**)(void *, uint64_t, uint64_t, void (*)(uint64_t, uint64_t, uint64_t)))(v35 + 8))(v15, v32, v17, v33);
    unsigned int v21 = *(_DWORD *)(v35 + 84);
    if (v21 > 1) {
      goto LABEL_8;
    }
    size_t v19 = v34;
    if (v34 <= 3)
    {
      unsigned int v27 = ((1 << (8 * v34)) - v21 + 1) >> (8 * v34);
      if (v27 <= 0xFFFE)
      {
        BOOL v28 = v27 != 0;
        BOOL v25 = v27 < 0xFF;
        uint64_t v26 = 2;
        if (v25) {
          uint64_t v26 = v28;
        }
        goto LABEL_26;
      }
      uint64_t v31 = 4;
    }
    else
    {
      uint64_t v31 = 1;
    }
    uint64_t v26 = v31;
LABEL_26:
    uint64_t v20 = a1;
    goto LABEL_27;
  }
  if (EnumTagSinglePayload)
  {
    unsigned int v18 = *(_DWORD *)(v35 + 84);
    if (v18 <= 1)
    {
      size_t v19 = v34;
      uint64_t v20 = a1;
      if (v34 <= 3)
      {
        unsigned int v23 = ((1 << (8 * v34)) - v18 + 1) >> (8 * v34);
        if (v23 <= 0xFFFE)
        {
          BOOL v24 = v23 != 0;
          BOOL v25 = v23 < 0xFF;
          uint64_t v26 = 2;
          if (v25) {
            uint64_t v26 = v24;
          }
          goto LABEL_27;
        }
        uint64_t v30 = 4;
      }
      else
      {
        uint64_t v30 = 1;
      }
      uint64_t v26 = v30;
LABEL_27:
      size_t v22 = v26 + v19;
      goto LABEL_28;
    }
LABEL_8:
    uint64_t v20 = a1;
    size_t v22 = v34;
LABEL_28:
    memcpy(v15, v14, v22);
    return v20;
  }
  (*(void (**)(void *, const void *, uint64_t))(v35 + 32))(v15, v14, v32);
  __swift_storeEnumTagSinglePayload((uint64_t)v15, 0, 2, v32);
  return a1;
}

uint64_t getEnumTagSinglePayload for InterspersedSequence.Iterator(unsigned __int8 *a1, unsigned int a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(a3 + 16);
  uint64_t v5 = *(void *)(a3 + 24);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v5, v4, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  uint64_t v7 = v5;
  unsigned int v8 = *(_DWORD *)(v6 + 84);
  unsigned int v9 = 0;
  uint64_t v10 = swift_getAssociatedTypeWitness(0, v7, v4, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v11 = *(void *)(v10 - 8);
  uint64_t v12 = *(unsigned int *)(v11 + 84);
  unsigned int v13 = v8;
  if (v12 > v8) {
    unsigned int v13 = *(_DWORD *)(v11 + 84);
  }
  unsigned int v14 = v12 - 2;
  if (v12 < 2) {
    unsigned int v14 = 0;
  }
  if (v14 <= v13) {
    unsigned int v14 = v13;
  }
  uint64_t v15 = *(void *)(v11 + 64);
  uint64_t v16 = v15;
  if (v12 <= 1)
  {
    if (v15 <= 3)
    {
      unsigned int v17 = (~(-1 << (8 * v15)) - v12 + 2) >> (8 * v15);
      if (v17 <= 0xFFFE)
      {
        BOOL v18 = v17 != 0;
        BOOL v19 = v17 < 0xFF;
        uint64_t v20 = 2;
        if (v19) {
          uint64_t v20 = v18;
        }
        goto LABEL_16;
      }
      uint64_t v36 = 4;
    }
    else
    {
      uint64_t v36 = 1;
    }
    uint64_t v20 = v36;
LABEL_16:
    uint64_t v16 = v15 + v20;
  }
  if (!a2) {
    return v9;
  }
  uint64_t v21 = *(unsigned __int8 *)(v11 + 80);
  uint64_t v22 = ~v21;
  uint64_t v23 = v21 + v15;
  uint64_t v24 = *(void *)(v6 + 64) + v21;
  BOOL v25 = a2 <= v14;
  unsigned int v26 = a2 - v14;
  if (!v25)
  {
    uint64_t v27 = (v22 & (v23 + (v22 & v24))) + v16;
    if (v27 > 3)
    {
LABEL_20:
      int v28 = a1[v27];
      goto LABEL_27;
    }
    unsigned int v29 = ((~(-1 << (8 * v27)) + v26) >> (8 * v27)) + 1;
    if (v29 > 0xFFFF)
    {
      int v28 = *(_DWORD *)&a1[v27];
    }
    else
    {
      if (v29 <= 0xFF)
      {
        if (v29 < 2) {
          goto LABEL_35;
        }
        goto LABEL_20;
      }
      int v28 = *(unsigned __int16 *)&a1[v27];
    }
LABEL_27:
    if (v28)
    {
      int v30 = (v28 - 1) << (8 * v27);
      int v31 = 0;
      if (v27 >= 4) {
        int v30 = 0;
      }
      if (v27)
      {
        int v32 = 4;
        if (v27 < 4) {
          int v32 = v27;
        }
        switch(v32)
        {
          case 1:
            int v31 = *a1;
            break;
          case 2:
            int v31 = *(unsigned __int16 *)a1;
            break;
          case 3:
            int v31 = *(unsigned __int16 *)a1 | (a1[2] << 16);
            break;
          case 4:
            int v31 = *(_DWORD *)a1;
            break;
        }
      }
      return v14 + (v30 | v31) + 1;
    }
  }
LABEL_35:
  if (!v14) {
    return v9;
  }
  if (v8 == v14) {
    return __swift_getEnumTagSinglePayload((uint64_t)a1, v8, AssociatedTypeWitness);
  }
  uint64_t v34 = v22 & (unint64_t)&a1[v24];
  if (v12 != v14)
  {
    unsigned int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v22 & (v34 + v23), v12, v10);
    unsigned int v9 = 0;
    if (EnumTagSinglePayload >= 3) {
      return EnumTagSinglePayload - 2;
    }
    return v9;
  }
  return __swift_getEnumTagSinglePayload(v34, v12, v10);
}

uint64_t storeEnumTagSinglePayload for InterspersedSequence.Iterator(uint64_t a1, unsigned int a2, unsigned int a3, uint64_t a4)
{
  uint64_t v4 = *(void *)(a4 + 16);
  uint64_t v5 = *(void *)(a4 + 24);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v5, v4, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  unsigned int v7 = *(_DWORD *)(v6 + 84);
  uint64_t result = swift_getAssociatedTypeWitness(0, v5, v4, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v9 = *(void *)(result - 8);
  uint64_t v10 = *(unsigned int *)(v9 + 84);
  unsigned int v46 = v7;
  if (v10 > v7) {
    unsigned int v7 = *(_DWORD *)(v9 + 84);
  }
  unsigned int v11 = v10 - 2;
  unsigned int v47 = 0;
  if (v10 < 2) {
    unsigned int v11 = 0;
  }
  if (v11 > v7) {
    unsigned int v7 = v11;
  }
  uint64_t v12 = *(unsigned __int8 *)(v9 + 80);
  uint64_t v13 = ~v12;
  uint64_t v14 = v12 + *(void *)(v6 + 64);
  uint64_t v15 = ~v12 & v14;
  uint64_t v16 = *(void *)(v9 + 64);
  uint64_t v17 = v16 + v12;
  uint64_t v18 = v13 & (v17 + v15);
  uint64_t v19 = v16;
  if (v10 <= 1)
  {
    if (v16 <= 3)
    {
      unsigned int v20 = (~(-1 << (8 * v16)) - v10 + 2) >> (8 * v16);
      if (v20 <= 0xFFFE)
      {
        uint64_t v21 = v20 != 0;
        if (v20 >= 0xFF) {
          uint64_t v21 = 2;
        }
        goto LABEL_16;
      }
      uint64_t v40 = 4;
    }
    else
    {
      uint64_t v40 = 1;
    }
    uint64_t v21 = v40;
LABEL_16:
    uint64_t v19 = v16 + v21;
  }
  uint64_t v22 = v18 + v19;
  if (a3 > v7)
  {
    if (v22 <= 3)
    {
      unsigned int v23 = ((~(-1 << (8 * v22)) + a3 - v7) >> (8 * v22)) + 1;
      unsigned int v47 = 4;
      if (v23 <= 0xFFFF)
      {
        int v24 = 2;
        if (v23 < 0x100) {
          int v24 = v23 >= 2;
        }
        unsigned int v47 = v24;
      }
    }
    else
    {
      unsigned int v47 = 1;
    }
  }
  unsigned int v25 = a2;
  if (v7 < a2)
  {
    unsigned int v26 = a2 + ~v7;
    if (v22 >= 4)
    {
      int v27 = 1;
      __bzero(a1, v22);
      *(_DWORD *)a1 = v26;
      uint64_t result = v47;
      switch(v47)
      {
        case 0u:
          return result;
        case 1u:
          goto LABEL_46;
        case 2u:
          goto LABEL_47;
        case 3u:
          goto LABEL_72;
        case 4u:
          goto LABEL_48;
      }
    }
    int v27 = (v26 >> (8 * v22)) + 1;
    if (v22)
    {
      int v28 = ~(-1 << (8 * v22)) & v26;
      __bzero(a1, v22);
      if (v22 != 3)
      {
        if (v22 == 2)
        {
          *(_WORD *)a1 = v28;
          uint64_t result = v47;
          switch(v47)
          {
            case 0u:
              return result;
            case 1u:
              goto LABEL_46;
            case 2u:
              goto LABEL_47;
            case 3u:
              goto LABEL_72;
            case 4u:
              goto LABEL_48;
          }
        }
        *(unsigned char *)a1 = v28;
        uint64_t result = v47;
        switch(v47)
        {
          case 0u:
            return result;
          case 1u:
            goto LABEL_46;
          case 2u:
            goto LABEL_47;
          case 3u:
            goto LABEL_72;
          case 4u:
            goto LABEL_48;
        }
      }
      *(_WORD *)a1 = v28;
      *(unsigned char *)(a1 + 2) = BYTE2(v28);
      uint64_t result = v47;
      switch(v47)
      {
        case 0u:
          return result;
        case 1u:
          goto LABEL_46;
        case 2u:
          goto LABEL_47;
        case 3u:
          goto LABEL_72;
        case 4u:
          goto LABEL_48;
      }
    }
    uint64_t result = v47;
    switch(v47)
    {
      case 0u:
        return result;
      case 1u:
LABEL_46:
        *(unsigned char *)(a1 + v22) = v27;
        return result;
      case 2u:
LABEL_47:
        *(_WORD *)(a1 + v22) = v27;
        return result;
      case 3u:
        goto LABEL_72;
      case 4u:
LABEL_48:
        *(_DWORD *)(a1 + v22) = v27;
        return result;
    }
  }
  switch(v47)
  {
    case 0u:
      break;
    case 1u:
      *(unsigned char *)(a1 + v22) = 0;
      break;
    case 2u:
      *(_WORD *)(a1 + v22) = 0;
      break;
    case 3u:
LABEL_72:
      BUG();
    case 4u:
      *(_DWORD *)(a1 + v22) = 0;
      break;
  }
  if (!a2) {
    return result;
  }
  if (v46 == v7) {
    return __swift_storeEnumTagSinglePayload(a1, a2, v46, AssociatedTypeWitness);
  }
  uint64_t v29 = v13 & (a1 + v14);
  if (v10 == v7)
  {
    uint64_t v30 = v29;
    return __swift_storeEnumTagSinglePayload(v30, v25, v10, result);
  }
  uint64_t v31 = v29 + v17;
  if (v10 <= 1)
  {
    if (v16 <= 3)
    {
      unsigned int v32 = ((~(-1 << (8 * v16)) - v10 + 2) >> (8 * v16)) + 1;
      if (v32 <= 0xFFFF)
      {
        BOOL v33 = v32 >= 2;
        BOOL v34 = v32 < 0x100;
        int v35 = 2;
        if (v34) {
          int v35 = v33;
        }
        goto LABEL_56;
      }
      int v41 = 4;
    }
    else
    {
      int v41 = 1;
    }
    int v35 = v41;
LABEL_56:
    uint64_t v16 = (v16 + v35);
  }
  uint64_t v36 = (unsigned char *)(v13 & v31);
  if (v11 >= a2)
  {
    unsigned int v25 = a2 + 2;
    uint64_t v30 = (uint64_t)v36;
    return __swift_storeEnumTagSinglePayload(v30, v25, v10, result);
  }
  int v37 = ~(-1 << (8 * v16));
  if (v16 >= 4) {
    int v37 = -1;
  }
  if (v16)
  {
    int v38 = (a2 + ~v11) & v37;
    int v39 = 4;
    if (v16 < 4) {
      int v39 = v16;
    }
    uint64_t result = __bzero(v36, v16);
    switch(v39)
    {
      case 1:
        *uint64_t v36 = v38;
        break;
      case 2:
        *(_WORD *)uint64_t v36 = v38;
        break;
      case 3:
        *(_WORD *)uint64_t v36 = v38;
        JUMPOUT(0x3278C2);
      case 4:
        *(_DWORD *)uint64_t v36 = v38;
        break;
    }
  }
  return result;
}

uint64_t type metadata completion function for InterspersedSequence.Iterator.State(uint64_t a1)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(319, *(void *)(a1 + 24), *(void *)(a1 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v2 = AssociatedTypeWitness;
  if (v3 <= 0x3F)
  {
    uint64_t v2 = 0;
    swift_initEnumMetadataSinglePayload(a1, 0, *(void *)(AssociatedTypeWitness - 8) + 64, 2);
  }
  return v2;
}

uint64_t *initializeBufferWithCopyOfBuffer for InterspersedSequence.Iterator.State(uint64_t *__dst, uint64_t *a2, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v5 = *(void *)(AssociatedTypeWitness - 8);
  unsigned int v6 = *(_DWORD *)(v5 + 84);
  size_t v7 = *(void *)(v5 + 64);
  unint64_t v8 = v7;
  if (v6 <= 1)
  {
    if (v7 <= 3)
    {
      unsigned int v9 = (~(-1 << (8 * v7)) - v6 + 2) >> (8 * v7);
      if (v9 <= 0xFFFE)
      {
        uint64_t v10 = v9 != 0;
        if (v9 >= 0xFF) {
          uint64_t v10 = 2;
        }
        goto LABEL_10;
      }
      uint64_t v17 = 4;
    }
    else
    {
      uint64_t v17 = 1;
    }
    uint64_t v10 = v17;
LABEL_10:
    unint64_t v8 = v7 + v10;
  }
  int v11 = *(_DWORD *)(v5 + 80);
  if (v11 > 7u || v8 > 0x18 || (v11 & 0x100000) != 0)
  {
    uint64_t v13 = *a2;
    *__dst = *a2;
    uint64_t v12 = (uint64_t *)(v13 + ((v11 + 16) & ~v11));
    swift_retain();
  }
  else
  {
    int v18 = *(_DWORD *)(v5 + 84);
    if (__swift_getEnumTagSinglePayload((uint64_t)a2, 2, AssociatedTypeWitness))
    {
      if (v6 <= 1)
      {
        if (v7 <= 3)
        {
          unsigned int v15 = (~(-1 << (8 * v7)) - v18 + 2) >> (8 * v7);
          uint64_t v12 = __dst;
          if (v15 > 0xFFFE)
          {
            uint64_t v14 = 4;
          }
          else
          {
            uint64_t v14 = 2;
            if (v15 < 0xFF) {
              uint64_t v14 = v15 != 0;
            }
          }
        }
        else
        {
          uint64_t v14 = 1;
          uint64_t v12 = __dst;
        }
        v7 += v14;
      }
      else
      {
        uint64_t v12 = __dst;
      }
      memcpy(v12, a2, v7);
    }
    else
    {
      uint64_t v12 = __dst;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v5 + 16))(__dst, a2, AssociatedTypeWitness);
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 2, AssociatedTypeWitness);
    }
  }
  return v12;
}

uint64_t destroy for InterspersedSequence.Iterator.State(uint64_t a1, uint64_t a2)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a2 + 24), *(void *)(a2 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t result = __swift_getEnumTagSinglePayload(a1, 2, AssociatedTypeWitness);
  if (!result) {
    return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 8))(a1, AssociatedTypeWitness);
  }
  return result;
}

void *initializeWithCopy for InterspersedSequence.Iterator.State(void *__dst, void *__src, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)__src, 2, AssociatedTypeWitness);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  if (EnumTagSinglePayload)
  {
    unsigned int v7 = *(_DWORD *)(v6 + 84);
    size_t v8 = *(void *)(v6 + 64);
    if (v7 > 1)
    {
LABEL_13:
      memcpy(__dst, __src, v8);
      return __dst;
    }
    if (v8 <= 3)
    {
      unsigned int v9 = (~(-1 << (8 * v8)) - v7 + 2) >> (8 * v8);
      if (v9 <= 0xFFFE)
      {
        uint64_t v10 = 2;
        if (v9 < 0xFF) {
          uint64_t v10 = v9 != 0;
        }
        goto LABEL_12;
      }
      uint64_t v12 = 4;
    }
    else
    {
      uint64_t v12 = 1;
    }
    uint64_t v10 = v12;
LABEL_12:
    v8 += v10;
    goto LABEL_13;
  }
  (*(void (**)(void *, void *, uint64_t))(v6 + 16))(__dst, __src, AssociatedTypeWitness);
  __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 2, AssociatedTypeWitness);
  return __dst;
}

void *assignWithCopy for InterspersedSequence.Iterator.State(void *__dst, void *__src, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)__dst, 2, AssociatedTypeWitness);
  int v6 = __swift_getEnumTagSinglePayload((uint64_t)__src, 2, AssociatedTypeWitness);
  uint64_t v7 = *(void *)(AssociatedTypeWitness - 8);
  if (!EnumTagSinglePayload)
  {
    if (!v6)
    {
      (*(void (**)(void *, void *, uint64_t))(v7 + 24))(__dst, __src, AssociatedTypeWitness);
      return __dst;
    }
    (*(void (**)(void *, uint64_t))(v7 + 8))(__dst, AssociatedTypeWitness);
LABEL_6:
    unsigned int v8 = *(_DWORD *)(v7 + 84);
    size_t v9 = *(void *)(v7 + 64);
    if (v8 > 1)
    {
LABEL_17:
      memcpy(__dst, __src, v9);
      return __dst;
    }
    if (v9 <= 3)
    {
      unsigned int v10 = (~(-1 << (8 * v9)) - v8 + 2) >> (8 * v9);
      if (v10 <= 0xFFFE)
      {
        uint64_t v11 = 2;
        if (v10 < 0xFF) {
          uint64_t v11 = v10 != 0;
        }
        goto LABEL_16;
      }
      uint64_t v13 = 4;
    }
    else
    {
      uint64_t v13 = 1;
    }
    uint64_t v11 = v13;
LABEL_16:
    v9 += v11;
    goto LABEL_17;
  }
  if (v6) {
    goto LABEL_6;
  }
  (*(void (**)(void *, void *, uint64_t))(v7 + 16))(__dst, __src, AssociatedTypeWitness);
  __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 2, AssociatedTypeWitness);
  return __dst;
}

void *initializeWithTake for InterspersedSequence.Iterator.State(void *__dst, void *__src, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)__src, 2, AssociatedTypeWitness);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  if (EnumTagSinglePayload)
  {
    unsigned int v7 = *(_DWORD *)(v6 + 84);
    size_t v8 = *(void *)(v6 + 64);
    if (v7 > 1)
    {
LABEL_13:
      memcpy(__dst, __src, v8);
      return __dst;
    }
    if (v8 <= 3)
    {
      unsigned int v9 = (~(-1 << (8 * v8)) - v7 + 2) >> (8 * v8);
      if (v9 <= 0xFFFE)
      {
        uint64_t v10 = 2;
        if (v9 < 0xFF) {
          uint64_t v10 = v9 != 0;
        }
        goto LABEL_12;
      }
      uint64_t v12 = 4;
    }
    else
    {
      uint64_t v12 = 1;
    }
    uint64_t v10 = v12;
LABEL_12:
    v8 += v10;
    goto LABEL_13;
  }
  (*(void (**)(void *, void *, uint64_t))(v6 + 32))(__dst, __src, AssociatedTypeWitness);
  __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 2, AssociatedTypeWitness);
  return __dst;
}

void *assignWithTake for InterspersedSequence.Iterator.State(void *__dst, void *__src, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)__dst, 2, AssociatedTypeWitness);
  int v6 = __swift_getEnumTagSinglePayload((uint64_t)__src, 2, AssociatedTypeWitness);
  uint64_t v7 = *(void *)(AssociatedTypeWitness - 8);
  if (!EnumTagSinglePayload)
  {
    if (!v6)
    {
      (*(void (**)(void *, void *, uint64_t))(v7 + 40))(__dst, __src, AssociatedTypeWitness);
      return __dst;
    }
    (*(void (**)(void *, uint64_t))(v7 + 8))(__dst, AssociatedTypeWitness);
LABEL_6:
    unsigned int v8 = *(_DWORD *)(v7 + 84);
    size_t v9 = *(void *)(v7 + 64);
    if (v8 > 1)
    {
LABEL_17:
      memcpy(__dst, __src, v9);
      return __dst;
    }
    if (v9 <= 3)
    {
      unsigned int v10 = (~(-1 << (8 * v9)) - v8 + 2) >> (8 * v9);
      if (v10 <= 0xFFFE)
      {
        uint64_t v11 = 2;
        if (v10 < 0xFF) {
          uint64_t v11 = v10 != 0;
        }
        goto LABEL_16;
      }
      uint64_t v13 = 4;
    }
    else
    {
      uint64_t v13 = 1;
    }
    uint64_t v11 = v13;
LABEL_16:
    v9 += v11;
    goto LABEL_17;
  }
  if (v6) {
    goto LABEL_6;
  }
  (*(void (**)(void *, void *, uint64_t))(v7 + 32))(__dst, __src, AssociatedTypeWitness);
  __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 2, AssociatedTypeWitness);
  return __dst;
}

uint64_t getEnumTagSinglePayload for InterspersedSequence.Iterator.State(unsigned __int8 *a1, unsigned int a2, uint64_t a3)
{
  unsigned int v5 = 0;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v7 = *(void *)(AssociatedTypeWitness - 8);
  uint64_t v8 = *(unsigned int *)(v7 + 84);
  unsigned int v9 = v8 - 2;
  uint64_t v10 = *(void *)(v7 + 64);
  if (v8 >= 2)
  {
    uint64_t v11 = *(void *)(v7 + 64);
    goto LABEL_13;
  }
  unsigned int v9 = 0;
  if (v10 <= 3)
  {
    unsigned int v12 = (~(-1 << (8 * v10)) - v8 + 2) >> (8 * v10);
    if (v12 <= 0xFFFE)
    {
      BOOL v13 = v12 != 0;
      BOOL v14 = v12 < 0xFF;
      uint64_t v15 = 2;
      if (v14) {
        uint64_t v15 = v13;
      }
      goto LABEL_12;
    }
    uint64_t v25 = 4;
  }
  else
  {
    uint64_t v25 = 1;
  }
  uint64_t v15 = v25;
LABEL_12:
  uint64_t v11 = v10 + v15;
  LODWORD(v10) = v11;
LABEL_13:
  if (!a2) {
    return v5;
  }
  BOOL v16 = a2 <= v9;
  unsigned int v17 = a2 - v9;
  if (v16) {
    goto LABEL_31;
  }
  if (v10 > 3)
  {
LABEL_16:
    int v18 = a1[v11];
    goto LABEL_23;
  }
  unsigned int v19 = ((~(-1 << (8 * v10)) + v17) >> (8 * v10)) + 1;
  if (v19 > 0xFFFF)
  {
    int v18 = *(_DWORD *)&a1[v11];
  }
  else
  {
    if (v19 <= 0xFF)
    {
      if (v19 < 2) {
        goto LABEL_31;
      }
      goto LABEL_16;
    }
    int v18 = *(unsigned __int16 *)&a1[v11];
  }
LABEL_23:
  if (v18)
  {
    int v20 = (v18 - 1) << (8 * v10);
    int v21 = 0;
    if (v10 >= 4) {
      int v20 = 0;
    }
    if (v10)
    {
      int v22 = 4;
      if (v10 < 4) {
        int v22 = v10;
      }
      switch(v22)
      {
        case 1:
          int v21 = *a1;
          break;
        case 2:
          int v21 = *(unsigned __int16 *)a1;
          break;
        case 3:
          int v21 = *(unsigned __int16 *)a1 | (a1[2] << 16);
          break;
        case 4:
          int v21 = *(_DWORD *)a1;
          break;
      }
    }
    return v9 + (v20 | v21) + 1;
  }
LABEL_31:
  if (v9)
  {
    unsigned int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)a1, v8, AssociatedTypeWitness);
    unsigned int v5 = 0;
    if (EnumTagSinglePayload >= 3) {
      return EnumTagSinglePayload - 2;
    }
  }
  return v5;
}

uint64_t storeEnumTagSinglePayload for InterspersedSequence.Iterator.State(uint64_t a1, unsigned int a2, unsigned int a3, uint64_t a4)
{
  unsigned int v5 = 0;
  uint64_t result = swift_getAssociatedTypeWitness(0, *(void *)(a4 + 24), *(void *)(a4 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v7 = *(void *)(result - 8);
  uint64_t v8 = *(unsigned int *)(v7 + 84);
  unsigned int v9 = v8 - 2;
  uint64_t v10 = *(void *)(v7 + 64);
  if (v8 < 2)
  {
    unsigned int v9 = 0;
    if (v10 <= 3)
    {
      unsigned int v11 = (~(-1 << (8 * v10)) - v8 + 2) >> (8 * v10);
      if (v11 <= 0xFFFE)
      {
        uint64_t v12 = 2;
        if (v11 < 0xFF) {
          uint64_t v12 = v11 != 0;
        }
        goto LABEL_10;
      }
      uint64_t v20 = 4;
    }
    else
    {
      uint64_t v20 = 1;
    }
    uint64_t v12 = v20;
LABEL_10:
    v10 += v12;
  }
  BOOL v13 = a3 <= v9;
  unsigned int v14 = a3 - v9;
  if (v13) {
    goto LABEL_20;
  }
  if (v10 > 3)
  {
    int v21 = 1;
LABEL_19:
    unsigned int v5 = v21;
    goto LABEL_20;
  }
  unsigned int v15 = ((~(-1 << (8 * v10)) + v14) >> (8 * v10)) + 1;
  if (v15 > 0xFFFF)
  {
    int v21 = 4;
    goto LABEL_19;
  }
  unsigned int v5 = 2;
  if (v15 < 0x100) {
    unsigned int v5 = v15 >= 2;
  }
LABEL_20:
  if (v9 < a2)
  {
    unsigned int v16 = a2 + ~v9;
    if (v10 >= 4)
    {
      int v17 = 1;
      __bzero(a1, v10);
      *(_DWORD *)a1 = v16;
      uint64_t v18 = a1;
      uint64_t result = v5;
      switch(v5)
      {
        case 0u:
          return result;
        case 1u:
          goto LABEL_36;
        case 2u:
          goto LABEL_37;
        case 3u:
          goto LABEL_40;
        case 4u:
          goto LABEL_38;
      }
    }
    int v17 = (v16 >> (8 * v10)) + 1;
    if (v10)
    {
      int v19 = ~(-1 << (8 * v10)) & v16;
      __bzero(a1, v10);
      if (v10 != 3)
      {
        if (v10 == 2)
        {
          uint64_t v18 = a1;
          *(_WORD *)a1 = v19;
          uint64_t result = v5;
          switch(v5)
          {
            case 0u:
              return result;
            case 1u:
              goto LABEL_36;
            case 2u:
              goto LABEL_37;
            case 3u:
              goto LABEL_40;
            case 4u:
              goto LABEL_38;
          }
        }
        uint64_t v18 = a1;
        *(unsigned char *)a1 = v19;
        uint64_t result = v5;
        switch(v5)
        {
          case 0u:
            return result;
          case 1u:
            goto LABEL_36;
          case 2u:
            goto LABEL_37;
          case 3u:
            goto LABEL_40;
          case 4u:
            goto LABEL_38;
        }
      }
      uint64_t v18 = a1;
      *(_WORD *)a1 = v19;
      *(unsigned char *)(a1 + 2) = BYTE2(v19);
      uint64_t result = v5;
      switch(v5)
      {
        case 0u:
          return result;
        case 1u:
          goto LABEL_36;
        case 2u:
          goto LABEL_37;
        case 3u:
          goto LABEL_40;
        case 4u:
          goto LABEL_38;
      }
    }
    uint64_t result = v5;
    uint64_t v18 = a1;
    switch(v5)
    {
      case 0u:
        return result;
      case 1u:
LABEL_36:
        *(unsigned char *)(v18 + v10) = v17;
        return result;
      case 2u:
LABEL_37:
        *(_WORD *)(v18 + v10) = v17;
        return result;
      case 3u:
        goto LABEL_40;
      case 4u:
LABEL_38:
        *(_DWORD *)(v18 + v10) = v17;
        return result;
    }
  }
  switch(v5)
  {
    case 0u:
      break;
    case 1u:
      *(unsigned char *)(a1 + v10) = 0;
      break;
    case 2u:
      *(_WORD *)(a1 + v10) = 0;
      break;
    case 3u:
LABEL_40:
      BUG();
    case 4u:
      *(_DWORD *)(a1 + v10) = 0;
      break;
  }
  if (a2) {
    return __swift_storeEnumTagSinglePayload(a1, a2 + 2, v8, result);
  }
  return result;
}

uint64_t getEnumTag for InterspersedSequence.Iterator.State(uint64_t a1, uint64_t a2)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a2 + 24), *(void *)(a2 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  return __swift_getEnumTagSinglePayload(a1, 2, AssociatedTypeWitness);
}

uint64_t destructiveInjectEnumTag for InterspersedSequence.Iterator.State(uint64_t a1, unsigned int a2, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  return __swift_storeEnumTagSinglePayload(a1, a2, 2, AssociatedTypeWitness);
}

uint64_t type metadata completion function for InterspersedSequence<>.Index(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v4 = type metadata accessor for InterspersedSequence<>.Index.Representation(319, *(void *)(a1 + 16), *(void *)(a1 + 24), a4);
  if (v5 <= 0x3F)
  {
    v7[0] = *(void *)(v4 - 8) + 64;
    uint64_t v4 = 0;
    swift_initStructMetadata(a1, 0, 1, v7, a1 + 32);
  }
  return v4;
}

void *initializeBufferWithCopyOfBuffer for InterspersedSequence<>.Index(void *a1, unsigned __int8 *a2, uint64_t a3)
{
  return initializeBufferWithCopyOfBuffer for InterspersedSequence<>.Index(a1, a2, a3);
}

{
  void *v3;
  uint64_t AssociatedTypeWitness;
  uint64_t v5;
  int v6;
  int v7;
  uint64_t v8;
  unsigned int v9;
  uint64_t v10;
  int v11;
  uint64_t v12;

  unint64_t v3 = a1;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  unint64_t v5 = *(void *)(AssociatedTypeWitness - 8);
  int v6 = *(_DWORD *)(v5 + 80);
  uint64_t v7 = v6;
  if (v6 > 7u
    || (uint64_t v8 = *(void *)(v5 + 64), (unint64_t)(v8 + 1) > 0x18)
    || (v6 & 0x100000) != 0)
  {
    uint64_t v12 = *(void *)a2;
    void *v3 = *(void *)a2;
    swift_retain(v12);
    return (void *)(v12 + ((v7 + 16) & ~v7));
  }
  else
  {
    unsigned int v9 = a2[v8];
    if (v9 >= 2)
    {
      uint64_t v10 = 4;
      if (v8 < 4) {
        uint64_t v10 = v8;
      }
      switch(v10)
      {
        case 0:
          break;
        case 1:
          unsigned int v11 = *a2;
          goto LABEL_13;
        case 2:
          unsigned int v11 = *(unsigned __int16 *)a2;
          goto LABEL_13;
        case 3:
          unsigned int v11 = *(unsigned __int16 *)a2 | (a2[2] << 16);
          goto LABEL_13;
        case 4:
          unsigned int v11 = *(_DWORD *)a2;
LABEL_13:
          if (v8 < 4) {
            v11 |= (v9 - 2) << (8 * v8);
          }
          unsigned int v9 = v11 + 2;
          break;
        case 5:
          JUMPOUT(0x3285A4);
      }
    }
    (*(void (**)(void *, unsigned __int8 *, uint64_t))(v5 + 16))(a1, a2, AssociatedTypeWitness);
    *((unsigned char *)a1 + v8) = v9 == 1;
  }
  return v3;
}

uint64_t destroy for InterspersedSequence<>.Index(uint64_t a1, uint64_t a2)
{
  return destroy for InterspersedSequence<>.Index(a1, a2);
}

{
  uint64_t AssociatedTypeWitness;

  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a2 + 24), *(void *)(a2 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 8))(a1, AssociatedTypeWitness);
}

uint64_t initializeWithCopy for InterspersedSequence<>.Index(uint64_t a1, unsigned __int8 *a2, uint64_t a3)
{
  return initializeWithCopy for InterspersedSequence<>.Index(a1, a2, a3);
}

{
  uint64_t AssociatedTypeWitness;
  uint64_t v4;
  uint64_t v5;
  unsigned int v6;
  uint64_t v7;
  int v8;

  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v4 = *(void *)(AssociatedTypeWitness - 8);
  unint64_t v5 = *(void *)(v4 + 64);
  int v6 = a2[v5];
  if (v6 >= 2)
  {
    uint64_t v7 = 4;
    if (v5 < 4) {
      uint64_t v7 = v5;
    }
    switch(v7)
    {
      case 0:
        break;
      case 1:
        uint64_t v8 = *a2;
        goto LABEL_9;
      case 2:
        uint64_t v8 = *(unsigned __int16 *)a2;
        goto LABEL_9;
      case 3:
        uint64_t v8 = *(unsigned __int16 *)a2 | (a2[2] << 16);
        goto LABEL_9;
      case 4:
        uint64_t v8 = *(_DWORD *)a2;
LABEL_9:
        if (v5 < 4) {
          v8 |= (v6 - 2) << (8 * v5);
        }
        int v6 = v8 + 2;
        break;
      case 5:
        JUMPOUT(0x3286C8);
    }
  }
  (*(void (**)(uint64_t, unsigned __int8 *, uint64_t))(v4 + 16))(a1, a2, AssociatedTypeWitness);
  *(unsigned char *)(a1 + v5) = v6 == 1;
  return a1;
}

unsigned __int8 *assignWithCopy for InterspersedSequence<>.Index(unsigned __int8 *a1, unsigned __int8 *a2, uint64_t a3)
{
  return assignWithCopy for InterspersedSequence<>.Index(a1, a2, a3);
}

{
  uint64_t AssociatedTypeWitness;
  uint64_t v4;
  uint64_t v5;
  unsigned int v6;
  uint64_t v7;
  int v8;
  uint64_t v10;

  if (a1 != a2)
  {
    uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
    uint64_t v4 = *(void *)(AssociatedTypeWitness - 8);
    unint64_t v5 = *(void *)(v4 + 64);
    uint64_t v10 = v4;
    (*(void (**)(unsigned __int8 *, uint64_t))(v4 + 8))(a1, AssociatedTypeWitness);
    int v6 = a2[v5];
    if (v6 >= 2)
    {
      uint64_t v7 = 4;
      if (v5 < 4) {
        uint64_t v7 = v5;
      }
      switch(v7)
      {
        case 0:
          break;
        case 1:
          uint64_t v8 = *a2;
          goto LABEL_10;
        case 2:
          uint64_t v8 = *(unsigned __int16 *)a2;
          goto LABEL_10;
        case 3:
          uint64_t v8 = *(unsigned __int16 *)a2 | (a2[2] << 16);
          goto LABEL_10;
        case 4:
          uint64_t v8 = *(_DWORD *)a2;
LABEL_10:
          if (v5 < 4) {
            v8 |= (v6 - 2) << (8 * v5);
          }
          int v6 = v8 + 2;
          break;
        case 5:
          JUMPOUT(0x3287CCLL);
      }
    }
    (*(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v10 + 16))(a1, a2, AssociatedTypeWitness);
    a1[v5] = v6 == 1;
  }
  return a1;
}

uint64_t initializeWithTake for InterspersedSequence<>.Index(uint64_t a1, unsigned __int8 *a2, uint64_t a3)
{
  return initializeWithTake for InterspersedSequence<>.Index(a1, a2, a3);
}

{
  uint64_t AssociatedTypeWitness;
  uint64_t v4;
  uint64_t v5;
  unsigned int v6;
  uint64_t v7;
  int v8;

  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v4 = *(void *)(AssociatedTypeWitness - 8);
  unint64_t v5 = *(void *)(v4 + 64);
  int v6 = a2[v5];
  if (v6 >= 2)
  {
    uint64_t v7 = 4;
    if (v5 < 4) {
      uint64_t v7 = v5;
    }
    switch(v7)
    {
      case 0:
        break;
      case 1:
        uint64_t v8 = *a2;
        goto LABEL_9;
      case 2:
        uint64_t v8 = *(unsigned __int16 *)a2;
        goto LABEL_9;
      case 3:
        uint64_t v8 = *(unsigned __int16 *)a2 | (a2[2] << 16);
        goto LABEL_9;
      case 4:
        uint64_t v8 = *(_DWORD *)a2;
LABEL_9:
        if (v5 < 4) {
          v8 |= (v6 - 2) << (8 * v5);
        }
        int v6 = v8 + 2;
        break;
      case 5:
        JUMPOUT(0x3288A8);
    }
  }
  (*(void (**)(uint64_t, unsigned __int8 *, uint64_t))(v4 + 32))(a1, a2, AssociatedTypeWitness);
  *(unsigned char *)(a1 + v5) = v6 == 1;
  return a1;
}

unsigned __int8 *assignWithTake for InterspersedSequence<>.Index(unsigned __int8 *a1, unsigned __int8 *a2, uint64_t a3)
{
  return assignWithTake for InterspersedSequence<>.Index(a1, a2, a3);
}

{
  uint64_t AssociatedTypeWitness;
  uint64_t v4;
  uint64_t v5;
  unsigned int v6;
  uint64_t v7;
  int v8;
  uint64_t v10;

  if (a1 != a2)
  {
    uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
    uint64_t v4 = *(void *)(AssociatedTypeWitness - 8);
    unint64_t v5 = *(void *)(v4 + 64);
    uint64_t v10 = v4;
    (*(void (**)(unsigned __int8 *, uint64_t))(v4 + 8))(a1, AssociatedTypeWitness);
    int v6 = a2[v5];
    if (v6 >= 2)
    {
      uint64_t v7 = 4;
      if (v5 < 4) {
        uint64_t v7 = v5;
      }
      switch(v7)
      {
        case 0:
          break;
        case 1:
          uint64_t v8 = *a2;
          goto LABEL_10;
        case 2:
          uint64_t v8 = *(unsigned __int16 *)a2;
          goto LABEL_10;
        case 3:
          uint64_t v8 = *(unsigned __int16 *)a2 | (a2[2] << 16);
          goto LABEL_10;
        case 4:
          uint64_t v8 = *(_DWORD *)a2;
LABEL_10:
          if (v5 < 4) {
            v8 |= (v6 - 2) << (8 * v5);
          }
          int v6 = v8 + 2;
          break;
        case 5:
          JUMPOUT(0x3289ACLL);
      }
    }
    (*(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v10 + 32))(a1, a2, AssociatedTypeWitness);
    a1[v5] = v6 == 1;
  }
  return a1;
}

uint64_t getEnumTagSinglePayload for InterspersedSequence<>.Index(unsigned __int8 *a1, unsigned int a2, uint64_t a3)
{
  return getEnumTagSinglePayload for InterspersedSequence<>.Index(a1, a2, a3);
}

{
  unsigned int v4;
  uint64_t AssociatedTypeWitness;
  uint64_t v6;
  uint64_t v7;
  int v8;
  unsigned int v9;
  int v10;
  int v11;
  int v12;

  uint64_t v4 = 0;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  if (!a2) {
    return v4;
  }
  int v6 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  if (a2 < 0xFF) {
    goto LABEL_19;
  }
  uint64_t v7 = v6 + 1;
  if ((v6 + 1) > 3)
  {
LABEL_4:
    uint64_t v8 = a1[v7];
    goto LABEL_11;
  }
  unsigned int v9 = ((a2 + ~(-1 << (8 * v7)) - 254) >> (8 * v7)) + 1;
  if (v9 > 0xFFFF)
  {
    uint64_t v8 = *(_DWORD *)&a1[v7];
  }
  else
  {
    if (v9 <= 0xFF)
    {
      if (v9 < 2) {
        goto LABEL_19;
      }
      goto LABEL_4;
    }
    uint64_t v8 = *(unsigned __int16 *)&a1[v7];
  }
LABEL_11:
  if (v8)
  {
    uint64_t v10 = (v8 - 1) << (8 * v7);
    unsigned int v11 = 0;
    if (v7 >= 4) {
      uint64_t v10 = 0;
    }
    if (v6 != -1)
    {
      uint64_t v12 = 4;
      if (v7 < 4) {
        uint64_t v12 = v6 + 1;
      }
      switch(v12)
      {
        case 1:
          unsigned int v11 = *a1;
          break;
        case 2:
          unsigned int v11 = *(unsigned __int16 *)a1;
          break;
        case 3:
          unsigned int v11 = *(unsigned __int16 *)a1 | (a1[2] << 16);
          break;
        case 4:
          unsigned int v11 = *(_DWORD *)a1;
          break;
        case 5:
          JUMPOUT(0x328AF0);
      }
    }
    return (v10 | v11) + 255;
  }
LABEL_19:
  uint64_t v4 = 0;
  if (a1[v6] >= 2u) {
    return (a1[v6] ^ 0xFFu) + 1;
  }
  return v4;
}

uint64_t storeEnumTagSinglePayload for InterspersedSequence<>.Index(uint64_t a1, unsigned int a2, unsigned int a3, uint64_t a4)
{
  return storeEnumTagSinglePayload for InterspersedSequence<>.Index(a1, a2, a3, a4);
}

{
  unsigned int v6;
  uint64_t result;
  uint64_t v8;
  unsigned int v9;
  unsigned int v10;
  int v11;
  int v12;
  int v13;

  int v6 = 0;
  uint64_t result = *(void *)(*(void *)(swift_getAssociatedTypeWitness(0, *(void *)(a4 + 24), *(void *)(a4 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index)- 8)+ 64);
  uint64_t v8 = result + 1;
  if (a3 >= 0xFF)
  {
    if (v8 > 3)
    {
      BOOL v13 = 1;
LABEL_9:
      int v6 = v13;
      goto LABEL_10;
    }
    unsigned int v9 = ((a3 + ~(-1 << (8 * v8)) - 254) >> (8 * v8)) + 1;
    if (v9 > 0xFFFF)
    {
      BOOL v13 = 4;
      goto LABEL_9;
    }
    int v6 = 2;
    if (v9 < 0x100) {
      int v6 = v9 >= 2;
    }
  }
LABEL_10:
  if (a2 > 0xFE)
  {
    uint64_t v10 = a2 - 255;
    if (v8 >= 4)
    {
      unsigned int v11 = 1;
      __bzero(a1, result + 1);
      *(_DWORD *)a1 = v10;
      uint64_t result = v6;
      switch(v6)
      {
        case 0u:
          return result;
        case 1u:
          goto LABEL_26;
        case 2u:
          goto LABEL_28;
        case 3u:
          goto LABEL_30;
        case 4u:
          goto LABEL_27;
      }
    }
    unsigned int v11 = (v10 >> (8 * v8)) + 1;
    if (result != -1)
    {
      uint64_t v12 = ~(-1 << (8 * v8)) & v10;
      uint64_t result = __bzero(a1, result + 1);
      if (v8 != 3)
      {
        if (v8 == 2)
        {
          *(_WORD *)a1 = v12;
          switch(v6)
          {
            case 0u:
              return result;
            case 1u:
              goto LABEL_26;
            case 2u:
              goto LABEL_28;
            case 3u:
              goto LABEL_30;
            case 4u:
              goto LABEL_27;
          }
        }
        *(unsigned char *)a1 = v12;
        switch(v6)
        {
          case 0u:
            return result;
          case 1u:
            goto LABEL_26;
          case 2u:
            goto LABEL_28;
          case 3u:
            goto LABEL_30;
          case 4u:
            goto LABEL_27;
        }
      }
      *(_WORD *)a1 = v12;
      *(unsigned char *)(a1 + 2) = BYTE2(v12);
      switch(v6)
      {
        case 0u:
          return result;
        case 1u:
          goto LABEL_26;
        case 2u:
          goto LABEL_28;
        case 3u:
          goto LABEL_30;
        case 4u:
          goto LABEL_27;
      }
    }
    switch(v6)
    {
      case 0u:
        return result;
      case 1u:
LABEL_26:
        *(unsigned char *)(a1 + v8) = v11;
        break;
      case 2u:
LABEL_28:
        *(_WORD *)(a1 + v8) = v11;
        break;
      case 3u:
LABEL_30:
        BUG();
      case 4u:
LABEL_27:
        *(_DWORD *)(a1 + v8) = v11;
        break;
    }
  }
  else
  {
    switch(v6)
    {
      case 0u:
        goto LABEL_21;
      case 1u:
        *(unsigned char *)(a1 + v8) = 0;
        goto LABEL_21;
      case 2u:
        *(_WORD *)(a1 + v8) = 0;
        goto LABEL_21;
      case 3u:
        goto LABEL_30;
      case 4u:
        *(_DWORD *)(a1 + v8) = 0;
LABEL_21:
        if (a2) {
          *(unsigned char *)(a1 + result) = -(char)a2;
        }
        break;
    }
  }
  return result;
}

uint64_t type metadata completion function for InterspersedSequence<>.Index.Representation(uint64_t a1)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(319, *(void *)(a1 + 24), *(void *)(a1 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v4 = AssociatedTypeWitness;
  if (v5 <= 0x3F)
  {
    v7[0] = *(void *)(AssociatedTypeWitness - 8) + 64;
    v7[1] = v7[0];
    uint64_t v4 = 0;
    swift_initEnumMetadataMultiPayload(a1, 0, 2, v7, v2, v3);
  }
  return v4;
}

uint64_t getEnumTag for InterspersedSequence<>.Index.Representation(unsigned __int8 *a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(*(void *)(swift_getAssociatedTypeWitness(0, *(void *)(a2 + 24), *(void *)(a2 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index)- 8)+ 64);
  uint64_t result = a1[v2];
  if (result >= 2)
  {
    uint64_t v4 = 4;
    if (v2 < 4) {
      uint64_t v4 = v2;
    }
    switch(v4)
    {
      case 0:
        return result;
      case 1:
        int v5 = *a1;
        goto LABEL_9;
      case 2:
        int v5 = *(unsigned __int16 *)a1;
        goto LABEL_9;
      case 3:
        int v5 = *(unsigned __int16 *)a1 | (a1[2] << 16);
        goto LABEL_9;
      case 4:
        int v5 = *(_DWORD *)a1;
LABEL_9:
        if (v2 < 4) {
          v5 |= (result - 2) << (8 * v2);
        }
        uint64_t result = (v5 + 2);
        break;
      case 5:
        JUMPOUT(0x328D6CLL);
    }
  }
  return result;
}

uint64_t destructiveInjectEnumTag for InterspersedSequence<>.Index.Representation(uint64_t a1, unsigned int a2, uint64_t a3)
{
  uint64_t result = *(void *)(swift_getAssociatedTypeWitness(0, *(void *)(a3 + 24), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index)- 8);
  uint64_t v4 = *(void *)(result + 64);
  if (a2 > 1)
  {
    unsigned int v5 = a2 - 2;
    if (v4 < 4)
    {
      int v6 = v5 & ~(-1 << (8 * v4));
      *(unsigned char *)(a1 + v4) = (v5 >> (8 * v4)) + 2;
      uint64_t result = __bzero(a1, v4);
      if (v4 == 3)
      {
        *(_WORD *)a1 = v6;
        *(unsigned char *)(a1 + 2) = BYTE2(v6);
      }
      else if (v4 == 2)
      {
        *(_WORD *)a1 = v6;
      }
      else
      {
        *(unsigned char *)a1 = v6;
      }
    }
    else
    {
      *(unsigned char *)(a1 + v4) = 2;
      uint64_t result = __bzero(a1, v4);
      *(_DWORD *)a1 = v5;
    }
  }
  else
  {
    *(unsigned char *)(a1 + v4) = a2;
  }
  return result;
}

uint64_t type metadata instantiation function for InterspersedMapSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_allocateGenericValueMetadata(a1, a2, a3, 40);
}

uint64_t type metadata completion function for InterspersedMapSequence(uint64_t a1)
{
  uint64_t v1 = swift_checkMetadataState(319, *(void *)(a1 + 16));
  uint64_t v2 = v1;
  if (v3 <= 0x3F)
  {
    v5[0] = *(void *)(v1 - 8) + 64;
    v5[1] = (char *)&value witness table for () + 64;
    v5[2] = (char *)&value witness table for () + 64;
    uint64_t v2 = 0;
    swift_initStructMetadata(a1, 0, 3, v5, a1 + 40);
  }
  return v2;
}

uint64_t *initializeBufferWithCopyOfBuffer for InterspersedMapSequence(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  unint64_t v3 = a1;
  uint64_t v4 = *(void *)(*(void *)(a3 + 16) - 8);
  int v5 = *(_DWORD *)(v4 + 80);
  if ((v5 & 0x1000F8) != 0
    || (uint64_t v6 = *(void *)(v4 + 64), ((((v6 + 7) & 0xFFFFFFFFFFFFFFF8) + 23) & 0xFFFFFFFFFFFFFFF8) + 16 > 0x18))
  {
    uint64_t v11 = *a2;
    *a1 = *a2;
    unint64_t v3 = (uint64_t *)(v11 + (((v5 | 7) + 16) & ~(v5 | 7u)));
  }
  else
  {
    (*(void (**)(uint64_t *, uint64_t *))(v4 + 16))(a1, a2);
    uint64_t v7 = (_OWORD *)(((unint64_t)a1 + v6 + 7) & 0xFFFFFFFFFFFFFFF8);
    unint64_t v8 = ((unint64_t)a2 + v6 + 7) & 0xFFFFFFFFFFFFFFF8;
    uint64_t v9 = *(void *)(v8 + 8);
    *uint64_t v7 = *(_OWORD *)v8;
    unint64_t v10 = (v8 + 23) & 0xFFFFFFFFFFFFFFF8;
    uint64_t v11 = *(void *)(v10 + 8);
    *(_OWORD *)(((unint64_t)v7 + 23) & 0xFFFFFFFFFFFFFFF8) = *(_OWORD *)v10;
    swift_retain(v9);
  }
  swift_retain(v11);
  return v3;
}

uint64_t destroy for InterspersedMapSequence(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(*(void *)(a2 + 16) - 8);
  (*(void (**)(void))(v2 + 8))();
  unint64_t v3 = (*(void *)(v2 + 64) + a1 + 7) & 0xFFFFFFFFFFFFFFF8;
  swift_release(*(void *)(v3 + 8));
  return swift_release(*(void *)(((v3 + 23) & 0xFFFFFFFFFFFFFFF8) + 8));
}

uint64_t initializeWithCopy for InterspersedMapSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(*(void *)(a3 + 16) - 8);
  (*(void (**)(uint64_t))(v4 + 16))(a1);
  uint64_t v5 = *(void *)(v4 + 64);
  uint64_t v6 = (_OWORD *)((v5 + a1 + 7) & 0xFFFFFFFFFFFFFFF8);
  unint64_t v7 = (a2 + v5 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v8 = *(void *)(v7 + 8);
  *uint64_t v6 = *(_OWORD *)v7;
  unint64_t v9 = (v7 + 23) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v10 = *(void *)(v9 + 8);
  *(_OWORD *)(((unint64_t)v6 + 23) & 0xFFFFFFFFFFFFFFF8) = *(_OWORD *)v9;
  swift_retain(v8);
  swift_retain(v10);
  return a1;
}

uint64_t assignWithCopy for InterspersedMapSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(*(void *)(a3 + 16) - 8);
  (*(void (**)(void))(v4 + 24))();
  uint64_t v5 = *(void *)(v4 + 64);
  unint64_t v6 = (v5 + a1 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v7 = (v5 + a2 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v8 = *(void *)(v6 + 8);
  uint64_t v9 = *(void *)(v7 + 8);
  *(_OWORD *)unint64_t v6 = *(_OWORD *)v7;
  swift_retain(v9);
  swift_release(v8);
  unint64_t v10 = (v6 + 23) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v11 = (v7 + 23) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v12 = *(void *)(v10 + 8);
  uint64_t v13 = *(void *)(v11 + 8);
  *(_OWORD *)unint64_t v10 = *(_OWORD *)v11;
  swift_retain(v13);
  swift_release(v12);
  return a1;
}

uint64_t initializeWithTake for InterspersedMapSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(*(void *)(a3 + 16) - 8);
  (*(void (**)(uint64_t))(v3 + 32))(a1);
  uint64_t v4 = *(void *)(v3 + 64);
  uint64_t v5 = (_OWORD *)((v4 + a1 + 7) & 0xFFFFFFFFFFFFFFF8);
  unint64_t v6 = (_OWORD *)((a2 + v4 + 7) & 0xFFFFFFFFFFFFFFF8);
  *uint64_t v5 = *v6;
  *(_OWORD *)(((unint64_t)v5 + 23) & 0xFFFFFFFFFFFFFFF8) = *(_OWORD *)(((unint64_t)v6 + 23) & 0xFFFFFFFFFFFFFFF8);
  return a1;
}

uint64_t assignWithTake for InterspersedMapSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(*(void *)(a3 + 16) - 8);
  (*(void (**)(uint64_t))(v4 + 40))(a1);
  uint64_t v5 = *(void *)(v4 + 64);
  unint64_t v6 = (v5 + a1 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v7 = (_OWORD *)((v5 + a2 + 7) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v8 = *(void *)(v6 + 8);
  *(_OWORD *)unint64_t v6 = *v7;
  swift_release(v8);
  unint64_t v9 = (v6 + 23) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v10 = *(void *)(v9 + 8);
  *(_OWORD *)unint64_t v9 = *(_OWORD *)(((unint64_t)v7 + 23) & 0xFFFFFFFFFFFFFFF8);
  swift_release(v10);
  return a1;
}

uint64_t getEnumTagSinglePayload for InterspersedMapSequence(int *a1, unsigned int a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(a3 + 16);
  uint64_t v5 = *(void *)(v4 - 8);
  uint64_t v6 = *(unsigned int *)(v5 + 84);
  unsigned int v7 = 0x7FFFFFFF;
  if (v6 >= 0x80000000) {
    unsigned int v7 = *(_DWORD *)(v5 + 84);
  }
  if (!a2) {
    return 0;
  }
  uint64_t v8 = *(void *)(v5 + 64);
  if (v7 >= a2)
  {
LABEL_20:
    if (v6 < 0x7FFFFFFF)
    {
      LODWORD(v18) = -1;
      if (*(void *)(((unint64_t)a1 + v8 + 7) & 0xFFFFFFFFFFFFFFF8) < 0xFFFFFFFFuLL) {
        uint64_t v18 = *(void *)(((unint64_t)a1 + v8 + 7) & 0xFFFFFFFFFFFFFFF8);
      }
      return (v18 + 1);
    }
    else
    {
      return __swift_getEnumTagSinglePayload((uint64_t)a1, v6, v4);
    }
  }
  else
  {
    unint64_t v9 = ((((v8 + 7) & 0xFFFFFFFFFFFFFFF8) + 23) & 0xFFFFFFFFFFFFFFF8) + 16;
    int v10 = a2 - v7 + 1;
    unsigned int v11 = 2;
    if ((v9 & 0xFFFFFFF8) == 0) {
      unsigned int v11 = v10;
    }
    unsigned int v12 = 1;
    if (v11 >= 0x100) {
      unsigned int v12 = 2 * (v11 >= 0x10000) + 2;
    }
    uint64_t v13 = 0;
    if (v11 >= 2) {
      uint64_t v13 = v12;
    }
    switch(v13)
    {
      case 0:
        goto LABEL_20;
      case 1:
        int v14 = *((unsigned __int8 *)a1 + v9);
        goto LABEL_16;
      case 2:
        int v14 = *(unsigned __int16 *)((char *)a1 + v9);
        goto LABEL_16;
      case 3:
        BUG();
      case 4:
        int v14 = *(int *)((char *)a1 + v9);
LABEL_16:
        if (!v14) {
          goto LABEL_20;
        }
        int v16 = v14 - 1;
        int v17 = 0;
        if ((v9 & 0xFFFFFFF8) != 0)
        {
          int v16 = 0;
          int v17 = *a1;
        }
        uint64_t result = v7 + (v16 | v17) + 1;
        break;
    }
  }
  return result;
}

unint64_t storeEnumTagSinglePayload for InterspersedMapSequence(_DWORD *a1, uint64_t a2, unsigned int a3, uint64_t a4)
{
  uint64_t v6 = *(void *)(a4 + 16);
  uint64_t v7 = *(void *)(v6 - 8);
  uint64_t v8 = *(unsigned int *)(v7 + 84);
  unsigned int v9 = 0x7FFFFFFF;
  if (v8 >= 0x80000000) {
    unsigned int v9 = *(_DWORD *)(v7 + 84);
  }
  uint64_t v10 = *(void *)(v7 + 64);
  unint64_t v11 = ((((v10 + 7) & 0xFFFFFFFFFFFFFFF8) + 23) & 0xFFFFFFFFFFFFFFF8) + 16;
  unsigned int v12 = 0;
  int v13 = 1;
  if (v9 < a3)
  {
    int v14 = a3 - v9 + 1;
    unsigned int v15 = 2;
    if (((((v10 + 7) & 0xFFFFFFF8) + 23) & 0xFFFFFFF8) == 0xFFFFFFF0) {
      unsigned int v15 = v14;
    }
    int v16 = 2 * (v15 >= 0x10000) + 2;
    if (v15 < 0x100) {
      int v16 = 1;
    }
    unsigned int v12 = 0;
    if (v15 >= 2) {
      unsigned int v12 = v16;
    }
  }
  if (a2 > v9)
  {
    if (((((v10 + 7) & 0xFFFFFFF8) + 23) & 0xFFFFFFF8) == 0xFFFFFFF0)
    {
      int v13 = a2 - v9;
    }
    else
    {
      __bzero(a1, v11);
      *a1 = a2 + ~v9;
    }
    unint64_t result = v12;
    switch(v12)
    {
      case 0u:
        return result;
      case 1u:
        *((unsigned char *)a1 + v11) = v13;
        return result;
      case 2u:
        *(_WORD *)((char *)a1 + v11) = v13;
        return result;
      case 3u:
        goto LABEL_29;
      case 4u:
        *(_DWORD *)((char *)a1 + v11) = v13;
        return result;
    }
  }
  unint64_t result = v12;
  switch(v12)
  {
    case 0u:
      break;
    case 1u:
      *((unsigned char *)a1 + v11) = 0;
      break;
    case 2u:
      *(_WORD *)((char *)a1 + v11) = 0;
      break;
    case 3u:
LABEL_29:
      BUG();
    case 4u:
      *(_DWORD *)((char *)a1 + v11) = 0;
      break;
  }
  if (a2)
  {
    if (v8 < 0x7FFFFFFF)
    {
      unint64_t result = ((unint64_t)a1 + v10 + 7) & 0xFFFFFFFFFFFFFFF8;
      if ((int)a2 < 0)
      {
        *(void *)unint64_t result = a2 + 0x80000000;
        *(void *)(result + 8) = 0;
      }
      else
      {
        *(void *)unint64_t result = (a2 - 1);
      }
    }
    else
    {
      return __swift_storeEnumTagSinglePayload((uint64_t)a1, a2, v8, v6);
    }
  }
  return result;
}

uint64_t type metadata accessor for InterspersedMapSequence(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for InterspersedMapSequence);
}

uint64_t type metadata completion function for InterspersedMapSequence.Iterator(void *a1)
{
  uint64_t v1 = a1[2];
  uint64_t v2 = a1[4];
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(319, v2, v1, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v4 = AssociatedTypeWitness;
  if (v5 <= 0x3F)
  {
    v8[0] = *(void *)(AssociatedTypeWitness - 8) + 64;
    v8[1] = (char *)&value witness table for () + 64;
    v8[2] = (char *)&value witness table for () + 64;
    uint64_t v4 = type metadata accessor for InterspersedMapSequence.Iterator.State(319, v1, a1[3], v2);
    if (v6 <= 0x3F)
    {
      v8[3] = *(void *)(v4 - 8) + 64;
      uint64_t v4 = 0;
      swift_initStructMetadata(a1, 0, 4, v8, a1 + 5);
    }
  }
  return v4;
}

uint64_t *initializeBufferWithCopyOfBuffer for InterspersedMapSequence.Iterator(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 16);
  uint64_t v4 = *(void *)(a3 + 32);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v5 = *(void *)(AssociatedTypeWitness - 8);
  uint64_t v32 = *(void *)(v5 + 64);
  uint64_t v6 = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v7 = *(void *)(v6 - 8);
  int v8 = *(_DWORD *)(v7 + 80);
  uint64_t v9 = v8;
  unsigned int v10 = v8 | *(_DWORD *)(v5 + 80) & 0xF8;
  if (v10 > 7
    || ((v8 | *(_DWORD *)(v5 + 80)) & 0x100000) != 0
    || (unint64_t v11 = ~(unint64_t)v8,
        uint64_t v12 = *(void *)(v7 + 64),
        v12 + (~v9 & (v9 + ((((v32 + 7) & 0xFFFFFFFFFFFFFFF8) + 23) & 0xFFFFFFFFFFFFFFF8) + 16)) + 1 > 0x18))
  {
    uint64_t v23 = *a2;
    *a1 = *a2;
    swift_retain(v23);
    return (uint64_t *)(v23 + (((v10 | 7) + 16) & ~(v10 | 7)));
  }
  else
  {
    uint64_t v30 = v6;
    uint64_t v29 = *(void *)(v6 - 8);
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v5 + 16))(a1, a2, AssociatedTypeWitness);
    int v13 = (_OWORD *)(((unint64_t)a1 + v32 + 7) & 0xFFFFFFFFFFFFFFF8);
    unint64_t v14 = ((unint64_t)a2 + v32 + 7) & 0xFFFFFFFFFFFFFFF8;
    uint64_t v15 = *(void *)(v14 + 8);
    *int v13 = *(_OWORD *)v14;
    int v16 = (_OWORD *)(((unint64_t)v13 + 23) & 0xFFFFFFFFFFFFFFF8);
    unint64_t v17 = (v14 + 23) & 0xFFFFFFFFFFFFFFF8;
    uint64_t v18 = *(void *)(v17 + 8);
    *int v16 = *(_OWORD *)v17;
    uint64_t v33 = (uint64_t)v16 + v9 + 16;
    int v19 = (unsigned __int8 *)(v11 & (v17 + v9 + 16));
    unsigned int v20 = v19[v12];
    swift_retain(v15);
    swift_retain(v18);
    if (v20 < 2)
    {
LABEL_8:
      uint64_t v22 = v33;
    }
    else
    {
      uint64_t v21 = 4;
      if (v12 < 4) {
        uint64_t v21 = v12;
      }
      switch(v21)
      {
        case 0:
          goto LABEL_8;
        case 1:
          int v25 = *v19;
          break;
        case 2:
          int v25 = *(unsigned __int16 *)v19;
          break;
        case 3:
          int v25 = *(unsigned __int16 *)v19 | (v19[2] << 16);
          break;
        case 4:
          int v25 = *(_DWORD *)v19;
          break;
      }
      uint64_t v22 = v33;
      if (v12 < 4) {
        v25 |= (v20 - 2) << (8 * v12);
      }
      unsigned int v20 = v25 + 2;
    }
    unsigned int v26 = (unsigned char *)(v11 & v22);
    if (v20 == 1)
    {
      (*(void (**)(unsigned char *, unsigned __int8 *, uint64_t))(v29 + 16))(v26, v19, v30);
      v26[v12] = 1;
    }
    else if (v20)
    {
      memcpy(v26, v19, v12 + 1);
    }
    else
    {
      (*(void (**)(unsigned char *, unsigned __int8 *, uint64_t))(v29 + 16))(v26, v19, v30);
      v26[v12] = 0;
    }
    return a1;
  }
}

uint64_t destroy for InterspersedMapSequence.Iterator(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 16);
  uint64_t v3 = *(void *)(a2 + 32);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v3, v2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v5 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t))(v5 + 8))(a1, AssociatedTypeWitness);
  unint64_t v6 = (*(void *)(v5 + 64) + a1 + 7) & 0xFFFFFFFFFFFFFFF8;
  swift_release(*(void *)(v6 + 8));
  unint64_t v7 = (v6 + 23) & 0xFFFFFFFFFFFFFFF8;
  swift_release(*(void *)(v7 + 8));
  uint64_t result = swift_getAssociatedTypeWitness(0, v3, v2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v9 = *(void *)(result - 8);
  unsigned int v10 = (unsigned __int8 *)((v7 + *(unsigned __int8 *)(v9 + 80) + 16) & ~(unint64_t)*(unsigned __int8 *)(v9 + 80));
  uint64_t v11 = *(void *)(v9 + 64);
  unsigned int v12 = v10[v11];
  if (v12 >= 2)
  {
    uint64_t v13 = 4;
    if (v11 < 4) {
      uint64_t v13 = v11;
    }
    switch(v13)
    {
      case 0:
        break;
      case 1:
        int v14 = *v10;
        goto LABEL_9;
      case 2:
        int v14 = *(unsigned __int16 *)v10;
        goto LABEL_9;
      case 3:
        int v14 = *(unsigned __int16 *)v10 | (*((unsigned __int8 *)&dword_0
                                          + ((v7 + *(unsigned __int8 *)(v9 + 80) + 16) & ~(unint64_t)*(unsigned __int8 *)(v9 + 80))
                                          + 2) << 16);
        goto LABEL_9;
      case 4:
        int v14 = *(_DWORD *)v10;
LABEL_9:
        if (v11 < 4) {
          v14 |= (v12 - 2) << (8 * v11);
        }
        unsigned int v12 = v14 + 2;
        break;
    }
  }
  if (v12 <= 1) {
    return (*(uint64_t (**)(unsigned __int8 *, uint64_t))(v9 + 8))(v10, result);
  }
  return result;
}

uint64_t initializeWithCopy for InterspersedMapSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 16);
  uint64_t v4 = *(void *)(a3 + 32);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 16))(a1, a2, AssociatedTypeWitness);
  uint64_t v7 = *(void *)(v6 + 64);
  int v8 = (_OWORD *)((v7 + a1 + 7) & 0xFFFFFFFFFFFFFFF8);
  unint64_t v9 = (v7 + a2 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v25 = *(void *)(v9 + 8);
  _OWORD *v8 = *(_OWORD *)v9;
  unsigned int v10 = (_OWORD *)(((unint64_t)v8 + 23) & 0xFFFFFFFFFFFFFFF8);
  unint64_t v11 = (v9 + 23) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v26 = *(void *)(v11 + 8);
  _OWORD *v10 = *(_OWORD *)v11;
  uint64_t v27 = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v12 = *(void *)(v27 - 8);
  uint64_t v13 = *(unsigned __int8 *)(v12 + 80);
  uint64_t v24 = (uint64_t)v10 + v13 + 16;
  uint64_t v14 = v13 + v11 + 16;
  uint64_t v15 = v12;
  uint64_t v16 = ~v13;
  unint64_t v17 = (unsigned __int8 *)(v16 & v14);
  uint64_t v18 = *(void *)(v12 + 64);
  unsigned int v19 = v17[v18];
  swift_retain(v25);
  swift_retain(v26);
  if (v19 >= 2)
  {
    uint64_t v20 = 4;
    if (v18 < 4) {
      uint64_t v20 = v18;
    }
    switch(v20)
    {
      case 0:
        break;
      case 1:
        int v21 = *v17;
        goto LABEL_9;
      case 2:
        int v21 = *(unsigned __int16 *)v17;
        goto LABEL_9;
      case 3:
        int v21 = *(unsigned __int16 *)v17 | (v17[2] << 16);
        goto LABEL_9;
      case 4:
        int v21 = *(_DWORD *)v17;
LABEL_9:
        if (v18 < 4) {
          v21 |= (v19 - 2) << (8 * v18);
        }
        unsigned int v19 = v21 + 2;
        break;
    }
  }
  uint64_t v22 = (unsigned char *)(v16 & v24);
  if (v19 == 1)
  {
    (*(void (**)(unsigned char *, unsigned __int8 *, uint64_t))(v15 + 16))(v22, v17, v27);
    v22[v18] = 1;
  }
  else if (v19)
  {
    memcpy(v22, v17, v18 + 1);
  }
  else
  {
    (*(void (**)(unsigned char *, unsigned __int8 *, uint64_t))(v15 + 16))(v22, v17, v27);
    v22[v18] = 0;
  }
  return a1;
}

uint64_t assignWithCopy for InterspersedMapSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 16);
  uint64_t v4 = *(void *)(a3 + 32);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 24))(a1, a2, AssociatedTypeWitness);
  uint64_t v7 = *(void *)(v6 + 64);
  unint64_t v8 = (v7 + a1 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v9 = (v7 + a2 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v10 = *(void *)(v8 + 8);
  uint64_t v11 = *(void *)(v9 + 8);
  *(_OWORD *)unint64_t v8 = *(_OWORD *)v9;
  swift_retain(v11);
  swift_release(v10);
  unint64_t v12 = (v8 + 23) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v13 = (v9 + 23) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v14 = *(void *)(v12 + 8);
  uint64_t v15 = *(void *)(v13 + 8);
  *(_OWORD *)unint64_t v12 = *(_OWORD *)v13;
  swift_retain(v15);
  swift_release(v14);
  uint64_t v16 = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v17 = *(void *)(v16 - 8);
  uint64_t v18 = *(unsigned __int8 *)(v17 + 80);
  uint64_t v19 = v18 + v12 + 16;
  uint64_t v20 = v18 + v13 + 16;
  uint64_t v21 = ~v18;
  uint64_t v22 = (unsigned __int8 *)(v21 & v19);
  uint64_t v23 = (unsigned __int8 *)(v20 & v21);
  if (v22 != v23)
  {
    uint64_t v24 = *(void *)(v17 + 64);
    unsigned int v25 = v22[v24];
    uint64_t v26 = 4;
    if (v25 >= 2)
    {
      uint64_t v27 = v24;
      if (v24 >= 4) {
        uint64_t v27 = 4;
      }
      switch(v27)
      {
        case 0:
          break;
        case 1:
          int v28 = *v22;
          goto LABEL_10;
        case 2:
          int v28 = *(unsigned __int16 *)v22;
          goto LABEL_10;
        case 3:
          int v28 = *(unsigned __int16 *)v22 | (v22[2] << 16);
          goto LABEL_10;
        case 4:
          int v28 = *(_DWORD *)v22;
LABEL_10:
          if (v24 < 4) {
            v28 |= (v25 - 2) << (8 * v24);
          }
          unsigned int v25 = v28 + 2;
          break;
      }
    }
    if (v25 <= 1)
    {
      uint64_t v29 = *(void *)(v16 - 8);
      uint64_t v30 = v16;
      (*(void (**)(unsigned __int8 *, uint64_t))(v17 + 8))(v22, v16);
      uint64_t v26 = 4;
      uint64_t v16 = v30;
      uint64_t v17 = v29;
    }
    unsigned int v31 = v23[v24];
    if (v31 >= 2)
    {
      if (v24 < 4) {
        uint64_t v26 = v24;
      }
      switch(v26)
      {
        case 0:
          break;
        case 1:
          int v32 = *v23;
          goto LABEL_23;
        case 2:
          int v32 = *(unsigned __int16 *)v23;
          goto LABEL_23;
        case 3:
          int v32 = *(unsigned __int16 *)v23 | (v23[2] << 16);
          goto LABEL_23;
        case 4:
          int v32 = *(_DWORD *)v23;
LABEL_23:
          if (v24 < 4) {
            v32 |= (v31 - 2) << (8 * v24);
          }
          unsigned int v31 = v32 + 2;
          break;
      }
    }
    if (v31 == 1)
    {
      (*(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v17 + 16))(v22, v23, v16);
      v22[v24] = 1;
    }
    else if (v31)
    {
      memcpy(v22, v23, v24 + 1);
    }
    else
    {
      (*(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v17 + 16))(v22, v23, v16);
      v22[v24] = 0;
    }
  }
  return a1;
}

uint64_t initializeWithTake for InterspersedMapSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 16);
  uint64_t v4 = *(void *)(a3 + 32);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 32))(a1, a2, AssociatedTypeWitness);
  uint64_t v7 = *(void *)(v6 + 64);
  unint64_t v8 = (_OWORD *)((v7 + a1 + 7) & 0xFFFFFFFFFFFFFFF8);
  unint64_t v9 = (_OWORD *)((v7 + a2 + 7) & 0xFFFFFFFFFFFFFFF8);
  _OWORD *v8 = *v9;
  uint64_t v10 = (_OWORD *)(((unint64_t)v8 + 23) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v11 = (_OWORD *)(((unint64_t)v9 + 23) & 0xFFFFFFFFFFFFFFF8);
  _OWORD *v10 = *v11;
  uint64_t v12 = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v13 = *(void *)(v12 - 8);
  uint64_t v14 = *(unsigned __int8 *)(v13 + 80);
  uint64_t v15 = (uint64_t)v10 + v14 + 16;
  uint64_t v16 = (uint64_t)v11 + v14 + 16;
  uint64_t v17 = ~v14;
  uint64_t v18 = (unsigned __int8 *)(v17 & v16);
  uint64_t v19 = *(void *)(v13 + 64);
  unsigned int v20 = v18[v19];
  if (v20 >= 2)
  {
    uint64_t v21 = 4;
    if (v19 < 4) {
      uint64_t v21 = v19;
    }
    switch(v21)
    {
      case 0:
        break;
      case 1:
        int v22 = *v18;
        goto LABEL_9;
      case 2:
        int v22 = *(unsigned __int16 *)v18;
        goto LABEL_9;
      case 3:
        int v22 = *(unsigned __int16 *)v18 | (v18[2] << 16);
        goto LABEL_9;
      case 4:
        int v22 = *(_DWORD *)v18;
LABEL_9:
        if (v19 < 4) {
          v22 |= (v20 - 2) << (8 * v19);
        }
        unsigned int v20 = v22 + 2;
        break;
    }
  }
  uint64_t v23 = (unsigned char *)(v17 & v15);
  if (v20 == 1)
  {
    (*(void (**)(unsigned char *, unsigned __int8 *, uint64_t))(v13 + 32))(v23, v18, v12);
    v23[v19] = 1;
  }
  else if (v20)
  {
    memcpy(v23, v18, v19 + 1);
  }
  else
  {
    (*(void (**)(unsigned char *, unsigned __int8 *, uint64_t))(v13 + 32))(v23, v18, v12);
    v23[v19] = 0;
  }
  return a1;
}

uint64_t assignWithTake for InterspersedMapSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 16);
  uint64_t v4 = *(void *)(a3 + 32);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 40))(a1, a2, AssociatedTypeWitness);
  uint64_t v7 = *(void *)(v6 + 64);
  unint64_t v8 = (v7 + a1 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v9 = (_OWORD *)((v7 + a2 + 7) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v10 = *(void *)(v8 + 8);
  *(_OWORD *)unint64_t v8 = *v9;
  swift_release(v10);
  unint64_t v11 = (v8 + 23) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v12 = (_OWORD *)(((unint64_t)v9 + 23) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v13 = *(void *)(v11 + 8);
  *(_OWORD *)unint64_t v11 = *v12;
  swift_release(v13);
  uint64_t v14 = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v15 = *(void *)(v14 - 8);
  uint64_t v16 = *(unsigned __int8 *)(v15 + 80);
  uint64_t v17 = v16 + v11 + 16;
  uint64_t v18 = (uint64_t)v12 + v16 + 16;
  uint64_t v19 = ~v16;
  unsigned int v20 = (unsigned __int8 *)(v19 & v17);
  uint64_t v21 = (unsigned __int8 *)(v18 & v19);
  if (v20 != v21)
  {
    uint64_t v22 = *(void *)(v15 + 64);
    unsigned int v23 = v20[v22];
    uint64_t v24 = 4;
    if (v23 >= 2)
    {
      uint64_t v25 = v22;
      if (v22 >= 4) {
        uint64_t v25 = 4;
      }
      switch(v25)
      {
        case 0:
          break;
        case 1:
          int v26 = *v20;
          goto LABEL_10;
        case 2:
          int v26 = *(unsigned __int16 *)v20;
          goto LABEL_10;
        case 3:
          int v26 = *(unsigned __int16 *)v20 | (v20[2] << 16);
          goto LABEL_10;
        case 4:
          int v26 = *(_DWORD *)v20;
LABEL_10:
          if (v22 < 4) {
            v26 |= (v23 - 2) << (8 * v22);
          }
          unsigned int v23 = v26 + 2;
          break;
      }
    }
    if (v23 <= 1)
    {
      uint64_t v27 = v14;
      uint64_t v28 = *(void *)(v14 - 8);
      (*(void (**)(unsigned __int8 *, uint64_t))(v15 + 8))(v20, v14);
      uint64_t v24 = 4;
      uint64_t v15 = v28;
      uint64_t v14 = v27;
    }
    unsigned int v29 = v21[v22];
    if (v29 >= 2)
    {
      if (v22 < 4) {
        uint64_t v24 = v22;
      }
      switch(v24)
      {
        case 0:
          break;
        case 1:
          int v30 = *v21;
          goto LABEL_23;
        case 2:
          int v30 = *(unsigned __int16 *)v21;
          goto LABEL_23;
        case 3:
          int v30 = *(unsigned __int16 *)v21 | (v21[2] << 16);
          goto LABEL_23;
        case 4:
          int v30 = *(_DWORD *)v21;
LABEL_23:
          if (v22 < 4) {
            v30 |= (v29 - 2) << (8 * v22);
          }
          unsigned int v29 = v30 + 2;
          break;
      }
    }
    if (v29 == 1)
    {
      (*(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v15 + 32))(v20, v21, v14);
      v20[v22] = 1;
    }
    else if (v29)
    {
      memcpy(v20, v21, v22 + 1);
    }
    else
    {
      (*(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v15 + 32))(v20, v21, v14);
      v20[v22] = 0;
    }
  }
  return a1;
}

uint64_t getEnumTagSinglePayload for InterspersedMapSequence.Iterator(unsigned __int8 *a1, unsigned int a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(a3 + 16);
  uint64_t v4 = *(void *)(a3 + 32);
  unsigned int v5 = 0;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  unsigned int v7 = 0x7FFFFFFF;
  unsigned int v19 = *(_DWORD *)(v6 + 84);
  if (v19 >= 0x80000000) {
    unsigned int v7 = *(_DWORD *)(v6 + 84);
  }
  uint64_t v8 = swift_getAssociatedTypeWitness(0, v4, v3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  if (!a2) {
    return v5;
  }
  uint64_t v9 = *(void *)(v6 + 64);
  if (a2 <= v7) {
    goto LABEL_21;
  }
  unint64_t v10 = *(void *)(*(void *)(v8 - 8) + 64)
      + ((*(unsigned __int8 *)(*(void *)(v8 - 8) + 80)
        + ((((v9 + 7) & 0xFFFFFFFFFFFFFFF8) + 23) & 0xFFFFFFFFFFFFFFF8)
        + 16) & ~(unint64_t)*(unsigned __int8 *)(*(void *)(v8 - 8) + 80))
      + 1;
  if (v10 > 3)
  {
LABEL_6:
    int v11 = a1[v10];
    goto LABEL_13;
  }
  unsigned int v12 = ((~(-1 << (8 * v10)) + a2 - v7) >> (8 * v10)) + 1;
  if (v12 > 0xFFFF)
  {
    int v11 = *(_DWORD *)&a1[v10];
  }
  else
  {
    if (v12 <= 0xFF)
    {
      if (v12 < 2) {
        goto LABEL_21;
      }
      goto LABEL_6;
    }
    int v11 = *(unsigned __int16 *)&a1[v10];
  }
LABEL_13:
  if (v11)
  {
    int v13 = (v11 - 1) << (8 * v10);
    int v14 = 0;
    if (v10 >= 4) {
      int v13 = 0;
    }
    if (v10)
    {
      int v15 = 4;
      if (v10 < 4) {
        int v15 = v10;
      }
      switch(v15)
      {
        case 1:
          int v14 = *a1;
          break;
        case 2:
          int v14 = *(unsigned __int16 *)a1;
          break;
        case 3:
          int v14 = *(unsigned __int16 *)a1 | (a1[2] << 16);
          break;
        case 4:
          int v14 = *(_DWORD *)a1;
          break;
      }
    }
    return v7 + (v13 | v14) + 1;
  }
LABEL_21:
  if (v19 >= 0x7FFFFFFF) {
    return __swift_getEnumTagSinglePayload((uint64_t)a1, v19, AssociatedTypeWitness);
  }
  LODWORD(v17) = -1;
  if (*(void *)((unint64_t)&a1[v9 + 7] & 0xFFFFFFFFFFFFFFF8) < 0xFFFFFFFFuLL) {
    uint64_t v17 = *(void *)((unint64_t)&a1[v9 + 7] & 0xFFFFFFFFFFFFFFF8);
  }
  return (v17 + 1);
}

unint64_t storeEnumTagSinglePayload for InterspersedMapSequence.Iterator(uint64_t a1, uint64_t a2, unsigned int a3, uint64_t a4)
{
  uint64_t v5 = *(void *)(a4 + 16);
  uint64_t v6 = *(void *)(a4 + 32);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v6, v5, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v7 = *(void *)(AssociatedTypeWitness - 8);
  unsigned int v8 = 0x7FFFFFFF;
  uint64_t v22 = *(unsigned int *)(v7 + 84);
  if (*(_DWORD *)(v7 + 84) >= 0x80000000) {
    unsigned int v8 = *(_DWORD *)(v7 + 84);
  }
  uint64_t v9 = *(void *)(swift_getAssociatedTypeWitness(0, v6, v5, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element)- 8);
  unint64_t result = *(void *)(v7 + 64);
  unint64_t v11 = *(void *)(v9 + 64)
      + ((*(unsigned __int8 *)(v9 + 80) + ((((result + 7) & 0xFFFFFFFFFFFFFFF8) + 23) & 0xFFFFFFFFFFFFFFF8) + 16) & ~(unint64_t)*(unsigned __int8 *)(v9 + 80))
      + 1;
  BOOL v12 = a3 <= v8;
  unsigned int v13 = a3 - v8;
  if (!v12)
  {
    if (v11 > 3)
    {
      int v19 = 1;
LABEL_11:
      HIDWORD(v22) = v19;
      goto LABEL_12;
    }
    unsigned int v14 = ((~(-1 << (8 * v11)) + v13) >> (8 * v11)) + 1;
    if (v14 > 0xFFFF)
    {
      int v19 = 4;
      goto LABEL_11;
    }
    int v15 = 2;
    if (v14 < 0x100) {
      int v15 = v14 >= 2;
    }
    HIDWORD(v22) = v15;
  }
LABEL_12:
  if (v8 < a2)
  {
    unsigned int v16 = a2 + ~v8;
    if (v11 >= 4)
    {
      int v17 = 1;
      __bzero(a1, v11);
      *(_DWORD *)a1 = v16;
      unint64_t result = HIDWORD(v22);
      switch(HIDWORD(v22))
      {
        case 0:
          return result;
        case 1:
          goto LABEL_32;
        case 2:
          goto LABEL_33;
        case 3:
          goto LABEL_36;
        case 4:
          goto LABEL_34;
      }
    }
    int v17 = (v16 >> (8 * v11)) + 1;
    if (*(_DWORD *)(v9 + 64)
       + ((*(unsigned __int8 *)(v9 + 80) + ((((result + 7) & 0xFFFFFFF8) + 23) & 0xFFFFFFF8) + 16) & ~*(unsigned __int8 *)(v9 + 80)) != -1)
    {
      int v18 = ~(-1 << (8 * v11)) & v16;
      __bzero(a1, v11);
      if (v11 != 3)
      {
        if (v11 == 2)
        {
          *(_WORD *)a1 = v18;
          unint64_t result = HIDWORD(v22);
          switch(HIDWORD(v22))
          {
            case 0:
              return result;
            case 1:
              goto LABEL_32;
            case 2:
              goto LABEL_33;
            case 3:
              goto LABEL_36;
            case 4:
              goto LABEL_34;
          }
        }
        *(unsigned char *)a1 = v18;
        unint64_t result = HIDWORD(v22);
        switch(HIDWORD(v22))
        {
          case 0:
            return result;
          case 1:
            goto LABEL_32;
          case 2:
            goto LABEL_33;
          case 3:
            goto LABEL_36;
          case 4:
            goto LABEL_34;
        }
      }
      *(_WORD *)a1 = v18;
      *(unsigned char *)(a1 + 2) = BYTE2(v18);
      unint64_t result = HIDWORD(v22);
      switch(HIDWORD(v22))
      {
        case 0:
          return result;
        case 1:
          goto LABEL_32;
        case 2:
          goto LABEL_33;
        case 3:
          goto LABEL_36;
        case 4:
          goto LABEL_34;
      }
    }
    unint64_t result = HIDWORD(v22);
    switch(HIDWORD(v22))
    {
      case 0:
        return result;
      case 1:
LABEL_32:
        *(unsigned char *)(a1 + v11) = v17;
        return result;
      case 2:
LABEL_33:
        *(_WORD *)(a1 + v11) = v17;
        return result;
      case 3:
        goto LABEL_36;
      case 4:
LABEL_34:
        *(_DWORD *)(a1 + v11) = v17;
        return result;
    }
  }
  switch(HIDWORD(v22))
  {
    case 0:
      break;
    case 1:
      *(unsigned char *)(a1 + v11) = 0;
      break;
    case 2:
      *(_WORD *)(a1 + v11) = 0;
      break;
    case 3:
LABEL_36:
      BUG();
    case 4:
      *(_DWORD *)(a1 + v11) = 0;
      break;
  }
  if (a2)
  {
    if (v22 < 0x7FFFFFFF)
    {
      unint64_t result = (a1 + result + 7) & 0xFFFFFFFFFFFFFFF8;
      if ((int)a2 < 0)
      {
        *(void *)unint64_t result = a2 + 0x80000000;
        *(void *)(result + 8) = 0;
      }
      else
      {
        *(void *)unint64_t result = (a2 - 1);
      }
    }
    else
    {
      return __swift_storeEnumTagSinglePayload(a1, a2, v22, AssociatedTypeWitness);
    }
  }
  return result;
}

uint64_t type metadata completion function for InterspersedMapSequence.Iterator.State(uint64_t a1)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(319, *(void *)(a1 + 32), *(void *)(a1 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v4 = AssociatedTypeWitness;
  if (v5 <= 0x3F)
  {
    v7[0] = *(void *)(AssociatedTypeWitness - 8) + 64;
    v7[1] = v7[0];
    uint64_t v4 = 0;
    swift_initEnumMetadataMultiPayload(a1, 0, 2, v7, v2, v3);
  }
  return v4;
}

unsigned char *initializeBufferWithCopyOfBuffer for InterspersedMapSequence.Iterator.State(unsigned char *__dst, unsigned __int8 *__src, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
  int v7 = *(_DWORD *)(v6 + 80);
  int v8 = v7;
  if (v7 > 7u
    || (uint64_t v9 = *(void *)(v6 + 64), (unint64_t)(v9 + 1) > 0x18)
    || (v7 & 0x100000) != 0)
  {
    uint64_t v13 = *(void *)__src;
    *(void *)__dst = *(void *)__src;
    swift_retain(v13);
    return (unsigned char *)(v13 + ((v8 + 16) & ~v8));
  }
  else
  {
    unsigned int v10 = __src[v9];
    if (v10 >= 2)
    {
      uint64_t v11 = 4;
      if (v9 < 4) {
        uint64_t v11 = v9;
      }
      switch(v11)
      {
        case 0:
          break;
        case 1:
          int v12 = *__src;
          goto LABEL_13;
        case 2:
          int v12 = *(unsigned __int16 *)__src;
          goto LABEL_13;
        case 3:
          int v12 = *(unsigned __int16 *)__src | (__src[2] << 16);
          goto LABEL_13;
        case 4:
          int v12 = *(_DWORD *)__src;
LABEL_13:
          if (v9 < 4) {
            v12 |= (v10 - 2) << (8 * v9);
          }
          unsigned int v10 = v12 + 2;
          break;
      }
    }
    if (v10 == 1)
    {
      (*(void (**)(unsigned char *, unsigned __int8 *, uint64_t))(v6 + 16))(__dst, __src, AssociatedTypeWitness);
      __dst[v9] = 1;
    }
    else if (v10)
    {
      memcpy(__dst, __src, v9 + 1);
    }
    else
    {
      (*(void (**)(unsigned char *, unsigned __int8 *, uint64_t))(v6 + 16))(__dst, __src, AssociatedTypeWitness);
      __dst[v9] = 0;
    }
  }
  return __dst;
}

uint64_t destroy for InterspersedMapSequence.Iterator.State(unsigned __int8 *a1, uint64_t a2)
{
  uint64_t result = swift_getAssociatedTypeWitness(0, *(void *)(a2 + 32), *(void *)(a2 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v4 = *(void *)(result - 8);
  uint64_t v5 = *(void *)(v4 + 64);
  unsigned int v6 = a1[v5];
  if (v6 >= 2)
  {
    uint64_t v7 = 4;
    if (v5 < 4) {
      uint64_t v7 = v5;
    }
    switch(v7)
    {
      case 0:
        break;
      case 1:
        int v8 = *a1;
        goto LABEL_9;
      case 2:
        int v8 = *(unsigned __int16 *)a1;
        goto LABEL_9;
      case 3:
        int v8 = *(unsigned __int16 *)a1 | (a1[2] << 16);
        goto LABEL_9;
      case 4:
        int v8 = *(_DWORD *)a1;
LABEL_9:
        if (v5 < 4) {
          v8 |= (v6 - 2) << (8 * v5);
        }
        unsigned int v6 = v8 + 2;
        break;
    }
  }
  if (v6 <= 1) {
    return (*(uint64_t (**)(unsigned __int8 *, uint64_t))(v4 + 8))(a1, result);
  }
  return result;
}

unsigned char *initializeWithCopy for InterspersedMapSequence.Iterator.State(unsigned char *__dst, unsigned __int8 *__src, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v5 = *(void *)(AssociatedTypeWitness - 8);
  uint64_t v6 = *(void *)(v5 + 64);
  unsigned int v7 = __src[v6];
  if (v7 >= 2)
  {
    uint64_t v8 = 4;
    if (v6 < 4) {
      uint64_t v8 = v6;
    }
    switch(v8)
    {
      case 0:
        break;
      case 1:
        int v9 = *__src;
        goto LABEL_9;
      case 2:
        int v9 = *(unsigned __int16 *)__src;
        goto LABEL_9;
      case 3:
        int v9 = *(unsigned __int16 *)__src | (__src[2] << 16);
        goto LABEL_9;
      case 4:
        int v9 = *(_DWORD *)__src;
LABEL_9:
        if (v6 < 4) {
          v9 |= (v7 - 2) << (8 * v6);
        }
        unsigned int v7 = v9 + 2;
        break;
    }
  }
  if (v7 == 1)
  {
    (*(void (**)(unsigned char *, unsigned __int8 *, uint64_t))(v5 + 16))(__dst, __src, AssociatedTypeWitness);
    __dst[v6] = 1;
  }
  else if (v7)
  {
    memcpy(__dst, __src, v6 + 1);
  }
  else
  {
    (*(void (**)(unsigned char *, unsigned __int8 *, uint64_t))(v5 + 16))(__dst, __src, AssociatedTypeWitness);
    __dst[v6] = 0;
  }
  return __dst;
}

unsigned __int8 *assignWithCopy for InterspersedMapSequence.Iterator.State(unsigned __int8 *__dst, unsigned __int8 *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
    uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
    uint64_t v7 = *(void *)(v6 + 64);
    unsigned int v8 = __dst[v7];
    uint64_t v9 = 4;
    if (v8 >= 2)
    {
      uint64_t v10 = v7;
      if (v7 >= 4) {
        uint64_t v10 = 4;
      }
      switch(v10)
      {
        case 0:
          break;
        case 1:
          int v11 = *__dst;
          goto LABEL_10;
        case 2:
          int v11 = *(unsigned __int16 *)__dst;
          goto LABEL_10;
        case 3:
          int v11 = *(unsigned __int16 *)__dst | (__dst[2] << 16);
          goto LABEL_10;
        case 4:
          int v11 = *(_DWORD *)__dst;
LABEL_10:
          if (v7 < 4) {
            v11 |= (v8 - 2) << (8 * v7);
          }
          unsigned int v8 = v11 + 2;
          break;
      }
    }
    if (v8 <= 1)
    {
      uint64_t v12 = AssociatedTypeWitness;
      (*(void (**)(unsigned __int8 *, uint64_t))(v6 + 8))(__dst, AssociatedTypeWitness);
      uint64_t v9 = 4;
      uint64_t AssociatedTypeWitness = v12;
    }
    unsigned int v13 = __src[v7];
    if (v13 >= 2)
    {
      if (v7 < 4) {
        uint64_t v9 = v7;
      }
      switch(v9)
      {
        case 0:
          break;
        case 1:
          int v14 = *__src;
          goto LABEL_23;
        case 2:
          int v14 = *(unsigned __int16 *)__src;
          goto LABEL_23;
        case 3:
          int v14 = *(unsigned __int16 *)__src | (__src[2] << 16);
          goto LABEL_23;
        case 4:
          int v14 = *(_DWORD *)__src;
LABEL_23:
          if (v7 < 4) {
            v14 |= (v13 - 2) << (8 * v7);
          }
          unsigned int v13 = v14 + 2;
          break;
      }
    }
    if (v13 == 1)
    {
      (*(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v6 + 16))(__dst, __src, AssociatedTypeWitness);
      __dst[v7] = 1;
    }
    else if (v13)
    {
      memcpy(__dst, __src, v7 + 1);
    }
    else
    {
      (*(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v6 + 16))(__dst, __src, AssociatedTypeWitness);
      __dst[v7] = 0;
    }
  }
  return __dst;
}

unsigned char *initializeWithTake for InterspersedMapSequence.Iterator.State(unsigned char *__dst, unsigned __int8 *__src, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v5 = *(void *)(AssociatedTypeWitness - 8);
  uint64_t v6 = *(void *)(v5 + 64);
  unsigned int v7 = __src[v6];
  if (v7 >= 2)
  {
    uint64_t v8 = 4;
    if (v6 < 4) {
      uint64_t v8 = v6;
    }
    switch(v8)
    {
      case 0:
        break;
      case 1:
        int v9 = *__src;
        goto LABEL_9;
      case 2:
        int v9 = *(unsigned __int16 *)__src;
        goto LABEL_9;
      case 3:
        int v9 = *(unsigned __int16 *)__src | (__src[2] << 16);
        goto LABEL_9;
      case 4:
        int v9 = *(_DWORD *)__src;
LABEL_9:
        if (v6 < 4) {
          v9 |= (v7 - 2) << (8 * v6);
        }
        unsigned int v7 = v9 + 2;
        break;
    }
  }
  if (v7 == 1)
  {
    (*(void (**)(unsigned char *, unsigned __int8 *, uint64_t))(v5 + 32))(__dst, __src, AssociatedTypeWitness);
    __dst[v6] = 1;
  }
  else if (v7)
  {
    memcpy(__dst, __src, v6 + 1);
  }
  else
  {
    (*(void (**)(unsigned char *, unsigned __int8 *, uint64_t))(v5 + 32))(__dst, __src, AssociatedTypeWitness);
    __dst[v6] = 0;
  }
  return __dst;
}

unsigned __int8 *assignWithTake for InterspersedMapSequence.Iterator.State(unsigned __int8 *__dst, unsigned __int8 *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
    uint64_t v6 = *(void *)(AssociatedTypeWitness - 8);
    uint64_t v7 = *(void *)(v6 + 64);
    unsigned int v8 = __dst[v7];
    uint64_t v9 = 4;
    if (v8 >= 2)
    {
      uint64_t v10 = v7;
      if (v7 >= 4) {
        uint64_t v10 = 4;
      }
      switch(v10)
      {
        case 0:
          break;
        case 1:
          int v11 = *__dst;
          goto LABEL_10;
        case 2:
          int v11 = *(unsigned __int16 *)__dst;
          goto LABEL_10;
        case 3:
          int v11 = *(unsigned __int16 *)__dst | (__dst[2] << 16);
          goto LABEL_10;
        case 4:
          int v11 = *(_DWORD *)__dst;
LABEL_10:
          if (v7 < 4) {
            v11 |= (v8 - 2) << (8 * v7);
          }
          unsigned int v8 = v11 + 2;
          break;
      }
    }
    if (v8 <= 1)
    {
      uint64_t v12 = AssociatedTypeWitness;
      (*(void (**)(unsigned __int8 *, uint64_t))(v6 + 8))(__dst, AssociatedTypeWitness);
      uint64_t v9 = 4;
      uint64_t AssociatedTypeWitness = v12;
    }
    unsigned int v13 = __src[v7];
    if (v13 >= 2)
    {
      if (v7 < 4) {
        uint64_t v9 = v7;
      }
      switch(v9)
      {
        case 0:
          break;
        case 1:
          int v14 = *__src;
          goto LABEL_23;
        case 2:
          int v14 = *(unsigned __int16 *)__src;
          goto LABEL_23;
        case 3:
          int v14 = *(unsigned __int16 *)__src | (__src[2] << 16);
          goto LABEL_23;
        case 4:
          int v14 = *(_DWORD *)__src;
LABEL_23:
          if (v7 < 4) {
            v14 |= (v13 - 2) << (8 * v7);
          }
          unsigned int v13 = v14 + 2;
          break;
      }
    }
    if (v13 == 1)
    {
      (*(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v6 + 32))(__dst, __src, AssociatedTypeWitness);
      __dst[v7] = 1;
    }
    else if (v13)
    {
      memcpy(__dst, __src, v7 + 1);
    }
    else
    {
      (*(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v6 + 32))(__dst, __src, AssociatedTypeWitness);
      __dst[v7] = 0;
    }
  }
  return __dst;
}

uint64_t getEnumTagSinglePayload for InterspersedMapSequence.Iterator.State(unsigned __int8 *a1, unsigned int a2, uint64_t a3)
{
  unsigned int v4 = 0;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  if (!a2) {
    return v4;
  }
  uint64_t v6 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  if (a2 < 0xFE) {
    goto LABEL_19;
  }
  uint64_t v7 = v6 + 1;
  if ((v6 + 1) > 3)
  {
LABEL_4:
    int v8 = a1[v7];
    goto LABEL_11;
  }
  unsigned int v9 = ((a2 + ~(-1 << (8 * v7)) - 253) >> (8 * v7)) + 1;
  if (v9 > 0xFFFF)
  {
    int v8 = *(_DWORD *)&a1[v7];
  }
  else
  {
    if (v9 <= 0xFF)
    {
      if (v9 < 2) {
        goto LABEL_19;
      }
      goto LABEL_4;
    }
    int v8 = *(unsigned __int16 *)&a1[v7];
  }
LABEL_11:
  if (v8)
  {
    int v10 = (v8 - 1) << (8 * v7);
    int v11 = 0;
    if (v7 >= 4) {
      int v10 = 0;
    }
    if (v6 != -1)
    {
      int v12 = 4;
      if (v7 < 4) {
        int v12 = v6 + 1;
      }
      switch(v12)
      {
        case 1:
          int v11 = *a1;
          break;
        case 2:
          int v11 = *(unsigned __int16 *)a1;
          break;
        case 3:
          int v11 = *(unsigned __int16 *)a1 | (a1[2] << 16);
          break;
        case 4:
          int v11 = *(_DWORD *)a1;
          break;
      }
    }
    return (v10 | v11) + 254;
  }
LABEL_19:
  unsigned int v4 = 0;
  if (a1[v6] >= 3u) {
    return (a1[v6] ^ 0xFFu) + 1;
  }
  return v4;
}

uint64_t storeEnumTagSinglePayload for InterspersedMapSequence.Iterator.State(uint64_t a1, unsigned int a2, unsigned int a3, uint64_t a4)
{
  unsigned int v6 = 0;
  uint64_t result = *(void *)(*(void *)(swift_getAssociatedTypeWitness(0, *(void *)(a4 + 32), *(void *)(a4 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element)- 8)+ 64);
  uint64_t v8 = result + 1;
  if (a3 >= 0xFE)
  {
    if (v8 > 3)
    {
      int v13 = 1;
LABEL_9:
      unsigned int v6 = v13;
      goto LABEL_10;
    }
    unsigned int v9 = ((a3 + ~(-1 << (8 * v8)) - 253) >> (8 * v8)) + 1;
    if (v9 > 0xFFFF)
    {
      int v13 = 4;
      goto LABEL_9;
    }
    unsigned int v6 = 2;
    if (v9 < 0x100) {
      unsigned int v6 = v9 >= 2;
    }
  }
LABEL_10:
  if (a2 > 0xFD)
  {
    unsigned int v10 = a2 - 254;
    if (v8 >= 4)
    {
      int v11 = 1;
      __bzero(a1, result + 1);
      *(_DWORD *)a1 = v10;
      uint64_t result = v6;
      switch(v6)
      {
        case 0u:
          return result;
        case 1u:
          goto LABEL_26;
        case 2u:
          goto LABEL_28;
        case 3u:
          goto LABEL_30;
        case 4u:
          goto LABEL_27;
      }
    }
    int v11 = (v10 >> (8 * v8)) + 1;
    if (result != -1)
    {
      int v12 = ~(-1 << (8 * v8)) & v10;
      uint64_t result = __bzero(a1, result + 1);
      if (v8 != 3)
      {
        if (v8 == 2)
        {
          *(_WORD *)a1 = v12;
          switch(v6)
          {
            case 0u:
              return result;
            case 1u:
              goto LABEL_26;
            case 2u:
              goto LABEL_28;
            case 3u:
              goto LABEL_30;
            case 4u:
              goto LABEL_27;
          }
        }
        *(unsigned char *)a1 = v12;
        switch(v6)
        {
          case 0u:
            return result;
          case 1u:
            goto LABEL_26;
          case 2u:
            goto LABEL_28;
          case 3u:
            goto LABEL_30;
          case 4u:
            goto LABEL_27;
        }
      }
      *(_WORD *)a1 = v12;
      *(unsigned char *)(a1 + 2) = BYTE2(v12);
      switch(v6)
      {
        case 0u:
          return result;
        case 1u:
          goto LABEL_26;
        case 2u:
          goto LABEL_28;
        case 3u:
          goto LABEL_30;
        case 4u:
          goto LABEL_27;
      }
    }
    switch(v6)
    {
      case 0u:
        return result;
      case 1u:
LABEL_26:
        *(unsigned char *)(a1 + v8) = v11;
        break;
      case 2u:
LABEL_28:
        *(_WORD *)(a1 + v8) = v11;
        break;
      case 3u:
LABEL_30:
        BUG();
      case 4u:
LABEL_27:
        *(_DWORD *)(a1 + v8) = v11;
        break;
    }
  }
  else
  {
    switch(v6)
    {
      case 0u:
        goto LABEL_21;
      case 1u:
        *(unsigned char *)(a1 + v8) = 0;
        goto LABEL_21;
      case 2u:
        *(_WORD *)(a1 + v8) = 0;
        goto LABEL_21;
      case 3u:
        goto LABEL_30;
      case 4u:
        *(_DWORD *)(a1 + v8) = 0;
LABEL_21:
        if (a2) {
          *(unsigned char *)(a1 + result) = -(char)a2;
        }
        break;
    }
  }
  return result;
}

uint64_t getEnumTag for InterspersedMapSequence.Iterator.State(unsigned __int8 *a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(*(void *)(swift_getAssociatedTypeWitness(0, *(void *)(a2 + 32), *(void *)(a2 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element)- 8)+ 64);
  uint64_t result = a1[v2];
  if (result >= 2)
  {
    uint64_t v4 = 4;
    if (v2 < 4) {
      uint64_t v4 = v2;
    }
    switch(v4)
    {
      case 0:
        return result;
      case 1:
        int v5 = *a1;
        goto LABEL_9;
      case 2:
        int v5 = *(unsigned __int16 *)a1;
        goto LABEL_9;
      case 3:
        int v5 = *(unsigned __int16 *)a1 | (a1[2] << 16);
        goto LABEL_9;
      case 4:
        int v5 = *(_DWORD *)a1;
LABEL_9:
        if (v2 < 4) {
          v5 |= (result - 2) << (8 * v2);
        }
        uint64_t result = (v5 + 2);
        break;
      case 5:
        JUMPOUT(0x32AFF8);
    }
  }
  return result;
}

uint64_t destructiveInjectEnumTag for InterspersedMapSequence.Iterator.State(uint64_t a1, unsigned int a2, uint64_t a3)
{
  uint64_t result = *(void *)(swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element)- 8);
  uint64_t v4 = *(void *)(result + 64);
  if (a2 > 1)
  {
    unsigned int v5 = a2 - 2;
    if (v4 < 4)
    {
      int v6 = v5 & ~(-1 << (8 * v4));
      *(unsigned char *)(a1 + v4) = (v5 >> (8 * v4)) + 2;
      uint64_t result = __bzero(a1, v4);
      if (v4 == 3)
      {
        *(_WORD *)a1 = v6;
        *(unsigned char *)(a1 + 2) = BYTE2(v6);
      }
      else if (v4 == 2)
      {
        *(_WORD *)a1 = v6;
      }
      else
      {
        *(unsigned char *)a1 = v6;
      }
    }
    else
    {
      *(unsigned char *)(a1 + v4) = 2;
      uint64_t result = __bzero(a1, v4);
      *(_DWORD *)a1 = v5;
    }
  }
  else
  {
    *(unsigned char *)(a1 + v4) = a2;
  }
  return result;
}

uint64_t type metadata completion function for InterspersedMapSequence<>.Index(uint64_t *a1)
{
  uint64_t v1 = type metadata accessor for InterspersedMapSequence<>.Index.Representation(319, a1[2], a1[3], a1[4]);
  if (v2 <= 0x3F)
  {
    v4[0] = *(void *)(v1 - 8) + 64;
    uint64_t v1 = 0;
    swift_initStructMetadata(a1, 0, 1, v4, a1 + 5);
  }
  return v1;
}

void *initializeBufferWithCopyOfBuffer for InterspersedMapSequence<>.Index(void *a1, unsigned __int8 *a2, uint64_t a3)
{
  return initializeBufferWithCopyOfBuffer for InterspersedMapSequence<>.Index(a1, a2, a3);
}

{
  uint64_t AssociatedTypeWitness;
  uint64_t v6;
  unint64_t v7;
  int v8;
  unint64_t v9;
  unint64_t v10;
  unint64_t v11;
  unsigned int v12;
  uint64_t v13;
  unsigned __int8 *v14;
  void *v15;
  uint64_t v16;
  uint64_t v17;
  int v19;
  void (*v20)(void *, unsigned __int8 *, uint64_t);
  unsigned __int8 *v21;
  unint64_t v22;
  uint64_t v23;
  unsigned int v24;

  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  int v6 = *(void *)(AssociatedTypeWitness - 8);
  uint64_t v7 = *(void *)(v6 + 64);
  uint64_t v8 = *(_DWORD *)(v6 + 80);
  unsigned int v9 = ~(unint64_t)v8;
  unsigned int v10 = v7 + v8;
  int v11 = v7 + (v9 & v10);
  if (v11 <= v7) {
    int v11 = *(void *)(v6 + 64);
  }
  if (v8 > 7u || (v8 & 0x100000) != 0 || v11 + 1 > 0x18)
  {
    unsigned int v16 = *(void *)a2;
    *a1 = *(void *)a2;
    int v17 = v16 + ((v8 + 16) & v9);
    swift_retain(v16);
    return (void *)v17;
  }
  else
  {
    int v12 = a2[v11];
    uint64_t v22 = v10;
    if (v12 < 2)
    {
LABEL_10:
      int v14 = a2;
      int v15 = a1;
      uint64_t v24 = v12;
    }
    else
    {
      int v13 = 4;
      if (v11 < 4) {
        int v13 = v11;
      }
      switch(v13)
      {
        case 0:
          goto LABEL_10;
        case 1:
          int v14 = a2;
          int v19 = *a2;
          goto LABEL_16;
        case 2:
          int v14 = a2;
          int v19 = *(unsigned __int16 *)a2;
          goto LABEL_16;
        case 3:
          int v14 = a2;
          int v19 = *(unsigned __int16 *)a2 | (a2[2] << 16);
          goto LABEL_16;
        case 4:
          int v14 = a2;
          int v19 = *(_DWORD *)a2;
LABEL_16:
          int v15 = a1;
          if (v11 < 4) {
            v19 |= (v12 - 2) << (8 * v11);
          }
          uint64_t v24 = v19 + 2;
          break;
        case 5:
          JUMPOUT(0x32B384);
      }
    }
    unsigned int v20 = *(void (**)(void *, unsigned __int8 *, uint64_t))(v6 + 16);
    uint64_t v21 = v14;
    unsigned int v23 = AssociatedTypeWitness;
    v20(v15, v14, AssociatedTypeWitness);
    if (v24 == 1)
    {
      v20((void *)(v9 & ((unint64_t)v15 + v22)), (unsigned __int8 *)(v9 & (unint64_t)&v21[v22]), v23);
      *((unsigned char *)v15 + v11) = 1;
    }
    else
    {
      *((unsigned char *)v15 + v11) = 0;
    }
    return v15;
  }
}

uint64_t destroy for InterspersedMapSequence<>.Index(unsigned __int8 *a1, uint64_t a2)
{
  return destroy for InterspersedMapSequence<>.Index(a1, a2);
}

{
  uint64_t AssociatedTypeWitness;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  unint64_t v10;
  unsigned int v11;
  uint64_t v12;
  int v13;
  uint64_t (*v14)(unsigned __int8 *, uint64_t);
  uint64_t result;
  uint64_t v16;

  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a2 + 32), *(void *)(a2 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v4 = AssociatedTypeWitness;
  unsigned int v5 = *(void *)(AssociatedTypeWitness - 8);
  int v6 = *(void *)(v5 + 64);
  uint64_t v7 = *(unsigned __int8 *)(v5 + 80);
  uint64_t v8 = v6 + v7;
  unsigned int v9 = ~v7;
  unsigned int v16 = v8;
  unsigned int v10 = v6 + (v9 & v8);
  if (v10 <= v6) {
    unsigned int v10 = *(void *)(v5 + 64);
  }
  int v11 = a1[v10];
  if (v11 >= 2)
  {
    int v12 = 4;
    if (v10 < 4) {
      int v12 = v10;
    }
    switch(v12)
    {
      case 0:
        break;
      case 1:
        int v13 = *a1;
        goto LABEL_11;
      case 2:
        int v13 = *(unsigned __int16 *)a1;
        goto LABEL_11;
      case 3:
        int v13 = *(unsigned __int16 *)a1 | (a1[2] << 16);
        goto LABEL_11;
      case 4:
        int v13 = *(_DWORD *)a1;
LABEL_11:
        if (v10 < 4) {
          v13 |= (v11 - 2) << (8 * v10);
        }
        int v11 = v13 + 2;
        break;
      case 5:
        JUMPOUT(0x32B494);
    }
  }
  int v14 = *(uint64_t (**)(unsigned __int8 *, uint64_t))(v5 + 8);
  uint64_t result = v14(a1, AssociatedTypeWitness);
  if (v11 == 1) {
    return v14((unsigned __int8 *)(v9 & (unint64_t)&a1[v16]), v4);
  }
  return result;
}

uint64_t initializeWithCopy for InterspersedMapSequence<>.Index(uint64_t a1, unsigned __int8 *a2, uint64_t a3)
{
  return initializeWithCopy for InterspersedMapSequence<>.Index(a1, a2, a3);
}

{
  uint64_t AssociatedTypeWitness;
  uint64_t v5;
  unint64_t v6;
  uint64_t v7;
  unint64_t v8;
  unsigned int v9;
  uint64_t v10;
  int v11;
  void (*v12)(uint64_t, unsigned __int8 *, uint64_t);
  char v13;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;

  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  unsigned int v5 = *(void *)(AssociatedTypeWitness - 8);
  int v6 = *(void *)(v5 + 64);
  uint64_t v7 = *(unsigned __int8 *)(v5 + 80);
  int v15 = v6 + v7;
  unsigned int v16 = ~v7;
  uint64_t v8 = v6 + (~v7 & (v6 + v7));
  if (v8 <= v6) {
    uint64_t v8 = *(void *)(v5 + 64);
  }
  unsigned int v9 = a2[v8];
  if (v9 >= 2)
  {
    unsigned int v10 = 4;
    if (v8 < 4) {
      unsigned int v10 = v8;
    }
    switch(v10)
    {
      case 0:
        break;
      case 1:
        int v11 = *a2;
        goto LABEL_11;
      case 2:
        int v11 = *(unsigned __int16 *)a2;
        goto LABEL_11;
      case 3:
        int v11 = *(unsigned __int16 *)a2 | (a2[2] << 16);
        goto LABEL_11;
      case 4:
        int v11 = *(_DWORD *)a2;
LABEL_11:
        if (v8 < 4) {
          v11 |= (v9 - 2) << (8 * v8);
        }
        unsigned int v9 = v11 + 2;
        break;
      case 5:
        JUMPOUT(0x32B5CCLL);
    }
  }
  int v12 = *(void (**)(uint64_t, unsigned __int8 *, uint64_t))(v5 + 16);
  int v17 = AssociatedTypeWitness;
  v12(a1, a2, AssociatedTypeWitness);
  if (v9 == 1)
  {
    v12(v16 & (v15 + a1), (unsigned __int8 *)(v16 & (unint64_t)&a2[v15]), v17);
    int v13 = 1;
  }
  else
  {
    int v13 = 0;
  }
  *(unsigned char *)(a1 + v8) = v13;
  return a1;
}

unsigned __int8 *assignWithCopy for InterspersedMapSequence<>.Index(unsigned __int8 *a1, unsigned __int8 *a2, uint64_t a3)
{
  return assignWithCopy for InterspersedMapSequence<>.Index(a1, a2, a3);
}

{
  unsigned __int8 *v3;
  uint64_t AssociatedTypeWitness;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  unint64_t v9;
  unsigned int v10;
  uint64_t v11;
  uint64_t v12;
  int v13;
  void (*v14)(unsigned __int8 *, uint64_t, uint64_t, uint64_t);
  uint64_t v15;
  unsigned int v16;
  uint64_t v17;
  uint64_t v18;
  int v19;
  void (*v20)(unsigned __int8 *, unsigned __int8 *, uint64_t);
  char v21;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  int v26;

  uint64_t v3 = a1;
  if (a1 != a2)
  {
    uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
    int v6 = *(void *)(AssociatedTypeWitness - 8);
    uint64_t v7 = *(void *)(v6 + 64);
    uint64_t v8 = *(unsigned __int8 *)(v6 + 80);
    uint64_t v25 = v7 + v8;
    uint64_t v24 = ~v8;
    unsigned int v9 = v7 + (~v8 & (v7 + v8));
    if (v9 <= v7) {
      unsigned int v9 = *(void *)(v6 + 64);
    }
    unsigned int v10 = a1[v9];
    int v11 = 4;
    if (v10 >= 2)
    {
      int v12 = v9;
      if (v9 >= 4) {
        int v12 = 4;
      }
      switch(v12)
      {
        case 0:
          break;
        case 1:
          int v13 = *a1;
          goto LABEL_12;
        case 2:
          int v13 = *(unsigned __int16 *)a1;
          goto LABEL_12;
        case 3:
          int v11 = *(unsigned __int16 *)a1;
          int v13 = v11 | (a1[2] << 16);
          goto LABEL_12;
        case 4:
          int v13 = *(_DWORD *)a1;
LABEL_12:
          if (v9 < 4)
          {
            int v11 = (8 * v9);
            v13 |= (v10 - 2) << (8 * v9);
          }
          unsigned int v10 = v13 + 2;
          break;
      }
    }
    unsigned int v23 = *(void *)(AssociatedTypeWitness - 8);
    int v14 = *(void (**)(unsigned __int8 *, uint64_t, uint64_t, uint64_t))(v6 + 8);
    int v15 = AssociatedTypeWitness;
    v14(a1, AssociatedTypeWitness, v6, v11);
    if (v10 == 1) {
      ((void (*)(unint64_t, uint64_t))v14)(v24 & (unint64_t)&a1[v25], AssociatedTypeWitness);
    }
    unsigned int v16 = a2[v9];
    int v17 = v15;
    if (v16 < 2)
    {
LABEL_21:
      int v26 = a2[v9];
    }
    else
    {
      int v18 = 4;
      if (v9 < 4) {
        int v18 = v9;
      }
      switch(v18)
      {
        case 0:
          goto LABEL_21;
        case 1:
          int v19 = *a2;
          goto LABEL_26;
        case 2:
          int v19 = *(unsigned __int16 *)a2;
          goto LABEL_26;
        case 3:
          int v19 = *(unsigned __int16 *)a2 | (a2[2] << 16);
          goto LABEL_26;
        case 4:
          int v19 = *(_DWORD *)a2;
LABEL_26:
          if (v9 < 4) {
            v19 |= (v16 - 2) << (8 * v9);
          }
          int v26 = v19 + 2;
          break;
        case 5:
          JUMPOUT(0x32B7BCLL);
      }
    }
    unsigned int v20 = *(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v23 + 16);
    uint64_t v3 = a1;
    v20(a1, a2, v17);
    if (v26 == 1)
    {
      v20((unsigned __int8 *)(v24 & (unint64_t)&a1[v25]), (unsigned __int8 *)(v24 & (unint64_t)&a2[v25]), v17);
      uint64_t v21 = 1;
    }
    else
    {
      uint64_t v21 = 0;
    }
    a1[v9] = v21;
  }
  return v3;
}

uint64_t initializeWithTake for InterspersedMapSequence<>.Index(uint64_t a1, unsigned __int8 *a2, uint64_t a3)
{
  return initializeWithTake for InterspersedMapSequence<>.Index(a1, a2, a3);
}

{
  uint64_t AssociatedTypeWitness;
  uint64_t v5;
  unint64_t v6;
  uint64_t v7;
  unint64_t v8;
  unsigned int v9;
  uint64_t v10;
  int v11;
  void (*v12)(uint64_t, unsigned __int8 *, uint64_t);
  char v13;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;

  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  unsigned int v5 = *(void *)(AssociatedTypeWitness - 8);
  int v6 = *(void *)(v5 + 64);
  uint64_t v7 = *(unsigned __int8 *)(v5 + 80);
  int v15 = v6 + v7;
  unsigned int v16 = ~v7;
  uint64_t v8 = v6 + (~v7 & (v6 + v7));
  if (v8 <= v6) {
    uint64_t v8 = *(void *)(v5 + 64);
  }
  unsigned int v9 = a2[v8];
  if (v9 >= 2)
  {
    unsigned int v10 = 4;
    if (v8 < 4) {
      unsigned int v10 = v8;
    }
    switch(v10)
    {
      case 0:
        break;
      case 1:
        int v11 = *a2;
        goto LABEL_11;
      case 2:
        int v11 = *(unsigned __int16 *)a2;
        goto LABEL_11;
      case 3:
        int v11 = *(unsigned __int16 *)a2 | (a2[2] << 16);
        goto LABEL_11;
      case 4:
        int v11 = *(_DWORD *)a2;
LABEL_11:
        if (v8 < 4) {
          v11 |= (v9 - 2) << (8 * v8);
        }
        unsigned int v9 = v11 + 2;
        break;
      case 5:
        JUMPOUT(0x32B8F4);
    }
  }
  int v12 = *(void (**)(uint64_t, unsigned __int8 *, uint64_t))(v5 + 32);
  int v17 = AssociatedTypeWitness;
  v12(a1, a2, AssociatedTypeWitness);
  if (v9 == 1)
  {
    v12(v16 & (v15 + a1), (unsigned __int8 *)(v16 & (unint64_t)&a2[v15]), v17);
    int v13 = 1;
  }
  else
  {
    int v13 = 0;
  }
  *(unsigned char *)(a1 + v8) = v13;
  return a1;
}

unsigned __int8 *assignWithTake for InterspersedMapSequence<>.Index(unsigned __int8 *a1, unsigned __int8 *a2, uint64_t a3)
{
  return assignWithTake for InterspersedMapSequence<>.Index(a1, a2, a3);
}

{
  unsigned __int8 *v3;
  uint64_t AssociatedTypeWitness;
  uint64_t v6;
  unint64_t v7;
  uint64_t v8;
  unint64_t v9;
  unsigned int v10;
  uint64_t v11;
  uint64_t v12;
  int v13;
  void (*v14)(unsigned __int8 *, uint64_t, uint64_t, uint64_t);
  uint64_t v15;
  unsigned int v16;
  uint64_t v17;
  uint64_t v18;
  int v19;
  void (*v20)(unsigned __int8 *, unsigned __int8 *, uint64_t);
  char v21;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  int v26;

  uint64_t v3 = a1;
  if (a1 != a2)
  {
    uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
    int v6 = *(void *)(AssociatedTypeWitness - 8);
    uint64_t v7 = *(void *)(v6 + 64);
    uint64_t v8 = *(unsigned __int8 *)(v6 + 80);
    uint64_t v25 = v7 + v8;
    uint64_t v24 = ~v8;
    unsigned int v9 = v7 + (~v8 & (v7 + v8));
    if (v9 <= v7) {
      unsigned int v9 = *(void *)(v6 + 64);
    }
    unsigned int v10 = a1[v9];
    int v11 = 4;
    if (v10 >= 2)
    {
      int v12 = v9;
      if (v9 >= 4) {
        int v12 = 4;
      }
      switch(v12)
      {
        case 0:
          break;
        case 1:
          int v13 = *a1;
          goto LABEL_12;
        case 2:
          int v13 = *(unsigned __int16 *)a1;
          goto LABEL_12;
        case 3:
          int v11 = *(unsigned __int16 *)a1;
          int v13 = v11 | (a1[2] << 16);
          goto LABEL_12;
        case 4:
          int v13 = *(_DWORD *)a1;
LABEL_12:
          if (v9 < 4)
          {
            int v11 = (8 * v9);
            v13 |= (v10 - 2) << (8 * v9);
          }
          unsigned int v10 = v13 + 2;
          break;
      }
    }
    unsigned int v23 = *(void *)(AssociatedTypeWitness - 8);
    int v14 = *(void (**)(unsigned __int8 *, uint64_t, uint64_t, uint64_t))(v6 + 8);
    int v15 = AssociatedTypeWitness;
    v14(a1, AssociatedTypeWitness, v6, v11);
    if (v10 == 1) {
      ((void (*)(unint64_t, uint64_t))v14)(v24 & (unint64_t)&a1[v25], AssociatedTypeWitness);
    }
    unsigned int v16 = a2[v9];
    int v17 = v15;
    if (v16 < 2)
    {
LABEL_21:
      int v26 = a2[v9];
    }
    else
    {
      int v18 = 4;
      if (v9 < 4) {
        int v18 = v9;
      }
      switch(v18)
      {
        case 0:
          goto LABEL_21;
        case 1:
          int v19 = *a2;
          goto LABEL_26;
        case 2:
          int v19 = *(unsigned __int16 *)a2;
          goto LABEL_26;
        case 3:
          int v19 = *(unsigned __int16 *)a2 | (a2[2] << 16);
          goto LABEL_26;
        case 4:
          int v19 = *(_DWORD *)a2;
LABEL_26:
          if (v9 < 4) {
            v19 |= (v16 - 2) << (8 * v9);
          }
          int v26 = v19 + 2;
          break;
        case 5:
          JUMPOUT(0x32BAE4);
      }
    }
    unsigned int v20 = *(void (**)(unsigned __int8 *, unsigned __int8 *, uint64_t))(v23 + 32);
    uint64_t v3 = a1;
    v20(a1, a2, v17);
    if (v26 == 1)
    {
      v20((unsigned __int8 *)(v24 & (unint64_t)&a1[v25]), (unsigned __int8 *)(v24 & (unint64_t)&a2[v25]), v17);
      uint64_t v21 = 1;
    }
    else
    {
      uint64_t v21 = 0;
    }
    a1[v9] = v21;
  }
  return v3;
}

uint64_t getEnumTagSinglePayload for InterspersedMapSequence<>.Index(unsigned __int8 *a1, unsigned int a2, uint64_t a3)
{
  return getEnumTagSinglePayload for InterspersedMapSequence<>.Index(a1, a2, a3);
}

{
  unsigned int v3;
  uint64_t v4;
  unint64_t v5;
  unint64_t v6;
  unint64_t v7;
  int v8;
  unsigned int v9;
  int v10;
  int v11;
  int v12;
  unsigned int v13;

  uint64_t v3 = 0;
  uint64_t v4 = *(void *)(swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index)- 8);
  unsigned int v5 = *(void *)(v4 + 64);
  int v6 = v5 + ((v5 + *(unsigned __int8 *)(v4 + 80)) & ~(unint64_t)*(unsigned __int8 *)(v4 + 80));
  if (v6 <= v5) {
    int v6 = v5;
  }
  if (a2)
  {
    if (a2 < 0xFF) {
      goto LABEL_21;
    }
    uint64_t v7 = v6 + 1;
    if ((v6 + 1) > 3)
    {
LABEL_6:
      uint64_t v8 = a1[v7];
      goto LABEL_13;
    }
    unsigned int v9 = ((a2 + ~(-1 << (8 * v7)) - 254) >> (8 * v7)) + 1;
    if (v9 > 0xFFFF)
    {
      uint64_t v8 = *(_DWORD *)&a1[v7];
    }
    else
    {
      if (v9 <= 0xFF)
      {
        if (v9 >= 2) {
          goto LABEL_6;
        }
LABEL_21:
        int v13 = a1[v6];
        uint64_t v3 = 0;
        if (v13 >= 2) {
          return (v13 ^ 0xFF) + 1;
        }
        return v3;
      }
      uint64_t v8 = *(unsigned __int16 *)&a1[v7];
    }
LABEL_13:
    if (v8)
    {
      unsigned int v10 = (v8 - 1) << (8 * v7);
      int v11 = 0;
      if (v7 >= 4) {
        unsigned int v10 = 0;
      }
      if (v6 != -1)
      {
        int v12 = 4;
        if (v7 < 4) {
          int v12 = v7;
        }
        switch(v12)
        {
          case 1:
            int v11 = *a1;
            break;
          case 2:
            int v11 = *(unsigned __int16 *)a1;
            break;
          case 3:
            int v11 = *(unsigned __int16 *)a1 | (a1[2] << 16);
            break;
          case 4:
            int v11 = *(_DWORD *)a1;
            break;
          case 5:
            JUMPOUT(0x32BC40);
        }
      }
      return (v10 | v11) + 255;
    }
    goto LABEL_21;
  }
  return v3;
}

unint64_t storeEnumTagSinglePayload for InterspersedMapSequence<>.Index(uint64_t a1, unsigned int a2, unsigned int a3, uint64_t a4)
{
  return storeEnumTagSinglePayload for InterspersedMapSequence<>.Index(a1, a2, a3, a4);
}

{
  unsigned int v6;
  uint64_t v7;
  unint64_t v8;
  unint64_t result;
  unint64_t v10;
  unsigned int v11;
  unsigned int v12;
  int v13;
  int v14;
  int v15;

  int v6 = 0;
  uint64_t v7 = *(void *)(swift_getAssociatedTypeWitness(0, *(void *)(a4 + 32), *(void *)(a4 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index)- 8);
  uint64_t v8 = *(void *)(v7 + 64);
  uint64_t result = v8 + ((v8 + *(unsigned __int8 *)(v7 + 80)) & ~(unint64_t)*(unsigned __int8 *)(v7 + 80));
  if (result <= v8) {
    uint64_t result = v8;
  }
  unsigned int v10 = result + 1;
  if (a3 >= 0xFF)
  {
    if (v10 > 3)
    {
      int v15 = 1;
LABEL_11:
      int v6 = v15;
      goto LABEL_12;
    }
    int v11 = ((a3 + ~(-1 << (8 * v10)) - 254) >> (8 * v10)) + 1;
    if (v11 > 0xFFFF)
    {
      int v15 = 4;
      goto LABEL_11;
    }
    int v6 = 2;
    if (v11 < 0x100) {
      int v6 = v11 >= 2;
    }
  }
LABEL_12:
  if (a2 > 0xFE)
  {
    int v12 = a2 - 255;
    if (v10 >= 4)
    {
      int v13 = 1;
      __bzero(a1, result + 1);
      *(_DWORD *)a1 = v12;
      uint64_t result = v6;
      switch(v6)
      {
        case 0u:
          return result;
        case 1u:
          goto LABEL_28;
        case 2u:
          goto LABEL_30;
        case 3u:
          goto LABEL_32;
        case 4u:
          goto LABEL_29;
      }
    }
    int v13 = (v12 >> (8 * v10)) + 1;
    if (result != -1)
    {
      int v14 = ~(-1 << (8 * v10)) & v12;
      uint64_t result = __bzero(a1, result + 1);
      if (v10 != 3)
      {
        if (v10 == 2)
        {
          *(_WORD *)a1 = v14;
          switch(v6)
          {
            case 0u:
              return result;
            case 1u:
              goto LABEL_28;
            case 2u:
              goto LABEL_30;
            case 3u:
              goto LABEL_32;
            case 4u:
              goto LABEL_29;
          }
        }
        *(unsigned char *)a1 = v14;
        switch(v6)
        {
          case 0u:
            return result;
          case 1u:
            goto LABEL_28;
          case 2u:
            goto LABEL_30;
          case 3u:
            goto LABEL_32;
          case 4u:
            goto LABEL_29;
        }
      }
      *(_WORD *)a1 = v14;
      *(unsigned char *)(a1 + 2) = BYTE2(v14);
      switch(v6)
      {
        case 0u:
          return result;
        case 1u:
          goto LABEL_28;
        case 2u:
          goto LABEL_30;
        case 3u:
          goto LABEL_32;
        case 4u:
          goto LABEL_29;
      }
    }
    switch(v6)
    {
      case 0u:
        return result;
      case 1u:
LABEL_28:
        *(unsigned char *)(a1 + v10) = v13;
        break;
      case 2u:
LABEL_30:
        *(_WORD *)(a1 + v10) = v13;
        break;
      case 3u:
LABEL_32:
        BUG();
      case 4u:
LABEL_29:
        *(_DWORD *)(a1 + v10) = v13;
        break;
    }
  }
  else
  {
    switch(v6)
    {
      case 0u:
        goto LABEL_23;
      case 1u:
        *(unsigned char *)(a1 + v10) = 0;
        goto LABEL_23;
      case 2u:
        *(_WORD *)(a1 + v10) = 0;
        goto LABEL_23;
      case 3u:
        goto LABEL_32;
      case 4u:
        *(_DWORD *)(a1 + v10) = 0;
LABEL_23:
        if (a2) {
          *(unsigned char *)(a1 + result) = -(char)a2;
        }
        break;
    }
  }
  return result;
}

uint64_t type metadata completion function for InterspersedMapSequence<>.Index.Representation(uint64_t a1)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(319, *(void *)(a1 + 32), *(void *)(a1 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index);
  uint64_t v2 = AssociatedTypeWitness;
  if (v3 <= 0x3F)
  {
    v8[0] = *(void *)(AssociatedTypeWitness - 8) + 64;
    swift_getTupleTypeLayout2(v7, v8[0]);
    v8[1] = v7;
    uint64_t v2 = 0;
    swift_initEnumMetadataMultiPayload(a1, 0, 2, v8, v4, v5);
  }
  return v2;
}

uint64_t getEnumTag for InterspersedMapSequence<>.Index.Representation(unsigned __int8 *a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(swift_getAssociatedTypeWitness(0, *(void *)(a2 + 32), *(void *)(a2 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index)- 8);
  unint64_t v3 = *(void *)(v2 + 64);
  unint64_t v4 = v3 + ((v3 + *(unsigned __int8 *)(v2 + 80)) & ~(unint64_t)*(unsigned __int8 *)(v2 + 80));
  if (v4 <= v3) {
    unint64_t v4 = *(void *)(v2 + 64);
  }
  uint64_t result = a1[v4];
  if (result >= 2)
  {
    uint64_t v6 = 4;
    if (v4 < 4) {
      uint64_t v6 = v4;
    }
    switch(v6)
    {
      case 0:
        return result;
      case 1:
        int v7 = *a1;
        goto LABEL_11;
      case 2:
        int v7 = *(unsigned __int16 *)a1;
        goto LABEL_11;
      case 3:
        int v7 = *(unsigned __int16 *)a1 | (a1[2] << 16);
        goto LABEL_11;
      case 4:
        int v7 = *(_DWORD *)a1;
LABEL_11:
        if (v4 < 4) {
          v7 |= (result - 2) << (8 * v4);
        }
        uint64_t result = (v7 + 2);
        break;
      case 5:
        JUMPOUT(0x32BEECLL);
    }
  }
  return result;
}

unint64_t destructiveInjectEnumTag for InterspersedMapSequence<>.Index.Representation(uint64_t a1, unsigned int a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Collection, &associated type descriptor for Collection.Index)- 8);
  unint64_t result = *(void *)(v3 + 64);
  unint64_t v5 = result + ((result + *(unsigned __int8 *)(v3 + 80)) & ~(unint64_t)*(unsigned __int8 *)(v3 + 80));
  if (a2 > 1)
  {
    if (v5 <= result) {
      unint64_t v5 = *(void *)(v3 + 64);
    }
    unsigned int v6 = a2 - 2;
    if (v5 < 4)
    {
      int v7 = v6 & ~(-1 << (8 * v5));
      *(unsigned char *)(a1 + v5) = (v6 >> (8 * v5)) + 2;
      unint64_t result = __bzero(a1, v5);
      if (v5 == 3)
      {
        *(_WORD *)a1 = v7;
        *(unsigned char *)(a1 + 2) = BYTE2(v7);
      }
      else if (v5 == 2)
      {
        *(_WORD *)a1 = v7;
      }
      else
      {
        *(unsigned char *)a1 = v7;
      }
    }
    else
    {
      *(unsigned char *)(a1 + v5) = 2;
      unint64_t result = __bzero(a1, v5);
      *(_DWORD *)a1 = v6;
    }
  }
  else
  {
    if (v5 <= result) {
      unint64_t v5 = *(void *)(v3 + 64);
    }
    *(unsigned char *)(a1 + v5) = a2;
  }
  return result;
}

uint64_t partial apply for closure #1 in InterspersedSequence<>.offsetBackward(_:by:limitedBy:)(uint64_t a1)
{
  return partial apply for closure #1 in InterspersedSequence<>.offsetForward(_:by:limitedBy:)(a1);
}

uint64_t partial apply for closure #2 in InterspersedSequence<>.offsetBackward(_:by:limitedBy:)(uint64_t a1)
{
  return partial apply for closure #2 in InterspersedSequence<>.offsetForward(_:by:limitedBy:)(a1);
}

uint64_t variable initialization expression of InclusiveReductionsSequence.Iterator.element(uint64_t a1, uint64_t a2)
{
  return variable initialization expression of AdjacentPairsSequence.Iterator.previousElement(a1, a2);
}

uint64_t InterspersedMapSequence.base.getter(uint64_t a1)
{
  return InterspersedSequence.base.getter(a1);
}

uint64_t UniquedSequence.base.getter(uint64_t a1)
{
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(*(void *)(a1 + 16) - 8) + 16))(v1, v2);
}

uint64_t UniquedSequence.projection.getter(uint64_t a1)
{
  return UniquedSequence.projection.getter(a1);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v2 = *(int *)(a1 + 52);
  uint64_t v3 = *(void *)(v1 + v2);
  swift_retain(*(void *)(v1 + v2 + 8));
  return v3;
}

uint64_t UniquedSequence.init(base:projection:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v14 = a3;
  uint64_t v9 = v7;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(a4 - 8) + 32))(v7, a1, a4);
  v13[0] = a4;
  v13[1] = a5;
  void v13[2] = a6;
  v13[3] = a7;
  uint64_t result = *(int *)(type metadata accessor for UniquedSequence(0, (uint64_t)v13) + 52);
  *(void *)(v9 + result) = a2;
  *(void *)(v9 + result + 8) = v14;
  return result;
}

uint64_t type metadata accessor for UniquedSequence(uint64_t a1, uint64_t a2)
{
  return swift_getGenericMetadata(a1, a2, &nominal type descriptor for UniquedSequence);
}

uint64_t UniquedSequence.Iterator.base.getter(uint64_t a1)
{
  uint64_t v3 = v1;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a1 + 32), *(void *)(a1 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 16))(v3, v2, AssociatedTypeWitness);
}

uint64_t UniquedSequence.Iterator.base.setter(uint64_t a1, uint64_t a2)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a2 + 32), *(void *)(a2 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 40))(v2, a1, AssociatedTypeWitness);
}

void (*UniquedSequence.Iterator.base.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UniquedSequence.Iterator.projection.getter(uint64_t a1)
{
  return UniquedSequence.projection.getter(a1);
}

uint64_t UniquedSequence.Iterator.seen.getter(uint64_t a1)
{
  return swift_bridgeObjectRetain(*(void *)(v1 + *(int *)(a1 + 56)));
}

uint64_t UniquedSequence.Iterator.seen.setter(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(int *)(a2 + 56);
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v2 + v3));
  *(void *)(v2 + v3) = a1;
  return result;
}

void (*UniquedSequence.Iterator.seen.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UniquedSequence.Iterator.init(base:projection:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v18 = a3;
  uint64_t v9 = v7;
  uint64_t v19 = a2;
  uint64_t v20 = a1;
  uint64_t v12 = static Array._allocateUninitialized(_:)(0, a5);
  if (Array._getCount()())
  {
    int v13 = Set.init(_nonEmptyArrayLiteral:)(v12, a5, a7);
  }
  else
  {
    swift_bridgeObjectRelease(v12);
    int v13 = &_swiftEmptySetSingleton;
  }
  v17[0] = a4;
  v17[1] = a5;
  double v17[2] = a6;
  v17[3] = a7;
  uint64_t v14 = type metadata accessor for UniquedSequence.Iterator(0, (uint64_t)v17);
  *(void *)(v9 + *(int *)(v14 + 56)) = v13;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a6, a4, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 32))(v9, v20, AssociatedTypeWitness);
  uint64_t result = *(int *)(v14 + 52);
  *(void *)(v9 + result) = v19;
  *(void *)(v9 + result + 8) = v18;
  return result;
}

uint64_t UniquedSequence.Iterator.next()(void *a1)
{
  uint64_t v45 = v2;
  uint64_t v44 = v1;
  uint64_t v34 = a1[3];
  uint64_t v35 = *(void *)(v34 - 8);
  int64_t v3 = *(void *)(v35 + 64);
  unint64_t v4 = alloca(v3);
  unint64_t v5 = alloca(v3);
  uint64_t v40 = &v32;
  unsigned int v6 = alloca(v3);
  uint64_t v7 = alloca(v3);
  uint64_t v36 = &v32;
  uint64_t v8 = a1[2];
  uint64_t v33 = a1;
  uint64_t v9 = a1[4];
  uint64_t v46 = v9;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(255, v9, v8, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v39 = type metadata accessor for Optional(0, AssociatedTypeWitness);
  uint64_t v38 = *(void *)(v39 - 8);
  int64_t v11 = *(void *)(v38 + 64);
  uint64_t v12 = alloca(v11);
  int v13 = alloca(v11);
  uint64_t v14 = &v32;
  uint64_t v41 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v15 = *(void *)(v41 + 64);
  unsigned int v16 = alloca(v15);
  int v17 = alloca(v15);
  uint64_t v18 = v9;
  uint64_t v19 = v8;
  uint64_t v20 = swift_getAssociatedTypeWitness(0, v18, v8, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v46, v19, v20, &protocol requirements base descriptor for Sequence, &associated conformance descriptor for Sequence.Sequence.Iterator: IteratorProtocol);
  uint64_t v46 = v20;
  uint64_t v37 = AssociatedConformanceWitness;
  dispatch thunk of IteratorProtocol.next()(v20, AssociatedConformanceWitness);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v32, 1, AssociatedTypeWitness) == 1)
  {
LABEL_5:
    (*(void (**)(uint64_t *, uint64_t))(v38 + 8))(v14, v39);
    uint64_t v29 = v44;
    uint64_t v30 = 1;
  }
  else
  {
    uint64_t v42 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v41 + 32);
    uint64_t v43 = AssociatedTypeWitness;
    while (1)
    {
      v42(&v32, v14, AssociatedTypeWitness);
      uint64_t v22 = v33;
      uint64_t v23 = (uint64_t)v14;
      (*(void (**)(uint64_t *))(v45 + *((int *)v33 + 13)))(&v32);
      uint64_t v24 = v22[5];
      uint64_t v25 = v34;
      uint64_t v26 = type metadata accessor for Set(0, v34, v24);
      uint64_t v27 = v36;
      char v28 = Set.insert(_:)(v36, v40, v26);
      (*(void (**)(uint64_t *, uint64_t))(v35 + 8))(v27, v25);
      if (v28) {
        break;
      }
      uint64_t AssociatedTypeWitness = v43;
      (*(void (**)(uint64_t *, uint64_t))(v41 + 8))(&v32, v43);
      dispatch thunk of IteratorProtocol.next()(v46, v37);
      uint64_t v14 = (uint64_t *)v23;
      if (__swift_getEnumTagSinglePayload(v23, 1, AssociatedTypeWitness) == 1) {
        goto LABEL_5;
      }
    }
    uint64_t v29 = v44;
    uint64_t AssociatedTypeWitness = v43;
    v42((uint64_t *)v44, &v32, v43);
    uint64_t v30 = 0;
  }
  return __swift_storeEnumTagSinglePayload(v29, v30, 1, AssociatedTypeWitness);
}

uint64_t protocol witness for IteratorProtocol.next() in conformance UniquedSequence<A, B>.Iterator(void *a1)
{
  return UniquedSequence.Iterator.next()(a1);
}

uint64_t UniquedSequence.makeIterator()(uint64_t a1)
{
  uint64_t v3 = v2;
  v18[1] = v1;
  uint64_t v4 = *(void *)(a1 + 16);
  uint64_t v21 = *(void *)(v4 - 8);
  int64_t v5 = *(void *)(v21 + 64);
  unsigned int v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v19 = *(void *)(a1 + 32);
  int64_t v8 = *(void *)(*(void *)(swift_getAssociatedTypeWitness(0, v19, v4, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator)- 8)+ 64);
  uint64_t v9 = alloca(v8);
  unsigned int v10 = alloca(v8);
  uint64_t v20 = v18;
  (*(void (**)(void *, uint64_t, uint64_t))(v21 + 16))(v18, v2, v4);
  uint64_t v11 = v19;
  dispatch thunk of Sequence.makeIterator()(v4, v19);
  uint64_t v12 = *(int *)(a1 + 52);
  uint64_t v13 = *(void *)(v2 + v12);
  uint64_t v14 = *(void *)(v3 + v12 + 8);
  uint64_t v21 = *(void *)(a1 + 24);
  uint64_t v15 = *(void *)(a1 + 40);
  swift_retain();
  UniquedSequence.Iterator.init(base:projection:)((uint64_t)v20, v13, v14, v4, v21, v11, v15);
  return v17;
}

uint64_t protocol witness for Sequence.makeIterator() in conformance UniquedSequence<A, B>(uint64_t a1)
{
  UniquedSequence.makeIterator()(a1);
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(a1 - 8) + 8))(v1, a1);
}

uint64_t Sequence<>.uniqued()(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v14[0] = v3;
  uint64_t v6 = *(void *)(a1 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  (*(void (**)(void *, uint64_t, uint64_t))(v6 + 16))(v14, v4, a1);
  unsigned int v10 = (void *)swift_allocObject(&unk_39E4B0, 40, 7);
  v10[2] = a1;
  v10[3] = a2;
  v10[4] = a3;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a2, a1, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  UniquedSequence.init(base:projection:)((uint64_t)v14, (uint64_t)partial apply for closure #1 in Sequence<>.uniqued(), (uint64_t)v10, a1, AssociatedTypeWitness, a2, a3);
  return v13;
}

uint64_t closure #1 in Sequence<>.uniqued()(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, a2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(AssociatedTypeWitness - 8) + 16))(v4, a1, AssociatedTypeWitness);
}

uint64_t Sequence.uniqued<A>(on:)(void (*a1)(uint64_t *), uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v8 = v6;
  uint64_t v63 = v7;
  uint64_t v61 = a6;
  uint64_t v59 = a4;
  uint64_t v52 = a2;
  uint64_t v53 = a1;
  uint64_t v54 = *(void *)(a4 - 8);
  int64_t v11 = *(void *)(v54 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = &v52;
  uint64_t v15 = alloca(v11);
  unsigned int v16 = alloca(v11);
  uint64_t v55 = &v52;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a5, a3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v70 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v18 = *(void *)(v70 + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v57 = &v52;
  uint64_t v21 = alloca(v18);
  uint64_t v22 = alloca(v18);
  uint64_t v66 = &v52;
  uint64_t v73 = AssociatedTypeWitness;
  int64_t v23 = *(void *)(*(void *)(type metadata accessor for Optional(0, AssociatedTypeWitness) - 8) + 64);
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  uint64_t v60 = &v52;
  uint64_t v68 = *(void *)(a3 - 8);
  int64_t v26 = *(void *)(v68 + 64);
  uint64_t v27 = alloca(v26);
  char v28 = alloca(v26);
  uint64_t v58 = &v52;
  uint64_t v69 = a5;
  uint64_t v67 = a3;
  uint64_t v71 = swift_getAssociatedTypeWitness(0, a5, a3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v62 = *(void *)(v71 - 8);
  int64_t v29 = *(void *)(v62 + 64);
  uint64_t v30 = alloca(v29);
  unsigned int v31 = alloca(v29);
  uint64_t v72 = &v52;
  uint64_t v32 = v59;
  uint64_t v33 = static Array._allocateUninitialized(_:)(0, v59);
  if (Array._getCount()())
  {
    uint64_t v34 = Set.init(_nonEmptyArrayLiteral:)(v33, v32, v61);
  }
  else
  {
    swift_bridgeObjectRelease(v33);
    uint64_t v34 = &_swiftEmptySetSingleton;
  }
  uint64_t v35 = v63;
  uint64_t v64 = v34;
  uint64_t v65 = static Array._allocateUninitialized(_:)(0, v73);
  uint64_t v36 = v35;
  uint64_t v37 = v67;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v68 + 16))(v58, v36, v67);
  dispatch thunk of Sequence.makeIterator()(v37, v69);
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v69, v37, v71, &protocol requirements base descriptor for Sequence, &associated conformance descriptor for Sequence.Sequence.Iterator: IteratorProtocol);
  uint64_t v39 = (uint64_t)v60;
  uint64_t v67 = AssociatedConformanceWitness;
  dispatch thunk of IteratorProtocol.next()(v71, AssociatedConformanceWitness);
  if (__swift_getEnumTagSinglePayload(v39, 1, v73) == 1)
  {
LABEL_10:
    (*(void (**)(uint64_t *, uint64_t))(v62 + 8))(v72, v71);
    swift_bridgeObjectRelease((_BYTE)v64);
    return v65;
  }
  else
  {
    uint64_t v68 = *(void *)(v70 + 32);
    uint64_t v40 = v66;
    uint64_t v56 = &v52;
    while (1)
    {
      ((void (*)(uint64_t *, uint64_t, uint64_t))v68)(v40, v39, v73);
      v53(v40);
      if (v8) {
        break;
      }
      uint64_t v69 = 0;
      uint64_t v41 = v14;
      uint64_t v42 = v59;
      uint64_t v43 = type metadata accessor for Set(0, v59, v61);
      uint64_t v44 = v55;
      LOBYTE(v41) = Set.insert(_:)(v55, v41, v43);
      (*(void (**)(uint64_t *, uint64_t))(v54 + 8))(v44, v42);
      uint64_t v45 = v66;
      if (v41)
      {
        uint64_t v46 = v57;
        uint64_t v47 = v73;
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v70 + 16))(v57, v66, v73);
        uint64_t v48 = type metadata accessor for Array(0, v47);
        Array.append(_:)(v46, v48);
      }
      uint64_t v49 = v73;
      (*(void (**)(uint64_t *, uint64_t))(v70 + 8))(v45, v73);
      uint64_t v39 = (uint64_t)v60;
      dispatch thunk of IteratorProtocol.next()(v71, v67);
      int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v39, 1, v49);
      uint64_t v40 = v45;
      uint64_t v14 = v56;
      uint64_t v8 = v69;
      if (EnumTagSinglePayload == 1) {
        goto LABEL_10;
      }
    }
    (*(void (**)(uint64_t *, uint64_t))(v70 + 8))(v66, v73);
    (*(void (**)(uint64_t *, uint64_t))(v62 + 8))(v72, v71);
    swift_bridgeObjectRelease(v65);
    return swift_bridgeObjectRelease((_BYTE)v64);
  }
}

uint64_t LazySequenceProtocol.uniqued<A>(on:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v15 = a4;
  uint64_t v17 = v6;
  uint64_t v16 = a6;
  uint64_t v10 = *(void *)(a3 - 8);
  int64_t v11 = *(void *)(v10 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  (*(void (**)(uint64_t *, uint64_t))(v10 + 16))(&v15, v7);
  UniquedSequence.init(base:projection:)((uint64_t)&v15, a1, a2, a3, v15, *(void *)(a5 + 8), v16);
  return swift_retain();
}

uint64_t type metadata accessor for UniquedSequence.Iterator(uint64_t a1, uint64_t a2)
{
  return swift_getGenericMetadata(a1, a2, &nominal type descriptor for UniquedSequence.Iterator);
}

uint64_t sub_32CBA5()
{
  return swift_deallocObject(v0, 40, 7);
}

uint64_t partial apply for closure #1 in Sequence<>.uniqued()(uint64_t a1)
{
  return closure #1 in Sequence<>.uniqued()(a1, *(void *)(v1 + 16), *(void *)(v1 + 24));
}

uint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in UniquedSequence<A, B>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UniquedSequence<A, B>.Iterator, a1);
}

uint64_t base witness table accessor for Sequence in <> UniquedSequence<A, B>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UniquedSequence<A, B>, a1);
}

uint64_t type metadata completion function for UniquedSequence(uint64_t a1)
{
  uint64_t v1 = swift_checkMetadataState(319, *(void *)(a1 + 16));
  uint64_t v2 = v1;
  if (v3 <= 0x3F)
  {
    v5[0] = *(void *)(v1 - 8) + 64;
    v5[1] = (char *)&value witness table for () + 64;
    uint64_t v2 = 0;
    swift_initStructMetadata(a1, 0, 2, v5, a1 + 48);
  }
  return v2;
}

uint64_t *initializeBufferWithCopyOfBuffer for UniquedSequence(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  unint64_t v3 = a1;
  uint64_t v4 = *(void *)(*(void *)(a3 + 16) - 8);
  int v5 = *(_DWORD *)(v4 + 80);
  if ((v5 & 0x1000F8) != 0 || (uint64_t v6 = *(void *)(v4 + 64), ((v6 + 7) & 0xFFFFFFFFFFFFFFF8) + 16 > 0x18))
  {
    uint64_t v8 = *a2;
    uint64_t *v3 = *a2;
    unint64_t v3 = (uint64_t *)(v8 + (((v5 | 7) + 16) & ~(v5 | 7u)));
  }
  else
  {
    (*(void (**)(uint64_t *, uint64_t *))(v4 + 16))(a1, a2);
    unint64_t v7 = ((unint64_t)a2 + v6 + 7) & 0xFFFFFFFFFFFFFFF8;
    uint64_t v8 = *(void *)(v7 + 8);
    *(_OWORD *)(((unint64_t)v3 + v6 + 7) & 0xFFFFFFFFFFFFFFF8) = *(_OWORD *)v7;
  }
  swift_retain(v8);
  return v3;
}

uint64_t destroy for UniquedSequence(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(*(void *)(a2 + 16) - 8);
  (*(void (**)(void))(v2 + 8))();
  return swift_release(*(void *)(((a1 + *(void *)(v2 + 64) + 7) & 0xFFFFFFFFFFFFFFF8) + 8));
}

uint64_t initializeWithCopy for UniquedSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(*(void *)(a3 + 16) - 8);
  (*(void (**)(uint64_t))(v4 + 16))(a1);
  uint64_t v5 = *(void *)(v4 + 64);
  uint64_t v6 = (_OWORD *)((v5 + a1 + 7) & 0xFFFFFFFFFFFFFFF8);
  unint64_t v7 = (a2 + v5 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v8 = *(void *)(v7 + 8);
  *uint64_t v6 = *(_OWORD *)v7;
  swift_retain(v8);
  return a1;
}

uint64_t assignWithCopy for UniquedSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(*(void *)(a3 + 16) - 8);
  (*(void (**)(uint64_t))(v4 + 24))(a1);
  uint64_t v5 = *(void *)(v4 + 64);
  unint64_t v6 = (v5 + a1 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v7 = (a2 + v5 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v8 = *(void *)(v6 + 8);
  uint64_t v9 = *(void *)(v7 + 8);
  *(_OWORD *)unint64_t v6 = *(_OWORD *)v7;
  swift_retain(v9);
  swift_release(v8);
  return a1;
}

uint64_t initializeWithTake for UniquedSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(*(void *)(a3 + 16) - 8);
  (*(void (**)(uint64_t))(v3 + 32))(a1);
  *(_OWORD *)((*(void *)(v3 + 64) + a1 + 7) & 0xFFFFFFFFFFFFFFF8) = *(_OWORD *)((a2 + *(void *)(v3 + 64) + 7) & 0xFFFFFFFFFFFFFFF8);
  return a1;
}

uint64_t assignWithTake for UniquedSequence(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(*(void *)(a3 + 16) - 8);
  (*(void (**)(uint64_t))(v4 + 40))(a1);
  uint64_t v5 = *(void *)(v4 + 64);
  unint64_t v6 = (v5 + a1 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v7 = *(void *)(v6 + 8);
  *(_OWORD *)unint64_t v6 = *(_OWORD *)((a2 + v5 + 7) & 0xFFFFFFFFFFFFFFF8);
  swift_release(v7);
  return a1;
}

uint64_t getEnumTagSinglePayload for UniquedSequence(int *a1, unsigned int a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(a3 + 16);
  uint64_t v5 = *(void *)(v4 - 8);
  uint64_t v6 = *(unsigned int *)(v5 + 84);
  unsigned int v7 = 0x7FFFFFFF;
  if (v6 >= 0x80000000) {
    unsigned int v7 = *(_DWORD *)(v5 + 84);
  }
  if (!a2) {
    return 0;
  }
  uint64_t v8 = *(void *)(v5 + 64);
  if (v7 >= a2)
  {
LABEL_20:
    if (v6 < 0x7FFFFFFF)
    {
      LODWORD(v18) = -1;
      if (*(void *)(((unint64_t)a1 + v8 + 7) & 0xFFFFFFFFFFFFFFF8) < 0xFFFFFFFFuLL) {
        uint64_t v18 = *(void *)(((unint64_t)a1 + v8 + 7) & 0xFFFFFFFFFFFFFFF8);
      }
      return (v18 + 1);
    }
    else
    {
      return __swift_getEnumTagSinglePayload((uint64_t)a1, v6, v4);
    }
  }
  else
  {
    unint64_t v9 = ((v8 + 7) & 0xFFFFFFFFFFFFFFF8) + 16;
    int v10 = a2 - v7 + 1;
    unsigned int v11 = 2;
    if ((v9 & 0xFFFFFFF8) == 0) {
      unsigned int v11 = v10;
    }
    unsigned int v12 = 1;
    if (v11 >= 0x100) {
      unsigned int v12 = 2 * (v11 >= 0x10000) + 2;
    }
    uint64_t v13 = 0;
    if (v11 >= 2) {
      uint64_t v13 = v12;
    }
    switch(v13)
    {
      case 0:
        goto LABEL_20;
      case 1:
        int v14 = *((unsigned __int8 *)a1 + v9);
        goto LABEL_16;
      case 2:
        int v14 = *(unsigned __int16 *)((char *)a1 + v9);
        goto LABEL_16;
      case 3:
        BUG();
      case 4:
        int v14 = *(int *)((char *)a1 + v9);
LABEL_16:
        if (!v14) {
          goto LABEL_20;
        }
        int v16 = v14 - 1;
        int v17 = 0;
        if ((v9 & 0xFFFFFFF8) != 0)
        {
          int v16 = 0;
          int v17 = *a1;
        }
        uint64_t result = v7 + (v16 | v17) + 1;
        break;
    }
  }
  return result;
}

unint64_t storeEnumTagSinglePayload for UniquedSequence(_DWORD *a1, uint64_t a2, unsigned int a3, uint64_t a4)
{
  uint64_t v5 = *(void *)(a4 + 16);
  uint64_t v6 = *(void *)(v5 - 8);
  uint64_t v7 = *(unsigned int *)(v6 + 84);
  unsigned int v8 = 0x7FFFFFFF;
  if (v7 >= 0x80000000) {
    unsigned int v8 = *(_DWORD *)(v6 + 84);
  }
  uint64_t v10 = *(void *)(v6 + 64);
  unint64_t v11 = ((v10 + 7) & 0xFFFFFFFFFFFFFFF8) + 16;
  unsigned int v12 = 0;
  int v13 = 1;
  if (v8 < a3)
  {
    int v14 = a3 - v8 + 1;
    unsigned int v15 = 2;
    if (((v10 + 7) & 0xFFFFFFF8) == 0xFFFFFFF0) {
      unsigned int v15 = v14;
    }
    int v16 = 2 * (v15 >= 0x10000) + 2;
    if (v15 < 0x100) {
      int v16 = 1;
    }
    unsigned int v12 = 0;
    if (v15 >= 2) {
      unsigned int v12 = v16;
    }
  }
  if (a2 > v8)
  {
    if (((v10 + 7) & 0xFFFFFFF8) == 0xFFFFFFF0)
    {
      int v13 = a2 - v8;
    }
    else
    {
      __bzero(a1, v11);
      *a1 = a2 + ~v8;
    }
    unint64_t result = v12;
    switch(v12)
    {
      case 0u:
        return result;
      case 1u:
        *((unsigned char *)a1 + v11) = v13;
        return result;
      case 2u:
        *(_WORD *)((char *)a1 + v11) = v13;
        return result;
      case 3u:
        goto LABEL_29;
      case 4u:
        *(_DWORD *)((char *)a1 + v11) = v13;
        return result;
    }
  }
  unint64_t result = v12;
  switch(v12)
  {
    case 0u:
      break;
    case 1u:
      *((unsigned char *)a1 + v11) = 0;
      break;
    case 2u:
      *(_WORD *)((char *)a1 + v11) = 0;
      break;
    case 3u:
LABEL_29:
      BUG();
    case 4u:
      *(_DWORD *)((char *)a1 + v11) = 0;
      break;
  }
  if (a2)
  {
    if (v7 < 0x7FFFFFFF)
    {
      unint64_t result = ((unint64_t)a1 + v10 + 7) & 0xFFFFFFFFFFFFFFF8;
      if ((int)a2 < 0)
      {
        *(void *)unint64_t result = a2 + 0x80000000;
        *(void *)(result + 8) = 0;
      }
      else
      {
        *(void *)unint64_t result = (a2 - 1);
      }
    }
    else
    {
      return __swift_storeEnumTagSinglePayload((uint64_t)a1, a2, v7, v5);
    }
  }
  return result;
}

uint64_t type metadata instantiation function for UniquedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_allocateGenericValueMetadata(a1, a2, a3, 48);
}

uint64_t type metadata completion function for UniquedSequence.Iterator(uint64_t a1)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(319, *(void *)(a1 + 32), *(void *)(a1 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v2 = AssociatedTypeWitness;
  if (v3 <= 0x3F)
  {
    v5[0] = *(void *)(AssociatedTypeWitness - 8) + 64;
    v5[1] = (char *)&value witness table for () + 64;
    v5[2] = (char *)&value witness table for Builtin.BridgeObject + 64;
    uint64_t v2 = 0;
    swift_initStructMetadata(a1, 0, 3, v5, a1 + 48);
  }
  return v2;
}

uint64_t *initializeBufferWithCopyOfBuffer for UniquedSequence.Iterator(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  unint64_t v3 = a1;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v5 = *(void *)(AssociatedTypeWitness - 8);
  int v6 = *(_DWORD *)(v5 + 80);
  if ((v6 & 0x1000F8) != 0
    || (uint64_t v7 = *(void *)(v5 + 64), ((((v7 + 7) & 0xFFFFFFFFFFFFFFF8) + 23) & 0xFFFFFFFFFFFFFFF8) + 8 > 0x18))
  {
    uint64_t v13 = *a2;
    uint64_t *v3 = *a2;
    uint64_t v14 = v13 + (((v6 | 7) + 16) & ~(v6 | 7u));
    swift_retain(v13);
    return (uint64_t *)v14;
  }
  else
  {
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v5 + 16))(a1, a2, AssociatedTypeWitness);
    unsigned int v8 = (_OWORD *)(((unint64_t)a1 + v7 + 7) & 0xFFFFFFFFFFFFFFF8);
    unint64_t v9 = ((unint64_t)a2 + v7 + 7) & 0xFFFFFFFFFFFFFFF8;
    uint64_t v10 = *(void *)(v9 + 8);
    _OWORD *v8 = *(_OWORD *)v9;
    unint64_t v11 = (uint64_t *)((v9 + 23) & 0xFFFFFFFFFFFFFFF8);
    uint64_t v12 = *v11;
    *(void *)(((unint64_t)v8 + 23) & 0xFFFFFFFFFFFFFFF8) = *v11;
    swift_retain(v10);
    swift_bridgeObjectRetain(v12);
  }
  return v3;
}

uint64_t destroy for UniquedSequence.Iterator(uint64_t a1, uint64_t a2)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a2 + 32), *(void *)(a2 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v3 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t))(v3 + 8))(a1, AssociatedTypeWitness);
  unint64_t v4 = (*(void *)(v3 + 64) + a1 + 7) & 0xFFFFFFFFFFFFFFF8;
  swift_release(*(void *)(v4 + 8));
  return swift_bridgeObjectRelease(*(void *)((v4 + 23) & 0xFFFFFFFFFFFFFFF8));
}

uint64_t initializeWithCopy for UniquedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v5 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v5 + 16))(a1, a2, AssociatedTypeWitness);
  uint64_t v6 = *(void *)(v5 + 64);
  uint64_t v7 = (_OWORD *)((v6 + a1 + 7) & 0xFFFFFFFFFFFFFFF8);
  unint64_t v8 = (a2 + v6 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v9 = *(void *)(v8 + 8);
  *uint64_t v7 = *(_OWORD *)v8;
  uint64_t v10 = (uint64_t *)((v8 + 23) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v11 = *v10;
  *(void *)(((unint64_t)v7 + 23) & 0xFFFFFFFFFFFFFFF8) = *v10;
  swift_retain(v9);
  swift_bridgeObjectRetain(v11);
  return a1;
}

uint64_t assignWithCopy for UniquedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v5 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v5 + 24))(a1, a2, AssociatedTypeWitness);
  uint64_t v6 = *(void *)(v5 + 64);
  unint64_t v7 = (v6 + a1 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v8 = (v6 + a2 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v9 = *(void *)(v7 + 8);
  uint64_t v10 = *(void *)(v8 + 8);
  *(_OWORD *)unint64_t v7 = *(_OWORD *)v8;
  swift_retain(v10);
  swift_release(v9);
  uint64_t v11 = (uint64_t *)((v7 + 23) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v12 = (uint64_t *)((v8 + 23) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v13 = *v12;
  uint64_t v14 = *v11;
  uint64_t *v11 = *v12;
  swift_bridgeObjectRetain(v13);
  swift_bridgeObjectRelease(v14);
  return a1;
}

uint64_t initializeWithTake for UniquedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v4 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v4 + 32))(a1, a2, AssociatedTypeWitness);
  uint64_t v5 = *(void *)(v4 + 64);
  uint64_t v6 = (_OWORD *)((v5 + a1 + 7) & 0xFFFFFFFFFFFFFFF8);
  unint64_t v7 = (_OWORD *)((a2 + v5 + 7) & 0xFFFFFFFFFFFFFFF8);
  *uint64_t v6 = *v7;
  *(void *)(((unint64_t)v6 + 23) & 0xFFFFFFFFFFFFFFF8) = *(void *)(((unint64_t)v7 + 23) & 0xFFFFFFFFFFFFFFF8);
  return a1;
}

uint64_t assignWithTake for UniquedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v5 = *(void *)(AssociatedTypeWitness - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v5 + 40))(a1, a2, AssociatedTypeWitness);
  uint64_t v6 = *(void *)(v5 + 64);
  unint64_t v7 = (v6 + a1 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v8 = (_OWORD *)((v6 + a2 + 7) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v9 = *(void *)(v7 + 8);
  *(_OWORD *)unint64_t v7 = *v8;
  swift_release(v9);
  uint64_t v10 = (uint64_t *)((v7 + 23) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v11 = *v10;
  uint64_t *v10 = *(void *)(((unint64_t)v8 + 23) & 0xFFFFFFFFFFFFFFF8);
  swift_bridgeObjectRelease(v11);
  return a1;
}

uint64_t getEnumTagSinglePayload for UniquedSequence.Iterator(int *a1, unsigned int a2, uint64_t a3)
{
  unsigned int v5 = 0;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, *(void *)(a3 + 32), *(void *)(a3 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v7 = *(void *)(AssociatedTypeWitness - 8);
  uint64_t v8 = *(unsigned int *)(v7 + 84);
  unsigned int v9 = 0x7FFFFFFF;
  if (v8 >= 0x80000000) {
    unsigned int v9 = *(_DWORD *)(v7 + 84);
  }
  if (a2)
  {
    uint64_t v10 = *(void *)(v7 + 64);
    if (v9 >= a2)
    {
LABEL_19:
      if (v8 >= 0x7FFFFFFF) {
        return __swift_getEnumTagSinglePayload((uint64_t)a1, v8, AssociatedTypeWitness);
      }
      LODWORD(v20) = -1;
      if (*(void *)(((unint64_t)a1 + v10 + 7) & 0xFFFFFFFFFFFFFFF8) < 0xFFFFFFFFuLL) {
        uint64_t v20 = *(void *)(((unint64_t)a1 + v10 + 7) & 0xFFFFFFFFFFFFFFF8);
      }
      return (v20 + 1);
    }
    else
    {
      unint64_t v11 = ((((v10 + 7) & 0xFFFFFFFFFFFFFFF8) + 23) & 0xFFFFFFFFFFFFFFF8) + 8;
      int v12 = a2 - v9 + 1;
      unsigned int v13 = 2;
      if ((v11 & 0xFFFFFFF8) == 0) {
        unsigned int v13 = v12;
      }
      unsigned int v14 = 1;
      if (v13 >= 0x100) {
        unsigned int v14 = 2 * (v13 >= 0x10000) + 2;
      }
      uint64_t v15 = 0;
      if (v13 >= 2) {
        uint64_t v15 = v14;
      }
      switch(v15)
      {
        case 0:
          goto LABEL_19;
        case 1:
          int v16 = *((unsigned __int8 *)a1 + v11);
          goto LABEL_15;
        case 2:
          int v16 = *(unsigned __int16 *)((char *)a1 + v11);
          goto LABEL_15;
        case 3:
          BUG();
        case 4:
          int v16 = *(int *)((char *)a1 + v11);
LABEL_15:
          if (!v16) {
            goto LABEL_19;
          }
          int v17 = v16 - 1;
          int v18 = 0;
          if ((v11 & 0xFFFFFFF8) != 0)
          {
            int v17 = 0;
            int v18 = *a1;
          }
          unsigned int v5 = v9 + (v17 | v18) + 1;
          break;
      }
    }
  }
  return v5;
}

unint64_t storeEnumTagSinglePayload for UniquedSequence.Iterator(_DWORD *a1, uint64_t a2, unsigned int a3, uint64_t a4)
{
  unsigned int v5 = 0;
  unint64_t result = swift_getAssociatedTypeWitness(0, *(void *)(a4 + 32), *(void *)(a4 + 16), &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v7 = *(void *)(result - 8);
  uint64_t v8 = *(unsigned int *)(v7 + 84);
  unsigned int v9 = 0x7FFFFFFF;
  if (v8 >= 0x80000000) {
    unsigned int v9 = *(_DWORD *)(v7 + 84);
  }
  uint64_t v10 = *(void *)(v7 + 64);
  unint64_t v11 = ((((v10 + 7) & 0xFFFFFFFFFFFFFFF8) + 23) & 0xFFFFFFFFFFFFFFF8) + 8;
  int v12 = 1;
  if (v9 < a3)
  {
    int v13 = a3 - v9 + 1;
    unsigned int v14 = 2;
    if (((((v10 + 7) & 0xFFFFFFF8) + 23) & 0xFFFFFFF8) == 0xFFFFFFF8) {
      unsigned int v14 = v13;
    }
    int v15 = 2 * (v14 >= 0x10000) + 2;
    if (v14 < 0x100) {
      int v15 = 1;
    }
    unsigned int v5 = 0;
    if (v14 >= 2) {
      unsigned int v5 = v15;
    }
  }
  if (a2 > v9)
  {
    if (((((v10 + 7) & 0xFFFFFFF8) + 23) & 0xFFFFFFF8) == 0xFFFFFFF8)
    {
      int v12 = a2 - v9;
    }
    else
    {
      __bzero(a1, ((((v10 + 7) & 0xFFFFFFFFFFFFFFF8) + 23) & 0xFFFFFFFFFFFFFFF8) + 8);
      *a1 = a2 + ~v9;
    }
    unint64_t result = v5;
    switch(v5)
    {
      case 0u:
        return result;
      case 1u:
        *((unsigned char *)a1 + v11) = v12;
        return result;
      case 2u:
        *(_WORD *)((char *)a1 + v11) = v12;
        return result;
      case 3u:
        goto LABEL_29;
      case 4u:
        *(_DWORD *)((char *)a1 + v11) = v12;
        return result;
    }
  }
  switch(v5)
  {
    case 0u:
      break;
    case 1u:
      *((unsigned char *)a1 + v11) = 0;
      break;
    case 2u:
      *(_WORD *)((char *)a1 + v11) = 0;
      break;
    case 3u:
LABEL_29:
      BUG();
    case 4u:
      *(_DWORD *)((char *)a1 + v11) = 0;
      break;
  }
  if (a2)
  {
    if (v8 < 0x7FFFFFFF)
    {
      unint64_t result = ((unint64_t)a1 + v10 + 7) & 0xFFFFFFFFFFFFFFF8;
      if ((int)a2 < 0)
      {
        *(void *)unint64_t result = a2 + 0x80000000;
        *(void *)(result + 8) = 0;
      }
      else
      {
        *(void *)unint64_t result = (a2 - 1);
      }
    }
    else
    {
      return __swift_storeEnumTagSinglePayload((uint64_t)a1, a2, v8, result);
    }
  }
  return result;
}

uint64_t Heap._UnsafeHandle.buffer.getter(uint64_t a1)
{
  return a1;
}

void Heap._UnsafeHandle.buffer.setter(uint64_t a1, uint64_t a2)
{
  *uint64_t v2 = a1;
  v2[1] = a2;
}

void (*Heap._UnsafeHandle.buffer.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t Heap._UnsafeHandle.init(_:)(uint64_t a1)
{
  return a1;
}

uint64_t Heap._update<A>(_:)(void (*a1)(uint64_t, uint64_t), uint64_t a2, uint64_t a3, uint64_t a4)
{
  v10[2] = a4;
  v10[4] = a2;
  v10[3] = (uint64_t)a1;
  v10[5] = v4;
  uint64_t v6 = *(void *)(a3 + 16);
  type metadata accessor for ContiguousArray(0, v6);
  ContiguousArray._makeMutableAndUnique()();
  uint64_t v7 = *(void *)(*(void *)v5 + 16);
  int v8 = *(unsigned __int8 *)(*(void *)(v6 - 8) + 80);
  v10[0] = *(void *)v5 + ((v8 + 32) & ~v8);
  v10[1] = v7;
  a1(v10[0], v7);
  return $defer #1 <A><A1>() in ContiguousArray.withUnsafeMutableBufferPointer<A>(_:)(v10, v10[0], v7, v5, v6);
}

uint64_t Heap._UnsafeHandle.count.getter(uint64_t a1, uint64_t a2)
{
  return a2;
}

uint64_t Heap._UnsafeHandle.subscript.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(a5 - 8) + 16))(v5, *(void *)(*(void *)(a5 - 8) + 72) * a1 + a3, a5);
}

void (*Heap._UnsafeHandle.subscript.modify(void *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6))(void (***a1)(void, void))
{
  int v8 = malloc(0x28uLL);
  *a1 = v8;
  v8[4] = UnsafeMutableBufferPointer.subscript.modify(v8, a2, a4, a5, a6);
  return Heap._UnsafeHandle.subscript.modify;
}

void Heap._UnsafeHandle.subscript.modify(void (***a1)(void, void))
{
  uint64_t v1 = *a1;
  v1[4](v1, 0);
  free(v1);
}

uint64_t Heap._UnsafeHandle.subscript.setter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(a6 - 8) + 40))(*(void *)(*(void *)(a6 - 8) + 72) * a2 + a4, a1, a6);
}

uint64_t Heap._UnsafeHandle.ptr(to:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v6 = UnsafeMutableBufferPointer.baseAddress.getter(a3, a4, a5);
  if (!v6) {
    BUG();
  }
  return *(void *)(*(void *)(a5 - 8) + 72) * a1 + v6;
}

uint64_t Heap._UnsafeHandle.extract(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v6 = UnsafeMutableBufferPointer.baseAddress.getter(a3, a4, a5);
  if (!v6) {
    BUG();
  }
  return UnsafeMutablePointer.move()(*(void *)(*(void *)(a5 - 8) + 72) * a1 + v6, a5);
}

uint64_t Heap._UnsafeHandle.initialize(_:to:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v15[0] = a3;
  uint64_t v7 = *(void *)(a6 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  unsigned int v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v11 = UnsafeMutableBufferPointer.baseAddress.getter(a4, a5, a6);
  if (!v11) {
    BUG();
  }
  uint64_t v12 = *(void *)(v7 + 72) * a1 + v11;
  uint64_t v13 = v15[0];
  (*(void (**)(void *, void, uint64_t))(v7 + 16))(v15, v15[0], a6);
  (*(void (**)(uint64_t, void *, uint64_t))(v7 + 32))(v12, v15, a6);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v7 + 8))(v13, a6);
}

void Heap._UnsafeHandle.swapAt(_:_:)(Swift::Int a1, uint64_t a2, Swift::Int a3)
{
}

uint64_t Heap._UnsafeHandle.swapAt(_:with:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v8 = UnsafeMutableBufferPointer.baseAddress.getter(a4, a5, a6);
  return swap<A>(_:_:)(v8 + *(void *)(*(void *)(a6 - 8) + 72) * a1, a3, a6);
}

uint64_t Heap._UnsafeHandle.minValue(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  v21[0] = a4;
  uint64_t v23 = a3;
  v21[1] = a2;
  uint64_t v24 = a1;
  unsigned int v9 = *(void **)(a7 - 8);
  int64_t v10 = v9[8];
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v22 = v21;
  uint64_t v13 = alloca(v10);
  unsigned int v14 = alloca(v10);
  int v15 = (void (*)(void *, uint64_t, uint64_t))v9[2];
  uint64_t v16 = v9[9];
  v15(v21, a5 + a1 * v16, a7);
  uint64_t v17 = a5 + v23 * v16;
  int v18 = v22;
  v15(v22, v17, a7);
  LOBYTE(v17) = dispatch thunk of static Comparable.< infix(_:_:)(v21, v18, a7, a8);
  uint64_t v19 = (void (*)(void *, uint64_t))v9[1];
  v19(v18, a7);
  v19(v21, a7);
  uint64_t result = v23;
  if (v17) {
    return v24;
  }
  return result;
}

uint64_t Heap._UnsafeHandle.maxValue(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  v21[0] = a4;
  uint64_t v23 = a3;
  v21[1] = a2;
  uint64_t v24 = a1;
  unsigned int v9 = *(void **)(a7 - 8);
  int64_t v10 = v9[8];
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v22 = v21;
  uint64_t v13 = alloca(v10);
  unsigned int v14 = alloca(v10);
  int v15 = (void (*)(void *, uint64_t, uint64_t))v9[2];
  uint64_t v16 = v9[9];
  v15(v21, a5 + a1 * v16, a7);
  uint64_t v17 = a5 + v23 * v16;
  int v18 = v22;
  v15(v22, v17, a7);
  LOBYTE(v17) = dispatch thunk of static Comparable.< infix(_:_:)(v21, v18, a7, a8);
  uint64_t v19 = (void (*)(void *, uint64_t))v9[1];
  v19(v18, a7);
  v19(v21, a7);
  uint64_t result = v24;
  if (v17) {
    return v23;
  }
  return result;
}

Swift::Int Heap._UnsafeHandle.bubbleUp(_:)(Swift::Int a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v52 = a6;
  uint64_t v51 = a4;
  uint64_t v8 = *(void (**)(Swift::Int *, uint64_t))(a5 - 8);
  int64_t v9 = *((void *)v8 + 8);
  int64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v50 = &v47;
  uint64_t v12 = alloca(v9);
  Swift::Int result = (v9 + 15) & 0xFFFFFFFFFFFFFFF0;
  unsigned int v14 = alloca(v9);
  uint64_t v57 = &v47;
  if (a1)
  {
    uint64_t v53 = a2;
    int v15 = (void (*)(Swift::Int *, uint64_t, uint64_t))*((void *)v8 + 2);
    uint64_t v55 = v8;
    uint64_t v16 = *((void *)v8 + 9);
    Swift::Int v56 = a1;
    v15(v57, a3 + a1 * v16, a5);
    uint64_t v49 = v16;
    Swift::Int v47 = (a1 - 1) / 2;
    Swift::Int v17 = a3 + v47 * v16;
    int v18 = v50;
    uint64_t v48 = v15;
    v15(v50, v17, a5);
    uint64_t v19 = a3;
    uint64_t v20 = v57;
    if (v53) {
      char v21 = dispatch thunk of static Comparable.< infix(_:_:)(v57, v18, a5, v52);
    }
    else {
      char v21 = dispatch thunk of static Comparable.> infix(_:_:)(v57, v18, a5, v52);
    }
    uint64_t v22 = v18;
    char v23 = v21;
    uint64_t v24 = (void (*)(Swift::Int *, uint64_t))*((void *)v55 + 1);
    v24(v22, a5);
    uint64_t v55 = v24;
    v24(v20, a5);
    if (v23)
    {
      char v25 = v53 - 1;
      Swift::Int v26 = v47;
      UnsafeMutableBufferPointer.swapAt(_:_:)(v56, v47);
      Swift::Int result = v26;
    }
    else
    {
      Swift::Int result = v56;
      char v25 = v53;
    }
    uint64_t v27 = v19;
    if (v25)
    {
      if (result >= 3)
      {
        uint64_t v54 = v19;
        do
        {
          Swift::Int v56 = result;
          unint64_t v38 = result - 3;
          Swift::Int v39 = (unint64_t)(result - 3) >> 2;
          uint64_t v40 = v49;
          Swift::Int v41 = v27 + result * v49;
          uint64_t v42 = v48;
          v48(v57, v41, a5);
          Swift::Int v43 = v54 + v40 * v39;
          uint64_t v44 = v50;
          v42(v50, v43, a5);
          LOBYTE(v42) = dispatch thunk of static Comparable.> infix(_:_:)(v57, v44, a5, v52);
          uint64_t v45 = v44;
          uint64_t v46 = (uint64_t (*)(Swift::Int *, uint64_t))v55;
          v55(v45, a5);
          Swift::Int result = v46(v57, a5);
          BOOL v37 = (v42 & 1) == 0;
          uint64_t v27 = v54;
          if (v37) {
            break;
          }
          UnsafeMutableBufferPointer.swapAt(_:_:)(v56, v39);
          Swift::Int result = v39;
        }
        while (v38 > 0xB);
      }
    }
    else if (result >= 3)
    {
      uint64_t v54 = v19;
      do
      {
        Swift::Int v56 = result;
        unint64_t v28 = result - 3;
        Swift::Int v29 = (unint64_t)(result - 3) >> 2;
        uint64_t v30 = v49;
        Swift::Int v31 = v27 + result * v49;
        uint64_t v32 = v48;
        v48(v57, v31, a5);
        Swift::Int v33 = v54 + v30 * v29;
        uint64_t v34 = v50;
        v32(v50, v33, a5);
        LOBYTE(v32) = dispatch thunk of static Comparable.< infix(_:_:)(v57, v34, a5, v52);
        uint64_t v35 = v34;
        uint64_t v36 = (uint64_t (*)(Swift::Int *, uint64_t))v55;
        v55(v35, a5);
        Swift::Int result = v36(v57, a5);
        BOOL v37 = (v32 & 1) == 0;
        uint64_t v27 = v54;
        if (v37) {
          break;
        }
        UnsafeMutableBufferPointer.swapAt(_:_:)(v56, v29);
        Swift::Int result = v29;
      }
      while (v28 > 0xB);
    }
  }
  return result;
}

uint64_t Heap._UnsafeHandle.trickleDownMin(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v142 = a6;
  uint64_t v6 = a5;
  uint64_t v134 = a2;
  uint64_t v8 = a1;
  uint64_t v9 = *(void *)(a5 - 8);
  int64_t v10 = *(void *)(v9 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v132 = &v129;
  uint64_t v13 = alloca(v10);
  unsigned int v14 = alloca(v10);
  uint64_t v138 = &v129;
  int v15 = alloca(v10);
  uint64_t v16 = alloca(v10);
  uint64_t v131 = &v129;
  Swift::Int v17 = alloca(v10);
  int v18 = alloca(v10);
  Swift::OpaquePointer v130 = &v129;
  uint64_t v19 = alloca(v10);
  uint64_t v20 = alloca(v10);
  uint64_t v135 = &v129;
  char v21 = alloca(v10);
  uint64_t v22 = alloca(v10);
  uint64_t v144 = &v129;
  char v23 = alloca(v10);
  uint64_t v24 = alloca(v10);
  char v25 = &v129;
  uint64_t v147 = a3;
  uint64_t v26 = UnsafeMutableBufferPointer.baseAddress.getter(a3, a4, a5);
  if (!v26) {
    BUG();
  }
  uint64_t v145 = *(void *)(v9 + 72);
  UnsafeMutablePointer.move()(a1 * v145 + v26, v6);
  uint64_t v27 = 4 * a1 + 3;
  uint64_t v28 = v9;
  uint64_t v29 = 4 * a1 + 6;
  uint64_t v137 = a4;
  uint64_t v143 = &v129;
  uint64_t v149 = v6;
  uint64_t v136 = v28;
  if (v29 < a4)
  {
    int v148 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v28 + 16);
    while (1)
    {
      uint64_t v139 = v27;
      uint64_t v140 = v8;
      uint64_t v30 = v27 + 1;
      uint64_t v31 = v145;
      uint64_t v32 = v147;
      uint64_t v33 = v147 + v145 * v27;
      uint64_t v34 = v6;
      uint64_t v35 = v148;
      v148(v144, v33, v34);
      uint64_t v133 = (void (*)(void, void, void))v30;
      uint64_t v36 = v32 + v31 * v30;
      BOOL v37 = v135;
      v35(v135, v36, v149);
      unint64_t v38 = v144;
      char v39 = dispatch thunk of static Comparable.< infix(_:_:)(v144, v37, v149, v142);
      uint64_t v40 = v149;
      LOBYTE(v146) = v39;
      Swift::Int v41 = *(void (**)(uint64_t *, uint64_t))(v136 + 8);
      v41(v37, v149);
      uint64_t v141 = v41;
      v41(v38, v40);
      uint64_t v42 = v139;
      Swift::Int v43 = (void (*)(void, void, void))v139;
      if ((v146 & 1) == 0) {
        Swift::Int v43 = v133;
      }
      uint64_t v146 = (uint64_t)v43;
      v139 += 2;
      uint64_t v44 = v145;
      uint64_t v45 = v147;
      uint64_t v46 = v144;
      uint64_t v47 = v40;
      uint64_t v48 = v148;
      v148(v144, v147 + v145 * (v42 + 2), v47);
      uint64_t v49 = v45 + v44 * v29;
      uint64_t v50 = v46;
      uint64_t v51 = v135;
      v48(v135, v49, v149);
      char v52 = dispatch thunk of static Comparable.< infix(_:_:)(v50, v51, v149, v142);
      uint64_t v53 = v149;
      LOBYTE(v44) = v52;
      uint64_t v54 = v51;
      uint64_t v55 = v141;
      v141(v54, v149);
      v55(v50, v53);
      if ((v44 & 1) == 0) {
        uint64_t v139 = v29;
      }
      uint64_t v56 = v145;
      uint64_t v57 = v147;
      uint64_t v58 = v148;
      v148(v50, v147 + v145 * v146, v53);
      uint64_t v59 = v57 + v56 * v139;
      uint64_t v60 = v135;
      v58(v135, v59, v53);
      char v61 = dispatch thunk of static Comparable.< infix(_:_:)(v50, v60, v149, v142);
      uint64_t v62 = v149;
      LOBYTE(v58) = v61;
      uint64_t v63 = v60;
      uint64_t v64 = v141;
      v141(v63, v149);
      v64(v50, v62);
      uint64_t v65 = v146;
      if ((v58 & 1) == 0) {
        uint64_t v65 = v139;
      }
      uint64_t v146 = v65;
      uint64_t v66 = v56 * v65;
      uint64_t v67 = v147;
      uint64_t v68 = v144;
      v148(v144, v147 + v66, v62);
      char v69 = dispatch thunk of static Comparable.< infix(_:_:)(v68, v143, v149, v142);
      uint64_t v6 = v149;
      char v70 = v69;
      v141(v68, v149);
      if ((v70 & 1) == 0) {
        goto LABEL_24;
      }
      uint64_t v71 = v137;
      uint64_t v72 = UnsafeMutableBufferPointer.baseAddress.getter(v67, v137, v6);
      uint64_t v73 = v140;
      if (!v72) {
        BUG();
      }
      uint64_t v74 = v66 + v72;
      uint64_t v75 = v130;
      UnsafeMutablePointer.move()(v74, v6);
      uint64_t v76 = UnsafeMutableBufferPointer.baseAddress.getter(v67, v71, v6);
      if (!v76) {
        BUG();
      }
      uint64_t v77 = v145 * v73 + v76;
      uint64_t v78 = v144;
      BOOL v79 = v148;
      v148(v144, (uint64_t)v75, v6);
      (*(void (**)(uint64_t, uint64_t *, uint64_t))(v136 + 32))(v77, v78, v149);
      v141(v75, v149);
      uint64_t v80 = v145 * ((v146 - 1) / 2);
      v79(v78, v147 + v80, v149);
      char v25 = v143;
      char v81 = dispatch thunk of static Comparable.< infix(_:_:)(v78, v143, v149, v142);
      uint64_t v6 = v149;
      LOBYTE(v79) = v81;
      v141(v78, v149);
      BOOL v82 = (v79 & 1) == 0;
      uint64_t v83 = v137;
      if (!v82)
      {
        uint64_t v84 = UnsafeMutableBufferPointer.baseAddress.getter(v147, v137, v6);
        swap<A>(_:_:)(v84 + v80, v25, v6);
      }
      uint64_t v27 = 4 * v146 + 3;
      uint64_t v29 = 4 * v146 + 6;
      v134 += 2;
      uint64_t v8 = v146;
      if (v29 >= v83)
      {
        uint64_t v85 = v134;
        uint64_t v86 = (char *)(v134 + 2);
        uint64_t v8 = v146;
        goto LABEL_18;
      }
    }
  }
  uint64_t v85 = v134;
  uint64_t v86 = (char *)(v134 + 2);
LABEL_18:
  uint64_t v87 = 2 * v8 + 1;
  uint64_t v88 = v147;
  if (v87 >= v137)
  {
    uint64_t v107 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v136 + 16);
    uint64_t v106 = v138;
    v107(v138, v25, v6);
  }
  else
  {
    uint64_t v140 = v8;
    uint64_t v139 = v27;
    uint64_t v89 = Heap._UnsafeHandle._minDescendant(c0:gc0:)(v87, (char *)(v85 + 1), v27, v86, v147, v137, v6, v142);
    uint64_t v90 = v25;
    uint64_t v91 = v136;
    uint64_t v141 = (void (*)(uint64_t *, uint64_t))v89;
    uint64_t v146 = v145 * (void)v89;
    uint64_t v92 = v144;
    int v148 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v136 + 16);
    v148(v144, v88 + v145 * (void)v89, v6);
    char v93 = dispatch thunk of static Comparable.< infix(_:_:)(v92, v90, v149, v142);
    uint64_t v6 = v149;
    char v94 = v93;
    uint64_t v95 = *(void (**)(uint64_t *, uint64_t))(v91 + 8);
    v95(v92, v149);
    if ((v94 & 1) == 0)
    {
LABEL_24:
      uint64_t v106 = v138;
      uint64_t v101 = v143;
      uint64_t v8 = v140;
      goto LABEL_25;
    }
    uint64_t v96 = v147;
    uint64_t v97 = v137;
    uint64_t v98 = UnsafeMutableBufferPointer.baseAddress.getter(v147, v137, v6);
    if (!v98) {
      BUG();
    }
    uint64_t v135 = (uint64_t *)v95;
    uint64_t v99 = v131;
    UnsafeMutablePointer.move()(v146 + v98, v6);
    uint64_t v100 = UnsafeMutableBufferPointer.baseAddress.getter(v96, v97, v6);
    uint64_t v101 = v143;
    if (!v100) {
      BUG();
    }
    uint64_t v102 = v145 * v140 + v100;
    uint64_t v103 = v144;
    v148(v144, (uint64_t)v99, v6);
    uint64_t v133 = *(void (**)(void, void, void))(v136 + 32);
    v133(v102, v103, v6);
    uint64_t v104 = v99;
    uint64_t v105 = v135;
    ((void (*)(uint64_t *, uint64_t))v135)(v104, v6);
    if ((uint64_t)v141 < v139)
    {
      uint64_t v8 = (uint64_t)v141;
      uint64_t v106 = v138;
LABEL_25:
      uint64_t v107 = (void (*)(uint64_t *, uint64_t *, uint64_t))v148;
      v148(v106, (uint64_t)v101, v6);
      goto LABEL_28;
    }
    uint64_t v140 = ((uint64_t)v141 - 1) / 2;
    uint64_t v116 = v145 * v140;
    v148(v103, v147 + v145 * v140, v6);
    char v117 = dispatch thunk of static Comparable.< infix(_:_:)(v103, v101, v149, v142);
    uint64_t v6 = v149;
    char v118 = v117;
    ((void (*)(uint64_t *, uint64_t))v105)(v103, v149);
    if ((v118 & 1) == 0)
    {
      uint64_t v8 = (uint64_t)v141;
      uint64_t v106 = v138;
      uint64_t v101 = v143;
      goto LABEL_25;
    }
    uint64_t v119 = v147;
    uint64_t v120 = v137;
    uint64_t v121 = UnsafeMutableBufferPointer.baseAddress.getter(v147, v137, v6);
    if (!v121) {
      BUG();
    }
    uint64_t v122 = v132;
    UnsafeMutablePointer.move()(v116 + v121, v6);
    uint64_t v123 = UnsafeMutableBufferPointer.baseAddress.getter(v119, v120, v6);
    if (!v123) {
      BUG();
    }
    uint64_t v124 = v146 + v123;
    uint64_t v125 = v144;
    uint64_t v126 = v6;
    uint64_t v127 = (void (*)(uint64_t *, uint64_t *, uint64_t))v148;
    v148(v144, (uint64_t)v122, v126);
    v133(v124, v125, v149);
    uint64_t v128 = v122;
    uint64_t v107 = v127;
    uint64_t v6 = v149;
    ((void (*)(uint64_t *, uint64_t))v135)(v128, v149);
    uint64_t v106 = v138;
    uint64_t v8 = v140;
    v107(v138, v143, v6);
  }
LABEL_28:
  uint64_t v108 = UnsafeMutableBufferPointer.baseAddress.getter(v147, v137, v6);
  if (!v108) {
    BUG();
  }
  uint64_t v109 = v108;
  uint64_t v110 = v107;
  uint64_t v111 = v145 * v8 + v109;
  uint64_t v112 = v144;
  v110(v144, v106, v6);
  uint64_t v113 = v136;
  (*(void (**)(uint64_t, uint64_t *, uint64_t))(v136 + 32))(v111, v112, v6);
  uint64_t v114 = *(void (**)(uint64_t *, uint64_t))(v113 + 8);
  v114(v106, v6);
  return ((uint64_t (*)(uint64_t *, uint64_t))v114)(v143, v6);
}

uint64_t Heap._UnsafeHandle._trickleDownMin(node:value:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v130 = a6;
  uint64_t v6 = a5;
  uint64_t v138 = a3;
  uint64_t v126 = a2;
  uint64_t v8 = *(void **)(a5 - 8);
  int64_t v9 = v8[8];
  int64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v123 = &v121;
  uint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v122 = &v121;
  unsigned int v14 = alloca(v9);
  int v15 = alloca(v9);
  uint64_t v16 = alloca(v9);
  Swift::Int v17 = alloca(v9);
  uint64_t v128 = &v121;
  int v18 = alloca(v9);
  uint64_t v19 = alloca(v9);
  uint64_t v137 = &v121;
  uint64_t result = *a1;
  uint64_t v134 = a1;
  uint64_t v21 = 4 * result + 3;
  uint64_t v124 = (char *)(a1[1] + 2);
  uint64_t v22 = 4 * result + 6;
  uint64_t v127 = a4;
  uint64_t v139 = v6;
  uint64_t v125 = v8;
  if (v22 >= a4)
  {
LABEL_16:
    uint64_t v79 = 2 * result + 1;
    uint64_t v80 = v138;
    if (v79 < a4)
    {
      char v81 = (char *)(v134[1] + 1);
      uint64_t v135 = v21;
      uint64_t v82 = v6;
      uint64_t v83 = v130;
      uint64_t v84 = (uint64_t)Heap._UnsafeHandle._minDescendant(c0:gc0:)(v79, v81, v21, v124, v138, v127, v82, v130);
      uint64_t v132 = v85;
      uint64_t v86 = v125;
      uint64_t v87 = (void (*)(void, void, void))v125[2];
      uint64_t v88 = v125[9];
      uint64_t v133 = v84;
      uint64_t v136 = v88;
      uint64_t v89 = v88 * v84;
      uint64_t v90 = v80 + v88 * v84;
      uint64_t v91 = v137;
      uint64_t v131 = (void (*)(uint64_t *, uint64_t))v87;
      v87(v137, v90, v82);
      char v92 = dispatch thunk of static Comparable.< infix(_:_:)(v91, v126, v139, v83);
      uint64_t v93 = v139;
      LOBYTE(v91) = v92;
      char v94 = (uint64_t (*)(uint64_t *, uint64_t))v86[1];
      uint64_t result = v94(v137, v139);
      uint64_t v95 = v138;
      if (v91)
      {
        uint64_t v128 = (uint64_t *)v94;
        uint64_t v96 = *v134;
        uint64_t v97 = v127;
        uint64_t v98 = UnsafeMutableBufferPointer.baseAddress.getter(v138, v127, v93);
        if (!v98) {
          BUG();
        }
        uint64_t v99 = v89 + v98;
        uint64_t v100 = v122;
        UnsafeMutablePointer.move()(v99, v93);
        uint64_t v101 = UnsafeMutableBufferPointer.baseAddress.getter(v95, v97, v93);
        if (!v101) {
          BUG();
        }
        uint64_t v102 = v136 * v96 + v101;
        uint64_t v103 = v137;
        uint64_t v104 = (void (*)(uint64_t *, uint64_t, uint64_t))v131;
        ((void (*)(uint64_t *, uint64_t *, uint64_t))v131)(v137, v100, v93);
        uint64_t v105 = v102;
        uint64_t v106 = v103;
        uint64_t v129 = v125[4];
        ((void (*)(uint64_t, uint64_t *, uint64_t))v129)(v105, v103, v93);
        uint64_t v107 = v128;
        ((void (*)(uint64_t *, uint64_t))v128)(v100, v93);
        uint64_t v108 = v134;
        uint64_t result = v133;
        *uint64_t v134 = v133;
        v108[1] = (uint64_t)v132;
        if (result >= v135)
        {
          uint64_t v135 = (result - 1) / 2;
          uint64_t v109 = v136 * v135;
          v104(v106, v138 + v136 * v135, v93);
          char v110 = dispatch thunk of static Comparable.< infix(_:_:)(v106, v126, v139, v130);
          uint64_t v111 = v139;
          char v112 = v110;
          uint64_t result = ((uint64_t (*)(uint64_t *, uint64_t))v107)(v137, v139);
          if (v112)
          {
            uint64_t v113 = *v134;
            uint64_t v114 = v127;
            uint64_t v115 = UnsafeMutableBufferPointer.baseAddress.getter(v138, v127, v111);
            if (!v115) {
              BUG();
            }
            uint64_t v116 = v123;
            UnsafeMutablePointer.move()(v109 + v115, v111);
            uint64_t v117 = UnsafeMutableBufferPointer.baseAddress.getter(v138, v114, v111);
            if (!v117) {
              BUG();
            }
            char v118 = v132 - 1;
            uint64_t v119 = v136 * v113 + v117;
            uint64_t v120 = v137;
            ((void (*)(uint64_t *, uint64_t *, uint64_t))v131)(v137, v116, v111);
            ((void (*)(uint64_t, uint64_t *, uint64_t))v129)(v119, v120, v111);
            ((void (*)(uint64_t *, uint64_t))v128)(v116, v111);
            uint64_t result = (uint64_t)v134;
            *uint64_t v134 = v135;
            *(void *)(result + 8) = v118;
          }
        }
      }
    }
  }
  else
  {
    uint64_t v121 = (uint64_t)&v121;
    uint64_t v132 = (char *)v8[2];
    uint64_t v136 = v8[9];
    while (1)
    {
      uint64_t v129 = v22;
      uint64_t v135 = v21;
      uint64_t v23 = v21 + 1;
      uint64_t v24 = v136;
      uint64_t v25 = v138;
      uint64_t v26 = v138 + v21 * v136;
      uint64_t v27 = v137;
      uint64_t v28 = v6;
      uint64_t v29 = (void (*)(uint64_t *, uint64_t, uint64_t))v132;
      ((void (*)(uint64_t *, uint64_t, uint64_t))v132)(v137, v26, v28);
      uint64_t v133 = v23;
      uint64_t v30 = v25 + v23 * v24;
      uint64_t v31 = v128;
      v29(v128, v30, v139);
      char v32 = dispatch thunk of static Comparable.< infix(_:_:)(v27, v31, v139, v130);
      uint64_t v33 = v139;
      LOBYTE(v29) = v32;
      uint64_t v34 = (void (*)(uint64_t *, uint64_t))v125[1];
      v34(v31, v139);
      uint64_t v131 = v34;
      v34(v27, v33);
      uint64_t v35 = v135;
      if ((v29 & 1) == 0) {
        uint64_t v35 = v133;
      }
      uint64_t v133 = v35;
      v135 += 2;
      uint64_t v36 = v136;
      uint64_t v37 = v138;
      unint64_t v38 = (void (*)(uint64_t *, uint64_t, uint64_t))v132;
      ((void (*)(uint64_t *, uint64_t, uint64_t))v132)(v137, v138 + v135 * v136, v33);
      char v39 = v128;
      v38(v128, v37 + v129 * v36, v33);
      uint64_t v40 = v137;
      char v41 = dispatch thunk of static Comparable.< infix(_:_:)(v137, v39, v139, v130);
      uint64_t v42 = v139;
      char v43 = v41;
      uint64_t v44 = v131;
      v131(v39, v139);
      v44(v40, v42);
      if ((v43 & 1) == 0) {
        uint64_t v135 = v129;
      }
      uint64_t v45 = v133;
      uint64_t v46 = v136;
      uint64_t v47 = v138;
      uint64_t v48 = (void (*)(uint64_t *, uint64_t, uint64_t))v132;
      ((void (*)(uint64_t *, uint64_t, uint64_t))v132)(v137, v138 + v136 * v133, v42);
      uint64_t v49 = v47 + v46 * v135;
      uint64_t v50 = v128;
      uint64_t v51 = v42;
      uint64_t v52 = v45;
      v48(v128, v49, v51);
      uint64_t v53 = v137;
      char v54 = dispatch thunk of static Comparable.< infix(_:_:)(v137, v50, v139, v130);
      uint64_t v55 = v139;
      LOBYTE(v129) = v54;
      uint64_t v56 = v131;
      v131(v50, v139);
      v56(v53, v55);
      if ((v129 & 1) == 0) {
        uint64_t v52 = v135;
      }
      uint64_t v133 = v52;
      uint64_t v57 = v136 * v52;
      uint64_t v58 = v138;
      uint64_t v59 = v137;
      ((void (*)(uint64_t *, uint64_t, uint64_t))v132)(v137, v138 + v57, v55);
      char v60 = dispatch thunk of static Comparable.< infix(_:_:)(v59, v126, v139, v130);
      uint64_t v61 = v139;
      char v62 = v60;
      uint64_t result = ((uint64_t (*)(uint64_t *, uint64_t))v131)(v59, v139);
      if ((v62 & 1) == 0) {
        break;
      }
      uint64_t v63 = *v134;
      uint64_t v64 = v58;
      uint64_t v65 = v127;
      uint64_t v66 = UnsafeMutableBufferPointer.baseAddress.getter(v64, v127, v61);
      if (!v66) {
        BUG();
      }
      uint64_t v67 = v121;
      UnsafeMutablePointer.move()(v57 + v66, v61);
      uint64_t v68 = UnsafeMutableBufferPointer.baseAddress.getter(v138, v65, v61);
      if (!v68) {
        BUG();
      }
      uint64_t v69 = v136 * v63 + v68;
      char v70 = v137;
      uint64_t v71 = (void (*)(uint64_t *, uint64_t, uint64_t))v132;
      ((void (*)(uint64_t *, uint64_t *, uint64_t))v132)(v137, (uint64_t *)v67, v61);
      ((void (*)(uint64_t, uint64_t *, uint64_t))v125[4])(v69, v70, v61);
      uint64_t v72 = v67;
      uint64_t v73 = v131;
      v131((uint64_t *)v72, v61);
      uint64_t v74 = v134;
      uint64_t v75 = v133;
      *uint64_t v134 = v133;
      v74[1] = (uint64_t)v124;
      uint64_t v76 = v136 * ((v75 - 1) / 2);
      v71(v70, v138 + v76, v61);
      LOBYTE(v71) = dispatch thunk of static Comparable.< infix(_:_:)(v70, v126, v61, v130);
      v73(v70, v61);
      BOOL v77 = (v71 & 1) == 0;
      a4 = v127;
      uint64_t v6 = v61;
      if (!v77)
      {
        uint64_t v78 = UnsafeMutableBufferPointer.baseAddress.getter(v138, v127, v61);
        swap<A>(_:_:)(v78 + v76, v126, v61);
      }
      uint64_t v21 = 4 * v133 + 3;
      v124 += 2;
      uint64_t v22 = 4 * v133 + 6;
      if (v22 >= a4)
      {
        uint64_t result = *v134;
        goto LABEL_16;
      }
    }
  }
  return result;
}

char *Heap._UnsafeHandle._minDescendant(c0:gc0:)(uint64_t a1, char *a2, uint64_t a3, char *a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  uint64_t v10 = a1;
  uint64_t v11 = *(void **)(a7 - 8);
  int64_t v12 = v11[8];
  uint64_t v13 = alloca(v12);
  unsigned int v14 = alloca(v12);
  int v15 = alloca(v12);
  uint64_t v16 = alloca(v12);
  if (a3 >= a6)
  {
    if (a1 + 1 < a6)
    {
      char v32 = (void (*)(uint64_t *, uint64_t))v11[2];
      uint64_t v33 = v11[9];
      uint64_t v63 = a1;
      uint64_t v61 = &v54;
      char v62 = a2;
      uint64_t v59 = a5;
      v32(&v54, a5 + a1 * v33);
      ((void (*)(uint64_t *, uint64_t, uint64_t))v32)(&v54, v59 + (a1 + 1) * v33, a7);
      uint64_t v34 = v61;
      LOBYTE(v32) = dispatch thunk of static Comparable.< infix(_:_:)(v61, &v54, a7, a8);
      uint64_t v35 = (void (*)(uint64_t *, uint64_t))v11[1];
      v35(&v54, a7);
      v35(v34, a7);
      uint64_t v10 = v63;
      if ((v32 & 1) == 0) {
        return (char *)(a1 + 1);
      }
    }
  }
  else
  {
    Swift::Int v17 = (void (*)(void, void))v11[2];
    uint64_t v18 = v11[9];
    uint64_t v57 = a4;
    uint64_t v56 = (void (*)(void, void, void))v17;
    uint64_t v58 = &v54;
    uint64_t v59 = a5;
    uint64_t v61 = &v54;
    if (a3 + 2 >= a6)
    {
      uint64_t v63 = a1 + 1;
      char v62 = a2;
      uint64_t v60 = a3;
      uint64_t v37 = (void (*)(uint64_t *, uint64_t, uint64_t))v17;
      v17(&v54, a5 + (a1 + 1) * v18);
      uint64_t v55 = v18;
      uint64_t v38 = a5 + v60 * v18;
      char v39 = (char *)v60;
      uint64_t v40 = v58;
      v37(v58, v38, a7);
      char v64 = dispatch thunk of static Comparable.< infix(_:_:)(v61, v40, a7, a8);
      char v41 = (void (*)(uint64_t *, uint64_t))v11[1];
      v41(v40, a7);
      uint64_t v42 = v61;
      v41(v61, a7);
      char v43 = v62;
      uint64_t v10 = v63;
      if ((v64 & 1) == 0)
      {
        uint64_t v10 = (uint64_t)v39;
        char v43 = v57;
      }
      uint64_t v44 = (void (*)(void, void))(v39 + 1);
      if ((uint64_t)v44 < a6)
      {
        uint64_t v45 = v44;
        uint64_t v60 = (uint64_t)v44;
        uint64_t v46 = v55;
        uint64_t v47 = v59;
        uint64_t v63 = v10;
        uint64_t v48 = v42;
        char v62 = v43;
        uint64_t v49 = (void (*)(uint64_t *, uint64_t, uint64_t))v56;
        v56(v48, v59 + v55 * v10, a7);
        uint64_t v50 = (void)v45 * v46;
        uint64_t v51 = v58;
        v49(v58, v47 + v50, a7);
        uint64_t v52 = v61;
        LOBYTE(v49) = dispatch thunk of static Comparable.< infix(_:_:)(v61, v51, a7, a8);
        v41(v51, a7);
        v41(v52, a7);
        uint64_t v10 = v63;
        if ((v49 & 1) == 0) {
          return (char *)v60;
        }
      }
    }
    else
    {
      uint64_t v63 = a3 + 1;
      char v62 = (char *)(a3 + 2);
      uint64_t v20 = (void (*)(uint64_t *, uint64_t, uint64_t))v17;
      v17(&v54, a5 + a3 * v18);
      uint64_t v21 = a5 + v63 * v18;
      uint64_t v22 = v58;
      v20(v58, v21, a7);
      char v64 = dispatch thunk of static Comparable.< infix(_:_:)(v61, v22, a7, a8);
      uint64_t v23 = (void (*)(uint64_t *, uint64_t))v11[1];
      uint64_t v60 = (uint64_t)v23;
      v23(v22, a7);
      uint64_t v24 = v61;
      v23(v61, a7);
      uint64_t v25 = v63;
      if (v64) {
        uint64_t v25 = a3;
      }
      uint64_t v63 = v25;
      uint64_t v26 = v59;
      uint64_t v27 = v24;
      uint64_t v28 = (void (*)(uint64_t *, uint64_t, uint64_t))v56;
      v56(v24, v59 + v18 * v25, a7);
      uint64_t v29 = v58;
      v28(v58, v26 + (void)v62 * v18, a7);
      uint64_t v30 = v27;
      LOBYTE(v27) = dispatch thunk of static Comparable.< infix(_:_:)(v27, v29, a7, a8);
      uint64_t v31 = (void (*)(uint64_t *, uint64_t))v60;
      ((void (*)(uint64_t *, uint64_t))v60)(v29, a7);
      v31(v30, a7);
      uint64_t v10 = v63;
      if ((v27 & 1) == 0) {
        return v62;
      }
    }
  }
  return (char *)v10;
}

uint64_t Heap._UnsafeHandle.trickleDownMax(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v133 = a6;
  uint64_t v6 = a5;
  uint64_t v128 = a2;
  uint64_t v7 = *(void *)(a5 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v129 = &v124;
  uint64_t v11 = alloca(v8);
  int64_t v12 = alloca(v8);
  uint64_t v132 = &v124;
  uint64_t v13 = alloca(v8);
  unsigned int v14 = alloca(v8);
  uint64_t v126 = &v124;
  int v15 = alloca(v8);
  uint64_t v16 = alloca(v8);
  uint64_t v125 = &v124;
  Swift::Int v17 = alloca(v8);
  uint64_t v18 = alloca(v8);
  uint64_t v131 = (uint64_t)&v124;
  uint64_t v19 = alloca(v8);
  uint64_t v20 = alloca(v8);
  uint64_t v140 = &v124;
  uint64_t v21 = alloca(v8);
  uint64_t v22 = alloca(v8);
  uint64_t v142 = a3;
  uint64_t v136 = a4;
  uint64_t v23 = UnsafeMutableBufferPointer.baseAddress.getter(a3, a4, a5);
  if (!v23) {
    BUG();
  }
  uint64_t v24 = *(void *)(v7 + 72);
  uint64_t v135 = &v124;
  UnsafeMutablePointer.move()(a1 * v24 + v23, v6);
  uint64_t v25 = 4 * a1 + 3;
  uint64_t v26 = 4 * a1 + 6;
  uint64_t v139 = v7;
  uint64_t v143 = v24;
  uint64_t v27 = a1;
  uint64_t v144 = v6;
  if (v26 < v136)
  {
    uint64_t v141 = *(void (**)(void, void, void))(v7 + 16);
    uint64_t v28 = v140;
    while (1)
    {
      uint64_t v138 = v25;
      uint64_t v137 = v27;
      uint64_t v29 = v25 + 1;
      uint64_t v30 = v142;
      uint64_t v31 = v142 + v24 * v25;
      uint64_t v32 = v6;
      uint64_t v33 = v141;
      v141(v28, v31, v32);
      uint64_t v130 = v29;
      uint64_t v34 = v30 + v24 * v29;
      uint64_t v35 = v131;
      v33(v131, v34, v144);
      uint64_t v36 = v140;
      char v37 = dispatch thunk of static Comparable.< infix(_:_:)(v140, v35, v144, v133);
      uint64_t v38 = v144;
      LOBYTE(v127) = v37;
      char v39 = *(void (**)(uint64_t, uint64_t))(v139 + 8);
      v39(v35, v144);
      uint64_t v134 = (uint64_t)v39;
      v39((uint64_t)v36, v38);
      uint64_t v40 = v138;
      if ((v127 & 1) == 0) {
        uint64_t v130 = v138;
      }
      v138 += 2;
      uint64_t v41 = v143;
      uint64_t v42 = v142;
      char v43 = v140;
      uint64_t v44 = v38;
      uint64_t v45 = v141;
      v141(v140, v142 + v143 * (v40 + 2), v44);
      uint64_t v46 = v42 + v41 * v26;
      uint64_t v47 = v131;
      v45(v131, v46, v144);
      char v48 = dispatch thunk of static Comparable.< infix(_:_:)(v43, v47, v144, v133);
      uint64_t v49 = v144;
      LOBYTE(v41) = v48;
      uint64_t v50 = v47;
      uint64_t v51 = (void (*)(uint64_t *, uint64_t))v134;
      ((void (*)(uint64_t, uint64_t))v134)(v50, v144);
      v51(v43, v49);
      if ((v41 & 1) == 0) {
        uint64_t v26 = v138;
      }
      uint64_t v52 = v143;
      uint64_t v53 = v142;
      uint64_t v54 = v140;
      uint64_t v55 = v49;
      uint64_t v56 = v141;
      v141(v140, v142 + v143 * v130, v55);
      uint64_t v57 = v53 + v52 * v26;
      uint64_t v58 = v131;
      v56(v131, v57, v144);
      char v59 = dispatch thunk of static Comparable.< infix(_:_:)(v54, v58, v144, v133);
      uint64_t v60 = v144;
      LOBYTE(v52) = v59;
      uint64_t v61 = v58;
      char v62 = (void (*)(uint64_t *, uint64_t))v134;
      ((void (*)(uint64_t, uint64_t))v134)(v61, v144);
      v62(v54, v60);
      uint64_t v63 = v26;
      if ((v52 & 1) == 0) {
        uint64_t v63 = v130;
      }
      uint64_t v64 = v143 * v63;
      uint64_t v65 = v140;
      v141(v140, v142 + v143 * v63, v60);
      char v66 = dispatch thunk of static Comparable.< infix(_:_:)(v135, v65, v144, v133);
      uint64_t v6 = v144;
      char v67 = v66;
      ((void (*)(uint64_t *, uint64_t))v134)(v65, v144);
      if ((v67 & 1) == 0) {
        goto LABEL_30;
      }
      uint64_t v138 = v63;
      uint64_t v68 = v136;
      uint64_t v69 = UnsafeMutableBufferPointer.baseAddress.getter(v142, v136, v6);
      if (!v69) {
        BUG();
      }
      char v70 = v125;
      UnsafeMutablePointer.move()(v64 + v69, v6);
      uint64_t v71 = UnsafeMutableBufferPointer.baseAddress.getter(v142, v68, v6);
      if (!v71) {
        BUG();
      }
      uint64_t v72 = v143 * v137 + v71;
      uint64_t v73 = v140;
      uint64_t v74 = (void (*)(uint64_t *, uint64_t, uint64_t))v141;
      v141(v140, v70, v6);
      (*(void (**)(uint64_t, uint64_t *, uint64_t))(v139 + 32))(v72, v73, v144);
      uint64_t v75 = v70;
      uint64_t v76 = (void (*)(uint64_t *, uint64_t))v134;
      ((void (*)(uint64_t *, uint64_t))v134)(v75, v144);
      uint64_t v77 = v143 * ((v138 - 1) / 2);
      v74(v73, v142 + v77, v144);
      char v78 = dispatch thunk of static Comparable.< infix(_:_:)(v135, v73, v144, v133);
      uint64_t v6 = v144;
      LOBYTE(v74) = v78;
      v76(v73, v144);
      uint64_t v79 = v136;
      if (v74)
      {
        uint64_t v80 = UnsafeMutableBufferPointer.baseAddress.getter(v142, v136, v6);
        swap<A>(_:_:)(v80 + v77, v135, v6);
      }
      uint64_t v25 = 4 * v138 + 3;
      uint64_t v26 = 4 * v138 + 6;
      v128 += 2;
      uint64_t v27 = v138;
      uint64_t v28 = v140;
      uint64_t v24 = v143;
      if (v26 >= v79)
      {
        uint64_t v81 = v128;
        uint64_t v82 = (char *)(v128 + 2);
        uint64_t v27 = v138;
        uint64_t v7 = v139;
        goto LABEL_18;
      }
    }
  }
  uint64_t v81 = v128;
  uint64_t v82 = (char *)(v128 + 2);
  uint64_t v28 = v140;
LABEL_18:
  uint64_t v137 = v27;
  uint64_t v83 = 2 * v27 + 1;
  if (v83 >= v136)
  {
    uint64_t v104 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v7 + 16);
    uint64_t v103 = v143;
    uint64_t v102 = v132;
    goto LABEL_31;
  }
  uint64_t v138 = v25;
  uint64_t v84 = v142;
  uint64_t v85 = v28;
  uint64_t v86 = v133;
  uint64_t v131 = (uint64_t)Heap._UnsafeHandle._maxDescendant(c0:gc0:)(v83, (char *)(v81 + 1), v25, v82, v142, v136, v6, v133);
  uint64_t v134 = v143 * v131;
  uint64_t v141 = *(void (**)(void, void, void))(v7 + 16);
  v141(v85, v84 + v143 * v131, v6);
  char v87 = dispatch thunk of static Comparable.< infix(_:_:)(v135, v85, v144, v86);
  uint64_t v6 = v144;
  uint64_t v88 = v85;
  LOBYTE(v85) = v87;
  uint64_t v89 = *(void (**)(uint64_t *, uint64_t))(v7 + 8);
  v89(v88, v144);
  if ((v85 & 1) == 0) {
    goto LABEL_30;
  }
  uint64_t v130 = (uint64_t)v89;
  uint64_t v90 = v142;
  uint64_t v91 = v136;
  uint64_t v92 = UnsafeMutableBufferPointer.baseAddress.getter(v142, v136, v6);
  if (!v92) {
    BUG();
  }
  uint64_t v93 = v126;
  UnsafeMutablePointer.move()(v134 + v92, v6);
  uint64_t v94 = UnsafeMutableBufferPointer.baseAddress.getter(v90, v91, v6);
  if (!v94) {
    BUG();
  }
  uint64_t v95 = v143 * v137 + v94;
  uint64_t v96 = v140;
  uint64_t v97 = v141;
  v141(v140, v93, v6);
  uint64_t v98 = v95;
  uint64_t v99 = v96;
  uint64_t v127 = *(void (**)(uint64_t, uint64_t *, uint64_t))(v139 + 32);
  v127(v98, v96, v6);
  uint64_t v100 = v93;
  uint64_t v101 = (void (*)(uint64_t *, uint64_t))v130;
  ((void (*)(uint64_t *, uint64_t))v130)(v100, v6);
  if (v131 < v138)
  {
    uint64_t v137 = v131;
    uint64_t v7 = v139;
    uint64_t v102 = v132;
    uint64_t v103 = v143;
    uint64_t v104 = (void (*)(uint64_t *, uint64_t *, uint64_t))v97;
    goto LABEL_31;
  }
  uint64_t v137 = (v131 - 1) / 2;
  uint64_t v105 = v143 * v137;
  v97(v99, v142 + v143 * v137, v6);
  char v106 = dispatch thunk of static Comparable.< infix(_:_:)(v135, v99, v144, v133);
  uint64_t v6 = v144;
  uint64_t v107 = v99;
  char v108 = v106;
  v101(v107, v144);
  if ((v108 & 1) == 0)
  {
    uint64_t v137 = v131;
LABEL_30:
    uint64_t v7 = v139;
    uint64_t v102 = v132;
    uint64_t v103 = v143;
    uint64_t v104 = (void (*)(uint64_t *, uint64_t *, uint64_t))v141;
    goto LABEL_31;
  }
  uint64_t v109 = v142;
  uint64_t v110 = v136;
  uint64_t v111 = UnsafeMutableBufferPointer.baseAddress.getter(v142, v136, v6);
  if (!v111) {
    BUG();
  }
  UnsafeMutablePointer.move()(v105 + v111, v6);
  uint64_t v112 = UnsafeMutableBufferPointer.baseAddress.getter(v109, v110, v6);
  if (!v112) {
    BUG();
  }
  uint64_t v113 = (char *)(v134 + v112);
  uint64_t v114 = v140;
  uint64_t v115 = v141;
  v141(v140, v129, v6);
  uint64_t v116 = v113;
  uint64_t v104 = (void (*)(uint64_t *, uint64_t *, uint64_t))v115;
  v127((uint64_t)v116, v114, v6);
  v101(v129, v6);
  uint64_t v7 = v139;
  uint64_t v102 = v132;
  uint64_t v103 = v143;
LABEL_31:
  uint64_t v117 = v102;
  v104(v102, v135, v6);
  uint64_t v118 = UnsafeMutableBufferPointer.baseAddress.getter(v142, v136, v6);
  if (!v118) {
    BUG();
  }
  uint64_t v119 = v104;
  uint64_t v120 = v103 * v137 + v118;
  uint64_t v121 = v140;
  v119(v140, v117, v6);
  (*(void (**)(uint64_t, uint64_t *, uint64_t))(v7 + 32))(v120, v121, v6);
  uint64_t v122 = *(void (**)(uint64_t *, uint64_t))(v7 + 8);
  v122(v117, v6);
  return ((uint64_t (*)(uint64_t *, uint64_t))v122)(v135, v6);
}

uint64_t Heap._UnsafeHandle._trickleDownMax(node:value:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v129 = a6;
  uint64_t v128 = a3;
  uint64_t v119 = a2;
  uint64_t v121 = a5;
  uint64_t v7 = *(void **)(a5 - 8);
  int64_t v8 = v7[8];
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v115 = &v113;
  uint64_t v11 = alloca(v8);
  int64_t v12 = alloca(v8);
  uint64_t v114 = &v113;
  uint64_t v13 = alloca(v8);
  unsigned int v14 = alloca(v8);
  int v15 = alloca(v8);
  uint64_t v16 = alloca(v8);
  uint64_t v124 = (uint64_t)&v113;
  Swift::Int v17 = alloca(v8);
  uint64_t v18 = alloca(v8);
  uint64_t v130 = &v113;
  uint64_t result = *a1;
  uint64_t v125 = a1;
  uint64_t v20 = 4 * result + 3;
  uint64_t v117 = (char *)(a1[1] + 2);
  uint64_t v21 = 4 * result + 6;
  uint64_t v120 = a4;
  uint64_t v118 = v7;
  if (v21 >= a4)
  {
LABEL_16:
    uint64_t v77 = 2 * result + 1;
    BOOL v78 = v77 < a4;
    uint64_t v79 = v128;
    uint64_t v80 = v121;
    if (v78)
    {
      uint64_t v81 = (uint64_t)Heap._UnsafeHandle._maxDescendant(c0:gc0:)(v77, (char *)(v125[1] + 1), v20, v117, v128, v120, v121, v129);
      uint64_t v122 = v82;
      uint64_t v83 = v118;
      uint64_t v84 = (void (*)(uint64_t *, uint64_t *, uint64_t))v118[2];
      uint64_t v85 = (void (*)(void, void))v118[9];
      uint64_t v123 = v81;
      uint64_t v126 = v85;
      uint64_t v86 = (void)v85 * v81;
      uint64_t v87 = v79 + (void)v85 * v81;
      uint64_t v88 = v130;
      uint64_t v127 = v84;
      v84(v130, (uint64_t *)v87, v80);
      LOBYTE(v131) = dispatch thunk of static Comparable.< infix(_:_:)(v119, v88, v80, v129);
      uint64_t v89 = (uint64_t (*)(uint64_t *, uint64_t))v83[1];
      uint64_t v90 = v88;
      uint64_t v91 = v128;
      uint64_t result = v89(v90, v80);
      if (v131)
      {
        uint64_t v131 = (void (*)(uint64_t *, uint64_t))v89;
        uint64_t v124 = *v125;
        uint64_t v92 = v120;
        uint64_t v93 = UnsafeMutableBufferPointer.baseAddress.getter(v91, v120, v80);
        if (!v93) {
          BUG();
        }
        uint64_t v94 = v86 + v93;
        uint64_t v95 = v114;
        UnsafeMutablePointer.move()(v94, v80);
        uint64_t v96 = UnsafeMutableBufferPointer.baseAddress.getter(v91, v92, v80);
        if (!v96) {
          BUG();
        }
        uint64_t v97 = (void)v126 * v124 + v96;
        uint64_t v98 = v130;
        v127(v130, v95, v80);
        uint64_t v124 = v118[4];
        ((void (*)(uint64_t, uint64_t *, uint64_t))v124)(v97, v98, v80);
        v131(v95, v80);
        uint64_t v99 = v125;
        uint64_t result = v123;
        *uint64_t v125 = v123;
        v99[1] = v122;
        uint64_t v100 = v128;
        if (result >= v20)
        {
          uint64_t v123 = (result - 1) / 2;
          uint64_t v101 = (void)v126 * v123;
          uint64_t v102 = v130;
          v127(v130, (uint64_t *)(v128 + (void)v126 * v123), v80);
          char v103 = dispatch thunk of static Comparable.< infix(_:_:)(v119, v102, v80, v129);
          uint64_t result = ((uint64_t (*)(uint64_t *, uint64_t))v131)(v102, v80);
          if (v103)
          {
            uint64_t v104 = *v125;
            uint64_t v105 = v120;
            uint64_t v106 = UnsafeMutableBufferPointer.baseAddress.getter(v100, v120, v80);
            if (!v106) {
              BUG();
            }
            uint64_t v129 = v104;
            uint64_t v107 = v101 + v106;
            char v108 = v115;
            UnsafeMutablePointer.move()(v107, v80);
            uint64_t v109 = UnsafeMutableBufferPointer.baseAddress.getter(v100, v105, v80);
            if (!v109) {
              BUG();
            }
            uint64_t v110 = v122 - 1;
            uint64_t v111 = (void)v126 * v129 + v109;
            uint64_t v112 = v130;
            v127(v130, v108, v80);
            ((void (*)(uint64_t, uint64_t *, uint64_t))v124)(v111, v112, v80);
            v131(v108, v80);
            uint64_t result = (uint64_t)v125;
            *uint64_t v125 = v123;
            *(void *)(result + 8) = v110;
          }
        }
      }
    }
  }
  else
  {
    uint64_t v113 = (uint64_t)&v113;
    uint64_t v127 = (void (*)(uint64_t *, uint64_t *, uint64_t))v7[2];
    uint64_t v131 = (void (*)(uint64_t *, uint64_t))v7[9];
    while (1)
    {
      uint64_t v123 = v20;
      uint64_t v122 = v21;
      uint64_t v22 = v20 + 1;
      uint64_t v23 = v131;
      uint64_t v24 = v20 * (void)v131;
      uint64_t v25 = v128;
      uint64_t v26 = v121;
      uint64_t v27 = (void (*)(uint64_t, uint64_t, uint64_t))v127;
      v127(v130, (uint64_t *)(v128 + v24), v121);
      uint64_t v116 = v22;
      uint64_t v28 = v25 + v22 * (void)v23;
      uint64_t v29 = v124;
      v27(v124, v28, v26);
      uint64_t v30 = v130;
      LOBYTE(v23) = dispatch thunk of static Comparable.< infix(_:_:)(v130, v29, v26, v129);
      uint64_t v31 = (void (*)(uint64_t, uint64_t))v118[1];
      uint64_t v32 = v29;
      uint64_t v33 = v123;
      v31(v32, v26);
      uint64_t v126 = v31;
      v31((uint64_t)v30, v26);
      if ((v23 & 1) == 0) {
        uint64_t v116 = v33;
      }
      uint64_t v123 = v33 + 2;
      uint64_t v34 = v131;
      uint64_t v35 = v128;
      uint64_t v36 = v121;
      char v37 = (void (*)(uint64_t, uint64_t, uint64_t))v127;
      v127(v130, (uint64_t *)(v128 + (v33 + 2) * (void)v131), v121);
      uint64_t v38 = (void (*)(void, void))v34;
      uint64_t v39 = v122;
      uint64_t v40 = v124;
      v37(v124, v35 + v122 * (void)v38, v36);
      uint64_t v41 = v130;
      LOBYTE(v37) = dispatch thunk of static Comparable.< infix(_:_:)(v130, v40, v36, v129);
      uint64_t v42 = v40;
      uint64_t v43 = v39;
      uint64_t v44 = (void (*)(uint64_t *, uint64_t))v126;
      v126(v42, v36);
      v44(v41, v36);
      if ((v37 & 1) == 0) {
        uint64_t v43 = v123;
      }
      uint64_t v45 = v131;
      uint64_t v46 = v128;
      uint64_t v47 = v121;
      char v48 = (void (*)(uint64_t, uint64_t, uint64_t))v127;
      v127(v130, (uint64_t *)(v128 + (void)v131 * v116), v121);
      uint64_t v49 = v46 + (void)v45 * v43;
      uint64_t v50 = v43;
      uint64_t v51 = v124;
      v48(v124, v49, v47);
      uint64_t v52 = v130;
      LOBYTE(v48) = dispatch thunk of static Comparable.< infix(_:_:)(v130, v51, v47, v129);
      uint64_t v53 = v51;
      uint64_t v54 = v50;
      uint64_t v55 = (void (*)(uint64_t *, uint64_t))v126;
      v126(v53, v47);
      v55(v52, v47);
      if ((v48 & 1) == 0) {
        uint64_t v54 = v116;
      }
      uint64_t v122 = v54;
      uint64_t v56 = (void)v131 * v54;
      uint64_t v57 = v128;
      uint64_t v58 = v130;
      uint64_t v59 = v121;
      v127(v130, (uint64_t *)(v128 + v56), v121);
      char v60 = dispatch thunk of static Comparable.< infix(_:_:)(v119, v58, v59, v129);
      uint64_t result = ((uint64_t (*)(uint64_t *, uint64_t))v126)(v58, v59);
      if ((v60 & 1) == 0) {
        break;
      }
      uint64_t v61 = *v125;
      uint64_t v62 = v120;
      uint64_t v63 = UnsafeMutableBufferPointer.baseAddress.getter(v57, v120, v59);
      if (!v63) {
        BUG();
      }
      uint64_t v64 = (uint64_t *)v113;
      UnsafeMutablePointer.move()(v56 + v63, v59);
      uint64_t v65 = UnsafeMutableBufferPointer.baseAddress.getter(v128, v62, v59);
      if (!v65) {
        BUG();
      }
      uint64_t v66 = v59;
      uint64_t v67 = (void)v131 * v61 + v65;
      uint64_t v68 = v130;
      uint64_t v69 = v59;
      char v70 = (void (*)(uint64_t *, uint64_t, uint64_t))v127;
      v127(v130, v64, v69);
      ((void (*)(uint64_t, uint64_t *, uint64_t))v118[4])(v67, v68, v66);
      v126((uint64_t)v64, v66);
      uint64_t v71 = v125;
      uint64_t v72 = v122;
      *uint64_t v125 = v122;
      v71[1] = (uint64_t)v117;
      uint64_t v73 = (void)v131 * ((v72 - 1) / 2);
      uint64_t v74 = v68;
      v70(v68, v128 + v73, v66);
      LOBYTE(v68) = dispatch thunk of static Comparable.< infix(_:_:)(v119, v68, v66, v129);
      v126((uint64_t)v74, v66);
      a4 = v120;
      if (v68)
      {
        uint64_t v75 = v121;
        uint64_t v76 = UnsafeMutableBufferPointer.baseAddress.getter(v128, v120, v121);
        swap<A>(_:_:)(v76 + v73, v119, v75);
      }
      uint64_t v20 = 4 * v122 + 3;
      uint64_t v21 = 4 * v122 + 6;
      v117 += 2;
      if (v21 >= a4)
      {
        uint64_t result = *v125;
        goto LABEL_16;
      }
    }
  }
  return result;
}

char *Heap._UnsafeHandle._maxDescendant(c0:gc0:)(uint64_t a1, char *a2, uint64_t a3, char *a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  uint64_t v9 = a3;
  uint64_t v11 = a1;
  int64_t v12 = *(void **)(a7 - 8);
  int64_t v13 = v12[8];
  unsigned int v14 = alloca(v13);
  int v15 = alloca(v13);
  uint64_t v16 = alloca(v13);
  Swift::Int v17 = alloca(v13);
  if (a3 >= a6)
  {
    if (a1 + 1 < a6)
    {
      uint64_t v32 = (void (*)(uint64_t *, uint64_t))v12[2];
      uint64_t v33 = v12[9];
      char v60 = &v51;
      uint64_t v58 = a1;
      uint64_t v59 = (uint64_t)a2;
      uint64_t v55 = a5;
      v32(&v51, a5 + a1 * v33);
      ((void (*)(uint64_t *, uint64_t, uint64_t))v32)(&v51, v55 + (a1 + 1) * v33, a7);
      uint64_t v34 = v60;
      LOBYTE(v32) = dispatch thunk of static Comparable.< infix(_:_:)(v60, &v51, a7, a8);
      uint64_t v35 = (void (*)(uint64_t *, uint64_t))v12[1];
      v35(&v51, a7);
      v35(v34, a7);
      uint64_t v11 = v58;
      if (v32) {
        return (char *)(a1 + 1);
      }
    }
  }
  else
  {
    uint64_t v54 = (void (*)(uint64_t *, uint64_t, uint64_t))v12[2];
    uint64_t v18 = v12[9];
    uint64_t v52 = a4;
    uint64_t v53 = &v51;
    uint64_t v55 = a5;
    char v60 = &v51;
    if (a3 + 2 >= a6)
    {
      uint64_t v58 = a1 + 1;
      uint64_t v36 = a5 + (a1 + 1) * v18;
      uint64_t v57 = v18;
      uint64_t v56 = a3;
      uint64_t v59 = (uint64_t)a2;
      uint64_t v38 = v54;
      ((void (*)(uint64_t *, uint64_t))v54)(&v51, v36);
      v38(&v51, a5 + v56 * v57, a7);
      char v61 = dispatch thunk of static Comparable.< infix(_:_:)(v60, &v51, a7, a8);
      uint64_t v39 = (void (*)(uint64_t *, uint64_t))v12[1];
      uint64_t v40 = (char *)v56;
      v39(&v51, a7);
      uint64_t v41 = v60;
      v39(v60, a7);
      uint64_t v42 = (char *)v59;
      uint64_t v11 = v58;
      if (v61)
      {
        uint64_t v11 = (uint64_t)v40;
        uint64_t v42 = v52;
      }
      uint64_t v43 = (uint64_t)(v40 + 1);
      if (v43 < a6)
      {
        uint64_t v44 = v57;
        uint64_t v45 = v55;
        uint64_t v46 = v41;
        uint64_t v58 = v11;
        uint64_t v59 = (uint64_t)v42;
        uint64_t v47 = v54;
        v54(v46, v55 + v57 * v11, a7);
        uint64_t v48 = v45 + v43 * v44;
        uint64_t v49 = v53;
        v47(v53, v48, a7);
        LOBYTE(v47) = dispatch thunk of static Comparable.< infix(_:_:)(v60, v49, a7, a8);
        v39(v49, a7);
        v39(v60, a7);
        uint64_t v11 = v58;
        if (v47) {
          return (char *)v43;
        }
      }
    }
    else
    {
      uint64_t v59 = a3 + 1;
      uint64_t v58 = a3 + 2;
      uint64_t v20 = v54;
      ((void (*)(uint64_t *, uint64_t, uint64_t, char *, uint64_t, uint64_t))v54)(&v51, a5 + a3 * v18, a7, a4, a5, a1);
      uint64_t v21 = a5 + v59 * v18;
      uint64_t v22 = v53;
      v20(v53, v21, a7);
      LOBYTE(v57) = dispatch thunk of static Comparable.< infix(_:_:)(v60, v22, a7, a8);
      uint64_t v23 = (void (*)(uint64_t *, uint64_t))v12[1];
      uint64_t v56 = (uint64_t)v23;
      v23(v22, a7);
      uint64_t v24 = v60;
      v23(v60, a7);
      if (v57) {
        uint64_t v9 = v59;
      }
      uint64_t v25 = v55;
      uint64_t v26 = v54;
      v54(v24, v55 + v18 * v9, a7);
      uint64_t v27 = v25 + v58 * v18;
      uint64_t v28 = v53;
      v26(v53, v27, a7);
      uint64_t v29 = v60;
      LOBYTE(v27) = dispatch thunk of static Comparable.< infix(_:_:)(v60, v28, a7, a8);
      uint64_t v30 = v28;
      uint64_t v31 = (void (*)(uint64_t *, uint64_t))v56;
      ((void (*)(uint64_t *, uint64_t))v56)(v30, a7);
      v31(v29, a7);
      if (v27) {
        return (char *)v58;
      }
      return (char *)v9;
    }
  }
  return (char *)v11;
}

Swift::Void __swiftcall Heap._UnsafeHandle.heapify()()
{
  uint64_t v4 = v1;
  int64_t v5 = v3 / 2;
  if (v3 < 2) {
    BUG();
  }
  uint64_t v6 = v3;
  uint64_t v7 = v2;
  if (v5)
  {
    _BitScanReverse64(&v8, v5);
    unint64_t v9 = v8 ^ 0x3F;
  }
  else
  {
    unint64_t v9 = 64;
  }
  uint64_t v19 = v5 - 1;
  uint64_t v10 = 63 - v9;
  uint64_t v20 = v4;
  uint64_t v21 = v0;
  uint64_t v11 = v6;
  int64_t v18 = v5;
  do
  {
    uint64_t v12 = ~(-1 << v10);
    if (v5 > v12)
    {
      uint64_t v15 = (1 << (v10 + 1)) - 2;
      if (v15 >= v5) {
        uint64_t v15 = v19;
      }
      uint64_t v13 = ~(-1 << v10);
      uint64_t v14 = v10;
    }
    else
    {
      uint64_t v13 = 0;
      uint64_t v14 = 0;
      uint64_t v15 = 0;
    }
    BOOL v16 = v5 <= v12 || v15 < v13;
    uint64_t v17 = v10;
    if (v10)
    {
      if (!v16)
      {
        do
        {
          Heap._UnsafeHandle.trickleDownMax(_:)(v13, v14, v7, v6, v21, v20);
          uint64_t v7 = v2;
          uint64_t v6 = v11;
          ++v13;
        }
        while (v15 >= v13);
      }
    }
    else if (!v16)
    {
      do
      {
        Heap._UnsafeHandle.trickleDownMin(_:)(v13, v14, v7, v6, v21, v20);
        uint64_t v7 = v2;
        uint64_t v6 = v11;
        ++v13;
      }
      while (v15 >= v13);
    }
    --v10;
    int64_t v5 = v18;
  }
  while (v17 > 0);
}

uint64_t type metadata accessor for Heap._UnsafeHandle(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for Heap._UnsafeHandle);
}

uint64_t Heap._storage.getter(uint64_t a1)
{
  return swift_retain(a1);
}

uint64_t Heap._storage.setter(uint64_t a1)
{
  uint64_t result = swift_release(*v1);
  void *v1 = a1;
  return result;
}

void (*Heap._storage.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t Heap.init()(uint64_t a1)
{
  uint64_t v1 = static Array._allocateUninitialized(_:)(0, a1);
  return ContiguousArray.init(arrayLiteral:)(v1, a1);
}

Swift::Void __swiftcall Heap.reserveCapacity(_:)(Swift::Int a1)
{
  type metadata accessor for ContiguousArray(0, *(void *)(v1 + 16));
  ContiguousArray.reserveCapacity(_:)(a1);
}

uint64_t Heap.isEmpty.getter(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for ContiguousArray(0, a2);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for ContiguousArray<A>, v2);
  return Collection.isEmpty.getter(v2, WitnessTable);
}

uint64_t Heap.count.getter()
{
  return ContiguousArray.count.getter();
}

uint64_t Heap.unordered.getter(uint64_t a1, uint64_t a2)
{
  v5[0] = a1;
  uint64_t v2 = type metadata accessor for ContiguousArray(0, a2);
  swift_retain(a1);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for ContiguousArray<A>, v2);
  return Array.init<A>(_:)(v5, a2, v2, WitnessTable);
}

uint64_t Heap.insert(_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v14 = a2;
  uint64_t v3 = *(void *)(a2 + 16);
  uint64_t v4 = *(void *)(v3 - 8);
  int64_t v5 = *(void *)(v4 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v4 + 16))(&v12, a1, v3);
  uint64_t v8 = type metadata accessor for ContiguousArray(0, v3);
  ContiguousArray.append(_:)(&v12, v8);
  ContiguousArray._makeMutableAndUnique()();
  unint64_t v9 = *(void *)(*(void *)v2 + 16);
  uint64_t v10 = *(void *)v2 + ((*(unsigned __int8 *)(v4 + 80) + 32) & ~*(unsigned __int8 *)(v4 + 80));
  v13[0] = v10;
  v13[1] = v9;
  closure #1 in Heap.insert(_:)(v10, v9, v3, *(void *)(v14 + 24));
  return $defer #1 <A><A1>() in ContiguousArray.withUnsafeMutableBufferPointer<A>(_:)(v13, v10, v9, v2, v3);
}

Swift::Int closure #1 in Heap.insert(_:)(uint64_t a1, unint64_t a2, uint64_t a3, uint64_t a4)
{
  unint64_t v6 = a2 - 1;
  if (__OFSUB__(a2, 1)) {
    BUG();
  }
  if (v6 > 0x7FFFFFFFFFFFFFFELL) {
    BUG();
  }
  uint64_t v8 = a2;
  _BitScanReverse64(&a2, a2);
  return Heap._UnsafeHandle.bubbleUp(_:)(v6, a2, a1, v8, a3, a4);
}

uint64_t Heap.min()(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for ContiguousArray(0, a2);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for ContiguousArray<A>, v2);
  return Collection.first.getter(v2, WitnessTable);
}

uint64_t Heap.max()(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = a2;
  uint64_t v7 = a3;
  uint64_t v3 = type metadata accessor for Optional(0, a2);
  return ContiguousArray.withUnsafeBufferPointer<A>(_:)(partial apply for closure #1 in Heap.max(), v5, a1, a2, v3);
}

uint64_t closure #1 in Heap.max()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v28 = v6;
  uint64_t v8 = *(void **)(a3 - 8);
  int64_t v9 = v8[8];
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  if (a2 < 3)
  {
    uint64_t v21 = type metadata accessor for UnsafeBufferPointer(0, a3, v9, a4, v23, a6, a1, a2);
    uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeBufferPointer<A>, v21);
    return BidirectionalCollection.last.getter(v21, WitnessTable);
  }
  else
  {
    uint64_t v14 = (void (*)(unsigned char *, uint64_t, uint64_t))v8[2];
    uint64_t v15 = v8[9];
    uint64_t v26 = v23;
    uint64_t v25 = v23;
    uint64_t v27 = a1;
    uint64_t v24 = a4;
    v14(v23, a1 + v15, a3);
    uint64_t v16 = v27 + 2 * v15;
    uint64_t v17 = v26;
    v14(v26, v16, a3);
    int64_t v18 = v25;
    max<A>(_:_:)(v25, v17, a3, v24);
    uint64_t v19 = (void (*)(unsigned char *, uint64_t))v8[1];
    v19(v17, a3);
    v19(v18, a3);
    return __swift_storeEnumTagSinglePayload(v28, 0, 1, a3);
  }
}

uint64_t Heap.popMin()(uint64_t a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = *(void *)(a1 + 16);
  uint64_t v5 = *(void *)(v4 - 8);
  int64_t v6 = *(void *)(v5 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v21 = &v17;
  if (ContiguousArray.count.getter(*v2, v4) <= 0) {
    return __swift_storeEnumTagSinglePayload(v3, 1, 1, v4);
  }
  uint64_t v20 = a1;
  uint64_t v19 = v3;
  uint64_t v9 = type metadata accessor for ContiguousArray(0, v4);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for ContiguousArray<A>, v9);
  uint64_t v11 = swift_getWitnessTable(&protocol conformance descriptor for ContiguousArray<A>, v9);
  RangeReplaceableCollection<>.removeLast()(v9, WitnessTable, v11);
  if (ContiguousArray.count.getter(*v2, v4) > 0)
  {
    ContiguousArray._makeMutableAndUnique()();
    uint64_t v12 = *(void *)(*v2 + 16);
    uint64_t v13 = *v2 + ((*(unsigned __int8 *)(v5 + 80) + 32) & ~*(unsigned __int8 *)(v5 + 80));
    v18[0] = v13;
    v18[1] = v12;
    closure #1 in Heap.popMin()(v13, v12, (uint64_t)v21, v4, *(void *)(v20 + 24));
    $defer #1 <A><A1>() in ContiguousArray.withUnsafeMutableBufferPointer<A>(_:)(v18, v13, v12, (uint64_t)v2, v4);
  }
  uint64_t v14 = v19;
  uint64_t v15 = (uint64_t)v21;
  (*(void (**)(uint64_t, uint64_t *, uint64_t))(v5 + 16))(v19, v21, v4);
  __swift_storeEnumTagSinglePayload(v14, 0, 1, v4);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v5 + 8))(v15, v4);
}

uint64_t closure #1 in Heap.popMin()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v8 = UnsafeMutableBufferPointer.baseAddress.getter(a1, a2, a4);
  swap<A>(_:_:)(v8, a3, a4);
  return Heap._UnsafeHandle.trickleDownMin(_:)(0, 0, a1, a2, a4, a5);
}

uint64_t Heap.popMax()(uint64_t a1)
{
  uint64_t v21 = v1;
  uint64_t v19 = a1;
  uint64_t v3 = *(void *)(a1 + 16);
  uint64_t v20 = *(void *)(v3 - 8);
  int64_t v4 = *(void *)(v20 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  int64_t v18 = v17;
  uint64_t v7 = ContiguousArray.count.getter(*v2, v3);
  uint64_t v8 = type metadata accessor for ContiguousArray(0, v3);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for ContiguousArray<A>, v8);
  uint64_t v10 = swift_getWitnessTable(&protocol conformance descriptor for ContiguousArray<A>, v8);
  if (v7 < 3) {
    return RangeReplaceableCollection<>.popLast()(v8, WitnessTable, v10);
  }
  uint64_t v11 = (uint64_t)v18;
  RangeReplaceableCollection<>.removeLast()(v8, WitnessTable, v10);
  ContiguousArray._makeMutableAndUnique()();
  uint64_t v12 = *(void *)(*v2 + 16);
  uint64_t v13 = *v2 + ((*(unsigned __int8 *)(v20 + 80) + 32) & ~*(unsigned __int8 *)(v20 + 80));
  v17[0] = v13;
  v17[1] = v12;
  closure #1 in Heap.popMax()(v13, v12, v11, v3, *(void *)(v19 + 24));
  $defer #1 <A><A1>() in ContiguousArray.withUnsafeMutableBufferPointer<A>(_:)(v17, v13, v12, (uint64_t)v2, v3);
  uint64_t v14 = v21;
  uint64_t v15 = v20;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v20 + 16))(v21, v11, v3);
  __swift_storeEnumTagSinglePayload(v14, 0, 1, v3);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v15 + 8))(v11, v3);
}

uint64_t closure #1 in Heap.popMax()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v29 = a3;
  int64_t v6 = *(void **)(a4 - 8);
  int64_t v7 = v6[8];
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  uint64_t v12 = v6[9];
  uint64_t v30 = a1;
  uint64_t v31 = a5;
  uint64_t v28 = &v25;
  if (a2 == 2)
  {
    uint64_t v13 = (void (*)(uint64_t *, uint64_t, uint64_t))v6[2];
    v13(&v25, a1 + v12, a4);
    v13(&v25, v29, a4);
    uint64_t v14 = v28;
    LOBYTE(v31) = dispatch thunk of static Comparable.> infix(_:_:)(v28, &v25, a4, v31);
    uint64_t v15 = (void (*)(uint64_t *, uint64_t))v6[1];
    v15(&v25, a4);
    uint64_t result = ((uint64_t (*)(uint64_t *, uint64_t))v15)(v14, a4);
    if (v31)
    {
      uint64_t v17 = UnsafeMutableBufferPointer.baseAddress.getter(v30, 2, a4);
      return swap<A>(_:_:)(v17 + v12, v29, a4);
    }
  }
  else
  {
    uint64_t v26 = a2;
    uint64_t v27 = &v25;
    int64_t v18 = (void (*)(uint64_t *, uint64_t, uint64_t))v6[2];
    uint64_t v25 = v12;
    v18(&v25, a1 + 2 * v12, a4);
    uint64_t v19 = a1 + v12;
    uint64_t v20 = v27;
    v18(v27, v19, a4);
    uint64_t v21 = v28;
    LOBYTE(v18) = dispatch thunk of static Comparable.< infix(_:_:)(v28, v20, a4, v31);
    uint64_t v22 = (void (*)(uint64_t *, uint64_t))v6[1];
    v22(v20, a4);
    v22(v21, a4);
    uint64_t v23 = v26;
    uint64_t v24 = UnsafeMutableBufferPointer.baseAddress.getter(v30, v26, a4);
    swap<A>(_:_:)(v24 + (v25 << ((v18 & 1) == 0)), v29, a4);
    return Heap._UnsafeHandle.trickleDownMax(_:)(2 - (v18 & 1), 1, v30, v23, a4, v31);
  }
  return result;
}

uint64_t Heap.removeMin()(uint64_t a1)
{
  return Heap.removeMin()(a1, (void (*)(uint64_t))Heap.popMin());
}

uint64_t Heap.removeMax()(uint64_t a1)
{
  return Heap.removeMin()(a1, (void (*)(uint64_t))Heap.popMax());
}

uint64_t Heap.removeMin()(uint64_t a1, void (*a2)(uint64_t))
{
  uint64_t v9 = v2;
  uint64_t v3 = *(void *)(a1 + 16);
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for Optional(0, v3) - 8) + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  a2(a1);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v8, 1, v3) == 1) {
    BUG();
  }
  return (*(uint64_t (**)(uint64_t, uint64_t *, uint64_t))(*(void *)(v3 - 8) + 32))(v9, &v8, v3);
}

Swift::Void __swiftcall Heap.removeAll(keepingCapacity:)(Swift::Bool keepingCapacity)
{
  type metadata accessor for ContiguousArray(0, *(void *)(v1 + 16));
  ContiguousArray.removeAll(keepingCapacity:)(keepingCapacity);
}

uint64_t Heap.init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  void v17[2] = a4;
  uint64_t v7 = *(void *)(a3 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v19 = a1;
  (*(void (**)(void *))(v7 + 16))(v17);
  uint64_t v11 = ContiguousArray.init<A>(_:)(v17, a2, a3, a5);
  uint64_t v18 = v11;
  swift_retain();
  uint64_t v12 = ContiguousArray.count.getter(v11, a2);
  swift_release();
  if (v12 < 2)
  {
    (*(void (**)(uint64_t, uint64_t))(v7 + 8))(v19, a3);
  }
  else
  {
    type metadata accessor for ContiguousArray(0, a2);
    ContiguousArray._makeMutableAndUnique()();
    uint64_t v13 = *(void *)(v18 + 16);
    int v14 = *(unsigned __int8 *)(*(void *)(a2 - 8) + 80);
    uint64_t v15 = v18 + ((v14 + 32) & ~v14);
    v17[0] = v15;
    v17[1] = v13;
    Heap._UnsafeHandle.heapify()();
    $defer #1 <A><A1>() in ContiguousArray.withUnsafeMutableBufferPointer<A>(_:)(v17, v15, v13, (uint64_t)&v18, a2);
    (*(void (**)(uint64_t, uint64_t))(v7 + 8))(v19, a3);
    return v18;
  }
  return v11;
}

uint64_t Heap.insert<A>(contentsOf:)(void (*a1)(uint64_t, uint64_t *, uint64_t), uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v45 = v4;
  uint64_t v48 = a1;
  uint64_t v41 = a2;
  uint64_t v7 = *(void *)(a2 + 16);
  uint64_t v40 = *(void *)(v7 - 8);
  int64_t v8 = *(void *)(v40 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  char v37 = &v36;
  int64_t v11 = *(void *)(*(void *)(type metadata accessor for Optional(0, v7) - 8) + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t AssociatedConformanceWitness = a4;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a4, a3, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v38 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v14 = *(void *)(v38 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v43 = &v36;
  uint64_t v44 = a3;
  uint64_t v17 = *(void *)(a3 - 8);
  int64_t v18 = *(void *)(v17 + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v21 = *v45;
  uint64_t v22 = *v45;
  uint64_t v46 = v7;
  if (ContiguousArray.count.getter(v22, v7))
  {
    uint64_t v39 = v17;
    uint64_t v23 = ContiguousArray.count.getter(v21, v46);
    uint64_t v24 = dispatch thunk of Sequence.underestimatedCount.getter(v44, AssociatedConformanceWitness);
    Swift::Int v25 = v23 + v24;
    if (__OFADD__(v23, v24)) {
      BUG();
    }
    type metadata accessor for ContiguousArray(0, v46);
    ContiguousArray.reserveCapacity(_:)(v25);
    uint64_t v26 = v44;
    (*(void (**)(uint64_t *, void, uint64_t))(v39 + 16))(&v36, v48, v44);
    uint64_t v27 = AssociatedConformanceWitness;
    dispatch thunk of Sequence.makeIterator()(v26, AssociatedConformanceWitness);
    uint64_t v28 = v26;
    uint64_t v29 = AssociatedTypeWitness;
    uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v27, v28, AssociatedTypeWitness, &protocol requirements base descriptor for Sequence, &associated conformance descriptor for Sequence.Sequence.Iterator: IteratorProtocol);
    dispatch thunk of IteratorProtocol.next()(v29, AssociatedConformanceWitness);
    uint64_t v30 = v46;
    int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)&v36, 1, v46);
    uint64_t v32 = v41;
    uint64_t v33 = (uint64_t)v37;
    if (EnumTagSinglePayload != 1)
    {
      uint64_t v48 = *(void (**)(uint64_t, uint64_t *, uint64_t))(v40 + 32);
      do
      {
        v48(v33, &v36, v30);
        Heap.insert(_:)(v33, v32);
        (*(void (**)(uint64_t, uint64_t))(v40 + 8))(v33, v30);
        dispatch thunk of IteratorProtocol.next()(AssociatedTypeWitness, AssociatedConformanceWitness);
      }
      while (__swift_getEnumTagSinglePayload((uint64_t)&v36, 1, v30) != 1);
    }
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v38 + 8))(v43, AssociatedTypeWitness);
  }
  else
  {
    swift_release();
    uint64_t v35 = v44;
    (*(void (**)(uint64_t *, void, uint64_t))(v17 + 16))(&v36, v48, v44);
    uint64_t result = Heap.init<A>(_:)((uint64_t)&v36, v46, v35, *(void *)(v41 + 24), AssociatedConformanceWitness);
    *uint64_t v45 = result;
  }
  return result;
}

uint64_t partial apply for closure #1 in Heap.max()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  return closure #1 in Heap.max()(a1, a2, *(void *)(v6 + 16), *(void *)(v6 + 24), a5, a6);
}

uint64_t type metadata accessor for Heap(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for Heap);
}

uint64_t UnsafeMutableMatrixPointer.baseAddress.getter(uint64_t a1)
{
  return a1;
}

void UnsafeMutableMatrixPointer.baseAddress.setter(uint64_t a1)
{
  void *v1 = a1;
}

void (*UnsafeMutableMatrixPointer.baseAddress.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeMutableMatrixPointer.rowCount.getter(uint64_t a1, uint64_t a2)
{
  return a2;
}

void UnsafeMutableMatrixPointer.rowCount.setter(uint64_t a1)
{
  *(void *)(v1 + 8) = a1;
}

void (*UnsafeMutableMatrixPointer.rowCount.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeMutableMatrixPointer.columnCount.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return a3;
}

void UnsafeMutableMatrixPointer.columnCount.setter(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
}

void (*UnsafeMutableMatrixPointer.columnCount.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

char UnsafeMutableMatrixPointer.layout.getter(uint64_t a1, uint64_t a2, uint64_t a3, char a4)
{
  return a4 & 1;
}

void UnsafeMutableMatrixPointer.layout.setter(char a1)
{
  *(unsigned char *)(v1 + 24) = a1 & 1;
}

void (*UnsafeMutableMatrixPointer.layout.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

unint64_t UnsafeMutableMatrixPointer.count.getter(uint64_t a1, unint64_t a2, unint64_t a3)
{
  unint64_t v3 = a3 * a2;
  if (!is_mul_ok(a3, a2)) {
    BUG();
  }
  return v3;
}

uint64_t UnsafeMutableMatrixPointer.init(start:rowCount:columnCount:layout:)(uint64_t a1)
{
  return UnsafeMutableMatrixPointer.init(start:rowCount:columnCount:layout:)(a1);
}

{
  return a1;
}

uint64_t UnsafeMutableMatrixPointer.init(_:)(uint64_t a1)
{
  return a1;
}

uint64_t UnsafeMutableMatrixPointer.init(mutating:)(uint64_t a1)
{
  return UnsafeMutableMatrixPointer.init(start:rowCount:columnCount:layout:)(a1);
}

Swift::Void __swiftcall UnsafeMutableMatrixPointer.deallocate()()
{
}

uint64_t static UnsafeMutableMatrixPointer.allocate(rowCount:columnCount:)(unint64_t a1, unint64_t a2, uint64_t a3)
{
  unint64_t v3 = a2 * a1;
  if (!is_mul_ok(a2, a1)) {
    BUG();
  }
  return static UnsafeMutablePointer.allocate(capacity:)(v3, a3);
}

unint64_t UnsafeMutableMatrixPointer.initialize(repeating:)(uint64_t a1, uint64_t a2, unint64_t a3, unint64_t a4, uint64_t a5, uint64_t a6)
{
  int64_t v8 = *(void *)(*(void *)(a6 - 8) + 64);
  uint64_t v9 = alloca(v8);
  unint64_t result = (v8 + 15) & 0xFFFFFFFFFFFFFFF0;
  int64_t v11 = alloca(result);
  uint64_t v12 = a4 * a3;
  if (!is_mul_ok(a4, a3)) {
    BUG();
  }
  if (v12 < 0) {
    BUG();
  }
  uint64_t v15 = *(void *)(a6 - 8);
  if (v12)
  {
    uint64_t v13 = *(void (**)(void, uint64_t, uint64_t))(v15 + 16);
    uint64_t v14 = *(void *)(v15 + 72);
    do
    {
      v13(&v13, a1, a6);
      unint64_t result = (*(uint64_t (**)(uint64_t, void, uint64_t))(v15 + 32))(a2, &v13, a6);
      a2 += v14;
      --v12;
    }
    while (v12);
  }
  return result;
}

uint64_t _sSpsRi_zrlE10initialize2toyxn_tF(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(a3 - 8) + 32))(a2, a1);
}

uint64_t UnsafeMutableMatrixPointer.assign(repeating:)(uint64_t a1, uint64_t a2, unint64_t a3, unint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v6 = a4 * a3;
  if (!is_mul_ok(a4, a3)) {
    BUG();
  }
  if (v6 < 0) {
    BUG();
  }
  if (v6)
  {
    uint64_t v9 = *(void *)(a6 - 8);
    uint64_t v12 = *(uint64_t (**)(uint64_t, uint64_t, uint64_t))(v9 + 24);
    uint64_t v10 = *(void *)(v9 + 72);
    do
    {
      uint64_t result = v12(a2, a1, a6);
      a2 += v10;
      --v6;
    }
    while (v6);
  }
  return result;
}

uint64_t UnsafeMutableMatrixPointer.subscript.getter(unint64_t a1, unint64_t a2, uint64_t a3, unint64_t a4, unint64_t a5, char a6, uint64_t a7)
{
  if (a6)
  {
    unint64_t v12 = a4 * a2;
    if (!is_mul_ok(a4, a2)) {
      BUG();
    }
    BOOL v10 = __OFADD__(v12, a1);
    unint64_t v11 = v12 + a1;
    if (v10) {
      BUG();
    }
  }
  else
  {
    unint64_t v8 = a5 * a1;
    if (!is_mul_ok(a5, a1)) {
      BUG();
    }
    BOOL v10 = __OFADD__(a2, v8);
    unint64_t v11 = a2 + v8;
    if (v10) {
      BUG();
    }
  }
  return (*(uint64_t (**)(uint64_t, unint64_t, uint64_t))(*(void *)(a7 - 8) + 16))(v7, *(void *)(*(void *)(a7 - 8) + 72) * v11 + a3, a7);
}

void (*UnsafeMutableMatrixPointer.subscript.modify(uint64_t a1, unint64_t a2, unint64_t a3, uint64_t a4, unint64_t a5, unint64_t a6, char a7))()
{
  if (a7)
  {
    unint64_t v9 = a5 * a3;
    if (!is_mul_ok(a5, a3)) {
      BUG();
    }
    if (__OFADD__(v9, a2)) {
      BUG();
    }
  }
  else
  {
    unint64_t v7 = a6 * a2;
    if (!is_mul_ok(a6, a2)) {
      BUG();
    }
    if (__OFADD__(a3, v7)) {
      BUG();
    }
  }
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeMutableMatrixPointer.subscript.setter(uint64_t a1, unint64_t a2, unint64_t a3, uint64_t a4, unint64_t a5, unint64_t a6, char a7, uint64_t a8)
{
  unint64_t v8 = UnsafeMutableMatrixPointer.subscript.modify((uint64_t)v12, a2, a3, a4, a5, a6, a7 & 1);
  uint64_t v9 = *(void *)(a8 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v9 + 24))(v10, a1, a8);
  ((void (*)(unsigned char *, void))v8)(v12, 0);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v9 + 8))(a1, a8);
}

uint64_t UnsafeMutableMatrixPointer.subscript.getter(unint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, char a5, uint64_t a6)
{
  if ((a5 & 1) == 0)
  {
    unint64_t v6 = a1;
    a1 *= a4;
    if (!is_mul_ok(a4, v6)) {
      BUG();
    }
  }
  return UnsafeMutableVectorPointer.init(start:count:stride:)(*(void *)(*(void *)(a6 - 8) + 72) * a1 + a2);
}

uint64_t UnsafeMutableMatrixPointer.subscript.getter(unint64_t a1, uint64_t a2, unint64_t a3, uint64_t a4, char a5, uint64_t a6)
{
  if (a5)
  {
    unint64_t v6 = a1;
    a1 *= a3;
    if (!is_mul_ok(a3, v6)) {
      BUG();
    }
  }
  return UnsafeMutableVectorPointer.init(start:count:stride:)(*(void *)(*(void *)(a6 - 8) + 72) * a1 + a2);
}

uint64_t UnsafeMutableMatrixPointer.debugDescription.getter(uint64_t a1, uint64_t a2, uint64_t a3, int a4, uint64_t a5)
{
  int v19 = a4;
  uint64_t v17 = a3;
  v16[0] = 0;
  uint64_t v18 = a2;
  v16[1] = 0xE000000000000000;
  _StringGuts.grow(_:)(72);
  v7._char object = "bounds" + 0x8000000000000000;
  v7._uint64_t countAndFlagsBits = 0xD000000000000022;
  String.append(_:)(v7);
  v20[0] = a1;
  uint64_t v8 = type metadata accessor for UnsafeMutablePointer(0, a5);
  DefaultStringInterpolation.appendInterpolation<A>(_:)(v20, v8);
  v7._uint64_t countAndFlagsBits = 0x203A73776F72202CLL;
  v7._char object = (void *)0xE800000000000000;
  String.append(_:)(v7);
  v20[0] = v18;
  uint64_t v9 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  unint64_t v11 = v10;
  v7._uint64_t countAndFlagsBits = v9;
  v7._char object = v10;
  String.append(_:)(v7);
  swift_bridgeObjectRelease(v11);
  v7._uint64_t countAndFlagsBits = 0x6E6D756C6F63202CLL;
  v7._char object = (void *)0xEB00000000203A73;
  String.append(_:)(v7);
  v20[0] = v17;
  uint64_t v12 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  uint64_t v14 = v13;
  v7._uint64_t countAndFlagsBits = v12;
  v7._char object = v13;
  String.append(_:)(v7);
  swift_bridgeObjectRelease(v14);
  LOBYTE(v14) = v19 & 1;
  v7._uint64_t countAndFlagsBits = 0x74756F79616C202CLL;
  v7._char object = (void *)0xEA0000000000203ALL;
  String.append(_:)(v7);
  LOBYTE(v20[0]) = (_BYTE)v14;
  _print_unlocked<A, B>(_:_:)(v20, v16, &type metadata for MatrixLayout, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v7._uint64_t countAndFlagsBits = 41;
  v7._char object = (void *)0xE100000000000000;
  String.append(_:)(v7);
  return v16[0];
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance UnsafeMutableMatrixPointer<A>(uint64_t a1)
{
  return UnsafeMutableMatrixPointer.debugDescription.getter(*(void *)v1, *(void *)(v1 + 8), *(void *)(v1 + 16), *(unsigned __int8 *)(v1 + 24), *(void *)(a1 + 16));
}

uint64_t variable initialization expression of SparseMatrix.IndexedSequence.Iterator.majorIndex()
{
  return 0;
}

uint64_t variable initialization expression of SparseMatrix.IndexedSequence.Iterator.flatIndex()
{
  return 0;
}

uint64_t variable initialization expression of DenseMatrix.IndexedSequence.Iterator.row()
{
  return 0;
}

uint64_t variable initialization expression of DenseMatrix.IndexedSequence.Iterator.column()
{
  return 0;
}

uint64_t variable initialization expression of DenseMatrix.IndexedSequence.Iterator.flatIndex()
{
  return 0;
}

uint64_t variable initialization expression of LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.row()
{
  return 1;
}

uint64_t variable initialization expression of LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.column()
{
  return 0;
}

uint64_t variable initialization expression of LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.flatIndex()
{
  return 0;
}

uint64_t variable initialization expression of DiagonalMatrix.IndexedSequence.Iterator.index()
{
  return 0;
}

uint64_t variable initialization expression of UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.row()
{
  return 0;
}

uint64_t variable initialization expression of UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.column()
{
  return 1;
}

uint64_t variable initialization expression of UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.flatIndex()
{
  return 0;
}

uint64_t getEnumTagSinglePayload for UnsafeMutableMatrixPointer(uint64_t a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 >= 0xFF && *(unsigned char *)(a1 + 25))
    {
      int v2 = *(_DWORD *)a1 + 254;
    }
    else
    {
      unsigned int v3 = *(unsigned __int8 *)(a1 + 24);
      int v4 = v3 - 2;
      BOOL v5 = v3 < 2;
      int v2 = -1;
      if (!v5) {
        int v2 = v4;
      }
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for UnsafeMutableMatrixPointer(uint64_t a1, unsigned int a2, unsigned int a3)
{
  if (a2 > 0xFE)
  {
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 - 255;
    *(unsigned char *)(a1 + 24) = 0;
    if (a3 >= 0xFF) {
      *(unsigned char *)(a1 + 25) = 1;
    }
  }
  else
  {
    if (a3 >= 0xFF) {
      *(unsigned char *)(a1 + 25) = 0;
    }
    if (a2) {
      *(unsigned char *)(a1 + 24) = a2 + 1;
    }
  }
}

uint64_t type metadata accessor for UnsafeMutableMatrixPointer(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for UnsafeMutableMatrixPointer);
}

uint64_t SparseMatrix.indexed()()
{
  uint64_t v2 = v0;
  char v3 = *(unsigned char *)(v1 + 16);
  uint64_t v4 = *(void *)(v1 + 24);
  uint64_t v5 = *(void *)(v1 + 32);
  uint64_t v10 = *(void *)(v1 + 40);
  uint64_t v7 = v4;
  uint64_t v8 = v5;
  uint64_t v9 = v10;
  outlined retain of [Int](&v7);
  outlined retain of [Int](&v8);
  outlined retain of ContiguousArray<Double>(&v9);
  *(_OWORD *)uint64_t v2 = *(_OWORD *)v1;
  *(unsigned char *)(v2 + 16) = v3 & 1;
  *(void *)(v2 + 24) = v4;
  *(void *)(v2 + 32) = v5;
  uint64_t result = v10;
  *(void *)(v2 + 40) = v10;
  return result;
}

uint64_t SparseMatrix.IndexedSequence.init(base:)(uint64_t a1)
{
  uint64_t v2 = *(void *)(a1 + 40);
  char v3 = *(unsigned char *)(a1 + 16) & 1;
  *(_OWORD *)uint64_t result = *(_OWORD *)a1;
  *(unsigned char *)(result + 16) = v3;
  *(_OWORD *)(result + 24) = *(_OWORD *)(a1 + 24);
  *(void *)(result + 40) = v2;
  return result;
}

uint64_t SparseMatrix.Transpose.indexed()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return SparseMatrix.indexed()();
}

uint64_t SparseMatrix.IndexedSequence.base.getter()
{
  char v2 = *(unsigned char *)(v1 + 16);
  uint64_t v3 = *(void *)(v1 + 24);
  uint64_t v4 = *(void *)(v1 + 32);
  uint64_t v5 = *(void *)(v1 + 40);
  *(_OWORD *)uint64_t v0 = *(_OWORD *)v1;
  *(unsigned char *)(v0 + 16) = v2;
  *(void *)(v0 + 24) = v3;
  *(void *)(v0 + 32) = v4;
  *(void *)(v0 + 40) = v5;
  swift_bridgeObjectRetain(v3);
  swift_bridgeObjectRetain(v4);
  return swift_retain(v5);
}

uint64_t SparseMatrix.IndexedSequence.makeIterator()(uint64_t a1)
{
  uint64_t v3 = v1;
  long long v4 = *v2;
  long long v5 = v2[2];
  long long v13 = v2[1];
  long long v14 = v5;
  long long v12 = v4;
  v17[0] = *((void *)&v13 + 1);
  uint64_t v15 = *((void *)&v5 + 1);
  uint64_t v16 = v5;
  outlined retain of [Int](v17);
  outlined retain of [Int](&v16);
  outlined retain of ContiguousArray<Double>(&v15);
  uint64_t result = SparseMatrix.IndexedSequence.Iterator.init(base:)(&v12, *(void *)(a1 + 16), *(void *)(a1 + 24), v6);
  void v3[3] = v11;
  v3[2] = v10;
  v3[1] = v9;
  _OWORD *v3 = v8;
  return result;
}

uint64_t SparseMatrix.IndexedSequence.Iterator.init(base:)(long long *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v6 = v4;
  long long v20 = *a1;
  char v7 = *((unsigned char *)a1 + 16);
  uint64_t v8 = *((void *)a1 + 5);
  __m128i v21 = _mm_loadu_si128((const __m128i *)((char *)a1 + 24));
  uint64_t v22 = v21.i64[0];
  uint64_t v9 = 0;
  uint64_t v10 = type metadata accessor for SparseMatrix(0, a2, a3, a4);
  uint64_t v11 = SparseMatrix.majorCount.getter(v10);
  if (v11 > 0)
  {
    unint64_t v12 = _mm_load_si128(&v21).u64[0];
    unint64_t v13 = *(void *)(v12 + 16);
    if (v13 < 2) {
      BUG();
    }
    if (*(uint64_t *)(v12 + 40) <= 0)
    {
      unint64_t v14 = v13 - 2;
      uint64_t v15 = 0;
      while (v11 - 1 != v15)
      {
        if (v14 == v15) {
          BUG();
        }
        uint64_t v9 = v15 + 1;
        if (*(void *)(v12 + 8 * v15++ + 48) > 0) {
          goto LABEL_11;
        }
      }
      uint64_t v9 = v11;
    }
    else
    {
      uint64_t v9 = 0;
    }
  }
LABEL_11:
  uint64_t v17 = *((void *)a1 + 4);
  uint64_t v24 = v8;
  uint64_t v19 = v17;
  uint64_t v23 = *((void *)a1 + 5);
  outlined retain of [Int](&v22);
  outlined retain of [Int](&v19);
  outlined retain of ContiguousArray<Double>(&v23);
  outlined release of SparseMatrix<Double>.MajorCollection(a1);
  *(_OWORD *)uint64_t v6 = v20;
  *(unsigned char *)(v6 + 16) = v7 & 1;
  *(__m128i *)(v6 + 24) = v21;
  uint64_t result = v24;
  *(void *)(v6 + 40) = v24;
  *(void *)(v6 + 48) = v9;
  *(void *)(v6 + 56) = 0;
  return result;
}

void *protocol witness for Sequence.makeIterator() in conformance SparseMatrix<A>.IndexedSequence(uint64_t a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = v2[3];
  uint64_t v5 = v2[4];
  uint64_t v14 = v2[5];
  SparseMatrix.IndexedSequence.makeIterator()(a1);
  uint64_t v11 = v4;
  outlined release of [Int?](&v11);
  uint64_t v12 = v5;
  outlined release of [Int?](&v12);
  uint64_t v13 = v14;
  uint64_t result = outlined release of _NativeDictionary<String?, Int>.Iterator(&v13);
  _OWORD *v3 = v7;
  v3[1] = v8;
  v3[2] = v9;
  void v3[3] = v10;
  return result;
}

uint64_t SparseMatrix.IndexedSequence.Iterator.base.getter()
{
  char v2 = *(unsigned char *)(v1 + 16);
  uint64_t v3 = *(void *)(v1 + 24);
  uint64_t v4 = *(void *)(v1 + 32);
  uint64_t v5 = *(void *)(v1 + 40);
  *(_OWORD *)uint64_t v0 = *(_OWORD *)v1;
  *(unsigned char *)(v0 + 16) = v2;
  *(void *)(v0 + 24) = v3;
  *(void *)(v0 + 32) = v4;
  *(void *)(v0 + 40) = v5;
  swift_bridgeObjectRetain(v3);
  swift_bridgeObjectRetain(v4);
  return swift_retain(v5);
}

uint64_t SparseMatrix.IndexedSequence.Iterator.majorIndex.getter()
{
  return *(void *)(v0 + 48);
}

void SparseMatrix.IndexedSequence.Iterator.majorIndex.setter(uint64_t a1)
{
  *(void *)(v1 + 48) = a1;
}

void (*SparseMatrix.IndexedSequence.Iterator.majorIndex.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t SparseMatrix.IndexedSequence.Iterator.flatIndex.getter()
{
  return *(void *)(v0 + 56);
}

void SparseMatrix.IndexedSequence.Iterator.flatIndex.setter(uint64_t a1)
{
  *(void *)(v1 + 56) = a1;
}

void (*SparseMatrix.IndexedSequence.Iterator.flatIndex.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t SparseMatrix.IndexedSequence.Iterator.next()(uint64_t a1)
{
  uint64_t v3 = v2;
  uint64_t v4 = v1;
  uint64_t v5 = *(void *)(a1 + 16);
  TupleTypeMetadata3 = swift_getTupleTypeMetadata3(0, &type metadata for Int, &type metadata for Int, v5, "row column element ", 0);
  int64_t v7 = *(void *)(*(void *)(TupleTypeMetadata3 - 8) + 64);
  long long v8 = alloca(v7);
  long long v9 = alloca(v7);
  long long v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  uint64_t v12 = *(void *)(v3 + 48);
  if (!*(unsigned char *)(v3 + 16))
  {
    uint64_t v30 = *(void *)v3;
    if (v12 < *(void *)v3)
    {
      uint64_t v57 = (void *)v4;
      uint64_t v31 = *(void *)(v3 + 56);
      if (v31 < 0) {
        BUG();
      }
      uint64_t v32 = *(void *)(v3 + 32);
      if ((unint64_t)v31 >= *(void *)(v32 + 16)) {
        BUG();
      }
      uint64_t v59 = v30;
      uint64_t v62 = *(int *)(v32 + 4 * v31 + 32);
      uint64_t v58 = TupleTypeMetadata3;
      uint64_t v33 = &v48[*(int *)(TupleTypeMetadata3 + 64)];
      uint64_t v56 = a1;
      uint64_t v34 = *(void *)(v3 + 40);
      uint64_t v55 = v12;
      uint64_t v60 = v32;
      swift_retain();
      char v61 = v33;
      ContiguousArray.subscript.getter(v31, v34, v5);
      swift_release();
      uint64_t v35 = v31 + 1;
      *(void *)(v3 + 56) = v35;
      uint64_t v36 = *(void *)(v3 + 8);
      uint64_t v37 = *(void *)(v3 + 24);
      uint64_t v49 = v59;
      uint64_t v50 = v36;
      char v51 = 0;
      uint64_t v52 = v37;
      uint64_t v53 = v60;
      uint64_t v54 = v34;
      uint64_t v21 = v5;
      uint64_t v38 = type metadata accessor for SparseMatrix(0, v5, *(void *)(v56 + 24), v59);
      uint64_t v39 = SparseMatrix.majorCount.getter(v38);
      uint64_t v40 = v55;
      if (v55 < v39)
      {
        if (v55 < -1) {
          BUG();
        }
        unint64_t v41 = *(void *)(v37 + 16);
        if (v55 + 1 >= v41) {
          BUG();
        }
        if (v35 >= *(void *)(v37 + 8 * v55 + 40))
        {
          uint64_t v42 = v55;
          while (1)
          {
            uint64_t v43 = v42 + 1;
            if (v42 + 1 >= v39) {
              break;
            }
            if (v42 + 2 >= v41) {
              BUG();
            }
            BOOL v29 = v35 < *(void *)(v37 + 8 * v42++ + 48);
            if (v29) {
              goto LABEL_31;
            }
          }
          uint64_t v43 = v39;
LABEL_31:
          *(void *)(v3 + 48) = v43;
        }
      }
      uint64_t v45 = v58;
      uint64_t v46 = (uint64_t)v57;
      uint64_t v47 = (char *)v57 + *(int *)(v58 + 64);
      void *v57 = v40;
      *(void *)(v46 + 8) = v62;
      goto LABEL_33;
    }
    return __swift_storeEnumTagSinglePayload(v4, 1, 1, TupleTypeMetadata3);
  }
  uint64_t v13 = *(void *)(v3 + 8);
  if (v12 >= v13) {
    return __swift_storeEnumTagSinglePayload(v4, 1, 1, TupleTypeMetadata3);
  }
  uint64_t v14 = *(void *)(v3 + 56);
  if (v14 < 0) {
    BUG();
  }
  uint64_t v15 = *(void *)(v3 + 32);
  if ((unint64_t)v14 >= *(void *)(v15 + 16)) {
    BUG();
  }
  uint64_t v57 = (void *)v4;
  uint64_t v59 = v13;
  uint64_t v62 = *(int *)(v15 + 4 * v14 + 32);
  uint64_t v58 = TupleTypeMetadata3;
  uint64_t v16 = &v48[*(int *)(TupleTypeMetadata3 + 64)];
  uint64_t v56 = a1;
  uint64_t v17 = *(void *)(v3 + 40);
  uint64_t v55 = v12;
  uint64_t v18 = v16;
  uint64_t v60 = v15;
  swift_retain();
  char v61 = v18;
  ContiguousArray.subscript.getter(v14, v17, v5);
  swift_release();
  uint64_t v19 = v14 + 1;
  *(void *)(v3 + 56) = v19;
  uint64_t v20 = *(void *)(v3 + 24);
  uint64_t v49 = *(void *)v3;
  uint64_t v50 = v59;
  char v51 = 1;
  uint64_t v52 = v20;
  uint64_t v53 = v60;
  uint64_t v54 = v17;
  uint64_t v21 = v5;
  uint64_t v23 = type metadata accessor for SparseMatrix(0, v5, *(void *)(v56 + 24), v22);
  uint64_t v24 = SparseMatrix.majorCount.getter(v23);
  uint64_t v25 = v55;
  if (v55 < v24)
  {
    if (v55 < -1) {
      BUG();
    }
    unint64_t v26 = *(void *)(v20 + 16);
    if (v55 + 1 >= v26) {
      BUG();
    }
    if (v19 >= *(void *)(v20 + 8 * v55 + 40))
    {
      uint64_t v27 = v55;
      while (1)
      {
        uint64_t v28 = v27 + 1;
        if (v27 + 1 >= v24) {
          break;
        }
        if (v27 + 2 >= v26) {
          BUG();
        }
        BOOL v29 = v19 < *(void *)(v20 + 8 * v27++ + 48);
        if (v29) {
          goto LABEL_28;
        }
      }
      uint64_t v28 = v24;
LABEL_28:
      *(void *)(v3 + 48) = v28;
    }
  }
  uint64_t v45 = v58;
  uint64_t v46 = (uint64_t)v57;
  uint64_t v47 = (char *)v57 + *(int *)(v58 + 64);
  void *v57 = v62;
  *(void *)(v46 + 8) = v25;
LABEL_33:
  (*(void (**)(char *, unsigned char *, uint64_t))(*(void *)(v21 - 8) + 32))(v47, v61, v21);
  return __swift_storeEnumTagSinglePayload(v46, 0, 1, v45);
}

uint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in SparseMatrix<A>.IndexedSequence(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for SparseMatrix<A>.IndexedSequence.Iterator, a1);
}

uint64_t protocol witness for IteratorProtocol.next() in conformance SparseMatrix<A>.IndexedSequence.Iterator(uint64_t a1)
{
  return SparseMatrix.IndexedSequence.Iterator.next()(a1);
}

uint64_t destroy for SparseMatrix.IndexedSequence(void *a1)
{
  return destroy for SparseMatrix.IndexedSequence(a1);
}

{
  swift_bridgeObjectRelease(a1[3]);
  swift_bridgeObjectRelease(a1[4]);
  return swift_release(a1[5]);
}

uint64_t initializeWithCopy for SparseMatrix.IndexedSequence(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v3 = *(void *)(a2 + 24);
  *(void *)(a1 + 24) = v3;
  uint64_t v4 = *(void *)(a2 + 32);
  *(void *)(a1 + 32) = v4;
  uint64_t v5 = *(void *)(a2 + 40);
  *(void *)(a1 + 40) = v5;
  swift_bridgeObjectRetain(v3);
  swift_bridgeObjectRetain(v4);
  swift_retain(v5);
  return a1;
}

uint64_t assignWithCopy for SparseMatrix.IndexedSequence(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v3 = *(void *)(a2 + 24);
  uint64_t v4 = *(void *)(a1 + 24);
  *(void *)(a1 + 24) = v3;
  swift_bridgeObjectRetain(v3);
  swift_bridgeObjectRelease(v4);
  uint64_t v5 = *(void *)(a2 + 32);
  uint64_t v6 = *(void *)(a1 + 32);
  *(void *)(a1 + 32) = v5;
  swift_bridgeObjectRetain(v5);
  swift_bridgeObjectRelease(v6);
  uint64_t v7 = *(void *)(a2 + 40);
  uint64_t v8 = *(void *)(a1 + 40);
  *(void *)(a1 + 40) = v7;
  swift_retain(v7);
  swift_release(v8);
  return a1;
}

uint64_t assignWithTake for SparseMatrix.IndexedSequence(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  swift_bridgeObjectRelease(*(void *)(a1 + 24));
  uint64_t v3 = *(void *)(a1 + 32);
  *(_OWORD *)(a1 + 24) = *(_OWORD *)(a2 + 24);
  swift_bridgeObjectRelease(v3);
  uint64_t v4 = *(void *)(a1 + 40);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  swift_release(v4);
  return a1;
}

uint64_t getEnumTagSinglePayload for SparseMatrix.IndexedSequence(uint64_t a1, int a2)
{
  if (a2)
  {
    if (a2 < 0 && *(unsigned char *)(a1 + 48)) {
      int v2 = *(_DWORD *)a1 + 0x7FFFFFFF;
    }
    else {
      int v2 = (*(void *)(a1 + 24) & 0xFFFFFFFF00000001) != 0 ? -1 : *(void *)(a1 + 24) >> 1;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for SparseMatrix.IndexedSequence(uint64_t a1, int a2, int a3)
{
  if (a2 < 0)
  {
    *(void *)(a1 + 40) = 0;
    *(_OWORD *)(a1 + 24) = 0;
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 + 0x80000000;
    if (a3 < 0) {
      *(unsigned char *)(a1 + 48) = 1;
    }
  }
  else
  {
    if (a3 < 0) {
      *(unsigned char *)(a1 + 48) = 0;
    }
    if (a2) {
      *(void *)(a1 + 24) = 2 * (a2 - 1);
    }
  }
}

uint64_t type metadata accessor for SparseMatrix.IndexedSequence(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for SparseMatrix.IndexedSequence);
}

uint64_t initializeWithCopy for SparseMatrix.IndexedSequence.Iterator(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v3 = *(void *)(a2 + 24);
  *(void *)(a1 + 24) = v3;
  uint64_t v4 = *(void *)(a2 + 32);
  *(void *)(a1 + 32) = v4;
  uint64_t v5 = *(void *)(a2 + 40);
  *(void *)(a1 + 40) = v5;
  *(_OWORD *)(a1 + 48) = *(_OWORD *)(a2 + 48);
  swift_bridgeObjectRetain(v3);
  swift_bridgeObjectRetain(v4);
  swift_retain(v5);
  return a1;
}

uint64_t assignWithCopy for SparseMatrix.IndexedSequence.Iterator(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v3 = *(void *)(a2 + 24);
  uint64_t v4 = *(void *)(a1 + 24);
  *(void *)(a1 + 24) = v3;
  swift_bridgeObjectRetain(v3);
  swift_bridgeObjectRelease(v4);
  uint64_t v5 = *(void *)(a2 + 32);
  uint64_t v6 = *(void *)(a1 + 32);
  *(void *)(a1 + 32) = v5;
  swift_bridgeObjectRetain(v5);
  swift_bridgeObjectRelease(v6);
  uint64_t v7 = *(void *)(a2 + 40);
  uint64_t v8 = *(void *)(a1 + 40);
  *(void *)(a1 + 40) = v7;
  swift_retain(v7);
  swift_release(v8);
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  return a1;
}

uint64_t assignWithTake for SparseMatrix.IndexedSequence.Iterator(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  swift_bridgeObjectRelease(*(void *)(a1 + 24));
  uint64_t v3 = *(void *)(a1 + 32);
  *(_OWORD *)(a1 + 24) = *(_OWORD *)(a2 + 24);
  swift_bridgeObjectRelease(v3);
  uint64_t v4 = *(void *)(a1 + 40);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  swift_release(v4);
  *(_OWORD *)(a1 + 48) = *(_OWORD *)(a2 + 48);
  return a1;
}

uint64_t getEnumTagSinglePayload for SparseMatrix.IndexedSequence.Iterator(uint64_t a1, int a2)
{
  if (a2)
  {
    if (a2 < 0 && *(unsigned char *)(a1 + 64)) {
      int v2 = *(_DWORD *)a1 + 0x7FFFFFFF;
    }
    else {
      int v2 = (*(void *)(a1 + 24) & 0xFFFFFFFF00000001) != 0 ? -1 : *(void *)(a1 + 24) >> 1;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for SparseMatrix.IndexedSequence.Iterator(uint64_t a1, int a2, int a3)
{
  if (a2 < 0)
  {
    *(void *)(a1 + 56) = 0;
    *(_OWORD *)(a1 + 40) = 0;
    *(_OWORD *)(a1 + 24) = 0;
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 + 0x80000000;
    if (a3 < 0) {
      *(unsigned char *)(a1 + 64) = 1;
    }
  }
  else
  {
    if (a3 < 0) {
      *(unsigned char *)(a1 + 64) = 0;
    }
    if (a2) {
      *(void *)(a1 + 24) = 2 * (a2 - 1);
    }
  }
}

uint64_t type metadata accessor for SparseMatrix.IndexedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for SparseMatrix.IndexedSequence.Iterator);
}

uint64_t protocol witness for Matrix.indexed() in conformance SparseMatrix<A>.Transpose(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return SparseMatrix.Transpose.indexed()(a1, a2, a3, a4);
}

uint64_t protocol witness for Matrix.indexed() in conformance SparseMatrix<A>()
{
  return SparseMatrix.indexed()();
}

uint64_t initializeBufferWithCopyOfBuffer for SparseMatrix.IndexedSequence(uint64_t *a1, uint64_t *a2)
{
  return initializeBufferWithCopyOfBuffer for CGRect(a1, a2);
}

uint64_t DenseMatrix.rowCount.getter(uint64_t a1)
{
  return a1;
}

uint64_t DenseMatrix.columnCount.getter(uint64_t a1, uint64_t a2)
{
  return a2;
}

char DenseMatrix.layout.getter(uint64_t a1, uint64_t a2, char a3)
{
  return a3 & 1;
}

uint64_t DenseMatrix.storage.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_retain(a4);
}

uint64_t DenseMatrix.storage.setter(uint64_t a1)
{
  uint64_t result = swift_release(*(void *)(v1 + 24));
  *(void *)(v1 + 24) = a1;
  return result;
}

void (*DenseMatrix.storage.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

unint64_t DenseMatrix.count.getter(unint64_t a1, unint64_t a2)
{
  unint64_t v2 = a2 * a1;
  if (!is_mul_ok(a2, a1)) {
    BUG();
  }
  return v2;
}

uint64_t DenseMatrix.scalars.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_retain(a4);
}

unint64_t DenseMatrix.init(rowCount:columnCount:)(unint64_t a1, unint64_t a2, uint64_t a3, uint64_t a4)
{
  unint64_t v19 = a2;
  unint64_t v20 = a1;
  int64_t v5 = *(void *)(*(void *)(a3 - 8) + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v8 = *(void *)(*(void *)(*(void *)(*(void *)(a4 + 16) + 16) + 8) + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v8, a3, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v10 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v8, a3, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, AssociatedConformanceWitness);
  unint64_t v14 = v20;
  uint64_t v15 = v8;
  unint64_t v16 = v19;
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(&v18, a3, v15);
  if (!is_mul_ok(v16, v14)) {
    BUG();
  }
  ContiguousArray.init(repeating:count:)(&v18, v16 * v14, a3);
  return v14;
}

float *specialized ContiguousArray.init(repeating:count:)(uint64_t a1, float a2)
{
  if (a1 < 0) {
    BUG();
  }
  if (!a1) {
    return (float *)_swiftEmptyArrayStorage;
  }
  uint64_t result = (float *)static ContiguousArray._allocateBufferUninitialized(minimumCapacity:)(a1, &type metadata for Float);
  *((void *)result + 2) = a1;
  for (uint64_t i = 0; i != a1; ++i)
    result[i + 8] = a2;
  return result;
}

unint64_t DenseMatrix.init<A>(rowCount:columnCount:layout:scalars:)(unint64_t a1, unint64_t a2, int a3, uint64_t a4, uint64_t a5, uint64_t a6, int a7, uint64_t a8)
{
  int v35 = a3;
  unint64_t v30 = a2;
  uint64_t v10 = *(void *)(a6 - 8);
  int64_t v11 = *(void *)(v10 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v32 = a4;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v10 + 16))(&v27, a4, a6);
  uint64_t v14 = ContiguousArray.init<A>(_:)(&v27, a5, a6, a8);
  swift_retain(v14);
  uint64_t v34 = v14;
  uint64_t v33 = a5;
  uint64_t v15 = ContiguousArray.count.getter(v14, a5);
  unint64_t v31 = a1;
  unint64_t v16 = v30 * a1;
  if (!is_mul_ok(v30, a1)) {
    BUG();
  }
  if (v15 != v16)
  {
    uint64_t v27 = 0;
    unint64_t v28 = 0xE000000000000000;
    _StringGuts.grow(_:)(52);
    v18._char object = "row column element " + 0x8000000000000000;
    v18._uint64_t countAndFlagsBits = 0xD000000000000026;
    String.append(_:)(v18);
    unint64_t v29 = v16;
    uint64_t v19 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    uint64_t v21 = v20;
    v18._uint64_t countAndFlagsBits = v19;
    v18._char object = v20;
    String.append(_:)(v18);
    swift_bridgeObjectRelease(v21);
    v18._uint64_t countAndFlagsBits = 0x746F672074756220;
    v18._char object = (void *)0xE900000000000020;
    String.append(_:)(v18);
    uint64_t v22 = v34;
    uint64_t v23 = ContiguousArray.count.getter(v34, v33);
    swift_release(v22);
    unint64_t v29 = v23;
    uint64_t v24 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    unint64_t v26 = v25;
    v18._uint64_t countAndFlagsBits = v24;
    v18._char object = v25;
    String.append(_:)(v18);
    swift_bridgeObjectRelease(v26);
    v18._uint64_t countAndFlagsBits = 46;
    v18._char object = (void *)0xE100000000000000;
    String.append(_:)(v18);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v27, v28, "LinearAlgebra/DenseMatrix.swift", 31, 2, 59, 0);
    BUG();
  }
  (*(void (**)(uint64_t, uint64_t))(v10 + 8))(v32, a6);
  swift_release(v34);
  return v31;
}

unint64_t DenseMatrix.init(rowCount:columnCount:layout:repeating:)(unint64_t a1, unint64_t a2, int a3, uint64_t a4, uint64_t a5)
{
  int v16 = a3;
  uint64_t v6 = *(void *)(a5 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  uint64_t v8 = alloca(v7);
  long long v9 = alloca(v7);
  uint64_t v15 = a4;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v6 + 16))(&v12, a4, a5);
  unint64_t v14 = a1;
  unint64_t v13 = a2;
  unint64_t v10 = a2 * a1;
  if (!is_mul_ok(v13, a1)) {
    BUG();
  }
  ContiguousArray.init(repeating:count:)(&v12, v10, a5);
  (*(void (**)(uint64_t, uint64_t))(v6 + 8))(v15, a5);
  return v14;
}

unint64_t DenseMatrix.init(rowCount:columnCount:layout:initializingWith:)(unint64_t a1, unint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  v14[0] = v7;
  uint64_t v9 = a2 * a1;
  if (!is_mul_ok(a2, a1)) {
    BUG();
  }
  int64_t v11 = alloca(64);
  uint64_t v12 = alloca(64);
  v14[2] = a6;
  v14[3] = a7;
  uint64_t savedregs = a4;
  ContiguousArray.init(unsafeUninitializedCapacity:initializingWith:)(v9, (uint64_t)partial apply for closure #1 in DenseMatrix.init(rowCount:columnCount:layout:initializingWith:), (uint64_t)v14, a6);
  return a1;
}

uint64_t partial apply for closure #1 in DenseMatrix.init(rowCount:columnCount:layout:initializingWith:)(uint64_t a1, unint64_t *a2)
{
  unint64_t v4 = *(void *)(v3 + 48);
  unint64_t v5 = *(void *)(v3 + 56);
  uint64_t result = (*(uint64_t (**)(void))(v3 + 32))();
  if (!v2)
  {
    unint64_t v8 = v4;
    unint64_t v7 = v5 * v4;
    if (!is_mul_ok(v5, v8)) {
      BUG();
    }
    *a2 = v7;
  }
  return result;
}

uint64_t ContiguousArray.init(unsafeUninitializedCapacity:initializingWith:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v7 = Array.init(_unsafeUninitializedCapacity:initializingWith:)();
  if (!v4)
  {
    uint64_t v8 = v7;
    swift_bridgeObjectRetain(v7);
    uint64_t v5 = _ArrayBuffer.requestNativeBuffer()(v8, a4);
    swift_bridgeObjectRelease(v8);
    if (!v5)
    {
      v12[0] = v8;
      uint64_t v9 = type metadata accessor for Array(0, a4);
      uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for [A], v9);
      uint64_t v5 = _copyCollectionToContiguousArray<A>(_:)(v12, v9, WitnessTable);
    }
    swift_bridgeObjectRelease(v8);
  }
  return v5;
}

void *DenseMatrix.subscript.read(void *a1, unint64_t a2, unint64_t a3, unint64_t a4, unint64_t a5, char a6, uint64_t a7, uint64_t a8)
{
  *a1 = a8;
  uint64_t v9 = *(void *)(a8 - 8);
  a1[1] = v9;
  size_t v10 = *(void *)(v9 + 64);
  a1[2] = malloc(v10);
  a1[3] = malloc(v10);
  if (a6)
  {
    unint64_t v16 = a3;
    unint64_t v15 = a4 * a3;
    if (!is_mul_ok(a4, v16)) {
      BUG();
    }
    unint64_t v13 = v15 + a2;
    if (__OFADD__(v15, a2)) {
      BUG();
    }
    unint64_t v14 = DenseMatrix.subscript.read;
  }
  else
  {
    unint64_t v11 = a5 * a2;
    if (!is_mul_ok(a5, a2)) {
      BUG();
    }
    BOOL v12 = __OFADD__(a3, v11);
    unint64_t v13 = a3 + v11;
    if (v12) {
      BUG();
    }
    unint64_t v14 = DenseMatrix.subscript.read;
  }
  ContiguousArray.subscript.getter(v13, a7, a8);
  return v14;
}

void DenseMatrix.subscript.read(void *a1)
{
  uint64_t v1 = (void *)a1[3];
  (*(void (**)(void *, void))(a1[1] + 8))(v1, *a1);
  uint64_t v2 = (void *)a1[2];
  free(v1);
  free(v2);
}

void DenseMatrix.subscript.read(uint64_t a1)
{
  uint64_t v1 = *(void **)(a1 + 16);
  (*(void (**)(void *, void))(*(void *)(a1 + 8) + 8))(v1, *(void *)a1);
  free(*(void **)(a1 + 24));
  free(v1);
}

void (*DenseMatrix.subscript.modify(void *a1, unint64_t a2, unint64_t a3, uint64_t a4))(void (***a1)(void, void))
{
  uint64_t v6 = malloc(0x30uLL);
  *a1 = v6;
  if (*(unsigned char *)(v4 + 16))
  {
    unint64_t v8 = a3;
    unint64_t v7 = *(void *)v4 * a3;
    if (!is_mul_ok(*(void *)v4, v8)) {
      BUG();
    }
    BOOL v9 = __OFADD__(a2, v7);
    unint64_t v10 = a2 + v7;
    if (v9) {
      BUG();
    }
    uint64_t v11 = type metadata accessor for ContiguousArray(0, *(void *)(a4 + 16));
    void v6[5] = ContiguousArray.subscript.modify(v6, v10, v11);
    return DenseMatrix.subscript.modify;
  }
  else
  {
    unint64_t v13 = *(void *)(v4 + 8) * a2;
    if (!is_mul_ok(*(void *)(v4 + 8), a2)) {
      BUG();
    }
    BOOL v9 = __OFADD__(a3, v13);
    unint64_t v14 = a3 + v13;
    if (v9) {
      BUG();
    }
    uint64_t v15 = type metadata accessor for ContiguousArray(0, *(void *)(a4 + 16));
    void v6[4] = ContiguousArray.subscript.modify(v6, v14, v15);
    return Heap._UnsafeHandle.subscript.modify;
  }
}

void DenseMatrix.subscript.modify(void (***a1)(void, void))
{
  uint64_t v1 = *a1;
  v1[5](v1, 0);
  free(v1);
}

uint64_t DenseMatrix.subscript.getter(unint64_t a1, unint64_t a2, unint64_t a3, unint64_t a4, char a5, uint64_t a6, uint64_t a7)
{
  uint64_t v8 = v7;
  BOOL v9 = DenseMatrix.subscript.read(v12, a1, a2, a3, a4, a5 & 1, a6, a7);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(a7 - 8) + 16))(v8, v10, a7);
  return ((uint64_t (*)(void *, void))v9)(v12, 0);
}

uint64_t DenseMatrix.subscript.setter(uint64_t a1, unint64_t a2, unint64_t a3, uint64_t a4)
{
  uint64_t v5 = DenseMatrix.subscript.modify(v10, a2, a3, a4);
  uint64_t v6 = *(void *)(a4 + 16);
  uint64_t v7 = *(void *)(v6 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v7 + 24))(v8, a1, v6);
  ((void (*)(void *, void))v5)(v10, 0);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v7 + 8))(a1, v6);
}

Swift::Void __swiftcall DenseMatrix.transpose()()
{
  uint64_t v2 = *(void *)v1;
  unint64_t v3 = *(void *)(v1 + 8);
  if (*(void *)v1 == v3)
  {
    if (v2 < 0) {
      BUG();
    }
    if (v2)
    {
      unint64_t v4 = 0;
      uint64_t v20 = v0;
      while (1)
      {
        if (v4 == v2) {
          BUG();
        }
        unint64_t v5 = v4 + 1;
        if (v4 + 1 == v2) {
          break;
        }
        unint64_t v6 = v2 * v4;
        if (!is_mul_ok(v2, v4)) {
          BUG();
        }
        unint64_t v22 = v4;
        unint64_t v21 = v4 + 1;
        do
        {
          if (__OFADD__(v5, v6)) {
            BUG();
          }
          unint64_t v18 = v5 + v6;
          unint64_t v7 = v2 * v5;
          if (!is_mul_ok(v2, v5)) {
            BUG();
          }
          BOOL v8 = __OFADD__(v22, v7);
          unint64_t v9 = v22 + v7;
          if (v8) {
            BUG();
          }
          ++v5;
          unint64_t v19 = v9;
          uint64_t v10 = type metadata accessor for ContiguousArray(0, *(void *)(v20 + 16));
          uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for ContiguousArray<A>, v10);
          MutableCollection.swapAt(_:_:)(&v18, &v19, v10, WitnessTable);
        }
        while (v2 != v5);
        unint64_t v4 = v21;
      }
    }
  }
  else
  {
    unint64_t v12 = DenseMatrix._transposed()(*(void *)v1, v3, *(unsigned __int8 *)(v1 + 16), *(void *)(v1 + 24), *(void *)(v0 + 16), *(void *)(v0 + 24));
    uint64_t v14 = v13;
    char v16 = v15;
    unint64_t v22 = v17;
    swift_release();
    *(void *)uint64_t v1 = v12;
    *(void *)(v1 + 8) = v14;
    *(unsigned char *)(v1 + 16) = v16 & 1;
    *(void *)(v1 + 24) = v22;
  }
}

unint64_t DenseMatrix._transposed()(unint64_t a1, unint64_t a2, int a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v49 = a4;
  unint64_t v54 = a2;
  unint64_t v50 = a1;
  LOBYTE(a3) = a3 & 1;
  LODWORD(v52) = a3;
  uint64_t v48 = *(void *)(a5 - 8);
  int64_t v8 = *(void *)(v48 + 64);
  unint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  char v51 = &v41;
  uint64_t v53 = *(void *)(*(void *)(*(void *)(*(void *)(a6 + 16) + 16) + 8) + 16);
  uint64_t v11 = v53;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v53, a5, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v13 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  uint64_t v14 = alloca(v13);
  char v15 = alloca(v13);
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v11, a5, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, AssociatedConformanceWitness);
  unint64_t v17 = v51;
  unint64_t v18 = v54;
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(&v41, a5, v53);
  uint64_t v19 = (uint64_t)v17;
  int v20 = v52;
  int64_t v21 = v18;
  unint64_t v22 = v18;
  uint64_t v23 = v50;
  unint64_t result = DenseMatrix.init(rowCount:columnCount:layout:repeating:)(v22, v50, v52, v19, a5);
  unint64_t v44 = result;
  uint64_t v45 = v25;
  char v46 = v26 & 1;
  uint64_t v47 = v27;
  if (v23 < 0) {
    BUG();
  }
  if (v23)
  {
    if (v21 < 0) {
      BUG();
    }
    unint64_t v28 = v23;
    LODWORD(v53) = v20;
    unint64_t v29 = 0;
    unint64_t v30 = &v42;
    uint64_t v43 = a6;
    do
    {
      if (v29 == v28) {
        BUG();
      }
      uint64_t v31 = v49;
      char v32 = v53;
      if (v21)
      {
        unint64_t v33 = 0;
        unint64_t v54 = v29;
        do
        {
          unint64_t v52 = v33 + 1;
          uint64_t v34 = v30;
          int v35 = (void (*)(char *, void))DenseMatrix.subscript.read(v30, v54, v33, v28, v21, v32, v31, a5);
          (*(void (**)(uint64_t *, uint64_t, uint64_t))(v48 + 16))(v51, v36, a5);
          v35(v34, 0);
          uint64_t v38 = type metadata accessor for DenseMatrix(0, a5, v43, v37);
          unint64_t v30 = v34;
          uint64_t v39 = (void (*)(char *, void))DenseMatrix.subscript.modify(v34, v33, v54, v38);
          (*(void (**)(uint64_t, uint64_t *, uint64_t))(v48 + 40))(v40, v51, a5);
          v39(v34, 0);
          char v32 = v53;
          uint64_t v31 = v49;
          unint64_t v29 = v54;
          unint64_t v28 = v50;
          unint64_t v33 = v52;
        }
        while (v21 != v52);
      }
      ++v29;
    }
    while (v29 != v28);
    return v44;
  }
  return result;
}

uint64_t type metadata accessor for DenseMatrix(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for DenseMatrix);
}

uint64_t DenseMatrix.transposed()(uint64_t a1)
{
  uint64_t v1 = DenseMatrix.Transpose.init(base:)(a1);
  swift_retain();
  return v1;
}

unint64_t static DenseMatrix.identity(rowCount:columnCount:)(unint64_t a1, unint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v6 = a3;
  uint64_t v7 = a4;
  unint64_t v8 = a1;
  unint64_t v9 = a2;
  return DenseMatrix.init(rowCount:columnCount:layout:initializingWith:)(a1, a2, 0, (uint64_t)partial apply for closure #1 in static DenseMatrix.identity(rowCount:columnCount:), (uint64_t)v5, a3, a4);
}

unint64_t closure #1 in static DenseMatrix.identity(rowCount:columnCount:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v33 = a3;
  uint64_t v5 = a2;
  uint64_t v24 = a1;
  uint64_t v25 = *(void *)(a4 - 8);
  int64_t v6 = *(void *)(v25 + 64);
  uint64_t v7 = alloca(v6);
  unint64_t v8 = alloca(v6);
  unint64_t v28 = &v20;
  uint64_t v30 = *(void *)(a5 + 8);
  uint64_t v29 = a4;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v30, a4, &protocol requirements base descriptor for ExpressibleByFloatLiteral, &associated type descriptor for ExpressibleByFloatLiteral.FloatLiteralType);
  int64_t v9 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  uint64_t v10 = alloca(v9);
  unint64_t result = (v9 + 15) & 0xFFFFFFFFFFFFFFF0;
  unint64_t v12 = alloca(result);
  char v26 = &v20;
  if (a2 < 0) {
    BUG();
  }
  if (a2)
  {
    if (v33 < 0) {
      BUG();
    }
    unint64_t result = 0;
    uint64_t v32 = 0;
    *(long double *)v21.i128 = 1.0;
    *(long double *)((char *)v21.i128 + 12) = 0.0;
    uint64_t v13 = 0;
    for (i = a2; i != v13; uint64_t v5 = i)
    {
      if (v13 == v5) {
        BUG();
      }
      if (v33)
      {
        uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v30, v29, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByFloatLiteral, &associated conformance descriptor for ExpressibleByFloatLiteral.ExpressibleByFloatLiteral.FloatLiteralType: _ExpressibleByBuiltinFloatLiteral);
        uint64_t v14 = 0;
        uint64_t v23 = v13;
        do
        {
          uint64_t v15 = v32 + v14;
          v21.i64[3] = *v24;
          char v16 = v26;
          dispatch thunk of _ExpressibleByBuiltinFloatLiteral.init(_builtinFloatLiteral:)(AssociatedTypeWitness, AssociatedConformanceWitness);
          uint64_t v17 = v29;
          dispatch thunk of ExpressibleByFloatLiteral.init(floatLiteral:)(v16, v29, v30);
          unint64_t result = (*(uint64_t (**)(uint64_t, uint64_t *, uint64_t))(v25 + 40))(v21.i64[3] + v15 * *(void *)(v25 + 72), v28, v17);
          BOOL v18 = __OFADD__(1, v15);
          uint64_t v19 = v15 + 1;
          if (v18) {
            BUG();
          }
          ++v14;
          uint64_t v13 = v23;
        }
        while (v33 != v14);
      }
      else
      {
        uint64_t v19 = v32;
      }
      ++v13;
      uint64_t v32 = v19;
    }
  }
  return result;
}

unint64_t partial apply for closure #1 in static DenseMatrix.identity(rowCount:columnCount:)(uint64_t *a1)
{
  return closure #1 in static DenseMatrix.identity(rowCount:columnCount:)(a1, v1[4], v1[5], v1[2], v1[3]);
}

uint64_t static DenseMatrix.__derived_struct_equals(_:_:)(uint64_t a1, uint64_t a2, unsigned __int8 a3, uint64_t a4, uint64_t a5, uint64_t a6, unsigned __int8 a7, uint64_t a8, uint64_t a9, uint64_t a10)
{
  if (a1 == a5 && a2 == a6 && ((a7 ^ a3) & 1) == 0) {
    return static ContiguousArray<A>.== infix(_:_:)(a4, a8, a9, *(void *)(*(void *)(*(void *)(a10 + 16) + 8) + 8));
  }
  else {
    return 0;
  }
}

uint64_t protocol witness for Matrix.rowCount.getter in conformance DenseMatrix<A>()
{
  return *(void *)v0;
}

uint64_t protocol witness for Matrix.columnCount.getter in conformance DenseMatrix<A>()
{
  return *(void *)(v0 + 8);
}

unint64_t protocol witness for Matrix.init(rowCount:columnCount:) in conformance DenseMatrix<A>(unint64_t a1, unint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  unint64_t result = DenseMatrix.init(rowCount:columnCount:)(a1, a2, *(void *)(a3 + 16), *(void *)(a3 + 24));
  *(void *)uint64_t v4 = result;
  *(void *)(v4 + 8) = v6;
  *(unsigned char *)(v4 + 16) = 0;
  *(void *)(v4 + 24) = v7;
  return result;
}

uint64_t protocol witness for Matrix.transposed() in conformance DenseMatrix<A>()
{
  uint64_t v2 = v0;
  uint64_t result = DenseMatrix.transposed()(*v1);
  *(void *)uint64_t v2 = result;
  *(void *)(v2 + 8) = v5;
  *(unsigned char *)(v2 + 16) = v4 & 1;
  *(void *)(v2 + 24) = v6;
  return result;
}

uint64_t protocol witness for Matrix.subscript.getter in conformance DenseMatrix<A>(unint64_t a1, unint64_t a2, uint64_t a3)
{
  uint64_t v5 = v3;
  uint64_t v6 = *(void *)(a3 + 16);
  uint64_t v7 = DenseMatrix.subscript.read(v10, a1, a2, *(void *)v4, *(void *)(v4 + 8), *(unsigned char *)(v4 + 16), *(void *)(v4 + 24), v6);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16))(v5, v8, v6);
  return ((uint64_t (*)(void *, void))v7)(v10, 0);
}

uint64_t protocol witness for Matrix.subscript.setter in conformance DenseMatrix<A>(uint64_t a1, unint64_t a2, unint64_t a3, uint64_t a4)
{
  uint64_t v5 = DenseMatrix.subscript.modify(v10, a2, a3, a4);
  uint64_t v6 = *(void *)(a4 + 16);
  uint64_t v7 = *(void *)(v6 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v7 + 24))(v8, a1, v6);
  ((void (*)(void *, void))v5)(v10, 0);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v7 + 8))(a1, v6);
}

void (*protocol witness for Matrix.subscript.modify in conformance DenseMatrix<A>(void *a1, unint64_t a2, unint64_t a3, uint64_t a4))(void (***a1)(void))
{
  uint64_t v5 = malloc(0x28uLL);
  *a1 = v5;
  void v5[4] = DenseMatrix.subscript.modify(v5, a2, a3, a4);
  return protocol witness for Collection.subscript.read in conformance <> InterspersedSequence<A>;
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance DenseMatrix<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return static DenseMatrix.__derived_struct_equals(_:_:)(*(void *)a1, *(void *)(a1 + 8), *(unsigned char *)(a1 + 16), *(void *)(a1 + 24), *(void *)a2, *(void *)(a2 + 8), *(unsigned char *)(a2 + 16), *(void *)(a2 + 24), *(void *)(a3 + 16), *(void *)(a3 + 24));
}

uint64_t DenseMatrix.withUnsafeMatrixPointer<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, char a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  uint64_t v11 = a7;
  uint64_t v12 = a8;
  uint64_t v13 = a9;
  uint64_t v14 = a3;
  uint64_t v15 = a4;
  char v16 = a5 & 1;
  uint64_t v17 = a6;
  uint64_t v18 = a1;
  uint64_t v19 = a2;
  return ContiguousArray.withUnsafeBufferPointer<A>(_:)(partial apply for closure #1 in DenseMatrix.withUnsafeMatrixPointer<A>(_:), v10, a6, a7, a8);
}

uint64_t closure #1 in DenseMatrix.withUnsafeMatrixPointer<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t (*a7)(uint64_t, uint64_t, uint64_t, void), uint64_t a8, uint64_t a9)
{
  uint64_t v9 = UnsafeBufferPointer.baseAddress.getter(a1, a2, a9);
  if (!v9) {
    BUG();
  }
  uint64_t v10 = UnsafeMatrixPointer.init(start:rowCount:columnCount:layout:)(v9);
  return a7(v10, v12, v13, v11 & 1);
}

uint64_t partial apply for closure #1 in DenseMatrix.withUnsafeMatrixPointer<A>(_:)(uint64_t a1, uint64_t a2)
{
  return closure #1 in DenseMatrix.withUnsafeMatrixPointer<A>(_:)(a1, a2, *(void *)(v2 + 40), *(void *)(v2 + 48), *(unsigned __int8 *)(v2 + 56), *(void *)(v2 + 64), *(uint64_t (**)(uint64_t, uint64_t, uint64_t, void))(v2 + 72), *(void *)(v2 + 80), *(void *)(v2 + 16));
}

uint64_t DenseMatrix.withUnsafeMutableMatrixPointer<A>(_:)(uint64_t (*a1)(uint64_t, uint64_t, uint64_t, void), uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v15 = a4;
  void v13[6] = a3;
  v13[5] = v4;
  void v13[2] = a2;
  uint64_t v6 = v5;
  void v13[4] = a1;
  uint64_t v7 = *(void *)(a3 + 16);
  type metadata accessor for ContiguousArray(0, v7);
  uint64_t v14 = v5 + 24;
  ContiguousArray._makeMutableAndUnique()();
  uint64_t v8 = *(void *)(v5 + 24);
  uint64_t v9 = *(void *)(v8 + 16);
  int v10 = *(unsigned __int8 *)(*(void *)(v7 - 8) + 80);
  uint64_t v11 = v8 + ((v10 + 32) & ~v10);
  v13[0] = v11;
  v13[1] = v9;
  closure #1 in DenseMatrix.withUnsafeMutableMatrixPointer<A>(_:)(v13, v6, a1, a2, v7);
  return $defer #1 <A><A1>() in ContiguousArray.withUnsafeMutableBufferPointer<A>(_:)(v13, v11, v9, v14, v7);
}

uint64_t closure #1 in DenseMatrix.withUnsafeMutableMatrixPointer<A>(_:)(void *a1, uint64_t a2, uint64_t (*a3)(uint64_t, uint64_t, uint64_t, void), uint64_t a4, uint64_t a5)
{
  uint64_t v5 = UnsafeMutableBufferPointer.baseAddress.getter(*a1, a1[1], a5);
  if (!v5) {
    BUG();
  }
  uint64_t v6 = UnsafeMutableMatrixPointer.init(start:rowCount:columnCount:layout:)(v5);
  return a3(v6, v8, v9, v7 & 1);
}

uint64_t DenseMatrix.withUnsafeVectorPointer<A>(row:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, char a6, long long a7, long long a8)
{
  return DenseMatrix.withUnsafeVectorPointer<A>(row:_:)(a1, a2, a3, a4, a5, a6, a7, *((uint64_t *)&a7 + 1), a8, *((uint64_t *)&a8 + 1), (uint64_t)partial apply for closure #1 in DenseMatrix.withUnsafeVectorPointer<A>(row:_:));
}

uint64_t closure #1 in DenseMatrix.withUnsafeVectorPointer<A>(row:_:)(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, char a5, uint64_t a6, unint64_t a7, uint64_t (*a8)(uint64_t, uint64_t, uint64_t), uint64_t a9, uint64_t a10)
{
  uint64_t v12 = a7;
  uint64_t v13 = UnsafeBufferPointer.baseAddress.getter(a1, a2, a10);
  if (a5)
  {
    if (!v13) {
      BUG();
    }
  }
  else
  {
    if (!v13) {
      BUG();
    }
    uint64_t v12 = a4 * a7;
    if (!is_mul_ok(a4, a7)) {
      BUG();
    }
  }
  uint64_t v14 = UnsafeVectorPointer.init(start:count:stride:)(*(void *)(*(void *)(a10 - 8) + 72) * v12 + v13);
  return a8(v14, v15, v16);
}

uint64_t DenseMatrix.withUnsafeMutableVectorPointer<A>(row:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return DenseMatrix.withUnsafeMutableVectorPointer<A>(row:_:)(a1, a2, a3, a4, a5, (void (*)(void *, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))closure #1 in DenseMatrix.withUnsafeMutableVectorPointer<A>(row:_:));
}

uint64_t closure #1 in DenseMatrix.withUnsafeMutableVectorPointer<A>(row:_:)(void *a1, uint64_t a2, unint64_t a3, uint64_t (*a4)(uint64_t, uint64_t, uint64_t), uint64_t a5, uint64_t a6)
{
  char v8 = *(unsigned char *)(a2 + 16);
  uint64_t v9 = UnsafeMutableBufferPointer.baseAddress.getter(*a1, a1[1], a6);
  if (v8)
  {
    if (!v9) {
      BUG();
    }
    uint64_t v10 = *(void *)(*(void *)(a6 - 8) + 72) * a3 + v9;
  }
  else
  {
    if (!v9) {
      BUG();
    }
    unint64_t v11 = *(void *)(a2 + 8);
    unint64_t v13 = a3;
    unint64_t v12 = v11 * a3;
    if (!is_mul_ok(v11, v13)) {
      BUG();
    }
    uint64_t v10 = *(void *)(*(void *)(a6 - 8) + 72) * v12 + v9;
  }
  uint64_t v14 = UnsafeMutableVectorPointer.init(start:count:stride:)(v10);
  return a4(v14, v15, v16);
}

uint64_t DenseMatrix.withUnsafeVectorPointer<A>(column:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, char a6, long long a7, long long a8)
{
  return DenseMatrix.withUnsafeVectorPointer<A>(row:_:)(a1, a2, a3, a4, a5, a6, a7, *((uint64_t *)&a7 + 1), a8, *((uint64_t *)&a8 + 1), (uint64_t)partial apply for closure #1 in DenseMatrix.withUnsafeVectorPointer<A>(column:_:));
}

uint64_t DenseMatrix.withUnsafeVectorPointer<A>(row:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, char a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11)
{
  uint64_t v13 = a8;
  uint64_t v14 = a9;
  uint64_t v15 = a10;
  uint64_t v16 = a4;
  uint64_t v17 = a5;
  char v18 = a6 & 1;
  uint64_t v19 = a7;
  uint64_t v20 = a1;
  uint64_t v21 = a2;
  uint64_t v22 = a3;
  return ContiguousArray.withUnsafeBufferPointer<A>(_:)(a11, v12, a7, a8, a9);
}

uint64_t closure #1 in DenseMatrix.withUnsafeVectorPointer<A>(column:_:)(uint64_t a1, uint64_t a2, unint64_t a3, uint64_t a4, char a5, uint64_t a6, unint64_t a7, uint64_t (*a8)(uint64_t, uint64_t, uint64_t), uint64_t a9, uint64_t a10)
{
  uint64_t v12 = a7;
  uint64_t v13 = UnsafeBufferPointer.baseAddress.getter(a1, a2, a10);
  if (a5)
  {
    if (!v13) {
      BUG();
    }
    uint64_t v12 = a3 * a7;
    if (!is_mul_ok(a3, a7)) {
      BUG();
    }
  }
  else if (!v13)
  {
    BUG();
  }
  uint64_t v14 = UnsafeVectorPointer.init(start:count:stride:)(*(void *)(*(void *)(a10 - 8) + 72) * v12 + v13);
  return a8(v14, v15, v16);
}

uint64_t DenseMatrix.withUnsafeMutableVectorPointer<A>(column:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return DenseMatrix.withUnsafeMutableVectorPointer<A>(row:_:)(a1, a2, a3, a4, a5, (void (*)(void *, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))closure #1 in DenseMatrix.withUnsafeMutableVectorPointer<A>(column:_:));
}

uint64_t DenseMatrix.withUnsafeMutableVectorPointer<A>(row:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, void (*a6)(void *, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))
{
  uint64_t v21 = a4;
  uint64_t v26 = a3;
  uint64_t v23 = v6;
  uint64_t v20 = a2;
  uint64_t v19 = a6;
  uint64_t v8 = v7;
  uint64_t v22 = a1;
  uint64_t v10 = *(void *)(a4 + 16);
  type metadata accessor for ContiguousArray(0, v10);
  uint64_t v24 = v7 + 24;
  ContiguousArray._makeMutableAndUnique()();
  uint64_t v11 = *(void *)(v7 + 24);
  uint64_t v12 = *(void *)(v11 + 16);
  int v13 = *(unsigned __int8 *)(*(void *)(v10 - 8) + 80);
  uint64_t v14 = v11 + ((v13 + 32) & ~v13);
  v18[0] = v14;
  uint64_t v25 = v12;
  v18[1] = v12;
  uint64_t v15 = v26;
  uint64_t v17 = *(void *)(v21 + 24);
  uint64_t v26 = a5;
  v19(v18, v8, a1, a2, v15, v10, a5, v17);
  return $defer #1 <A><A1>() in ContiguousArray.withUnsafeMutableBufferPointer<A>(_:)(v18, v14, v25, v24, v10);
}

uint64_t closure #1 in DenseMatrix.withUnsafeMutableVectorPointer<A>(column:_:)(void *a1, uint64_t a2, unint64_t a3, uint64_t (*a4)(uint64_t, uint64_t, uint64_t), uint64_t a5, uint64_t a6)
{
  char v8 = *(unsigned char *)(a2 + 16);
  uint64_t v9 = UnsafeMutableBufferPointer.baseAddress.getter(*a1, a1[1], a6);
  if (v8)
  {
    if (!v9) {
      BUG();
    }
    unint64_t v11 = a3;
    unint64_t v10 = *(void *)a2 * a3;
    if (!is_mul_ok(*(void *)a2, v11)) {
      BUG();
    }
    uint64_t v12 = *(void *)(*(void *)(a6 - 8) + 72) * v10 + v9;
  }
  else
  {
    if (!v9) {
      BUG();
    }
    uint64_t v12 = *(void *)(*(void *)(a6 - 8) + 72) * a3 + v9;
  }
  uint64_t v13 = UnsafeMutableVectorPointer.init(start:count:stride:)(v12);
  return a4(v13, v14, v15);
}

unsigned __int8 static DenseMatrix.+= infix(_:_:)(uint64_t a1, int64_t a2, int64_t a3, char a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  unint64_t v8 = a3;
  unint64_t v10 = (uint64_t *)a1;
  uint64_t v61 = a6;
  uint64_t v11 = *(void *)(a6 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  if (*(void *)a1 != a2 || *(void *)(a1 + 8) != a3)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000022, "LinearAlgebra/DenseMatrix.swift" + 0x8000000000000000, "LinearAlgebra/DenseMatrix.swift", 31, 2, 304, 0);
    BUG();
  }
  unsigned __int8 v15 = a4 & 1;
  unsigned __int8 result = *(unsigned char *)(a1 + 16);
  uint64_t v59 = a5;
  uint64_t v60 = v11;
  uint64_t v66 = v56;
  if ((result ^ (v15 != 0)))
  {
    int64_t v65 = a2;
    unint64_t v58 = a3;
    if (result)
    {
      if (a3 < 0) {
        BUG();
      }
      if (a3)
      {
        unint64_t v17 = 0;
        char v18 = v56;
        uint64_t v69 = (uint64_t *)a1;
        LODWORD(v64) = v15;
        uint64_t v19 = v61;
        do
        {
          if (v17 == v8) {
            BUG();
          }
          uint64_t v20 = *v10;
          BOOL v21 = *v10 == 0;
          if (*v10 < 0) {
            BUG();
          }
          unint64_t v57 = v17 + 1;
          uint64_t v22 = v66;
          if (!v21)
          {
            unint64_t v23 = 0;
            uint64_t v63 = v20;
            unint64_t v67 = v17;
            do
            {
              uint64_t v62 = (void *)(v23 + 1);
              uint64_t v68 = DenseMatrix.subscript.read(v18, v23, v67, a2, v8, v64, a5, v19);
              uint64_t v24 = v22;
              uint64_t v25 = v18;
              uint64_t v26 = v22;
              uint64_t v27 = v60;
              (*(void (**)(void *, uint64_t, uint64_t))(v60 + 16))(v24, v28, v19);
              ((void (*)(void *, void))v68)(v25, 0);
              uint64_t v30 = type metadata accessor for DenseMatrix(0, v19, a7, v29);
              uint64_t v68 = DenseMatrix.subscript.modify(v25, v23, v67, v30);
              dispatch thunk of static AdditiveArithmetic.+= infix(_:_:)(v31, v26, v19, *(void *)(*(void *)(*(void *)(*(void *)(a7 + 16) + 16) + 8) + 8));
              (*(void (**)(void *, uint64_t))(v27 + 8))(v26, v19);
              uint64_t v22 = v26;
              char v18 = v25;
              ((void (*)(void *, void))v68)(v25, 0);
              unint64_t v8 = v58;
              a2 = v65;
              a5 = v59;
              unint64_t v23 = (unint64_t)v62;
            }
            while ((void *)v63 != v62);
          }
          unsigned __int8 result = v57;
          unint64_t v17 = v57;
          unint64_t v10 = v69;
        }
        while (v57 != v8);
      }
    }
    else
    {
      if (a2 < 0) {
        BUG();
      }
      if (a2)
      {
        unint64_t v43 = 0;
        char v44 = v15;
        LODWORD(v63) = v15;
        uint64_t v69 = (uint64_t *)a1;
        uint64_t v45 = v66;
        uint64_t v46 = v60;
        do
        {
          if (v43 == a2) {
            BUG();
          }
          uint64_t v47 = v10[1];
          if (v47 < 0) {
            BUG();
          }
          unint64_t v64 = v43 + 1;
          if (v47)
          {
            unint64_t v48 = 0;
            uint64_t v68 = (void *)v47;
            unint64_t v67 = v43;
            do
            {
              uint64_t v62 = (void *)(v48 + 1);
              uint64_t v49 = v61;
              unint64_t v50 = DenseMatrix.subscript.read(v56, v67, v48, a2, v8, v44, a5, v61);
              (*(void (**)(void *, uint64_t, uint64_t))(v46 + 16))(v45, v51, v49);
              ((void (*)(void *, void))v50)(v56, 0);
              uint64_t v53 = type metadata accessor for DenseMatrix(0, v49, a7, v52);
              unint64_t v54 = DenseMatrix.subscript.modify(v56, v67, v48, v53);
              dispatch thunk of static AdditiveArithmetic.+= infix(_:_:)(v55, v45, v49, *(void *)(*(void *)(*(void *)(*(void *)(a7 + 16) + 16) + 8) + 8));
              (*(void (**)(void *, uint64_t))(v46 + 8))(v45, v49);
              ((void (*)(void *, void))v54)(v56, 0);
              char v44 = v63;
              unint64_t v8 = v58;
              a2 = v65;
              a5 = v59;
              unint64_t v48 = (unint64_t)v62;
            }
            while (v68 != v62);
          }
          unsigned __int8 result = v64;
          unint64_t v43 = v64;
          unint64_t v10 = v69;
        }
        while (v64 != a2);
      }
    }
  }
  else
  {
    unint64_t v33 = a2;
    uint64_t v32 = a3 * a2;
    if (!is_mul_ok(a3, v33)) {
      BUG();
    }
    uint64_t v34 = (void *)(a1 + 24);
    if (v32 < 0) {
      BUG();
    }
    if (v32)
    {
      Swift::Int v35 = 0;
      int64_t v65 = v32;
      uint64_t v36 = v61;
      uint64_t v37 = v60;
      do
      {
        uint64_t v69 = (uint64_t *)(v35 + 1);
        ContiguousArray.subscript.getter(v35, a5, v36);
        type metadata accessor for ContiguousArray(0, v36);
        uint64_t v38 = v34;
        ContiguousArray._makeMutableAndUnique()();
        uint64_t v39 = *v34;
        ContiguousArray._checkSubscript_mutating(_:)(v35);
        uint64_t v40 = v39 + ((*(unsigned __int8 *)(v37 + 80) + 32) & ~*(unsigned __int8 *)(v37 + 80));
        uint64_t v34 = v38;
        Swift::Int v41 = v40 + *(void *)(v37 + 72) * v35;
        char v42 = v66;
        dispatch thunk of static AdditiveArithmetic.+= infix(_:_:)(v41, v66, v36, *(void *)(*(void *)(*(void *)(*(void *)(a7 + 16) + 16) + 8) + 8));
        (*(void (**)(void *, uint64_t))(v37 + 8))(v42, v36);
        a5 = v59;
        unsigned __int8 result = v69;
        Swift::Int v35 = (Swift::Int)v69;
      }
      while ((uint64_t *)v65 != v69);
    }
  }
  return result;
}

uint64_t static DenseMatrix.+ infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, int64_t a5, int64_t a6, char a7, uint64_t a8, uint64_t a9, uint64_t a10)
{
  v13[0] = a1;
  v13[1] = a2;
  char v14 = a3 & 1;
  uint64_t v15 = a4;
  swift_retain();
  static DenseMatrix.+= infix(_:_:)((uint64_t)v13, a5, a6, a7 & 1, a8, a9, a10);
  return v13[0];
}

unint64_t static DenseMatrix.-= infix(_:_:)(uint64_t a1, unint64_t a2, unint64_t a3, unsigned __int8 a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v8 = *(void *)(a6 - 8);
  int64_t v9 = *(void *)(v8 + 64);
  unint64_t v10 = alloca(v9);
  unint64_t result = (v9 + 15) & 0xFFFFFFFFFFFFFFF0;
  int64_t v12 = alloca(result);
  uint64_t v13 = &v21;
  if (((*(unsigned char *)(a1 + 16) ^ a4) & 1) != 0 || *(void *)a1 != a2 || *(void *)(a1 + 8) != a3)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000002DLL, "ve the same shape." + 0x8000000000000000, "LinearAlgebra/DenseMatrix.swift", 31, 2, 338, 0);
    BUG();
  }
  uint64_t v14 = a3 * a2;
  if (!is_mul_ok(a3, a2)) {
    BUG();
  }
  uint64_t v16 = (uint64_t *)(a1 + 24);
  if (v14 < 0) {
    BUG();
  }
  unint64_t v23 = v16;
  if (v14)
  {
    Swift::Int v17 = 0;
    uint64_t v24 = v14;
    uint64_t v25 = a5;
    do
    {
      Swift::Int v22 = v17 + 1;
      ContiguousArray.subscript.getter(v17, a5, a6);
      type metadata accessor for ContiguousArray(0, a6);
      char v18 = v13;
      uint64_t v19 = v23;
      ContiguousArray._makeMutableAndUnique()();
      uint64_t v20 = *v19;
      ContiguousArray._checkSubscript_mutating(_:)(v17);
      dispatch thunk of static AdditiveArithmetic.-= infix(_:_:)(v20 + ((*(unsigned __int8 *)(v8 + 80) + 32) & ~*(unsigned __int8 *)(v8 + 80)) + *(void *)(v8 + 72) * v17, v18, a6, *(void *)(*(void *)(*(void *)(*(void *)(a7 + 16) + 16) + 8) + 8));
      uint64_t v13 = v18;
      (*(void (**)(uint64_t *, uint64_t))(v8 + 8))(v18, a6);
      a5 = v25;
      unint64_t result = v22;
      Swift::Int v17 = v22;
    }
    while (v24 != v22);
  }
  return result;
}

uint64_t static DenseMatrix.- infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, unint64_t a5, unint64_t a6, char a7, uint64_t a8, uint64_t a9, uint64_t a10)
{
  v13[0] = a1;
  v13[1] = a2;
  char v14 = a3 & 1;
  uint64_t v15 = a4;
  swift_retain();
  static DenseMatrix.-= infix(_:_:)((uint64_t)v13, a5, a6, a7 & 1, a8, a9, a10);
  return v13[0];
}

uint64_t static DenseMatrix<>.*= infix(_:_:)(unint64_t *a1)
{
  uint64_t v2 = (char *)a1[3];
  char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v2);
  a1[3] = (unint64_t)v2;
  if (!isUniquelyReferenced_nonNull_native)
  {
    uint64_t v2 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)v2);
    a1[3] = (unint64_t)v2;
  }
  uint64_t v4 = a1[1] * *a1;
  if (!is_mul_ok(a1[1], *a1)) {
    BUG();
  }
  if (v4 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (v4 > 0x7FFFFFFF) {
    BUG();
  }
  uint64_t result = cblas_sscal_NEWLAPACK(v4, v2 + 32);
  a1[3] = (unint64_t)v2;
  return result;
}

{
  char *v2;
  char isUniquelyReferenced_nonNull_native;
  uint64_t v4;
  uint64_t result;

  uint64_t v2 = (char *)a1[3];
  char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v2);
  a1[3] = (unint64_t)v2;
  if (!isUniquelyReferenced_nonNull_native)
  {
    uint64_t v2 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)v2);
    a1[3] = (unint64_t)v2;
  }
  uint64_t v4 = a1[1] * *a1;
  if (!is_mul_ok(a1[1], *a1)) {
    BUG();
  }
  if (v4 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (v4 > 0x7FFFFFFF) {
    BUG();
  }
  uint64_t result = cblas_dscal_NEWLAPACK(v4, v2 + 32);
  a1[3] = (unint64_t)v2;
  return result;
}

unint64_t static DenseMatrix<>.* infix(_:_:)(unint64_t a1, unint64_t a2, uint64_t a3, char *a4)
{
  swift_retain();
  if (!swift_isUniquelyReferenced_nonNull_native(a4)) {
    a4 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)a4);
  }
  uint64_t v6 = a2 * a1;
  if (!is_mul_ok(a2, a1)) {
    BUG();
  }
  if (v6 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (v6 > 0x7FFFFFFF) {
    BUG();
  }
  cblas_sscal_NEWLAPACK(v6, a4 + 32);
  return a1;
}

{
  uint64_t v6;

  swift_retain();
  if (!swift_isUniquelyReferenced_nonNull_native(a4)) {
    a4 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)a4);
  }
  uint64_t v6 = a2 * a1;
  if (!is_mul_ok(a2, a1)) {
    BUG();
  }
  if (v6 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (v6 > 0x7FFFFFFF) {
    BUG();
  }
  cblas_sscal_NEWLAPACK(v6, a4 + 32);
  return a1;
}

{
  uint64_t v6;

  swift_retain();
  if (!swift_isUniquelyReferenced_nonNull_native(a4)) {
    a4 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)a4);
  }
  uint64_t v6 = a2 * a1;
  if (!is_mul_ok(a2, a1)) {
    BUG();
  }
  if (v6 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (v6 > 0x7FFFFFFF) {
    BUG();
  }
  cblas_dscal_NEWLAPACK(v6, a4 + 32);
  return a1;
}

{
  uint64_t v6;

  swift_retain();
  if (!swift_isUniquelyReferenced_nonNull_native(a4)) {
    a4 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)a4);
  }
  uint64_t v6 = a2 * a1;
  if (!is_mul_ok(a2, a1)) {
    BUG();
  }
  if (v6 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (v6 > 0x7FFFFFFF) {
    BUG();
  }
  cblas_dscal_NEWLAPACK(v6, a4 + 32);
  return a1;
}

unint64_t static DenseMatrix<>./ infix(_:_:)(unint64_t a1, unint64_t a2, uint64_t a3, char *a4)
{
  swift_retain();
  if (!swift_isUniquelyReferenced_nonNull_native(a4)) {
    a4 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)a4);
  }
  uint64_t v6 = a2 * a1;
  if (!is_mul_ok(a2, a1)) {
    BUG();
  }
  if (v6 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (v6 > 0x7FFFFFFF) {
    BUG();
  }
  cblas_sscal_NEWLAPACK(v6, a4 + 32);
  return a1;
}

{
  uint64_t v6;

  swift_retain();
  if (!swift_isUniquelyReferenced_nonNull_native(a4)) {
    a4 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)a4);
  }
  uint64_t v6 = a2 * a1;
  if (!is_mul_ok(a2, a1)) {
    BUG();
  }
  if (v6 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (v6 > 0x7FFFFFFF) {
    BUG();
  }
  cblas_dscal_NEWLAPACK(v6, a4 + 32);
  return a1;
}

unint64_t static DenseMatrix<>.* infix(_:_:)(unint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, unint64_t a6, char a7, uint64_t a8)
{
  uint64_t v9 = a6 * a1;
  if (!is_mul_ok(a6, a1)) {
    BUG();
  }
  uint64_t v13 = specialized ContiguousArray.init(repeating:count:)(v9, 0.0);
  if (!swift_isUniquelyReferenced_nonNull_native(v13)) {
    uint64_t v13 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)v13);
  }
  UnsafeMutableMatrixPointer<A>.addProduct(_:transposed:_:transposed:scaledBy:)(a4 + 32, a1, a2, a3 & 1, 0, a8 + 32, COERCE_DOUBLE(1065353216), a5, a6, a7 & 1, 0, (uint64_t)v13 + 32, a1, a6, a3 & 1);
  return a1;
}

{
  uint64_t v9;
  void *v13;

  uint64_t v9 = a6 * a1;
  if (!is_mul_ok(a6, a1)) {
    BUG();
  }
  uint64_t v13 = specialized ContiguousArray.init(repeating:count:)(v9, 0.0);
  if (!swift_isUniquelyReferenced_nonNull_native(v13)) {
    uint64_t v13 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)v13);
  }
  UnsafeMutableMatrixPointer<A>.addProduct(_:transposed:_:transposed:scaledBy:)(a4 + 32, a1, a2, a3 & 1, 0, a8 + 32, 1.0, a5, a6, a7 & 1, 0, (uint64_t)v13 + 32, a1, a6, a3 & 1);
  return a1;
}

uint64_t static DenseMatrix<>.* infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5)
{
  return static DenseMatrix<>.* infix(_:_:)(a1, a2, a3, a4, a5, (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, void, uint64_t))specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:));
}

{
  return static DenseMatrix<>.* infix(_:_:)(a1, a2, a3, a4, a5, (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, void, uint64_t))specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:));
}

uint64_t static DenseMatrix<>.* infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, char a4, uint64_t a5)
{
  return static DenseMatrix<>.* infix(_:_:)(a1, a2, a3, a4, a5, (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, void, uint64_t))specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:));
}

{
  return static DenseMatrix<>.* infix(_:_:)(a1, a2, a3, a4, a5, (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, void, uint64_t))specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:));
}

uint64_t static DenseMatrix<>.* infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t (*a6)(uint64_t, uint64_t, uint64_t, uint64_t, void, uint64_t))
{
  unsigned __int8 v8 = a3 & 1;
  swift_retain(a5);
  swift_retain(a4);
  return a6(a1, a5, a1, a2, v8, a4);
}

uint64_t static DenseMatrix<>.* infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, char a4, uint64_t a5, uint64_t (*a6)(uint64_t, uint64_t, uint64_t, uint64_t, void, uint64_t))
{
  unsigned __int8 v8 = a4 & 1;
  swift_retain(a1);
  swift_retain(a5);
  return a6(a3, a1, a2, a3, v8, a5);
}

void static DenseMatrix.*= infix(_:_:)(unint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v4 = a1[1] * *a1;
  if (!is_mul_ok(a1[1], *a1)) {
    BUG();
  }
  uint64_t v5 = (uint64_t *)(a1 + 3);
  if (v4 < 0) {
    BUG();
  }
  if (v4)
  {
    Swift::Int v7 = 0;
    type metadata accessor for ContiguousArray(0, a3);
    ContiguousArray._makeMutableAndUnique()();
    ContiguousArray._makeMutableAndUnique()();
    do
    {
      ContiguousArray._makeMutableAndUnique()();
      uint64_t v8 = *v5;
      ContiguousArray._checkSubscript_mutating(_:)(v7);
      dispatch thunk of static Numeric.*= infix(_:_:)(v8+ ((*(unsigned __int8 *)(*(void *)(a3 - 8) + 80) + 32) & ~*(unsigned __int8 *)(*(void *)(a3 - 8) + 80))+ *(void *)(*(void *)(a3 - 8) + 72) * v7++, a2, a3, *(void *)(*(void *)(*(void *)(a4 + 16) + 16) + 8));
    }
    while (v4 != v7);
  }
}

unint64_t static DenseMatrix.* infix(_:_:)(unint64_t a1, unint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  v10[0] = a1;
  v10[1] = a2;
  char v11 = a3 & 1;
  uint64_t v12 = a4;
  swift_retain();
  static DenseMatrix.*= infix(_:_:)(v10, a5, a6, a7);
  return v10[0];
}

unint64_t static DenseMatrix.* infix(_:_:)(uint64_t a1, unint64_t a2, unint64_t a3, char a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  v9[0] = a2;
  v9[1] = a3;
  char v10 = a4 & 1;
  uint64_t v11 = a5;
  swift_retain();
  static DenseMatrix.*= infix(_:_:)(v9, a1, a6, a7);
  return v9[0];
}

unint64_t static DenseMatrix./ infix(_:_:)(unint64_t a1, unint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v28 = a5;
  uint64_t AssociatedConformanceWitness = a1;
  char v9 = a3 & 1;
  uint64_t v31 = *(void *)(a7 + 8);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v31, a6, &protocol requirements base descriptor for ExpressibleByFloatLiteral, &associated type descriptor for ExpressibleByFloatLiteral.FloatLiteralType);
  int64_t v11 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v30 = v25;
  uint64_t v29 = *(void *)(a6 - 8);
  int64_t v14 = *(void *)(v29 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  unint64_t v33 = v25;
  Swift::Int v17 = alloca(v14);
  char v18 = alloca(v14);
  uint64_t v32 = v25;
  v25[0] = a1;
  v25[1] = a2;
  char v26 = v9;
  uint64_t v27 = a4;
  uint64_t v19 = v31;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v31, a6, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByFloatLiteral, &associated conformance descriptor for ExpressibleByFloatLiteral.ExpressibleByFloatLiteral.FloatLiteralType: _ExpressibleByBuiltinFloatLiteral);
  swift_retain();
  uint64_t v20 = v30;
  dispatch thunk of _ExpressibleByBuiltinFloatLiteral.init(_builtinFloatLiteral:)(AssociatedTypeWitness, AssociatedConformanceWitness);
  uint64_t v21 = v33;
  dispatch thunk of ExpressibleByFloatLiteral.init(floatLiteral:)(v20, a6, v19);
  uint64_t v22 = (uint64_t)v32;
  dispatch thunk of static FloatingPoint./ infix(_:_:)(v21, v28, a6, *(void *)(a7 + 16));
  unint64_t v23 = *(void (**)(unint64_t *, uint64_t))(v29 + 8);
  v23(v21, a6);
  static DenseMatrix.*= infix(_:_:)(v25, v22, a6, a7);
  v23((unint64_t *)v22, a6);
  return v25[0];
}

unint64_t static DenseMatrix.* infix(_:_:)(unint64_t a1, unint64_t a2, int a3, uint64_t a4, uint64_t a5, unint64_t a6, char a7, uint64_t a8, uint64_t a9, uint64_t a10)
{
  LODWORD(v98) = a3;
  unint64_t v97 = a1;
  uint64_t v90 = *(void *)(a9 - 8);
  int64_t v13 = *(void *)(v90 + 64);
  int64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v16 = alloca(v13);
  Swift::Int v17 = alloca(v13);
  uint64_t v83 = &v75;
  char v18 = alloca(v13);
  uint64_t v19 = alloca(v13);
  uint64_t v94 = &v75;
  uint64_t v20 = alloca(v13);
  uint64_t v21 = alloca(v13);
  uint64_t v91 = &v75;
  uint64_t v78 = *(void *)(*(void *)(*(void *)(a10 + 16) + 16) + 8);
  uint64_t v85 = *(void *)(v78 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v85, a9, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v22 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  unint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  uint64_t v87 = &v75;
  unint64_t v95 = a2;
  if (a2 != a5)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000040, "ve the same shape and layout." + 0x8000000000000000, "LinearAlgebra/DenseMatrix.swift", 31, 2, 546, 0);
    BUG();
  }
  uint64_t v77 = &v75;
  uint64_t v84 = a4;
  unint64_t v93 = a6;
  if (one-time initialization token for linearAlgebra != -1) {
    swift_once(&one-time initialization token for linearAlgebra, one-time initialization function for linearAlgebra);
  }
  uint64_t v25 = type metadata accessor for Logger(0);
  __swift_project_value_buffer(v25, (uint64_t)static Logger.linearAlgebra);
  char v26 = (os_log_s *)Logger.logObject.getter();
  os_log_type_t v27 = static os_log_type_t.error.getter(v25, static Logger.linearAlgebra);
  uint64_t v28 = a9;
  if (os_log_type_enabled(v26, v27))
  {
    uint64_t v29 = (uint8_t *)swift_slowAlloc(12, -1);
    *(void *)uint64_t v99 = swift_slowAlloc(32, -1);
    v80[0] = *(void *)v99;
    *(_DWORD *)uint64_t v29 = 136315138;
    uint64_t v96 = v29 + 4;
    uint64_t v30 = _typeName(_:qualified:)(a9, 0);
    uint64_t v31 = v26;
    char v33 = v32;
    uint64_t v75 = getNullTerminatedUTF8PointerImpl(_:storingStringOwnersIn:)(v30, v32, v80);
    UnsafeMutableRawBufferPointer.copyMemory(from:)(&v75, v76, v96, v29 + 12);
    swift_bridgeObjectRelease(v33);
    _os_log_impl(&dword_0, v31, v27, "Using a slow implementation of matrix multiplication for %s. Prefer using Float or Double.", v29, 0xCu);
    uint64_t v34 = *(void (**)(void (***)(void, void)))v99;
    swift_arrayDestroy(*(void *)v99, 1, (char *)&type metadata for Any + 8);
    swift_slowDealloc(v34, -1, -1);
    swift_slowDealloc(v29, -1, -1);
    Swift::Int v35 = v31;
    uint64_t v28 = a9;
  }
  else
  {
    Swift::Int v35 = v26;
  }

  int64_t v36 = v95;
  int v37 = v98;
  LOBYTE(v37) = v98 & 1;
  LODWORD(v98) = v37;
  v99[0] = a7 & 1;
  uint64_t v38 = v85;
  uint64_t v39 = AssociatedTypeWitness;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v85, v28, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  Swift::Int v41 = v87;
  uint64_t v79 = AssociatedConformanceWitness;
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, v39, AssociatedConformanceWitness);
  uint64_t v42 = v28;
  unint64_t v43 = v91;
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v41, v42, v38);
  uint64_t v44 = v97;
  uint64_t v45 = (uint64_t)v43;
  uint64_t v46 = v93;
  unint64_t result = DenseMatrix.init(rowCount:columnCount:layout:repeating:)(v97, v93, 0, v45, v42);
  v80[0] = result;
  v80[1] = v48;
  char v81 = v49 & 1;
  uint64_t v82 = v50;
  if (v44 < 0) {
    BUG();
  }
  if (v44)
  {
    if (v46 < 0) {
      BUG();
    }
    unint64_t v51 = 0;
    unint64_t v52 = v97;
    int v88 = v99[0];
    int v89 = v98;
    do
    {
      if (v51 == v52) {
        BUG();
      }
      unint64_t v92 = v51;
      if (v46)
      {
        if (v36 < 0) {
          BUG();
        }
        unint64_t v53 = 0;
        do
        {
          if (v53 == v46) {
            BUG();
          }
          unint64_t v54 = v87;
          uint64_t v96 = (uint8_t *)v53;
          dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, v79);
          dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v54, a9, v85);
          uint64_t v56 = v84;
          if (v36)
          {
            unint64_t v57 = 0;
            do
            {
              unint64_t v98 = v57 + 1;
              unint64_t v58 = (void (*)(uint64_t *, void))DenseMatrix.subscript.read(&v75, v92, v57, v97, v36, v89, v56, a9);
              *(void *)uint64_t v99 = *(void *)(v90 + 16);
              uint64_t v59 = v83;
              (*(void (**)(uint64_t *, uint64_t, uint64_t))v99)(v83, v60, a9);
              v58(&v75, 0);
              uint64_t v61 = (void (*)(uint64_t *, void))DenseMatrix.subscript.read(&v75, v57, (unint64_t)v96, v95, v93, v88, a8, a9);
              uint64_t v62 = v77;
              (*(void (**)(uint64_t *, uint64_t, uint64_t))v99)(v77, v63, a9);
              v61(&v75, 0);
              unint64_t v64 = v59;
              uint64_t v65 = v78;
              dispatch thunk of static Numeric.* infix(_:_:)(v64, v62, a9, v78);
              uint64_t v66 = *(void (**)(uint64_t *, uint64_t))(v90 + 8);
              unint64_t v67 = v62;
              int64_t v36 = v95;
              v66(v67, a9);
              v66(v83, a9);
              uint64_t v68 = *(void *)(v65 + 8);
              uint64_t v69 = v91;
              dispatch thunk of static AdditiveArithmetic.+= infix(_:_:)(v94, v91, a9, v68);
              v66(v69, a9);
              uint64_t v56 = v84;
              unint64_t v57 = v98;
            }
            while (v36 != v98);
          }
          unint64_t v70 = (unint64_t)v96;
          unint64_t v98 = (unint64_t)(v96 + 1);
          uint64_t v71 = type metadata accessor for DenseMatrix(0, a9, a10, v55);
          *(void *)uint64_t v99 = DenseMatrix.subscript.modify(&v75, v92, v70, v71);
          uint64_t v72 = v94;
          uint64_t v73 = v90;
          (*(void (**)(uint64_t, uint64_t *, uint64_t))(v90 + 24))(v74, v94, a9);
          (*(void (**)(uint64_t *, void))v99)(&v75, 0);
          (*(void (**)(uint64_t *, uint64_t))(v73 + 8))(v72, a9);
          unint64_t v53 = v98;
          uint64_t v46 = v93;
        }
        while (v98 != v93);
      }
      unint64_t v51 = v92 + 1;
      unint64_t v52 = v97;
    }
    while (v92 + 1 != v97);
    return v80[0];
  }
  return result;
}

uint64_t static DenseMatrix.* infix(_:_:)(unint64_t a1, unint64_t a2, int a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  LODWORD(v78) = a3;
  unint64_t v72 = a1;
  uint64_t v71 = *(void *)(a6 - 8);
  int64_t v10 = *(void *)(v71 + 64);
  int64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v61 = v57;
  int64_t v13 = alloca(v10);
  int64_t v14 = alloca(v10);
  uint64_t v65 = v57;
  uint64_t v15 = alloca(v10);
  uint64_t v16 = alloca(v10);
  unint64_t v70 = v57;
  Swift::Int v17 = alloca(v10);
  char v18 = alloca(v10);
  uint64_t v75 = v57;
  uint64_t v62 = *(void *)(*(void *)(*(void *)(a7 + 16) + 16) + 8);
  uint64_t v73 = *(void *)(v62 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v73, a6, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v19 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  uint64_t v68 = v57;
  uint64_t v66 = a5;
  if (DenseVector.count.getter(a5, a6) != a2)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000052, "right row count." + 0x8000000000000000, "LinearAlgebra/DenseMatrix.swift", 31, 2, 568, 0);
    BUG();
  }
  uint64_t v59 = a4;
  if (one-time initialization token for linearAlgebra != -1) {
    swift_once(&one-time initialization token for linearAlgebra, one-time initialization function for linearAlgebra);
  }
  uint64_t v22 = type metadata accessor for Logger(0);
  __swift_project_value_buffer(v22, (uint64_t)static Logger.linearAlgebra);
  unint64_t v23 = (os_log_s *)Logger.logObject.getter();
  os_log_type_t v24 = static os_log_type_t.error.getter(v22, static Logger.linearAlgebra);
  BOOL v25 = os_log_type_enabled(v23, v24);
  unint64_t v60 = a2;
  if (v25)
  {
    char v26 = (uint8_t *)swift_slowAlloc(12, -1);
    uint64_t v76 = swift_slowAlloc(32, -1);
    v57[0] = v76;
    *(_DWORD *)char v26 = 136315138;
    uint64_t v77 = (void (*)(uint64_t *, uint64_t, uint64_t))(v26 + 4);
    uint64_t v27 = _typeName(_:qualified:)(a6, 0);
    char v29 = v28;
    uint64_t v74 = getNullTerminatedUTF8PointerImpl(_:storingStringOwnersIn:)(v27, v28, v57);
    UnsafeMutableRawBufferPointer.copyMemory(from:)(&v74, &v75, v77, v26 + 12);
    swift_bridgeObjectRelease(v29);
    _os_log_impl(&dword_0, v23, v24, "Using a slow implementation of matrix multiplication for %s. Prefer using Float or Double.", v26, 0xCu);
    uint64_t v30 = v76;
    swift_arrayDestroy(v76, 1, (char *)&type metadata for Any + 8);
    swift_slowDealloc(v30, -1, -1);
    swift_slowDealloc(v26, -1, -1);
  }

  int v31 = v78;
  LOBYTE(v31) = v78 & 1;
  LODWORD(v78) = v31;
  uint64_t v32 = AssociatedTypeWitness;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v73, a6, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  uint64_t v34 = v68;
  uint64_t v64 = AssociatedConformanceWitness;
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, v32, AssociatedConformanceWitness);
  Swift::Int v35 = v75;
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v34, a6, v73);
  uint64_t v36 = (uint64_t)v35;
  uint64_t v37 = v72;
  uint64_t result = DenseVector.init(repeating:count:)(v36, v72, a6);
  uint64_t v74 = result;
  if (v37 < 0) {
    BUG();
  }
  if (v37)
  {
    uint64_t v39 = 0;
    int v69 = v78;
    do
    {
      if (v39 == v37) {
        BUG();
      }
      uint64_t v76 = v39;
      uint64_t v63 = v39 + 1;
      uint64_t v40 = v68;
      dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, v64);
      dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v40, a6, v73);
      uint64_t v41 = DenseVector.count.getter(v66, a6);
      if (v41 < 0) {
        BUG();
      }
      if (v41)
      {
        unint64_t v42 = 0;
        uint64_t v58 = v41;
        do
        {
          unint64_t v78 = v42 + 1;
          unint64_t v43 = (void (*)(uint64_t *, void))DenseMatrix.subscript.read(v57, v76, v42, v72, v60, v69, v59, a6);
          uint64_t v44 = v71;
          uint64_t v45 = v65;
          uint64_t v77 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v71 + 16);
          v77(v65, v46, a6);
          v43(v57, 0);
          uint64_t v47 = v61;
          DenseVector.subscript.getter();
          uint64_t v48 = v45;
          uint64_t v49 = v62;
          dispatch thunk of static Numeric.* infix(_:_:)(v48, v47, a6, v62);
          uint64_t v50 = *(void (**)(uint64_t *, uint64_t))(v44 + 8);
          v50(v47, a6);
          v50(v65, a6);
          uint64_t v51 = *(void *)(v49 + 8);
          unint64_t v52 = v75;
          dispatch thunk of static AdditiveArithmetic.+= infix(_:_:)(v70, v75, a6, v51);
          v50(v52, a6);
          unint64_t v42 = v78;
        }
        while (v58 != v78);
      }
      else
      {
        uint64_t v77 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v71 + 16);
      }
      uint64_t v53 = (uint64_t)v75;
      unint64_t v54 = v70;
      v77(v75, (uint64_t)v70, a6);
      uint64_t v56 = type metadata accessor for DenseVector(0, a6, a7, v55);
      DenseVector.subscript.setter(v53, v76, v56);
      (*(void (**)(uint64_t *, uint64_t))(v71 + 8))(v54, a6);
      uint64_t v39 = v63;
      uint64_t v37 = v72;
    }
    while (v63 != v72);
    return v74;
  }
  return result;
}

uint64_t static DenseMatrix.* infix(_:_:)(uint64_t a1, unint64_t a2, uint64_t a3, int a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v7 = a6;
  LODWORD(v79) = a4;
  uint64_t v67 = a3;
  uint64_t v73 = *(void *)(a6 - 8);
  int64_t v9 = *(void *)(v73 + 64);
  int64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v62 = v58;
  uint64_t v12 = alloca(v9);
  int64_t v13 = alloca(v9);
  unint64_t v72 = v58;
  int64_t v14 = alloca(v9);
  uint64_t v15 = alloca(v9);
  uint64_t v74 = v58;
  uint64_t v16 = alloca(v9);
  Swift::Int v17 = alloca(v9);
  uint64_t v76 = v58;
  uint64_t v63 = *(void *)(*(void *)(*(void *)(a7 + 16) + 16) + 8);
  uint64_t v68 = *(void *)(v63 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v68, a6, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v18 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  int64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  unint64_t v70 = v58;
  uint64_t v66 = a1;
  if (DenseVector.count.getter(a1, v7) != a2)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000004FLL, "tor element count." + 0x8000000000000000, "LinearAlgebra/DenseMatrix.swift", 31, 2, 588, 0);
    BUG();
  }
  uint64_t v60 = a5;
  if (one-time initialization token for linearAlgebra != -1) {
    swift_once(&one-time initialization token for linearAlgebra, one-time initialization function for linearAlgebra);
  }
  uint64_t v21 = type metadata accessor for Logger(0);
  __swift_project_value_buffer(v21, (uint64_t)static Logger.linearAlgebra);
  uint64_t v22 = (os_log_s *)Logger.logObject.getter();
  os_log_type_t v23 = static os_log_type_t.error.getter(v21, static Logger.linearAlgebra);
  BOOL v24 = os_log_type_enabled(v22, v23);
  unint64_t v61 = a2;
  if (v24)
  {
    uint64_t v25 = swift_slowAlloc(12, -1);
    os_log_t log = v22;
    char v26 = (uint8_t *)v25;
    uint64_t v27 = swift_slowAlloc(32, -1);
    v58[0] = v27;
    *(_DWORD *)char v26 = 136315138;
    unint64_t v78 = (void (*)(uint64_t *, uint64_t, uint64_t))(v26 + 4);
    uint64_t v28 = _typeName(_:qualified:)(v7, 0);
    char v30 = v29;
    uint64_t v75 = getNullTerminatedUTF8PointerImpl(_:storingStringOwnersIn:)(v28, v29, v58);
    UnsafeMutableRawBufferPointer.copyMemory(from:)(&v75, &v76, v78, v26 + 12);
    swift_bridgeObjectRelease(v30);
    os_log_t v31 = log;
    _os_log_impl(&dword_0, log, v23, "Using a slow implementation of matrix multiplication for %s. Prefer using Float or Double.", v26, 0xCu);
    swift_arrayDestroy(v27, 1, (char *)&type metadata for Any + 8);
    swift_slowDealloc(v27, -1, -1);
    swift_slowDealloc(v26, -1, -1);
    os_log_t v32 = v31;
  }
  else
  {
    os_log_t v32 = v22;
  }

  int v33 = v79;
  LOBYTE(v33) = v79 & 1;
  LODWORD(v79) = v33;
  uint64_t v34 = v68;
  uint64_t v35 = AssociatedTypeWitness;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v68, v7, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  uint64_t v37 = v70;
  uint64_t v65 = AssociatedConformanceWitness;
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, v35, AssociatedConformanceWitness);
  uint64_t v38 = (uint64_t)v76;
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v37, v7, v34);
  int64_t v39 = v67;
  uint64_t result = DenseVector.init(repeating:count:)(v38, v67, v7);
  uint64_t v75 = result;
  if (v39 < 0) {
    BUG();
  }
  if (v39)
  {
    uint64_t v41 = 0;
    int v71 = v79;
    do
    {
      if (v41 == (os_log_s *)v39) {
        BUG();
      }
      os_log_t log = v41;
      uint64_t v64 = (os_log_s *)((char *)v41 + 1);
      uint64_t v42 = v7;
      unint64_t v43 = v70;
      dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, v65);
      dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v43, v42, v68);
      uint64_t v44 = DenseVector.count.getter(v66, v42);
      if (v44 < 0) {
        BUG();
      }
      uint64_t v7 = v42;
      if (v44)
      {
        unint64_t v45 = 0;
        uint64_t v59 = v44;
        do
        {
          unint64_t v79 = v45 + 1;
          DenseVector.subscript.getter();
          uint64_t v46 = (void (*)(uint64_t *, void))DenseMatrix.subscript.read(v58, v45, (unint64_t)log, v61, v39, v71, v60, v7);
          uint64_t v47 = v73;
          uint64_t v48 = v62;
          unint64_t v78 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v73 + 16);
          v78(v62, v49, v7);
          v46(v58, 0);
          uint64_t v50 = v63;
          dispatch thunk of static Numeric.* infix(_:_:)(v72, v48, v7, v63);
          uint64_t v51 = *(void (**)(uint64_t *, uint64_t))(v47 + 8);
          v51(v48, v7);
          v51(v72, v7);
          uint64_t v52 = *(void *)(v50 + 8);
          uint64_t v53 = v76;
          dispatch thunk of static AdditiveArithmetic.+= infix(_:_:)(v74, v76, v7, v52);
          v51(v53, v7);
          int64_t v39 = v67;
          unint64_t v45 = v79;
        }
        while (v59 != v79);
      }
      else
      {
        unint64_t v78 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v73 + 16);
      }
      uint64_t v54 = (uint64_t)v76;
      uint64_t v55 = v74;
      v78(v76, (uint64_t)v74, v7);
      uint64_t v57 = type metadata accessor for DenseVector(0, v7, a7, v56);
      DenseVector.subscript.setter(v54, (Swift::Int)log, v57);
      (*(void (**)(uint64_t *, uint64_t))(v73 + 8))(v55, v7);
      uint64_t v41 = v64;
    }
    while (v64 != (os_log_s *)v39);
    return v75;
  }
  return result;
}

void *specialized UnsafeMutableRawPointer.initializeMemory<A>(as:from:count:)(char *__src, int64_t __n, char *__dst)
{
  if (__n < 0)
  {
    _fatalErrorMessage(_:_:file:line:flags:)("Fatal error", 11, 2, "UnsafeMutableRawPointer.initializeMemory with negative count", 60, 2, "Swift/UnsafeRawPointer.swift", 28, 2, 1170, 1);
    goto LABEL_7;
  }
  if (&__dst[__n] > __src && &__src[__n] > __dst)
  {
    _fatalErrorMessage(_:_:file:line:flags:)("Fatal error", 11, 2, "UnsafeMutableRawPointer.initializeMemory overlapping range", 58, 2, "Swift/UnsafeRawPointer.swift", 28, 2, 1173, 1);
LABEL_7:
    BUG();
  }
  return memcpy(__dst, __src, __n);
}

Swift::Void __swiftcall ContiguousArray._checkSubscript_mutating(_:)(Swift::Int a1)
{
  if (a1 < 0) {
    BUG();
  }
  if (*(void *)(v1 + 16) <= (unint64_t)a1) {
    BUG();
  }
}

char *specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(char a1, int64_t a2, char a3, uint64_t a4, void (*a5)(char *, uint64_t, char *))
{
  uint64_t v7 = a2;
  if (a3)
  {
    unint64_t v9 = *(void *)(a4 + 24);
    if ((uint64_t)(v9 >> 1) >= a2)
    {
      uint64_t v7 = *(void *)(a4 + 24) >> 1;
    }
    else
    {
      if ((uint64_t)((v9 >> 1) + 0x4000000000000000) < 0) {
        BUG();
      }
      int64_t v10 = v9 & 0xFFFFFFFFFFFFFFFELL;
      if (v10 > a2) {
        uint64_t v7 = v10;
      }
    }
  }
  uint64_t v11 = *(void *)(a4 + 16);
  if (v7 <= v11) {
    uint64_t v7 = *(void *)(a4 + 16);
  }
  if (v7)
  {
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Float>);
    int64_t v13 = (char *)swift_allocObject(v12, 4 * v7 + 32, 7);
    long long v14 = (uint64_t)(_swift_stdlib_malloc_size(v13) - 32);
    *((void *)v13 + 2) = v11;
    *((void *)v13 + 3) = 2 * (v14 / 4);
  }
  else
  {
    int64_t v13 = (char *)_swiftEmptyArrayStorage;
  }
  uint64_t v15 = v13 + 32;
  uint64_t v16 = (char *)(a4 + 32);
  if (a1)
  {
    a5(v16, v11, v15);
    *(void *)(a4 + 16) = 0;
  }
  else
  {
    specialized UnsafeMutablePointer.initialize(from:count:)(v16, v11, v15);
  }
  swift_release();
  return v13;
}

{
  uint64_t v7;
  unint64_t v9;
  int64_t v10;
  uint64_t v11;
  uint64_t v12;
  char *v13;
  long long v14;
  char *v15;
  char *v16;

  uint64_t v7 = a2;
  if (a3)
  {
    unint64_t v9 = *(void *)(a4 + 24);
    if ((uint64_t)(v9 >> 1) >= a2)
    {
      uint64_t v7 = *(void *)(a4 + 24) >> 1;
    }
    else
    {
      if ((uint64_t)((v9 >> 1) + 0x4000000000000000) < 0) {
        BUG();
      }
      int64_t v10 = v9 & 0xFFFFFFFFFFFFFFFELL;
      if (v10 > a2) {
        uint64_t v7 = v10;
      }
    }
  }
  uint64_t v11 = *(void *)(a4 + 16);
  if (v7 <= v11) {
    uint64_t v7 = *(void *)(a4 + 16);
  }
  if (v7)
  {
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Double>);
    int64_t v13 = (char *)swift_allocObject(v12, 8 * v7 + 32, 7);
    long long v14 = (uint64_t)(_swift_stdlib_malloc_size(v13) - 32);
    *((void *)v13 + 2) = v11;
    *((void *)v13 + 3) = 2 * (v14 / 8);
  }
  else
  {
    int64_t v13 = (char *)_swiftEmptyArrayStorage;
  }
  uint64_t v15 = v13 + 32;
  uint64_t v16 = (char *)(a4 + 32);
  if (a1)
  {
    a5(v16, v11, v15);
    *(void *)(a4 + 16) = 0;
  }
  else
  {
    specialized UnsafeMutablePointer.initialize(from:count:)(v16, v11, v15);
  }
  swift_release();
  return v13;
}

uint64_t $defer #1 <A><A1>() in ContiguousArray.withUnsafeMutableBufferPointer<A>(_:)(void *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  if (!*a1) {
    BUG();
  }
  if (*a1 != a2) {
    BUG();
  }
  if (a1[1] != a3) {
    BUG();
  }
  return type metadata accessor for ContiguousArray(0, a5);
}

uint64_t partial apply for closure #1 in DenseMatrix.withUnsafeVectorPointer<A>(row:_:)(uint64_t a1, uint64_t a2)
{
  return partial apply for closure #1 in DenseMatrix.withUnsafeVectorPointer<A>(row:_:)(a1, a2, (uint64_t (*)(uint64_t, uint64_t, void, void, void, void, void, void, void, void, void, void))closure #1 in DenseMatrix.withUnsafeVectorPointer<A>(row:_:));
}

uint64_t partial apply for closure #1 in DenseMatrix.withUnsafeVectorPointer<A>(column:_:)(uint64_t a1, uint64_t a2)
{
  return partial apply for closure #1 in DenseMatrix.withUnsafeVectorPointer<A>(row:_:)(a1, a2, (uint64_t (*)(uint64_t, uint64_t, void, void, void, void, void, void, void, void, void, void))closure #1 in DenseMatrix.withUnsafeVectorPointer<A>(column:_:));
}

uint64_t partial apply for closure #1 in DenseMatrix.withUnsafeVectorPointer<A>(row:_:)(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t, uint64_t, void, void, void, void, void, void, void, void, void, void))
{
  return a3(a1, a2, *(void *)(v3 + 40), *(void *)(v3 + 48), *(unsigned __int8 *)(v3 + 56), *(void *)(v3 + 64), *(void *)(v3 + 72), *(void *)(v3 + 80), *(void *)(v3 + 88), *(void *)(v3 + 16), *(void *)(v3 + 24), *(void *)(v3 + 32));
}

uint64_t associated type witness table accessor for Matrix.IndexedSequence : Sequence in DenseMatrix<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for DenseMatrix<A>.IndexedSequence, a1);
}

uint64_t associated type witness table accessor for Matrix.Transpose : Matrix in DenseMatrix<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for DenseMatrix<A>.Transpose, a1);
}

uint64_t destroy for DenseMatrix(uint64_t a1)
{
  return swift_release(*(void *)(a1 + 24));
}

uint64_t initializeWithCopy for DenseMatrix(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v3 = *(void *)(a2 + 24);
  *(void *)(a1 + 24) = v3;
  swift_retain(v3);
  return a1;
}

uint64_t assignWithCopy for DenseMatrix(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v3 = *(void *)(a2 + 24);
  uint64_t v4 = *(void *)(a1 + 24);
  *(void *)(a1 + 24) = v3;
  swift_retain(v3);
  swift_release(v4);
  return a1;
}

uint64_t assignWithTake for DenseMatrix(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v3 = *(void *)(a1 + 24);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  swift_release(v3);
  return a1;
}

uint64_t getEnumTagSinglePayload for DenseMatrix(uint64_t a1, int a2)
{
  if (a2)
  {
    if (a2 < 0 && *(unsigned char *)(a1 + 32)) {
      int v2 = *(_DWORD *)a1 + 0x7FFFFFFF;
    }
    else {
      int v2 = (*(void *)(a1 + 24) & 0xFFFFFFFF00000001) != 0 ? -1 : *(void *)(a1 + 24) >> 1;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for DenseMatrix(uint64_t a1, int a2, int a3)
{
  if (a2 < 0)
  {
    *(void *)(a1 + 24) = 0;
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 + 0x80000000;
    if (a3 < 0) {
      *(unsigned char *)(a1 + 32) = 1;
    }
  }
  else
  {
    if (a3 < 0) {
      *(unsigned char *)(a1 + 32) = 0;
    }
    if (a2) {
      *(void *)(a1 + 24) = 2 * (a2 - 1);
    }
  }
}

uint64_t UpperStrictlyTriangularMatrix.rowCount.getter(uint64_t a1)
{
  return a1;
}

uint64_t UpperStrictlyTriangularMatrix.columnCount.getter(uint64_t a1, uint64_t a2)
{
  return a2;
}

uint64_t UpperStrictlyTriangularMatrix.storage.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_retain(a3);
}

uint64_t UpperStrictlyTriangularMatrix.storage.setter(uint64_t a1)
{
  uint64_t result = swift_release(*(void *)(v1 + 16));
  *(void *)(v1 + 16) = a1;
  return result;
}

void (*UpperStrictlyTriangularMatrix.storage.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UpperStrictlyTriangularMatrix.rowStartIndices.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_bridgeObjectRetain(a4);
}

uint64_t UpperStrictlyTriangularMatrix.rowStartIndices.setter(uint64_t a1)
{
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v1 + 24));
  *(void *)(v1 + 24) = a1;
  return result;
}

void (*UpperStrictlyTriangularMatrix.rowStartIndices.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UpperStrictlyTriangularMatrix.unordered.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  v10[0] = a3;
  uint64_t v7 = type metadata accessor for ContiguousArray(0, a5);
  swift_retain(a3);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for ContiguousArray<A>, v7);
  return Array.init<A>(_:)(v10, a5, v7, WitnessTable);
}

uint64_t UpperStrictlyTriangularMatrix.init(rowCount:columnCount:)(uint64_t a1, uint64_t a2, unsigned char *a3, unint64_t a4)
{
  uint64_t v31 = a2;
  uint64_t v5 = a1;
  int64_t v6 = *(void *)(*((void *)a3 - 1) + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  os_log_t v32 = v25;
  v27[1] = a4;
  uint64_t v9 = *(void *)(a4 + 16);
  uint64_t v33 = v9;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v9, a3, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v11 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  uint64_t v12 = alloca(v11);
  int64_t v13 = alloca(v11);
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v9, a3, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, AssociatedConformanceWitness);
  uint64_t v15 = v32;
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v25, a3, v33);
  unint64_t v16 = static UpperStrictlyTriangularMatrix.dataSize(_:_:)(a1, v31);
  os_log_t v32 = a3;
  uint64_t v33 = ContiguousArray.init(repeating:count:)(v15, v16, a3);
  if (a1 < 0) {
    BUG();
  }
  if (a1)
  {
    char v30 = (char *)_swiftEmptyArrayStorage;
    unint64_t v17 = 0;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, a1, 0);
    int64_t v18 = v30;
    for (i = a1; i != v17; uint64_t v5 = i)
    {
      if (v5 == v17) {
        BUG();
      }
      v27[0] = v17;
      closure #1 in UpperStrictlyTriangularMatrix.init(rowCount:columnCount:)(v27, v31);
      uint64_t v19 = v26;
      char v30 = v18;
      unint64_t v20 = *((void *)v18 + 2);
      unint64_t v21 = *((void *)v18 + 3);
      if (v21 >> 1 <= v20)
      {
        uint64_t v29 = v26;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v21 >= 2, v20 + 1, 1);
        uint64_t v19 = v29;
        int64_t v18 = v30;
      }
      ++v17;
      *((void *)v18 + 2) = v20 + 1;
      *(void *)&v18[8 * v20 + 32] = v19;
    }
  }
  else
  {
    int64_t v18 = (char *)_swiftEmptyArrayStorage;
  }
  uint64_t v22 = ContiguousArray.count.getter(v33, v32);
  if (!swift_isUniquelyReferenced_nonNull_native(v18)) {
    int64_t v18 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v18 + 2) + 1, 1, v18);
  }
  unint64_t v23 = *((void *)v18 + 2);
  if (*((void *)v18 + 3) >> 1 <= v23) {
    int64_t v18 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v18 + 3) >= 2uLL, v23 + 1, 1, v18);
  }
  *((void *)v18 + 2) = v23 + 1;
  *(void *)&v18[8 * v23 + 32] = v22;
  return v5;
}

unint64_t static UpperStrictlyTriangularMatrix.dataSize(_:_:)(unint64_t a1, uint64_t a2)
{
  BOOL v2 = __OFSUB__(a2, 1);
  unint64_t v3 = a2 - 1;
  if (v2) {
    BUG();
  }
  unint64_t v5 = v3;
  unint64_t v4 = a1 * v3;
  if (!is_mul_ok(a1, v5)) {
    BUG();
  }
  unint64_t v6 = a1 - 1;
  if (__OFSUB__(a1, 1)) {
    BUG();
  }
  int64_t v7 = v6 * a1;
  if (!is_mul_ok(v6, a1)) {
    BUG();
  }
  BOOL v2 = __OFSUB__(v4, v7 / 2);
  unint64_t v9 = v4 - v7 / 2;
  if (v2) {
    BUG();
  }
  return v9;
}

unint64_t closure #1 in UpperStrictlyTriangularMatrix.init(rowCount:columnCount:)(unint64_t *a1, uint64_t a2)
{
  unint64_t v3 = v2;
  unint64_t v4 = *a1;
  unint64_t v5 = static UpperStrictlyTriangularMatrix.dataSize(_:_:)(*a1, a2);
  BOOL v6 = __OFSUB__(v5, v4);
  unint64_t result = v5 - v4;
  if (v6) {
    BUG();
  }
  unint64_t *v3 = result;
  return result;
}

uint64_t UpperStrictlyTriangularMatrix.subscript.getter(Swift::Int a1, Swift::Int a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  v18[1] = a4;
  uint64_t v23 = v8;
  uint64_t v21 = a6;
  uint64_t v20 = a5;
  uint64_t v19 = *(void *)(a8 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v19, a7, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v10 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  int64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v22 = v18;
  UpperStrictlyTriangularMatrix.checkBounds(row:column:)(a1, a2);
  if (a1 >= a2)
  {
    uint64_t v15 = v19;
    uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v19, a7, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
    unint64_t v17 = v22;
    dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, AssociatedConformanceWitness);
    return dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v17, a7, v15);
  }
  else
  {
    Swift::Int v13 = UpperStrictlyTriangularMatrix.dataIndex(_:_:)(a1, a2);
    return ContiguousArray.subscript.getter(v13, v20, a7);
  }
}

Swift::Void __swiftcall UpperStrictlyTriangularMatrix.checkBounds(row:column:)(Swift::Int row, Swift::Int column)
{
  if (row < 0 || row >= v2)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000012, "gularMatrix.swift" + 0x8000000000000000, "LinearAlgebra/UpperStrictlyTriangularMatrix.swift", 49, 2, 61, 0);
    goto LABEL_8;
  }
  if (column < 0 || column >= v3)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000015, "Row out of bounds." + 0x8000000000000000, "LinearAlgebra/UpperStrictlyTriangularMatrix.swift", 49, 2, 64, 0);
LABEL_8:
    BUG();
  }
}

Swift::Int __swiftcall UpperStrictlyTriangularMatrix.dataIndex(_:_:)(Swift::Int a1, Swift::Int a2)
{
  if (a1 < 0) {
    BUG();
  }
  if (*(void *)(v2 + 16) <= (unint64_t)a1) {
    BUG();
  }
  BOOL v3 = __OFSUB__(a2, 1);
  Swift::Int v4 = a2 - 1;
  if (v3) {
    BUG();
  }
  BOOL v3 = __OFADD__(*(void *)(v2 + 8 * a1 + 32), v4);
  Swift::Int v5 = *(void *)(v2 + 8 * a1 + 32) + v4;
  if (v3) {
    BUG();
  }
  return v5;
}

uint64_t UpperStrictlyTriangularMatrix.subscript.setter(uint64_t a1, Swift::Int a2, Swift::Int a3, uint64_t a4)
{
  uint64_t v6 = *(void *)(a4 + 16);
  UpperStrictlyTriangularMatrix.checkBounds(row:column:)(a2, a3);
  if (a2 >= a3)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000003BLL, "Column out of bounds." + 0x8000000000000000, "LinearAlgebra/UpperStrictlyTriangularMatrix.swift", 49, 2, 52, 0);
    BUG();
  }
  Swift::Int v7 = UpperStrictlyTriangularMatrix.dataIndex(_:_:)(a2, a3);
  type metadata accessor for ContiguousArray(0, v6);
  ContiguousArray._makeMutableAndUnique()();
  uint64_t v8 = *(void *)(v4 + 16);
  ContiguousArray._checkSubscript_mutating(_:)(v7);
  uint64_t v9 = *(void *)(v6 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v9 + 24))(v8 + ((*(unsigned __int8 *)(v9 + 80) + 32) & ~*(unsigned __int8 *)(v9 + 80)) + *(void *)(v9 + 72) * v7, a1, v6);
  MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
  return (*(uint64_t (**)(uint64_t, uint64_t))(v9 + 8))(a1, v6);
}

void (*UpperStrictlyTriangularMatrix.subscript.modify(void *a1, Swift::Int a2, Swift::Int a3, uint64_t a4))(Swift::Int **a1, char a2)
{
  uint64_t v6 = malloc(0x40uLL);
  *a1 = v6;
  v6[3] = v4;
  void v6[2] = a4;
  v6[1] = a3;
  *uint64_t v6 = a2;
  uint64_t v7 = *(void *)(a4 + 16);
  void v6[4] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  void v6[5] = v8;
  size_t v9 = *(void *)(v8 + 64);
  v6[6] = malloc(v9);
  v6[7] = malloc(v9);
  UpperStrictlyTriangularMatrix.subscript.getter(a2, a3, *v4, v4[1], v4[2], v4[3], v7, *(void *)(a4 + 24));
  return UpperStrictlyTriangularMatrix.subscript.modify;
}

void UpperStrictlyTriangularMatrix.subscript.modify(Swift::Int **a1, char a2)
{
  uint64_t v2 = *a1;
  BOOL v3 = (void *)(*a1)[6];
  uint64_t v4 = (void *)(*a1)[7];
  if (a2)
  {
    Swift::Int v8 = v2[5];
    Swift::Int v5 = v2[4];
    uint64_t v7 = v2[2];
    Swift::Int v6 = *v2;
    Swift::Int v9 = v2[1];
    (*(void (**)(void *, void *, Swift::Int))(v8 + 16))(v3, v4, v5);
    UpperStrictlyTriangularMatrix.subscript.setter((uint64_t)v3, v6, v9, v7);
    (*(void (**)(void *, Swift::Int))(v8 + 8))(v4, v5);
  }
  else
  {
    UpperStrictlyTriangularMatrix.subscript.setter((*a1)[7], *v2, v2[1], v2[2]);
  }
  free(v4);
  free(v3);
  free(v2);
}

uint64_t UpperStrictlyTriangularMatrix.transposed()(uint64_t a1, uint64_t a2, uint64_t a3, char a4)
{
  uint64_t v5 = LowerStrictlyTriangularMatrix.init(base:)(a1);
  swift_retain();
  swift_bridgeObjectRetain(a4);
  return v5;
}

BOOL static UpperStrictlyTriangularMatrix.__derived_struct_equals(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10)
{
  return a1 == a5
      && a2 == a6
      && (static ContiguousArray<A>.== infix(_:_:)(a3, a7, a9, *(void *)(*(void *)(a10 + 8) + 8)) & 1) != 0
      && specialized static Array<A>.== infix(_:_:)(a4, a8);
}

uint64_t protocol witness for Matrix.init(rowCount:columnCount:) in conformance UpperStrictlyTriangularMatrix<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  uint64_t result = UpperStrictlyTriangularMatrix.init(rowCount:columnCount:)(a1, a2, *(unsigned char **)(a3 + 16), *(void *)(a3 + 24));
  *uint64_t v4 = result;
  v4[1] = v6;
  v4[2] = v7;
  uint64_t v4[3] = v8;
  return result;
}

uint64_t protocol witness for Matrix.transposed() in conformance UpperStrictlyTriangularMatrix<A>()
{
  uint64_t v2 = v0;
  uint64_t result = UpperStrictlyTriangularMatrix.transposed()(*v1, v1[1], v1[2], v1[3]);
  *uint64_t v2 = result;
  v2[1] = v4;
  v2[2] = v5;
  v2[3] = v6;
  return result;
}

uint64_t protocol witness for Matrix.subscript.getter in conformance UpperStrictlyTriangularMatrix<A>(Swift::Int a1, Swift::Int a2, uint64_t a3)
{
  return UpperStrictlyTriangularMatrix.subscript.getter(a1, a2, *v3, v3[1], v3[2], v3[3], *(void *)(a3 + 16), *(void *)(a3 + 24));
}

uint64_t protocol witness for Matrix.subscript.setter in conformance UpperStrictlyTriangularMatrix<A>(uint64_t a1, Swift::Int a2, Swift::Int a3, uint64_t a4)
{
  return UpperStrictlyTriangularMatrix.subscript.setter(a1, a2, a3, a4);
}

void (*protocol witness for Matrix.subscript.modify in conformance UpperStrictlyTriangularMatrix<A>(void *a1, Swift::Int a2, Swift::Int a3, uint64_t a4))(Swift::Int **a1, char a2)
{
  uint64_t v6 = malloc(0x40uLL);
  *a1 = v6;
  v6[3] = a4;
  void v6[2] = v4;
  v6[1] = a3;
  *uint64_t v6 = a2;
  uint64_t v7 = *(void *)(a4 + 16);
  void v6[4] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  void v6[5] = v8;
  size_t v9 = *(void *)(v8 + 64);
  v6[6] = malloc(v9);
  v6[7] = malloc(v9);
  UpperStrictlyTriangularMatrix.subscript.getter(a2, a3, *v4, v4[1], v4[2], v4[3], v7, *(void *)(a4 + 24));
  return protocol witness for Matrix.subscript.modify in conformance UpperStrictlyTriangularMatrix<A>;
}

void protocol witness for Matrix.subscript.modify in conformance UpperStrictlyTriangularMatrix<A>(Swift::Int **a1, char a2)
{
  uint64_t v2 = *a1;
  BOOL v3 = (void *)(*a1)[6];
  uint64_t v4 = (void *)(*a1)[7];
  if (a2)
  {
    Swift::Int v8 = v2[5];
    Swift::Int v5 = v2[4];
    uint64_t v7 = v2[3];
    Swift::Int v6 = *v2;
    Swift::Int v9 = v2[1];
    (*(void (**)(void *, void *, Swift::Int))(v8 + 16))(v3, v4, v5);
    UpperStrictlyTriangularMatrix.subscript.setter((uint64_t)v3, v6, v9, v7);
    (*(void (**)(void *, Swift::Int))(v8 + 8))(v4, v5);
  }
  else
  {
    UpperStrictlyTriangularMatrix.subscript.setter((*a1)[7], *v2, v2[1], v2[3]);
  }
  free(v4);
  free(v3);
  free(v2);
}

BOOL protocol witness for static Equatable.== infix(_:_:) in conformance UpperStrictlyTriangularMatrix<A>(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  return static UpperStrictlyTriangularMatrix.__derived_struct_equals(_:_:)(*a1, a1[1], a1[2], a1[3], *a2, a2[1], a2[2], a2[3], *(void *)(a3 + 16), *(void *)(a3 + 24));
}

char *specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(char a1, int64_t a2, char a3, uint64_t a4, void (*a5)(uint64_t, uint64_t, char *))
{
  uint64_t v7 = a2;
  if (a3)
  {
    unint64_t v8 = *(void *)(a4 + 24);
    if ((uint64_t)(v8 >> 1) >= a2)
    {
      uint64_t v7 = *(void *)(a4 + 24) >> 1;
    }
    else
    {
      if ((uint64_t)((v8 >> 1) + 0x4000000000000000) < 0) {
        BUG();
      }
      int64_t v9 = v8 & 0xFFFFFFFFFFFFFFFELL;
      if (v9 > a2) {
        uint64_t v7 = v9;
      }
    }
  }
  uint64_t v10 = *(void *)(a4 + 16);
  if (v7 <= v10) {
    uint64_t v7 = *(void *)(a4 + 16);
  }
  if (v7)
  {
    uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int32>);
    uint64_t v12 = (char *)swift_allocObject(v11, 4 * v7 + 32, 7);
    long long v13 = (uint64_t)(_swift_stdlib_malloc_size(v12) - 32);
    *((void *)v12 + 2) = v10;
    *((void *)v12 + 3) = 2 * (v13 / 4);
  }
  else
  {
    uint64_t v12 = (char *)_swiftEmptyArrayStorage;
  }
  long long v14 = v12 + 32;
  if (a1)
  {
    a5(a4 + 32, v10, v14);
    *(void *)(a4 + 16) = 0;
    swift_bridgeObjectRelease(a4);
  }
  else
  {
    specialized _ArrayBuffer._copyContents(subRange:initializing:)(0, v10, v14, a4);
  }
  return v12;
}

uint64_t associated type witness table accessor for Matrix.IndexedSequence : Sequence in UpperStrictlyTriangularMatrix<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UpperStrictlyTriangularMatrix<A>.IndexedSequence, a1);
}

uint64_t associated type witness table accessor for Matrix.Transpose : Matrix in UpperStrictlyTriangularMatrix<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for LowerStrictlyTriangularMatrix<A>, a1);
}

uint64_t destroy for UpperStrictlyTriangularMatrix(uint64_t a1)
{
  return swift_bridgeObjectRelease(*(void *)(a1 + 24));
}

uint64_t initializeWithCopy for UpperStrictlyTriangularMatrix(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  uint64_t v3 = *(void *)(a2 + 16);
  *(void *)(a1 + 16) = v3;
  uint64_t v4 = *(void *)(a2 + 24);
  *(void *)(a1 + 24) = v4;
  swift_retain(v3);
  swift_bridgeObjectRetain(v4);
  return a1;
}

void *assignWithCopy for UpperStrictlyTriangularMatrix(void *a1, void *a2)
{
  *a1 = *a2;
  a1[1] = a2[1];
  uint64_t v3 = a2[2];
  uint64_t v4 = a1[2];
  a1[2] = v3;
  swift_retain(v3);
  swift_release(v4);
  uint64_t v5 = a2[3];
  uint64_t v6 = a1[3];
  a1[3] = v5;
  swift_bridgeObjectRetain(v5);
  swift_bridgeObjectRelease(v6);
  return a1;
}

uint64_t assignWithTake for UpperStrictlyTriangularMatrix(uint64_t a1, _OWORD *a2)
{
  *(_OWORD *)a1 = *a2;
  swift_release(*(void *)(a1 + 16));
  uint64_t v3 = *(void *)(a1 + 24);
  *(_OWORD *)(a1 + 16) = a2[1];
  swift_bridgeObjectRelease(v3);
  return a1;
}

uint64_t getEnumTagSinglePayload for UpperStrictlyTriangularMatrix(uint64_t a1, int a2)
{
  if (a2)
  {
    if (a2 < 0 && *(unsigned char *)(a1 + 32)) {
      int v2 = *(_DWORD *)a1 + 0x7FFFFFFF;
    }
    else {
      int v2 = (*(void *)(a1 + 16) & 0xFFFFFFFF00000001) != 0 ? -1 : *(void *)(a1 + 16) >> 1;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for UpperStrictlyTriangularMatrix(uint64_t a1, int a2, int a3)
{
  if (a2 < 0)
  {
    *(void *)(a1 + 24) = 0;
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 + 0x80000000;
    if (a3 < 0) {
      *(unsigned char *)(a1 + 32) = 1;
    }
  }
  else
  {
    if (a3 < 0) {
      *(unsigned char *)(a1 + 32) = 0;
    }
    if (a2) {
      *(void *)(a1 + 16) = 2 * (a2 - 1);
    }
  }
}

uint64_t type metadata accessor for UpperStrictlyTriangularMatrix(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for UpperStrictlyTriangularMatrix);
}

uint64_t UnsafeMutableVectorPointer.init(start:count:stride:)(uint64_t a1)
{
  return a1;
}

BOOL UnsafeMutableVectorPointer.initialize(repeating:)(uint64_t a1, uint64_t a2, int64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v7 = a1;
  unint64_t v8 = *(void **)(a5 - 8);
  int64_t v9 = v8[8];
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  if (!a4) {
    BUG();
  }
  BOOL result = a3 >= 0;
  if (a4 > 0) {
    BOOL result = a3 <= 0;
  }
  if (!result)
  {
    uint64_t v20 = (void (*)(uint64_t *, uint64_t, uint64_t))v8[2];
    uint64_t v21 = v8[9];
    int64_t v13 = 0;
    uint64_t v17 = a2;
    int64_t v18 = a3;
    uint64_t v19 = a1;
    do
    {
      unint64_t v14 = ((v13 + a4) >> 63) ^ 0x8000000000000000;
      int64_t v15 = v13 * v21;
      BOOL v16 = __OFADD__(a4, v13);
      v13 += a4;
      if (v16) {
        int64_t v13 = v14;
      }
      v20(&v17, v7, a5);
      _sSpsRi_zrlE10initialize2toyxn_tF((uint64_t)&v17, a2 + v15, a5);
      uint64_t v7 = v19;
      a2 = v17;
      BOOL result = v13 <= v18;
      if (a4 > 0) {
        BOOL result = v13 >= v18;
      }
    }
    while (!result);
  }
  return result;
}

uint64_t UnsafeMutableVectorPointer.baseAddress.getter(uint64_t a1)
{
  return a1;
}

void UnsafeMutableVectorPointer.baseAddress.setter(uint64_t a1)
{
  void *v1 = a1;
}

void (*UnsafeMutableVectorPointer.baseAddress.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeMutableVectorPointer.count.getter(uint64_t a1, uint64_t a2)
{
  return a2;
}

void UnsafeMutableVectorPointer.count.setter(uint64_t a1)
{
  *(void *)(v1 + 8) = a1;
}

void (*UnsafeMutableVectorPointer.count.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeMutableVectorPointer.stride.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return a3;
}

void UnsafeMutableVectorPointer.stride.setter(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
}

void (*UnsafeMutableVectorPointer.stride.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeMutableVectorPointer.init(_:)(uint64_t a1)
{
  return a1;
}

uint64_t UnsafeMutableVectorPointer.init(_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return UnsafeMutableVectorPointer.init(_:)(a1, a2, a3, (uint64_t (*)(uint64_t))&UnsafeMutableBufferPointer.baseAddress.getter);
}

uint64_t UnsafeMutableVectorPointer.init(mutating:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return UnsafeMutableVectorPointer.init(_:)(a1, a2, a3, (uint64_t (*)(uint64_t))&UnsafeBufferPointer.baseAddress.getter);
}

uint64_t UnsafeMutableVectorPointer.init(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t (*a4)(uint64_t))
{
  uint64_t result = a4(a1);
  if (!result) {
    BUG();
  }
  return result;
}

uint64_t UnsafeMutableVectorPointer.makeIterator()(uint64_t a1, unint64_t a2, unint64_t a3)
{
  if (!is_mul_ok(a3, a2)) {
    BUG();
  }
  return UnsafeVectorPointer.Iterator.init(baseAddress:end:stride:)(a1);
}

uint64_t UnsafeMutableVectorPointer._copyContents(initializing:)(uint64_t a1, Swift::Int a2, uint64_t a3, Swift::Int a4, unint64_t a5, uint64_t a6)
{
  unint64_t v41 = a5;
  Swift::Int v42 = a2;
  uint64_t v43 = a1;
  unint64_t v45 = *(void **)(a6 - 8);
  int64_t v9 = v45[8];
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v40 = &v34;
  int64_t v12 = *(void *)(*(void *)(type metadata accessor for Optional(0, a6) - 8) + 64);
  int64_t v13 = alloca(v12);
  unint64_t v14 = alloca(v12);
  uint64_t v44 = a3;
  uint64_t v35 = a3;
  Swift::Int offsetBy = a4;
  Swift::Int v36 = a4;
  unint64_t v15 = v41;
  unint64_t v37 = v41;
  uint64_t v18 = type metadata accessor for UnsafeMutableVectorPointer(0, a6, v16, v17);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, v18);
  if (Collection.isEmpty.getter(v18, WitnessTable))
  {
    uint64_t v20 = UnsafeMutableVectorPointer.makeIterator()(v44, offsetBy, v15);
    UnsafeMutableBufferPointer.startIndex.getter(v43, v42, a6);
  }
  else
  {
    Swift::Int v21 = v42;
    uint64_t v22 = UnsafeMutableBufferPointer.baseAddress.getter(v43, v42, a6);
    if (!v22)
    {
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000030, "safeMutableVectorPointer.swift" + 0x8000000000000000, "LinearAlgebra/UnsafeMutableVectorPointer.swift", 46, 2, 109, 0);
      BUG();
    }
    uint64_t v23 = v22;
    unint64_t v24 = v41;
    if (v21 < offsetBy) {
      BUG();
    }
    if (v41 == 1)
    {
      uint64_t v25 = v44;
      UnsafeMutablePointer.initialize(from:count:)(v44, offsetBy, v22, a6);
      Swift::Int v26 = offsetBy;
      uint64_t v27 = v43;
    }
    else
    {
      uint64_t v35 = UnsafeMutableVectorPointer.makeIterator()(v44, offsetBy, v41);
      Swift::Int v36 = v28;
      unint64_t v37 = v29;
      uint64_t v38 = type metadata accessor for UnsafeVectorPointer.Iterator(0, a6, v28, v29);
      UnsafeVectorPointer.Iterator.next()(v38);
      int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)&v34, 1, a6);
      uint64_t v31 = (uint64_t)v40;
      if (EnumTagSinglePayload != 1)
      {
        int64_t v39 = (void (*)(uint64_t, uint64_t *, uint64_t))v45[4];
        do
        {
          v39(v31, &v34, a6);
          _sSpsRi_zrlE10initialize2toyxn_tF(v31, v23, a6);
          v23 += v45[9];
          UnsafeVectorPointer.Iterator.next()(v38);
        }
        while (__swift_getEnumTagSinglePayload((uint64_t)&v34, 1, a6) != 1);
      }
      Swift::Int v21 = v42;
      uint64_t v27 = v43;
      Swift::Int v26 = offsetBy;
      unint64_t v24 = v41;
      uint64_t v25 = v44;
    }
    if (!is_mul_ok(v24, v26)) {
      BUG();
    }
    unint64_t v45 = (void *)UnsafeVectorPointer.Iterator.init(baseAddress:end:stride:)(v45[9] * v24 * v26 + v25);
    Swift::Int v32 = UnsafeMutableBufferPointer.startIndex.getter(v27, v21, a6);
    uint64_t v20 = (uint64_t)v45;
    UnsafeMutableBufferPointer.index(_:offsetBy:)(v32, offsetBy);
  }
  return v20;
}

uint64_t type metadata accessor for UnsafeMutableVectorPointer(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for UnsafeMutableVectorPointer);
}

uint64_t protocol witness for Sequence.makeIterator() in conformance UnsafeMutableVectorPointer<A>()
{
  int v2 = v0;
  uint64_t result = UnsafeMutableVectorPointer.makeIterator()(*(void *)v1, *(void *)(v1 + 8), *(void *)(v1 + 16));
  *int v2 = result;
  v2[1] = v4;
  v2[2] = v5;
  return result;
}

uint64_t protocol witness for Sequence.underestimatedCount.getter in conformance UnsafeMutableVectorPointer<A>(uint64_t a1)
{
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, a1);
  return Collection.underestimatedCount.getter(a1, WitnessTable);
}

uint64_t protocol witness for Sequence._copyToContiguousArray() in conformance UnsafeMutableVectorPointer<A>(uint64_t a1)
{
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, a1);
  return Collection._copyToContiguousArray()(a1, WitnessTable);
}

uint64_t protocol witness for Sequence._copyContents(initializing:) in conformance UnsafeMutableVectorPointer<A>(uint64_t *a1, uint64_t a2, Swift::Int a3, uint64_t a4)
{
  *a1 = UnsafeMutableVectorPointer._copyContents(initializing:)(a2, a3, *(void *)v4, *(void *)(v4 + 8), *(void *)(v4 + 16), *(void *)(a4 + 16));
  a1[1] = v5;
  a1[2] = v6;
  return v7;
}

uint64_t protocol witness for Sequence.withContiguousStorageIfAvailable<A>(_:) in conformance UnsafeMutableVectorPointer<A>(uint64_t (*a1)(uint64_t, uint64_t), uint64_t a2, uint64_t a3, uint64_t a4)
{
  return UnsafeMutableVectorPointer.withContiguousStorageIfAvailable<A>(_:)(a1, a2, *v4, v4[1], v4[2], *(void *)(a4 + 16), a3);
}

uint64_t UnsafeMutableVectorPointer.withContiguousStorageIfAvailable<A>(_:)(uint64_t (*a1)(uint64_t, uint64_t), uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v9 = v7;
  if (a5 == 1)
  {
    uint64_t v10 = UnsafeBufferPointer.init(start:count:)(a3, a4, a6);
    uint64_t result = a1(v10, v11);
    if (v8) {
      return result;
    }
    uint64_t v13 = 0;
  }
  else
  {
    uint64_t v13 = 1;
  }
  return __swift_storeEnumTagSinglePayload(v9, v13, 1, a7);
}

uint64_t UnsafeMutableVectorPointer.startIndex.getter()
{
  return 0;
}

uint64_t UnsafeMutableVectorPointer.endIndex.getter(uint64_t a1, uint64_t a2)
{
  return a2;
}

Swift::Int __swiftcall UnsafeMutableVectorPointer.index(after:)(Swift::Int after)
{
  return after + 1;
}

Swift::Void __swiftcall UnsafeMutableVectorPointer.formIndex(after:)(Swift::Int *after)
{
}

Swift::Int __swiftcall UnsafeMutableVectorPointer.index(before:)(Swift::Int before)
{
  return before - 1;
}

Swift::Void __swiftcall UnsafeMutableVectorPointer.formIndex(before:)(Swift::Int *before)
{
}

Swift::Int __swiftcall UnsafeMutableVectorPointer.index(_:offsetBy:)(Swift::Int _, Swift::Int offsetBy)
{
  return _ + offsetBy;
}

Swift::Int_optional __swiftcall UnsafeMutableVectorPointer.index(_:offsetBy:limitedBy:)(Swift::Int _, Swift::Int offsetBy, Swift::Int limitedBy)
{
  Swift::Int v3 = limitedBy - _;
  if (offsetBy <= 0)
  {
    if (v3 > 0 || v3 <= offsetBy) {
      goto LABEL_8;
    }
  }
  else if (v3 < 0 || v3 >= (unint64_t)offsetBy)
  {
LABEL_8:
    v4.value = _ + offsetBy;
    v4.is_nil = 0;
    return v4;
  }
  v4.value = 0;
  v4.is_nil = 1;
  return v4;
}

Swift::Int __swiftcall UnsafeMutableVectorPointer.distance(from:to:)(Swift::Int from, Swift::Int to)
{
  return to - from;
}

uint64_t UnsafeMutableVectorPointer.indices.getter()
{
  return 0;
}

uint64_t UnsafeMutableVectorPointer.subscript.getter(unint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, uint64_t a5)
{
  return UnsafeMutableVectorPointer.subscript.getter(a1, a2, a3, a4, a5);
}

{
  return UnsafeMutableVectorPointer.subscript.getter(a1, a2, a3, a4, a5);
}

{
  uint64_t v5;
  unint64_t v6;

  uint64_t v6 = a4 * a1;
  if (!is_mul_ok(a4, a1)) {
    BUG();
  }
  return (*(uint64_t (**)(uint64_t, unint64_t, uint64_t))(*(void *)(a5 - 8) + 16))(v5, *(void *)(*(void *)(a5 - 8) + 72) * v6 + a2, a5);
}

void (*UnsafeMutableVectorPointer.subscript.modify(uint64_t a1, unint64_t a2, uint64_t a3, uint64_t a4, unint64_t a5))()
{
  if (!is_mul_ok(a5, a2)) {
    BUG();
  }
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

{
  if (!is_mul_ok(a5, a2)) {
    BUG();
  }
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeMutableVectorPointer.subscript.setter(uint64_t a1, unint64_t a2, uint64_t a3, uint64_t a4, unint64_t a5, uint64_t a6)
{
  return UnsafeMutableVectorPointer.subscript.setter(a1, a2, a3, a4, a5, a6);
}

{
  return UnsafeMutableVectorPointer.subscript.setter(a1, a2, a3, a4, a5, a6);
}

{
  unint64_t v6;

  uint64_t v6 = a5 * a2;
  if (!is_mul_ok(a5, a2)) {
    BUG();
  }
  return (*(uint64_t (**)(unint64_t, uint64_t, uint64_t))(*(void *)(a6 - 8) + 40))(*(void *)(*(void *)(a6 - 8) + 72) * v6 + a3, a1, a6);
}

uint64_t UnsafeMutableVectorPointer.subscript.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v7 = v6;
  v14[0] = a3;
  v14[1] = a4;
  v14[2] = a5;
  v15[0] = a1;
  v15[1] = a2;
  uint64_t v8 = type metadata accessor for UnsafeMutableVectorPointer(0, a6, a3, a4);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, v8);
  Slice.init(base:bounds:)(v14, v15, v8, WitnessTable);
  uint64_t result = v12;
  *(_OWORD *)uint64_t v7 = v11;
  *(void *)(v7 + 16) = v12;
  *(_OWORD *)(v7 + 24) = v13;
  return result;
}

uint64_t UnsafeMutableVectorPointer.subscript.setter(long long *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, unint64_t a6, uint64_t a7)
{
  unint64_t v36 = a6;
  uint64_t v39 = a4;
  uint64_t v40 = *(void *)(a7 - 8);
  int64_t v7 = *(void *)(v40 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  *(void *)&v34[0] = a2;
  *((void *)&v34[0] + 1) = a3;
  uint64_t v33 = *((void *)a1 + 4);
  long long v10 = *a1;
  long long v32 = a1[1];
  long long v31 = v10;
  uint64_t v11 = type metadata accessor for UnsafeMutableVectorPointer(255, a7, a3, a7);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, v11);
  uint64_t v37 = v11;
  uint64_t v13 = v11;
  uint64_t v14 = type metadata accessor for Slice(0, v11, WitnessTable);
  Slice.startIndex.getter(v14);
  uint64_t v33 = *((void *)a1 + 4);
  long long v15 = *a1;
  long long v32 = a1[1];
  uint64_t v38 = v14;
  Slice.endIndex.getter(v14, v13, v16, v17, v18, v19, v15, *((void *)&v15 + 1), v32, *((void *)&v32 + 1), v33);
  if (v35 < (uint64_t)v41) {
    BUG();
  }
  *(void *)&long long v31 = v41;
  *((void *)&v31 + 1) = v35;
  uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Range<Int>);
  uint64_t v21 = lazy protocol witness table accessor for type Range<Int> and conformance <> Range<A>();
  zip<A, B>(_:_:)(v34, &v31, v20, v20, v21, v21);
  v34[0] = v41;
  v34[1] = v42;
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Range<Int>, Range<Int>>);
  Zip2Sequence.makeIterator()(v22);
  uint64_t v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Range<Int>, Range<Int>>.Iterator);
  uint64_t result = Zip2Sequence.Iterator.next()(v23);
  if (!(_BYTE)v42)
  {
    uint64_t result = *((void *)&v41 + 1);
    unint64_t v25 = v41;
    do
    {
      uint64_t v43 = *((void *)a1 + 4);
      long long v26 = *a1;
      long long v42 = a1[1];
      long long v41 = v26;
      *(void *)&v34[0] = result;
      uint64_t v27 = swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, v37);
      Slice<>.subscript.getter(v34, v38, v27);
      unint64_t v29 = v25;
      unint64_t v28 = v36 * v25;
      if (!is_mul_ok(v36, v29)) {
        BUG();
      }
      (*(void (**)(unint64_t, long long *, uint64_t))(v40 + 40))(v39 + *(void *)(v40 + 72) * v28, &v31, a7);
      uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Range<Int>, Range<Int>>.Iterator);
      Zip2Sequence.Iterator.next()(v30);
      uint64_t result = *((void *)&v41 + 1);
      unint64_t v25 = v41;
    }
    while ((_BYTE)v42 != 1);
  }
  return result;
}

void (*UnsafeMutableVectorPointer.subscript.modify(void *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7))(uint64_t *a1, char a2)
{
  long long v10 = malloc(0xA8uLL);
  *a1 = v10;
  v10[20] = a7;
  v10[19] = a6;
  v10[18] = a5;
  v10[17] = a4;
  unsigned char v10[16] = a3;
  v10[15] = a2;
  UnsafeMutableVectorPointer.subscript.getter(a2, a3, a4, a5, a6, a7);
  return UnsafeMutableVectorPointer.subscript.modify;
}

void UnsafeMutableVectorPointer.subscript.modify(uint64_t *a1, char a2)
{
  uint64_t v2 = *a1;
  uint64_t v3 = *a1 + 40;
  uint64_t v4 = *(void *)(v2 + 160);
  unint64_t v5 = *(void *)(v2 + 152);
  uint64_t v6 = *(void *)(v2 + 136);
  uint64_t v7 = *(void *)(v2 + 128);
  uint64_t v8 = *(void *)(v2 + 120);
  if (a2) {
    uint64_t v3 = v2;
  }
  *(void *)(v3 + 32) = *(void *)(v2 + 112);
  long long v9 = *(_OWORD *)(v2 + 80);
  *(_OWORD *)(v3 + 16) = *(_OWORD *)(v2 + 96);
  *(_OWORD *)uint64_t v3 = v9;
  UnsafeMutableVectorPointer.subscript.setter((long long *)v3, v8, v7, v6, v4, v5, v4);
  free((void *)v2);
}

Swift::Void __swiftcall UnsafeMutableVectorPointer.swapAt(_:_:)(Swift::Int a1, Swift::Int a2)
{
  v17[0] = v2;
  uint64_t v6 = v5;
  uint64_t v7 = *(void *)(v5 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  long long v9 = alloca(v8);
  long long v10 = alloca(v8);
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  if (a1 != a2)
  {
    if (!is_mul_ok(v4, a1)) {
      BUG();
    }
    if (!is_mul_ok(v4, a2)) {
      BUG();
    }
    uint64_t v13 = *(void *)(v7 + 72);
    Swift::Int v14 = v3 + v13 * v4 * a1;
    uint64_t v15 = v3 + v13 * v4 * a2;
    v17[0] = v17;
    UnsafeMutablePointer.move()(v14);
    UnsafeMutablePointer.moveInitialize(from:count:)(v15, 1, v14, v6);
    uint64_t v16 = v17[0];
    (*(void (**)(void *, void, uint64_t))(v7 + 16))(v17, v17[0], v6);
    _sSpsRi_zrlE10initialize2toyxn_tF((uint64_t)v17, v15, v6);
    (*(void (**)(uint64_t, uint64_t))(v7 + 8))(v16, v6);
  }
}

uint64_t protocol witness for MutableCollection.subscript.setter in conformance UnsafeMutableVectorPointer<A>(uint64_t a1, unint64_t *a2, uint64_t a3, uint64_t a4)
{
  uint64_t v5 = *(void *)(a3 + 16);
  uint64_t v6 = UnsafeMutableVectorPointer.subscript.modify((uint64_t)v10, *a2, *(void *)v4, a4, *(void *)(v4 + 16));
  uint64_t v7 = *(void *)(v5 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v7 + 24))(v8, a1, v5);
  ((void (*)(unsigned char *, void))v6)(v10, 0);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v7 + 8))(a1, v5);
}

void (*protocol witness for MutableCollection.subscript.modify in conformance UnsafeMutableVectorPointer<A>(void *a1, unint64_t *a2))(void (***a1)(void))
{
  uint64_t v3 = malloc(0x28uLL);
  *a1 = v3;
  v3[4] = UnsafeMutableVectorPointer.subscript.modify((uint64_t)v3, *a2, *(void *)v2, v4, *(void *)(v2 + 16));
  return protocol witness for Collection.subscript.read in conformance <> InterspersedSequence<A>;
}

uint64_t protocol witness for MutableCollection.subscript.setter in conformance UnsafeMutableVectorPointer<A>(long long *a1, uint64_t *a2, uint64_t a3)
{
  return UnsafeMutableVectorPointer.subscript.setter(a1, *a2, a2[1], *(void *)v3, a2[1], *(void *)(v3 + 16), *(void *)(a3 + 16));
}

void (*protocol witness for MutableCollection.subscript.modify in conformance UnsafeMutableVectorPointer<A>(void *a1, uint64_t *a2, uint64_t a3))(uint64_t *a1, char a2)
{
  uint64_t v5 = malloc(0xA8uLL);
  *a1 = v5;
  uint64_t v6 = *a2;
  v5[15] = *a2;
  uint64_t v7 = a2[1];
  unsigned char v5[16] = v7;
  uint64_t v8 = *v3;
  v5[17] = *v3;
  uint64_t v9 = v3[1];
  v5[18] = v9;
  uint64_t v10 = v3[2];
  v5[19] = v10;
  uint64_t v11 = *(void *)(a3 + 16);
  v5[20] = v11;
  UnsafeMutableVectorPointer.subscript.getter(v6, v7, v8, v9, v10, v11);
  return UnsafeMutableVectorPointer.subscript.modify;
}

uint64_t protocol witness for MutableCollection.partition(by:) in conformance UnsafeMutableVectorPointer<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, a3);
  return MutableCollection<>.partition(by:)(a1, a2, a3, WitnessTable, a4);
}

void protocol witness for MutableCollection.swapAt(_:_:) in conformance UnsafeMutableVectorPointer<A>(Swift::Int *a1, Swift::Int *a2)
{
}

uint64_t protocol witness for MutableCollection._withUnsafeMutableBufferPointerIfSupported<A>(_:) in conformance UnsafeMutableVectorPointer<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MutableCollection._withUnsafeMutableBufferPointerIfSupported<A>(_:)(a1, a2, a4, a3);
}

uint64_t protocol witness for MutableCollection.withContiguousMutableStorageIfAvailable<A>(_:) in conformance UnsafeMutableVectorPointer<A>(uint64_t (*a1)(uint64_t *), uint64_t a2, uint64_t a3, uint64_t a4)
{
  return UnsafeMutableVectorPointer.withContiguousMutableStorageIfAvailable<A>(_:)(a1, a2, a4, a3);
}

uint64_t UnsafeMutableVectorPointer.withContiguousMutableStorageIfAvailable<A>(_:)(uint64_t (*a1)(uint64_t *), uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v7 = v4;
  int64_t v9 = *(void *)(*(void *)(a4 - 8) + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  if (v6[2] != 1) {
    return __swift_storeEnumTagSinglePayload(v7, 1, 1, a4);
  }
  uint64_t v40 = *(void *)(a4 - 8);
  uint64_t v39 = v7;
  uint64_t v38 = a4;
  uint64_t v33 = a1;
  uint64_t v12 = *v6;
  uint64_t v13 = v6[1];
  uint64_t v14 = *(void *)(a3 + 16);
  uint64_t v34 = a2;
  uint64_t v15 = UnsafeMutableBufferPointer.init(start:count:)(v12, v13, v14);
  uint64_t v35 = v5;
  uint64_t v17 = v16;
  uint64_t v28 = v15;
  uint64_t v29 = v16;
  uint64_t v36 = v14;
  uint64_t v37 = UnsafeMutableBufferPointer.baseAddress.getter(v15, v16, v14);
  long long v41 = v27;
  uint64_t v18 = v35;
  uint64_t result = v33(&v28);
  if (!v18)
  {
    uint64_t v30 = v37;
    uint64_t v31 = v17;
    uint64_t v20 = v29;
    uint64_t v21 = v36;
    uint64_t v32 = UnsafeMutableBufferPointer.baseAddress.getter(v28, v29, v36);
    v27[0] = v20;
    uint64_t v22 = type metadata accessor for UnsafeMutablePointer(255, v21);
    uint64_t v23 = type metadata accessor for Optional(0, v22);
    v27[1] = swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutablePointer<A>, v22);
    uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for <A> A?, v23);
    if ((== infix<A, B>(_:_:)(&v30, &v31, &v32, v27, v23, &type metadata for Int, WitnessTable) & 1) == 0) {
      BUG();
    }
    uint64_t v25 = v39;
    uint64_t v26 = v38;
    (*(void (**)(uint64_t, void *, uint64_t))(v40 + 32))(v39, v41, v38);
    return __swift_storeEnumTagSinglePayload(v25, 0, 1, v26);
  }
  return result;
}

Swift::Int protocol witness for RandomAccessCollection.index(_:offsetBy:limitedBy:) in conformance UnsafeMutableVectorPointer<A>(Swift::Int *a1, Swift::Int a2, Swift::Int *a3)
{
  return protocol witness for RandomAccessCollection.index(_:offsetBy:limitedBy:) in conformance UnsafeMutableVectorPointer<A>(a1, a2, a3);
}

{
  uint64_t v3;
  uint64_t v4;
  Swift::Int_optional v5;

  uint64_t v4 = v3;
  uint64_t v5 = UnsafeMutableVectorPointer.index(_:offsetBy:limitedBy:)(*a1, a2, *a3);
  *(void *)uint64_t v4 = v5.value;
  *(unsigned char *)(v4 + 8) = v5.is_nil;
  return v5.value;
}

void *protocol witness for Collection.endIndex.getter in conformance UnsafeMutableVectorPointer<A>()
{
  *uint64_t result = *(void *)(v1 + 8);
  return result;
}

void (*protocol witness for Collection.subscript.read in conformance UnsafeMutableVectorPointer<A>(uint64_t **a1, unint64_t *a2, uint64_t a3))(void (***a1)(void))
{
  uint64_t v5 = (uint64_t *)malloc(0x28uLL);
  *a1 = v5;
  void v5[4] = (uint64_t)UnsafeMutableVectorPointer.subscript.read(v5, *a2, *(void *)v3, *(void *)(v3 + 8), *(void *)(v3 + 16), *(void *)(a3 + 16));
  return protocol witness for Collection.subscript.read in conformance <> InterspersedSequence<A>;
}

void (*UnsafeMutableVectorPointer.subscript.read(uint64_t *a1, unint64_t a2, uint64_t a3, uint64_t a4, unint64_t a5, uint64_t a6))(void *a1)
{
  *a1 = a6;
  uint64_t v8 = *(void *)(a6 - 8);
  a1[1] = v8;
  a1[2] = (uint64_t)malloc(*(void *)(v8 + 64));
  UnsafeMutableVectorPointer.subscript.getter(a2, a3, v9, a5, a6);
  return InterspersedSequence<>.subscript.read;
}

uint64_t protocol witness for Collection.subscript.getter in conformance UnsafeMutableVectorPointer<A>(uint64_t *a1, uint64_t a2)
{
  uint64_t v4 = v2;
  UnsafeMutableVectorPointer.subscript.getter(*a1, a1[1], *v3, v3[1], v3[2], *(void *)(a2 + 16));
  uint64_t result = v8;
  *(void *)(v4 + 32) = v8;
  *(_OWORD *)(v4 + 16) = v7;
  *(_OWORD *)uint64_t v4 = v6;
  return result;
}

uint64_t protocol witness for Collection.indices.getter in conformance UnsafeMutableVectorPointer<A>()
{
  uint64_t v1 = v0;
  uint64_t result = UnsafeMutableVectorPointer.indices.getter();
  void *v1 = 0;
  v1[1] = v3;
  return result;
}

Swift::Int protocol witness for Collection.index(after:) in conformance UnsafeMutableVectorPointer<A>(Swift::Int *a1)
{
  uint64_t v2 = v1;
  Swift::Int result = UnsafeMutableVectorPointer.index(after:)(*a1);
  *uint64_t v2 = result;
  return result;
}

void protocol witness for Collection.formIndex(after:) in conformance UnsafeMutableVectorPointer<A>(Swift::Int *after)
{
}

Swift::Int protocol witness for BidirectionalCollection.index(before:) in conformance UnsafeMutableVectorPointer<A>(Swift::Int *a1)
{
  uint64_t v2 = v1;
  Swift::Int result = UnsafeMutableVectorPointer.index(before:)(*a1);
  *uint64_t v2 = result;
  return result;
}

void protocol witness for BidirectionalCollection.formIndex(before:) in conformance UnsafeMutableVectorPointer<A>(Swift::Int *before)
{
}

Swift::Int protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance UnsafeMutableVectorPointer<A>(Swift::Int *a1, Swift::Int a2)
{
  uint64_t v3 = v2;
  Swift::Int result = UnsafeMutableVectorPointer.index(_:offsetBy:)(*a1, a2);
  Swift::Int *v3 = result;
  return result;
}

Swift::Int protocol witness for BidirectionalCollection.distance(from:to:) in conformance UnsafeMutableVectorPointer<A>(Swift::Int *a1, Swift::Int *a2)
{
  return UnsafeMutableVectorPointer.distance(from:to:)(*a1, *a2);
}

uint64_t UnsafeMutableVectorPointer.init(rebasing:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v4 = type metadata accessor for UnsafeMutableVectorPointer(255, a2, a3, a4);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, v4);
  uint64_t v6 = v4;
  uint64_t v7 = type metadata accessor for Slice(0, v4, WitnessTable);
  Slice.base.getter(v7);
  Slice.startIndex.getter(v7);
  Slice.base.getter(v7);
  if (!is_mul_ok(v13, v15)) {
    BUG();
  }
  uint64_t v17 = *(void *)(*(void *)(a2 - 8) + 72) * v13 * v15 + v14;
  Slice.endIndex.getter(v7, v6, v8, v9, v10, v11);
  Slice.startIndex.getter(v7);
  Slice.base.getter(v7);
  return v17;
}

Swift::Void __swiftcall UnsafeMutableVectorPointer.deallocate()()
{
}

uint64_t static UnsafeMutableVectorPointer.allocate(capacity:)(uint64_t a1, uint64_t a2)
{
  return static UnsafeMutablePointer.allocate(capacity:)(a1, a2);
}

BOOL UnsafeMutableVectorPointer.assign(repeating:)(uint64_t a1, uint64_t a2, int64_t a3, uint64_t a4, uint64_t a5)
{
  if (!a4) {
    BUG();
  }
  BOOL result = a3 >= 0;
  if (a4 > 0) {
    BOOL result = a3 <= 0;
  }
  if (!result)
  {
    uint64_t v10 = *(void *)(a5 - 8);
    uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v10 + 24);
    uint64_t v17 = *(void *)(v10 + 72);
    int64_t v11 = 0;
    uint64_t v15 = a2;
    do
    {
      unint64_t v12 = ((a4 + v11) >> 63) ^ 0x8000000000000000;
      int64_t v13 = v11 * v17;
      BOOL v14 = __OFADD__(a4, v11);
      v11 += a4;
      if (v14) {
        int64_t v11 = v12;
      }
      v16(a2 + v13, a1, a5);
      a2 = v15;
      BOOL result = v11 <= a3;
      if (a4 > 0) {
        BOOL result = v11 >= a3;
      }
    }
    while (!result);
  }
  return result;
}

uint64_t UnsafeMutableVectorPointer.debugDescription.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  _StringGuts.grow(_:)(60);
  v6._char object = "l buffer pointer" + 0x8000000000000000;
  v6._uint64_t countAndFlagsBits = 0xD000000000000022;
  String.append(_:)(v6);
  v17[0] = a1;
  uint64_t v7 = type metadata accessor for UnsafeMutablePointer(0, a4);
  DefaultStringInterpolation.appendInterpolation<A>(_:)(v17, v7);
  v6._uint64_t countAndFlagsBits = 0x3A746E756F63202CLL;
  v6._char object = (void *)0xE900000000000020;
  String.append(_:)(v6);
  v17[0] = a2;
  uint64_t v8 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  uint64_t v10 = v9;
  v6._uint64_t countAndFlagsBits = v8;
  v6._char object = v9;
  String.append(_:)(v6);
  swift_bridgeObjectRelease(v10);
  v6._uint64_t countAndFlagsBits = 0x656469727473202CLL;
  v6._char object = (void *)0xEA0000000000203ALL;
  String.append(_:)(v6);
  v17[0] = a3;
  uint64_t v11 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  int64_t v13 = v12;
  v6._uint64_t countAndFlagsBits = v11;
  v6._char object = v12;
  String.append(_:)(v6);
  swift_bridgeObjectRelease(v13);
  v6._uint64_t countAndFlagsBits = 41;
  v6._char object = (void *)0xE100000000000000;
  String.append(_:)(v6);
  return 0;
}

uint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in UnsafeMutableVectorPointer<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UnsafeVectorPointer<A>.Iterator, a1);
}

uint64_t base witness table accessor for Collection in UnsafeMutableVectorPointer<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, a1);
}

uint64_t associated type witness table accessor for Collection.SubSequence : MutableCollection in UnsafeMutableVectorPointer<A>(uint64_t a1, uint64_t a2)
{
  return swift_getWitnessTable(&protocol conformance descriptor for <> Slice<A>, a1);
}

uint64_t base witness table accessor for BidirectionalCollection in UnsafeMutableVectorPointer<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, a1);
}

uint64_t associated type witness table accessor for Collection.Indices : RandomAccessCollection in UnsafeMutableVectorPointer<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return associated type witness table accessor for Collection.Indices : RandomAccessCollection in UnsafeMutableVectorPointer<A>(a1, a2, a3, (uint64_t)&protocol conformance descriptor for <> Range<A>);
}

uint64_t associated type witness table accessor for Collection.SubSequence : RandomAccessCollection in UnsafeMutableVectorPointer<A>(uint64_t a1, uint64_t a2)
{
  return swift_getWitnessTable(&protocol conformance descriptor for <> Slice<A>, a1);
}

uint64_t base witness table accessor for Sequence in UnsafeMutableVectorPointer<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, a1);
}

uint64_t associated type witness table accessor for Collection.Indices : Collection in UnsafeMutableVectorPointer<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return associated type witness table accessor for Collection.Indices : RandomAccessCollection in UnsafeMutableVectorPointer<A>(a1, a2, a3, (uint64_t)&protocol conformance descriptor for <> Range<A>);
}

uint64_t associated type witness table accessor for Collection.Indices : BidirectionalCollection in UnsafeMutableVectorPointer<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return associated type witness table accessor for Collection.Indices : RandomAccessCollection in UnsafeMutableVectorPointer<A>(a1, a2, a3, (uint64_t)&protocol conformance descriptor for <> Range<A>);
}

uint64_t associated type witness table accessor for Collection.Indices : RandomAccessCollection in UnsafeMutableVectorPointer<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_getWitnessTable(a4, a1);
}

uint64_t associated type witness table accessor for Collection.SubSequence : BidirectionalCollection in UnsafeMutableVectorPointer<A>(uint64_t a1, uint64_t a2)
{
  return swift_getWitnessTable(&protocol conformance descriptor for <> Slice<A>, a1);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance UnsafeMutableVectorPointer<A>(uint64_t a1)
{
  return UnsafeMutableVectorPointer.debugDescription.getter(*v1, v1[1], v1[2], *(void *)(a1 + 16));
}

uint64_t base witness table accessor for AccelerateBuffer in UnsafeMutableVectorPointer<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, a1);
}

uint64_t protocol witness for AccelerateMutableBuffer.withUnsafeMutableBufferPointer<A>(_:) in conformance UnsafeMutableVectorPointer<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, a4);
  return AccelerateMutableBuffer<>.withUnsafeMutableBufferPointer<A>(_:)(a1, a2, a4, a3, a5, WitnessTable);
}

uint64_t protocol witness for AccelerateBuffer.withUnsafeBufferPointer<A>(_:) in conformance UnsafeMutableVectorPointer<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, a4);
  return AccelerateBuffer<>.withUnsafeBufferPointer<A>(_:)(a1, a2, a4, a3, a5, WitnessTable);
}

uint64_t getEnumTagSinglePayload for UnsafeMutableVectorPointer(uint64_t a1, int a2)
{
  if (a2)
  {
    if (a2 == 1 || !*(unsigned char *)(a1 + 24)) {
      int v2 = -(*(void *)a1 != 0);
    }
    else {
      int v2 = *(_DWORD *)a1 + 1;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for UnsafeMutableVectorPointer(uint64_t a1, unsigned int a2, unsigned int a3)
{
  if (a2 > 1)
  {
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 - 2;
    if (a3 >= 2) {
      *(unsigned char *)(a1 + 24) = 1;
    }
  }
  else
  {
    if (a3 >= 2) {
      *(unsigned char *)(a1 + 24) = 0;
    }
    if (a2) {
      *(void *)a1 = 0;
    }
  }
}

uint64_t UnsafeMutableVectorPointer.init(mutating:)(uint64_t a1)
{
  return UnsafeMutableVectorPointer.init(start:count:stride:)(a1);
}

Swift::Int protocol witness for Collection.distance(from:to:) in conformance UnsafeMutableVectorPointer<A>(Swift::Int *a1, Swift::Int *a2)
{
  return protocol witness for BidirectionalCollection.distance(from:to:) in conformance UnsafeMutableVectorPointer<A>(a1, a2);
}

Swift::Int protocol witness for Collection.index(_:offsetBy:) in conformance UnsafeMutableVectorPointer<A>(Swift::Int *a1, Swift::Int a2)
{
  return protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance UnsafeMutableVectorPointer<A>(a1, a2);
}

uint64_t protocol witness for Collection.count.getter in conformance UnsafeMutableVectorPointer<A>()
{
  return protocol witness for Matrix.columnCount.getter in conformance DenseMatrix<A>();
}

uint64_t protocol witness for Matrix.indexed() in conformance DenseMatrix<A>(uint64_t a1, uint64_t a2)
{
  return protocol witness for Matrix.indexed() in conformance DenseMatrix<A>(a1, a2, DenseMatrix.indexed());
}

uint64_t DenseMatrix.indexed()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a1;
}

uint64_t DenseMatrix.IndexedSequence.init(base:)(uint64_t a1)
{
  return a1;
}

uint64_t DenseMatrix.Transpose.indexed()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a1;
}

uint64_t DenseMatrix.IndexedSequence.base.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a1;
}

uint64_t DenseMatrix.IndexedSequence.makeIterator()(uint64_t a1, uint64_t a2, char a3, uint64_t a4)
{
  *(_OWORD *)(v4 + 32) = 0;
  *(void *)(v4 + 48) = 0;
  *(void *)uint64_t v4 = a1;
  *(void *)(v4 + 8) = a2;
  *(unsigned char *)(v4 + 16) = a3 & 1;
  *(void *)(v4 + 24) = a4;
  return swift_retain(a4);
}

uint64_t DenseMatrix.IndexedSequence.Iterator.init(base:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4)
{
  *(void *)uint64_t result = a1;
  *(void *)(result + 8) = a2;
  *(unsigned char *)(result + 16) = a3 & 1;
  *(void *)(result + 24) = a4;
  *(_OWORD *)(result + 32) = 0;
  *(void *)(result + 48) = 0;
  return result;
}

uint64_t protocol witness for Sequence.makeIterator() in conformance DenseMatrix<A>.IndexedSequence()
{
  DenseMatrix.IndexedSequence.makeIterator()(*(void *)v0, *(void *)(v0 + 8), *(unsigned char *)(v0 + 16), *(void *)(v0 + 24));
  return swift_release();
}

uint64_t DenseMatrix.IndexedSequence.Iterator.base.getter()
{
  uint64_t v1 = *v0;
  swift_retain(v0[3]);
  return v1;
}

uint64_t DenseMatrix.IndexedSequence.Iterator.row.getter()
{
  return *(void *)(v0 + 32);
}

void DenseMatrix.IndexedSequence.Iterator.row.setter(uint64_t a1)
{
  *(void *)(v1 + 32) = a1;
}

void (*DenseMatrix.IndexedSequence.Iterator.row.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t DenseMatrix.IndexedSequence.Iterator.column.getter()
{
  return *(void *)(v0 + 40);
}

void DenseMatrix.IndexedSequence.Iterator.column.setter(uint64_t a1)
{
  *(void *)(v1 + 40) = a1;
}

void (*DenseMatrix.IndexedSequence.Iterator.column.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t DenseMatrix.IndexedSequence.Iterator.flatIndex.getter()
{
  return *(void *)(v0 + 48);
}

void DenseMatrix.IndexedSequence.Iterator.flatIndex.setter(uint64_t a1)
{
  *(void *)(v1 + 48) = a1;
}

void (*DenseMatrix.IndexedSequence.Iterator.flatIndex.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t DenseMatrix.IndexedSequence.Iterator.next()(uint64_t a1)
{
  uint64_t v36 = v1;
  uint64_t v3 = *(void *)(a1 + 16);
  TupleTypeMetadata3 = swift_getTupleTypeMetadata3(0, &type metadata for Int, &type metadata for Int, v3, "row column element ", 0);
  int64_t v5 = *(void *)(*(void *)(TupleTypeMetadata3 - 8) + 64);
  Swift::String v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v8 = *(void *)(v3 - 8);
  int64_t v9 = *(void *)(v8 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v12 = v2[1];
  uint64_t v13 = v2[5];
  if (v13 >= v12) {
    return __swift_storeEnumTagSinglePayload((uint64_t)v36, 1, 1, TupleTypeMetadata3);
  }
  uint64_t v14 = v2[4];
  if (v14 >= *v2) {
    return __swift_storeEnumTagSinglePayload((uint64_t)v36, 1, 1, TupleTypeMetadata3);
  }
  uint64_t v35 = *v2;
  uint64_t v38 = v14;
  uint64_t v37 = v13;
  uint64_t v39 = v2 + 5;
  uint64_t v40 = v2 + 4;
  uint64_t v15 = v2[3];
  uint64_t v32 = v2[6];
  uint64_t v31 = (uint64_t)&v31;
  uint64_t v16 = TupleTypeMetadata3;
  uint64_t v33 = &v31;
  ContiguousArray.subscript.getter(v32, v15, v3);
  uint64_t v34 = v16;
  uint64_t v17 = *(int *)(v16 + 64) + v31;
  uint64_t v18 = *(void (**)(uint64_t, uint64_t *, uint64_t))(v8 + 32);
  v18(v17, v33, v3);
  if (*((unsigned char *)v2 + 16))
  {
    uint64_t v19 = v38;
    uint64_t v20 = v38 + 1;
    uint64_t v21 = v40;
    void *v40 = v38 + 1;
    uint64_t v22 = v37;
    uint64_t v23 = v37;
    unint64_t v24 = v39;
    if (v20 != v35) {
      goto LABEL_9;
    }
    goto LABEL_8;
  }
  uint64_t v22 = v37;
  uint64_t v26 = v37 + 1;
  uint64_t v21 = v39;
  void *v39 = v37 + 1;
  uint64_t v19 = v38;
  uint64_t v23 = v38;
  unint64_t v24 = v40;
  if (v26 == v12)
  {
LABEL_8:
    *unint64_t v24 = v23 + 1;
    void *v21 = 0;
  }
LABEL_9:
  if (__OFADD__(1, v32)) {
    BUG();
  }
  v2[6] = v32 + 1;
  uint64_t v27 = v34;
  uint64_t v28 = v18;
  uint64_t v29 = v36;
  uint64_t v30 = (char *)v36 + *(int *)(v34 + 64);
  *uint64_t v36 = v19;
  v29[1] = v22;
  ((void (*)(char *, uint64_t, uint64_t, void *))v28)(v30, v17, v3, v24);
  return __swift_storeEnumTagSinglePayload((uint64_t)v29, 0, 1, v27);
}

uint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in DenseMatrix<A>.IndexedSequence(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for DenseMatrix<A>.IndexedSequence.Iterator, a1);
}

uint64_t protocol witness for IteratorProtocol.next() in conformance DenseMatrix<A>.IndexedSequence.Iterator(uint64_t a1)
{
  return DenseMatrix.IndexedSequence.Iterator.next()(a1);
}

uint64_t type metadata accessor for DenseMatrix.IndexedSequence(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for DenseMatrix.IndexedSequence);
}

uint64_t initializeWithCopy for DenseMatrix.IndexedSequence.Iterator(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v3 = *(void *)(a2 + 24);
  *(void *)(a1 + 24) = v3;
  *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  swift_retain(v3);
  return a1;
}

uint64_t assignWithCopy for DenseMatrix.IndexedSequence.Iterator(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v3 = *(void *)(a2 + 24);
  uint64_t v4 = *(void *)(a1 + 24);
  *(void *)(a1 + 24) = v3;
  swift_retain(v3);
  swift_release(v4);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  return a1;
}

uint64_t assignWithTake for DenseMatrix.IndexedSequence.Iterator(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v3 = *(void *)(a1 + 24);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  swift_release(v3);
  *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  return a1;
}

uint64_t getEnumTagSinglePayload for DenseMatrix.IndexedSequence.Iterator(uint64_t a1, int a2)
{
  if (a2)
  {
    if (a2 < 0 && *(unsigned char *)(a1 + 56)) {
      int v2 = *(_DWORD *)a1 + 0x7FFFFFFF;
    }
    else {
      int v2 = (*(void *)(a1 + 24) & 0xFFFFFFFF00000001) != 0 ? -1 : *(void *)(a1 + 24) >> 1;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for DenseMatrix.IndexedSequence.Iterator(uint64_t a1, int a2, int a3)
{
  if (a2 < 0)
  {
    *(_OWORD *)(a1 + 40) = 0;
    *(_OWORD *)(a1 + 24) = 0;
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 + 0x80000000;
    if (a3 < 0) {
      *(unsigned char *)(a1 + 56) = 1;
    }
  }
  else
  {
    if (a3 < 0) {
      *(unsigned char *)(a1 + 56) = 0;
    }
    if (a2) {
      *(void *)(a1 + 24) = 2 * (a2 - 1);
    }
  }
}

uint64_t type metadata accessor for DenseMatrix.IndexedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for DenseMatrix.IndexedSequence.Iterator);
}

uint64_t protocol witness for Matrix.indexed() in conformance DenseMatrix<A>.Transpose(uint64_t a1, uint64_t a2)
{
  return protocol witness for Matrix.indexed() in conformance DenseMatrix<A>(a1, a2, DenseMatrix.Transpose.indexed());
}

uint64_t protocol witness for Matrix.indexed() in conformance DenseMatrix<A>(uint64_t a1, uint64_t a2, uint64_t (*a3)(void, void, void, void))
{
  uint64_t v5 = v3;
  uint64_t result = a3(*(void *)v4, *(void *)(v4 + 8), *(unsigned __int8 *)(v4 + 16), *(void *)(v4 + 24));
  *(void *)uint64_t v5 = result;
  *(void *)(v5 + 8) = v8;
  *(unsigned char *)(v5 + 16) = v7 & 1;
  *(void *)(v5 + 24) = v9;
  return result;
}

uint64_t destroy for DenseMatrix.IndexedSequence(uint64_t a1)
{
  return destroy for DenseMatrix(a1);
}

uint64_t initializeBufferWithCopyOfBuffer for DenseMatrix.IndexedSequence(uint64_t *a1, uint64_t *a2)
{
  return initializeBufferWithCopyOfBuffer for CGRect(a1, a2);
}

uint64_t LowerStrictlyTriangularMatrix.indexed()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a1;
}

uint64_t LowerStrictlyTriangularMatrix.IndexedSequence.init(base:)(uint64_t a1)
{
  return a1;
}

uint64_t LowerStrictlyTriangularMatrix.IndexedSequence.base.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a1;
}

uint64_t LowerStrictlyTriangularMatrix.IndexedSequence.makeIterator()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  *(_OWORD *)(v4 + 40) = 0;
  *(void *)uint64_t v4 = a1;
  *(void *)(v4 + 8) = a2;
  *(void *)(v4 + 16) = a3;
  *(void *)(v4 + 24) = a4;
  *(void *)(v4 + 32) = 1;
  swift_retain(a3);
  return swift_bridgeObjectRetain(a4);
}

uint64_t LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.init(base:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  *(void *)uint64_t result = a1;
  *(void *)(result + 8) = a2;
  *(void *)(result + 16) = a3;
  *(void *)(result + 24) = a4;
  *(void *)(result + 32) = 1;
  *(_OWORD *)(result + 40) = 0;
  return result;
}

uint64_t protocol witness for Sequence.makeIterator() in conformance LowerStrictlyTriangularMatrix<A>.IndexedSequence()
{
  uint64_t v1 = v0[3];
  LowerStrictlyTriangularMatrix.IndexedSequence.makeIterator()(*v0, v0[1], v0[2], v1);
  swift_bridgeObjectRelease(v1);
  return swift_release();
}

uint64_t LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.base.getter()
{
  uint64_t v1 = *v0;
  uint64_t v2 = v0[3];
  swift_retain(v0[2]);
  swift_bridgeObjectRetain(v2);
  return v1;
}

uint64_t LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.row.getter()
{
  return *(void *)(v0 + 32);
}

void LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.row.setter(uint64_t a1)
{
  *(void *)(v1 + 32) = a1;
}

void (*LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.row.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.column.getter()
{
  return *(void *)(v0 + 40);
}

void LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.column.setter(uint64_t a1)
{
  *(void *)(v1 + 40) = a1;
}

void (*LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.column.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.flatIndex.getter()
{
  return *(void *)(v0 + 48);
}

void LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.flatIndex.setter(uint64_t a1)
{
  *(void *)(v1 + 48) = a1;
}

void (*LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.flatIndex.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.next()(uint64_t a1)
{
  unint64_t v24 = v1;
  uint64_t v3 = *(void *)(a1 + 16);
  TupleTypeMetadata3 = swift_getTupleTypeMetadata3(0, &type metadata for Int, &type metadata for Int, v3, "row column element ", 0);
  int64_t v5 = *(void *)(*(void *)(TupleTypeMetadata3 - 8) + 64);
  Swift::String v6 = alloca(v5);
  char v7 = alloca(v5);
  uint64_t v8 = *(void *)(v3 - 8);
  int64_t v9 = *(void *)(v8 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v12 = v2[5];
  if (v12 >= v2[1]) {
    return __swift_storeEnumTagSinglePayload((uint64_t)v24, 1, 1, TupleTypeMetadata3);
  }
  uint64_t v13 = *v2;
  uint64_t v14 = v2[4];
  if (v14 >= *v2) {
    return __swift_storeEnumTagSinglePayload((uint64_t)v24, 1, 1, TupleTypeMetadata3);
  }
  uint64_t v28 = (char *)v2[2];
  uint64_t v26 = v2[6];
  uint64_t v27 = TupleTypeMetadata3;
  uint64_t v22 = v14;
  uint64_t v25 = &v22;
  uint64_t v23 = v13;
  swift_retain();
  ContiguousArray.subscript.getter(v26, v28, v3);
  swift_release();
  uint64_t v15 = *(void (**)(char *, uint64_t *, uint64_t))(v8 + 32);
  uint64_t v28 = (char *)&v22 + *(int *)(v27 + 64);
  v15(v28, v25, v3);
  uint64_t v16 = v22;
  uint64_t v17 = v22 + 1;
  v2[4] = v22 + 1;
  if (v17 == v23)
  {
    v2[5] = v12 + 1;
    if (__OFADD__(2, v12)) {
      BUG();
    }
    v2[4] = v12 + 2;
  }
  if (__OFADD__(1, v26)) {
    BUG();
  }
  v2[6] = v26 + 1;
  uint64_t v18 = v27;
  uint64_t v19 = v24;
  uint64_t v20 = (char *)v24 + *(int *)(v27 + 64);
  *unint64_t v24 = v16;
  v19[1] = v12;
  v15(v20, (uint64_t *)v28, v3);
  return __swift_storeEnumTagSinglePayload((uint64_t)v19, 0, 1, v18);
}

uint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in LowerStrictlyTriangularMatrix<A>.IndexedSequence(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for LowerStrictlyTriangularMatrix<A>.IndexedSequence.Iterator, a1);
}

uint64_t protocol witness for IteratorProtocol.next() in conformance LowerStrictlyTriangularMatrix<A>.IndexedSequence.Iterator(uint64_t a1)
{
  return LowerStrictlyTriangularMatrix.IndexedSequence.Iterator.next()(a1);
}

uint64_t destroy for LowerStrictlyTriangularMatrix.IndexedSequence(uint64_t a1)
{
  return destroy for UpperStrictlyTriangularMatrix(a1);
}

uint64_t type metadata accessor for LowerStrictlyTriangularMatrix.IndexedSequence(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for LowerStrictlyTriangularMatrix.IndexedSequence);
}

uint64_t initializeWithCopy for LowerStrictlyTriangularMatrix.IndexedSequence.Iterator(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  uint64_t v3 = *(void *)(a2 + 16);
  *(void *)(a1 + 16) = v3;
  uint64_t v4 = *(void *)(a2 + 24);
  *(void *)(a1 + 24) = v4;
  *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  swift_retain(v3);
  swift_bridgeObjectRetain(v4);
  return a1;
}

void *assignWithCopy for LowerStrictlyTriangularMatrix.IndexedSequence.Iterator(void *a1, void *a2)
{
  *a1 = *a2;
  a1[1] = a2[1];
  uint64_t v3 = a2[2];
  uint64_t v4 = a1[2];
  a1[2] = v3;
  swift_retain(v3);
  swift_release(v4);
  uint64_t v5 = a2[3];
  uint64_t v6 = a1[3];
  a1[3] = v5;
  swift_bridgeObjectRetain(v5);
  swift_bridgeObjectRelease(v6);
  a1[4] = a2[4];
  a1[5] = a2[5];
  a1[6] = a2[6];
  return a1;
}

uint64_t assignWithTake for LowerStrictlyTriangularMatrix.IndexedSequence.Iterator(uint64_t a1, uint64_t a2)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  swift_release(*(void *)(a1 + 16));
  uint64_t v3 = *(void *)(a1 + 24);
  *(_OWORD *)(a1 + 16) = *(_OWORD *)(a2 + 16);
  swift_bridgeObjectRelease(v3);
  *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  return a1;
}

uint64_t getEnumTagSinglePayload for LowerStrictlyTriangularMatrix.IndexedSequence.Iterator(uint64_t a1, int a2)
{
  if (a2)
  {
    if (a2 < 0 && *(unsigned char *)(a1 + 56)) {
      int v2 = *(_DWORD *)a1 + 0x7FFFFFFF;
    }
    else {
      int v2 = (*(void *)(a1 + 16) & 0xFFFFFFFF00000001) != 0 ? -1 : *(void *)(a1 + 16) >> 1;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for LowerStrictlyTriangularMatrix.IndexedSequence.Iterator(uint64_t a1, int a2, int a3)
{
  if (a2 < 0)
  {
    *(_OWORD *)(a1 + 40) = 0;
    *(_OWORD *)(a1 + 24) = 0;
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 + 0x80000000;
    if (a3 < 0) {
      *(unsigned char *)(a1 + 56) = 1;
    }
  }
  else
  {
    if (a3 < 0) {
      *(unsigned char *)(a1 + 56) = 0;
    }
    if (a2) {
      *(void *)(a1 + 16) = 2 * (a2 - 1);
    }
  }
}

uint64_t type metadata accessor for LowerStrictlyTriangularMatrix.IndexedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for LowerStrictlyTriangularMatrix.IndexedSequence.Iterator);
}

uint64_t protocol witness for Matrix.indexed() in conformance LowerStrictlyTriangularMatrix<A>()
{
  int v2 = v0;
  uint64_t result = LowerStrictlyTriangularMatrix.indexed()(*v1, v1[1], v1[2], v1[3]);
  *int v2 = result;
  v2[1] = v4;
  v2[2] = v5;
  v2[3] = v6;
  return result;
}

uint64_t initializeBufferWithCopyOfBuffer for LowerStrictlyTriangularMatrix.IndexedSequence(uint64_t *a1, uint64_t *a2)
{
  return initializeBufferWithCopyOfBuffer for CGRect(a1, a2);
}

uint64_t DenseMatrix.Transpose.init(base:)(uint64_t a1)
{
  return a1;
}

uint64_t DenseMatrix.Transpose.base.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a1;
}

uint64_t DenseMatrix.Transpose.base.setter(uint64_t a1, uint64_t a2, char a3, uint64_t a4)
{
  char v6 = a3 & 1;
  uint64_t result = swift_release(*(void *)(v4 + 24));
  *(void *)uint64_t v4 = a1;
  *(void *)(v4 + 8) = a2;
  *(unsigned char *)(v4 + 16) = v6;
  *(void *)(v4 + 24) = a4;
  return result;
}

void (*DenseMatrix.Transpose.base.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t DenseMatrix.Transpose.rowCount.getter(uint64_t a1, uint64_t a2)
{
  return a2;
}

uint64_t DenseMatrix.Transpose.columnCount.getter(uint64_t a1)
{
  return a1;
}

char DenseMatrix.Transpose.layout.getter(uint64_t a1, uint64_t a2, char a3)
{
  return a3 & 1;
}

unint64_t DenseMatrix.Transpose.count.getter(unint64_t a1, unint64_t a2)
{
  return DenseMatrix.count.getter(a1, a2);
}

unint64_t DenseMatrix.Transpose.init(rowCount:columnCount:)(unint64_t a1, unint64_t a2, uint64_t a3, uint64_t a4)
{
  return DenseMatrix.init(rowCount:columnCount:)(a2, a1, a3, a4);
}

void (*DenseMatrix.Transpose.subscript.read(void *a1, unint64_t a2, unint64_t a3, unint64_t a4, unint64_t a5, char a6, long long a7))(void (***a1)(void, void))
{
  int64_t v9 = malloc(0x28uLL);
  *a1 = v9;
  v9[4] = DenseMatrix.subscript.read(v9, a3, a2, a4, a5, a6 & 1, a7, *((uint64_t *)&a7 + 1));
  return DenseMatrix.Transpose.subscript.read;
}

void DenseMatrix.Transpose.subscript.read(void (***a1)(void, void))
{
}

void (*DenseMatrix.Transpose.subscript.modify(void *a1, unint64_t a2, unint64_t a3, uint64_t a4))(void (***a1)(void, void))
{
  char v6 = malloc(0x28uLL);
  *a1 = v6;
  uint64_t v8 = type metadata accessor for DenseMatrix(0, *(void *)(a4 + 16), *(void *)(a4 + 24), v7);
  void v6[4] = DenseMatrix.subscript.modify(v6, a3, a2, v8);
  return DenseMatrix.Transpose.subscript.read;
}

uint64_t DenseMatrix.Transpose.subscript.getter(unint64_t a1, unint64_t a2, unint64_t a3, unint64_t a4, char a5, uint64_t a6, uint64_t a7)
{
  uint64_t v8 = v7;
  int64_t v9 = DenseMatrix.subscript.read(v12, a2, a1, a3, a4, a5 & 1, a6, a7);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(a7 - 8) + 16))(v8, v10, a7);
  return ((uint64_t (*)(void *, void))v9)(v12, 0);
}

uint64_t DenseMatrix.Transpose.subscript.setter(uint64_t a1, unint64_t a2, unint64_t a3, uint64_t a4)
{
  uint64_t v5 = *(void *)(a4 + 16);
  uint64_t v6 = type metadata accessor for DenseMatrix(0, v5, *(void *)(a4 + 24), a4);
  uint64_t v7 = DenseMatrix.subscript.modify(v11, a3, a2, v6);
  uint64_t v8 = *(void *)(v5 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v8 + 24))(v9, a1, v5);
  ((void (*)(void *, void))v7)(v11, 0);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v8 + 8))(a1, v5);
}

uint64_t DenseMatrix.Transpose.transposed()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a1;
}

uint64_t static DenseMatrix.Transpose.__derived_struct_equals(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, char a7, long long a8, uint64_t a9)
{
  return static DenseMatrix.__derived_struct_equals(_:_:)(a1, a2, a3 & 1, a4, a5, a6, a7 & 1, a8, *((uint64_t *)&a8 + 1), a9);
}

unint64_t protocol witness for Matrix.init(rowCount:columnCount:) in conformance DenseMatrix<A>.Transpose(unint64_t a1, unint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  unint64_t result = DenseMatrix.Transpose.init(rowCount:columnCount:)(a1, a2, *(void *)(a3 + 16), *(void *)(a3 + 24));
  *(void *)uint64_t v4 = result;
  *(void *)(v4 + 8) = v7;
  *(unsigned char *)(v4 + 16) = v6 & 1;
  *(void *)(v4 + 24) = v8;
  return result;
}

uint64_t protocol witness for Matrix.transposed() in conformance DenseMatrix<A>.Transpose()
{
  uint64_t v2 = v0;
  uint64_t result = DenseMatrix.Transpose.transposed()(*(void *)v1, *(void *)(v1 + 8), *(unsigned __int8 *)(v1 + 16), *(void *)(v1 + 24));
  *(void *)uint64_t v2 = result;
  *(void *)(v2 + 8) = v5;
  *(unsigned char *)(v2 + 16) = v4 & 1;
  *(void *)(v2 + 24) = v6;
  return result;
}

uint64_t protocol witness for Matrix.subscript.getter in conformance DenseMatrix<A>.Transpose(unint64_t a1, unint64_t a2, uint64_t a3)
{
  uint64_t v5 = v3;
  uint64_t v6 = *(void *)(a3 + 16);
  *((void *)&v10 + 1) = v6;
  *(void *)&long long v10 = *(void *)(v4 + 24);
  uint64_t v7 = DenseMatrix.Transpose.subscript.read(v11, a1, a2, *(void *)v4, *(void *)(v4 + 8), *(unsigned char *)(v4 + 16), v10);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16))(v5, v8, v6);
  return ((uint64_t (*)(void *, void))v7)(v11, 0);
}

uint64_t protocol witness for Matrix.subscript.setter in conformance DenseMatrix<A>.Transpose(uint64_t a1, unint64_t a2, unint64_t a3, uint64_t a4)
{
  uint64_t v5 = DenseMatrix.Transpose.subscript.modify(v10, a2, a3, a4);
  uint64_t v6 = *(void *)(a4 + 16);
  uint64_t v7 = *(void *)(v6 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v7 + 24))(v8, a1, v6);
  ((void (*)(void *, void))v5)(v10, 0);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v7 + 8))(a1, v6);
}

void (*protocol witness for Matrix.subscript.modify in conformance DenseMatrix<A>.Transpose(void *a1, unint64_t a2, unint64_t a3, uint64_t a4))(void (***a1)(void))
{
  uint64_t v5 = malloc(0x28uLL);
  *a1 = v5;
  void v5[4] = DenseMatrix.Transpose.subscript.modify(v5, a2, a3, a4);
  return protocol witness for Collection.subscript.read in conformance <> InterspersedSequence<A>;
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance DenseMatrix<A>.Transpose(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)&v4[8] = *(_OWORD *)(a3 + 16);
  *(void *)uint64_t v4 = *(void *)(a2 + 24);
  return static DenseMatrix.Transpose.__derived_struct_equals(_:_:)(*(void *)a1, *(void *)(a1 + 8), *(unsigned char *)(a1 + 16), *(void *)(a1 + 24), *(void *)a2, *(void *)(a2 + 8), *(unsigned char *)(a2 + 16), *(long long *)v4, *(void *)(a3 + 24));
}

unsigned __int8 static DenseMatrix.Transpose.+= infix(_:_:)(uint64_t a1, int64_t a2, int64_t a3, char a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  return static DenseMatrix.+= infix(_:_:)(a1, a2, a3, a4 & 1, a5, a6, a7);
}

uint64_t static DenseMatrix.Transpose.+ infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, char a7, long long a8, uint64_t a9)
{
  return static DenseMatrix.Transpose.+ infix(_:_:)(a1, a2, a3, a4, a5, a6, a7, a8, a9, (uint64_t (*)(uint64_t, uint64_t, void, uint64_t, uint64_t, uint64_t, int, void, void, uint64_t))static DenseMatrix.+ infix(_:_:));
}

unint64_t static DenseMatrix.Transpose.-= infix(_:_:)(uint64_t a1, unint64_t a2, unint64_t a3, char a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  return static DenseMatrix.-= infix(_:_:)(a1, a2, a3, a4 & 1, a5, a6, a7);
}

uint64_t static DenseMatrix.Transpose.- infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, char a7, long long a8, uint64_t a9)
{
  return static DenseMatrix.Transpose.+ infix(_:_:)(a1, a2, a3, a4, a5, a6, a7, a8, a9, (uint64_t (*)(uint64_t, uint64_t, void, uint64_t, uint64_t, uint64_t, int, void, void, uint64_t))static DenseMatrix.- infix(_:_:));
}

uint64_t static DenseMatrix.Transpose.+ infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, char a7, long long a8, uint64_t a9, uint64_t (*a10)(uint64_t, uint64_t, void, uint64_t, uint64_t, uint64_t, int, void, void, uint64_t))
{
  return a10(a1, a2, a3 & 1, a4, a5, a6, a7 & 1, a8, *((void *)&a8 + 1), a9);
}

void static DenseMatrix.Transpose.*= infix(_:_:)(unint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  static DenseMatrix.*= infix(_:_:)(a1, a2, a3, a4);
}

uint64_t static DenseMatrix.Transpose.* infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  return static DenseMatrix.Transpose.* infix(_:_:)(a1, a2, a3, a4, a5, a6, a7, (uint64_t (*)(uint64_t, uint64_t, void))static DenseMatrix.* infix(_:_:));
}

unint64_t static DenseMatrix.Transpose.* infix(_:_:)(uint64_t a1, unint64_t a2, unint64_t a3, char a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  return static DenseMatrix.* infix(_:_:)(a1, a2, a3, a4 & 1, a5, a6, a7);
}

uint64_t static DenseMatrix.Transpose./ infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  return static DenseMatrix.Transpose.* infix(_:_:)(a1, a2, a3, a4, a5, a6, a7, (uint64_t (*)(uint64_t, uint64_t, void))static DenseMatrix./ infix(_:_:));
}

uint64_t static DenseMatrix.Transpose.* infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t (*a8)(uint64_t, uint64_t, void))
{
  return a8(a1, a2, a3 & 1);
}

uint64_t static DenseMatrix.Transpose.* infix(_:_:)(uint64_t a1, unint64_t a2, char a3, uint64_t a4, unint64_t a5, unint64_t a6, char a7, uint64_t a8, uint64_t a9, uint64_t a10)
{
  unint64_t v10 = static DenseMatrix.* infix(_:_:)(a5, a6, a7 & 1, a8, a1, a2, a3 & 1, a4, a9, a10);
  uint64_t v11 = DenseMatrix.transposed()(v10);
  swift_release();
  return v11;
}

uint64_t static DenseMatrix.Transpose.* infix(_:_:)(unint64_t a1, unint64_t a2, int a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v54 = a4;
  LODWORD(v73) = a3;
  uint64_t v65 = *(void *)(a6 - 8);
  int64_t v9 = *(void *)(v65 + 64);
  unint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v56 = v53;
  uint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v60 = v53;
  uint64_t v14 = alloca(v9);
  uint64_t v15 = alloca(v9);
  int v71 = v53;
  uint64_t v16 = alloca(v9);
  uint64_t v17 = alloca(v9);
  unint64_t v72 = v53;
  uint64_t v57 = *(void *)(*(void *)(*(void *)(a7 + 16) + 16) + 8);
  uint64_t v68 = *(void *)(v57 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v68, a6, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v18 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v63 = v53;
  if (DenseVector.count.getter(a5, a6) != a1)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000052, "right row count." + 0x8000000000000000, "LinearAlgebra/DenseMatrix+Transpose.swift", 41, 2, 123, 0);
    BUG();
  }
  unint64_t v55 = a1;
  unint64_t v66 = a2;
  if (one-time initialization token for linearAlgebra != -1) {
    swift_once(&one-time initialization token for linearAlgebra, one-time initialization function for linearAlgebra);
  }
  uint64_t v21 = type metadata accessor for Logger(0);
  __swift_project_value_buffer(v21, (uint64_t)static Logger.linearAlgebra);
  uint64_t v22 = (os_log_s *)Logger.logObject.getter();
  os_log_type_t v23 = static os_log_type_t.error.getter(v21, static Logger.linearAlgebra);
  if (os_log_type_enabled(v22, v23))
  {
    unint64_t v24 = (uint8_t *)swift_slowAlloc(12, -1);
    unint64_t v70 = (void (*)(void, void, void))swift_slowAlloc(32, -1);
    v53[0] = (uint64_t)v70;
    *(_DWORD *)unint64_t v24 = 136315138;
    uint64_t v67 = v24 + 4;
    uint64_t v25 = _typeName(_:qualified:)(a6, 0);
    os_log_t log = v22;
    char v27 = v26;
    uint64_t v69 = getNullTerminatedUTF8PointerImpl(_:storingStringOwnersIn:)(v25, v26, v53);
    UnsafeMutableRawBufferPointer.copyMemory(from:)(&v69, &v70, v67, v24 + 12);
    swift_bridgeObjectRelease(v27);
    _os_log_impl(&dword_0, log, v23, "Using a slow implementation of matrix multiplication for %s. Prefer using Float or Double.", v24, 0xCu);
    uint64_t v28 = v70;
    swift_arrayDestroy(v70, 1, (char *)&type metadata for Any + 8);
    swift_slowDealloc(v28, -1, -1);
    swift_slowDealloc(v24, -1, -1);
    os_log_t v29 = log;
  }
  else
  {
    os_log_t v29 = v22;
  }

  int v30 = v73;
  LOBYTE(v30) = v73 & 1;
  LODWORD(v73) = v30;
  uint64_t v31 = AssociatedTypeWitness;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v68, a6, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  uint64_t v33 = v63;
  uint64_t v59 = AssociatedConformanceWitness;
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, v31, AssociatedConformanceWitness);
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v33, a6, v68);
  uint64_t v34 = v66;
  uint64_t result = DenseVector.init(repeating:count:)((uint64_t)v72, v66, a6);
  uint64_t v69 = result;
  if (v34 < 0) {
    BUG();
  }
  if (v34)
  {
    uint64_t v36 = 0;
    int v64 = v73;
    uint64_t v61 = a5;
    do
    {
      if (v36 == (os_log_s *)v34) {
        BUG();
      }
      os_log_t log = v36;
      uint64_t v58 = (os_log_s *)((char *)v36 + 1);
      uint64_t v37 = v63;
      dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, v59);
      dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v37, a6, v68);
      uint64_t v38 = DenseVector.count.getter(a5, a6);
      if (v38 < 0) {
        BUG();
      }
      if (v38)
      {
        unint64_t v39 = 0;
        uint64_t v67 = (uint8_t *)v38;
        do
        {
          unint64_t v73 = v39 + 1;
          uint64_t v40 = (void (*)(uint64_t *, void))DenseMatrix.subscript.read(v53, v39, (unint64_t)log, v55, v66, v64, v54, a6);
          uint64_t v41 = v65;
          long long v42 = v60;
          unint64_t v70 = *(void (**)(void, void, void))(v65 + 16);
          v70(v60, v43, a6);
          v40(v53, 0);
          uint64_t v44 = v56;
          DenseVector.subscript.getter();
          unint64_t v45 = v42;
          uint64_t v46 = v57;
          dispatch thunk of static Numeric.* infix(_:_:)(v45, v44, a6, v57);
          uint64_t v47 = *(void (**)(uint64_t *, uint64_t))(v41 + 8);
          v47(v44, a6);
          v47(v60, a6);
          uint64_t v48 = (uint64_t)v72;
          dispatch thunk of static AdditiveArithmetic.+= infix(_:_:)(v71, v72, a6, *(void *)(v46 + 8));
          v47((uint64_t *)v48, a6);
          unint64_t v39 = v73;
        }
        while (v67 != (uint8_t *)v73);
      }
      else
      {
        unint64_t v70 = *(void (**)(void, void, void))(v65 + 16);
      }
      uint64_t v49 = (uint64_t)v72;
      uint64_t v50 = v71;
      v70(v72, v71, a6);
      uint64_t v52 = type metadata accessor for DenseVector(0, a6, a7, v51);
      DenseVector.subscript.setter(v49, (Swift::Int)log, v52);
      (*(void (**)(uint64_t *, uint64_t))(v65 + 8))(v50, a6);
      uint64_t v36 = v58;
      uint64_t v34 = v66;
      a5 = v61;
    }
    while (v58 != (os_log_s *)v66);
    return v69;
  }
  return result;
}

uint64_t static DenseMatrix.Transpose.* infix(_:_:)(uint64_t a1, uint64_t a2, unint64_t a3, int a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v7 = a6;
  LODWORD(v79) = a4;
  uint64_t v67 = a2;
  uint64_t v73 = *(void *)(a6 - 8);
  int64_t v11 = *(void *)(v73 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v62 = v58;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  unint64_t v72 = v58;
  uint64_t v16 = alloca(v11);
  uint64_t v17 = alloca(v11);
  uint64_t v74 = v58;
  int64_t v18 = alloca(v11);
  uint64_t v19 = alloca(v11);
  uint64_t v76 = v58;
  uint64_t v63 = *(void *)(*(void *)(*(void *)(a7 + 16) + 16) + 8);
  uint64_t v68 = *(void *)(v63 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v68, a6, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v20 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  unint64_t v70 = v58;
  if (DenseVector.count.getter(a1, v7) != a3)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000004FLL, "tor element count." + 0x8000000000000000, "LinearAlgebra/DenseMatrix+Transpose.swift", 41, 2, 143, 0);
    BUG();
  }
  unint64_t v61 = a3;
  if (one-time initialization token for linearAlgebra != -1) {
    swift_once(&one-time initialization token for linearAlgebra, one-time initialization function for linearAlgebra);
  }
  uint64_t v23 = type metadata accessor for Logger(0);
  __swift_project_value_buffer(v23, (uint64_t)static Logger.linearAlgebra);
  unint64_t v24 = (os_log_s *)Logger.logObject.getter();
  os_log_type_t v25 = static os_log_type_t.error.getter(v23, static Logger.linearAlgebra);
  BOOL v26 = os_log_type_enabled(v24, v25);
  uint64_t v60 = a5;
  uint64_t v66 = a1;
  if (v26)
  {
    char v27 = v24;
    uint64_t v28 = (uint8_t *)swift_slowAlloc(12, -1);
    uint64_t v77 = swift_slowAlloc(32, -1);
    v58[0] = v77;
    *(_DWORD *)uint64_t v28 = 136315138;
    unint64_t v78 = (void (*)(uint64_t *, uint64_t, uint64_t))(v28 + 4);
    uint64_t v29 = _typeName(_:qualified:)(v7, 0);
    char v31 = v30;
    uint64_t v75 = getNullTerminatedUTF8PointerImpl(_:storingStringOwnersIn:)(v29, v30, v58);
    UnsafeMutableRawBufferPointer.copyMemory(from:)(&v75, &v76, v78, v28 + 12);
    swift_bridgeObjectRelease(v31);
    _os_log_impl(&dword_0, v27, v25, "Using a slow implementation of matrix multiplication for %s. Prefer using Float or Double.", v28, 0xCu);
    uint64_t v32 = v77;
    swift_arrayDestroy(v77, 1, (char *)&type metadata for Any + 8);
    swift_slowDealloc(v32, -1, -1);
    swift_slowDealloc(v28, -1, -1);
    uint64_t v33 = v27;
  }
  else
  {
    uint64_t v33 = v24;
  }

  int v34 = v79;
  LOBYTE(v34) = v79 & 1;
  LODWORD(v79) = v34;
  uint64_t v35 = v68;
  uint64_t v36 = AssociatedTypeWitness;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v68, v7, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  uint64_t v38 = v70;
  uint64_t v65 = AssociatedConformanceWitness;
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, v36, AssociatedConformanceWitness);
  uint64_t v39 = (uint64_t)v76;
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v38, v7, v35);
  int64_t v40 = v67;
  uint64_t result = DenseVector.init(repeating:count:)(v39, v67, v7);
  uint64_t v75 = result;
  if (v40 < 0) {
    BUG();
  }
  if (v40)
  {
    uint64_t v42 = 0;
    int v71 = v79;
    do
    {
      if (v42 == v40) {
        BUG();
      }
      uint64_t v77 = v42;
      uint64_t v64 = v42 + 1;
      uint64_t v43 = v7;
      uint64_t v44 = v70;
      dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, v65);
      dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v44, v43, v68);
      uint64_t v45 = DenseVector.count.getter(v66, v43);
      if (v45 < 0) {
        BUG();
      }
      if (v45)
      {
        unint64_t v46 = 0;
        uint64_t v7 = v43;
        uint64_t v59 = v45;
        do
        {
          unint64_t v79 = v46 + 1;
          DenseVector.subscript.getter();
          uint64_t v47 = (void (*)(uint64_t *, void))DenseMatrix.subscript.read(v58, v77, v46, v40, v61, v71, v60, v7);
          uint64_t v48 = v73;
          uint64_t v49 = v62;
          unint64_t v78 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v73 + 16);
          v78(v62, v50, v7);
          v47(v58, 0);
          uint64_t v51 = v63;
          dispatch thunk of static Numeric.* infix(_:_:)(v72, v49, v7, v63);
          uint64_t v52 = *(void (**)(uint64_t *, uint64_t))(v48 + 8);
          v52(v49, v7);
          v52(v72, v7);
          uint64_t v53 = v76;
          dispatch thunk of static AdditiveArithmetic.+= infix(_:_:)(v74, v76, v7, *(void *)(v51 + 8));
          v52(v53, v7);
          int64_t v40 = v67;
          unint64_t v46 = v79;
        }
        while (v59 != v79);
      }
      else
      {
        unint64_t v78 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v73 + 16);
        uint64_t v7 = v43;
      }
      uint64_t v54 = (uint64_t)v76;
      unint64_t v55 = v74;
      v78(v76, (uint64_t)v74, v7);
      uint64_t v57 = type metadata accessor for DenseVector(0, v7, a7, v56);
      DenseVector.subscript.setter(v54, v77, v57);
      (*(void (**)(uint64_t *, uint64_t))(v73 + 8))(v55, v7);
      uint64_t v42 = v64;
    }
    while (v64 != v40);
    return v75;
  }
  return result;
}

uint64_t static DenseMatrix.Transpose<>.* infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, char a7, uint64_t a8)
{
  return static DenseMatrix.Transpose<>.* infix(_:_:)(a1, a2, a3, a4, a5, a6, a7, a8, (uint64_t (*)(uint64_t, uint64_t, void, uint64_t, uint64_t, uint64_t, void, uint64_t))static DenseMatrix<>.* infix(_:_:));
}

{
  return static DenseMatrix.Transpose<>.* infix(_:_:)(a1, a2, a3, a4, a5, a6, a7, a8, (uint64_t (*)(uint64_t, uint64_t, void, uint64_t, uint64_t, uint64_t, void, uint64_t))static DenseMatrix<>.* infix(_:_:));
}

uint64_t static DenseMatrix.Transpose<>.* infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5)
{
  return static DenseMatrix.Transpose<>.* infix(_:_:)(a1, a2, a3, a4, a5, (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, void, uint64_t))specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:));
}

{
  return static DenseMatrix.Transpose<>.* infix(_:_:)(a1, a2, a3, a4, a5, (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, void, uint64_t))specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:));
}

uint64_t static DenseMatrix.Transpose<>.* infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, char a4, uint64_t a5)
{
  return static DenseMatrix.Transpose<>.* infix(_:_:)(a1, a2, a3, a4, a5, (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, void, uint64_t))specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:));
}

{
  return static DenseMatrix.Transpose<>.* infix(_:_:)(a1, a2, a3, a4, a5, (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, void, uint64_t))specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:));
}

uint64_t static DenseMatrix.Transpose<>.* infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t a6, char a7, uint64_t a8, uint64_t (*a9)(uint64_t, uint64_t, void, uint64_t, uint64_t, uint64_t, void, uint64_t))
{
  return a9(a5, a6, a7 & 1, a8, a1, a2, a3 & 1, a4);
}

uint64_t static DenseMatrix.Transpose<>.* infix(_:_:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, uint64_t (*a6)(uint64_t, uint64_t, uint64_t, uint64_t, void, uint64_t))
{
  unsigned __int8 v8 = a3 & 1;
  swift_retain(a5);
  swift_retain(a4);
  return a6(a2, a5, a1, a2, v8, a4);
}

uint64_t static DenseMatrix.Transpose<>.* infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, char a4, uint64_t a5, uint64_t (*a6)(uint64_t, uint64_t, uint64_t, uint64_t, void, uint64_t))
{
  unsigned __int8 v8 = a4 & 1;
  swift_retain(a1);
  swift_retain(a5);
  return a6(a2, a1, a2, a3, v8, a5);
}

uint64_t associated type witness table accessor for Matrix.Transpose : Matrix in DenseMatrix<A>.Transpose(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for DenseMatrix<A>, a1);
}

uint64_t type metadata accessor for DenseMatrix.Transpose(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for DenseMatrix.Transpose);
}

BOOL static MatrixLayout.__derived_enum_equals(_:_:)(unsigned __int8 a1, unsigned __int8 a2)
{
  return ((a2 ^ a1) & 1) == 0;
}

uint64_t MatrixLayout.debugDescription.getter(char a1)
{
  uint64_t result = 0x6D2D6E6D756C6F63;
  if ((a1 & 1) == 0) {
    return 0x6F6A616D2D776F72;
  }
  return result;
}

char MatrixLayout.CodingKeys.init(stringValue:)(uint64_t a1, uint64_t a2)
{
  if (a1 == 0x726F6A614D776F72 && a2 == 0xE800000000000000
    || (_stringCompareWithSmolCheck(_:_:expecting:)(0x726F6A614D776F72, 0xE800000000000000, a1, a2, 0) & 1) != 0)
  {
    swift_bridgeObjectRelease(a2);
    return 0;
  }
  else if (a1 == 0x614D6E6D756C6F63 && a2 == 0xEB00000000726F6ALL)
  {
    swift_bridgeObjectRelease(0xEB00000000726F6ALL);
    return 1;
  }
  else
  {
    char v3 = _stringCompareWithSmolCheck(_:_:expecting:)(0x614D6E6D756C6F63, 0xEB00000000726F6ALL, a1, a2, 0);
    swift_bridgeObjectRelease(a2);
    return 2 - (v3 & 1);
  }
}

Swift::Int MatrixLayout.CodingKeys.hashValue.getter(char a1)
{
  return Rectangle.CodingKeys.hashValue.getter(a1);
}

uint64_t MatrixLayout.CodingKeys.stringValue.getter(char a1)
{
  uint64_t result = 0x614D6E6D756C6F63;
  if ((a1 & 1) == 0) {
    return 0x726F6A614D776F72;
  }
  return result;
}

uint64_t protocol witness for CodingKey.stringValue.getter in conformance MatrixLayout.CodingKeys()
{
  return MatrixLayout.CodingKeys.stringValue.getter(*v0);
}

char protocol witness for CodingKey.init(stringValue:) in conformance MatrixLayout.CodingKeys(uint64_t a1, uint64_t a2)
{
  char v3 = v2;
  char result = MatrixLayout.CodingKeys.init(stringValue:)(a1, a2);
  char *v3 = result;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MatrixLayout.CodingKeys(uint64_t a1)
{
  uint64_t v1 = lazy protocol witness table accessor for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys();
  return CodingKey.description.getter(a1, v1);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MatrixLayout.CodingKeys(uint64_t a1)
{
  uint64_t v1 = lazy protocol witness table accessor for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys();
  return CodingKey.debugDescription.getter(a1, v1);
}

char MatrixLayout.RowMajorCodingKeys.init(stringValue:)(uint64_t a1, uint64_t a2)
{
  return 1;
}

uint64_t MatrixLayout.RowMajorCodingKeys.stringValue.getter()
{
  return 0;
}

uint64_t protocol witness for CodingKey.stringValue.getter in conformance MatrixLayout.ColumnMajorCodingKeys()
{
  return MatrixLayout.RowMajorCodingKeys.stringValue.getter();
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MatrixLayout.ColumnMajorCodingKeys(uint64_t a1)
{
  uint64_t v1 = lazy protocol witness table accessor for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys();
  return CodingKey.description.getter(a1, v1);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MatrixLayout.ColumnMajorCodingKeys(uint64_t a1)
{
  uint64_t v1 = lazy protocol witness table accessor for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys();
  return CodingKey.debugDescription.getter(a1, v1);
}

char protocol witness for CodingKey.init(stringValue:) in conformance MatrixLayout.RowMajorCodingKeys(uint64_t a1, uint64_t a2)
{
  char v3 = v2;
  char result = MatrixLayout.RowMajorCodingKeys.init(stringValue:)(a1, a2) & 1;
  unsigned char *v3 = result;
  return result;
}

uint64_t protocol witness for CodingKey.intValue.getter in conformance MatrixLayout.RowMajorCodingKeys()
{
  return Rectangle.CodingKeys.intValue.getter();
}

char protocol witness for CodingKey.init(intValue:) in conformance MatrixLayout.RowMajorCodingKeys()
{
  uint64_t v1 = v0;
  char result = protocol witness for static Equatable.== infix(_:_:) in conformance MLHandActionClassifier.ModelParameters.ModelAlgorithmType() & 1;
  unsigned char *v1 = result;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MatrixLayout.RowMajorCodingKeys(uint64_t a1)
{
  uint64_t v1 = lazy protocol witness table accessor for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys();
  return CodingKey.description.getter(a1, v1);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MatrixLayout.RowMajorCodingKeys(uint64_t a1)
{
  uint64_t v1 = lazy protocol witness table accessor for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys();
  return CodingKey.debugDescription.getter(a1, v1);
}

uint64_t MatrixLayout.encode(to:)(void *a1, int a2)
{
  int v32 = a2;
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedEncodingContainer<MatrixLayout.ColumnMajorCodingKeys>);
  uint64_t v24 = *(void *)(v25 - 8);
  int64_t v2 = *(void *)(v24 + 64);
  char v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  BOOL v26 = &v23;
  uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedEncodingContainer<MatrixLayout.RowMajorCodingKeys>);
  uint64_t v28 = *(void *)(v27 - 8);
  int64_t v5 = *(void *)(v28 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v29 = &v23;
  uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedEncodingContainer<MatrixLayout.CodingKeys>);
  uint64_t v31 = *(void *)(v30 - 8);
  int64_t v8 = *(void *)(v31 + 64);
  int64_t v9 = alloca(v8);
  unint64_t v10 = alloca(v8);
  uint64_t v11 = a1[3];
  uint64_t v12 = a1[4];
  __swift_project_boxed_opaque_existential_0Tm(a1, v11);
  uint64_t v13 = lazy protocol witness table accessor for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys();
  dispatch thunk of Encoder.container<A>(keyedBy:)(&unk_39EB50, &unk_39EB50, v13, v11, v12);
  if (v32)
  {
    char v33 = 1;
    uint64_t v20 = lazy protocol witness table accessor for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys();
    uint64_t v21 = v26;
    uint64_t v16 = v30;
    KeyedEncodingContainer.nestedContainer<A>(keyedBy:forKey:)(&unk_39EB90, &v33, v30, &unk_39EB90, v20);
    uint64_t v17 = v21;
    uint64_t v18 = v25;
    uint64_t v19 = v24;
  }
  else
  {
    v34[0] = 0;
    uint64_t v14 = lazy protocol witness table accessor for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys();
    uint64_t v15 = v29;
    uint64_t v16 = v30;
    KeyedEncodingContainer.nestedContainer<A>(keyedBy:forKey:)(&unk_39EB70, v34, v30, &unk_39EB70, v14);
    uint64_t v17 = v15;
    uint64_t v18 = v27;
    uint64_t v19 = v28;
  }
  (*(void (**)(uint64_t *, uint64_t))(v19 + 8))(v17, v18);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v31 + 8))(&v23, v16);
}

uint64_t lazy protocol witness table accessor for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys()
{
  uint64_t result = lazy protocol witness table cache variable for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys;
  if (!lazy protocol witness table cache variable for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MatrixLayout.CodingKeys, &unk_39EB50);
    lazy protocol witness table cache variable for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys;
  if (!lazy protocol witness table cache variable for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MatrixLayout.CodingKeys, &unk_39EB50);
    lazy protocol witness table cache variable for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys;
  if (!lazy protocol witness table cache variable for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MatrixLayout.CodingKeys, &unk_39EB50);
    lazy protocol witness table cache variable for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys;
  if (!lazy protocol witness table cache variable for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MatrixLayout.CodingKeys, &unk_39EB50);
    lazy protocol witness table cache variable for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys()
{
  uint64_t result = lazy protocol witness table cache variable for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys;
  if (!lazy protocol witness table cache variable for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MatrixLayout.ColumnMajorCodingKeys, &unk_39EB90);
    lazy protocol witness table cache variable for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys;
  if (!lazy protocol witness table cache variable for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MatrixLayout.ColumnMajorCodingKeys, &unk_39EB90);
    lazy protocol witness table cache variable for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys;
  if (!lazy protocol witness table cache variable for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MatrixLayout.ColumnMajorCodingKeys, &unk_39EB90);
    lazy protocol witness table cache variable for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys()
{
  uint64_t result = lazy protocol witness table cache variable for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys;
  if (!lazy protocol witness table cache variable for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MatrixLayout.RowMajorCodingKeys, &unk_39EB70);
    lazy protocol witness table cache variable for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys;
  if (!lazy protocol witness table cache variable for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MatrixLayout.RowMajorCodingKeys, &unk_39EB70);
    lazy protocol witness table cache variable for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys;
  if (!lazy protocol witness table cache variable for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MatrixLayout.RowMajorCodingKeys, &unk_39EB70);
    lazy protocol witness table cache variable for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys = result;
  }
  return result;
}

Swift::Int MatrixLayout.hashValue.getter(char a1)
{
  return Rectangle.CodingKeys.hashValue.getter(a1);
}

uint64_t MatrixLayout.init(from:)(void *a1)
{
  uint64_t v52 = v1;
  int64_t v2 = a1;
  uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedDecodingContainer<MatrixLayout.ColumnMajorCodingKeys>);
  uint64_t v45 = *(void *)(v46 - 8);
  int64_t v3 = *(void *)(v45 + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  uint64_t v43 = &v43;
  uint64_t v48 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedDecodingContainer<MatrixLayout.RowMajorCodingKeys>);
  uint64_t v47 = *(void *)(v48 - 8);
  int64_t v6 = *(void *)(v47 + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v44 = &v43;
  uint64_t v56 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedDecodingContainer<MatrixLayout.CodingKeys>);
  uint64_t v51 = *(void *)(v56 - 8);
  int64_t v9 = *(void *)(v51 + 64);
  unint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v12 = a1[3];
  uint64_t v55 = a1[4];
  __swift_project_boxed_opaque_existential_0Tm(a1, v12);
  uint64_t v13 = lazy protocol witness table accessor for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys();
  uint64_t v49 = &v43;
  uint64_t v14 = v52;
  dispatch thunk of Decoder.container<A>(keyedBy:)(&unk_39EB50, &unk_39EB50, v13, v12, v55);
  if (v14) {
    goto LABEL_11;
  }
  uint64_t v50 = a1;
  uint64_t v15 = v56;
  uint64_t v16 = KeyedDecodingContainer.allKeys.getter(v56);
  uint64_t v17 = *(void *)(v16 + 16);
  if (!v17)
  {
    uint64_t v55 = v16;
LABEL_9:
    uint64_t v56 = type metadata accessor for DecodingError(0);
    uint64_t v52 = swift_allocError(v56, &protocol witness table for DecodingError, 0, 0);
    uint64_t v30 = v29;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (@thick Any.Type, DecodingError.Context));
    void *v30 = &type metadata for MatrixLayout;
    uint64_t v31 = v49;
    uint64_t v32 = KeyedDecodingContainer.codingPath.getter(v15);
    DecodingError.Context.init(codingPath:debugDescription:underlyingError:)(v32, 0xD00000000000002BLL, "nseMatrix+Transpose.swift" + 0x8000000000000000, 0);
    uint64_t v33 = enum case for DecodingError.typeMismatch(_:);
    (*(void (**)(void *, void))(*(void *)(v56 - 8) + 104))(v30, enum case for DecodingError.typeMismatch(_:));
    swift_willThrow(v30, v33, v34, v35, v36, v37);
    swift_unknownObjectRelease(v55);
    uint64_t v27 = v31;
    uint64_t v28 = v15;
    goto LABEL_10;
  }
  uint64_t v52 = 0;
  char v57 = *(unsigned char *)(v16 + 32);
  LODWORD(v2) = v16;
  uint64_t v18 = specialized ArraySlice.subscript.getter(1, v17, v16, v16 + 32, 0, 2 * v17 + 1);
  uint64_t v20 = v19;
  unint64_t v22 = v21;
  swift_bridgeObjectRelease((_BYTE)v2);
  uint64_t v55 = v18;
  if (v20 != v22 >> 1)
  {
    uint64_t v15 = v56;
    goto LABEL_9;
  }
  LOBYTE(v2) = v57;
  if (!v57)
  {
    char v54 = 0;
    uint64_t v39 = lazy protocol witness table accessor for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys();
    int64_t v40 = v44;
    uint64_t v41 = v49;
    uint64_t v42 = v52;
    KeyedDecodingContainer.nestedContainer<A>(keyedBy:forKey:)(&unk_39EB70, &v54, v56, &unk_39EB70, v39);
    if (v42)
    {
      swift_unknownObjectRelease(v55);
      uint64_t v27 = v41;
      uint64_t v28 = v56;
      goto LABEL_10;
    }
    (*(void (**)(void *, uint64_t))(v47 + 8))(v40, v48);
    swift_unknownObjectRelease(v55);
    (*(void (**)(void *, uint64_t))(v51 + 8))(v41, v56);
LABEL_17:
    __swift_destroy_boxed_opaque_existential_1Tm(v50);
    return v2;
  }
  char v53 = 1;
  uint64_t v23 = lazy protocol witness table accessor for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys();
  int64_t v2 = v43;
  uint64_t v24 = v56;
  uint64_t v25 = v49;
  uint64_t v26 = v52;
  KeyedDecodingContainer.nestedContainer<A>(keyedBy:forKey:)(&unk_39EB90, &v53, v56, &unk_39EB90, v23);
  if (!v26)
  {
    (*(void (**)(void *, uint64_t))(v45 + 8))(v2, v46);
    swift_unknownObjectRelease(v55);
    (*(void (**)(void *, uint64_t))(v51 + 8))(v25, v24);
    LOBYTE(v2) = v57;
    goto LABEL_17;
  }
  swift_unknownObjectRelease(v55);
  uint64_t v27 = v25;
  uint64_t v28 = v24;
LABEL_10:
  (*(void (**)(void *, uint64_t))(v51 + 8))(v27, v28);
  int64_t v2 = v50;
LABEL_11:
  __swift_destroy_boxed_opaque_existential_1Tm(v2);
  return v2;
}

BOOL protocol witness for static Equatable.== infix(_:_:) in conformance MatrixLayout(unsigned __int8 *a1, unsigned __int8 *a2)
{
  return static MatrixLayout.__derived_enum_equals(_:_:)(*a1, *a2);
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MatrixLayout()
{
  return MatrixLayout.CodingKeys.hashValue.getter(*v0);
}

char protocol witness for Decodable.init(from:) in conformance MatrixLayout(void *a1)
{
  int64_t v3 = v1;
  char result = MatrixLayout.init(from:)(a1);
  if (!v2)
  {
    result &= 1u;
    unsigned char *v3 = result;
  }
  return result;
}

uint64_t protocol witness for Encodable.encode(to:) in conformance MatrixLayout(void *a1)
{
  return MatrixLayout.encode(to:)(a1, *v1);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MatrixLayout()
{
  return MatrixLayout.debugDescription.getter(*v0);
}

uint64_t base witness table accessor for Equatable in MatrixLayout()
{
  return lazy protocol witness table accessor for type MatrixLayout and conformance MatrixLayout();
}

uint64_t lazy protocol witness table accessor for type MatrixLayout and conformance MatrixLayout()
{
  uint64_t result = lazy protocol witness table cache variable for type MatrixLayout and conformance MatrixLayout;
  if (!lazy protocol witness table cache variable for type MatrixLayout and conformance MatrixLayout)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MatrixLayout, &type metadata for MatrixLayout);
    lazy protocol witness table cache variable for type MatrixLayout and conformance MatrixLayout = result;
  }
  return result;
}

ValueMetadata *type metadata accessor for MatrixLayout()
{
  return &type metadata for MatrixLayout;
}

void *type metadata accessor for MatrixLayout.CodingKeys()
{
  return &unk_39EB50;
}

void *type metadata accessor for MatrixLayout.RowMajorCodingKeys()
{
  return &unk_39EB70;
}

void *type metadata accessor for MatrixLayout.ColumnMajorCodingKeys()
{
  return &unk_39EB90;
}

uint64_t base witness table accessor for Equatable in MatrixLayout.CodingKeys()
{
  return lazy protocol witness table accessor for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys();
}

uint64_t base witness table accessor for CustomDebugStringConvertible in MatrixLayout.RowMajorCodingKeys()
{
  return lazy protocol witness table accessor for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys();
}

uint64_t base witness table accessor for CustomStringConvertible in MatrixLayout.RowMajorCodingKeys()
{
  return lazy protocol witness table accessor for type MatrixLayout.RowMajorCodingKeys and conformance MatrixLayout.RowMajorCodingKeys();
}

uint64_t base witness table accessor for CustomDebugStringConvertible in MatrixLayout.ColumnMajorCodingKeys()
{
  return lazy protocol witness table accessor for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys();
}

uint64_t base witness table accessor for CustomStringConvertible in MatrixLayout.ColumnMajorCodingKeys()
{
  return lazy protocol witness table accessor for type MatrixLayout.ColumnMajorCodingKeys and conformance MatrixLayout.ColumnMajorCodingKeys();
}

uint64_t base witness table accessor for CustomDebugStringConvertible in MatrixLayout.CodingKeys()
{
  return lazy protocol witness table accessor for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys();
}

uint64_t base witness table accessor for CustomStringConvertible in MatrixLayout.CodingKeys()
{
  return lazy protocol witness table accessor for type MatrixLayout.CodingKeys and conformance MatrixLayout.CodingKeys();
}

char protocol witness for CodingKey.init(stringValue:) in conformance MatrixLayout.ColumnMajorCodingKeys(uint64_t a1, uint64_t a2)
{
  return protocol witness for CodingKey.init(stringValue:) in conformance MatrixLayout.RowMajorCodingKeys(a1, a2);
}

void MatrixLayout.hash(into:)(uint64_t a1, char a2)
{
}

char protocol witness for CodingKey.init(intValue:) in conformance MatrixLayout.ColumnMajorCodingKeys()
{
  return protocol witness for CodingKey.init(intValue:) in conformance MatrixLayout.RowMajorCodingKeys();
}

uint64_t protocol witness for CodingKey.intValue.getter in conformance MatrixLayout.ColumnMajorCodingKeys()
{
  return protocol witness for CodingKey.intValue.getter in conformance MatrixLayout.RowMajorCodingKeys();
}

uint64_t SparseMatrix.Transpose.base.getter()
{
  char v2 = *(unsigned char *)(v1 + 16);
  uint64_t v3 = *(void *)(v1 + 24);
  uint64_t v4 = *(void *)(v1 + 32);
  uint64_t v5 = *(void *)(v1 + 40);
  *(_OWORD *)uint64_t v0 = *(_OWORD *)v1;
  *(unsigned char *)(v0 + 16) = v2;
  *(void *)(v0 + 24) = v3;
  *(void *)(v0 + 32) = v4;
  *(void *)(v0 + 40) = v5;
  swift_bridgeObjectRetain(v3);
  swift_bridgeObjectRetain(v4);
  return swift_retain(v5);
}

uint64_t SparseMatrix.Transpose.base.setter(uint64_t a1)
{
  uint64_t v2 = *(void *)(a1 + 40);
  char v3 = *(unsigned char *)(a1 + 16) & 1;
  swift_bridgeObjectRelease(*(void *)(v1 + 24));
  swift_bridgeObjectRelease(*(void *)(v1 + 32));
  uint64_t result = swift_release(*(void *)(v1 + 40));
  *(_OWORD *)uint64_t v1 = *(_OWORD *)a1;
  *(unsigned char *)(v1 + 16) = v3;
  *(_OWORD *)(v1 + 24) = *(_OWORD *)(a1 + 24);
  *(void *)(v1 + 40) = v2;
  return result;
}

void (*SparseMatrix.Transpose.base.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t SparseMatrix.Transpose.rowCount.getter()
{
  return *(void *)(v0 + 8);
}

uint64_t SparseMatrix.Transpose.columnCount.getter()
{
  return *(void *)v0;
}

unint64_t SparseMatrix.Transpose.count.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return SparseMatrix.count.getter();
}

uint64_t SparseMatrix.Transpose.init(base:)(uint64_t a1)
{
  uint64_t v2 = *(void *)(a1 + 40);
  char v3 = *(unsigned char *)(a1 + 16) & 1;
  *(_OWORD *)uint64_t result = *(_OWORD *)a1;
  *(unsigned char *)(result + 16) = v3;
  *(_OWORD *)(result + 24) = *(_OWORD *)(a1 + 24);
  *(void *)(result + 40) = v2;
  return result;
}

char SparseMatrix.Transpose.init(rowCount:columnCount:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  SparseMatrix.init(rowCount:columnCount:)(a2, a1, a3);
  char result = v7;
  *(_OWORD *)uint64_t v4 = v6;
  *(unsigned char *)(v4 + 16) = v7;
  *(_OWORD *)(v4 + 24) = v8;
  *(void *)(v4 + 40) = v9;
  return result;
}

void (*SparseMatrix.Transpose.subscript.read(void *a1, uint64_t a2, uint64_t a3, uint64_t a4))(uint64_t a1)
{
  long long v6 = malloc(0x48uLL);
  *a1 = v6;
  uint64_t v7 = *(void *)(a4 + 16);
  v6[6] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  v6[7] = v8;
  void v6[8] = malloc(*(void *)(v8 + 64));
  long long v9 = v4[1];
  long long v10 = v4[2];
  *(_OWORD *)long long v6 = *v4;
  *((_OWORD *)v6 + 1) = v9;
  *((_OWORD *)v6 + 2) = v10;
  uint64_t v12 = type metadata accessor for SparseMatrix(0, v7, *(void *)(a4 + 24), v11);
  SparseMatrix.subscript.getter(a3, a2, v12);
  return SparseMatrix.Transpose.subscript.read;
}

void SparseMatrix.Transpose.subscript.read(uint64_t a1)
{
  uint64_t v1 = *(void **)a1;
  uint64_t v2 = *(void **)(*(void *)a1 + 64);
  (*(void (**)(void *, void))(*(void *)(*(void *)a1 + 56) + 8))(v2, *(void *)(*(void *)a1 + 48));
  free(v2);
  free(v1);
}

void (*SparseMatrix.Transpose.subscript.modify(void *a1, uint64_t a2, uint64_t a3, uint64_t a4))(uint64_t **a1, char a2)
{
  long long v6 = malloc(0x70uLL);
  *a1 = v6;
  void v6[8] = v4;
  v6[7] = a3;
  v6[6] = a2;
  uint64_t v7 = *(void *)(a4 + 16);
  v6[9] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  v6[10] = v8;
  size_t v9 = *(void *)(v8 + 64);
  v6[11] = malloc(v9);
  v6[12] = malloc(v9);
  long long v10 = v4[1];
  long long v11 = v4[2];
  *(_OWORD *)long long v6 = *v4;
  *((_OWORD *)v6 + 1) = v10;
  *((_OWORD *)v6 + 2) = v11;
  uint64_t v13 = type metadata accessor for SparseMatrix(0, v7, *(void *)(a4 + 24), v12);
  v6[13] = v13;
  SparseMatrix.subscript.getter(a3, a2, v13);
  return SparseMatrix.Transpose.subscript.modify;
}

void SparseMatrix.Transpose.subscript.modify(uint64_t **a1, char a2)
{
  uint64_t v2 = *a1;
  uint64_t v3 = (*a1)[13];
  uint64_t v4 = (void *)(*a1)[11];
  uint64_t v5 = (void *)(*a1)[12];
  if (a2)
  {
    uint64_t v7 = v2[10];
    uint64_t v8 = v2[9];
    uint64_t v6 = v2[6];
    Swift::Int v9 = v2[7];
    (*(void (**)(void *, void *))(v7 + 16))(v4, v5);
    SparseMatrix.subscript.setter((uint64_t)v4, v9, v6, v3);
    (*(void (**)(void *, uint64_t))(v7 + 8))(v5, v8);
  }
  else
  {
    SparseMatrix.subscript.setter((*a1)[12], v2[7], v2[6], v3);
  }
  free(v5);
  free(v4);
  free(v2);
}

uint64_t SparseMatrix.Transpose.subscript.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v4 = type metadata accessor for SparseMatrix(0, *(void *)(a3 + 16), *(void *)(a3 + 24), a4);
  return SparseMatrix.subscript.getter(a2, a1, v4);
}

uint64_t SparseMatrix.Transpose.subscript.setter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v23 = a3;
  uint64_t v21 = a2;
  uint64_t v18 = a1;
  uint64_t v5 = *(void *)(a4 + 16);
  uint64_t v19 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v19 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v20 = v4;
  long long v9 = *v4;
  long long v10 = v4[1];
  void v17[2] = v4[2];
  v17[1] = v10;
  v17[0] = v9;
  uint64_t v11 = *(void *)(a4 + 24);
  uint64_t v22 = v5;
  uint64_t v12 = type metadata accessor for SparseMatrix(0, v5, v11, a4);
  SparseMatrix.subscript.getter(v23, a2, v12);
  uint64_t v13 = v18;
  uint64_t v14 = v5;
  uint64_t v15 = v19;
  (*(void (**)(_OWORD *, uint64_t, uint64_t))(v19 + 24))(v17, v18, v14);
  SparseMatrix.subscript.setter((uint64_t)v17, v23, v21, v12);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v15 + 8))(v13, v22);
}

uint64_t SparseMatrix.Transpose.transposed()()
{
  char v2 = *(unsigned char *)(v1 + 16);
  uint64_t v3 = *(void *)(v1 + 24);
  uint64_t v4 = *(void *)(v1 + 32);
  uint64_t v5 = *(void *)(v1 + 40);
  *(_OWORD *)uint64_t v0 = *(_OWORD *)v1;
  *(unsigned char *)(v0 + 16) = v2;
  *(void *)(v0 + 24) = v3;
  *(void *)(v0 + 32) = v4;
  *(void *)(v0 + 40) = v5;
  swift_bridgeObjectRetain(v3);
  swift_bridgeObjectRetain(v4);
  return swift_retain(v5);
}

uint64_t static SparseMatrix.Transpose.__derived_struct_equals(_:_:)(_OWORD *a1, _OWORD *a2, uint64_t a3, uint64_t a4)
{
  long long v4 = a1[1];
  long long v5 = a1[2];
  v9[0] = *a1;
  v9[1] = v4;
  unint64_t v9[2] = v5;
  long long v6 = a2[1];
  long long v7 = a2[2];
  v10[0] = *a2;
  v10[1] = v6;
  unint64_t v10[2] = v7;
  return static SparseMatrix.__derived_struct_equals(_:_:)((uint64_t)v9, (uint64_t)v10, a3, a4);
}

uint64_t associated type witness table accessor for Matrix.IndexedSequence : Sequence in SparseMatrix<A>.Transpose(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for SparseMatrix<A>.IndexedSequence, a1);
}

uint64_t associated type witness table accessor for Matrix.Transpose : Matrix in SparseMatrix<A>.Transpose(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for SparseMatrix<A>, a1);
}

uint64_t protocol witness for Matrix.rowCount.getter in conformance SparseMatrix<A>.Transpose()
{
  return SparseMatrix.Transpose.rowCount.getter();
}

uint64_t protocol witness for Matrix.columnCount.getter in conformance SparseMatrix<A>.Transpose()
{
  return SparseMatrix.Transpose.columnCount.getter();
}

char protocol witness for Matrix.init(rowCount:columnCount:) in conformance SparseMatrix<A>.Transpose(uint64_t a1, uint64_t a2, uint64_t a3)
{
  long long v4 = v3;
  char result = SparseMatrix.Transpose.init(rowCount:columnCount:)(a1, a2, *(void *)(a3 + 16));
  v4[2] = v8;
  v4[1] = v7;
  *long long v4 = v6;
  return result;
}

uint64_t protocol witness for Matrix.transposed() in conformance SparseMatrix<A>.Transpose()
{
  return SparseMatrix.Transpose.transposed()();
}

uint64_t protocol witness for Matrix.subscript.getter in conformance SparseMatrix<A>.Transpose(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = v3;
  long long v6 = SparseMatrix.Transpose.subscript.read(v9, a1, a2, a3);
  (*(void (**)(uint64_t, uint64_t, void))(*(void *)(*(void *)(a3 + 16) - 8) + 16))(v5, v7, *(void *)(a3 + 16));
  return ((uint64_t (*)(void *, void))v6)(v9, 0);
}

uint64_t protocol witness for Matrix.subscript.setter in conformance SparseMatrix<A>.Transpose(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v5 = SparseMatrix.Transpose.subscript.modify(v10, a2, a3, a4);
  uint64_t v6 = *(void *)(a4 + 16);
  uint64_t v7 = *(void *)(v6 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v7 + 24))(v8, a1, v6);
  v5((uint64_t **)v10, 0);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v7 + 8))(a1, v6);
}

void (*protocol witness for Matrix.subscript.modify in conformance SparseMatrix<A>.Transpose(void *a1, uint64_t a2, uint64_t a3, uint64_t a4))(void (***a1)(void))
{
  uint64_t v5 = malloc(0x28uLL);
  *a1 = v5;
  void v5[4] = SparseMatrix.Transpose.subscript.modify(v5, a2, a3, a4);
  return protocol witness for Collection.subscript.read in conformance <> InterspersedSequence<A>;
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance SparseMatrix<A>.Transpose(_OWORD *a1, _OWORD *a2, uint64_t a3)
{
  return static SparseMatrix.Transpose.__derived_struct_equals(_:_:)(a1, a2, *(void *)(a3 + 16), *(void *)(a3 + 24));
}

_OWORD *__swift_memcpy48_8(_OWORD *a1, long long *a2)
{
  char result = a1;
  long long v3 = *a2;
  long long v4 = a2[1];
  a1[2] = a2[2];
  a1[1] = v4;
  *a1 = v3;
  return result;
}

uint64_t type metadata accessor for SparseMatrix.Transpose(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for SparseMatrix.Transpose);
}

uint64_t LowerStrictlyTriangularMatrix.init(base:)(uint64_t a1)
{
  return a1;
}

uint64_t LowerStrictlyTriangularMatrix.base.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a1;
}

uint64_t LowerStrictlyTriangularMatrix.base.setter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  swift_release(v4[2]);
  uint64_t result = swift_bridgeObjectRelease(v4[3]);
  *long long v4 = a1;
  v4[1] = a2;
  v4[2] = a3;
  uint64_t v4[3] = a4;
  return result;
}

void (*LowerStrictlyTriangularMatrix.base.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t LowerStrictlyTriangularMatrix.rowCount.getter(uint64_t a1, uint64_t a2)
{
  return a2;
}

uint64_t LowerStrictlyTriangularMatrix.columnCount.getter(uint64_t a1)
{
  return a1;
}

uint64_t LowerStrictlyTriangularMatrix.unordered.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return UpperStrictlyTriangularMatrix.unordered.getter(a1, a2, a3, a4, a5);
}

uint64_t LowerStrictlyTriangularMatrix.init(rowCount:columnCount:)(uint64_t a1, uint64_t a2, unsigned char *a3, unint64_t a4)
{
  return UpperStrictlyTriangularMatrix.init(rowCount:columnCount:)(a2, a1, a3, a4);
}

void (*LowerStrictlyTriangularMatrix.subscript.read(uint64_t *a1, Swift::Int a2, Swift::Int a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9))(void *a1)
{
  *a1 = a8;
  uint64_t v10 = *(void *)(a8 - 8);
  a1[1] = v10;
  a1[2] = (uint64_t)malloc(*(void *)(v10 + 64));
  UpperStrictlyTriangularMatrix.subscript.getter(a3, a2, a4, a5, a6, a7, a8, a9);
  return InterspersedSequence<>.subscript.read;
}

void (*LowerStrictlyTriangularMatrix.subscript.modify(void *a1, Swift::Int a2, Swift::Int a3, uint64_t a4))(Swift::Int **a1, char a2, uint64_t a3, uint64_t a4)
{
  uint64_t v6 = malloc(0x40uLL);
  *a1 = v6;
  void v6[2] = v4;
  v6[1] = a3;
  *uint64_t v6 = a2;
  uint64_t v7 = *(void *)(a4 + 16);
  v6[3] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  void v6[4] = v8;
  size_t v9 = *(void *)(v8 + 64);
  void v6[5] = malloc(v9);
  v6[6] = malloc(v9);
  uint64_t v10 = *v4;
  uint64_t v11 = v4[1];
  uint64_t v12 = v4[2];
  uint64_t v13 = v4[3];
  uint64_t v14 = *(void *)(a4 + 24);
  v6[7] = v14;
  UpperStrictlyTriangularMatrix.subscript.getter(a3, a2, v10, v11, v12, v13, v7, v14);
  return LowerStrictlyTriangularMatrix.subscript.modify;
}

void LowerStrictlyTriangularMatrix.subscript.modify(Swift::Int **a1, char a2, uint64_t a3, uint64_t a4)
{
  long long v4 = *a1;
  uint64_t v5 = (void *)(*a1)[5];
  uint64_t v6 = (void *)(*a1)[6];
  if (a2)
  {
    Swift::Int v13 = v4[4];
    uint64_t v7 = v4[3];
    Swift::Int v8 = *v4;
    Swift::Int v14 = v4[1];
    uint64_t v15 = (*a1)[7];
    (*(void (**)(void *, void *, uint64_t))(v13 + 16))(v5, v6, v7);
    uint64_t v10 = type metadata accessor for UpperStrictlyTriangularMatrix(0, v7, v15, v9);
    UpperStrictlyTriangularMatrix.subscript.setter((uint64_t)v5, v14, v8, v10);
    (*(void (**)(void *, uint64_t))(v13 + 8))(v6, v7);
  }
  else
  {
    Swift::Int v16 = *v4;
    Swift::Int v11 = v4[1];
    uint64_t v12 = type metadata accessor for UpperStrictlyTriangularMatrix(0, v4[3], (*a1)[7], a4);
    UpperStrictlyTriangularMatrix.subscript.setter((uint64_t)v6, v11, v16, v12);
  }
  free(v6);
  free(v5);
  free(v4);
}

uint64_t LowerStrictlyTriangularMatrix.subscript.getter(Swift::Int a1, Swift::Int a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  return UpperStrictlyTriangularMatrix.subscript.getter(a2, a1, a3, a4, a5, a6, a7, a8);
}

uint64_t LowerStrictlyTriangularMatrix.subscript.setter(uint64_t a1, Swift::Int a2, Swift::Int a3, uint64_t a4)
{
  Swift::Int v16 = a3;
  Swift::Int v15 = a2;
  uint64_t v17 = a1;
  uint64_t v5 = *(void *)(a4 + 16);
  uint64_t v14 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v14 + 64);
  uint64_t v7 = alloca(v6);
  Swift::Int v8 = alloca(v6);
  uint64_t v9 = *(void *)(a4 + 24);
  UpperStrictlyTriangularMatrix.subscript.getter(a3, a2, *v4, v4[1], v4[2], v4[3], v5, v9);
  uint64_t v10 = v14;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v14 + 24))(&v14, a1, v5);
  uint64_t v12 = type metadata accessor for UpperStrictlyTriangularMatrix(0, v5, v9, v11);
  UpperStrictlyTriangularMatrix.subscript.setter((uint64_t)&v14, v16, v15, v12);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v10 + 8))(v17, v5);
}

uint64_t LowerStrictlyTriangularMatrix.transposed()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a1;
}

BOOL static LowerStrictlyTriangularMatrix.__derived_struct_equals(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10)
{
  return static UpperStrictlyTriangularMatrix.__derived_struct_equals(_:_:)(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10);
}

uint64_t associated type witness table accessor for Matrix.IndexedSequence : Sequence in LowerStrictlyTriangularMatrix<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for LowerStrictlyTriangularMatrix<A>.IndexedSequence, a1);
}

uint64_t associated type witness table accessor for Matrix.Transpose : Matrix in LowerStrictlyTriangularMatrix<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UpperStrictlyTriangularMatrix<A>, a1);
}

uint64_t protocol witness for Matrix.init(rowCount:columnCount:) in conformance LowerStrictlyTriangularMatrix<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  long long v4 = v3;
  uint64_t result = LowerStrictlyTriangularMatrix.init(rowCount:columnCount:)(a1, a2, *(unsigned char **)(a3 + 16), *(void *)(a3 + 24));
  *long long v4 = result;
  v4[1] = v6;
  v4[2] = v7;
  uint64_t v4[3] = v8;
  return result;
}

uint64_t protocol witness for Matrix.transposed() in conformance LowerStrictlyTriangularMatrix<A>()
{
  char v2 = v0;
  uint64_t result = LowerStrictlyTriangularMatrix.transposed()(*v1, v1[1], v1[2], v1[3]);
  *char v2 = result;
  v2[1] = v4;
  v2[2] = v5;
  v2[3] = v6;
  return result;
}

uint64_t protocol witness for Matrix.subscript.getter in conformance LowerStrictlyTriangularMatrix<A>(Swift::Int a1, Swift::Int a2, uint64_t a3)
{
  uint64_t v5 = v3;
  uint64_t v6 = *(void *)(a3 + 16);
  uint64_t v7 = LowerStrictlyTriangularMatrix.subscript.read(v10, a1, a2, *v4, v4[1], v4[2], v4[3], v6, *(void *)(a3 + 24));
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16))(v5, v8, v6);
  return ((uint64_t (*)(uint64_t *, void))v7)(v10, 0);
}

uint64_t protocol witness for Matrix.subscript.setter in conformance LowerStrictlyTriangularMatrix<A>(uint64_t a1, Swift::Int a2, Swift::Int a3, uint64_t a4)
{
  uint64_t v5 = LowerStrictlyTriangularMatrix.subscript.modify(v10, a2, a3, a4);
  uint64_t v6 = *(void *)(a4 + 16);
  uint64_t v7 = *(void *)(v6 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v7 + 24))(v8, a1, v6);
  ((void (*)(void *, void))v5)(v10, 0);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v7 + 8))(a1, v6);
}

void (*protocol witness for Matrix.subscript.modify in conformance LowerStrictlyTriangularMatrix<A>(void *a1, Swift::Int a2, Swift::Int a3, uint64_t a4))(void (***a1)(void))
{
  uint64_t v5 = malloc(0x28uLL);
  *a1 = v5;
  void v5[4] = LowerStrictlyTriangularMatrix.subscript.modify(v5, a2, a3, a4);
  return protocol witness for Collection.subscript.read in conformance <> InterspersedSequence<A>;
}

BOOL protocol witness for static Equatable.== infix(_:_:) in conformance LowerStrictlyTriangularMatrix<A>(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  return static LowerStrictlyTriangularMatrix.__derived_struct_equals(_:_:)(*a1, a1[1], a1[2], a1[3], *a2, a2[1], a2[2], a2[3], *(void *)(a3 + 16), *(void *)(a3 + 24));
}

uint64_t type metadata accessor for LowerStrictlyTriangularMatrix(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for LowerStrictlyTriangularMatrix);
}

uint64_t UnsafeVectorPointer.init(start:count:stride:)(uint64_t a1)
{
  return a1;
}

uint64_t UnsafeVectorPointer.Iterator.init(baseAddress:end:stride:)(uint64_t a1)
{
  return a1;
}

uint64_t UnsafeVectorPointer.Iterator.next()(uint64_t a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = *v2;
  if (!*v2) {
    return __swift_storeEnumTagSinglePayload(v3, 1, 1, *(void *)(a1 + 16));
  }
  uint64_t v5 = v2[1];
  if (!v5) {
    BUG();
  }
  if (v4 == v5) {
    return __swift_storeEnumTagSinglePayload(v3, 1, 1, *(void *)(a1 + 16));
  }
  uint64_t v6 = *(void *)(a1 + 16);
  uint64_t v7 = *(void *)(v6 - 8);
  *char v2 = v4 + v2[2] * *(void *)(v7 + 72);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v7 + 16))(v3, v4, v6);
  return __swift_storeEnumTagSinglePayload(v3, 0, 1, v6);
}

uint64_t UnsafeVectorPointer.baseAddress.getter(uint64_t a1)
{
  return a1;
}

void UnsafeVectorPointer.baseAddress.setter(uint64_t a1)
{
  void *v1 = a1;
}

void (*UnsafeVectorPointer.baseAddress.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeVectorPointer.count.getter(uint64_t a1, uint64_t a2)
{
  return a2;
}

void UnsafeVectorPointer.count.setter(uint64_t a1)
{
  *(void *)(v1 + 8) = a1;
}

void (*UnsafeVectorPointer.count.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeVectorPointer.stride.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return a3;
}

void UnsafeVectorPointer.stride.setter(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
}

void (*UnsafeVectorPointer.stride.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeVectorPointer.init(_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t result = UnsafeMutableBufferPointer.baseAddress.getter(a1, a2, a3);
  if (!result) {
    BUG();
  }
  return result;
}

uint64_t UnsafeVectorPointer.Iterator.baseAddress.getter(uint64_t a1)
{
  return a1;
}

void UnsafeVectorPointer.Iterator.baseAddress.setter(uint64_t a1)
{
  void *v1 = a1;
}

void (*UnsafeVectorPointer.Iterator.baseAddress.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeVectorPointer.Iterator.end.getter(uint64_t a1, uint64_t a2)
{
  return a2;
}

uint64_t UnsafeVectorPointer.Iterator.stride.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return a3;
}

void (*UnsafeVectorPointer.Iterator.stride.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t protocol witness for IteratorProtocol.next() in conformance UnsafeVectorPointer<A>.Iterator(uint64_t a1)
{
  return UnsafeVectorPointer.Iterator.next()(a1);
}

uint64_t UnsafeVectorPointer.makeIterator()(uint64_t a1, unint64_t a2, unint64_t a3)
{
  if (!is_mul_ok(a3, a2)) {
    BUG();
  }
  return a1;
}

uint64_t UnsafeVectorPointer._copyContents(initializing:)(uint64_t a1, Swift::Int a2, uint64_t a3, Swift::Int a4, unint64_t a5, uint64_t a6)
{
  unint64_t v42 = a5;
  Swift::Int v43 = a2;
  uint64_t v44 = a1;
  uint64_t v41 = *(void **)(a6 - 8);
  int64_t v9 = v41[8];
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  int64_t v40 = &v34;
  int64_t v12 = *(void *)(*(void *)(type metadata accessor for Optional(0, a6) - 8) + 64);
  Swift::Int v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v45 = a3;
  uint64_t v35 = a3;
  Swift::Int offsetBy = a4;
  Swift::Int v36 = a4;
  unint64_t v15 = v42;
  unint64_t v37 = v42;
  uint64_t v18 = type metadata accessor for UnsafeVectorPointer(0, a6, v16, v17);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeVectorPointer<A>, v18);
  if (Collection.isEmpty.getter(v18, WitnessTable))
  {
    uint64_t v20 = UnsafeVectorPointer.makeIterator()(v45, offsetBy, v15);
    UnsafeMutableBufferPointer.startIndex.getter(v44, v43, a6);
  }
  else
  {
    uint64_t v21 = v44;
    Swift::Int v22 = v43;
    uint64_t v23 = UnsafeMutableBufferPointer.baseAddress.getter(v44, v43, a6);
    if (!v23)
    {
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000030, "safeMutableVectorPointer.swift" + 0x8000000000000000, "LinearAlgebra/UnsafeVectorPointer.swift", 39, 2, 126, 0);
      BUG();
    }
    if (v22 < offsetBy) {
      BUG();
    }
    uint64_t v24 = v23;
    if (v42 == 1)
    {
      uint64_t v25 = v45;
      UnsafeMutablePointer.initialize(from:count:)(v45, offsetBy, v23, a6);
    }
    else
    {
      uint64_t v35 = UnsafeVectorPointer.makeIterator()(v45, offsetBy, v42);
      Swift::Int v36 = v26;
      unint64_t v37 = v27;
      uint64_t v38 = type metadata accessor for UnsafeVectorPointer.Iterator(0, a6, v26, v27);
      UnsafeVectorPointer.Iterator.next()(v38);
      int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)&v34, 1, a6);
      uint64_t v29 = (uint64_t)v40;
      if (EnumTagSinglePayload != 1)
      {
        uint64_t v39 = (void (*)(uint64_t, uint64_t *, uint64_t))v41[4];
        do
        {
          v39(v29, &v34, a6);
          _sSpsRi_zrlE10initialize2toyxn_tF(v29, v24, a6);
          v24 += v41[9];
          UnsafeVectorPointer.Iterator.next()(v38);
        }
        while (__swift_getEnumTagSinglePayload((uint64_t)&v34, 1, a6) != 1);
      }
      uint64_t v25 = v45;
      Swift::Int v22 = v43;
      uint64_t v21 = v44;
    }
    if (!is_mul_ok(v42, offsetBy)) {
      BUG();
    }
    uint64_t v20 = v41[9] * v42 * offsetBy + v25;
    uint64_t v30 = v21;
    Swift::Int v31 = offsetBy;
    Swift::Int v32 = UnsafeMutableBufferPointer.startIndex.getter(v30, v22, a6);
    UnsafeMutableBufferPointer.index(_:offsetBy:)(v32, v31);
  }
  return v20;
}

uint64_t type metadata accessor for UnsafeVectorPointer(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for UnsafeVectorPointer);
}

uint64_t type metadata accessor for UnsafeVectorPointer.Iterator(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for UnsafeVectorPointer.Iterator);
}

uint64_t protocol witness for Sequence.makeIterator() in conformance UnsafeVectorPointer<A>()
{
  char v2 = v0;
  uint64_t result = UnsafeVectorPointer.makeIterator()(*(void *)v1, *(void *)(v1 + 8), *(void *)(v1 + 16));
  *char v2 = result;
  v2[1] = v4;
  v2[2] = v5;
  return result;
}

uint64_t protocol witness for Sequence.underestimatedCount.getter in conformance UnsafeVectorPointer<A>(uint64_t a1)
{
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeVectorPointer<A>, a1);
  return Collection.underestimatedCount.getter(a1, WitnessTable);
}

uint64_t protocol witness for Sequence._copyToContiguousArray() in conformance UnsafeVectorPointer<A>(uint64_t a1)
{
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeVectorPointer<A>, a1);
  return Collection._copyToContiguousArray()(a1, WitnessTable);
}

uint64_t protocol witness for Sequence._copyContents(initializing:) in conformance UnsafeVectorPointer<A>(uint64_t *a1, uint64_t a2, Swift::Int a3, uint64_t a4)
{
  *a1 = UnsafeVectorPointer._copyContents(initializing:)(a2, a3, *(void *)v4, *(void *)(v4 + 8), *(void *)(v4 + 16), *(void *)(a4 + 16));
  a1[1] = v5;
  a1[2] = v6;
  return v7;
}

uint64_t UnsafeVectorPointer.startIndex.getter()
{
  return 0;
}

uint64_t UnsafeVectorPointer.endIndex.getter(uint64_t a1, uint64_t a2)
{
  return a2;
}

Swift::Int __swiftcall UnsafeVectorPointer.index(after:)(Swift::Int after)
{
  return after + 1;
}

Swift::Void __swiftcall UnsafeVectorPointer.formIndex(after:)(Swift::Int *after)
{
}

Swift::Int __swiftcall UnsafeVectorPointer.index(before:)(Swift::Int before)
{
  return before - 1;
}

Swift::Void __swiftcall UnsafeVectorPointer.formIndex(before:)(Swift::Int *before)
{
}

Swift::Int __swiftcall UnsafeVectorPointer.index(_:offsetBy:)(Swift::Int _, Swift::Int offsetBy)
{
  return _ + offsetBy;
}

Swift::Int_optional __swiftcall UnsafeVectorPointer.index(_:offsetBy:limitedBy:)(Swift::Int _, Swift::Int offsetBy, Swift::Int limitedBy)
{
  Swift::Int v3 = limitedBy - _;
  if (offsetBy <= 0)
  {
    if (v3 > 0 || v3 <= offsetBy) {
      goto LABEL_8;
    }
  }
  else if (v3 < 0 || v3 >= (unint64_t)offsetBy)
  {
LABEL_8:
    v4.value = _ + offsetBy;
    v4.is_nil = 0;
    return v4;
  }
  v4.value = 0;
  v4.is_nil = 1;
  return v4;
}

Swift::Int __swiftcall UnsafeVectorPointer.distance(from:to:)(Swift::Int from, Swift::Int to)
{
  return to - from;
}

uint64_t UnsafeVectorPointer.indices.getter()
{
  return 0;
}

uint64_t UnsafeVectorPointer.subscript.getter(unint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, uint64_t a5)
{
  return UnsafeMutableVectorPointer.subscript.getter(a1, a2, a3, a4, a5);
}

{
  return UnsafeMutableVectorPointer.subscript.getter(a1, a2, a3, a4, a5);
}

uint64_t UnsafeVectorPointer.subscript.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v7 = v6;
  v14[0] = a3;
  v14[1] = a4;
  v14[2] = a5;
  v15[0] = a1;
  v15[1] = a2;
  uint64_t v8 = type metadata accessor for UnsafeVectorPointer(0, a6, a3, a4);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeVectorPointer<A>, v8);
  Slice.init(base:bounds:)(v14, v15, v8, WitnessTable);
  uint64_t result = v12;
  *(_OWORD *)uint64_t v7 = v11;
  *(void *)(v7 + 16) = v12;
  *(_OWORD *)(v7 + 24) = v13;
  return result;
}

void (*protocol witness for Collection.subscript.read in conformance UnsafeVectorPointer<A>(uint64_t **a1, unint64_t *a2, uint64_t a3))(void (***a1)(void))
{
  uint64_t v5 = (uint64_t *)malloc(0x28uLL);
  *a1 = v5;
  void v5[4] = (uint64_t)UnsafeVectorPointer.subscript.read(v5, *a2, *(void *)v3, *(void *)(v3 + 8), *(void *)(v3 + 16), *(void *)(a3 + 16));
  return protocol witness for Collection.subscript.read in conformance <> InterspersedSequence<A>;
}

void (*UnsafeVectorPointer.subscript.read(uint64_t *a1, unint64_t a2, uint64_t a3, uint64_t a4, unint64_t a5, uint64_t a6))(void *a1)
{
  *a1 = a6;
  uint64_t v8 = *(void *)(a6 - 8);
  a1[1] = v8;
  a1[2] = (uint64_t)malloc(*(void *)(v8 + 64));
  UnsafeVectorPointer.subscript.getter(a2, a3, v9, a5, a6);
  return InterspersedSequence<>.subscript.read;
}

uint64_t protocol witness for Collection.subscript.getter in conformance UnsafeVectorPointer<A>(uint64_t *a1, uint64_t a2)
{
  uint64_t v4 = v2;
  UnsafeVectorPointer.subscript.getter(*a1, a1[1], *v3, v3[1], v3[2], *(void *)(a2 + 16));
  uint64_t result = v8;
  *(void *)(v4 + 32) = v8;
  *(_OWORD *)(v4 + 16) = v7;
  *(_OWORD *)uint64_t v4 = v6;
  return result;
}

uint64_t protocol witness for Collection.indices.getter in conformance UnsafeVectorPointer<A>()
{
  uint64_t v1 = v0;
  uint64_t result = UnsafeVectorPointer.indices.getter();
  void *v1 = 0;
  v1[1] = v3;
  return result;
}

Swift::Int protocol witness for Collection.index(_:offsetBy:limitedBy:) in conformance UnsafeVectorPointer<A>(Swift::Int *a1, Swift::Int a2, Swift::Int *a3)
{
  return protocol witness for Collection.index(_:offsetBy:limitedBy:) in conformance UnsafeVectorPointer<A>(a1, a2, a3);
}

{
  uint64_t v3;
  uint64_t v4;
  Swift::Int_optional v5;

  uint64_t v4 = v3;
  uint64_t v5 = UnsafeVectorPointer.index(_:offsetBy:limitedBy:)(*a1, a2, *a3);
  *(void *)uint64_t v4 = v5.value;
  *(unsigned char *)(v4 + 8) = v5.is_nil;
  return v5.value;
}

Swift::Int protocol witness for Collection.index(after:) in conformance UnsafeVectorPointer<A>(Swift::Int *a1)
{
  uint64_t v2 = v1;
  Swift::Int result = UnsafeVectorPointer.index(after:)(*a1);
  *uint64_t v2 = result;
  return result;
}

void protocol witness for Collection.formIndex(after:) in conformance UnsafeVectorPointer<A>(Swift::Int *after)
{
}

Swift::Int protocol witness for BidirectionalCollection.index(before:) in conformance UnsafeVectorPointer<A>(Swift::Int *a1)
{
  uint64_t v2 = v1;
  Swift::Int result = UnsafeVectorPointer.index(before:)(*a1);
  *uint64_t v2 = result;
  return result;
}

void protocol witness for BidirectionalCollection.formIndex(before:) in conformance UnsafeVectorPointer<A>(Swift::Int *before)
{
}

Swift::Int protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance UnsafeVectorPointer<A>(Swift::Int *a1, Swift::Int a2)
{
  uint64_t v3 = v2;
  Swift::Int result = UnsafeVectorPointer.index(_:offsetBy:)(*a1, a2);
  Swift::Int *v3 = result;
  return result;
}

Swift::Int protocol witness for BidirectionalCollection.distance(from:to:) in conformance UnsafeVectorPointer<A>(Swift::Int *a1, Swift::Int *a2)
{
  return UnsafeVectorPointer.distance(from:to:)(*a1, *a2);
}

uint64_t UnsafeVectorPointer.withContiguousStorageIfAvailable<A>(_:)(uint64_t (*a1)(uint64_t, uint64_t, uint64_t), uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v9 = v7;
  if (a5 == 1)
  {
    uint64_t result = a1(a3, a4, 1);
    if (v8) {
      return result;
    }
    uint64_t v11 = 0;
  }
  else
  {
    uint64_t v11 = 1;
  }
  return __swift_storeEnumTagSinglePayload(v9, v11, 1, a7);
}

uint64_t UnsafeVectorPointer.init(rebasing:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v4 = type metadata accessor for UnsafeVectorPointer(255, a2, a3, a4);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeVectorPointer<A>, v4);
  uint64_t v6 = v4;
  uint64_t v7 = type metadata accessor for Slice(0, v4, WitnessTable);
  Slice.base.getter(v7);
  Slice.startIndex.getter(v7);
  Slice.base.getter(v7);
  if (!is_mul_ok(v13, v15)) {
    BUG();
  }
  uint64_t v17 = *(void *)(*(void *)(a2 - 8) + 72) * v13 * v15 + v14;
  Slice.endIndex.getter(v7, v6, v8, v9, v10, v11);
  Slice.startIndex.getter(v7);
  Slice.base.getter(v7);
  return v17;
}

{
  uint64_t v4;
  uint64_t WitnessTable;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  unint64_t v13;
  uint64_t v14;
  unint64_t v15;
  uint64_t v17;

  uint64_t v4 = type metadata accessor for UnsafeMutableVectorPointer(255, a2, a3, a4);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeMutableVectorPointer<A>, v4);
  uint64_t v6 = v4;
  uint64_t v7 = type metadata accessor for Slice(0, v4, WitnessTable);
  Slice.base.getter(v7);
  Slice.startIndex.getter(v7);
  Slice.base.getter(v7);
  if (!is_mul_ok(v13, v15)) {
    BUG();
  }
  uint64_t v17 = *(void *)(*(void *)(a2 - 8) + 72) * v13 * v15 + v14;
  Slice.endIndex.getter(v7, v6, v8, v9, v10, v11);
  Slice.startIndex.getter(v7);
  Slice.base.getter(v7);
  return v17;
}

Swift::Void __swiftcall UnsafeVectorPointer.deallocate()()
{
}

uint64_t UnsafeVectorPointer.debugDescription.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  _StringGuts.grow(_:)(53);
  v6._char object = "safeVectorPointer.swift" + 0x8000000000000000;
  v6._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
  String.append(_:)(v6);
  v17[0] = a1;
  uint64_t v7 = type metadata accessor for UnsafePointer(0, a4);
  DefaultStringInterpolation.appendInterpolation<A>(_:)(v17, v7);
  v6._uint64_t countAndFlagsBits = 0x3A746E756F63202CLL;
  v6._char object = (void *)0xE900000000000020;
  String.append(_:)(v6);
  v17[0] = a2;
  uint64_t v8 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  uint64_t v10 = v9;
  v6._uint64_t countAndFlagsBits = v8;
  v6._char object = v9;
  String.append(_:)(v6);
  swift_bridgeObjectRelease(v10);
  v6._uint64_t countAndFlagsBits = 0x656469727473202CLL;
  v6._char object = (void *)0xEA0000000000203ALL;
  String.append(_:)(v6);
  v17[0] = a3;
  uint64_t v11 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  unint64_t v13 = v12;
  v6._uint64_t countAndFlagsBits = v11;
  v6._char object = v12;
  String.append(_:)(v6);
  swift_bridgeObjectRelease(v13);
  v6._uint64_t countAndFlagsBits = 41;
  v6._char object = (void *)0xE100000000000000;
  String.append(_:)(v6);
  return 0;
}

uint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in UnsafeVectorPointer<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UnsafeVectorPointer<A>.Iterator, a1);
}

uint64_t base witness table accessor for Sequence in UnsafeVectorPointer<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UnsafeVectorPointer<A>, a1);
}

uint64_t base witness table accessor for BidirectionalCollection in UnsafeVectorPointer<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UnsafeVectorPointer<A>, a1);
}

uint64_t associated type witness table accessor for Collection.SubSequence : RandomAccessCollection in UnsafeVectorPointer<A>(uint64_t a1, uint64_t a2)
{
  return swift_getWitnessTable(&protocol conformance descriptor for <> Slice<A>, a1);
}

uint64_t base witness table accessor for Collection in UnsafeVectorPointer<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UnsafeVectorPointer<A>, a1);
}

uint64_t associated type witness table accessor for Collection.SubSequence : BidirectionalCollection in UnsafeVectorPointer<A>(uint64_t a1, uint64_t a2)
{
  return swift_getWitnessTable(&protocol conformance descriptor for <> Slice<A>, a1);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance UnsafeVectorPointer<A>(uint64_t a1)
{
  return UnsafeVectorPointer.debugDescription.getter(*v1, v1[1], v1[2], *(void *)(a1 + 16));
}

uint64_t protocol witness for AccelerateBuffer.withUnsafeBufferPointer<A>(_:) in conformance UnsafeVectorPointer<A>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeVectorPointer<A>, a4);
  return AccelerateBuffer<>.withUnsafeBufferPointer<A>(_:)(a1, a2, a4, a3, a5, WitnessTable);
}

uint64_t __swift_memcpy24_8(uint64_t a1, uint64_t a2)
{
  uint64_t result = a1;
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(_OWORD *)a1 = *(_OWORD *)a2;
  return result;
}

uint64_t UnsafeVectorPointer.init(_:)(uint64_t a1)
{
  return UnsafeVectorPointer.init(start:count:stride:)(a1);
}

Swift::Int protocol witness for Collection.distance(from:to:) in conformance UnsafeVectorPointer<A>(Swift::Int *a1, Swift::Int *a2)
{
  return protocol witness for BidirectionalCollection.distance(from:to:) in conformance UnsafeVectorPointer<A>(a1, a2);
}

Swift::Int protocol witness for Collection.index(_:offsetBy:) in conformance UnsafeVectorPointer<A>(Swift::Int *a1, Swift::Int a2)
{
  return protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance UnsafeVectorPointer<A>(a1, a2);
}

void UnsafeVectorPointer.Iterator.stride.setter(uint64_t a1)
{
}

uint64_t protocol witness for Collection._customLastIndexOfEquatableElement(_:) in conformance UnsafeVectorPointer<A>()
{
  return protocol witness for Collection._customIndexOfEquatableElement(_:) in conformance MLDataTable.ColumnNames();
}

uint64_t UnsafeMatrixPointer.init(start:rowCount:columnCount:layout:)(uint64_t a1)
{
  return UnsafeMutableMatrixPointer.init(start:rowCount:columnCount:layout:)(a1);
}

uint64_t UnsafeMatrixPointer.baseAddress.getter(uint64_t a1)
{
  return a1;
}

void UnsafeMatrixPointer.baseAddress.setter(uint64_t a1)
{
  void *v1 = a1;
}

void (*UnsafeMatrixPointer.baseAddress.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeMatrixPointer.rowCount.getter(uint64_t a1, uint64_t a2)
{
  return a2;
}

void UnsafeMatrixPointer.rowCount.setter(uint64_t a1)
{
  *(void *)(v1 + 8) = a1;
}

void (*UnsafeMatrixPointer.rowCount.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeMatrixPointer.columnCount.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return a3;
}

void UnsafeMatrixPointer.columnCount.setter(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
}

void (*UnsafeMatrixPointer.columnCount.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

char UnsafeMatrixPointer.layout.getter(uint64_t a1, uint64_t a2, uint64_t a3, char a4)
{
  return a4 & 1;
}

void UnsafeMatrixPointer.layout.setter(char a1)
{
  *(unsigned char *)(v1 + 24) = a1 & 1;
}

void (*UnsafeMatrixPointer.layout.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

unint64_t UnsafeMatrixPointer.count.getter(uint64_t a1, unint64_t a2, unint64_t a3)
{
  unint64_t v3 = a3 * a2;
  if (!is_mul_ok(a3, a2)) {
    BUG();
  }
  return v3;
}

uint64_t UnsafeMatrixPointer.init(_:)(uint64_t a1)
{
  return UnsafeMutableMatrixPointer.init(start:rowCount:columnCount:layout:)(a1);
}

Swift::Void __swiftcall UnsafeMatrixPointer.deallocate()()
{
}

uint64_t UnsafeMatrixPointer.subscript.getter(unint64_t a1, unint64_t a2, uint64_t a3, unint64_t a4, unint64_t a5, char a6, uint64_t a7)
{
  if (a6)
  {
    unint64_t v12 = a4 * a2;
    if (!is_mul_ok(a4, a2)) {
      BUG();
    }
    BOOL v10 = __OFADD__(v12, a1);
    unint64_t v11 = v12 + a1;
    if (v10) {
      BUG();
    }
  }
  else
  {
    unint64_t v8 = a5 * a1;
    if (!is_mul_ok(a5, a1)) {
      BUG();
    }
    BOOL v10 = __OFADD__(a2, v8);
    unint64_t v11 = a2 + v8;
    if (v10) {
      BUG();
    }
  }
  return (*(uint64_t (**)(uint64_t, unint64_t, uint64_t))(*(void *)(a7 - 8) + 16))(v7, *(void *)(*(void *)(a7 - 8) + 72) * v11 + a3, a7);
}

uint64_t UnsafeMatrixPointer.subscript.getter(unint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, char a5, uint64_t a6)
{
  if ((a5 & 1) == 0)
  {
    unint64_t v6 = a1;
    a1 *= a4;
    if (!is_mul_ok(a4, v6)) {
      BUG();
    }
  }
  return UnsafeVectorPointer.init(start:count:stride:)(*(void *)(*(void *)(a6 - 8) + 72) * a1 + a2);
}

uint64_t UnsafeMatrixPointer.subscript.getter(unint64_t a1, uint64_t a2, unint64_t a3, uint64_t a4, char a5, uint64_t a6)
{
  if (a5)
  {
    unint64_t v6 = a1;
    a1 *= a3;
    if (!is_mul_ok(a3, v6)) {
      BUG();
    }
  }
  return UnsafeVectorPointer.init(start:count:stride:)(*(void *)(*(void *)(a6 - 8) + 72) * a1 + a2);
}

uint64_t UnsafeMatrixPointer.debugDescription.getter(uint64_t a1, uint64_t a2, uint64_t a3, int a4, uint64_t a5)
{
  int v19 = a4;
  uint64_t v17 = a3;
  v16[0] = 0;
  uint64_t v18 = a2;
  v16[1] = 0xE000000000000000;
  _StringGuts.grow(_:)(65);
  v7._char object = "UnsafeVectorPointer(start: " + 0x8000000000000000;
  v7._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
  String.append(_:)(v7);
  v20[0] = a1;
  uint64_t v8 = type metadata accessor for UnsafePointer(0, a5);
  DefaultStringInterpolation.appendInterpolation<A>(_:)(v20, v8);
  v7._uint64_t countAndFlagsBits = 0x203A73776F72202CLL;
  v7._char object = (void *)0xE800000000000000;
  String.append(_:)(v7);
  v20[0] = v18;
  uint64_t v9 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  unint64_t v11 = v10;
  v7._uint64_t countAndFlagsBits = v9;
  v7._char object = v10;
  String.append(_:)(v7);
  swift_bridgeObjectRelease(v11);
  v7._uint64_t countAndFlagsBits = 0x6E6D756C6F63202CLL;
  v7._char object = (void *)0xEB00000000203A73;
  String.append(_:)(v7);
  v20[0] = v17;
  uint64_t v12 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  uint64_t v14 = v13;
  v7._uint64_t countAndFlagsBits = v12;
  v7._char object = v13;
  String.append(_:)(v7);
  swift_bridgeObjectRelease(v14);
  v7._uint64_t countAndFlagsBits = 0x74756F79616C202CLL;
  v7._char object = (void *)0xEA0000000000203ALL;
  String.append(_:)(v7);
  LOBYTE(v20[0]) = v19 & 1;
  _print_unlocked<A, B>(_:_:)(v20, v16, &type metadata for MatrixLayout, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v7._uint64_t countAndFlagsBits = 41;
  v7._char object = (void *)0xE100000000000000;
  String.append(_:)(v7);
  return v16[0];
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance UnsafeMatrixPointer<A>(uint64_t a1)
{
  return UnsafeMatrixPointer.debugDescription.getter(*(void *)v1, *(void *)(v1 + 8), *(void *)(v1 + 16), *(unsigned __int8 *)(v1 + 24), *(void *)(a1 + 16));
}

uint64_t type metadata accessor for UnsafeMatrixPointer(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for UnsafeMatrixPointer);
}

uint64_t SparseMatrix.majorCount.getter()
{
  return *(void *)(v0 + 8 * *(unsigned __int8 *)(v0 + 16));
}

unint64_t SparseMatrix.count.getter()
{
  unint64_t result = v0[1] * *v0;
  if (!is_mul_ok(v0[1], *v0)) {
    BUG();
  }
  return result;
}

uint64_t SparseMatrix.init(rowCount:columnCount:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  uint64_t result = SparseMatrix.init(rowCount:columnCount:layout:)(a1, a2, 0, a3);
  v4[2] = v8;
  v4[1] = v7;
  *uint64_t v4 = v6;
  return result;
}

uint64_t SparseMatrix.subscript.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = v4;
  uint64_t v25 = v3;
  uint64_t v7 = *(void *)(a3 + 16);
  uint64_t v24 = *(void *)(*(void *)(a3 + 24) + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v24, v7, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v9 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  BOOL v10 = alloca(v9);
  unint64_t v11 = alloca(v9);
  uint64_t v12 = a2;
  if (*(unsigned char *)(v5 + 16))
  {
    uint64_t v12 = a1;
    a1 = a2;
  }
  if (a1 < 0) {
    BUG();
  }
  uint64_t v13 = *(void *)(v5 + 24);
  unint64_t v14 = *(void *)(v13 + 16);
  if (a1 >= v14) {
    BUG();
  }
  if (a1 + 1 >= v14) {
    BUG();
  }
  int64_t v15 = *(void *)(v13 + 8 * a1 + 32);
  int64_t v16 = *(void *)(v13 + 8 * a1 + 40);
  if (v15 != v16)
  {
    if (v15 > v16) {
      BUG();
    }
    if (v15 < 0) {
      BUG();
    }
    uint64_t v17 = *(void *)(v5 + 32);
    unint64_t v18 = *(void *)(v17 + 16);
    if (v18 < v15 || (uint64_t)v18 < v16) {
      BUG();
    }
    if (v12 < (uint64_t)0xFFFFFFFF80000000) {
      BUG();
    }
    if (v12 > 0x7FFFFFFF) {
      BUG();
    }
    uint64_t v19 = specialized Collection<>.firstIndex(of:)(v12, v17, v17 + 32, v15, 2 * v16 + 1);
    if ((v20 & 1) == 0) {
      return ContiguousArray.subscript.getter(v19, *(void *)(v5 + 40), v7);
    }
  }
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v24, v7, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, AssociatedConformanceWitness);
  return dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(&v23, v7, v24);
}

uint64_t SparseMatrix.subscript.setter(uint64_t a1, Swift::Int a2, uint64_t a3, uint64_t a4)
{
  uint64_t v8 = *(void *)(a4 + 16);
  uint64_t v55 = *(void *)(v8 - 8);
  int64_t v9 = *(void *)(v55 + 64);
  BOOL v10 = alloca(v9);
  unint64_t v11 = alloca(v9);
  unint64_t v61 = &v50;
  uint64_t v59 = a4;
  uint64_t v58 = *(void *)(a4 + 24);
  uint64_t v12 = *(void *)(v58 + 16);
  uint64_t v13 = v12;
  uint64_t v52 = v8;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v12, v8, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  uint64_t v15 = v4;
  uint64_t v16 = AssociatedTypeWitness;
  int64_t v17 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  unint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v20 = a3;
  if (*(unsigned char *)(v15 + 16))
  {
    uint64_t v20 = a2;
    a2 = a3;
  }
  if (a2 < 0) {
    BUG();
  }
  uint64_t v21 = *(void *)(v15 + 24);
  unint64_t v22 = *(void *)(v21 + 16);
  if (a2 >= v22) {
    BUG();
  }
  if (a2 + 1 >= v22) {
    BUG();
  }
  uint64_t v57 = v15;
  uint64_t v60 = a1;
  int64_t v23 = *(void *)(v21 + 8 * a2 + 32);
  int64_t v24 = *(void *)(v21 + 8 * a2 + 40);
  uint64_t v56 = v20;
  uint64_t v53 = v13;
  if (v23 != v24)
  {
    if (v23 > v24) {
      BUG();
    }
    if (v23 < 0) {
      BUG();
    }
    uint64_t v33 = *(void *)(v57 + 32);
    unint64_t v34 = *(void *)(v33 + 16);
    if (v34 < v23 || (uint64_t)v34 < v24) {
      BUG();
    }
    if (v20 < (uint64_t)0xFFFFFFFF80000000) {
      BUG();
    }
    if (v20 > 0x7FFFFFFF) {
      BUG();
    }
    unint64_t v51 = v24;
    uint64_t v50 = (uint64_t)&v50;
    Swift::Int index = specialized Collection<>.firstIndex(of:)(v20, v33, v33 + 32, v23, 2 * v24 + 1);
    char v62 = v35;
    uint64_t v36 = v13;
    uint64_t v26 = v52;
    uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v36, v52, v16, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
    dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, v16, AssociatedConformanceWitness);
    uint64_t v38 = v61;
    dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(v50, v26, v53);
    char v39 = dispatch thunk of static Equatable.== infix(_:_:)(v60, v38, v26, *(void *)(*(void *)(v58 + 8) + 8));
    unint64_t v61 = *(uint64_t **)(v55 + 8);
    ((void (*)(uint64_t *, uint64_t))v61)(v38, v26);
    if ((v62 & 1) == 0)
    {
      if ((v39 & 1) == 0)
      {
        uint64_t v40 = v57;
        type metadata accessor for ContiguousArray(0, v26);
        ContiguousArray._makeMutableAndUnique()();
        uint64_t v41 = *(void *)(v40 + 40);
        Swift::Int v42 = index;
        ContiguousArray._checkSubscript_mutating(_:)(index);
        Swift::Int v43 = v41
            + ((*(unsigned __int8 *)(v55 + 80) + 32) & ~*(unsigned __int8 *)(v55 + 80))
            + *(void *)(v55 + 72) * v42;
        uint64_t v29 = v60;
        (*(void (**)(Swift::Int, uint64_t, uint64_t))(v55 + 24))(v43, v60, v26);
        MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
        goto LABEL_34;
      }
      SparseMatrix.remove(index:major:)(index, a2);
LABEL_20:
      uint64_t v29 = v60;
LABEL_34:
      uint64_t v30 = v61;
      return ((uint64_t (*)(uint64_t, uint64_t))v30)(v29, v26);
    }
    if (v39) {
      goto LABEL_20;
    }
    uint64_t v44 = *(void *)(v57 + 32);
    unint64_t v45 = *(void *)(v44 + 16);
    uint64_t v46 = v51;
    if (v45 < v23 || v45 < v51) {
      BUG();
    }
    if (v23 >= v51) {
      BUG();
    }
    if (*(_DWORD *)(v44 + 4 * v23 + 32) <= (int)v56)
    {
      if (v23 + 1 == v51)
      {
LABEL_32:
        uint64_t v48 = v56;
        uint64_t v47 = a2;
        goto LABEL_33;
      }
      while (1)
      {
        if (v23 + 1 >= (uint64_t)v51) {
          BUG();
        }
        if (*(_DWORD *)(v44 + 4 * v23 + 36) > (int)v56) {
          break;
        }
        int64_t v49 = v23 + 2;
        if (__OFADD__(1, v23 + 1)) {
          BUG();
        }
        ++v23;
        if (v49 == v51) {
          goto LABEL_32;
        }
      }
      ++v23;
    }
    uint64_t v46 = v23;
    uint64_t v47 = a2;
    uint64_t v48 = v56;
LABEL_33:
    uint64_t v29 = v60;
    SparseMatrix.insert(index:major:minor:value:)(v46, v47, v48, v60, v59);
    goto LABEL_34;
  }
  uint64_t v25 = v13;
  uint64_t v26 = v52;
  uint64_t v27 = swift_getAssociatedConformanceWitness(v25, v52, v16, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, v16, v27);
  uint64_t v28 = v61;
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(&v50, v26, v53);
  uint64_t v29 = v60;
  LOBYTE(v58) = dispatch thunk of static Equatable.== infix(_:_:)(v60, v28, v26, *(void *)(*(void *)(v58 + 8) + 8));
  uint64_t v30 = *(uint64_t **)(v55 + 8);
  ((void (*)(uint64_t *, uint64_t))v30)(v28, v26);
  if (v58) {
    return ((uint64_t (*)(uint64_t, uint64_t))v30)(v29, v26);
  }
  uint64_t v31 = *(void *)(v57 + 24);
  if ((unint64_t)a2 >= *(void *)(v31 + 16)) {
    BUG();
  }
  SparseMatrix.insert(index:major:minor:value:)(*(void *)(v31 + 8 * a2 + 32), a2, v56, v29, v59);
  return ((uint64_t (*)(uint64_t, uint64_t))v30)(v29, v26);
}

uint64_t static SparseMatrix.__derived_struct_equals(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (*(void *)a1 == *(void *)a2
    && *(void *)(a1 + 8) == *(void *)(a2 + 8)
    && *(unsigned char *)(a1 + 16) == *(unsigned char *)(a2 + 16)
    && specialized static Array<A>.== infix(_:_:)(*(void *)(a1 + 24), *(void *)(a2 + 24))
    && specialized static Array<A>.== infix(_:_:)(*(void *)(a1 + 32), *(void *)(a2 + 32)))
  {
    return static ContiguousArray<A>.== infix(_:_:)(*(void *)(a1 + 40), *(void *)(a2 + 40), a3, *(void *)(*(void *)(a4 + 8) + 8));
  }
  else
  {
    return 0;
  }
}

uint64_t SparseMatrix.rowCount.getter()
{
  return *(void *)v0;
}

uint64_t SparseMatrix.columnCount.getter()
{
  return *(void *)(v0 + 8);
}

char SparseMatrix.layout.getter()
{
  return *(unsigned char *)(v0 + 16);
}

uint64_t SparseMatrix.minorCount.getter()
{
  return *(void *)(v0 + 8 * (*(unsigned __int8 *)(v0 + 16) ^ 1));
}

uint64_t SparseMatrix.majorStarts.getter()
{
  return swift_bridgeObjectRetain(*(void *)(v0 + 24));
}

uint64_t SparseMatrix.majorStarts.setter(uint64_t a1)
{
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v1 + 24));
  *(void *)(v1 + 24) = a1;
  return result;
}

void (*SparseMatrix.majorStarts.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t SparseMatrix.minorIndices.getter()
{
  return swift_bridgeObjectRetain(*(void *)(v0 + 32));
}

uint64_t SparseMatrix.minorIndices.setter(uint64_t a1)
{
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v1 + 32));
  *(void *)(v1 + 32) = a1;
  return result;
}

void (*SparseMatrix.minorIndices.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t SparseMatrix.storage.getter()
{
  return swift_retain(*(void *)(v0 + 40));
}

uint64_t SparseMatrix.storage.setter(uint64_t a1)
{
  uint64_t result = swift_release(*(void *)(v1 + 40));
  *(void *)(v1 + 40) = a1;
  return result;
}

void (*SparseMatrix.storage.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t SparseMatrix.nonZeroValues.getter(uint64_t a1)
{
  v6[0] = *(void *)(v1 + 40);
  uint64_t v2 = *(void *)(a1 + 16);
  uint64_t v3 = type metadata accessor for ContiguousArray(0, v2);
  swift_retain(v6[0]);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for ContiguousArray<A>, v3);
  return Array.init<A>(_:)(v6, v2, v3, WitnessTable);
}

uint64_t SparseMatrix.init(rowCount:columnCount:layout:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4)
{
  uint64_t v6 = v4;
  char v7 = a3 & 1;
  if (a3)
  {
    uint64_t v8 = a2 + 1;
    if (__OFADD__(1, a2)) {
      BUG();
    }
  }
  else
  {
    uint64_t v8 = a1 + 1;
    if (__OFADD__(1, a1)) {
      BUG();
    }
  }
  BOOL v10 = specialized Array.init(repeating:count:)(0, v8);
  uint64_t v11 = static Array._allocateUninitialized(_:)(0, a4);
  uint64_t result = ContiguousArray.init(arrayLiteral:)(v11, a4);
  *(void *)uint64_t v6 = a1;
  *(void *)(v6 + 8) = a2;
  *(unsigned char *)(v6 + 16) = v7;
  *(void *)(v6 + 24) = v10;
  *(void *)(v6 + 32) = _swiftEmptyArrayStorage;
  *(void *)(v6 + 40) = result;
  return result;
}

uint64_t SparseMatrix.init(rowCount:columnCount:columnStarts:rowIndices:values:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v7 = v6;
  if (__OFADD__(1, a2)) {
    BUG();
  }
  uint64_t v15 = a1;
  uint64_t v14 = a4;
  if (*(void *)(a3 + 16) != a2 + 1)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000043, "arseMatrix.swift" + 0x8000000000000000, "LinearAlgebra/SparseMatrix.swift", 32, 2, 102, 0);
    BUG();
  }
  uint64_t v13 = a5;
  uint64_t v10 = type metadata accessor for Array(0, a6);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for [A], v10);
  uint64_t result = ContiguousArray.init<A>(_:)(&v13, a6, v10, WitnessTable);
  *(void *)uint64_t v7 = v15;
  *(void *)(v7 + 8) = a2;
  *(unsigned char *)(v7 + 16) = 1;
  *(void *)(v7 + 24) = a3;
  *(void *)(v7 + 32) = v14;
  *(void *)(v7 + 40) = result;
  return result;
}

uint64_t SparseMatrix.init(rowCount:columnCount:rowStarts:columnIndices:values:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v7 = v6;
  if (__OFADD__(1, a1)) {
    BUG();
  }
  uint64_t v15 = a2;
  uint64_t v14 = a4;
  if (*(void *)(a3 + 16) != a1 + 1)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000003DLL, "plus and end index." + 0x8000000000000000, "LinearAlgebra/SparseMatrix.swift", 32, 2, 123, 0);
    BUG();
  }
  uint64_t v13 = a5;
  uint64_t v10 = type metadata accessor for Array(0, a6);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for [A], v10);
  uint64_t result = ContiguousArray.init<A>(_:)(&v13, a6, v10, WitnessTable);
  *(void *)uint64_t v7 = a1;
  *(void *)(v7 + 8) = v15;
  *(unsigned char *)(v7 + 16) = 0;
  *(void *)(v7 + 24) = a3;
  *(void *)(v7 + 32) = v14;
  *(void *)(v7 + 40) = result;
  return result;
}

Swift::Void __swiftcall SparseMatrix.removeAll(keepingCapacity:)(Swift::Bool keepingCapacity)
{
  specialized Array.removeAll(keepingCapacity:)(keepingCapacity);
  uint64_t v3 = (void *)(v2 + 8);
  if ((*(unsigned char *)(v2 + 16) & 1) == 0) {
    uint64_t v3 = (void *)v2;
  }
  if (__OFADD__(1, *v3)) {
    BUG();
  }
  if (*v3 + 1 < 0) {
    BUG();
  }
  specialized Array.append<A>(contentsOf:)(*v3 + 1, 0);
  specialized Array.removeAll(keepingCapacity:)(keepingCapacity);
  type metadata accessor for ContiguousArray(0, *(void *)(v1 + 16));
  ContiguousArray.removeAll(keepingCapacity:)(keepingCapacity);
}

char *specialized Array.removeAll(keepingCapacity:)(char a1)
{
  uint64_t v3 = *v1;
  if (a1)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v3);
    uint64_t v5 = *v1;
    if (isUniquelyReferenced_nonNull_native) {
      return specialized Array.replaceSubrange<A>(_:with:)(0, *(void *)(v5 + 16));
    }
    unint64_t v7 = *(void *)(v5 + 24);
    if (v7 >= 2)
    {
      uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
      uint64_t v8 = (void *)swift_allocObject(v9, 4 * (v7 & 0xFFFFFFFFFFFFFFFELL) + 32, 7);
      long long v10 = (uint64_t)(_swift_stdlib_malloc_size(v8) - 32);
      v8[2] = 0;
      v8[3] = 2 * (v10 / 8);
    }
    else
    {
      uint64_t v8 = _swiftEmptyArrayStorage;
    }
    uint64_t *v1 = (uint64_t)v8;
    LOBYTE(v3) = v5;
  }
  else
  {
    uint64_t *v1 = (uint64_t)_swiftEmptyArrayStorage;
  }
  return (char *)swift_bridgeObjectRelease(v3);
}

void *specialized Array.removeAll(keepingCapacity:)(char a1)
{
  uint64_t v3 = *v1;
  if (a1)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v3);
    uint64_t v5 = *v1;
    if (isUniquelyReferenced_nonNull_native) {
      return specialized Array.replaceSubrange<A>(_:with:)(0, *(void *)(v5 + 16));
    }
    unint64_t v7 = *(void *)(v5 + 24);
    if (v7 >= 2)
    {
      uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int32>);
      uint64_t v8 = (void *)swift_allocObject(v9, 2 * (v7 & 0xFFFFFFFFFFFFFFFELL) + 32, 7);
      long long v10 = (uint64_t)(_swift_stdlib_malloc_size(v8) - 32);
      v8[2] = 0;
      v8[3] = 2 * (v10 / 4);
    }
    else
    {
      uint64_t v8 = _swiftEmptyArrayStorage;
    }
    uint64_t *v1 = (uint64_t)v8;
    LOBYTE(v3) = v5;
  }
  else
  {
    uint64_t *v1 = (uint64_t)_swiftEmptyArrayStorage;
  }
  return (void *)swift_bridgeObjectRelease(v3);
}

uint64_t specialized Array.append<A>(contentsOf:)(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = *v2;
  int64_t v5 = *((void *)*v2 + 2);
  int64_t v6 = a1 + v5;
  if (__OFADD__(a1, v5)) {
    BUG();
  }
  uint64_t v38 = a2;
  char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v4);
  uint64_t v8 = v4;
  if (!isUniquelyReferenced_nonNull_native || (int64_t v9 = *((void *)v4 + 3) >> 1, v9 < v6))
  {
    if (v5 > v6) {
      int64_t v6 = v5;
    }
    uint64_t v8 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(isUniquelyReferenced_nonNull_native, v6, 1, v4);
    int64_t v9 = *((void *)v8 + 3) >> 1;
  }
  uint64_t v10 = *((void *)v8 + 2);
  uint64_t v11 = v9 - v10;
  uint64_t v12 = v8;
  uint64_t result = specialized Sequence._copySequenceContents(initializing:)(&v32, (uint64_t *)&v8[8 * v10 + 32], v11, a1, v38);
  if (result < a1) {
    BUG();
  }
  uint64_t i = v12;
  if (result > 0)
  {
    uint64_t v15 = *((void *)v12 + 2);
    BOOL v16 = __OFADD__(result, v15);
    uint64_t v17 = result + v15;
    if (v16) {
      BUG();
    }
    *((void *)v12 + 2) = v17;
  }
  if (result == v11)
  {
    uint64_t v18 = v34;
    uint64_t result = v32;
    if (v34 != v32)
    {
      uint64_t v19 = *((void *)v12 + 2);
      uint64_t v38 = v32;
      uint64_t v36 = v33;
      uint64_t v20 = specialized Repeated.subscript.read(v31, v34, v32, v33);
      uint64_t v22 = *v21;
      ((void (*)(void *, void))v20)(v31, 0);
      uint64_t v23 = v38;
      if (v18 < 0 || v18 >= v38) {
        BUG();
      }
      uint64_t v24 = v18 + 1;
      for (uint64_t i = v12; ; *((void *)i + 2) = result)
      {
        uint64_t result = *((void *)i + 3);
        int64_t v25 = v19 + 1;
        int64_t v37 = (unint64_t)result >> 1;
        if ((uint64_t)((unint64_t)result >> 1) < v19 + 1)
        {
          uint64_t v30 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)((unint64_t)result >= 2, v25, 1, i);
          uint64_t v23 = v38;
          uint64_t i = v30;
          uint64_t result = *((void *)v30 + 3) >> 1;
          int64_t v37 = result;
        }
        if (v19 >= v37)
        {
          uint64_t result = v19;
        }
        else
        {
          *(void *)&i[8 * v19 + 32] = v22;
          uint64_t v26 = v24;
          uint64_t v35 = v24;
          if (v24 == v23)
          {
LABEL_32:
            *((void *)i + 2) = v25;
            break;
          }
          while (1)
          {
            uint64_t v27 = i;
            uint64_t v28 = specialized Repeated.subscript.read(v31, v26, v38, v36);
            uint64_t v22 = *v29;
            ((void (*)(void *, void))v28)(v31, 0);
            uint64_t v23 = v38;
            if (v35 < 0 || v26 >= v38) {
              BUG();
            }
            uint64_t result = v19 + 1;
            uint64_t i = v27;
            if (v19 + 1 >= v37) {
              break;
            }
            ++v26;
            *(void *)&v27[8 * v19++ + 40] = v22;
            if (v23 == v26)
            {
              int64_t v25 = v19 + 1;
              goto LABEL_32;
            }
          }
          uint64_t v24 = v26 + 1;
          ++v19;
        }
      }
    }
  }
  *uint64_t v2 = i;
  return result;
}

int64_t SparseMatrix.insert(index:major:minor:value:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v7 = *(void *)(a5 + 16);
  int64_t v8 = *(void *)(*(void *)(v7 - 8) + 64);
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  if (a3 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  if (*(void *)(*(void *)(v5 + 32) + 16) < a1) {
    BUG();
  }
  if (a1 < 0) {
    BUG();
  }
  uint64_t v21 = *(void *)(v7 - 8);
  uint64_t v19 = v7;
  uint64_t v20 = a4;
  specialized Array.replaceSubrange<A>(_:with:)(a1, a1, a3);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v21 + 16))(&v19, v20, v7);
  uint64_t v21 = v5 + 40;
  uint64_t v11 = type metadata accessor for ContiguousArray(0, v7);
  ContiguousArray.insert(_:at:)(&v19, a1, v11);
  int64_t result = a2 + 1;
  if (__OFADD__(1, a2)) {
    BUG();
  }
  uint64_t v13 = *(char **)(v5 + 24);
  uint64_t v14 = *((void *)v13 + 2);
  if (v14 < result) {
    BUG();
  }
  if (result != v14)
  {
    if (result >= v14) {
      BUG();
    }
    if (!swift_isUniquelyReferenced_nonNull_native(*(void *)(v5 + 24))) {
      uint64_t v13 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v13);
    }
    uint64_t v15 = v14 - 1;
    int64_t result = a2;
    do
    {
      if (++result < 0) {
        BUG();
      }
      if ((unint64_t)result >= *((void *)v13 + 2)) {
        BUG();
      }
      uint64_t v16 = *(void *)&v13[8 * a2 + 40];
      BOOL v17 = __OFADD__(1, v16);
      uint64_t v18 = v16 + 1;
      if (v17) {
        BUG();
      }
      *(void *)&v13[8 * a2 + 40] = v18;
      a2 = result;
    }
    while (v15 != result);
    *(void *)(v5 + 24) = v13;
  }
  return result;
}

Swift::Void __swiftcall SparseMatrix.remove(index:major:)(Swift::Int index, Swift::Int major)
{
  Swift::Int v4 = major;
  Swift::Int v20 = index;
  uint64_t v5 = *(void *)(v2 + 16);
  uint64_t v19 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v19 + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  specialized Array.remove(at:)(index);
  uint64_t v9 = type metadata accessor for ContiguousArray(0, v5);
  ContiguousArray.remove(at:)(v20, v9);
  (*(void (**)(uint64_t *, uint64_t))(v19 + 8))(&v18, v5);
  Swift::Int v10 = major + 1;
  if (__OFADD__(1, major)) {
    BUG();
  }
  uint64_t v11 = *(char **)(v3 + 24);
  Swift::Int v12 = *((void *)v11 + 2);
  if (v12 < v10) {
    BUG();
  }
  if (v10 != v12)
  {
    if (v10 >= v12) {
      BUG();
    }
    if (!swift_isUniquelyReferenced_nonNull_native(*(void *)(v3 + 24))) {
      uint64_t v11 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v11);
    }
    Swift::Int v13 = v12 - 1;
    unint64_t v14 = major;
    do
    {
      if ((++v14 & 0x8000000000000000) != 0) {
        BUG();
      }
      if (v14 >= *((void *)v11 + 2)) {
        BUG();
      }
      uint64_t v15 = *(void *)&v11[8 * v4 + 40];
      BOOL v16 = __OFSUB__(v15, 1);
      uint64_t v17 = v15 - 1;
      if (v16) {
        BUG();
      }
      *(void *)&v11[8 * v4 + 40] = v17;
      Swift::Int v4 = v14;
    }
    while (v13 != v14);
    *(void *)(v3 + 24) = v11;
  }
}

void (*SparseMatrix.subscript.modify(void *a1, uint64_t a2, uint64_t a3, uint64_t a4))(Swift::Int **a1, char a2)
{
  uint64_t v7 = malloc(0x70uLL);
  *a1 = v7;
  v7[9] = v4;
  v7[8] = a4;
  v7[7] = a3;
  v7[6] = a2;
  uint64_t v8 = *(void *)(a4 + 16);
  v7[10] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v7[11] = v9;
  size_t v10 = *(void *)(v9 + 64);
  v7[12] = malloc(v10);
  v7[13] = malloc(v10);
  long long v11 = v4[1];
  long long v12 = v4[2];
  *(_OWORD *)uint64_t v7 = *v4;
  *((_OWORD *)v7 + 1) = v11;
  *((_OWORD *)v7 + 2) = v12;
  SparseMatrix.subscript.getter(a2, a3, a4);
  return SparseMatrix.subscript.modify;
}

void SparseMatrix.subscript.modify(Swift::Int **a1, char a2)
{
  uint64_t v2 = *a1;
  uint64_t v3 = (void *)(*a1)[12];
  Swift::Int v4 = (void *)(*a1)[13];
  if (a2)
  {
    Swift::Int v8 = v2[11];
    Swift::Int v5 = v2[10];
    uint64_t v7 = v2[8];
    Swift::Int v6 = v2[6];
    uint64_t v9 = v2[7];
    (*(void (**)(void *, void *, Swift::Int))(v8 + 16))(v3, v4, v5);
    SparseMatrix.subscript.setter((uint64_t)v3, v6, v9, v7);
    (*(void (**)(void *, Swift::Int))(v8 + 8))(v4, v5);
  }
  else
  {
    SparseMatrix.subscript.setter((*a1)[13], v2[6], v2[7], v2[8]);
  }
  free(v4);
  free(v3);
  free(v2);
}

uint64_t specialized Array.remove(at:)(unint64_t a1)
{
  uint64_t v2 = (void *)*v1;
  if (!swift_isUniquelyReferenced_nonNull_native(*v1)) {
    uint64_t v2 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v2);
  }
  unint64_t v3 = v2[2];
  if (v3 <= a1) {
    BUG();
  }
  unint64_t v4 = v3 - 1;
  unsigned int v5 = *((_DWORD *)v2 + a1 + 8);
  specialized UnsafeMutablePointer.moveInitialize(from:count:)((char *)v2 + 4 * a1 + 36, v4 - a1, (char *)v2 + 4 * a1 + 32);
  v2[2] = v4;
  void *v1 = v2;
  return v5;
}

void *SparseMatrix.transposed()()
{
  uint64_t v2 = v0;
  SparseMatrix.Transpose.init(base:)((uint64_t)v1);
  uint64_t v7 = v1[3];
  uint64_t v8 = v1[4];
  v9[0] = v1[5];
  outlined retain of [Int](&v7);
  outlined retain of [Int](&v8);
  int64_t result = outlined retain of ContiguousArray<Double>(v9);
  *uint64_t v2 = v4;
  v2[1] = v5;
  v2[2] = v6;
  return result;
}

uint64_t protocol witness for Matrix.init(rowCount:columnCount:) in conformance SparseMatrix<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  long long v4 = v3;
  uint64_t result = SparseMatrix.init(rowCount:columnCount:)(a1, a2, *(void *)(a3 + 16));
  v4[2] = v8;
  v4[1] = v7;
  *long long v4 = v6;
  return result;
}

void *protocol witness for Matrix.transposed() in conformance SparseMatrix<A>()
{
  uint64_t v1 = v0;
  uint64_t result = SparseMatrix.transposed()();
  v1[2] = v5;
  v1[1] = v4;
  _OWORD *v1 = v3;
  return result;
}

uint64_t protocol witness for Matrix.subscript.getter in conformance SparseMatrix<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return SparseMatrix.subscript.getter(a1, a2, a3);
}

uint64_t protocol witness for Matrix.subscript.setter in conformance SparseMatrix<A>(uint64_t a1, Swift::Int a2, uint64_t a3, uint64_t a4)
{
  return SparseMatrix.subscript.setter(a1, a2, a3, a4);
}

void (*protocol witness for Matrix.subscript.modify in conformance SparseMatrix<A>(void *a1, uint64_t a2, uint64_t a3, uint64_t a4))(Swift::Int **a1, char a2)
{
  long long v7 = malloc(0x70uLL);
  *a1 = v7;
  v7[9] = a4;
  v7[8] = v4;
  v7[7] = a3;
  v7[6] = a2;
  uint64_t v8 = *(void *)(a4 + 16);
  v7[10] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v7[11] = v9;
  size_t v10 = *(void *)(v9 + 64);
  v7[12] = malloc(v10);
  v7[13] = malloc(v10);
  long long v11 = v4[1];
  long long v12 = v4[2];
  *(_OWORD *)long long v7 = *v4;
  *((_OWORD *)v7 + 1) = v11;
  *((_OWORD *)v7 + 2) = v12;
  SparseMatrix.subscript.getter(a2, a3, a4);
  return protocol witness for Matrix.subscript.modify in conformance SparseMatrix<A>;
}

void protocol witness for Matrix.subscript.modify in conformance SparseMatrix<A>(Swift::Int **a1, char a2)
{
  uint64_t v2 = *a1;
  long long v3 = (void *)(*a1)[12];
  long long v4 = (void *)(*a1)[13];
  if (a2)
  {
    Swift::Int v8 = v2[11];
    Swift::Int v5 = v2[10];
    uint64_t v7 = v2[9];
    Swift::Int v6 = v2[6];
    uint64_t v9 = v2[7];
    (*(void (**)(void *, void *, Swift::Int))(v8 + 16))(v3, v4, v5);
    SparseMatrix.subscript.setter((uint64_t)v3, v6, v9, v7);
    (*(void (**)(void *, Swift::Int))(v8 + 8))(v4, v5);
  }
  else
  {
    SparseMatrix.subscript.setter((*a1)[13], v2[6], v2[7], v2[9]);
  }
  free(v4);
  free(v3);
  free(v2);
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance SparseMatrix<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return static SparseMatrix.__derived_struct_equals(_:_:)(a1, a2, *(void *)(a3 + 16), *(void *)(a3 + 24));
}

char **specialized Array.replaceSubrange<A>(_:with:)(uint64_t a1, int64_t a2, int a3)
{
  if (a1 < 0) {
    BUG();
  }
  long long v4 = *v3;
  int64_t v5 = *((void *)*v3 + 2);
  if (v5 < a2) {
    BUG();
  }
  int64_t v6 = a2 - a1;
  if (__OFSUB__(a2, a1)) {
    BUG();
  }
  uint64_t v7 = 1 - v6;
  if (__OFSUB__(1, v6)) {
    BUG();
  }
  int64_t v8 = v7 + v5;
  if (__OFADD__(v7, v5)) {
    BUG();
  }
  char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v4);
  if (!isUniquelyReferenced_nonNull_native || *((void *)v4 + 3) >> 1 < v8)
  {
    if (v5 > v8) {
      int64_t v8 = v5;
    }
    long long v4 = (char *)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(isUniquelyReferenced_nonNull_native, v8, 1, (uint64_t)v4);
  }
  if (v7)
  {
    uint64_t v10 = *((void *)v4 + 2);
    BOOL v11 = __OFSUB__(v10, a2);
    uint64_t v12 = v10 - a2;
    if (v11) {
      BUG();
    }
    specialized UnsafeMutablePointer.moveInitialize(from:count:)(&v4[4 * a2 + 32], v12, &v4[4 * a1 + 36]);
    BOOL v11 = __OFADD__(*((void *)v4 + 2), v7);
    uint64_t v13 = *((void *)v4 + 2) + v7;
    if (v11) {
      BUG();
    }
    *((void *)v4 + 2) = v13;
  }
  *(_DWORD *)&v4[4 * a1 + 32] = a3;
  uint64_t result = v3;
  void *v3 = v4;
  return result;
}

void *specialized Array.replaceSubrange<A>(_:with:)(uint64_t a1, uint64_t a2)
{
  if (a1 < 0) {
    BUG();
  }
  long long v3 = *v2;
  int64_t v4 = *((void *)*v2 + 2);
  if (v4 < a2) {
    BUG();
  }
  if (__OFSUB__(a2, a1)) {
    BUG();
  }
  uint64_t v5 = a1 - a2;
  if (__OFSUB__(a1 - a2, 1)) {
    BUG();
  }
  int64_t v6 = v5 + v4;
  if (__OFADD__(v5, v4)) {
    BUG();
  }
  char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v3);
  if (!isUniquelyReferenced_nonNull_native || *((void *)v3 + 3) >> 1 < v6)
  {
    if (v4 > v6) {
      int64_t v6 = v4;
    }
    long long v3 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(isUniquelyReferenced_nonNull_native, v6, 1, (uint64_t)v3);
  }
  uint64_t result = (void *)a2;
  if (v5)
  {
    uint64_t v9 = *((void *)v3 + 2);
    BOOL v10 = __OFSUB__(v9, a2);
    uint64_t v11 = v9 - a2;
    if (v10) {
      BUG();
    }
    uint64_t result = specialized UnsafeMutablePointer.moveInitialize(from:count:)(&v3[4 * a2 + 32], v11, &v3[4 * a1 + 32]);
    BOOL v10 = __OFADD__(*((void *)v3 + 2), v5);
    uint64_t v12 = *((void *)v3 + 2) + v5;
    if (v10) {
      BUG();
    }
    *((void *)v3 + 2) = v12;
  }
  *uint64_t v2 = v3;
  return result;
}

char *specialized Array.replaceSubrange<A>(_:with:)(uint64_t a1, int64_t a2)
{
  if (a1 < 0) {
    BUG();
  }
  long long v3 = *v2;
  int64_t v4 = *((void *)*v2 + 2);
  if (v4 < a2) {
    BUG();
  }
  if (__OFSUB__(a2, a1)) {
    BUG();
  }
  uint64_t v5 = a1 - a2;
  if (__OFSUB__(a1 - a2, 1)) {
    BUG();
  }
  uint64_t v15 = v2;
  int64_t v6 = v5 + v4;
  if (__OFADD__(v5, v4)) {
    BUG();
  }
  uint64_t result = (char *)swift_isUniquelyReferenced_nonNull_native(v3);
  if (!(_BYTE)result || *((void *)v3 + 3) >> 1 < v6)
  {
    if (v4 > v6) {
      int64_t v6 = v4;
    }
    uint64_t result = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)((char)result, v6, 1, v3);
    long long v3 = result;
  }
  if (v5)
  {
    uint64_t v9 = *((void *)v3 + 2);
    uint64_t v10 = v9 - a2;
    if (__OFSUB__(v9, a2)) {
      BUG();
    }
    uint64_t v11 = &v3[8 * a2 + 32];
    uint64_t v12 = &v3[8 * a1 + 32];
    if (a1 != a2 || &v11[8 * v10] <= v12)
    {
      memmove(v12, v11, 8 * v10);
      uint64_t v9 = *((void *)v3 + 2);
    }
    BOOL v13 = __OFADD__(v5, v9);
    uint64_t result = (char *)(v5 + v9);
    if (v13) {
      BUG();
    }
    *((void *)v3 + 2) = result;
  }
  uint64_t *v15 = v3;
  return result;
}

uint64_t associated type witness table accessor for Matrix.Transpose : Matrix in SparseMatrix<A>(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for SparseMatrix<A>.Transpose, a1);
}

uint64_t type metadata accessor for SparseMatrix(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for SparseMatrix);
}

void (*specialized Repeated.subscript.read(void *a1, uint64_t a2, uint64_t a3, uint64_t a4))()
{
  if (a2 < 0 || a2 >= a3) {
    BUG();
  }
  *a1 = a4;
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UnsafeMutableVectorPointer<A>.add(_:scaledBy:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  if (a5 != a2)
  {
    _StringGuts.grow(_:)(75);
    v7._char object = "each row, plus and end index." + 0x8000000000000000;
    v7._uint64_t countAndFlagsBits = 0xD000000000000041;
    String.append(_:)(v7);
    uint64_t v8 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    uint64_t v10 = v9;
    v7._uint64_t countAndFlagsBits = v8;
    v7._char object = v9;
    String.append(_:)(v7);
    swift_bridgeObjectRelease(v10);
    v7._uint64_t countAndFlagsBits = 0x20646E6120;
    v7._char object = (void *)0xE500000000000000;
    String.append(_:)(v7);
    uint64_t v11 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    BOOL v13 = v12;
    v7._uint64_t countAndFlagsBits = v11;
    v7._char object = v12;
    String.append(_:)(v7);
    swift_bridgeObjectRelease(v13);
    v7._uint64_t countAndFlagsBits = 46;
    v7._char object = (void *)0xE100000000000000;
    String.append(_:)(v7);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0, 0xE000000000000000, "LinearAlgebra/UnsafeVectorOperations.swift", 42, 2, 122, 0);
    BUG();
  }
  if (a5 > 0x7FFFFFFF) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  if (a3 < (uint64_t)0xFFFFFFFF80000000 || a5 < (uint64_t)0xFFFFFFFF80000000 || a6 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a6 > 0x7FFFFFFF) {
    BUG();
  }
  return cblas_saxpy_NEWLAPACK(a5, a1, a3, a4, a6);
}

{
  Swift::String v7;
  uint64_t v8;
  void *v9;
  void *v10;
  uint64_t v11;
  void *v12;
  void *v13;

  if (a5 != a2)
  {
    _StringGuts.grow(_:)(75);
    v7._char object = "each row, plus and end index." + 0x8000000000000000;
    v7._uint64_t countAndFlagsBits = 0xD000000000000041;
    String.append(_:)(v7);
    uint64_t v8 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    uint64_t v10 = v9;
    v7._uint64_t countAndFlagsBits = v8;
    v7._char object = v9;
    String.append(_:)(v7);
    swift_bridgeObjectRelease(v10);
    v7._uint64_t countAndFlagsBits = 0x20646E6120;
    v7._char object = (void *)0xE500000000000000;
    String.append(_:)(v7);
    uint64_t v11 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    BOOL v13 = v12;
    v7._uint64_t countAndFlagsBits = v11;
    v7._char object = v12;
    String.append(_:)(v7);
    swift_bridgeObjectRelease(v13);
    v7._uint64_t countAndFlagsBits = 46;
    v7._char object = (void *)0xE100000000000000;
    String.append(_:)(v7);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0, 0xE000000000000000, "LinearAlgebra/UnsafeVectorOperations.swift", 42, 2, 179, 0);
    BUG();
  }
  if (a5 > 0x7FFFFFFF) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  if (a3 < (uint64_t)0xFFFFFFFF80000000 || a5 < (uint64_t)0xFFFFFFFF80000000 || a6 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a6 > 0x7FFFFFFF) {
    BUG();
  }
  return cblas_daxpy_NEWLAPACK(a5, a1, a3, a4, a6);
}

uint64_t UnsafeMutableVectorPointer<A>.multiply(by:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a2 > 0x7FFFFFFF) {
    BUG();
  }
  if (a2 < (uint64_t)0xFFFFFFFF80000000 || a3 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  return cblas_sscal_NEWLAPACK(a2, a1);
}

{
  if (a2 > 0x7FFFFFFF) {
    BUG();
  }
  if (a2 < (uint64_t)0xFFFFFFFF80000000 || a3 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  return cblas_dscal_NEWLAPACK(a2, a1);
}

BOOL UnsafeVectorPointer<A>.squaredMagnitude.getter(uint64_t a1, int64_t a2, int64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v37 = v5;
  int64_t v43 = a2;
  uint64_t v38 = a1;
  char v39 = *(void **)(a4 - 8);
  int64_t v8 = v39[8];
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  Swift::Int v42 = &v33;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v40 = &v33;
  BOOL v13 = alloca(v8);
  unint64_t v14 = alloca(v8);
  uint64_t v41 = &v33;
  uint64_t v33 = *(void *)(*(void *)(a5 + 16) + 8);
  uint64_t v15 = *(void *)(v33 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v15, a4, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v17 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v15, a4, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, AssociatedConformanceWitness);
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(&v33, a4, v15);
  int64_t v21 = a3 * v43;
  if (!is_mul_ok(a3, v43)) {
    BUG();
  }
  if (!a3) {
    BUG();
  }
  BOOL result = v21 >= 0;
  if (a3 > 0) {
    BOOL result = v21 <= 0;
  }
  uint64_t v23 = v38;
  uint64_t v24 = v42;
  if (!result)
  {
    uint64_t v35 = (void (*)(uint64_t *, uint64_t, uint64_t))v39[2];
    uint64_t v36 = v39[9];
    uint64_t v25 = 0;
    v43 *= a3;
    uint64_t v34 = a3;
    do
    {
      unint64_t v26 = ((v25 + a3) >> 63) ^ 0x8000000000000000;
      uint64_t v27 = v25 * v36;
      BOOL v28 = __OFADD__(a3, v25);
      v25 += a3;
      if (v28) {
        uint64_t v25 = v26;
      }
      uint64_t v29 = v23 + v27;
      uint64_t v30 = v35;
      v35(v40, v29, a4);
      v30(v24, v29, a4);
      uint64_t v31 = v33;
      dispatch thunk of static Numeric.* infix(_:_:)(v40, v24, a4, v33);
      uint64_t v32 = (void (*)(uint64_t *, uint64_t))v39[1];
      v32(v42, a4);
      v32(v40, a4);
      dispatch thunk of static AdditiveArithmetic.+= infix(_:_:)(v37, v41, a4, *(void *)(v31 + 8));
      v32(v41, a4);
      a3 = v34;
      uint64_t v24 = v42;
      BOOL result = v43 >= v25;
      if (v34 > 0) {
        BOOL result = v43 <= v25;
      }
      uint64_t v23 = v38;
    }
    while (!result);
  }
  return result;
}

uint64_t UnsafeVectorPointer<A>.magnitude.getter(uint64_t a1, int64_t a2, int64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = v5;
  uint64_t v8 = *(void *)(a4 - 8);
  int64_t v9 = *(void *)(v8 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  UnsafeVectorPointer<A>.squaredMagnitude.getter(a1, a2, a3, a4, a5);
  dispatch thunk of FloatingPoint.squareRoot()(a4, a5);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v8 + 8))(&v13, a4);
}

uint64_t UnsafeVectorPointer<A>.maximumAbsoluteValue.getter(uint64_t a1, uint64_t a2, int64_t a3, uint64_t a4, uint64_t a5)
{
  int64_t v41 = a3;
  uint64_t v43 = v5;
  uint64_t v34 = a1;
  uint64_t v35 = *(void *)(*(void *)(a5 + 16) + 8);
  unint64_t v45 = *(void (**)(void, void))(v35 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v45, a4, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v9 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v12 = *(void *)(a4 - 8);
  int64_t v13 = *(void *)(v12 + 64);
  unint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v36 = &v34;
  BOOL v16 = alloca(v13);
  int64_t v17 = alloca(v13);
  uint64_t v18 = alloca(v13);
  uint64_t v19 = alloca(v13);
  int64_t v44 = a2;
  if (a2 <= 0) {
    return dispatch thunk of static FloatingPoint.nan.getter(a4, a5);
  }
  uint64_t v37 = a5;
  uint64_t v38 = &v34;
  uint64_t v46 = v12;
  Swift::Int v20 = v45;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v45, a4, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, AssociatedConformanceWitness);
  Swift::Int v42 = &v34;
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(&v34, a4, v20);
  int64_t v22 = v41;
  int64_t v23 = v41 * v44;
  if (!is_mul_ok(v41, v44)) {
    BUG();
  }
  if (!v41) {
    BUG();
  }
  v44 *= v41;
  BOOL v24 = v23 >= 0;
  if (v41 > 0) {
    BOOL v24 = v23 <= 0;
  }
  if (!v24)
  {
    char v39 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v46 + 16);
    uint64_t v40 = *(void *)(v46 + 72);
    uint64_t v25 = 0;
    unint64_t v26 = v38;
    do
    {
      unint64_t v27 = ((v25 + v22) >> 63) ^ 0x8000000000000000;
      uint64_t v28 = v25 * v40;
      BOOL v29 = __OFADD__(v22, v25);
      v25 += v22;
      if (v29) {
        uint64_t v25 = v27;
      }
      uint64_t v30 = v36;
      v39(v36, v34 + v28, a4);
      dispatch thunk of Numeric.magnitude.getter(a4, v35);
      unint64_t v45 = *(void (**)(void, void))(v46 + 8);
      v45(v30, a4);
      uint64_t v31 = v42;
      if (dispatch thunk of static Comparable.> infix(_:_:)(v26, v42, a4, *(void *)(*(void *)(v37 + 24) + 8)))
      {
        v45(v31, a4);
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v46 + 32))(v31, v26, a4);
      }
      else
      {
        v45(v26, a4);
      }
      BOOL v32 = v44 >= v25;
      int64_t v22 = v41;
      if (v41 > 0) {
        BOOL v32 = v44 <= v25;
      }
    }
    while (!v32);
  }
  return (*(uint64_t (**)(uint64_t, uint64_t *, uint64_t))(v46 + 32))(v43, v42, a4);
}

BOOL UnsafeMutableVectorPointer<A>.add(_:scaledBy:)(uint64_t a1, unint64_t a2, int64_t a3, uint64_t a4, uint64_t a5, unint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  uint64_t v43 = a5;
  uint64_t v44 = a4;
  uint64_t v45 = a1;
  uint64_t v46 = *(void *)(a8 - 8);
  int64_t v10 = *(void *)(v46 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v47 = &v37;
  int64_t v13 = alloca(v10);
  unint64_t v14 = alloca(v10);
  uint64_t v50 = &v37;
  if (a6 != a2)
  {
    uint64_t v37 = 0;
    unint64_t v38 = 0xE000000000000000;
    _StringGuts.grow(_:)(75);
    v30._char object = "each row, plus and end index." + 0x8000000000000000;
    v30._uint64_t countAndFlagsBits = 0xD000000000000041;
    String.append(_:)(v30);
    unint64_t v39 = a6;
    uint64_t v31 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    uint64_t v33 = v32;
    v30._uint64_t countAndFlagsBits = v31;
    v30._char object = v32;
    String.append(_:)(v30);
    swift_bridgeObjectRelease(v33);
    v30._uint64_t countAndFlagsBits = 0x20646E6120;
    v30._char object = (void *)0xE500000000000000;
    String.append(_:)(v30);
    unint64_t v39 = a2;
    uint64_t v34 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    uint64_t v36 = v35;
    v30._uint64_t countAndFlagsBits = v34;
    v30._char object = v35;
    String.append(_:)(v30);
    swift_bridgeObjectRelease(v36);
    v30._uint64_t countAndFlagsBits = 46;
    v30._char object = (void *)0xE100000000000000;
    String.append(_:)(v30);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v37, v38, "LinearAlgebra/UnsafeVectorOperations.swift", 42, 2, 53, 0);
    BUG();
  }
  uint64_t v15 = a7;
  uint64_t v51 = a7 * a6;
  if (!is_mul_ok(a7, a6)) {
    BUG();
  }
  int64_t v16 = a3 * a6;
  if (!is_mul_ok(a3, a6)) {
    BUG();
  }
  if (!a3 || !a7) {
    BUG();
  }
  BOOL result = v51 >= 0;
  if (a7 > 0) {
    BOOL result = v51 <= 0;
  }
  if (!result)
  {
    int64_t v18 = 0;
    int64_t v19 = 0;
    unint64_t v48 = a3 * a6;
    int64_t v49 = a3;
    do
    {
      BOOL result = v16 >= v18;
      if (a3 > 0) {
        BOOL result = v16 <= v18;
      }
      if (result) {
        break;
      }
      unint64_t v20 = a3 + v18;
      if (__OFADD__(a3, v18)) {
        unint64_t v20 = ((v18 + a3) >> 63) ^ 0x8000000000000000;
      }
      unint64_t v40 = v20;
      unint64_t v21 = ((v19 + v15) >> 63) ^ 0x8000000000000000;
      int64_t v41 = v19;
      BOOL v22 = __OFADD__(v15, v19);
      v19 += v15;
      if (v22) {
        int64_t v19 = v21;
      }
      uint64_t v23 = v46;
      uint64_t v24 = *(void *)(v46 + 72);
      uint64_t v25 = v47;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v46 + 16))(v47, v45 + v24 * v18, a8);
      uint64_t v42 = *(void *)(*(void *)(*(void *)(a9 + 16) + 16) + 8);
      dispatch thunk of static Numeric.* infix(_:_:)(v25, v44, a8, v42);
      unint64_t v26 = *(void (**)(uint64_t *, uint64_t))(v23 + 8);
      v26(v25, a8);
      uint64_t v27 = v43 + v41 * v24;
      int64_t v16 = v48;
      uint64_t v28 = v50;
      dispatch thunk of static AdditiveArithmetic.+= infix(_:_:)(v27, v50, a8, *(void *)(v42 + 8));
      v26(v28, a8);
      uint64_t v15 = a7;
      a3 = v49;
      BOOL result = v51 >= v19;
      if (a7 > 0) {
        BOOL result = v51 <= v19;
      }
      int64_t v18 = v40;
    }
    while (!result);
  }
  return result;
}

BOOL UnsafeMutableVectorPointer<A>.multiply(by:)(uint64_t a1, uint64_t a2, unint64_t a3, int64_t a4, uint64_t a5, uint64_t a6)
{
  int64_t v6 = a4 * a3;
  if (!is_mul_ok(a4, a3)) {
    BUG();
  }
  if (!a4) {
    BUG();
  }
  BOOL result = v6 >= 0;
  if (a4 > 0) {
    BOOL result = v6 <= 0;
  }
  if (!result)
  {
    uint64_t v16 = *(void *)(*(void *)(a5 - 8) + 72);
    uint64_t v17 = *(void *)(*(void *)(*(void *)(a6 + 16) + 16) + 8);
    int64_t v11 = 0;
    uint64_t v15 = a2;
    do
    {
      unint64_t v12 = ((v11 + a4) >> 63) ^ 0x8000000000000000;
      int64_t v13 = v11 * v16;
      BOOL v14 = __OFADD__(a4, v11);
      v11 += a4;
      if (v14) {
        int64_t v11 = v12;
      }
      dispatch thunk of static Numeric.*= infix(_:_:)(a2 + v13, a1, a5, v17);
      a2 = v15;
      BOOL result = v6 >= v11;
      if (a4 > 0) {
        BOOL result = v6 <= v11;
      }
    }
    while (!result);
  }
  return result;
}

BOOL dot<A>(_:_:)(uint64_t a1, unint64_t a2, int64_t a3, uint64_t a4, int64_t a5, unint64_t a6, uint64_t a7, uint64_t a8)
{
  uint64_t v47 = a4;
  uint64_t v55 = v8;
  unint64_t v59 = a6;
  uint64_t v48 = a1;
  char v54 = *(void **)(a7 - 8);
  int64_t v12 = v54[8];
  int64_t v13 = alloca(v12);
  BOOL v14 = alloca(v12);
  int64_t v49 = &v44;
  uint64_t v15 = alloca(v12);
  uint64_t v16 = alloca(v12);
  uint64_t v57 = &v44;
  uint64_t v17 = alloca(v12);
  int64_t v18 = alloca(v12);
  uint64_t v50 = &v44;
  uint64_t v51 = *(void *)(*(void *)(a8 + 16) + 8);
  unint64_t v60 = *(void *)(v51 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v60, a7, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v20 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  unint64_t v21 = alloca(v20);
  BOOL v22 = alloca(v20);
  int64_t v58 = a5;
  if (a2 != a5)
  {
    uint64_t v44 = 0;
    unint64_t v45 = 0xE000000000000000;
    _StringGuts.grow(_:)(90);
    v37._char object = "safeVectorOperations.swift" + 0x8000000000000000;
    v37._uint64_t countAndFlagsBits = 0xD000000000000050;
    String.append(_:)(v37);
    unint64_t v46 = a2;
    uint64_t v38 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    unint64_t v40 = v39;
    v37._uint64_t countAndFlagsBits = v38;
    v37._char object = v39;
    String.append(_:)(v37);
    swift_bridgeObjectRelease(v40);
    v37._uint64_t countAndFlagsBits = 0x20646E6120;
    v37._char object = (void *)0xE500000000000000;
    String.append(_:)(v37);
    unint64_t v46 = v58;
    uint64_t v41 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    uint64_t v43 = v42;
    v37._uint64_t countAndFlagsBits = v41;
    v37._char object = v42;
    String.append(_:)(v37);
    swift_bridgeObjectRelease(v43);
    v37._uint64_t countAndFlagsBits = 46;
    v37._char object = (void *)0xE100000000000000;
    String.append(_:)(v37);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v44, v45, "LinearAlgebra/UnsafeVectorOperations.swift", 42, 2, 78, 0);
    BUG();
  }
  int64_t v56 = a3 * a2;
  if (!is_mul_ok(a3, a2)) {
    BUG();
  }
  int64_t v23 = v59 * a2;
  if (!is_mul_ok(v59, a2)) {
    BUG();
  }
  if (!a3 || !v59) {
    BUG();
  }
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v60, a7, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, AssociatedConformanceWitness);
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(&v44, a7, v60);
  uint64_t v25 = v59;
  BOOL result = v56 >= 0;
  if (a3 > 0) {
    BOOL result = v56 <= 0;
  }
  if (!result)
  {
    int64_t v27 = 0;
    uint64_t v28 = 0;
    int64_t v52 = v23;
    uint64_t v53 = a3;
    do
    {
      BOOL result = v23 >= v27;
      if (v25 > 0) {
        BOOL result = v23 <= v27;
      }
      if (result) {
        break;
      }
      unint64_t v29 = v25 + v27;
      if (__OFADD__(v25, v27)) {
        unint64_t v29 = ((v27 + v25) >> 63) ^ 0x8000000000000000;
      }
      unint64_t v60 = v29;
      unint64_t v30 = a3 + v28;
      if (__OFADD__(a3, v28)) {
        unint64_t v30 = ((v28 + a3) >> 63) ^ 0x8000000000000000;
      }
      int64_t v58 = v30;
      uint64_t v31 = (void (*)(uint64_t *, uint64_t, uint64_t))v54[2];
      uint64_t v32 = v54[9];
      v31(v57, v48 + v32 * v28, a7);
      uint64_t v33 = v49;
      v31(v49, v47 + v27 * v32, a7);
      uint64_t v34 = v50;
      uint64_t v35 = v51;
      dispatch thunk of static Numeric.* infix(_:_:)(v57, v33, a7, v51);
      uint64_t v36 = (void (*)(uint64_t *, uint64_t))v54[1];
      v36(v33, a7);
      v36(v57, a7);
      dispatch thunk of static AdditiveArithmetic.+= infix(_:_:)(v55, v34, a7, *(void *)(v35 + 8));
      v36(v34, a7);
      uint64_t v25 = v59;
      uint64_t v28 = v58;
      BOOL result = v56 >= v58;
      a3 = v53;
      if (v53 > 0) {
        BOOL result = v56 <= v58;
      }
      int64_t v27 = v60;
      int64_t v23 = v52;
    }
    while (!result);
  }
  return result;
}

uint64_t UnsafeVectorPointer<A>.magnitude.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a2 > 0x7FFFFFFF) {
    BUG();
  }
  if (a2 < (uint64_t)0xFFFFFFFF80000000 || a3 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  return cblas_snrm2_NEWLAPACK(a2, a1);
}

{
  if (a2 > 0x7FFFFFFF) {
    BUG();
  }
  if (a2 < (uint64_t)0xFFFFFFFF80000000 || a3 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  return cblas_dnrm2_NEWLAPACK(a2, a1);
}

float UnsafeVectorPointer<A>.maximumAbsoluteValue.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a2 <= 0) {
    return NAN;
  }
  if ((unint64_t)a2 > 0x7FFFFFFF) {
    BUG();
  }
  if (a3 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  return fabs(*(float *)(a1 + 4 * a3 * (int)cblas_isamax_NEWLAPACK(a2, a1, a3)));
}

uint64_t dot(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  if (a2 != a5)
  {
    _StringGuts.grow(_:)(90);
    v7._char object = "safeVectorOperations.swift" + 0x8000000000000000;
    v7._uint64_t countAndFlagsBits = 0xD000000000000050;
    String.append(_:)(v7);
    uint64_t v8 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    int64_t v10 = v9;
    v7._uint64_t countAndFlagsBits = v8;
    v7._char object = v9;
    String.append(_:)(v7);
    swift_bridgeObjectRelease(v10);
    v7._uint64_t countAndFlagsBits = 0x20646E6120;
    v7._char object = (void *)0xE500000000000000;
    String.append(_:)(v7);
    uint64_t v11 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    int64_t v13 = v12;
    v7._uint64_t countAndFlagsBits = v11;
    v7._char object = v12;
    String.append(_:)(v7);
    swift_bridgeObjectRelease(v13);
    v7._uint64_t countAndFlagsBits = 46;
    v7._char object = (void *)0xE100000000000000;
    String.append(_:)(v7);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0, 0xE000000000000000, "LinearAlgebra/UnsafeVectorOperations.swift", 42, 2, 141, 0);
    BUG();
  }
  if (a2 > 0x7FFFFFFF) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  if (a2 < (uint64_t)0xFFFFFFFF80000000 || a3 < (uint64_t)0xFFFFFFFF80000000 || a6 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a6 > 0x7FFFFFFF) {
    BUG();
  }
  return cblas_sdot_NEWLAPACK(a2, a1, a3, a4, a6);
}

{
  Swift::String v7;
  uint64_t v8;
  void *v9;
  void *v10;
  uint64_t v11;
  void *v12;
  void *v13;

  if (a2 != a5)
  {
    _StringGuts.grow(_:)(90);
    v7._char object = "safeVectorOperations.swift" + 0x8000000000000000;
    v7._uint64_t countAndFlagsBits = 0xD000000000000050;
    String.append(_:)(v7);
    uint64_t v8 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    int64_t v10 = v9;
    v7._uint64_t countAndFlagsBits = v8;
    v7._char object = v9;
    String.append(_:)(v7);
    swift_bridgeObjectRelease(v10);
    v7._uint64_t countAndFlagsBits = 0x20646E6120;
    v7._char object = (void *)0xE500000000000000;
    String.append(_:)(v7);
    uint64_t v11 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    int64_t v13 = v12;
    v7._uint64_t countAndFlagsBits = v11;
    v7._char object = v12;
    String.append(_:)(v7);
    swift_bridgeObjectRelease(v13);
    v7._uint64_t countAndFlagsBits = 46;
    v7._char object = (void *)0xE100000000000000;
    String.append(_:)(v7);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0, 0xE000000000000000, "LinearAlgebra/UnsafeVectorOperations.swift", 42, 2, 198, 0);
    BUG();
  }
  if (a2 > 0x7FFFFFFF) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  if (a2 < (uint64_t)0xFFFFFFFF80000000 || a3 < (uint64_t)0xFFFFFFFF80000000 || a6 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a6 > 0x7FFFFFFF) {
    BUG();
  }
  return cblas_ddot_NEWLAPACK(a2, a1, a3, a4, a6);
}

double UnsafeVectorPointer<A>.maximumAbsoluteValue.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a2 <= 0) {
    return NAN;
  }
  if ((unint64_t)a2 > 0x7FFFFFFF) {
    BUG();
  }
  if (a3 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  return fabs(*(double *)(a1 + 8 * a3 * (int)cblas_idamax_NEWLAPACK(a2, a1, a3)));
}

uint64_t protocol witness for Matrix.indexed() in conformance UpperStrictlyTriangularMatrix<A>()
{
  uint64_t v2 = v0;
  uint64_t result = UpperStrictlyTriangularMatrix.indexed()(*v1, v1[1], v1[2], v1[3]);
  *uint64_t v2 = result;
  v2[1] = v4;
  v2[2] = v5;
  v2[3] = v6;
  return result;
}

uint64_t UpperStrictlyTriangularMatrix.indexed()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a1;
}

uint64_t UpperStrictlyTriangularMatrix.IndexedSequence.init(base:)(uint64_t a1)
{
  return a1;
}

uint64_t UpperStrictlyTriangularMatrix.IndexedSequence.base.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return a1;
}

uint64_t UpperStrictlyTriangularMatrix.IndexedSequence.makeIterator()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  *uint64_t v4 = a1;
  v4[1] = a2;
  v4[2] = a3;
  uint64_t v4[3] = a4;
  void v4[4] = 0;
  v4[5] = 1;
  v4[6] = 0;
  swift_retain(a3);
  return swift_bridgeObjectRetain(a4);
}

void *UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.init(base:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  *uint64_t result = a1;
  result[1] = a2;
  result[2] = a3;
  result[3] = a4;
  result[4] = 0;
  result[5] = 1;
  result[6] = 0;
  return result;
}

uint64_t protocol witness for Sequence.makeIterator() in conformance UpperStrictlyTriangularMatrix<A>.IndexedSequence()
{
  uint64_t v1 = v0[3];
  UpperStrictlyTriangularMatrix.IndexedSequence.makeIterator()(*v0, v0[1], v0[2], v1);
  swift_bridgeObjectRelease(v1);
  return swift_release();
}

uint64_t UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.base.getter()
{
  uint64_t v1 = *v0;
  uint64_t v2 = v0[3];
  swift_retain(v0[2]);
  swift_bridgeObjectRetain(v2);
  return v1;
}

uint64_t UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.row.getter()
{
  return *(void *)(v0 + 32);
}

void UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.row.setter(uint64_t a1)
{
  *(void *)(v1 + 32) = a1;
}

void (*UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.row.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.column.getter()
{
  return *(void *)(v0 + 40);
}

void UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.column.setter(uint64_t a1)
{
  *(void *)(v1 + 40) = a1;
}

void (*UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.column.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.flatIndex.getter()
{
  return *(void *)(v0 + 48);
}

void UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.flatIndex.setter(uint64_t a1)
{
  *(void *)(v1 + 48) = a1;
}

void (*UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.flatIndex.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.next()(uint64_t a1)
{
  BOOL v22 = v1;
  uint64_t v3 = *(void *)(a1 + 16);
  TupleTypeMetadata3 = swift_getTupleTypeMetadata3(0, &type metadata for Int, &type metadata for Int, v3, "row column element ", 0);
  int64_t v5 = *(void *)(*(void *)(TupleTypeMetadata3 - 8) + 64);
  uint64_t v6 = alloca(v5);
  Swift::String v7 = alloca(v5);
  uint64_t v8 = *(void *)(v3 - 8);
  int64_t v9 = *(void *)(v8 + 64);
  int64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v12 = v2[1];
  uint64_t v13 = v2[5];
  if (v13 >= v12) {
    return __swift_storeEnumTagSinglePayload((uint64_t)v22, 1, 1, TupleTypeMetadata3);
  }
  uint64_t v14 = v2[4];
  if (v14 >= *v2) {
    return __swift_storeEnumTagSinglePayload((uint64_t)v22, 1, 1, TupleTypeMetadata3);
  }
  uint64_t v24 = v2[2];
  uint64_t v25 = v2[6];
  int64_t v27 = &v21;
  uint64_t v26 = TupleTypeMetadata3;
  uint64_t v21 = v14;
  int64_t v23 = &v21;
  swift_retain();
  ContiguousArray.subscript.getter(v25, v24, v3);
  swift_release();
  uint64_t v15 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v8 + 32);
  int64_t v27 = (uint64_t *)((char *)v27 + *(int *)(v26 + 64));
  v15(v27, v23, v3);
  uint64_t v16 = v21;
  v2[5] = v13 + 1;
  if (v13 + 1 == v12)
  {
    v2[4] = v16 + 1;
    if (__OFADD__(2, v16)) {
      BUG();
    }
    v2[5] = v16 + 2;
  }
  if (__OFADD__(1, v25)) {
    BUG();
  }
  v2[6] = v25 + 1;
  uint64_t v17 = v26;
  int64_t v18 = v22;
  int64_t v19 = (char *)v22 + *(int *)(v26 + 64);
  *BOOL v22 = v16;
  v18[1] = v13;
  v15((uint64_t *)v19, v27, v3);
  return __swift_storeEnumTagSinglePayload((uint64_t)v18, 0, 1, v17);
}

uint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in UpperStrictlyTriangularMatrix<A>.IndexedSequence(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for UpperStrictlyTriangularMatrix<A>.IndexedSequence.Iterator, a1);
}

uint64_t protocol witness for IteratorProtocol.next() in conformance UpperStrictlyTriangularMatrix<A>.IndexedSequence.Iterator(uint64_t a1)
{
  return UpperStrictlyTriangularMatrix.IndexedSequence.Iterator.next()(a1);
}

uint64_t type metadata accessor for UpperStrictlyTriangularMatrix.IndexedSequence(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for UpperStrictlyTriangularMatrix.IndexedSequence);
}

uint64_t type metadata accessor for UpperStrictlyTriangularMatrix.IndexedSequence.Iterator(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for UpperStrictlyTriangularMatrix.IndexedSequence.Iterator);
}

uint64_t initializeBufferWithCopyOfBuffer for UpperStrictlyTriangularMatrix.IndexedSequence(uint64_t *a1, uint64_t *a2)
{
  return initializeBufferWithCopyOfBuffer for CGRect(a1, a2);
}

uint64_t UnsafeMutableMatrixPointer<A>.addProduct(_:transposed:_:transposed:scaledBy:)(uint64_t a1, uint64_t a2, uint64_t a3, char a4, char a5, uint64_t a6, double a7, uint64_t a8, uint64_t a9, char a10, char a11, uint64_t a12, uint64_t a13, uint64_t a14, char a15)
{
  char v15 = a4 & 1;
  if ((a15 & 1) != (a4 & 1) || v15 != (a10 & 1))
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000026, "safeMatrixOperations.swift" + 0x8000000000000000, "LinearAlgebra/UnsafeMatrixOperations.swift", 42, 2, 35, 0);
    goto LABEL_49;
  }
  int v16 = a9;
  uint64_t v17 = a3;
  if (a5) {
    uint64_t v17 = a2;
  }
  uint64_t v18 = a9;
  if (a11) {
    uint64_t v18 = a8;
  }
  uint64_t v19 = a8;
  if (a11) {
    uint64_t v19 = a9;
  }
  if (v17 != v19)
  {
    unint64_t v24 = 0xD000000000000040;
    uint64_t v26 = 43;
    uint64_t v25 = "ve the same shape and layout.";
LABEL_48:
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v24, (unint64_t)v25 | 0x8000000000000000, "LinearAlgebra/UnsafeMatrixOperations.swift", 42, 2, v26, 0);
LABEL_49:
    BUG();
  }
  uint64_t v20 = a2;
  if (a5) {
    uint64_t v20 = a3;
  }
  if (v20 != a13)
  {
    unint64_t v24 = 0xD00000000000003ELL;
    uint64_t v26 = 46;
    uint64_t v25 = "hould all be the same.";
    goto LABEL_48;
  }
  if (v18 != a14)
  {
    unint64_t v24 = 0xD000000000000045;
    uint64_t v26 = 49;
    uint64_t v25 = "he same as the left row count.";
    goto LABEL_48;
  }
  if (a13 > 0x7FFFFFFF) {
    BUG();
  }
  if (a14 > 0x7FFFFFFF) {
    BUG();
  }
  if (v17 < (uint64_t)0xFFFFFFFF80000000 || a13 < (uint64_t)0xFFFFFFFF80000000 || a14 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (v17 > 0x7FFFFFFF) {
    BUG();
  }
  if (v15)
  {
    if (a2 < (uint64_t)0xFFFFFFFF80000000) {
      BUG();
    }
    if (a2 > 0x7FFFFFFF) {
      BUG();
    }
    if (a8 < (uint64_t)0xFFFFFFFF80000000) {
      BUG();
    }
    if (a8 > 0x7FFFFFFF) {
      BUG();
    }
    unsigned int v21 = 102;
    int v16 = a8;
    LODWORD(a3) = a2;
    int v22 = a13;
  }
  else
  {
    if (a3 < (uint64_t)0xFFFFFFFF80000000) {
      BUG();
    }
    if (a3 > 0x7FFFFFFF) {
      BUG();
    }
    if (a9 < (uint64_t)0xFFFFFFFF80000000) {
      BUG();
    }
    if (a9 > 0x7FFFFFFF) {
      BUG();
    }
    unsigned int v21 = 101;
    int v22 = a14;
  }
  return cblas_sgemm_NEWLAPACK(v21, (a5 & 1u) + 111, (a11 & 1u) + 111, a13, a14, v17, a7, 1.0, a1, a3, a6, v16, a12, v22);
}

{
  char v15;
  int v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  unsigned int v21;
  int v22;
  unint64_t v24;
  char *v25;
  uint64_t v26;

  char v15 = a4 & 1;
  if ((a15 & 1) != (a4 & 1) || v15 != (a10 & 1))
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000026, "safeMatrixOperations.swift" + 0x8000000000000000, "LinearAlgebra/UnsafeMatrixOperations.swift", 42, 2, 167, 0);
    goto LABEL_49;
  }
  int v16 = a9;
  uint64_t v17 = a3;
  if (a5) {
    uint64_t v17 = a2;
  }
  uint64_t v18 = a9;
  if (a11) {
    uint64_t v18 = a8;
  }
  uint64_t v19 = a8;
  if (a11) {
    uint64_t v19 = a9;
  }
  if (v17 != v19)
  {
    unint64_t v24 = 0xD000000000000040;
    uint64_t v26 = 175;
    uint64_t v25 = "ve the same shape and layout.";
LABEL_48:
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v24, (unint64_t)v25 | 0x8000000000000000, "LinearAlgebra/UnsafeMatrixOperations.swift", 42, 2, v26, 0);
LABEL_49:
    BUG();
  }
  uint64_t v20 = a2;
  if (a5) {
    uint64_t v20 = a3;
  }
  if (v20 != a13)
  {
    unint64_t v24 = 0xD00000000000003ELL;
    uint64_t v26 = 178;
    uint64_t v25 = "hould all be the same.";
    goto LABEL_48;
  }
  if (v18 != a14)
  {
    unint64_t v24 = 0xD000000000000045;
    uint64_t v26 = 181;
    uint64_t v25 = "he same as the left row count.";
    goto LABEL_48;
  }
  if (a13 > 0x7FFFFFFF) {
    BUG();
  }
  if (a14 > 0x7FFFFFFF) {
    BUG();
  }
  if (v17 < (uint64_t)0xFFFFFFFF80000000 || a13 < (uint64_t)0xFFFFFFFF80000000 || a14 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (v17 > 0x7FFFFFFF) {
    BUG();
  }
  if (v15)
  {
    if (a2 < (uint64_t)0xFFFFFFFF80000000) {
      BUG();
    }
    if (a2 > 0x7FFFFFFF) {
      BUG();
    }
    if (a8 < (uint64_t)0xFFFFFFFF80000000) {
      BUG();
    }
    if (a8 > 0x7FFFFFFF) {
      BUG();
    }
    unsigned int v21 = 102;
    int v16 = a8;
    LODWORD(a3) = a2;
    int v22 = a13;
  }
  else
  {
    if (a3 < (uint64_t)0xFFFFFFFF80000000) {
      BUG();
    }
    if (a3 > 0x7FFFFFFF) {
      BUG();
    }
    if (a9 < (uint64_t)0xFFFFFFFF80000000) {
      BUG();
    }
    if (a9 > 0x7FFFFFFF) {
      BUG();
    }
    unsigned int v21 = 101;
    int v22 = a14;
  }
  return cblas_dgemm_NEWLAPACK(v21, (a5 & 1u) + 111, (a11 & 1u) + 111, a13, a14, v17, a7, 1.0, a1, a3, a6, v16, a12, v22);
}

uint64_t UnsafeMutableVectorPointer<A>.addProduct(_:_:transposed:scaledBy:)(uint64_t a1, uint64_t a2, uint64_t a3, char a4, uint64_t a5, uint64_t a6, double a7, uint64_t a8, char a9, uint64_t a10, int a11, uint64_t a12)
{
  uint64_t v19 = v12;
  if (a2 > 0x7FFFFFFF) {
    BUG();
  }
  if (a2 < (uint64_t)0xFFFFFFFF80000000 || a3 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  uint64_t v15 = a3;
  if (a9) {
    uint64_t v15 = a2;
  }
  if (v15 != a6)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000044, "e right column count." + 0x8000000000000000, "LinearAlgebra/UnsafeMatrixOperations.swift", 42, 2, 90, 0);
    BUG();
  }
  if (a8 > 0x7FFFFFFF) {
    BUG();
  }
  if (a8 < (uint64_t)0xFFFFFFFF80000000 || a12 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a12 > 0x7FFFFFFF) {
    BUG();
  }
  unsigned __int8 v16 = a4 & 1;
  uint64_t v17 = a2;
  if (!v16) {
    uint64_t v17 = a3;
  }
  return cblas_sgemv_NEWLAPACK(v16 + 101, (a9 & 1u) + 111, a2, a3, a1, v17, a7, 1.0, a5, a8, a10, a12, v19);
}

{
  uint64_t v12;
  uint64_t v15;
  unsigned __int8 v16;
  uint64_t v17;
  uint64_t v19;

  uint64_t v19 = v12;
  if (a2 > 0x7FFFFFFF) {
    BUG();
  }
  if (a2 < (uint64_t)0xFFFFFFFF80000000 || a3 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  uint64_t v15 = a3;
  if (a9) {
    uint64_t v15 = a2;
  }
  if (v15 != a6)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000044, "e right column count." + 0x8000000000000000, "LinearAlgebra/UnsafeMatrixOperations.swift", 42, 2, 222, 0);
    BUG();
  }
  if (a8 > 0x7FFFFFFF) {
    BUG();
  }
  if (a8 < (uint64_t)0xFFFFFFFF80000000 || a12 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a12 > 0x7FFFFFFF) {
    BUG();
  }
  unsigned __int8 v16 = a4 & 1;
  uint64_t v17 = a2;
  if (!v16) {
    uint64_t v17 = a3;
  }
  return cblas_dgemv_NEWLAPACK(v16 + 101, (a9 & 1u) + 111, a2, a3, a1, v17, a7, 1.0, a5, a8, a10, a12, v19);
}

uint64_t UnsafeMutableVectorPointer<A>.addProduct(_:_:transposed:scaledBy:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, double a7, char a8, char a9, uint64_t a10, int a11, uint64_t a12)
{
  if (a5 > 0x7FFFFFFF) {
    BUG();
  }
  if (a5 < (uint64_t)0xFFFFFFFF80000000 || a6 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a6 > 0x7FFFFFFF) {
    BUG();
  }
  uint64_t v13 = a5;
  if (a9) {
    uint64_t v13 = a6;
  }
  if (v13 != a2)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000044, "right element count." + 0x8000000000000000, "LinearAlgebra/UnsafeMatrixOperations.swift", 42, 2, 127, 0);
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  if (a3 < (uint64_t)0xFFFFFFFF80000000 || a12 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a12 > 0x7FFFFFFF) {
    BUG();
  }
  unsigned int v14 = a5;
  if ((a8 & 1) == 0) {
    unsigned int v14 = a6;
  }
  return cblas_sgemv_NEWLAPACK((a8 & 1u) + 101, 112 - (a9 & 1u), a5, a6, a4, v14, a7, 1.0, a1, a3, a10, a12);
}

{
  uint64_t v13;
  unsigned int v14;

  if (a5 > 0x7FFFFFFF) {
    BUG();
  }
  if (a5 < (uint64_t)0xFFFFFFFF80000000 || a6 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a6 > 0x7FFFFFFF) {
    BUG();
  }
  uint64_t v13 = a5;
  if (a9) {
    uint64_t v13 = a6;
  }
  if (v13 != a2)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000044, "right element count." + 0x8000000000000000, "LinearAlgebra/UnsafeMatrixOperations.swift", 42, 2, 259, 0);
    BUG();
  }
  if (a3 > 0x7FFFFFFF) {
    BUG();
  }
  if (a3 < (uint64_t)0xFFFFFFFF80000000 || a12 < (uint64_t)0xFFFFFFFF80000000) {
    BUG();
  }
  if (a12 > 0x7FFFFFFF) {
    BUG();
  }
  unsigned int v14 = a5;
  if ((a8 & 1) == 0) {
    unsigned int v14 = a6;
  }
  return cblas_dgemv_NEWLAPACK((a8 & 1u) + 101, 112 - (a9 & 1u), a5, a6, a4, v14, a7, 1.0, a1, a3, a10, a12);
}

uint64_t MatrixLayout.blasValue.getter(char a1)
{
  return (a1 & 1u) + 101;
}

float _ss15ContiguousArrayV23withUnsafeBufferPointeryqd__qd__SRyxGKXEKlFSf_SfTg5038_s13LinearAlgebra11DenseVectorV010withd53D7Pointeryqd__qd__AA0fdG0VyxGKXEKlFqd__SRyxGKXEfU_Sf_W3TG50H7Algebra0dkF0VyxGq_s5Error_pRi_zRi0_zRi__Ri0__r0_lyS2fIsgyrzo_Tf1cn_n(uint64_t a1, void (*a2)(uint64_t, void, uint64_t))
{
  float v5 = *((float *)&v2 + 1);
  a2(a1 + 32, *(void *)(a1 + 16), 1);
  if (!v3) {
    return v5;
  }
  return result;
}

double _ss15ContiguousArrayV23withUnsafeBufferPointeryqd__qd__SRyxGKXEKlFSd_SdTg5038_s13LinearAlgebra11DenseVectorV010withd53D7Pointeryqd__qd__AA0fdG0VyxGKXEKlFqd__SRyxGKXEfU_Sd_W3TG50H7Algebra0dkF0VyxGq_s5Error_pRi_zRi0_zRi__Ri0__r0_lyS2dIsgyrzo_Tf1cn_n(uint64_t a1, void (*a2)(uint64_t, void, uint64_t))
{
  double v5 = v2;
  a2(a1 + 32, *(void *)(a1 + 16), 1);
  if (!v3) {
    return v5;
  }
  return result;
}

uint64_t DenseVector.withUnsafeVectorPointer<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v8 = a4;
  uint64_t v9 = a5;
  uint64_t v10 = a6;
  uint64_t v11 = a1;
  uint64_t v12 = a2;
  return ContiguousArray.withUnsafeBufferPointer<A>(_:)(partial apply for closure #1 in DenseVector.withUnsafeVectorPointer<A>(_:), v7, a3, a4, a5);
}

void *specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, char a5, uint64_t a6)
{
  return specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(a1, a2, a3, a4, a5, a6, 0);
}

{
  return specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(a1, a2, a3, a4, a5, a6, 0);
}

{
  return specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(a1, a2, a3, a4, a5, a6, 1);
}

{
  return specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(a1, a2, a3, a4, a5, a6, 1);
}

{
  return specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(a1, a2, a3, a4, a5, a6, 0);
}

{
  return specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(a1, a2, a3, a4, a5, a6, 0);
}

{
  return specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(a1, a2, a3, a4, a5, a6, 1);
}

{
  return specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(a1, a2, a3, a4, a5, a6, 1);
}

void *specialized DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, char a5, uint64_t a6, char a7)
{
  if (a1 < 0) {
    BUG();
  }
  uint64_t v7 = a4;
  char v8 = a7;
  if (a1)
  {
    uint64_t v10 = a3;
    uint64_t v11 = static Array._allocateBufferUninitialized(minimumCapacity:)(a1);
    *(void *)(v11 + 16) = a1;
    unsigned __int8 v16 = (void *)v11;
    uint64_t v12 = (void *)(v11 + 32);
    __bzero(v11 + 32, 4 * a1);
    char v8 = a7;
    a3 = v10;
    uint64_t v7 = a4;
  }
  else
  {
    unsigned __int8 v16 = _swiftEmptyArrayStorage;
    uint64_t v12 = &_swiftEmptyArrayStorage[4];
  }
  UnsafeMutableVectorPointer<A>.addProduct(_:_:transposed:scaledBy:)(a6 + 32, a3, v7, a5 & 1, a2 + 32, *(void *)(a2 + 16), COERCE_DOUBLE(1065353216), 1, v8, (uint64_t)v12, a1, 1);
  void v16[2] = a1;
  swift_release();
  swift_release();
  return v16;
}

{
  char v8;
  uint64_t v9;
  char v10;
  uint64_t v11;
  void *v12;
  void *v16;

  if (a1 < 0) {
    BUG();
  }
  char v8 = a7;
  if (a1)
  {
    uint64_t v9 = a3;
    uint64_t v10 = a5;
    uint64_t v11 = static Array._allocateBufferUninitialized(minimumCapacity:)(a1);
    *(void *)(v11 + 16) = a1;
    unsigned __int8 v16 = (void *)v11;
    uint64_t v12 = (void *)(v11 + 32);
    __bzero(v11 + 32, 4 * a1);
    char v8 = a7;
    a5 = v10;
    a3 = v9;
  }
  else
  {
    unsigned __int8 v16 = _swiftEmptyArrayStorage;
    uint64_t v12 = &_swiftEmptyArrayStorage[4];
  }
  UnsafeMutableVectorPointer<A>.addProduct(_:_:transposed:scaledBy:)(a2 + 32, *(void *)(a2 + 16), 1, a6 + 32, a3, a4, COERCE_DOUBLE(1065353216), a5 & 1, v8, (uint64_t)v12, a1, 1);
  void v16[2] = a1;
  swift_release();
  swift_release();
  return v16;
}

{
  uint64_t v7;
  char v8;
  uint64_t v10;
  uint64_t v11;
  void *v12;
  void *v16;

  if (a1 < 0) {
    BUG();
  }
  uint64_t v7 = a4;
  char v8 = a7;
  if (a1)
  {
    uint64_t v10 = a3;
    uint64_t v11 = static Array._allocateBufferUninitialized(minimumCapacity:)(a1);
    *(void *)(v11 + 16) = a1;
    unsigned __int8 v16 = (void *)v11;
    uint64_t v12 = (void *)(v11 + 32);
    __bzero(v11 + 32, 8 * a1);
    char v8 = a7;
    a3 = v10;
    uint64_t v7 = a4;
  }
  else
  {
    unsigned __int8 v16 = _swiftEmptyArrayStorage;
    uint64_t v12 = &_swiftEmptyArrayStorage[4];
  }
  UnsafeMutableVectorPointer<A>.addProduct(_:_:transposed:scaledBy:)(a6 + 32, a3, v7, a5 & 1, a2 + 32, *(void *)(a2 + 16), 1.0, 1, v8, (uint64_t)v12, a1, 1);
  void v16[2] = a1;
  swift_release();
  swift_release();
  return v16;
}

{
  char v8;
  uint64_t v9;
  char v10;
  uint64_t v11;
  void *v12;
  void *v16;

  if (a1 < 0) {
    BUG();
  }
  char v8 = a7;
  if (a1)
  {
    uint64_t v9 = a3;
    uint64_t v10 = a5;
    uint64_t v11 = static Array._allocateBufferUninitialized(minimumCapacity:)(a1);
    *(void *)(v11 + 16) = a1;
    unsigned __int8 v16 = (void *)v11;
    uint64_t v12 = (void *)(v11 + 32);
    __bzero(v11 + 32, 8 * a1);
    char v8 = a7;
    a5 = v10;
    a3 = v9;
  }
  else
  {
    unsigned __int8 v16 = _swiftEmptyArrayStorage;
    uint64_t v12 = &_swiftEmptyArrayStorage[4];
  }
  UnsafeMutableVectorPointer<A>.addProduct(_:_:transposed:scaledBy:)(a2 + 32, *(void *)(a2 + 16), 1, a6 + 32, a3, a4, 1.0, a5 & 1, v8, (uint64_t)v12, a1, 1);
  void v16[2] = a1;
  swift_release();
  swift_release();
  return v16;
}

uint64_t DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v7 = a4;
  uint64_t v8 = a5;
  uint64_t v9 = a1;
  uint64_t v10 = a2;
  uint64_t v11 = a3;
  return ContiguousArray.init(unsafeUninitializedCapacity:initializingWith:)(a1, (uint64_t)partial apply for closure #1 in DenseVector.init(unsafeUninitializedCapacity:initializingWith:), (uint64_t)v6, a4);
}

uint64_t DenseVector.count.getter(uint64_t a1, uint64_t a2)
{
  swift_retain(a1);
  uint64_t v2 = ContiguousArray.count.getter(a1, a2);
  swift_release(a1);
  return v2;
}

uint64_t DenseVector.init(repeating:count:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v11[0] = v3;
  uint64_t v5 = *(void *)(a3 - 8);
  int64_t v6 = *(void *)(v5 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  (*(void (**)(void *, uint64_t))(v5 + 16))(v11, a1);
  uint64_t v9 = ContiguousArray.init(repeating:count:)(v11, a2, a3);
  (*(void (**)(uint64_t, uint64_t))(v5 + 8))(a1, a3);
  return v9;
}

uint64_t DenseVector.subscript.getter()
{
  return ContiguousArray.subscript.getter();
}

uint64_t DenseVector.subscript.setter(uint64_t a1, Swift::Int a2, uint64_t a3)
{
  uint64_t v4 = *(void *)(a3 + 16);
  type metadata accessor for ContiguousArray(0, v4);
  ContiguousArray._makeMutableAndUnique()();
  uint64_t v5 = *v3;
  ContiguousArray._checkSubscript_mutating(_:)(a2);
  uint64_t v6 = *(void *)(v4 - 8);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v6 + 24))(v5 + ((*(unsigned __int8 *)(v6 + 80) + 32) & ~*(unsigned __int8 *)(v6 + 80)) + *(void *)(v6 + 72) * a2, a1, v4);
  MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
  return (*(uint64_t (**)(uint64_t, uint64_t))(v6 + 8))(a1, v4);
}

void (*DenseVector.subscript.modify(void *a1, uint64_t a2, uint64_t a3))(Swift::Int **a1, char a2)
{
  uint64_t v5 = malloc(0x38uLL);
  *a1 = v5;
  v5[2] = v3;
  v5[1] = a3;
  *uint64_t v5 = a2;
  uint64_t v6 = *(void *)(a3 + 16);
  v5[3] = v6;
  uint64_t v7 = *(void *)(v6 - 8);
  void v5[4] = v7;
  size_t v8 = *(void *)(v7 + 64);
  void v5[5] = malloc(v8);
  v5[6] = malloc(v8);
  ContiguousArray.subscript.getter(a2, *v3, v6);
  return DenseVector.subscript.modify;
}

void DenseVector.subscript.modify(Swift::Int **a1, char a2)
{
  uint64_t v2 = *a1;
  uint64_t v3 = (void *)(*a1)[5];
  uint64_t v4 = (void *)(*a1)[6];
  if (a2)
  {
    Swift::Int v7 = v2[4];
    Swift::Int v5 = v2[3];
    Swift::Int v6 = *v2;
    uint64_t v8 = v2[1];
    (*(void (**)(void *, void *, Swift::Int))(v7 + 16))(v3, v4, v5);
    DenseVector.subscript.setter((uint64_t)v3, v6, v8);
    (*(void (**)(void *, Swift::Int))(v7 + 8))(v4, v5);
  }
  else
  {
    DenseVector.subscript.setter((*a1)[6], *v2, v2[1]);
  }
  free(v4);
  free(v3);
  free(v2);
}

uint64_t default argument 1 of UnsafeMutableVectorPointer<A>.add(_:scaledBy:)(uint64_t a1, uint64_t a2)
{
  v10[0] = v2;
  uint64_t v3 = *(void *)(a2 + 8);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v3, a1, &protocol requirements base descriptor for ExpressibleByFloatLiteral, &associated type descriptor for ExpressibleByFloatLiteral.FloatLiteralType);
  int64_t v5 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  Swift::Int v6 = alloca(v5);
  Swift::Int v7 = alloca(v5);
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v3, a1, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByFloatLiteral, &associated conformance descriptor for ExpressibleByFloatLiteral.ExpressibleByFloatLiteral.FloatLiteralType: _ExpressibleByBuiltinFloatLiteral);
  dispatch thunk of _ExpressibleByBuiltinFloatLiteral.init(_builtinFloatLiteral:)(AssociatedTypeWitness, AssociatedConformanceWitness);
  return dispatch thunk of ExpressibleByFloatLiteral.init(floatLiteral:)(v10, a1, v3);
}

uint64_t DenseVector.storage.getter(uint64_t a1)
{
  return swift_retain(a1);
}

uint64_t DenseVector.storage.setter(uint64_t a1)
{
  uint64_t result = swift_release(*v1);
  void *v1 = a1;
  return result;
}

void (*DenseVector.storage.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t DenseVector.scalars.getter(uint64_t a1)
{
  return swift_retain(a1);
}

uint64_t DenseVector.init(scalars:)(uint64_t a1)
{
  return a1;
}

uint64_t DenseVector.init<A>(scalars:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  v12[0] = a5;
  uint64_t v6 = *(void *)(a3 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  (*(void (**)(void *, uint64_t))(v6 + 16))(v12, a1);
  uint64_t v10 = ContiguousArray.init<A>(_:)(v12, a2, a3, v12[0]);
  (*(void (**)(uint64_t, uint64_t))(v6 + 8))(a1, a3);
  return v10;
}

uint64_t closure #1 in DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(uint64_t *a1, void *a2, uint64_t a3, uint64_t (*a4)(void), uint64_t a5, uint64_t a6)
{
  *a2 = a3;
  uint64_t v11 = UnsafeMutableVectorPointer.init(_:)(*a1, a1[1], a6);
  uint64_t v12 = v8;
  uint64_t result = a4();
  if (!v6)
  {
    uint64_t result = UnsafeMutableBufferPointer.init(start:count:)(v11, v12, a6);
    *a1 = result;
    a1[1] = v10;
  }
  return result;
}

uint64_t DenseVector.squaredMagnitude.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return DenseVector.squaredMagnitude.getter(a1, a2, a3, (uint64_t)&unk_354178, (uint64_t)partial apply for implicit closure #1 in DenseVector.squaredMagnitude.getter);
}

uint64_t static DenseVector.__derived_struct_equals(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static ContiguousArray<A>.== infix(_:_:)(a1, a2, a3, *(void *)(*(void *)(*(void *)(a4 + 16) + 8) + 8));
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance DenseVector<A>(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  return static DenseVector.__derived_struct_equals(_:_:)(*a1, *a2, *(void *)(a3 + 16), *(void *)(a3 + 24));
}

uint64_t DenseVector.init(arrayLiteral:)(uint64_t a1, uint64_t a2)
{
  v5[0] = a1;
  uint64_t v2 = type metadata accessor for Array(0, a2);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for [A], v2);
  return ContiguousArray.init<A>(_:)(v5, a2, v2, WitnessTable);
}

uint64_t protocol witness for ExpressibleByArrayLiteral.init(arrayLiteral:) in conformance DenseVector<A>(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  uint64_t result = DenseVector.init(arrayLiteral:)(a1, *(void *)(a2 + 16));
  uint64_t *v3 = result;
  return result;
}

uint64_t closure #1 in DenseVector.withUnsafeVectorPointer<A>(_:)(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t, uint64_t, uint64_t), uint64_t a4, uint64_t a5)
{
  uint64_t v5 = UnsafeBufferPointer.baseAddress.getter(a1, a2, a5);
  if (!v5) {
    BUG();
  }
  uint64_t v6 = UnsafeVectorPointer.init(start:count:stride:)(v5);
  return a3(v6, v7, v8);
}

uint64_t partial apply for closure #1 in DenseVector.withUnsafeVectorPointer<A>(_:)(uint64_t a1, uint64_t a2)
{
  return closure #1 in DenseVector.withUnsafeVectorPointer<A>(_:)(a1, a2, *(uint64_t (**)(uint64_t, uint64_t, uint64_t))(v2 + 40), *(void *)(v2 + 48), *(void *)(v2 + 16));
}

uint64_t partial apply for closure #1 in DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(uint64_t *a1, void *a2)
{
  return closure #1 in DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(a1, a2, *(void *)(v2 + 32), *(uint64_t (**)(void))(v2 + 40), *(void *)(v2 + 48), *(void *)(v2 + 16));
}

uint64_t DenseVector.withUnsafeMutableVectorPointer<A>(_:)(uint64_t (*a1)(uint64_t, uint64_t, uint64_t), uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v13 = a4;
  void v11[5] = v4;
  v11[3] = a2;
  v11[4] = a1;
  uint64_t v6 = *(void *)(a3 + 16);
  type metadata accessor for ContiguousArray(0, v6);
  ContiguousArray._makeMutableAndUnique()();
  uint64_t v7 = *(void *)(*(void *)v5 + 16);
  int v8 = *(unsigned __int8 *)(*(void *)(v6 - 8) + 80);
  uint64_t v9 = *(void *)v5 + ((v8 + 32) & ~v8);
  v11[0] = v9;
  uint64_t v12 = v7;
  v11[1] = v7;
  closure #1 in DenseVector.withUnsafeMutableVectorPointer<A>(_:)(v11, a1, a2, v6);
  return $defer #1 <A><A1>() in ContiguousArray.withUnsafeMutableBufferPointer<A>(_:)(v11, v9, v12, v5, v6);
}

uint64_t closure #1 in DenseVector.withUnsafeMutableVectorPointer<A>(_:)(void *a1, uint64_t (*a2)(uint64_t, uint64_t, uint64_t), uint64_t a3, uint64_t a4)
{
  uint64_t v4 = UnsafeMutableBufferPointer.baseAddress.getter(*a1, a1[1], a4);
  if (!v4) {
    BUG();
  }
  uint64_t v5 = UnsafeMutableVectorPointer.init(start:count:stride:)(v4);
  return a2(v5, v6, v7);
}

uint64_t DenseVector.magnitude.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return DenseVector.squaredMagnitude.getter(a1, a2, a3, (uint64_t)&unk_3541A8, (uint64_t)partial apply for implicit closure #1 in DenseVector.squaredMagnitude.getter);
}

uint64_t DenseVector.squaredMagnitude.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v12 = a1;
  uint64_t v10 = a2;
  uint64_t v11 = a3;
  uint64_t v8 = a3;
  uint64_t KeyPath = swift_getKeyPath(a4);
  DenseVector.withUnsafeVectorPointer<A>(_:)(a5, (uint64_t)v7, a1, a2, a2, v8);
  return swift_release();
}

uint64_t DenseVector.maximumAbsoluteValue.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return DenseVector.squaredMagnitude.getter(a1, a2, a3, (uint64_t)&unk_3541D8, (uint64_t)partial apply for implicit closure #1 in DenseVector.squaredMagnitude.getter);
}

uint64_t key path getter for UnsafeVectorPointer<A>.squaredMagnitude : <A>UnsafeVectorPointer<A>, serialized(void *a1, uint64_t a2, uint64_t a3, uint64_t (*a4)(void, void, void, void, void))
{
  return a4(*a1, a1[1], a1[2], *(void *)(a3 + a2 - 16), *(void *)(*(void *)(a3 + a2 - 8) + 16));
}

Swift::Void __swiftcall DenseVector.negate()()
{
  uint64_t v2 = *(void *)(v0 + 16);
  uint64_t v3 = *(void *)(v2 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  int v22 = &v16;
  uint64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  unsigned int v21 = &v16;
  uint64_t v9 = *v1;
  uint64_t v19 = *(void *)(v0 + 24);
  swift_retain();
  uint64_t v10 = DenseVector.count.getter(v9, v2);
  swift_release();
  if (v10 < 0) {
    BUG();
  }
  uint64_t v11 = v3;
  uint64_t v12 = v1;
  if (v10)
  {
    uint64_t v13 = v10;
    Swift::Int v14 = 0;
    uint64_t v20 = v13;
    do
    {
      Swift::Int v17 = v14 + 1;
      ContiguousArray.subscript.getter(v14, *v12, v2);
      dispatch thunk of static SignedNumeric.- prefix(_:)(v22, v2, *(void *)(*(void *)(v19 + 16) + 16));
      (*(void (**)(uint64_t *, uint64_t))(v11 + 8))(v22, v2);
      uint64_t v18 = type metadata accessor for ContiguousArray(0, v2);
      ContiguousArray._makeMutableAndUnique()();
      uint64_t v15 = *v12;
      ContiguousArray._checkSubscript_mutating(_:)(v14);
      (*(void (**)(uint64_t, uint64_t *, uint64_t))(v11 + 40))(v15 + ((*(unsigned __int8 *)(v11 + 80) + 32) & ~*(unsigned __int8 *)(v11 + 80)) + *(void *)(v11 + 72) * v14, v21, v2);
      MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
      Swift::Int v14 = v17;
    }
    while (v20 != v17);
  }
}

uint64_t static DenseVector.- prefix(_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = DenseVector.count.getter(a1, a2);
  uint64_t v7 = a2;
  uint64_t v8 = a3;
  uint64_t v9 = a1;
  return DenseVector.init(unsafeUninitializedCapacity:initializingWith:)(v4, (uint64_t)partial apply for closure #1 in static DenseVector.- prefix(_:), (uint64_t)v6, a2, a3);
}

uint64_t closure #1 in static DenseVector.- prefix(_:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v17 = a4;
  uint64_t v18 = a2;
  uint64_t v5 = *(void *)(a3 - 8);
  int64_t v6 = *(void *)(v5 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  int v22 = &v16;
  uint64_t v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  uint64_t v19 = a1;
  uint64_t result = a1[1];
  uint64_t v20 = result;
  if (result < 0) {
    BUG();
  }
  if (result)
  {
    unint64_t v12 = 0;
    unsigned int v21 = &v16;
    do
    {
      uint64_t v16 = *v19;
      unint64_t v13 = v19[2];
      ContiguousArray.subscript.getter(v12, v18, a3);
      dispatch thunk of static SignedNumeric.- prefix(_:)(v22, a3, *(void *)(*(void *)(v17 + 16) + 16));
      (*(void (**)(uint64_t *, uint64_t))(v5 + 8))(v22, a3);
      unint64_t v15 = v13;
      unint64_t v14 = v12 * v13;
      if (!is_mul_ok(v12, v15)) {
        BUG();
      }
      ++v12;
      uint64_t result = (*(uint64_t (**)(unint64_t, uint64_t *, uint64_t))(v5 + 40))(*(void *)(v5 + 72) * v14 + v16, v21, a3);
    }
    while (v20 != v12);
  }
  return result;
}

uint64_t static DenseVector.+ prefix(_:)(uint64_t a1)
{
  return swift_retain(a1);
}

uint64_t static DenseVector.+= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static DenseVector.+= infix(_:_:)(a1, a2, a3, a4, partial apply for closure #1 in static DenseVector.+= infix(_:_:));
}

uint64_t closure #1 in closure #1 in static DenseVector.+= infix(_:_:)(uint64_t a1, unint64_t a2, int64_t a3, uint64_t a4, unint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  uint64_t v14 = a6;
  unint64_t v15 = a5;
  uint64_t v16 = a4;
  int64_t v17 = a3;
  unint64_t v18 = a2;
  uint64_t v8 = *(void *)(a7 - 8);
  int64_t v9 = *(void *)(v8 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  default argument 1 of UnsafeMutableVectorPointer<A>.add(_:scaledBy:)(a7, a8);
  UnsafeMutableVectorPointer<A>.add(_:scaledBy:)(a1, v18, v17, (uint64_t)&v13, v16, v15, v14, a7, a8);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v8 + 8))(&v13, a7);
}

uint64_t static DenseVector.-= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static DenseVector.+= infix(_:_:)(a1, a2, a3, a4, partial apply for closure #1 in static DenseVector.-= infix(_:_:));
}

uint64_t static DenseVector.+= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t (*a5)(uint64_t, uint64_t, uint64_t))
{
  uint64_t v9 = a3;
  uint64_t v10 = a4;
  uint64_t v11 = a2;
  uint64_t v6 = type metadata accessor for DenseVector(0, a3, a4, a4);
  return DenseVector.withUnsafeMutableVectorPointer<A>(_:)(a5, (uint64_t)v8, v6, (uint64_t)&type metadata for () + 8);
}

uint64_t closure #1 in static DenseVector.+= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v9 = a5;
  uint64_t v10 = a6;
  uint64_t v11 = a1;
  uint64_t v12 = a2;
  uint64_t v13 = a3;
  return DenseVector.withUnsafeVectorPointer<A>(_:)(a7, (uint64_t)v8, a4, a5, (uint64_t)&type metadata for () + 8, a6);
}

uint64_t closure #1 in closure #1 in static DenseVector.-= infix(_:_:)(uint64_t a1, unint64_t a2, int64_t a3, uint64_t a4, unint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  uint64_t v19 = a6;
  unint64_t v21 = a5;
  uint64_t v22 = a4;
  int64_t v23 = a3;
  unint64_t v24 = a2;
  uint64_t v25 = a1;
  uint64_t v20 = *(void *)(a7 - 8);
  int64_t v8 = *(void *)(v20 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v11 = *(void *)(a8 + 8);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v11, a7, &protocol requirements base descriptor for ExpressibleByFloatLiteral, &associated type descriptor for ExpressibleByFloatLiteral.FloatLiteralType);
  int64_t v13 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  uint64_t v14 = alloca(v13);
  unint64_t v15 = alloca(v13);
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v11, a7, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByFloatLiteral, &associated conformance descriptor for ExpressibleByFloatLiteral.ExpressibleByFloatLiteral.FloatLiteralType: _ExpressibleByBuiltinFloatLiteral);
  dispatch thunk of _ExpressibleByBuiltinFloatLiteral.init(_builtinFloatLiteral:)(AssociatedTypeWitness, AssociatedConformanceWitness);
  dispatch thunk of ExpressibleByFloatLiteral.init(floatLiteral:)(&v18, a7, v11);
  UnsafeMutableVectorPointer<A>.add(_:scaledBy:)(v25, v24, v23, (uint64_t)&v18, v22, v21, v19, a7, a8);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v20 + 8))(&v18, a7);
}

uint64_t static DenseVector.+ infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static DenseVector.+ infix(_:_:)(a1, a2, a3, a4, (void (*)(void *, uint64_t, uint64_t, uint64_t))static DenseVector.+= infix(_:_:));
}

uint64_t static DenseVector.- infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static DenseVector.+ infix(_:_:)(a1, a2, a3, a4, (void (*)(void *, uint64_t, uint64_t, uint64_t))static DenseVector.-= infix(_:_:));
}

uint64_t static DenseVector.+ infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void (*a5)(void *, uint64_t, uint64_t, uint64_t))
{
  v9[0] = a1;
  swift_retain(a1);
  a5(v9, a2, a3, a4);
  return v9[0];
}

uint64_t static DenseVector.*= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v7 = a3;
  uint64_t v8 = a4;
  uint64_t v9 = a2;
  uint64_t v4 = type metadata accessor for DenseVector(0, a3, a4, a4);
  return DenseVector.withUnsafeMutableVectorPointer<A>(_:)((uint64_t (*)(uint64_t, uint64_t, uint64_t))partial apply for closure #1 in static DenseVector.*= infix(_:_:), (uint64_t)v6, v4, (uint64_t)&type metadata for () + 8);
}

uint64_t closure #1 in static DenseVector.*= infix(_:_:)(uint64_t a1, uint64_t a2, unint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  if (a2 < 0) {
    BUG();
  }
  if (a2)
  {
    for (unint64_t i = 0; i != a2; ++i)
    {
      unint64_t v9 = a3 * i;
      if (!is_mul_ok(a3, i)) {
        BUG();
      }
      uint64_t result = dispatch thunk of static Numeric.*= infix(_:_:)(a1 + *(void *)(*(void *)(a5 - 8) + 72) * v9, a4, a5, *(void *)(*(void *)(*(void *)(a6 + 16) + 16) + 8));
    }
  }
  return result;
}

uint64_t static DenseVector.* infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v7[0] = a1;
  swift_retain();
  static DenseVector.*= infix(_:_:)((uint64_t)v7, a2, a3, a4);
  return v7[0];
}

{
  void v7[5];

  v7[0] = a2;
  swift_retain();
  static DenseVector.*= infix(_:_:)((uint64_t)v7, a1, a3, a4);
  return v7[0];
}

uint64_t static DenseVector./ infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v21 = a4;
  uint64_t v20 = a2;
  uint64_t v24 = *(void *)(a4 + 8);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v24, a3, &protocol requirements base descriptor for ExpressibleByFloatLiteral, &associated type descriptor for ExpressibleByFloatLiteral.FloatLiteralType);
  int64_t v6 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v22 = *(void *)(a3 - 8);
  int64_t v9 = *(void *)(v22 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v26 = &v20;
  uint64_t v12 = alloca(v9);
  int64_t v13 = alloca(v9);
  int64_t v23 = &v20;
  uint64_t v25 = a1;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v24, a3, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByFloatLiteral, &associated conformance descriptor for ExpressibleByFloatLiteral.ExpressibleByFloatLiteral.FloatLiteralType: _ExpressibleByBuiltinFloatLiteral);
  swift_retain();
  dispatch thunk of _ExpressibleByBuiltinFloatLiteral.init(_builtinFloatLiteral:)(AssociatedTypeWitness, AssociatedConformanceWitness);
  unint64_t v15 = v26;
  dispatch thunk of ExpressibleByFloatLiteral.init(floatLiteral:)(&v20, a3, v24);
  uint64_t v16 = v21;
  uint64_t v17 = (uint64_t)v23;
  dispatch thunk of static FloatingPoint./ infix(_:_:)(v15, v20, a3, *(void *)(v21 + 16));
  uint64_t v18 = *(void (**)(uint64_t *, uint64_t))(v22 + 8);
  v18(v26, a3);
  static DenseVector.*= infix(_:_:)((uint64_t)&v25, v17, a3, v16);
  v18((uint64_t *)v17, a3);
  return v25;
}

uint64_t static DenseVector<>.*= infix(_:_:)(void *a1)
{
  uint64_t v1 = (void *)*a1;
  if (!swift_isUniquelyReferenced_nonNull_native(*a1)) {
    uint64_t v1 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)v1);
  }
  uint64_t result = UnsafeMutableVectorPointer<A>.multiply(by:)((uint64_t)(v1 + 4), v1[2], 1);
  *a1 = v1;
  return result;
}

void *static DenseVector<>.* infix(_:_:)(uint64_t a1)
{
  uint64_t v1 = (void *)a1;
  swift_retain();
  if (!swift_isUniquelyReferenced_nonNull_native(a1)) {
    uint64_t v1 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()(a1);
  }
  UnsafeMutableVectorPointer<A>.multiply(by:)((uint64_t)(v1 + 4), v1[2], 1);
  return v1;
}

{
  void *v1;

  uint64_t v1 = (void *)a1;
  swift_retain();
  if (!swift_isUniquelyReferenced_nonNull_native(a1)) {
    uint64_t v1 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()(a1);
  }
  UnsafeMutableVectorPointer<A>.multiply(by:)((uint64_t)(v1 + 4), v1[2], 1);
  return v1;
}

void *static DenseVector<>./ infix(_:_:)(uint64_t a1)
{
  uint64_t v1 = (void *)a1;
  swift_retain();
  if (!swift_isUniquelyReferenced_nonNull_native(a1)) {
    uint64_t v1 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()(a1);
  }
  UnsafeMutableVectorPointer<A>.multiply(by:)((uint64_t)(v1 + 4), v1[2], 1);
  return v1;
}

uint64_t static DenseVector<>.*= infix(_:_:)(char **a1)
{
  uint64_t v1 = *a1;
  if (!swift_isUniquelyReferenced_nonNull_native(*a1)) {
    uint64_t v1 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)v1);
  }
  uint64_t result = UnsafeMutableVectorPointer<A>.multiply(by:)((uint64_t)(v1 + 32), *((void *)v1 + 2), 1);
  *a1 = v1;
  return result;
}

char *static DenseVector<>.* infix(_:_:)(uint64_t a1)
{
  uint64_t v1 = (char *)a1;
  swift_retain();
  if (!swift_isUniquelyReferenced_nonNull_native(a1)) {
    uint64_t v1 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()(a1);
  }
  UnsafeMutableVectorPointer<A>.multiply(by:)((uint64_t)(v1 + 32), *((void *)v1 + 2), 1);
  return v1;
}

{
  char *v1;

  uint64_t v1 = (char *)a1;
  swift_retain();
  if (!swift_isUniquelyReferenced_nonNull_native(a1)) {
    uint64_t v1 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()(a1);
  }
  UnsafeMutableVectorPointer<A>.multiply(by:)((uint64_t)(v1 + 32), *((void *)v1 + 2), 1);
  return v1;
}

char *static DenseVector<>./ infix(_:_:)(uint64_t a1)
{
  uint64_t v1 = (char *)a1;
  swift_retain();
  if (!swift_isUniquelyReferenced_nonNull_native(a1)) {
    uint64_t v1 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()(a1);
  }
  UnsafeMutableVectorPointer<A>.multiply(by:)((uint64_t)(v1 + 32), *((void *)v1 + 2), 1);
  return v1;
}

uint64_t dot<A>(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v6 = a4;
  uint64_t v7 = a2;
  return DenseVector.withUnsafeVectorPointer<A>(_:)((uint64_t)partial apply for closure #1 in dot<A>(_:_:), (uint64_t)v5, a1, a3, a3, a4);
}

uint64_t closure #1 in dot<A>(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v8 = a5;
  uint64_t v9 = a6;
  uint64_t v10 = a1;
  uint64_t v11 = a2;
  uint64_t v12 = a3;
  return DenseVector.withUnsafeVectorPointer<A>(_:)((uint64_t)partial apply for closure #1 in closure #1 in dot<A>(_:_:), (uint64_t)v7, a4, a5, a5, a6);
}

uint64_t closure #1 in closure #1 in dot<A>(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8)
{
  uint64_t v61 = a4;
  *(void *)&long long v70 = a3;
  uint64_t v68 = v8;
  *((void *)&v70 + 1) = a2;
  uint64_t v63 = a6;
  uint64_t v64 = a5;
  uint64_t v62 = a1;
  uint64_t v66 = *(void **)(a7 - 8);
  int64_t v9 = v66[8];
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  int64_t v58 = &v46;
  uint64_t v12 = alloca(v9);
  int64_t v13 = alloca(v9);
  uint64_t v67 = &v46;
  uint64_t v14 = alloca(v9);
  unint64_t v15 = alloca(v9);
  uint64_t v69 = &v46;
  TupleTypeMetadata2 = swift_getTupleTypeMetadata2(255, a7, a7, 0, 0);
  int64_t v17 = *(void *)(*(void *)(type metadata accessor for Optional(0, TupleTypeMetadata2) - 8) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v65 = &v46;
  uint64_t v60 = *(void *)(*(void *)(*(void *)(a8 + 16) + 16) + 8);
  uint64_t v20 = *(void *)(v60 + 16);
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, v20, a7, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated type descriptor for ExpressibleByIntegerLiteral.IntegerLiteralType);
  int64_t v22 = *(void *)(*(void *)(AssociatedTypeWitness - 8) + 64);
  int64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v20, a7, AssociatedTypeWitness, &protocol requirements base descriptor for ExpressibleByIntegerLiteral, &associated conformance descriptor for ExpressibleByIntegerLiteral.ExpressibleByIntegerLiteral.IntegerLiteralType: _ExpressibleByBuiltinIntegerLiteral);
  dispatch thunk of _ExpressibleByBuiltinIntegerLiteral.init(_builtinIntegerLiteral:)(&qword_3474D0, 256, AssociatedTypeWitness, AssociatedConformanceWitness);
  dispatch thunk of ExpressibleByIntegerLiteral.init(integerLiteral:)(&v46, a7, v20);
  uint64_t v50 = v61;
  uint64_t v51 = v64;
  uint64_t v52 = v63;
  uint64_t v46 = v62;
  *(void *)&long long v47 = *((void *)&v70 + 1);
  *((void *)&v47 + 1) = v70;
  uint64_t v27 = type metadata accessor for UnsafeVectorPointer(0, a7, v26, (uint64_t)&v46);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for UnsafeVectorPointer<A>, v27);
  zip<A, B>(_:_:)(&v50, &v46, v27, v27, WitnessTable, WitnessTable);
  long long v47 = v55;
  uint64_t v48 = v56;
  long long v49 = v57;
  uint64_t v50 = v27;
  *(void *)&long long v70 = v27;
  uint64_t v51 = v27;
  uint64_t v52 = WitnessTable;
  *((void *)&v70 + 1) = WitnessTable;
  uint64_t v53 = WitnessTable;
  uint64_t v31 = type metadata accessor for Zip2Sequence(0, &v50, &v46, v56, v29, v30, v54);
  Zip2Sequence.makeIterator()(v31);
  uint64_t v59 = TupleTypeMetadata2;
  while (1)
  {
    uint64_t v54 = v70;
    long long v55 = v70;
    uint64_t v56 = *((void *)&v70 + 1);
    uint64_t v36 = type metadata accessor for Zip2Sequence.Iterator(0, &v54, v32, v33, v34, v35, v46, v47, *((void *)&v47 + 1), v48);
    uint64_t v37 = (uint64_t)v65;
    Zip2Sequence.Iterator.next()(v36);
    uint64_t result = __swift_getEnumTagSinglePayload(v37, 1, TupleTypeMetadata2);
    if (result == 1) {
      break;
    }
    unint64_t v39 = (char *)v65 + *(int *)(TupleTypeMetadata2 + 48);
    unint64_t v40 = (void (*)(uint64_t *, uint64_t *, uint64_t))v66[4];
    v40(v69, v65, a7);
    uint64_t v41 = v67;
    v40(v67, (uint64_t *)v39, a7);
    uint64_t v42 = v58;
    uint64_t v43 = v60;
    dispatch thunk of static Numeric.* infix(_:_:)(v69, v41, a7, v60);
    dispatch thunk of static AdditiveArithmetic.+= infix(_:_:)(v68, v42, a7, *(void *)(v43 + 8));
    uint64_t v44 = (void (*)(uint64_t *, uint64_t))v66[1];
    unint64_t v45 = v42;
    TupleTypeMetadata2 = v59;
    v44(v45, a7);
    v44(v67, a7);
    v44(v69, a7);
  }
  return result;
}

float dot(_:_:)(uint64_t a1)
{
  return _ss15ContiguousArrayV23withUnsafeBufferPointeryqd__qd__SRyxGKXEKlFSf_SfTg5038_s13LinearAlgebra11DenseVectorV010withd53D7Pointeryqd__qd__AA0fdG0VyxGKXEKlFqd__SRyxGKXEfU_Sf_W3TG50H7Algebra0dkF0VyxGq_s5Error_pRi_zRi0_zRi__Ri0__r0_lyS2fIsgyrzo_Tf1cn_n(a1, (void (*)(uint64_t, void, uint64_t))partial apply for closure #1 in dot(_:_:));
}

NSURL *closure #1 in dot(_:_:)(const float *a1, int64_t a2, vDSP_Stride a3, uint64_t a4)
{
  uint64_t v5 = v4;
  int64_t v6 = a2;
  int64_t v7 = *(void *)(a4 + 16);
  float __C = 0.0;
  if (v7 < a2) {
    int64_t v6 = v7;
  }
  if (v6 < 0) {
    BUG();
  }
  vDSP_dotpr(a1, a3, (const float *)(a4 + 32), 1, &__C, v6);
  *uint64_t v5 = __C;
  return __stack_chk_guard;
}

double dot(_:_:)(uint64_t a1)
{
  return _ss15ContiguousArrayV23withUnsafeBufferPointeryqd__qd__SRyxGKXEKlFSd_SdTg5038_s13LinearAlgebra11DenseVectorV010withd53D7Pointeryqd__qd__AA0fdG0VyxGKXEKlFqd__SRyxGKXEfU_Sd_W3TG50H7Algebra0dkF0VyxGq_s5Error_pRi_zRi0_zRi__Ri0__r0_lyS2dIsgyrzo_Tf1cn_n(a1, (void (*)(uint64_t, void, uint64_t))partial apply for closure #1 in dot(_:_:));
}

NSURL *closure #1 in dot(_:_:)(const double *a1, int64_t a2, vDSP_Stride a3, uint64_t a4)
{
  uint64_t v5 = v4;
  int64_t v6 = a2;
  int64_t v7 = *(void *)(a4 + 16);
  double __C = 0.0;
  if (v7 < a2) {
    int64_t v6 = v7;
  }
  if (v6 < 0) {
    BUG();
  }
  vDSP_dotprD(a1, a3, (const double *)(a4 + 32), 1, &__C, v6);
  *uint64_t v5 = __C;
  return __stack_chk_guard;
}

uint64_t sub_3431F9(void *a1, uint64_t a2, uint64_t a3)
{
  return key path getter for UnsafeVectorPointer<A>.squaredMagnitude : <A>UnsafeVectorPointer<A>, serialized(a1, a2, a3, (uint64_t (*)(void, void, void, void, void))UnsafeVectorPointer<A>.squaredMagnitude.getter);
}

uint64_t sub_34320B()
{
  return 16;
}

void sub_343225(_OWORD *a1, _OWORD *a2)
{
  *a2 = *a1;
}

uint64_t partial apply for implicit closure #1 in DenseVector.squaredMagnitude.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return partial apply for implicit closure #1 in DenseVector.squaredMagnitude.getter(a1, a2, a3);
}

{
  uint64_t v3;
  uint64_t v4;
  void v6[4];

  uint64_t v4 = *(void *)(v3 + 24);
  v6[0] = a1;
  v6[1] = a2;
  void v6[2] = a3;
  return swift_getAtKeyPath(v6, v4);
}

uint64_t sub_34323C(void *a1, uint64_t a2, uint64_t a3)
{
  return key path getter for UnsafeVectorPointer<A>.squaredMagnitude : <A>UnsafeVectorPointer<A>, serialized(a1, a2, a3, UnsafeVectorPointer<A>.magnitude.getter);
}

uint64_t sub_34324E()
{
  return 16;
}

void sub_343268(_OWORD *a1, _OWORD *a2)
{
  *a2 = *a1;
}

uint64_t sub_34327F(void *a1, uint64_t a2, uint64_t a3)
{
  return key path getter for UnsafeVectorPointer<A>.squaredMagnitude : <A>UnsafeVectorPointer<A>, serialized(a1, a2, a3, UnsafeVectorPointer<A>.maximumAbsoluteValue.getter);
}

uint64_t sub_343291()
{
  return 16;
}

void sub_3432AB(_OWORD *a1, _OWORD *a2)
{
  *a2 = *a1;
}

uint64_t partial apply for closure #1 in static DenseVector.- prefix(_:)(uint64_t *a1)
{
  return closure #1 in static DenseVector.- prefix(_:)(a1, v1[4], v1[2], v1[3]);
}

uint64_t partial apply for closure #1 in static DenseVector.+= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return closure #1 in static DenseVector.+= infix(_:_:)(a1, a2, a3, v3[4], v3[2], v3[3], (uint64_t)partial apply for closure #1 in closure #1 in static DenseVector.+= infix(_:_:));
}

uint64_t type metadata accessor for DenseVector(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for DenseVector);
}

uint64_t partial apply for closure #1 in static DenseVector.-= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return closure #1 in static DenseVector.+= infix(_:_:)(a1, a2, a3, v3[4], v3[2], v3[3], (uint64_t)partial apply for closure #1 in closure #1 in static DenseVector.-= infix(_:_:));
}

uint64_t partial apply for closure #1 in static DenseVector.*= infix(_:_:)(uint64_t a1, uint64_t a2, unint64_t a3)
{
  return closure #1 in static DenseVector.*= infix(_:_:)(a1, a2, a3, v3[4], v3[2], v3[3]);
}

uint64_t partial apply for closure #1 in dot<A>(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return closure #1 in dot<A>(_:_:)(a1, a2, a3, v3[4], v3[2], v3[3]);
}

NSURL *partial apply for closure #1 in dot(_:_:)(const float *a1, int64_t a2, vDSP_Stride a3)
{
  return closure #1 in dot(_:_:)(a1, a2, a3, v3);
}

NSURL *partial apply for closure #1 in dot(_:_:)(const double *a1, int64_t a2, vDSP_Stride a3)
{
  return closure #1 in dot(_:_:)(a1, a2, a3, v3);
}

uint64_t partial apply for closure #1 in closure #1 in dot<A>(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return closure #1 in closure #1 in dot<A>(_:_:)(a1, a2, a3, v3[4], v3[5], v3[6], v3[2], v3[3]);
}

uint64_t partial apply for closure #1 in closure #1 in static DenseVector.-= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return partial apply for closure #1 in closure #1 in static DenseVector.-= infix(_:_:)(a1, a2, a3, (uint64_t (*)(uint64_t, uint64_t, uint64_t, void, void, void, void, void))closure #1 in closure #1 in static DenseVector.-= infix(_:_:));
}

uint64_t partial apply for closure #1 in closure #1 in static DenseVector.+= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return partial apply for closure #1 in closure #1 in static DenseVector.-= infix(_:_:)(a1, a2, a3, (uint64_t (*)(uint64_t, uint64_t, uint64_t, void, void, void, void, void))closure #1 in closure #1 in static DenseVector.+= infix(_:_:));
}

uint64_t partial apply for closure #1 in closure #1 in static DenseVector.-= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t (*a4)(uint64_t, uint64_t, uint64_t, void, void, void, void, void))
{
  return a4(a1, a2, a3, v4[4], v4[5], v4[6], v4[2], v4[3]);
}

uint64_t Logger.linearAlgebra.unsafeMutableAddressor()
{
  if (one-time initialization token for linearAlgebra != -1) {
    swift_once(&one-time initialization token for linearAlgebra, one-time initialization function for linearAlgebra);
  }
  uint64_t v0 = type metadata accessor for Logger(0);
  return __swift_project_value_buffer(v0, (uint64_t)static Logger.linearAlgebra);
}

uint64_t one-time initialization function for linearAlgebra()
{
  uint64_t v0 = type metadata accessor for Logger(0);
  __swift_allocate_value_buffer(v0, static Logger.linearAlgebra);
  __swift_project_value_buffer(v0, (uint64_t)static Logger.linearAlgebra);
  return Logger.init(subsystem:category:)(0xD000000000000012, "Target Frame Rate" + 0x8000000000000000, 0x612D7261656E696CLL, 0xEE0061726265676CLL);
}

uint64_t static Logger.linearAlgebra.getter()
{
  uint64_t v1 = v0;
  if (one-time initialization token for linearAlgebra != -1) {
    swift_once(&one-time initialization token for linearAlgebra, one-time initialization function for linearAlgebra);
  }
  uint64_t v2 = type metadata accessor for Logger(0);
  uint64_t v3 = __swift_project_value_buffer(v2, (uint64_t)static Logger.linearAlgebra);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(v1, v3, v2);
}