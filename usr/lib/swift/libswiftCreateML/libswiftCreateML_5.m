uint64_t closure #1 in MLSoundClassifier.init(trainingData:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  void *v4;
  uint64_t v5;

  v4[5] = a4;
  v4[4] = a3;
  v4[3] = a2;
  v4[2] = a1;
  v5 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  v4[6] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(closure #1 in MLSoundClassifier.init(trainingData:parameters:), 0, 0);
}

uint64_t closure #1 in MLSoundClassifier.init(trainingData:parameters:)()
{
  uint64_t v1 = v0[3];
  v2 = (void *)v0[4];
  v3 = v2;
  if (!v2) {
    v3 = _swiftEmptyArrayStorage;
  }
  v8 = v3;
  outlined init with copy of MLTrainingSessionParameters(v0[5], v0[6], type metadata accessor for MLSoundClassifier.ModelParameters);
  v4 = (char *)&async function pointer to specialized MLSoundClassifier.init<A, B>(training:validation:parameters:)
     + async function pointer to specialized MLSoundClassifier.init<A, B>(training:validation:parameters:);
  uint64_t v5 = dword_3ACEF4;
  swift_bridgeObjectRetain(v1);
  swift_bridgeObjectRetain((_BYTE)v2);
  v6 = (void *)swift_task_alloc(v5);
  v0[7] = v6;
  void *v6 = v0;
  v6[1] = closure #1 in MLSoundClassifier.init(trainingData:parameters:);
  return ((uint64_t (*)(void, void, void *, void))v4)(v0[2], v0[3], v8, v0[6]);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;

  v2 = *(void *)(*v1 + 56);
  v3 = *v1;
  *(void *)(v3 + 64) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    return swift_task_switch(closure #1 in MLSoundClassifier.init(trainingData:parameters:), 0, 0);
  }
  swift_task_dealloc(*(void *)(v3 + 48));
  return (*(uint64_t (**)(void))(v3 + 8))();
}

{
  return closure #1 in closure #1 in closure #1 in closure #1 in static MLStyleTransfer.resume(_:)();
}

uint64_t specialized MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v4[6] = a4;
  v4[5] = a3;
  v4[4] = a2;
  v4[3] = a1;
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationMetrics<String>);
  v4[7] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v4[8] = v6;
  unint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[9] = swift_task_alloc(v7);
  v4[10] = swift_task_alloc(v7);
  unint64_t v8 = (*(void *)(*(void *)(type metadata accessor for MLClassifierMetrics(0) - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[11] = swift_task_alloc(v8);
  v4[12] = swift_task_alloc(v8);
  unint64_t v9 = (*(void *)(*(void *)(type metadata accessor for MLSoundClassifier.Model(0) - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[13] = swift_task_alloc(v9);
  v4[14] = swift_task_alloc(v9);
  uint64_t v10 = type metadata accessor for TrainingTablePrinter(0);
  v4[15] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v4[16] = v11;
  uint64_t v12 = *(void *)(v11 + 64);
  v4[17] = v12;
  unint64_t v13 = (v12 + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[18] = swift_task_alloc(v13);
  v4[19] = swift_task_alloc(v13);
  unint64_t v14 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingTablePrinter?)
                               - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[20] = swift_task_alloc(v14);
  v4[21] = swift_task_alloc(v14);
  v4[22] = swift_task_alloc(v14);
  v4[23] = swift_task_alloc(v14);
  uint64_t v15 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  v4[24] = swift_task_alloc((*(void *)(*(void *)(v15 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = *(void *)(type metadata accessor for MLSoundClassifier.Classifier(0) - 8);
  v4[25] = v16;
  uint64_t v17 = *(void *)(v16 + 64);
  v4[26] = v17;
  unint64_t v18 = (v17 + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[27] = swift_task_alloc(v18);
  v4[28] = swift_task_alloc(v18);
  return swift_task_switch(specialized MLSoundClassifier.init<A, B>(training:validation:parameters:), 0, 0);
}

{
  void *v4;
  uint64_t v5;
  unint64_t v6;

  v4[18] = a4;
  v4[17] = a3;
  v4[16] = a2;
  v4[15] = a1;
  uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  v4[19] = v5;
  uint64_t v6 = (*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[20] = swift_task_alloc(v6);
  v4[21] = swift_task_alloc(v6);
  return swift_task_switch(specialized MLSoundClassifier.init<A, B>(training:validation:parameters:), 0, 0);
}

uint64_t specialized MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v8 = *(void *)(v7 + 24);
  __swift_storeEnumTagSinglePayload(v8, 1, 1, *(void *)(v7 + 120));
  unint64_t v9 = (int *)type metadata accessor for MLSoundClassifier(0);
  *(void *)(v7 + 232) = v9;
  *(_DWORD *)(v7 + 304) = v9[8];
  MLClassifierMetrics.init()();
  uint64_t v10 = v9[9];
  *(_DWORD *)(v7 + 308) = v10;
  uint64_t v11 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v12 = swift_allocError(&type metadata for MLCreateError, v11, 0, 0);
  *(void *)uint64_t v13 = 0xD0000000000000C0;
  *(void *)(v13 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v13 + 16) = 0;
  *(_OWORD *)(v13 + 32) = 0;
  *(unsigned char *)(v13 + 48) = 0;
  *(void *)(v8 + v10) = v12;
  uint64_t v14 = type metadata accessor for MLClassifierMetrics.Contents(0);
  *(void *)(v7 + 240) = v14;
  swift_storeEnumTagMultiPayload(v8 + v10, v14, 2);
  MLSoundClassifier.ModelParameters.validate()();
  *(void *)(v7 + 248) = v15;
  if (v15)
  {
    uint64_t v16 = *(void *)(v7 + 32);
    uint64_t v17 = *(void *)(v7 + 40);
    outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v7 + 48), type metadata accessor for MLSoundClassifier.ModelParameters);
    swift_bridgeObjectRelease(v17);
    swift_bridgeObjectRelease(v16);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v7 + 24), &demangling cache variable for type metadata for TrainingTablePrinter?);
    if (!*(void *)(v7 + 248)) {
      outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v7 + 24) + *(int *)(*(void *)(v7 + 232) + 28), type metadata accessor for MLSoundClassifier.ModelParameters);
    }
    uint64_t v18 = *(void *)(v7 + 224);
    uint64_t v19 = *(void *)(v7 + 216);
    uint64_t v65 = *(void *)(v7 + 192);
    uint64_t v64 = *(void *)(v7 + 184);
    uint64_t v63 = *(void *)(v7 + 176);
    uint64_t v68 = *(void *)(v7 + 168);
    uint64_t v70 = *(void *)(v7 + 160);
    uint64_t v66 = *(void *)(v7 + 152);
    uint64_t v74 = *(void *)(v7 + 144);
    uint64_t v77 = *(void *)(v7 + 112);
    uint64_t v20 = *(void *)(v7 + 24);
    uint64_t v21 = v20 + *(int *)(v7 + 308);
    uint64_t v75 = *(void *)(v7 + 104);
    uint64_t v69 = *(void *)(v7 + 96);
    uint64_t v72 = *(void *)(v7 + 88);
    uint64_t v80 = *(void *)(v7 + 80);
    uint64_t v87 = *(void *)(v7 + 72);
    outlined destroy of MLActivityClassifier.ModelParameters(v20 + *(int *)(v7 + 304), type metadata accessor for MLClassifierMetrics);
    outlined destroy of MLActivityClassifier.ModelParameters(v21, type metadata accessor for MLClassifierMetrics);
    swift_task_dealloc(v18);
    swift_task_dealloc(v19);
    swift_task_dealloc(v65);
    swift_task_dealloc(v64);
    swift_task_dealloc(v63);
    swift_task_dealloc(v68);
    swift_task_dealloc(v70);
    swift_task_dealloc(v66);
    swift_task_dealloc(v74);
    swift_task_dealloc(v77);
    swift_task_dealloc(v75);
    swift_task_dealloc(v69);
    swift_task_dealloc(v72);
    swift_task_dealloc(v80);
    swift_task_dealloc(v87);
    v23 = *(uint64_t (__stdcall **)(uint64_t (*)(uint64_t)))(v7 + 8);
    return v23(v22);
  }
  uint64_t v78 = *(void *)(v7 + 192);
  uint64_t v88 = *(void *)(v7 + 184);
  uint64_t v84 = *(void *)(v7 + 120);
  uint64_t v25 = *(void *)(v7 + 48);
  uint64_t v81 = *(void *)(v7 + 24);
  uint64_t v26 = *(void *)(v7 + 32);
  v67 = v9;
  outlined init with copy of MLTrainingSessionParameters(v25, v81 + v9[7], type metadata accessor for MLSoundClassifier.ModelParameters);
  MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v26, v7 + 16, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>, (uint64_t)&unk_34FC08);
  uint64_t v28 = specialized Set.init<A>(_:)((uint64_t)MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm);
  *(void *)(v7 + 256) = v28;
  outlined init with copy of MLTrainingSessionParameters(v25, v78, type metadata accessor for MLSoundClassifier.ModelParameters);
  swift_bridgeObjectRetain(v28);
  MLSoundClassifier.Classifier.init(labels:parameters:)(v28, v78);
  uint64_t v29 = type metadata accessor for EventCollector();
  swift_allocObject(v29, 32, 7);
  uint64_t v30 = EventCollector.init()();
  *(void *)(v7 + 264) = v30;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v81, v88, &demangling cache variable for type metadata for TrainingTablePrinter?);
  LODWORD(v25) = __swift_getEnumTagSinglePayload(v88, 1, v84);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v88, &demangling cache variable for type metadata for TrainingTablePrinter?);
  uint64_t v73 = v30;
  if (v25 == 1)
  {
    uint64_t v31 = *(void *)(v7 + 176);
    uint64_t v32 = *(void *)(v7 + 168);
    uint64_t v33 = *(void *)(v7 + 120);
    uint64_t v34 = *(void *)(v7 + 24);
    static MLSoundClassifier.createTablePrinter(hasValidation:)(*(void *)(*(void *)(v7 + 40) + 16) != 0);
    __swift_storeEnumTagSinglePayload(v31, 0, 1, v33);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v31, v34, &demangling cache variable for type metadata for TrainingTablePrinter?);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v34, v32, &demangling cache variable for type metadata for TrainingTablePrinter?);
    if (__swift_getEnumTagSinglePayload(v32, 1, v33) == 1) {
      BUG();
    }
    uint64_t v35 = *(void *)(v7 + 168);
    TrainingTablePrinter.beginTable()();
    outlined destroy of MLActivityClassifier.ModelParameters(v35, type metadata accessor for TrainingTablePrinter);
  }
  uint64_t v36 = *(void *)(v7 + 160);
  uint64_t v37 = *(void *)(v7 + 120);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v7 + 24), v36, &demangling cache variable for type metadata for TrainingTablePrinter?);
  if (__swift_getEnumTagSinglePayload(v36, 1, v37) != 1)
  {
    uint64_t v82 = *(void *)(v7 + 224);
    uint64_t v38 = *(void *)(v7 + 216);
    uint64_t v85 = *(void *)(v7 + 208);
    uint64_t v89 = *(void *)(v7 + 200);
    uint64_t v39 = *(void *)(v7 + 152);
    uint64_t v40 = *(void *)(v7 + 40);
    uint64_t v41 = *(void *)(v7 + 144);
    outlined init with take of MLClassifierMetrics(*(void *)(v7 + 160), v39, type metadata accessor for TrainingTablePrinter);
    uint64_t v42 = *(void *)(v40 + 16);
    *(void *)(v7 + 272) = v42;
    outlined init with copy of MLTrainingSessionParameters(v82, v38, type metadata accessor for MLSoundClassifier.Classifier);
    outlined init with copy of MLTrainingSessionParameters(v39, v41, type metadata accessor for TrainingTablePrinter);
    uint64_t v43 = *(unsigned __int8 *)(v89 + 80);
    uint64_t v44 = ~*(unsigned __int8 *)(v89 + 80) & (v43 + 16);
    unint64_t v86 = (v85 + v44 + 7) & 0xFFFFFFFFFFFFFFF8;
    unint64_t v45 = (v86 + 15) & 0xFFFFFFFFFFFFFFF8;
    uint64_t v90 = *(void *)(v7 + 216);
    uint64_t v83 = *(void *)(v7 + 144);
    uint64_t v46 = *(void *)(v7 + 128);
    uint64_t v47 = *(void *)(v7 + 136);
    unint64_t v79 = v45;
    if (v42)
    {
      uint64_t v71 = *(void *)(v7 + 32);
      uint64_t v76 = *(void *)(v7 + 40);
      unint64_t v48 = (v45 + 15) & 0xFFFFFFFFFFFFFFF8;
      uint64_t v49 = *(unsigned __int8 *)(v46 + 80);
      uint64_t v50 = ~v49 & (v48 + v49 + 8);
      uint64_t v51 = swift_allocObject(&unk_39BF58, v50 + v47, v49 | v43 | 7);
      outlined init with take of MLClassifierMetrics(v90, v51 + v44, type metadata accessor for MLSoundClassifier.Classifier);
      *(void *)(v51 + v86) = v71;
      *(void *)(v51 + v79) = v76;
      *(void *)(v51 + v48) = v73;
      outlined init with take of MLClassifierMetrics(v83, v51 + v50, type metadata accessor for TrainingTablePrinter);
      swift_bridgeObjectRetain(v71);
      swift_retain();
      swift_bridgeObjectRetain(v76);
      specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for specialized closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:), v51);
      v52 = (uint64_t *)(v7 + 104);
    }
    else
    {
      uint64_t v53 = *(void *)(v7 + 32);
      uint64_t v54 = *(unsigned __int8 *)(v46 + 80);
      uint64_t v55 = ~v54 & (v45 + v54 + 8);
      uint64_t v56 = swift_allocObject(&unk_39BF80, v55 + v47, v54 | v43 | 7);
      outlined init with take of MLClassifierMetrics(v90, v56 + v44, type metadata accessor for MLSoundClassifier.Classifier);
      *(void *)(v56 + v86) = v53;
      *(void *)(v56 + v79) = v73;
      outlined init with take of MLClassifierMetrics(v83, v56 + v55, type metadata accessor for TrainingTablePrinter);
      swift_bridgeObjectRetain(v53);
      swift_retain();
      specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for specialized closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:), v56);
      v52 = (uint64_t *)(v7 + 112);
    }
    uint64_t v57 = *v52;
    uint64_t v58 = *(void *)(v7 + 24);
    swift_release();
    outlined init with take of MLClassifierMetrics(v57, v58 + v67[5], type metadata accessor for MLSoundClassifier.Model);
    static os_log_type_t.info.getter();
    uint64_t v59 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
    v60 = (void *)swift_allocObject(v59, 72, 7);
    v60[2] = 1;
    v60[3] = 2;
    v60[7] = &type metadata for Int;
    v60[8] = &protocol witness table for Int;
    v60[4] = 3;
    os_log(_:dso:log:type:_:)("event: %lu", 10);
    swift_bridgeObjectRelease((_BYTE)v60);
    v61 = (uint64_t (__stdcall *)(uint64_t (*)(uint64_t)))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                                                                 + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
    v62 = (void *)swift_task_alloc(dword_3AE254);
    *(void *)(v7 + 280) = v62;
    void *v62 = v7;
    v22 = specialized MLSoundClassifier.init<A, B>(training:validation:parameters:);
    v62[1] = specialized MLSoundClassifier.init<A, B>(training:validation:parameters:);
    v23 = v61;
    return v23(v22);
  }
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v7 + 160), &demangling cache variable for type metadata for TrainingTablePrinter?);
  return _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000027, "range [0.0, 1.0), but got " + 0x8000000000000000, "CreateML/MLSoundClassifier.swift", 32, 2, 229, 0);
}

uint64_t specialized MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1)
{
  uint64_t v5 = *(void *)(*v2 + 280);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 288) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    swift_bridgeObjectRelease(*(void *)(v4 + 256));
    uint64_t v6 = specialized MLSoundClassifier.init<A, B>(training:validation:parameters:);
  }
  else
  {
    *(void *)(v4 + 296) = a1;
    uint64_t v6 = specialized MLSoundClassifier.init<A, B>(training:validation:parameters:);
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t specialized MLSoundClassifier.init<A, B>(training:validation:parameters:)()
{
  uint64_t v1 = *(void *)(v0 + 288);
  uint64_t v2 = *(void *)(v0 + 32);
  *(void *)(*(void *)(v0 + 24) + *(int *)(*(void *)(v0 + 232) + 24)) = *(void *)(v0 + 296);
  specialized MLSoundClassifier.evaluate<A>(on:)(v2);
  if (v1)
  {
    uint64_t v50 = *(void *)(v0 + 224);
    uint64_t v54 = *(void *)(v0 + 152);
    uint64_t v3 = *(void *)(v0 + 48);
    uint64_t v4 = *(void *)(v0 + 256);
    uint64_t v5 = *(void *)(v0 + 32);
    uint64_t v6 = *(void *)(v0 + 40);
    swift_release();
    swift_bridgeObjectRelease(v4);
    outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLSoundClassifier.ModelParameters);
    swift_bridgeObjectRelease(v6);
    swift_bridgeObjectRelease(v5);
    outlined destroy of MLActivityClassifier.ModelParameters(v54, type metadata accessor for TrainingTablePrinter);
    outlined destroy of MLActivityClassifier.ModelParameters(v50, type metadata accessor for MLSoundClassifier.Classifier);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 24), &demangling cache variable for type metadata for TrainingTablePrinter?);
    outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 24) + *(int *)(*(void *)(v0 + 232) + 20), type metadata accessor for MLSoundClassifier.Model);

    if (!*(void *)(v0 + 248)) {
      outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 24) + *(int *)(*(void *)(v0 + 232) + 28), type metadata accessor for MLSoundClassifier.ModelParameters);
    }
    uint64_t v7 = *(void *)(v0 + 224);
    uint64_t v8 = *(void *)(v0 + 216);
    uint64_t v47 = *(void *)(v0 + 192);
    uint64_t v45 = *(void *)(v0 + 184);
    uint64_t v43 = *(void *)(v0 + 176);
    uint64_t v41 = *(void *)(v0 + 168);
    uint64_t v39 = *(void *)(v0 + 160);
    uint64_t v35 = *(void *)(v0 + 152);
    uint64_t v31 = *(void *)(v0 + 144);
    uint64_t v29 = *(void *)(v0 + 112);
    uint64_t v9 = *(void *)(v0 + 24);
    uint64_t v10 = v9 + *(int *)(v0 + 308);
    uint64_t v37 = *(void *)(v0 + 104);
    uint64_t v33 = *(void *)(v0 + 96);
    uint64_t v27 = *(void *)(v0 + 88);
    uint64_t v55 = *(void *)(v0 + 80);
    uint64_t v51 = *(void *)(v0 + 72);
    outlined destroy of MLActivityClassifier.ModelParameters(v9 + *(int *)(v0 + 304), type metadata accessor for MLClassifierMetrics);
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLClassifierMetrics);
    swift_task_dealloc(v7);
    swift_task_dealloc(v8);
    swift_task_dealloc(v47);
    swift_task_dealloc(v45);
    swift_task_dealloc(v43);
    swift_task_dealloc(v41);
    swift_task_dealloc(v39);
    swift_task_dealloc(v35);
    swift_task_dealloc(v31);
    swift_task_dealloc(v29);
    swift_task_dealloc(v37);
    swift_task_dealloc(v33);
    swift_task_dealloc(v27);
    swift_task_dealloc(v55);
    swift_task_dealloc(v51);
    uint64_t v11 = *(uint64_t (**)(void))(v0 + 8);
  }
  else
  {
    uint64_t v12 = *(void *)(v0 + 240);
    uint64_t v13 = *(void *)(v0 + 96);
    uint64_t v14 = *(void *)(v0 + 272);
    uint64_t v15 = *(void *)(v0 + 24) + *(int *)(v0 + 304);
    v52 = *(void (**)(uint64_t, void, void))(*(void *)(v0 + 64) + 32);
    v52(v13, *(void *)(v0 + 80), *(void *)(v0 + 56));
    uint64_t v56 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    swift_storeEnumTagMultiPayload(v13, v56, 0);
    swift_storeEnumTagMultiPayload(v13, v12, 0);
    outlined assign with take of MLClassifierMetrics(v13, v15);
    if (v14)
    {
      specialized MLSoundClassifier.evaluate<A>(on:)(*(void *)(v0 + 40));
      uint64_t v16 = *(void *)(v0 + 240);
      uint64_t v17 = *(void *)(v0 + 88);
      uint64_t v18 = *(void *)(v0 + 24) + *(int *)(v0 + 308);
      v52(v17, *(void *)(v0 + 72), *(void *)(v0 + 56));
      swift_storeEnumTagMultiPayload(v17, v56, 0);
      swift_storeEnumTagMultiPayload(v17, v16, 0);
      outlined assign with take of MLClassifierMetrics(v17, v18);
    }
    uint64_t v19 = *(void *)(v0 + 256);
    uint64_t v48 = *(void *)(v0 + 224);
    uint64_t v46 = *(void *)(v0 + 216);
    uint64_t v44 = *(void *)(v0 + 192);
    uint64_t v42 = *(void *)(v0 + 184);
    uint64_t v40 = *(void *)(v0 + 176);
    uint64_t v38 = *(void *)(v0 + 168);
    uint64_t v36 = *(void *)(v0 + 160);
    uint64_t v25 = *(void *)(v0 + 152);
    uint64_t v34 = *(void *)(v0 + 144);
    uint64_t v32 = *(void *)(v0 + 112);
    uint64_t v30 = *(void *)(v0 + 104);
    uint64_t v28 = *(void *)(v0 + 96);
    uint64_t v57 = *(void *)(v0 + 88);
    uint64_t v53 = *(void *)(v0 + 80);
    uint64_t v49 = *(void *)(v0 + 72);
    uint64_t v20 = *(void *)(v0 + 48);
    uint64_t v21 = *(void *)(v0 + 32);
    uint64_t v26 = *(void *)(v0 + 40);
    Swift::Int v22 = *(void *)(v21 + 16);
    Swift::Int v23 = *(void *)(v19 + 16);
    swift_bridgeObjectRelease(v19);
    static MLSoundClassifier.reportAnalytics(trainingExampleCount:classCount:parameters:)(v22, v23, v20);
    swift_release();
    outlined destroy of MLActivityClassifier.ModelParameters(v20, type metadata accessor for MLSoundClassifier.ModelParameters);
    swift_bridgeObjectRelease(v26);
    swift_bridgeObjectRelease(v21);
    outlined destroy of MLActivityClassifier.ModelParameters(v25, type metadata accessor for TrainingTablePrinter);
    outlined destroy of MLActivityClassifier.ModelParameters(v48, type metadata accessor for MLSoundClassifier.Classifier);
    swift_task_dealloc(v48);
    swift_task_dealloc(v46);
    swift_task_dealloc(v44);
    swift_task_dealloc(v42);
    swift_task_dealloc(v40);
    swift_task_dealloc(v38);
    swift_task_dealloc(v36);
    swift_task_dealloc(v25);
    swift_task_dealloc(v34);
    swift_task_dealloc(v32);
    swift_task_dealloc(v30);
    swift_task_dealloc(v28);
    swift_task_dealloc(v57);
    swift_task_dealloc(v53);
    swift_task_dealloc(v49);
    uint64_t v11 = *(uint64_t (**)(void))(v0 + 8);
  }
  return v11();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;

  Swift::Int v23 = *(void *)(v0 + 224);
  uint64_t v1 = *(void *)(v0 + 152);
  uint64_t v2 = *(void *)(v0 + 48);
  uint64_t v3 = *(void *)(v0 + 32);
  uint64_t v4 = *(void *)(v0 + 40);
  swift_release();
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLSoundClassifier.ModelParameters);
  swift_bridgeObjectRelease(v4);
  swift_bridgeObjectRelease(v3);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for TrainingTablePrinter);
  outlined destroy of MLActivityClassifier.ModelParameters(v23, type metadata accessor for MLSoundClassifier.Classifier);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 24), &demangling cache variable for type metadata for TrainingTablePrinter?);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 24) + *(int *)(*(void *)(v0 + 232) + 20), type metadata accessor for MLSoundClassifier.Model);
  if (!*(void *)(v0 + 248)) {
    outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 24) + *(int *)(*(void *)(v0 + 232) + 28), type metadata accessor for MLSoundClassifier.ModelParameters);
  }
  uint64_t v5 = *(void *)(v0 + 224);
  uint64_t v6 = *(void *)(v0 + 216);
  Swift::Int v22 = *(void *)(v0 + 192);
  uint64_t v21 = *(void *)(v0 + 184);
  uint64_t v20 = *(void *)(v0 + 176);
  uint64_t v19 = *(void *)(v0 + 168);
  uint64_t v18 = *(void *)(v0 + 160);
  uint64_t v16 = *(void *)(v0 + 152);
  uint64_t v14 = *(void *)(v0 + 144);
  uint64_t v13 = *(void *)(v0 + 112);
  uint64_t v7 = *(void *)(v0 + 24);
  uint64_t v8 = v7 + *(int *)(v0 + 308);
  uint64_t v17 = *(void *)(v0 + 104);
  uint64_t v15 = *(void *)(v0 + 96);
  uint64_t v12 = *(void *)(v0 + 88);
  uint64_t v11 = *(void *)(v0 + 80);
  uint64_t v10 = *(void *)(v0 + 72);
  outlined destroy of MLActivityClassifier.ModelParameters(v7 + *(int *)(v0 + 304), type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(v8, type metadata accessor for MLClassifierMetrics);
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v22);
  swift_task_dealloc(v21);
  swift_task_dealloc(v20);
  swift_task_dealloc(v19);
  swift_task_dealloc(v18);
  swift_task_dealloc(v16);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v17);
  swift_task_dealloc(v15);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  char v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  char *v13;
  void *v14;
  double v16;
  _OWORD *v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;

  uint64_t v17 = (_OWORD *)(v0 + 16);
  uint64_t v1 = *(void *)(v0 + 168);
  uint64_t v2 = *(void *)(v0 + 152);
  uint64_t v3 = *(void *)(v0 + 128);
  outlined init with copy of MLTrainingSessionParameters(*(void *)(v0 + 144), v1, type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v4 = *(void *)(v3 + 16);
  uint64_t v18 = *(void *)(v1 + *(int *)(v2 + 24));
  uint64_t v16 = MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.getter();
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1 + *(int *)(v2 + 28), v0 + 64, &demangling cache variable for type metadata for Any?);
  uint64_t v20 = v4;
  if (!*(void *)(v0 + 88))
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + 64, &demangling cache variable for type metadata for Any?);
    goto LABEL_5;
  }
  if (!swift_dynamicCast(v0 + 96, v0 + 64, (char *)&type metadata for Any + 8, &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType, 6))
  {
LABEL_5:
    uint64_t v6 = 1;
    uint64_t v5 = 1;
    LOBYTE(v7) = 0;
    goto LABEL_6;
  }
  uint64_t v5 = *(void *)(v0 + 96);
  uint64_t v6 = *(unsigned char *)(v0 + 104);
  uint64_t v7 = *(void *)(v0 + 112);
LABEL_6:
  uint64_t v8 = *(void *)(v0 + 128);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 168), type metadata accessor for MLSoundClassifier.ModelParameters);
  swift_bridgeObjectRelease(v7);
  *(void *)(v0 + 16) = v18;
  *(_OWORD *)(v0 + 24) = *(unint64_t *)&v16;
  *(void *)(v0 + 40) = v20;
  *(void *)(v0 + 48) = v5;
  *(unsigned char *)(v0 + 56) = v6;
  uint64_t v9 = type metadata accessor for MLSoundClassifier.FeatureExtractor();
  swift_allocObject(v9, 88, 7);
  swift_bridgeObjectRetain(v8);
  specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(v8, v17);
  uint64_t v21 = MLSoundClassifier.FeatureExtractor.extractFeatures()();
  uint64_t v19 = *(void *)(v0 + 136);
  swift_release();
  swift_allocObject(v9, 88, 7);
  swift_bridgeObjectRetain(v19);
  specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(v19, v17);
  uint64_t v10 = MLSoundClassifier.FeatureExtractor.extractFeatures()();
  uint64_t v11 = *(void *)(v0 + 144);
  uint64_t v12 = *(void *)(v0 + 160);
  swift_release();
  outlined init with copy of MLTrainingSessionParameters(v11, v12, type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v13 = (char *)&async function pointer to specialized MLSoundClassifier.init<A, B>(training:validation:parameters:)
      + async function pointer to specialized MLSoundClassifier.init<A, B>(training:validation:parameters:);
  uint64_t v14 = (void *)swift_task_alloc(dword_3ACEF4);
  *(void *)(v0 + 176) = v14;
  *uint64_t v14 = v0;
  v14[1] = specialized MLSoundClassifier.init<A, B>(training:validation:parameters:);
  return ((uint64_t (*)(void, uint64_t, uint64_t, void))v13)(*(void *)(v0 + 120), v21, v10, *(void *)(v0 + 160));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 176);
  *(void *)(*(void *)v1 + 184) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLSoundClassifier.init<A, B>(training:validation:parameters:);
  }
  else {
    uint64_t v3 = specialized MLSoundClassifier.init<A, B>(training:validation:parameters:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;

  uint64_t v1 = *(void *)(v0 + 168);
  uint64_t v2 = *(void *)(v0 + 160);
  uint64_t v3 = *(void *)(v0 + 128);
  uint64_t v4 = *(void *)(v0 + 136);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 144), type metadata accessor for MLSoundClassifier.ModelParameters);
  swift_bridgeObjectRelease(v4);
  swift_bridgeObjectRelease(v3);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;

  uint64_t v1 = *(void *)(v0 + 168);
  uint64_t v2 = *(void *)(v0 + 160);
  uint64_t v3 = *(void *)(v0 + 128);
  uint64_t v4 = *(void *)(v0 + 136);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 144), type metadata accessor for MLSoundClassifier.ModelParameters);
  swift_bridgeObjectRelease(v4);
  swift_bridgeObjectRelease(v3);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t closure #2 in MLSoundClassifier.init(trainingData:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v4[5] = a4;
  v4[4] = a3;
  v4[3] = a2;
  v4[2] = a1;
  uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  v4[6] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(closure #2 in MLSoundClassifier.init(trainingData:parameters:), 0, 0);
}

uint64_t closure #2 in MLSoundClassifier.init(trainingData:parameters:)()
{
  uint64_t v1 = v0[3];
  uint64_t v2 = (void *)v0[4];
  uint64_t v3 = v2;
  if (!v2) {
    uint64_t v3 = _swiftEmptyArrayStorage;
  }
  uint64_t v8 = v3;
  outlined init with copy of MLTrainingSessionParameters(v0[5], v0[6], type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v4 = (char *)&async function pointer to specialized MLSoundClassifier.init<A, B>(training:validation:parameters:)
     + async function pointer to specialized MLSoundClassifier.init<A, B>(training:validation:parameters:);
  uint64_t v5 = dword_3ACF2C;
  swift_bridgeObjectRetain(v1);
  swift_bridgeObjectRetain((_BYTE)v2);
  uint64_t v6 = (void *)swift_task_alloc(v5);
  v0[7] = v6;
  void *v6 = v0;
  v6[1] = closure #1 in closure #1 in closure #1 in closure #1 in static MLStyleTransfer.resume(_:);
  return ((uint64_t (*)(void, void, void *, void))v4)(v0[2], v0[3], v8, v0[6]);
}

uint64_t sub_245971()
{
  return objectdestroyTm_5();
}

uint64_t partial apply for closure #2 in MLSoundClassifier.init(trainingData:parameters:)(uint64_t a1)
{
  uint64_t v3 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  uint64_t v4 = *(void *)(v1 + 16);
  uint64_t v5 = *(void *)(v1 + 24);
  uint64_t v6 = v1
     + (~*(unsigned __int8 *)(*(void *)(v3 - 8) + 80) & (*(unsigned __int8 *)(*(void *)(v3 - 8)
                                                                                              + 80)
                                                           + 32));
  uint64_t v7 = (void *)swift_task_alloc(dword_3ACDB4);
  *(void *)(v2 + 16) = v7;
  *uint64_t v7 = v2;
  v7[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #2 in MLSoundClassifier.init(trainingData:parameters:)(a1, v4, v5, v6);
}

uint64_t sub_245A0D()
{
  return objectdestroyTm_5();
}

uint64_t objectdestroyTm_5()
{
  uint64_t v1 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  uint64_t v2 = *(void *)(v1 - 8);
  uint64_t v3 = *(unsigned __int8 *)(v2 + 80);
  uint64_t v4 = ~*(unsigned __int8 *)(v2 + 80) & (v3 + 32);
  uint64_t v14 = *(void *)(v2 + 64);
  swift_bridgeObjectRelease(*(void *)(v0 + 16));
  swift_bridgeObjectRelease(*(void *)(v0 + 24));
  uint64_t v5 = v4 + v0;
  uint64_t v6 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v4 + v0, v6);
  if (EnumCaseMultiPayload == 2)
  {
LABEL_5:
    uint64_t v10 = *(void *)v5;
LABEL_6:
    swift_bridgeObjectRelease(v10);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v8 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(v4 + v0, v8))
    {
      case 0u:
      case 1u:
        uint64_t v9 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(v4 + v0, v9);
        break;
      case 2u:
        goto LABEL_5;
      case 3u:
        outlined consume of Result<_DataTable, Error>(*(void *)v5, *(_DWORD *)(v5 + 8));
        swift_bridgeObjectRelease(*(void *)(v5 + 24));
        uint64_t v10 = *(void *)(v5 + 40);
        goto LABEL_6;
      case 4u:
        uint64_t v13 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v13 - 8) + 8))(v4 + v0, v13);
        uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        swift_bridgeObjectRelease(*(void *)(v5 + *(int *)(v15 + 48) + 8));
        uint64_t v10 = *(void *)(v5 + *(int *)(v15 + 64) + 8);
        goto LABEL_6;
      default:
        break;
    }
  }
  uint64_t v11 = *(int *)(v1 + 28);
  if (*(void *)(v5 + v11 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(v11 + v5));
  }
  return swift_deallocObject(v0, v14 + v4, v3 | 7);
}

uint64_t partial apply for closure #1 in MLSoundClassifier.init(trainingData:parameters:)(uint64_t a1)
{
  uint64_t v3 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  uint64_t v4 = *(void *)(v1 + 16);
  uint64_t v5 = *(void *)(v1 + 24);
  uint64_t v6 = v1
     + (~*(unsigned __int8 *)(*(void *)(v3 - 8) + 80) & (*(unsigned __int8 *)(*(void *)(v3 - 8)
                                                                                              + 80)
                                                           + 32));
  uint64_t v7 = (void *)swift_task_alloc(dword_3ACDC4);
  *(void *)(v2 + 16) = v7;
  *uint64_t v7 = v2;
  v7[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLSoundClassifier.init(trainingData:parameters:)(a1, v4, v5, v6);
}

uint64_t specialized closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v6[7] = a6;
  v6[6] = a5;
  v6[5] = a4;
  v6[4] = a3;
  v6[3] = a2;
  v6[2] = a1;
  uint64_t v7 = *(void *)(type metadata accessor for TrainingTablePrinter(0) - 8);
  v6[8] = v7;
  uint64_t v8 = *(void *)(v7 + 64);
  v6[9] = v8;
  v6[10] = swift_task_alloc((v8 + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:), 0, 0);
}

uint64_t specialized closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:)()
{
  uint64_t v1 = v0[10];
  uint64_t v2 = v0[9];
  uint64_t v3 = v0[8];
  uint64_t v4 = v0[6];
  outlined init with copy of MLTrainingSessionParameters(v0[7], v1, type metadata accessor for TrainingTablePrinter);
  uint64_t v5 = *(unsigned __int8 *)(v3 + 80);
  uint64_t v6 = ~*(unsigned __int8 *)(v3 + 80) & (v5 + 24);
  uint64_t v7 = swift_allocObject(&unk_39BFD0, v6 + v2, v5 | 7);
  v0[11] = v7;
  *(void *)(v7 + 16) = v4;
  outlined init with take of MLClassifierMetrics(v1, v7 + v6, type metadata accessor for TrainingTablePrinter);
  uint64_t v8 = (char *)&async function pointer to specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)
     + async function pointer to specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  uint64_t v9 = dword_3A745C;
  swift_retain();
  uint64_t v10 = (void *)swift_task_alloc(v9);
  v0[12] = v10;
  *uint64_t v10 = v0;
  v10[1] = specialized closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:);
  return ((uint64_t (*)(void, void, void, uint64_t (*)(uint64_t), uint64_t))v8)(v0[2], v0[4], v0[5], partial apply for closure #1 in closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:), v7);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v2 = *(void *)(*v1 + 96);
  uint64_t v3 = *v1;
  *(void *)(v3 + 104) = v0;
  swift_task_dealloc(v2);
  swift_release();
  if (v0) {
    return swift_task_switch(specialized closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:), 0, 0);
  }
  swift_task_dealloc(*(void *)(v3 + 80));
  return (*(uint64_t (**)(void))(v3 + 8))();
}

{
  uint64_t v0;

  swift_task_dealloc(*(void *)(v0 + 80));
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t specialized closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  v5[6] = a5;
  v5[5] = a4;
  v5[4] = a3;
  v5[3] = a2;
  v5[2] = a1;
  uint64_t v6 = *(void *)(type metadata accessor for TrainingTablePrinter(0) - 8);
  v5[7] = v6;
  uint64_t v7 = *(void *)(v6 + 64);
  v5[8] = v7;
  v5[9] = swift_task_alloc((v7 + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:), 0, 0);
}

uint64_t specialized closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:)()
{
  uint64_t v1 = v0[9];
  uint64_t v2 = v0[8];
  uint64_t v3 = v0[7];
  uint64_t v4 = v0[5];
  outlined init with copy of MLTrainingSessionParameters(v0[6], v1, type metadata accessor for TrainingTablePrinter);
  uint64_t v5 = *(unsigned __int8 *)(v3 + 80);
  uint64_t v6 = ~*(unsigned __int8 *)(v3 + 80) & (v5 + 24);
  uint64_t v7 = swift_allocObject(&unk_39BFA8, v6 + v2, v5 | 7);
  v0[10] = v7;
  *(void *)(v7 + 16) = v4;
  outlined init with take of MLClassifierMetrics(v1, v7 + v6, type metadata accessor for TrainingTablePrinter);
  uint64_t v8 = (char *)&async function pointer to specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:)
     + async function pointer to specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
  uint64_t v9 = dword_3A746C;
  swift_retain();
  uint64_t v10 = (void *)swift_task_alloc(v9);
  v0[11] = v10;
  *uint64_t v10 = v0;
  v10[1] = specialized closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:);
  return ((uint64_t (*)(void, void, uint64_t (*)(uint64_t), uint64_t))v8)(v0[2], v0[4], partial apply for closure #1 in closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:), v7);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v2 = *(void *)(*v1 + 88);
  uint64_t v3 = *v1;
  *(void *)(v3 + 96) = v0;
  swift_task_dealloc(v2);
  swift_release();
  if (v0) {
    return swift_task_switch(specialized closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:), 0, 0);
  }
  swift_task_dealloc(*(void *)(v3 + 72));
  return (*(uint64_t (**)(void))(v3 + 8))();
}

{
  uint64_t v0;

  swift_task_dealloc(*(void *)(v0 + 72));
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t specialized MLSoundClassifier.evaluate<A>(on:)(uint64_t a1)
{
  uint64_t v27 = v2;
  uint64_t v28 = a1;
  uint64_t v29 = v1;
  uint64_t v4 = *(void *)(type metadata accessor for MLSoundClassifier(0) - 8);
  int64_t v5 = *(void *)(v4 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  outlined init with copy of MLTrainingSessionParameters(v3, (uint64_t)&v22, type metadata accessor for MLSoundClassifier);
  uint64_t v8 = *(unsigned __int8 *)(v4 + 80);
  uint64_t v9 = ~*(unsigned __int8 *)(v4 + 80) & (v8 + 16);
  unint64_t v10 = (v9 + v5 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v11 = swift_allocObject(&unk_39BF08, v10 + 8, v8 | 7);
  uint64_t v12 = v11 + v9;
  uint64_t v13 = v28;
  outlined init with take of MLClassifierMetrics((uint64_t)&v22, v12, type metadata accessor for MLSoundClassifier);
  *(void *)(v11 + v10) = v13;
  swift_bridgeObjectRetain(v13);
  uint64_t v14 = v27;
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for specialized closure #1 in MLSoundClassifier.evaluate<A>(on:), v11);
  uint64_t v16 = v15;
  uint64_t result = swift_release();
  if (!v14)
  {
    MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v16, (uint64_t)v23, &demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>, (uint64_t)&unk_34FC40);
    swift_bridgeObjectRelease(v16);
    uint64_t v26 = MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
    uint64_t v25 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v13, (uint64_t)v24, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>, (uint64_t)&unk_34FC08);
    uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
    uint64_t v20 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [String] and conformance [A], &demangling cache variable for type metadata for [String], (uint64_t)&protocol conformance descriptor for [A]);
    ClassificationMetrics.init<A, B>(_:_:)(&v26, &v25, &type metadata for String, v19, v19, &protocol witness table for String, v20, v20);
    return v21;
  }
  return result;
}

char static MLSoundClassifier.reportAnalytics(trainingExampleCount:classCount:parameters:)(Swift::Int quantity, Swift::Int a2, uint64_t a3)
{
  char result = AnalyticsReporter.init()();
  if (result) {
    return result;
  }
  AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_soundClassifier, (Swift::String)__PAIR128__((unint64_t)(" training session" + 0x8000000000000000), 0xD000000000000011), quantity);
  AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_soundClassifier, (Swift::String)__PAIR128__((unint64_t)("Number of Images" + 0x8000000000000000), 0xD000000000000011), a2);
  int64_t v5 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_soundClassifier, (Swift::String)__PAIR128__(0xEE00736E6F697461, 0x726574492078614DLL), *(void *)(a3 + v5[5]));
  Swift::Float v6 = *(double *)(a3 + v5[6]);
  AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_soundClassifier, (Swift::String)__PAIR128__(0xEE00726F74636146, 0x2070616C7265764FLL), v6);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a3 + v5[7], (uint64_t)&v16, &demangling cache variable for type metadata for Any?);
  if (!v17)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v16, &demangling cache variable for type metadata for Any?);
    goto LABEL_6;
  }
  if (!swift_dynamicCast(&v18, &v16, (char *)&type metadata for Any + 8, &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType, 6))
  {
LABEL_6:
    char v8 = 1;
    uint64_t v7 = 1;
    uint64_t v9 = 0;
    goto LABEL_7;
  }
  uint64_t v7 = v18;
  char v8 = v19;
  uint64_t v9 = v20;
LABEL_7:
  v16._countAndFlagsBits = v7;
  LOBYTE(v16._object) = v8 & 1;
  swift_bridgeObjectRetain(v9);
  unint64_t v21 = MLSoundClassifier.ModelParameters.FeatureExtractorType.description.getter();
  uint64_t v11 = v10;
  if (v9)
  {
    swift_bridgeObjectRelease(v9);
    uint64_t v12 = "Feature Extractor: " + 0x8000000000000000;
    uint64_t v13 = 0xD000000000000015;
  }
  else
  {
    swift_bridgeObjectRelease(0);
    uint64_t v12 = "Multilayer Perceptron" + 0x8000000000000000;
    uint64_t v13 = 0xD000000000000012;
  }
  v16._countAndFlagsBits = v21;
  v16._char object = v11;
  swift_bridgeObjectRetain((_BYTE)v11);
  v14._countAndFlagsBits = v13;
  v14._char object = v12;
  String.append(_:)(v14);
  swift_bridgeObjectRelease(v9);
  swift_bridgeObjectRelease((_BYTE)v11);
  swift_bridgeObjectRelease((_BYTE)v12);
  char object = (char)v16._object;
  AnalyticsReporter.reportParameterSettings(model:parameterName:parameterValue:)(CreateML_ModelType_soundClassifier, (Swift::String)__PAIR128__(0xE90000000000006DLL, 0x687469726F676C41), v16);
  return swift_bridgeObjectRelease(object);
}

uint64_t MLSoundClassifier.init(checkpoint:)(uint64_t a1)
{
  uint64_t v110 = v2;
  uint64_t v114 = a1;
  uint64_t v3 = v1;
  uint64_t v97 = *(void *)(type metadata accessor for MLSoundClassifier.Model(0) - 8);
  int64_t v4 = *(void *)(v97 + 64);
  int64_t v5 = alloca(v4);
  Swift::Float v6 = alloca(v4);
  v95 = &v86;
  int64_t v96 = v4;
  uint64_t v7 = alloca(v4);
  char v8 = alloca(v4);
  v104 = &v86;
  uint64_t v92 = type metadata accessor for MLSoundClassifier.Classifier(0);
  int64_t v9 = *(void *)(*(void *)(v92 - 8) + 64);
  unint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  v105 = &v86;
  uint64_t v94 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  int64_t v12 = *(void *)(*(void *)(v94 - 8) + 64);
  uint64_t v13 = alloca(v12);
  Swift::String v14 = alloca(v12);
  v93 = &v86;
  int64_t v15 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0) - 8)
                  + 64);
  Swift::String v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  v101 = &v86;
  uint64_t v106 = type metadata accessor for MLSoundClassifier.PersistentParameters(0);
  int64_t v18 = *(void *)(*(void *)(v106 - 8) + 64);
  char v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  v109 = &v86;
  uint64_t v108 = type metadata accessor for URL(0);
  uint64_t v102 = *(void *)(v108 - 8);
  int64_t v21 = *(void *)(v102 + 64);
  uint64_t v22 = alloca(v21);
  Swift::Int v23 = alloca(v21);
  v103 = &v86;
  v24 = alloca(v21);
  uint64_t v25 = alloca(v21);
  v113 = &v86;
  uint64_t v26 = alloca(v21);
  uint64_t v27 = alloca(v21);
  v111 = &v86;
  uint64_t v28 = alloca(v21);
  uint64_t v29 = alloca(v21);
  v115 = &v86;
  uint64_t v30 = type metadata accessor for TrainingTablePrinter(0);
  __swift_storeEnumTagSinglePayload(v3, 1, 1, v30);
  uint64_t v31 = type metadata accessor for MLSoundClassifier(0);
  uint64_t v107 = v3 + *(int *)(v31 + 32);
  MLClassifierMetrics.init()();
  uint64_t v100 = v31;
  uint64_t v32 = *(int *)(v31 + 36);
  uint64_t v33 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v34 = swift_allocError(&type metadata for MLCreateError, v33, 0, 0);
  *(void *)uint64_t v35 = 0xD0000000000000C0;
  *(void *)(v35 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v35 + 16) = 0;
  *(_OWORD *)(v35 + 32) = 0;
  *(unsigned char *)(v35 + 48) = 0;
  uint64_t v112 = v3;
  *(void *)(v3 + v32) = v34;
  uint64_t v36 = type metadata accessor for MLClassifierMetrics.Contents(0);
  uint64_t v91 = v32 + v3;
  swift_storeEnumTagMultiPayload(v32 + v3, v36, 2);
  switch(*(unsigned char *)(v114 + *(int *)(type metadata accessor for MLCheckpoint(0) + 20)))
  {
    case 0:
      uint64_t v37 = v33;
      uint64_t v38 = 0x696C616974696E69;
      uint64_t v39 = v115;
      unint64_t v40 = 0xEB0000000064657ALL;
      goto LABEL_9;
    case 1:
      uint64_t v37 = v33;
      uint64_t v38 = 0x6974636172747865;
      goto LABEL_6;
    case 2:
      unint64_t v41 = 0xE800000000000000;
      swift_bridgeObjectRelease(0);
      uint64_t v39 = v115;
      goto LABEL_10;
    case 3:
      uint64_t v37 = v33;
      uint64_t v38 = 0x697461756C617665;
LABEL_6:
      unint64_t v40 = 0xEA0000000000676ELL;
      break;
    case 4:
      uint64_t v37 = v33;
      unint64_t v40 = 0xEB00000000676E69;
      uint64_t v38 = 0x636E657265666E69;
      break;
  }
  uint64_t v39 = v115;
LABEL_9:
  char v42 = _stringCompareWithSmolCheck(_:_:expecting:)(v38, v40, 0x676E696E69617274, 0xE800000000000000, 0);
  unint64_t v41 = v40;
  swift_bridgeObjectRelease(v40);
  if ((v42 & 1) == 0)
  {
    char v50 = 0;
    swift_allocError(&type metadata for MLCreateError, v37, 0, 0);
    *(void *)uint64_t v54 = 0xD00000000000003BLL;
    *(void *)(v54 + 8) = "s not contain string elements." + 0x8000000000000000;
    *(_OWORD *)(v54 + 16) = 0;
    *(_OWORD *)(v54 + 32) = 0;
    *(unsigned char *)(v54 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v37, v54, v55, v56, v57);
    outlined destroy of MLActivityClassifier.ModelParameters(v114, type metadata accessor for MLCheckpoint);
LABEL_16:
    uint64_t v52 = v112;
    uint64_t v53 = v107;
    goto LABEL_17;
  }
LABEL_10:
  uint64_t v43 = v39;
  URL.deletingLastPathComponent()(v41);
  uint64_t v44 = v113;
  URL.appendingPathComponent(_:)(0x6C65646F6DLL, 0xE500000000000000);
  URL.appendingPathExtension(_:)(6777712, 0xE300000000000000);
  uint64_t v45 = v102;
  uint64_t v46 = v108;
  v113 = *(uint64_t **)(v102 + 8);
  ((void (*)(uint64_t *, uint64_t))v113)(v44, v108);
  uint64_t v47 = (uint64_t)v103;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v45 + 16))(v103, v43, v46);
  uint64_t v48 = (uint64_t)v109;
  uint64_t v49 = v110;
  MLSoundClassifier.PersistentParameters.init(sessionDirectory:)(v47);
  uint64_t v110 = v49;
  if (!v49)
  {
    uint64_t v102 = v112 + *(int *)(v100 + 28);
    uint64_t v58 = (int *)v106;
    outlined init with copy of MLTrainingSessionParameters(*(int *)(v106 + 20) + v48, (uint64_t)v101, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v98 = *(void *)(v48 + v58[8]);
    uint64_t v99 = *(void *)(v48 + v58[6]);
    uint64_t v59 = v58[9];
    v103 = *(uint64_t **)(v48 + v59);
    LOBYTE(v106) = *(unsigned char *)(v48 + v59 + 8);
    v60 = (int *)v94;
    uint64_t v61 = *(int *)(v94 + 28);
    uint64_t v62 = (uint64_t)v93;
    uint64_t v63 = (uint64_t)v93 + v61;
    *(_OWORD *)((char *)v93 + v61) = 0;
    *(_OWORD *)(v62 + v61 + 16) = 0;
    uint64_t v64 = v60[8];
    *(void *)(v62 + v64) = 0;
    uint64_t v65 = *(void *)(v48 + v59 + 16);
    *(unsigned char *)(v62 + v64 + 8) = 1;
    *(void *)(v62 + v60[9]) = 32;
    outlined init with copy of MLTrainingSessionParameters((uint64_t)v101, v62, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    *(void *)(v62 + v60[5]) = v98;
    *(void *)(v62 + v60[6]) = v99;
    uint64_t v90 = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
    uint64_t v87 = v103;
    char v88 = v106;
    uint64_t v89 = v65;
    swift_bridgeObjectRetain(v65);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)&v87, v63, &demangling cache variable for type metadata for Any?);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v101, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v66 = v102;
    outlined init with take of MLClassifierMetrics(v62, v102, type metadata accessor for MLSoundClassifier.ModelParameters);
    outlined init with copy of MLTrainingSessionParameters(v66, v62, type metadata accessor for MLSoundClassifier.ModelParameters);
    uint64_t v67 = (uint64_t)v105;
    MLSoundClassifier.Classifier.init(labels:parameters:)((uint64_t)&_swiftEmptySetSingleton, v62);
    uint64_t v68 = lazy protocol witness table accessor for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier();
    uint64_t v69 = (uint64_t)v104;
    uint64_t v70 = v111;
    uint64_t v71 = v110;
    UpdatableSupervisedEstimator.readWithOptimizer(from:)(v111, v92, v68);
    if (!v71)
    {
      uint64_t v73 = (uint64_t)v95;
      outlined init with copy of MLTrainingSessionParameters(v69, (uint64_t)v95, type metadata accessor for MLSoundClassifier.Model);
      uint64_t v74 = *(unsigned __int8 *)(v97 + 80);
      uint64_t v75 = ~*(unsigned __int8 *)(v97 + 80) & (v74 + 16);
      uint64_t v76 = swift_allocObject(&unk_39BEA8, v75 + v96, v74 | 7);
      outlined init with take of MLClassifierMetrics(v73, v76 + v75, type metadata accessor for MLSoundClassifier.Model);
      specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLSoundClassifier.init(checkpoint:), v76);
      uint64_t v80 = v79;
      swift_release();
      outlined destroy of MLActivityClassifier.ModelParameters(v114, type metadata accessor for MLCheckpoint);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v105, type metadata accessor for MLSoundClassifier.Classifier);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v109, type metadata accessor for MLSoundClassifier.PersistentParameters);
      uint64_t v81 = v108;
      uint64_t v82 = v113;
      ((void (*)(uint64_t *, uint64_t))v113)(v111, v108);
      ((void (*)(uint64_t *, uint64_t))v82)(v115, v81);
      uint64_t v83 = v100;
      uint64_t v84 = v112;
      *(void *)(v112 + *(int *)(v100 + 24)) = v80;
      return outlined init with take of MLClassifierMetrics((uint64_t)v104, v84 + *(int *)(v83 + 20), type metadata accessor for MLSoundClassifier.Model);
    }
    outlined destroy of MLActivityClassifier.ModelParameters(v114, type metadata accessor for MLCheckpoint);
    outlined destroy of MLActivityClassifier.ModelParameters(v67, type metadata accessor for MLSoundClassifier.Classifier);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v109, type metadata accessor for MLSoundClassifier.PersistentParameters);
    uint64_t v72 = v70;
    uint64_t v77 = v108;
    uint64_t v78 = v113;
    ((void (*)(uint64_t *, uint64_t))v113)(v72, v108);
    ((void (*)(uint64_t *, uint64_t))v78)(v115, v77);
    char v50 = 1;
    goto LABEL_16;
  }
  char v50 = 0;
  outlined destroy of MLActivityClassifier.ModelParameters(v114, type metadata accessor for MLCheckpoint);
  uint64_t v51 = v113;
  ((void (*)(uint64_t *, uint64_t))v113)(v111, v46);
  ((void (*)(uint64_t *, uint64_t))v51)(v115, v46);
  uint64_t v52 = v112;
  uint64_t v53 = v107;
LABEL_17:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v52, &demangling cache variable for type metadata for TrainingTablePrinter?);
  if (v50) {
    outlined destroy of MLActivityClassifier.ModelParameters(*(int *)(v100 + 28) + v52, type metadata accessor for MLSoundClassifier.ModelParameters);
  }
  outlined destroy of MLActivityClassifier.ModelParameters(v53, type metadata accessor for MLClassifierMetrics);
  return outlined destroy of MLActivityClassifier.ModelParameters(v91, type metadata accessor for MLClassifierMetrics);
}

uint64_t closure #1 in MLSoundClassifier.init(checkpoint:)(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
  uint64_t v2 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                         + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v3 = (void *)swift_task_alloc(dword_3AE254);
  *(void *)(v1 + 24) = v3;
  void *v3 = v1;
  v3[1] = closure #1 in MLRandomForestRegressor.init(checkpoint:);
  return v2();
}

void *static MLSoundClassifier.train(trainingData:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  int64_t v4 = (void *)a2;
  uint64_t v5 = MLSoundClassifier.DataSource.labeledSounds()(a1, a2, a3);
  if (!v3)
  {
    char v6 = v5;
    int64_t v4 = static MLSoundClassifier.train(trainingData:parameters:sessionParameters:)(v5, a2, a3);
    swift_bridgeObjectRelease(v6);
  }
  return v4;
}

{
  uint64_t v3;
  uint64_t v6;
  int64_t v7;
  void *v8;
  void *v9;
  uint64_t v10;
  uint64_t v11;
  void *result;
  uint64_t v13;
  void *v14;
  uint64_t v15;

  char v6 = type metadata accessor for MLSoundClassifier.DataSource(0);
  uint64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  char v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  int64_t v15 = a1;
  swift_storeEnumTagMultiPayload(&v15, v6, 2);
  swift_bridgeObjectRetain(a1);
  static MLSoundClassifier.makeTrainingSession(trainingData:parameters:sessionParameters:)((uint64_t)&v15, a2, a3);
  uint64_t v11 = v10;
  char result = (void *)outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v15, type metadata accessor for MLSoundClassifier.DataSource);
  if (!v3)
  {
    uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLSoundClassifier>);
    Swift::String v14 = (void *)swift_allocObject(v13, *(unsigned int *)(v13 + 48), *(unsigned __int16 *)(v13 + 52));
    return specialized MLJob.init(_:)(v14, v11);
  }
  return result;
}

void static MLSoundClassifier.makeTrainingSession(trainingData:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v44 = a3;
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  char v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  unint64_t v41 = &v31;
  char v8 = alloca(v5);
  int64_t v9 = alloca(v5);
  uint64_t v39 = &v31;
  int64_t v10 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0) - 8)
                  + 64);
  uint64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  uint64_t v43 = &v31;
  uint64_t v13 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  int64_t v14 = *(void *)(*((void *)v13 - 1) + 64);
  int64_t v15 = alloca(v14);
  Swift::String v16 = alloca(v14);
  unint64_t v40 = &v31;
  int64_t v17 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.DataSource(0) - 8) + 64);
  int64_t v18 = alloca(v17);
  char v19 = alloca(v17);
  char v42 = &v31;
  MLSoundClassifier.ModelParameters.validate()();
  if (!v20)
  {
    MLSoundClassifier.ModelParameters.ValidationData.validate(modelParameters:)(a2);
    double v45 = MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.getter();
    outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v42, type metadata accessor for MLSoundClassifier.DataSource);
    outlined init with copy of MLTrainingSessionParameters(a2, (uint64_t)v43, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v21 = *(void *)(a2 + v13[5]);
    double v46 = *(double *)(a2 + v13[6]);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a2 + v13[7], (uint64_t)&v31, &demangling cache variable for type metadata for Any?);
    if (v34)
    {
      if (swift_dynamicCast(&v36, &v31, (char *)&type metadata for Any + 8, &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType, 6))
      {
        uint64_t v22 = v36;
        char v23 = v37;
        uint64_t v24 = v38;
LABEL_7:
        uint64_t v31 = (void *)v22;
        char v32 = v23 & 1;
        uint64_t v33 = v24;
        uint64_t v25 = (uint64_t)v40;
        MLSoundClassifier.ModelParameters.init(validation:maxIterations:overlapFactor:algorithm:featureExtractionTimeWindowSize:)((uint64_t)v43, v21, (uint64_t)&v31, v46, v45);
        uint64_t v26 = (uint64_t)v39;
        outlined init with copy of MLTrainingSessionParameters(v44, (uint64_t)v39, type metadata accessor for MLTrainingSessionParameters);
        uint64_t v27 = type metadata accessor for SoundClassifierTrainingSessionDelegate(0);
        swift_allocObject(v27, *(unsigned int *)(v27 + 48), *(unsigned __int16 *)(v27 + 52));
        uint64_t v28 = SoundClassifierTrainingSessionDelegate.init(trainingData:featureExtractionOnly:modelParameters:sessionParameters:)((uint64_t)v42, 0, v25, v26);
        uint64_t v34 = v27;
        uint64_t v35 = &protocol witness table for SoundClassifierTrainingSessionDelegate;
        uint64_t v31 = v28;
        uint64_t v29 = (uint64_t)v41;
        outlined init with copy of MLTrainingSessionParameters(v44, (uint64_t)v41, type metadata accessor for MLTrainingSessionParameters);
        uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>);
        swift_allocObject(v30, *(unsigned int *)(v30 + 48), *(unsigned __int16 *)(v30 + 52));
        specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)&v31, v29, 19);
        return;
      }
    }
    else
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v31, &demangling cache variable for type metadata for Any?);
    }
    char v23 = 1;
    uint64_t v22 = 1;
    uint64_t v24 = 0;
    goto LABEL_7;
  }
}

void *static MLSoundClassifier.resume(_:)(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLSoundClassifier>);
  uint64_t v2 = (void *)swift_allocObject(v1, *(unsigned int *)(v1 + 48), *(unsigned __int16 *)(v1 + 52));
  swift_retain();
  return specialized MLJob.init(_:)(v2, a1);
}

void *static MLSoundClassifier.extractFeatures(trainingData:parameters:sessionParameters:)(uint64_t a1, long long *a2, uint64_t a3)
{
  char v13 = *((unsigned char *)a2 + 32);
  long long v4 = *a2;
  v12[1] = a2[1];
  v12[0] = v4;
  char v11 = *((unsigned char *)a2 + 32);
  long long v5 = *a2;
  v10[1] = a2[1];
  v10[0] = v5;
  char result = (void *)static MLSoundClassifier.makeFeatureExtractionSession(trainingData:parameters:sessionParameters:)(a1, (uint64_t)v10, a3);
  if (!v3)
  {
    uint64_t v7 = (uint64_t)result;
    uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLSoundClassifier.DataSource>);
    int64_t v9 = (void *)swift_allocObject(v8, *(unsigned int *)(v8 + 48), *(unsigned __int16 *)(v8 + 52));
    return specialized MLJob.init(_:)(v9, v7, (uint64_t)v12);
  }
  return result;
}

uint64_t static MLSoundClassifier.makeFeatureExtractionSession(trainingData:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v38 = v3;
  uint64_t v45 = a3;
  uint64_t v47 = (long long *)a1;
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  long long v5 = alloca(v4);
  char v6 = alloca(v4);
  uint64_t v44 = &v33;
  uint64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  uint64_t v39 = &v33;
  int64_t v9 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.DataSource(0) - 8) + 64);
  int64_t v10 = alloca(v9);
  char v11 = alloca(v9);
  unint64_t v40 = &v33;
  uint64_t v42 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int64_t v12 = *(void *)(*(void *)(v42 - 8) + 64);
  char v13 = alloca(v12);
  int64_t v14 = alloca(v12);
  int64_t v15 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.ModelParameters(0) - 8) + 64);
  Swift::String v16 = alloca(v15);
  int64_t v17 = alloca(v15);
  unint64_t v41 = &v33;
  int64_t v18 = alloca(v15);
  char v19 = alloca(v15);
  double v43 = *(double *)a2;
  double v20 = *(double *)(a2 + 8);
  uint64_t v21 = *(void *)(a2 + 24);
  char v22 = *(unsigned char *)(a2 + 32);
  BOOL v23 = *(unsigned char *)(a2 + 16) == 0;
  long long v33 = 0;
  __int16 v34 = 256;
  if (v23) {
    double v46 = v20;
  }
  else {
    double v46 = 0.975;
  }
  swift_storeEnumTagMultiPayload(&v33, v42, 0);
  *((void *)&v33 + 1) = v21;
  LOBYTE(v34) = v22;
  uint64_t v35 = 0;
  MLSoundClassifier.ModelParameters.init(validation:maxIterations:overlapFactor:algorithm:featureExtractionTimeWindowSize:)((uint64_t)&v33, 25, (uint64_t)&v33 + 8, v43, v46);
  uint64_t v24 = (uint64_t)v40;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v47, (uint64_t)v40, type metadata accessor for MLSoundClassifier.DataSource);
  uint64_t v47 = &v33;
  uint64_t v25 = (uint64_t)v41;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)&v33, (uint64_t)v41, type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v26 = (uint64_t)v39;
  outlined init with copy of MLTrainingSessionParameters(v45, (uint64_t)v39, type metadata accessor for MLTrainingSessionParameters);
  uint64_t v27 = type metadata accessor for SoundClassifierTrainingSessionDelegate(0);
  swift_allocObject(v27, *(unsigned int *)(v27 + 48), *(unsigned __int16 *)(v27 + 52));
  uint64_t v28 = v38;
  uint64_t v29 = SoundClassifierTrainingSessionDelegate.init(trainingData:featureExtractionOnly:modelParameters:sessionParameters:)(v24, 1, v25, v26);
  if (v28)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v47, type metadata accessor for MLSoundClassifier.ModelParameters);
  }
  else
  {
    uint64_t v36 = v27;
    char v37 = &protocol witness table for SoundClassifierTrainingSessionDelegate;
    *((void *)&v33 + 1) = v29;
    uint64_t v30 = (uint64_t)v44;
    outlined init with copy of MLTrainingSessionParameters(v45, (uint64_t)v44, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier.DataSource>);
    swift_allocObject(v31, *(unsigned int *)(v31 + 48), *(unsigned __int16 *)(v31 + 52));
    swift_retain();
    uint64_t v27 = specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)&v33 + 8, v30, 19);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v47, type metadata accessor for MLSoundClassifier.ModelParameters);
    swift_release();
  }
  return v27;
}

uint64_t closure #1 in closure #1 in static MLSoundClassifier.extractFeatures(trainingData:parameters:sessionParameters:)(uint64_t a1, char a2, uint64_t a3, uint64_t a4, void (*a5)(uint64_t *), uint64_t a6)
{
  uint64_t v34 = a6;
  uint64_t v27 = a4;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLSoundClassifier.DataSource, Error>);
  int64_t v9 = *(void *)(*(void *)(v8 - 8) + 64);
  int64_t v10 = alloca(v9);
  char v11 = alloca(v9);
  if (a2)
  {
    uint64_t v24 = a1;
    swift_storeEnumTagMultiPayload(&v24, v8, 1);
    swift_errorRetain(a1);
    a5(&v24);
  }
  else
  {
    uint64_t v28 = v8;
    outlined init with copy of TabularRegressionTask(direct field offset for MLTrainingSession.delegate + a3, (uint64_t)v25);
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingSessionDelegate);
    uint64_t v32 = type metadata accessor for SoundClassifierTrainingSessionDelegate(0);
    swift_dynamicCast(&v26, v25, v12, v32, 7);
    uint64_t v29 = &v24;
    uint64_t v13 = v26;
    uint64_t v31 = v26;
    int64_t v14 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
    uint64_t v30 = a5;
    uint64_t v15 = v14[12];
    uint64_t v33 = v14[16];
    uint64_t v16 = v14[20];
    uint64_t v17 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures;
    swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures + v13, v25, 0, 0);
    uint64_t v18 = *(void *)(v13 + v17);
    swift_bridgeObjectRetain(v18);
    static SoundClassifierTrainingSessionDelegate.createDataFrame(from:)(v18);
    swift_bridgeObjectRelease(v18);
    *(void *)&v25[v15 - 8] = 0x7365727574616566;
    *(void *)&v25[v15] = 0xE800000000000000;
    uint64_t v19 = v33;
    *(void *)&v25[v33 - 8] = 0x62614C7373616C63;
    *(void *)&v25[v19] = 0xEA00000000006C65;
    double v20 = (long long *)v27;
    v25[v16 + 24] = *(unsigned char *)(v27 + 32);
    long long v21 = *v20;
    *(_OWORD *)&v25[v16 + 8] = v20[1];
    *(_OWORD *)&v25[v16 - 8] = v21;
    uint64_t v22 = type metadata accessor for MLSoundClassifier.DataSource(0);
    swift_storeEnumTagMultiPayload(&v24, v22, 4);
    swift_storeEnumTagMultiPayload(&v24, v28, 0);
    v30(&v24);
    swift_release();
  }
  return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v24, &demangling cache variable for type metadata for Result<MLSoundClassifier.DataSource, Error>);
}

uint64_t static MLSoundClassifier.restoreTrainingSession(sessionParameters:)(uint64_t a1)
{
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  uint64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  uint64_t v12 = v11;
  long long v5 = alloca(v2);
  char v6 = alloca(v2);
  outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v11, type metadata accessor for MLTrainingSessionParameters);
  uint64_t v7 = type metadata accessor for SoundClassifierTrainingSessionDelegate(0);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  uint64_t result = SoundClassifierTrainingSessionDelegate.init(sessionParameters:)((uint64_t)v11);
  if (!v1)
  {
    v11[3] = v7;
    v11[4] = &protocol witness table for SoundClassifierTrainingSessionDelegate;
    v11[0] = result;
    uint64_t v9 = (uint64_t)v12;
    outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v12, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLSoundClassifier>);
    swift_allocObject(v10, *(unsigned int *)(v10 + 48), *(unsigned __int16 *)(v10 + 52));
    return specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)v11, v9, 19);
  }
  return result;
}

uint64_t closure #1 in closure #1 in static MLSoundClassifier.resume(_:)(uint64_t a1, char a2, uint64_t a3, void (*a4)(uint64_t *), uint64_t a5)
{
  uint64_t v22 = a5;
  BOOL v23 = a4;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLSoundClassifier, Error>);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TaskPriority?)
                              - 8)
                  + 64);
  char v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  if (a2)
  {
    uint64_t v19 = a1;
    swift_storeEnumTagMultiPayload(&v19, v6, 1);
    swift_errorRetain(a1);
    v23(&v19);
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v19, &demangling cache variable for type metadata for Result<MLSoundClassifier, Error>);
  }
  else
  {
    outlined init with copy of TabularRegressionTask(direct field offset for MLTrainingSession.delegate + a3, (uint64_t)v20);
    uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingSessionDelegate);
    uint64_t v14 = type metadata accessor for SoundClassifierTrainingSessionDelegate(0);
    swift_dynamicCast(&v21, v20, v13, v14, 7);
    uint64_t v15 = v21;
    uint64_t v16 = type metadata accessor for TaskPriority(0);
    __swift_storeEnumTagSinglePayload((uint64_t)&v19, 1, 1, v16);
    uint64_t v17 = swift_allocObject(&unk_39BF30, 56, 7);
    *(_OWORD *)(v17 + 16) = 0;
    *(void *)(v17 + 32) = v15;
    *(void *)(v17 + 40) = v23;
    *(void *)(v17 + 48) = v22;
    swift_retain();
    _sScTss5NeverORs_rlE8priority9operationScTyxABGScPSg_xyYaYAcntcfCyt_Tgm5((uint64_t)&v19, (uint64_t)&async function pointer to partial apply for closure #1 in static MLSoundClassifier.handleResult(_:session:fulfill:), v17);
    return swift_release();
  }
}

uint64_t closure #1 in static MLSoundClassifier.handleResult(_:session:fulfill:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v6[4] = a6;
  v6[3] = a5;
  v6[2] = a4;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLSoundClassifier, Error>);
  v6[5] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(closure #1 in static MLSoundClassifier.handleResult(_:session:fulfill:), 0, 0);
}

uint64_t closure #1 in static MLSoundClassifier.handleResult(_:session:fulfill:)()
{
  uint64_t v1 = (char *)&async function pointer to specialized Result<>.init(catching:)
     + async function pointer to specialized Result<>.init(catching:);
  uint64_t v2 = dword_3AE64C;
  swift_retain();
  uint64_t v3 = (void *)swift_task_alloc(v2);
  v0[6] = v3;
  void *v3 = v0;
  v3[1] = closure #1 in static MLSoundClassifier.handleResult(_:session:fulfill:);
  return ((uint64_t (*)(void, void))v1)(v0[5], v0[2]);
}

{
  uint64_t v0;

  swift_task_dealloc(*(void *)(*(void *)v0 + 48));
  return swift_task_switch(closure #1 in static MLSoundClassifier.handleResult(_:session:fulfill:), 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;

  uint64_t v1 = *(void *)(v0 + 40);
  (*(void (**)(uint64_t))(v0 + 24))(v1);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, &demangling cache variable for type metadata for Result<MLSoundClassifier, Error>);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLSoundClassifier.init(delegate:)(uint64_t a1, uint64_t a2)
{
  v2[19] = a2;
  v2[18] = a1;
  uint64_t v3 = type metadata accessor for MLClassifierMetrics(0);
  v2[20] = v3;
  v2[21] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v4 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLClassifierMetrics?)
                              - 8)
                  + 64)
      + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[22] = swift_task_alloc(v4);
  v2[23] = swift_task_alloc(v4);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?);
  v2[24] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = type metadata accessor for MLSoundClassifier(0);
  v2[25] = v6;
  v2[26] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  v2[27] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  v2[28] = v8;
  unint64_t v9 = (*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[29] = swift_task_alloc(v9);
  v2[30] = swift_task_alloc(v9);
  v2[31] = swift_task_alloc(v9);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  v2[32] = swift_task_alloc((*(void *)(*(void *)(v10 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = type metadata accessor for MLSoundClassifier.PersistentParameters(0);
  v2[33] = v11;
  v2[34] = swift_task_alloc((*(void *)(*(void *)(v11 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLSoundClassifier.init(delegate:), 0, 0);
}

uint64_t MLSoundClassifier.init(delegate:)()
{
  uint64_t v1 = *(void *)(v0 + 264);
  uint64_t v2 = *(void *)(v0 + 256);
  uint64_t v3 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters + *(void *)(v0 + 152);
  swift_beginAccess(v3, v0 + 48, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v3, v2, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1) {
    BUG();
  }
  uint64_t v4 = *(void *)(v0 + 272);
  uint64_t v5 = *(int **)(v0 + 264);
  uint64_t v28 = *(void *)(v0 + 248);
  uint64_t v6 = *(void *)(v0 + 240);
  uint64_t v7 = *(int **)(v0 + 224);
  uint64_t v33 = *(void *)(v0 + 216);
  uint64_t v27 = *(void *)(v0 + 152);
  uint64_t v26 = *(void *)(v0 + 192);
  outlined init with take of MLClassifierMetrics(*(void *)(v0 + 256), v4, type metadata accessor for MLSoundClassifier.PersistentParameters);
  outlined init with copy of MLTrainingSessionParameters(v4 + v5[5], v33, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
  uint64_t v31 = *(void *)(v4 + v5[8]);
  uint64_t v32 = *(void *)(v4 + v5[6]);
  uint64_t v8 = v5[9];
  uint64_t v30 = *(void *)(v4 + v8);
  char v35 = *(unsigned char *)(v4 + v8 + 8);
  uint64_t v9 = *(void *)(v4 + v8 + 16);
  uint64_t v10 = v7[7];
  *(_OWORD *)(v6 + v10) = 0;
  *(_OWORD *)(v6 + v10 + 16) = 0;
  uint64_t v11 = v7[8];
  *(void *)(v6 + v11) = 0;
  uint64_t v29 = v6 + v10;
  *(unsigned char *)(v6 + v11 + 8) = 1;
  *(void *)(v6 + v7[9]) = 32;
  outlined init with copy of MLTrainingSessionParameters(v33, v6, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
  *(void *)(v6 + v7[5]) = v31;
  *(void *)(v6 + v7[6]) = v32;
  *(void *)(v0 + 40) = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
  *(void *)(v0 + 16) = v30;
  *(unsigned char *)(v0 + 24) = v35;
  *(void *)(v0 + 32) = v9;
  swift_bridgeObjectRetain(v9);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v0 + 16, v29, &demangling cache variable for type metadata for Any?);
  outlined destroy of MLActivityClassifier.ModelParameters(v33, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
  outlined init with take of MLClassifierMetrics(v6, v28, type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v12 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model + v27;
  swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model + v27, v0 + 72, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v12, v26, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
  uint64_t v13 = type metadata accessor for MLSoundClassifier.Model(0);
  if (__swift_getEnumTagSinglePayload(v26, 1, v13) == 1) {
    BUG();
  }
  uint64_t v14 = *(void *)(v0 + 208);
  uint64_t v34 = *(void *)(v0 + 192);
  uint64_t v15 = *(int **)(v0 + 200);
  outlined init with copy of MLTrainingSessionParameters(*(void *)(v0 + 248), *(void *)(v0 + 232), type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v16 = type metadata accessor for TrainingTablePrinter(0);
  __swift_storeEnumTagSinglePayload(v14, 1, 1, v16);
  *(_DWORD *)(v0 + 304) = v15[8];
  MLClassifierMetrics.init()();
  uint64_t v17 = v15[9];
  *(_DWORD *)(v0 + 308) = v17;
  uint64_t v18 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v19 = swift_allocError(&type metadata for MLCreateError, v18, 0, 0);
  *(void *)uint64_t v20 = 0xD0000000000000C0;
  *(void *)(v20 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v20 + 16) = 0;
  *(_OWORD *)(v20 + 32) = 0;
  *(unsigned char *)(v20 + 48) = 0;
  *(void *)(v14 + v17) = v19;
  uint64_t v21 = type metadata accessor for MLClassifierMetrics.Contents(0);
  swift_storeEnumTagMultiPayload(v17 + v14, v21, 2);
  uint64_t v22 = v15[5];
  *(_DWORD *)(v0 + 312) = v22;
  outlined init with copy of MLTrainingSessionParameters(v34, v22 + v14, type metadata accessor for MLSoundClassifier.Model);
  BOOL v23 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                          + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v24 = (void *)swift_task_alloc(dword_3AE254);
  *(void *)(v0 + 280) = v24;
  void *v24 = v0;
  v24[1] = MLSoundClassifier.init(delegate:);
  return v23();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;

  uint64_t v1 = *(void *)(v0 + 296);
  uint64_t v20 = *(void *)(v0 + 232);
  uint64_t v2 = *(void *)(v0 + 208);
  uint64_t v3 = *(void *)(v0 + 200);
  uint64_t v25 = *(void *)(v0 + 184);
  uint64_t v22 = *(void *)(v0 + 160);
  uint64_t v29 = *(void *)(v0 + 144);
  uint64_t v4 = *(void *)(v0 + 152);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 192), type metadata accessor for MLSoundClassifier.Model);
  *(void *)(v2 + *(int *)(v3 + 24)) = v1;
  outlined init with take of MLClassifierMetrics(v20, v2 + *(int *)(v3 + 28), type metadata accessor for MLSoundClassifier.ModelParameters);
  outlined init with take of MLClassifierMetrics(v2, v29, type metadata accessor for MLSoundClassifier);
  uint64_t v5 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingMetrics + v4;
  swift_beginAccess(v5, v0 + 96, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v5, v25, &demangling cache variable for type metadata for MLClassifierMetrics?);
  if (__swift_getEnumTagSinglePayload(v25, 1, v22) == 1) {
    BUG();
  }
  uint64_t v6 = *(void *)(v0 + 272);
  uint64_t v7 = *(void *)(v0 + 200);
  uint64_t v30 = *(void *)(v0 + 184);
  uint64_t v26 = *(void *)(v0 + 176);
  BOOL v23 = *(void *)(v0 + 160);
  uint64_t v8 = *(void *)(v0 + 144);
  uint64_t v9 = *(void *)(v0 + 152);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 248), type metadata accessor for MLSoundClassifier.ModelParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v6, type metadata accessor for MLSoundClassifier.PersistentParameters);
  outlined assign with take of MLClassifierMetrics(v30, v8 + *(int *)(v7 + 32));
  uint64_t v10 = v9 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationMetrics;
  swift_beginAccess(v9 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationMetrics, v0 + 120, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, v26, &demangling cache variable for type metadata for MLClassifierMetrics?);
  swift_release();
  if (__swift_getEnumTagSinglePayload(v26, 1, v23) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 176), &demangling cache variable for type metadata for MLClassifierMetrics?);
  }
  else
  {
    uint64_t v11 = *(void *)(v0 + 200);
    uint64_t v12 = *(void *)(v0 + 144);
    uint64_t v13 = *(void *)(v0 + 168);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 176), v13, type metadata accessor for MLClassifierMetrics);
    outlined assign with take of MLClassifierMetrics(v13, v12 + *(int *)(v11 + 36));
  }
  uint64_t v14 = *(void *)(v0 + 256);
  uint64_t v15 = *(void *)(v0 + 248);
  uint64_t v16 = *(void *)(v0 + 240);
  uint64_t v17 = *(void *)(v0 + 232);
  uint64_t v19 = *(void *)(v0 + 216);
  uint64_t v21 = *(void *)(v0 + 208);
  uint64_t v31 = *(void *)(v0 + 192);
  uint64_t v28 = *(void *)(v0 + 184);
  uint64_t v24 = *(void *)(v0 + 168);
  uint64_t v27 = *(void *)(v0 + 176);
  swift_task_dealloc(*(void *)(v0 + 272));
  swift_task_dealloc(v14);
  swift_task_dealloc(v15);
  swift_task_dealloc(v16);
  swift_task_dealloc(v17);
  swift_task_dealloc(v19);
  swift_task_dealloc(v21);
  swift_task_dealloc(v31);
  swift_task_dealloc(v28);
  swift_task_dealloc(v27);
  swift_task_dealloc(v24);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;

  uint64_t v13 = *(void *)(v0 + 272);
  uint64_t v11 = *(void *)(v0 + 256);
  uint64_t v14 = *(void *)(v0 + 248);
  uint64_t v10 = *(void *)(v0 + 240);
  uint64_t v12 = *(void *)(v0 + 232);
  uint64_t v9 = *(void *)(v0 + 216);
  uint64_t v1 = *(void *)(v0 + 208);
  uint64_t v2 = *(void *)(v0 + 192);
  uint64_t v6 = *(void *)(v0 + 184);
  uint64_t v3 = v1 + *(int *)(v0 + 312);
  uint64_t v15 = v1 + *(int *)(v0 + 308);
  uint64_t v4 = v1 + *(int *)(v0 + 304);
  uint64_t v8 = *(void *)(v0 + 176);
  uint64_t v7 = *(void *)(v0 + 168);
  outlined destroy of MLActivityClassifier.ModelParameters(v12, type metadata accessor for MLSoundClassifier.ModelParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLSoundClassifier.Model);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, &demangling cache variable for type metadata for TrainingTablePrinter?);
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLSoundClassifier.Model);
  outlined destroy of MLActivityClassifier.ModelParameters(v4, type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(v15, type metadata accessor for MLClassifierMetrics);
  swift_release();
  outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLSoundClassifier.ModelParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v13, type metadata accessor for MLSoundClassifier.PersistentParameters);
  swift_task_dealloc(v13);
  swift_task_dealloc(v11);
  swift_task_dealloc(v14);
  swift_task_dealloc(v10);
  swift_task_dealloc(v12);
  swift_task_dealloc(v9);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v6);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLSoundClassifier.init(delegate:)(uint64_t a1)
{
  uint64_t v5 = *(void *)(*v2 + 280);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 288) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = MLSoundClassifier.init(delegate:);
  }
  else
  {
    *(void *)(v4 + 296) = a1;
    uint64_t v6 = MLSoundClassifier.init(delegate:);
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t MLSoundClassifier.evaluation(on:)(uint64_t a1, uint64_t a2)
{
  v16[2] = v3;
  uint64_t v17 = v2;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationMetrics<String>);
  uint64_t v5 = *(void *)(v4 - 8);
  int64_t v6 = *(void *)(v5 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v18 = v16;
  uint64_t v10 = MLSoundClassifier.DataSource.labeledSounds()(&demangling cache variable for type metadata for ClassificationMetrics<String>, a2, v9);
  char v11 = v10;
  MLSoundClassifier.evaluate(on:)(v10);
  swift_bridgeObjectRelease(v11);
  uint64_t v13 = v17;
  (*(void (**)(uint64_t, void *, uint64_t))(v5 + 32))(v17, v18, v4);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
  swift_storeEnumTagMultiPayload(v13, v14, 0);
  uint64_t v15 = type metadata accessor for MLClassifierMetrics.Contents(0);
  return swift_storeEnumTagMultiPayload(v13, v15, 0);
}

void *MLSoundClassifier.evaluate(on:)(uint64_t a1)
{
  uint64_t v32 = v2;
  uint64_t v31 = v1;
  uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  int64_t v6 = *(void *)(*(void *)(v5 - 8) + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v9 = *(int *)(type metadata accessor for MLSoundClassifier(0) + 28);
  uint64_t v30 = v3;
  outlined init with copy of MLTrainingSessionParameters(v3 + v9, (uint64_t)&v19, type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v27 = a1;
  uint64_t v10 = v32;
  char v11 = specialized Sequence.flatMap<A>(_:)(a1);
  uint64_t v32 = v10;
  uint64_t v12 = specialized Set.init<A>(_:)((uint64_t)v11);
  uint64_t v28 = *(void *)(v12 + 16);
  swift_bridgeObjectRelease(v12);
  *(void *)&long long v29 = *(void *)((char *)&v19 + *(int *)(v5 + 24));
  *((void *)&v29 + 1) = MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.getter();
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v19 + *(int *)(v5 + 28), (uint64_t)&v19, &demangling cache variable for type metadata for Any?);
  if (v21)
  {
    if (swift_dynamicCast(&v24, &v19, (char *)&type metadata for Any + 8, &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType, 6))
    {
      uint64_t v13 = v24;
      char v14 = v25;
      char v15 = v26;
      goto LABEL_6;
    }
  }
  else
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v19, &demangling cache variable for type metadata for Any?);
  }
  char v14 = 1;
  uint64_t v13 = 1;
  char v15 = 0;
LABEL_6:
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v19, type metadata accessor for MLSoundClassifier.ModelParameters);
  swift_bridgeObjectRelease(v15);
  type metadata accessor for MLSoundClassifier.FeatureExtractor();
  long long v19 = v29;
  uint64_t v20 = 0;
  uint64_t v21 = v28;
  uint64_t v22 = v13;
  char v23 = v14;
  uint64_t v16 = v32;
  uint64_t result = static MLSoundClassifier.FeatureExtractor.extractFeatures(from:options:)(v27, &v19);
  if (!v16)
  {
    char v18 = (char)result;
    specialized MLSoundClassifier.evaluate<A>(on:)((uint64_t)result);
    return (void *)swift_bridgeObjectRelease(v18);
  }
  return result;
}

uint64_t MLSoundClassifier.evaluation(on:)(uint64_t a1)
{
  uint64_t v12 = v1;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationMetrics<String>);
  uint64_t v3 = *(void *)(v2 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  MLSoundClassifier.evaluate(on:)(a1);
  uint64_t v7 = v12;
  (*(void (**)(uint64_t, uint64_t *, uint64_t))(v3 + 32))(v12, &v11, v2);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
  swift_storeEnumTagMultiPayload(v7, v8, 0);
  uint64_t v9 = type metadata accessor for MLClassifierMetrics.Contents(0);
  return swift_storeEnumTagMultiPayload(v7, v9, 0);
}

uint64_t specialized closure #1 in MLSoundClassifier.evaluate<A>(on:)(uint64_t a1, uint64_t a2)
{
  type metadata accessor for MLSoundClassifier(0);
  uint64_t v3 = (char *)&async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:)
     + async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:);
  int64_t v4 = (void *)swift_task_alloc(dword_3A743C);
  *(void *)(v2 + 16) = v4;
  void *v4 = v2;
  v4[1] = specialized closure #1 in MLSoundClassifier.evaluate<A>(on:);
  return ((uint64_t (*)(uint64_t, void, void))v3)(a2, 0, 0);
}

uint64_t specialized closure #1 in MLSoundClassifier.evaluate<A>(on:)(uint64_t a1)
{
  uint64_t v4 = *(void *)(*v2 + 16);
  uint64_t v5 = *v2;
  swift_task_dealloc(v4);
  if (!v1) {
    uint64_t v4 = a1;
  }
  return (*(uint64_t (**)(uint64_t))(v5 + 8))(v4);
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;

  uint64_t v4 = *v2;
  uint64_t v5 = *(void *)(*v2 + 24);
  int64_t v6 = *v2;
  swift_task_dealloc(v5);
  if (!v1) {
    **(void **)(v4 + 16) = a1;
  }
  return (*(uint64_t (**)(void))(v6 + 8))();
}

uint64_t MLSoundClassifier.write(to:metadata:)(uint64_t a1, uint64_t *a2)
{
  uint64_t v62 = v2;
  unint64_t v64 = v3;
  uint64_t v63 = a1;
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.Model(0) - 8) + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v45 = v41;
  uint64_t v53 = type metadata accessor for Model(0);
  uint64_t v52 = *(void *)(v53 - 8);
  int64_t v7 = *(void *)(v52 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v42 = v41;
  uint64_t v10 = type metadata accessor for URL(0);
  uint64_t v11 = *(void *)(v10 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  uint64_t v13 = alloca(v12);
  char v14 = alloca(v12);
  uint64_t v46 = *a2;
  uint64_t v43 = a2[1];
  unint64_t v47 = a2[2];
  uint64_t v48 = (char *)a2[3];
  uint64_t v49 = a2[4];
  uint64_t v50 = a2[5];
  uint64_t v61 = a2[6];
  unint64_t v51 = a2[7];
  uint64_t v15 = a2[8];
  uint64_t v16 = v62;
  uint64_t result = static _ValidationUtilities.validateWriteLocation(atURL:defaultName:fileExtension:)(v63, 0x616C43646E756F53, 0xEF72656966697373, 0x6C65646F6D6C6DLL, (void *)0xE700000000000000);
  if (!v16)
  {
    uint64_t v44 = 0;
    uint64_t v55 = v15;
    uint64_t v59 = v41;
    uint64_t v60 = v10;
    uint64_t v54 = v11;
    uint64_t v18 = type metadata accessor for MLSoundClassifier(0);
    outlined init with copy of MLTrainingSessionParameters(*(int *)(v18 + 20) + v64, (uint64_t)v45, type metadata accessor for MLSoundClassifier.Model);
    uint64_t v19 = v43;
    if (v43)
    {
      uint64_t v20 = v46;
      uint64_t v56 = v46;
      uint64_t v21 = v43;
      uint64_t v22 = v47;
      unint64_t v58 = v47;
      uint64_t v23 = (uint64_t)v48;
      uint64_t v24 = v48;
      uint64_t v25 = v49;
      uint64_t v26 = v49;
      uint64_t v27 = v50;
      uint64_t v63 = v50;
      uint64_t v28 = v61;
      uint64_t v57 = v61;
      uint64_t v29 = v51;
      unint64_t v64 = v51;
      uint64_t v30 = v55;
      uint64_t v62 = v55;
    }
    else
    {
      uint64_t v31 = NSFullUserName();
      uint64_t v32 = v31;
      uint64_t v56 = static String._unconditionallyBridgeFromObjectiveC(_:)(v32);
      uint64_t v21 = v33;

      uint64_t v24 = "RandomForestRegressor" + 0x8000000000000000;
      unint64_t v64 = 0xE100000000000000;
      uint64_t v57 = 49;
      unint64_t v58 = 0xD000000000000033;
      uint64_t v26 = 0;
      uint64_t v63 = 0;
      uint64_t v62 = 0;
      uint64_t v28 = v61;
      uint64_t v20 = v46;
      uint64_t v22 = v47;
      uint64_t v23 = (uint64_t)v48;
      uint64_t v25 = v49;
      uint64_t v27 = v50;
      uint64_t v29 = v51;
      uint64_t v30 = v55;
    }
    v41[0] = v56;
    uint64_t v61 = v21;
    v41[1] = v21;
    v41[2] = v58;
    v41[3] = v24;
    v41[4] = v26;
    v41[5] = v63;
    v41[6] = v57;
    v41[7] = v64;
    v41[8] = v62;
    uint64_t v34 = v19;
    outlined copy of MLModelMetadata?(v20, v19, v22, v23, v25, v27, v28, v29, v30);
    char v35 = v42;
    uint64_t v36 = (uint64_t)v45;
    uint64_t v37 = v44;
    specialized CoreMLExportable.export(metadata:)((uint64_t)v41, v34);
    swift_bridgeObjectRelease(v64);
    swift_bridgeObjectRelease((_BYTE)v24);
    swift_bridgeObjectRelease(v61);
    swift_bridgeObjectRelease(v63);
    swift_bridgeObjectRelease(v62);
    outlined destroy of MLActivityClassifier.ModelParameters(v36, type metadata accessor for MLSoundClassifier.Model);
    if (v37)
    {
      uint64_t v38 = v54;
      uint64_t v39 = v60;
      unint64_t v40 = v59;
    }
    else
    {
      Model.write(to:)(v59);
      uint64_t v38 = v54;
      (*(void (**)(void *, uint64_t))(v52 + 8))(v35, v53);
      unint64_t v40 = v59;
      uint64_t v39 = v60;
    }
    return (*(uint64_t (**)(void *, uint64_t))(v38 + 8))(v40, v39);
  }
  return result;
}

uint64_t MLSoundClassifier.write(toFile:metadata:)(uint64_t a1, uint64_t a2, long long *a3)
{
  uint64_t v23 = v3;
  uint64_t v25 = a2;
  uint64_t v24 = a1;
  uint64_t v26 = type metadata accessor for URL.DirectoryHint(0);
  uint64_t v27 = *(void *)(v26 - 8);
  int64_t v5 = *(void *)(v27 + 64);
  int64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v11 = type metadata accessor for URL(0);
  uint64_t v29 = *(void *)(v11 - 8);
  int64_t v12 = *(void *)(v29 + 64);
  uint64_t v13 = alloca(v12);
  char v14 = alloca(v12);
  uint64_t v28 = *((void *)a3 + 8);
  long long v19 = *a3;
  long long v20 = a3[1];
  long long v21 = a3[2];
  long long v22 = a3[3];
  uint64_t v30 = v11;
  __swift_storeEnumTagSinglePayload((uint64_t)v17, 1, 1, v11);
  (*(void (**)(_OWORD *, void, uint64_t))(v27 + 104))(v17, enum case for URL.DirectoryHint.inferFromPath(_:), v26);
  uint64_t v15 = v25;
  swift_bridgeObjectRetain(v25);
  URL.init(filePath:directoryHint:relativeTo:)(v24, v15, v17, v17);
  v17[0] = v19;
  v17[1] = v20;
  v17[2] = v21;
  v17[3] = v22;
  uint64_t v18 = v28;
  MLSoundClassifier.write(to:metadata:)((uint64_t)v17, (uint64_t *)v17);
  return (*(uint64_t (**)(_OWORD *, uint64_t))(v29 + 8))(v17, v30);
}

void *MLSoundClassifier.predictions(from:)(uint64_t a1)
{
  type metadata accessor for MLSoundClassifier(0);
  type metadata accessor for MLSoundClassifier.ModelParameters(0);
  double v1 = MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.getter();
  return MLSoundClassifier.predictions(from:overlapFactor:predictionTimeWindowSize:)(a1, v1, v1);
}

void *MLSoundClassifier.predictions(from:overlapFactor:predictionTimeWindowSize:)(uint64_t a1, double a2, double a3)
{
  *(void *)&long long v116 = v3;
  double v113 = a3;
  uint64_t v115 = a1;
  uint64_t v109 = type metadata accessor for URL(0);
  uint64_t v106 = *(void *)(v109 - 8);
  int64_t v85 = *(void *)(v106 + 64);
  int64_t v5 = alloca(v85);
  int64_t v6 = alloca(v85);
  v103 = v83;
  uint64_t v7 = type metadata accessor for MLSoundClassifier(0);
  uint64_t v86 = *(void *)(v7 - 8);
  int64_t v107 = *(void *)(v86 + 64);
  int64_t v8 = alloca(v107);
  uint64_t v9 = alloca(v107);
  v104 = v83;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                              - 8)
                  + 64);
  uint64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  v105 = v83;
  uint64_t v13 = (void *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  int64_t v14 = *(void *)(*(v13 - 1) + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v17 = *(int *)(v7 + 28);
  uint64_t v84 = v4;
  uint64_t v18 = v4 + v17;
  outlined init with copy of MLTrainingSessionParameters(v18, (uint64_t)v83, type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v108 = *(void *)(v115 + 16);
  v117 = *(void (**)(unsigned char *, uint64_t, uint64_t))&v83[*((int *)v13 + 6)];
  double v114 = MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.getter();
  v118 = v13;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v83[*((int *)v13 + 7)], (uint64_t)&v98, &demangling cache variable for type metadata for Any?);
  uint64_t v19 = 1;
  uint64_t v110 = v18;
  if (v100)
  {
    if (swift_dynamicCast(&v95, &v98, (char *)&type metadata for Any + 8, &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType, 6))
    {
      uint64_t v19 = v95;
      LOBYTE(v112) = v96;
      char v20 = v97;
      goto LABEL_6;
    }
  }
  else
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v98, &demangling cache variable for type metadata for Any?);
  }
  LOBYTE(v112) = 1;
  char v20 = 0;
LABEL_6:
  type metadata accessor for MLSoundClassifier.FeatureExtractor();
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v83, type metadata accessor for MLSoundClassifier.ModelParameters);
  swift_bridgeObjectRelease(v20);
  *(void *)&long long v98 = v117;
  *((double *)&v98 + 1) = v114;
  uint64_t v99 = 0;
  uint64_t v21 = v108;
  uint64_t v100 = v108;
  uint64_t v101 = v19;
  char v102 = v112;
  uint64_t v22 = v116;
  uint64_t result = (void *)static MLSoundClassifier.FeatureExtractor.extractFeatures(from:options:)(v115, &v98);
  uint64_t v24 = v22;
  if (v22) {
    return result;
  }
  uint64_t v25 = result;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*((int *)v118 + 7) + v110, (uint64_t)&v98, &demangling cache variable for type metadata for Any?);
  if (!v100)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v98, &demangling cache variable for type metadata for Any?);
    uint64_t v27 = v115;
    goto LABEL_13;
  }
  char v26 = swift_dynamicCast(&v95, &v98, (char *)&type metadata for Any + 8, &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType, 6);
  uint64_t v27 = v115;
  if (!v26)
  {
LABEL_13:
    double v30 = v113;
    goto LABEL_14;
  }
  char v28 = v96;
  swift_bridgeObjectRelease(v97);
  BOOL v29 = v28 == 0;
  uint64_t v21 = v108;
  double v30 = v113;
  if (v29 && v113 != 0.975)
  {
    swift_bridgeObjectRelease((_BYTE)v25);
    *(void *)&long long v98 = 0;
    *((void *)&v98 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(86);
    v31._countAndFlagsBits = 0xD00000000000004BLL;
    v31._char object = ". The expected range is from " + 0x8000000000000000;
    String.append(_:)(v31);
    Double.write<A>(to:)(&v98, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    v31._countAndFlagsBits = 0x73646E6F63657320;
    v31._char object = (void *)0xE90000000000002ELL;
    String.append(_:)(v31);
    long long v116 = v98;
    uint64_t v32 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v32, 0, 0);
    *(_OWORD *)uint64_t v33 = v116;
    *(_OWORD *)(v33 + 16) = 0;
    *(_OWORD *)(v33 + 32) = 0;
    *(unsigned char *)(v33 + 48) = 1;
    return (void *)swift_willThrow(&type metadata for MLCreateError, v32, v33, v34, v35, v36);
  }
LABEL_14:
  if (v30 < 0.5 || v30 > 15.0)
  {
    swift_bridgeObjectRelease((_BYTE)v25);
    *(void *)&long long v98 = 0;
    *((void *)&v98 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(69);
    v82._char object = "ires a training checkpoint." + 0x8000000000000000;
    v82._countAndFlagsBits = 0xD00000000000003DLL;
    String.append(_:)(v82);
    Double.write<A>(to:)(&v98, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    v82._char object = (void *)0xE400000000000000;
    v82._countAndFlagsBits = 544175136;
    String.append(_:)(v82);
    Double.write<A>(to:)(&v98, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    long long v116 = v98;
    uint64_t v32 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v32, 0, 0);
    *(_OWORD *)uint64_t v33 = v116;
    *(_OWORD *)(v33 + 16) = 0;
    *(_OWORD *)(v33 + 32) = 0;
    *(unsigned char *)(v33 + 48) = 0;
    return (void *)swift_willThrow(&type metadata for MLCreateError, v32, v33, v34, v35, v36);
  }
  v111 = v25;
  if (v21)
  {
    uint64_t v37 = *(unsigned __int8 *)(v106 + 80);
    uint64_t v93 = ~v37;
    uint64_t v89 = v27 + ((v37 + 32) & ~v37);
    uint64_t v90 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v106 + 16);
    uint64_t v91 = *(void *)(v106 + 72);
    v107 += 7;
    uint64_t v92 = v37;
    uint64_t v94 = v37 + 8;
    swift_bridgeObjectRetain(v27);
    v118 = _swiftEmptyArrayStorage;
    uint64_t v38 = 0;
    uint64_t v39 = 0;
    while (1)
    {
      *(void *)&long long v116 = v24;
      uint64_t v110 = v39;
      uint64_t v40 = (uint64_t)v105;
      uint64_t v41 = v109;
      v90(v105, v89 + v39 * v91, v109);
      __swift_storeEnumTagSinglePayload(v40, 0, 1, v41);
      if (__swift_getEnumTagSinglePayload(v40, 1, v41) == 1) {
        break;
      }
      outlined init with copy of MLTrainingSessionParameters(v84, (uint64_t)v104, type metadata accessor for MLSoundClassifier);
      v117 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v106 + 32);
      v117(v103, v40, v41);
      uint64_t v42 = *(unsigned __int8 *)(v86 + 80);
      uint64_t v43 = ~*(unsigned __int8 *)(v86 + 80) & (v42 + 16);
      *(void *)&double v114 = (v107 + v43) & 0xFFFFFFFFFFFFFFF8;
      uint64_t v44 = v93 & (v94 + *(void *)&v114);
      uint64_t v45 = swift_allocObject(&unk_39BED0, v85 + v44, v92 | v42 | 7);
      outlined init with take of MLClassifierMetrics((uint64_t)v104, v45 + v43, type metadata accessor for MLSoundClassifier);
      LOBYTE(v43) = (_BYTE)v111;
      *(void *)(v45 + *(void *)&v114) = v111;
      v117((unsigned char *)(v45 + v44), (uint64_t)v103, v109);
      swift_bridgeObjectRetain(v43);
      uint64_t v46 = v116;
      specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLSoundClassifier.predictions(from:overlapFactor:predictionTimeWindowSize:), v45);
      if (v46)
      {
        swift_bridgeObjectRelease((_BYTE)v118);
        swift_bridgeObjectRelease(v115);
        swift_bridgeObjectRelease((_BYTE)v111);
        swift_release();
        return (void *)_sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v38, 0);
      }
      uint64_t v48 = v47;
      swift_release();
      MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v48, (uint64_t)v83, &demangling cache variable for type metadata for ClassificationDistribution<String>, (uint64_t)&unk_34FBC8);
      uint64_t v50 = 0;
      swift_bridgeObjectRelease(v48);
      uint64_t v51 = MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm[2];
      if (v51)
      {
        uint64_t v87 = 0;
        char v88 = MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
        uint64_t v52 = (void (**)(unsigned char *, uint64_t, uint64_t))(MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm
                                                              + 5);
        uint64_t v53 = _swiftEmptyDictionarySingleton;
        do
        {
          uint64_t v112 = v51;
          uint64_t v54 = (uint64_t)*(v52 - 1);
          double v113 = *(double *)&v52;
          uint64_t v55 = *v52;
          swift_bridgeObjectRetain(*v52);
          _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v38, 0);
          uint64_t v56 = v53;
          char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v53);
          *(void *)&long long v98 = v56;
          double v114 = *(double *)&v54;
          v117 = v55;
          unint64_t v58 = specialized __RawDictionaryStorage.find<A>(_:)(v54, (uint64_t)v55);
          LOBYTE(v116) = v59;
          BOOL v60 = (v59 & 1) == 0;
          BOOL v61 = __OFADD__(v56[2], v60);
          Swift::Int v62 = v56[2] + v60;
          if (v61) {
            BUG();
          }
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, Int>);
          Swift::Bool v63 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v62);
          uint64_t v53 = (void *)v98;
          unint64_t v64 = (void (*)(void, void, void))v117;
          if (v63)
          {
            uint64_t v65 = (void (*)(void, void, void))v117;
            unint64_t v58 = specialized __RawDictionaryStorage.find<A>(_:)(*(uint64_t *)&v114, (uint64_t)v117);
            if ((v116 & 1) != (v66 & 1))
            {
              KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
              BUG();
            }
            unint64_t v64 = v65;
          }
          swift_bridgeObjectRelease(0);
          char v67 = (char)v53;
          if ((v116 & 1) == 0)
          {
            v53[(v58 >> 6) + 8] |= 1 << v58;
            uint64_t v68 = v53[6];
            uint64_t v69 = 16 * v58;
            *(double *)(v68 + v69) = v114;
            *(void *)(v68 + v69 + 8) = v64;
            *(void *)(v53[7] + 8 * v58) = 0;
            uint64_t v70 = v53[2];
            swift_bridgeObjectRetain((_BYTE)v53);
            BOOL v61 = __OFADD__(1, v70);
            uint64_t v71 = v70 + 1;
            if (v61) {
              BUG();
            }
            v53[2] = v71;
            char v67 = (char)v64;
          }
          swift_bridgeObjectRetain(v67);
          uint64_t v72 = v53[7];
          swift_bridgeObjectRelease((_BYTE)v53);
          uint64_t v73 = *(void *)(v72 + 8 * v58);
          BOOL v61 = __OFADD__(1, v73);
          uint64_t v74 = v73 + 1;
          if (v61) {
            BUG();
          }
          *(void *)(v72 + 8 * v58) = v74;
          swift_bridgeObjectRelease((_BYTE)v64);
          uint64_t v52 = (void (**)(unsigned char *, uint64_t, uint64_t))(*(void *)&v113 + 16);
          uint64_t v38 = specialized OptionSet<>.init();
          uint64_t v51 = v112 - 1;
        }
        while (v112 != 1);
        uint64_t v38 = specialized OptionSet<>.init();
        uint64_t v50 = v87;
        LOBYTE(MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm) = (_BYTE)v88;
      }
      else
      {
        uint64_t v53 = _swiftEmptyDictionarySingleton;
      }
      swift_bridgeObjectRelease((_BYTE)MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm);
      swift_bridgeObjectRetain((_BYTE)v53);
      v117 = (void (*)(unsigned char *, uint64_t, uint64_t))specialized Sequence.max(by:)((uint64_t)v53);
      char v75 = (char)v53;
      uint64_t v77 = v76;
      swift_bridgeObjectRelease(v75);
      if (!v77) {
        BUG();
      }
      swift_bridgeObjectRelease(v75);
      char v78 = swift_isUniquelyReferenced_nonNull_native(v118);
      *(void *)&long long v116 = v50;
      if (v78) {
        uint64_t v79 = v118;
      }
      else {
        uint64_t v79 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v118[2] + 1, 1, (uint64_t)v118);
      }
      unint64_t v80 = v79[2];
      if (v79[3] >> 1 <= v80) {
        uint64_t v79 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v79[3] >= 2uLL, v80 + 1, 1, (uint64_t)v79);
      }
      uint64_t v39 = v110 + 1;
      v79[2] = v80 + 1;
      uint64_t v81 = 2 * v80;
      v79[v81 + 4] = v117;
      v118 = v79;
      v79[v81 + 5] = v77;
      uint64_t v24 = v116;
      if (v39 == v108) {
        goto LABEL_45;
      }
    }
  }
  else
  {
    swift_bridgeObjectRetain(v27);
    v118 = _swiftEmptyArrayStorage;
    uint64_t v38 = 0;
LABEL_45:
    __swift_storeEnumTagSinglePayload((uint64_t)v105, 1, 1, v109);
  }
  swift_bridgeObjectRelease((_BYTE)v111);
  swift_bridgeObjectRelease(v115);
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v38, 0);
  return v118;
}

uint64_t closure #1 in MLSoundClassifier.predictions(from:overlapFactor:predictionTimeWindowSize:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v4[5] = a4;
  v4[4] = a3;
  v4[3] = a2;
  v4[2] = a1;
  uint64_t v5 = type metadata accessor for MLSoundClassifier.Model(0);
  v4[6] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(closure #1 in MLSoundClassifier.predictions(from:overlapFactor:predictionTimeWindowSize:), 0, 0);
}

uint64_t closure #1 in MLSoundClassifier.predictions(from:overlapFactor:predictionTimeWindowSize:)()
{
  uint64_t v1 = v0[6];
  uint64_t v2 = v0[5];
  uint64_t v3 = v0[3];
  uint64_t v4 = v0[4];
  uint64_t v5 = type metadata accessor for MLSoundClassifier(0);
  outlined init with copy of MLTrainingSessionParameters(v3 + *(int *)(v5 + 20), v1, type metadata accessor for MLSoundClassifier.Model);
  uint64_t v6 = specialized Dictionary.subscript.getter(v2, v4);
  v0[7] = v6;
  if (!v6) {
    BUG();
  }
  uint64_t v7 = v6;
  int64_t v8 = (char *)&async function pointer to specialized Transformer.applied<A>(to:eventHandler:)
     + async function pointer to specialized Transformer.applied<A>(to:eventHandler:);
  uint64_t v9 = (void *)swift_task_alloc(dword_3ADED4);
  v0[8] = v9;
  *uint64_t v9 = v0;
  v9[1] = closure #1 in MLSoundClassifier.predictions(from:overlapFactor:predictionTimeWindowSize:);
  return ((uint64_t (*)(uint64_t, void, void))v8)(v7, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;

  uint64_t v1 = *(void *)(v0 + 48);
  **(void **)(v0 + 16) = *(void *)(v0 + 80);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;

  swift_task_dealloc(*(void *)(v0 + 48));
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t closure #1 in MLSoundClassifier.predictions(from:overlapFactor:predictionTimeWindowSize:)(uint64_t a1)
{
  uint64_t v5 = *(void *)(*(void *)v2 + 56);
  uint64_t v6 = *(void *)(*(void *)v2 + 64);
  uint64_t v4 = *(void **)v2;
  v4[9] = v1;
  swift_task_dealloc(v6);
  swift_bridgeObjectRelease(v5);
  uint64_t v7 = v4[6];
  if (v1)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(v7, type metadata accessor for MLSoundClassifier.Model);
    int64_t v8 = closure #1 in MLSoundClassifier.predictions(from:overlapFactor:predictionTimeWindowSize:);
  }
  else
  {
    v4[10] = a1;
    outlined destroy of MLActivityClassifier.ModelParameters(v7, type metadata accessor for MLSoundClassifier.Model);
    int64_t v8 = closure #1 in MLSoundClassifier.predictions(from:overlapFactor:predictionTimeWindowSize:);
  }
  return swift_task_switch(v8, 0, 0);
}

unint64_t MLSoundClassifier.description.getter()
{
  return MLSoundClassifier.debugDescription.getter();
}

unint64_t MLSoundClassifier.debugDescription.getter()
{
  uint64_t v1 = v0;
  v25._char object = (void *)type metadata accessor for MLClassifierMetrics.Contents(0);
  int64_t v2 = *(void *)(*((void *)v25._object - 1) + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v5 = type metadata accessor for MLSoundClassifier(0);
  v25._countAndFlagsBits = MLSoundClassifier.ModelParameters.description.getter();
  uint64_t v7 = v6;
  v22._countAndFlagsBits = MLClassifierMetrics.description.getter();
  v22._char object = v8;
  uint64_t v9 = *(int *)(v5 + 36);
  int64_t v10 = v7;
  outlined init with copy of MLTrainingSessionParameters(v1 + v9, (uint64_t)&v20, type metadata accessor for MLClassifierMetrics.Contents);
  LODWORD(v7) = swift_getEnumCaseMultiPayload(&v20, v25._object);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v20, type metadata accessor for MLClassifierMetrics.Contents);
  v25._char object = (void *)MLClassifierMetrics.description.getter();
  int64_t v12 = v11;
  unint64_t v23 = 0xD00000000000001CLL;
  uint64_t v24 = "odelType" + 0x8000000000000000;
  v13._countAndFlagsBits = v25._countAndFlagsBits;
  v25._countAndFlagsBits = (uint64_t)v10;
  v13._char object = v10;
  String.append(_:)(v13);
  v21._countAndFlagsBits = 0xD00000000000001ELL;
  v21._char object = "ActivityClassifier\n\nParameters\n" + 0x8000000000000000;
  char object = (char)v22._object;
  String.append(_:)(v22);
  char v15 = (char)v21._object;
  String.append(_:)(v21);
  swift_bridgeObjectRelease(v15);
  if (v7 > 1)
  {
    char v18 = object;
  }
  else
  {
    v21._countAndFlagsBits = 0xD000000000000020;
    v21._char object = "\nPerformance on Training Data\n" + 0x8000000000000000;
    v16._countAndFlagsBits = (uint64_t)v25._object;
    v16._char object = v12;
    String.append(_:)(v16);
    char v17 = (char)v21._object;
    String.append(_:)(v21);
    swift_bridgeObjectRelease(object);
    char v18 = (char)v12;
    LOBYTE(v12) = v17;
  }
  swift_bridgeObjectRelease(v18);
  swift_bridgeObjectRelease((_BYTE)v12);
  swift_bridgeObjectRelease(v25._countAndFlagsBits);
  return v23;
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLSoundClassifier()
{
  return MLSoundClassifier.description.getter();
}

unint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLSoundClassifier()
{
  return MLSoundClassifier.debugDescription.getter();
}

NSAttributedString MLSoundClassifier.playgroundDescription.getter()
{
  uint64_t v1 = v0;
  uint64_t v2 = type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for NSAttributedString, NSAttributedString_ptr);
  v3._countAndFlagsBits = MLSoundClassifier.debugDescription.getter();
  v3._char object = v4;
  result.super.isa = NSAttributedString.__allocating_init(string:)(v3).super.isa;
  v1[3].super.isa = (Class)v2;
  v1->super.isa = result.super.isa;
  return result;
}

NSAttributedString protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLSoundClassifier()
{
  return MLSoundClassifier.playgroundDescription.getter();
}

uint64_t closure #1 in static MLSoundClassifier.convertFeatures(_:)(uint64_t a1)
{
  uint64_t v13 = a1;
  uint64_t v12 = v1;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  uint64_t v3 = *(void *)(v2 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v3 + 16))(&v11, v13, v2);
  uint64_t v13 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
  uint64_t v8 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Double> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Double>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
  uint64_t v9 = v12;
  MLShapedArrayProtocol.init<A>(converting:)(&v11, v7, v2, v13, v8);
  return __swift_storeEnumTagSinglePayload(v9, 0, 1, v7);
}

uint64_t closure #2 in static MLSoundClassifier.convertFeatures(_:)(void **a1)
{
  uint64_t v2 = v1;
  uint64_t v3 = *a1;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  uint64_t v5 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
  id v6 = v3;
  MLShapedArrayProtocol.init(converting:)(v6, v4, v5);
  return __swift_storeEnumTagSinglePayload(v2, 0, 1, v4);
}

uint64_t closure #3 in static MLSoundClassifier.convertFeatures(_:)(uint64_t *a1)
{
  uint64_t v2 = v1;
  uint64_t v10 = *a1;
  uint64_t v3 = v10;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v5 = (void *)swift_allocObject(v4, 40, 7);
  v5[2] = 1;
  v5[3] = 2;
  v5[4] = *(void *)(v3 + 16);
  swift_bridgeObjectRetain(v3);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  uint64_t v7 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float], (uint64_t)&protocol conformance descriptor for [A]);
  MLShapedArray.init<A>(scalars:shape:)(&v10, v5, &type metadata for Float, v6, &protocol witness table for Float, v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  return __swift_storeEnumTagSinglePayload(v2, 0, 1, v8);
}

uint64_t closure #4 in static MLSoundClassifier.convertFeatures(_:)(uint64_t *a1)
{
  uint64_t v16 = v1;
  uint64_t v2 = *a1;
  int64_t v19 = *(void *)(*a1 + 16);
  if (v19)
  {
    char v18 = _swiftEmptyArrayStorage;
    uint64_t v3 = 0;
    uint64_t v17 = v2;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v19, 0);
    uint64_t v4 = v17;
    int64_t v5 = v19;
    uint64_t v6 = _swiftEmptyArrayStorage;
    unint64_t v7 = _swiftEmptyArrayStorage[2];
    do
    {
      double v8 = *(double *)(v4 + 8 * v3 + 32);
      char v18 = v6;
      if (v6[3] >> 1 <= v7)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v6[3] >= 2uLL, v7 + 1, 1);
        uint64_t v4 = v17;
        int64_t v5 = v19;
        uint64_t v6 = v18;
      }
      ++v3;
      float v9 = v8;
      v6[2] = v7 + 1;
      *((float *)v6 + v7++ + 8) = v9;
    }
    while (v5 != v3);
  }
  else
  {
    uint64_t v6 = _swiftEmptyArrayStorage;
  }
  char v18 = v6;
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v11 = (void *)swift_allocObject(v10, 40, 7);
  v11[2] = 1;
  v11[3] = 2;
  v11[4] = v19;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  uint64_t v13 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float], (uint64_t)&protocol conformance descriptor for [A]);
  MLShapedArray.init<A>(scalars:shape:)(&v18, v11, &type metadata for Float, v12, &protocol witness table for Float, v13);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  return __swift_storeEnumTagSinglePayload(v16, 0, 1, v14);
}

uint64_t closure #5 in static MLSoundClassifier.convertFeatures(_:)(uint64_t *a1)
{
  uint64_t v18 = v1;
  uint64_t v2 = *a1;
  int64_t v3 = *(void *)(*a1 + 16);
  uint64_t v19 = *a1;
  if (v3)
  {
    Swift::String v21 = (float *)_swiftEmptyArrayStorage;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3, 0);
    uint64_t v4 = v2 + 32;
    do
    {
      outlined init with copy of Any(v4, (uint64_t)v16);
      float v20 = static MLSoundClassifier.convertToFloat(_:)((uint64_t)v16);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v16, &demangling cache variable for type metadata for Any?);
      int64_t v5 = v21;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v21);
      int64_t v17 = v3;
      if (!isUniquelyReferenced_nonNull_native)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v5 + 2) + 1, 1);
        int64_t v5 = v21;
      }
      unint64_t v7 = *((void *)v5 + 2);
      unint64_t v8 = v7 + 1;
      if (*((void *)v5 + 3) >> 1 <= v7)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v5 + 3) >= 2uLL, v7 + 1, 1);
        unint64_t v8 = v7 + 1;
        int64_t v5 = v21;
      }
      *((void *)v5 + 2) = v8;
      v5[v7 + 8] = v20;
      v4 += 32;
      int64_t v3 = v17 - 1;
    }
    while (v17 != 1);
  }
  else
  {
    int64_t v5 = (float *)_swiftEmptyArrayStorage;
  }
  v16[0] = v5;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v10 = (void *)swift_allocObject(v9, 40, 7);
  _OWORD v10[2] = 1;
  v10[3] = 2;
  v10[4] = *(void *)(v19 + 16);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  uint64_t v12 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float], (uint64_t)&protocol conformance descriptor for [A]);
  uint64_t v13 = v18;
  MLShapedArray.init<A>(scalars:shape:)(v16, v10, &type metadata for Float, v11, &protocol witness table for Float, v12);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  return __swift_storeEnumTagSinglePayload(v13, 0, 1, v14);
}

float static MLSoundClassifier.convertToFloat(_:)(uint64_t a1)
{
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, (uint64_t)v6, &demangling cache variable for type metadata for Any?);
  __m128i v1 = _mm_cvtsi32_si128(0x7FC00000u);
  if (!v7) {
    goto LABEL_16;
  }
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v6, (uint64_t)v8, &demangling cache variable for type metadata for Any?);
  if (!swift_dynamicCast(v9, v8, (char *)&type metadata for Any + 8, &type metadata for Float, 0))
  {
    if (swift_dynamicCast(v9, v8, (char *)&type metadata for Any + 8, &type metadata for Double, 0))
    {
      *(float *)v1.i32 = *(double *)v9;
      goto LABEL_8;
    }
    if (swift_dynamicCast(v9, v8, (char *)&type metadata for Any + 8, &type metadata for Int, 0))
    {
      *(float *)v1.i32 = (float)SLODWORD(v9[0]);
      goto LABEL_8;
    }
    uint64_t v2 = type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for NSNumber, NSNumber_ptr);
    if (swift_dynamicCast(v9, v8, (char *)&type metadata for Any + 8, v2, 0))
    {
      id v3 = v9[0];
      [v9[0] floatValue:*(double *)v1.i64];
      float v10 = COERCE_FLOAT(_mm_cvtsi128_si32(v1));

      goto LABEL_9;
    }
    if (swift_dynamicCast(v9, v8, (char *)&type metadata for Any + 8, &type metadata for String, 0))
    {
      unint64_t v4 = specialized Float.init<A>(_:)((unint64_t)v9[0], (uint64_t)v9[1]);
      if ((v4 & 0x100000000) != 0) {
        __m128i v1 = _mm_cvtsi32_si128(0x7FC00000u);
      }
      else {
        __m128i v1 = _mm_cvtsi32_si128(v4);
      }
      goto LABEL_8;
    }
    __swift_destroy_boxed_opaque_existential_1Tm(v8);
    __m128i v1 = _mm_cvtsi32_si128(0x7FC00000u);
LABEL_16:
    float v10 = COERCE_FLOAT(_mm_cvtsi128_si32(v1));
    goto LABEL_17;
  }
  __m128i v1 = _mm_cvtsi32_si128(v9[0]);
LABEL_8:
  float v10 = COERCE_FLOAT(_mm_cvtsi128_si32(v1));
LABEL_9:
  __swift_destroy_boxed_opaque_existential_1Tm(v8);
LABEL_17:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v6, &demangling cache variable for type metadata for Any?);
  return v10;
}

uint64_t closure #6 in static MLSoundClassifier.convertFeatures(_:)(uint64_t *a1)
{
  uint64_t v15 = v1;
  uint64_t v2 = *a1;
  int64_t v18 = *(void *)(*a1 + 16);
  if (v18)
  {
    int64_t v17 = _swiftEmptyArrayStorage;
    uint64_t v3 = 0;
    uint64_t v16 = v2;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v18, 0);
    uint64_t v4 = v16;
    int64_t v5 = v18;
    uint64_t v6 = _swiftEmptyArrayStorage;
    unint64_t v7 = _swiftEmptyArrayStorage[2];
    do
    {
      int v8 = 2143289344;
      if (!*(unsigned char *)(v4 + 8 * v3 + 36)) {
        int v8 = *(_DWORD *)(v4 + 8 * v3 + 32);
      }
      int64_t v17 = v6;
      if (v6[3] >> 1 <= v7)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v6[3] >= 2uLL, v7 + 1, 1);
        uint64_t v4 = v16;
        int64_t v5 = v18;
        uint64_t v6 = v17;
      }
      ++v3;
      v6[2] = v7 + 1;
      *((_DWORD *)v6 + v7++ + 8) = v8;
    }
    while (v5 != v3);
  }
  else
  {
    uint64_t v6 = _swiftEmptyArrayStorage;
  }
  int64_t v17 = v6;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  float v10 = (void *)swift_allocObject(v9, 40, 7);
  _OWORD v10[2] = 1;
  v10[3] = 2;
  v10[4] = v18;
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  uint64_t v12 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float], (uint64_t)&protocol conformance descriptor for [A]);
  MLShapedArray.init<A>(scalars:shape:)(&v17, v10, &type metadata for Float, v11, &protocol witness table for Float, v12);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  return __swift_storeEnumTagSinglePayload(v15, 0, 1, v13);
}

uint64_t closure #7 in static MLSoundClassifier.convertFeatures(_:)(uint64_t *a1)
{
  uint64_t v18 = v1;
  uint64_t v2 = *a1;
  int64_t v3 = *(void *)(*a1 + 16);
  uint64_t v4 = _swiftEmptyArrayStorage;
  if (v3)
  {
    float v20 = _swiftEmptyArrayStorage;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3, 0);
    uint64_t v4 = _swiftEmptyArrayStorage;
    unint64_t v5 = _swiftEmptyArrayStorage[2];
    uint64_t v6 = (double *)(v2 + 40);
    int64_t v19 = v3;
    do
    {
      float v7 = *(v6 - 1);
      char v8 = *(unsigned char *)v6;
      float v20 = v4;
      unint64_t v9 = v4[3];
      int64_t v10 = v5 + 1;
      if (v9 >> 1 <= v5)
      {
        char v21 = v8;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v9 >= 2, v10, 1);
        char v8 = v21;
        int64_t v10 = v5 + 1;
        uint64_t v4 = v20;
      }
      int v11 = 2143289344;
      if ((v8 & 1) == 0) {
        int v11 = LODWORD(v7);
      }
      v4[2] = v10;
      *((_DWORD *)v4 + v5 + 8) = v11;
      v6 += 2;
      unint64_t v5 = v10;
      --v3;
    }
    while (v3);
    int64_t v3 = v19;
  }
  float v20 = v4;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v13 = (void *)swift_allocObject(v12, 40, 7);
  v13[2] = 1;
  v13[3] = 2;
  v13[4] = v3;
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  uint64_t v15 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float], (uint64_t)&protocol conformance descriptor for [A]);
  MLShapedArray.init<A>(scalars:shape:)(&v20, v13, &type metadata for Float, v14, &protocol witness table for Float, v15);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  return __swift_storeEnumTagSinglePayload(v18, 0, 1, v16);
}

uint64_t closure #8 in static MLSoundClassifier.convertFeatures(_:)(uint64_t *a1)
{
  uint64_t v24 = v1;
  uint64_t v2 = *a1;
  int64_t v25 = *(void *)(*a1 + 16);
  int64_t v3 = v25;
  if (v25)
  {
    BOOL v29 = _swiftEmptyArrayStorage;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v25, 0);
    uint64_t v4 = v2 + 32;
    unint64_t v23 = (char *)&type metadata for Any + 8;
    while (1)
    {
      int64_t v22 = v3;
      uint64_t v21 = v4;
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v4, (uint64_t)v20, &demangling cache variable for type metadata for Any?);
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v20, (uint64_t)v26, &demangling cache variable for type metadata for Any?);
      int v30 = 2143289344;
      if (v27) {
        break;
      }
LABEL_12:
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v26, &demangling cache variable for type metadata for Any?);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v20, &demangling cache variable for type metadata for Any?);
      float v7 = v29;
      if (!swift_isUniquelyReferenced_nonNull_native(v29))
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v7[2] + 1, 1);
        float v7 = v29;
      }
      unint64_t v8 = v7[2];
      if (v7[3] >> 1 <= v8)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v7[3] >= 2uLL, v8 + 1, 1);
        float v7 = v29;
      }
      v7[2] = v8 + 1;
      *((_DWORD *)v7 + v8 + 8) = v30;
      uint64_t v4 = v21 + 32;
      int64_t v3 = v22 - 1;
      if (v22 == 1) {
        goto LABEL_26;
      }
    }
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v26, (uint64_t)v19, &demangling cache variable for type metadata for Any?);
    unint64_t v5 = v23;
    if (swift_dynamicCast(v28, v19, v23, &type metadata for Float, 0))
    {
      float v6 = *(float *)v28;
    }
    else if (swift_dynamicCast(v28, v19, v5, &type metadata for Double, 0))
    {
      float v6 = *(double *)v28;
    }
    else
    {
      if (!swift_dynamicCast(v28, v19, v5, &type metadata for Int, 0))
      {
        uint64_t v9 = type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for NSNumber, NSNumber_ptr);
        if (swift_dynamicCast(v28, v19, v5, v9, 0))
        {
          id v10 = v28[0];
          [v28[0] floatValue];
          int v30 = 2143289344;
        }
        else
        {
          if (!swift_dynamicCast(v28, v19, v5, &type metadata for String, 0))
          {
            __swift_destroy_boxed_opaque_existential_1Tm(v19);
            int v30 = 2143289344;
            goto LABEL_12;
          }
          unint64_t v11 = specialized Float.init<A>(_:)((unint64_t)v28[0], (uint64_t)v28[1]);
          if ((v11 & 0x100000000) != 0) {
            int v30 = 2143289344;
          }
          else {
            int v30 = v11;
          }
        }
        goto LABEL_11;
      }
      float v6 = (float)SLODWORD(v28[0]);
    }
    int v30 = LODWORD(v6);
LABEL_11:
    __swift_destroy_boxed_opaque_existential_1Tm(v19);
    goto LABEL_12;
  }
  float v7 = _swiftEmptyArrayStorage;
LABEL_26:
  v20[0] = v7;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v13 = (void *)swift_allocObject(v12, 40, 7);
  v13[2] = 1;
  v13[3] = 2;
  v13[4] = v25;
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  uint64_t v15 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float], (uint64_t)&protocol conformance descriptor for [A]);
  uint64_t v16 = v24;
  MLShapedArray.init<A>(scalars:shape:)(v20, v13, &type metadata for Float, v14, &protocol witness table for Float, v15);
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  return __swift_storeEnumTagSinglePayload(v16, 0, 1, v17);
}

unint64_t specialized Float.init<A>(_:)(unint64_t a1, uint64_t a2)
{
  v15[0] = 0;
  v13[2] = v15;
  if ((a2 & 0x1000000000000000) != 0 || !(a2 & 0x2000000000000000 | a1 & 0x1000000000000000))
  {
    _StringGuts._slowWithCString<A>(_:)(partial apply for closure #1 in closure #1 in Float.init<A>(_:), v13, a1, a2, &type metadata for Bool);
    swift_bridgeObjectRelease(a2);
    char v7 = v14[0];
  }
  else
  {
    int64_t v3 = alloca(32);
    uint64_t v4 = alloca(32);
    v13[0] = partial apply for closure #1 in closure #1 in Float.init<A>(_:);
    v13[1] = v13;
    if ((a2 & 0x2000000000000000) != 0)
    {
      v14[0] = a1;
      v14[1] = a2 & 0xFFFFFFFFFFFFFFLL;
      char v7 = (a1 > 0x20u || (v8 = 0x100003E01, !_bittest64(&v8, a1)))
        && (uint64_t v9 = (unsigned char *)_swift_stdlib_strtof_clocale(v14, v15)) != 0
        && *v9 == 0;
      swift_bridgeObjectRelease(a2);
    }
    else
    {
      if ((a1 & 0x1000000000000000) != 0)
      {
        uint64_t v5 = (a2 & 0xFFFFFFFFFFFFFFFLL) + 32;
        uint64_t v6 = a1 & 0xFFFFFFFFFFFFLL;
      }
      else
      {
        uint64_t v5 = _StringObject.sharedUTF8.getter(a1, a2);
        uint64_t v6 = v12;
      }
      char v7 = _sSRsRi_zrlE17withMemoryRebound2to_qd_1_qd__m_qd_1_SRyqd__Gqd_0_YKXEtqd_0_YKs5ErrorRd_0_Ri_d__Ri_d_1_r1_lFSRyxGq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lys4Int8VsAD_pqd_1_Isgyrzr_SRys5UInt8VGqd_1_sAD_pAIRszAGRsd__sAD_pRsd_0_Ri_d_1_r_1_lIetMgyrzo_Tpq5Sb_Tg507_sSRys4f5VGxs5E34_pIgyrzo_ACxsAD_pIegyrzr_lTRSb_TG5SRyAGGSbsAD_pIgyrzo_Tf1cn_n(v5, v6, (uint64_t (*)(uint64_t))_ss11_StringGutsV11withCStringyxxSPys4Int8VGKXEKlFxSRyAEGKXEfU_Sb_TG5TA_0);
      swift_bridgeObjectRelease(a2);
    }
  }
  uint64_t v10 = 0;
  if (v7) {
    uint64_t v10 = v15[0];
  }
  return ((unint64_t)((v7 & 1) == 0) << 32) | v10;
}

uint64_t lazy protocol witness table accessor for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier()
{
  uint64_t result = lazy protocol witness table cache variable for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier;
  if (!lazy protocol witness table cache variable for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier)
  {
    uint64_t v1 = type metadata accessor for MLSoundClassifier.Classifier(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLSoundClassifier.Classifier, v1);
    lazy protocol witness table cache variable for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier = result;
  }
  return result;
}

uint64_t sub_24B10C()
{
  uint64_t v1 = type metadata accessor for MLSoundClassifier.Model(0);
  uint64_t v2 = *(void *)(v1 - 8);
  uint64_t v3 = *(unsigned __int8 *)(v2 + 80);
  uint64_t v4 = ~*(unsigned __int8 *)(v2 + 80) & (v3 + 16);
  uint64_t v18 = *(void *)(v2 + 64);
  uint64_t v5 = v4 + v0;
  uint64_t v6 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v4 + v0, v6);
  if (EnumCaseMultiPayload == 2)
  {
LABEL_5:
    uint64_t v10 = *(void *)v5;
LABEL_6:
    swift_bridgeObjectRelease(v10);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v8 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(v4 + v0, v8))
    {
      case 0u:
      case 1u:
        uint64_t v9 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(v4 + v0, v9);
        break;
      case 2u:
        goto LABEL_5;
      case 3u:
        outlined consume of Result<_DataTable, Error>(*(void *)v5, *(unsigned char *)(v5 + 8));
        swift_bridgeObjectRelease(*(void *)(v5 + 24));
        uint64_t v10 = *(void *)(v5 + 40);
        goto LABEL_6;
      case 4u:
        uint64_t v17 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v17 - 8) + 8))(v4 + v0, v17);
        uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        swift_bridgeObjectRelease(*(void *)(v5 + *(int *)(v19 + 48) + 8));
        uint64_t v10 = *(void *)(v5 + *(int *)(v19 + 64) + 8);
        goto LABEL_6;
      default:
        break;
    }
  }
  uint64_t v11 = *(int *)(type metadata accessor for MLSoundClassifier.ModelParameters(0) + 28);
  if (*(void *)(v5 + v11 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(v5 + v11));
  }
  uint64_t v12 = *(int *)(v1 + 20) + v5;
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  uint64_t v14 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (swift_getEnumCaseMultiPayload(v12, v13) == 1) {
    uint64_t v14 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(v14);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v15 - 8) + 8))(v12, v15);
  return swift_deallocObject(v0, v18 + v4, v3 | 7);
}

uint64_t partial apply for closure #1 in MLSoundClassifier.init(checkpoint:)(uint64_t a1)
{
  type metadata accessor for MLSoundClassifier.Model(0);
  uint64_t v2 = (void *)swift_task_alloc(dword_3ACDD4);
  *(void *)(v1 + 16) = v2;
  void *v2 = v1;
  v2[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLSoundClassifier.init(checkpoint:)(a1);
}

uint64_t sub_24B321()
{
  uint64_t v1 = (int *)type metadata accessor for MLSoundClassifier(0);
  uint64_t v2 = *((void *)v1 - 1);
  uint64_t v3 = *(unsigned __int8 *)(v2 + 80);
  uint64_t v4 = ~*(unsigned __int8 *)(v2 + 80) & (v3 + 16);
  uint64_t v61 = *(void *)(v2 + 64);
  uint64_t v69 = type metadata accessor for URL(0);
  uint64_t v5 = *(void *)(v69 - 8);
  uint64_t v6 = *(unsigned __int8 *)(v5 + 80);
  uint64_t v70 = v5;
  uint64_t v64 = *(void *)(v5 + 64);
  uint64_t v60 = v4;
  uint64_t v59 = v0;
  uint64_t v7 = v4 + v0;
  uint64_t v8 = type metadata accessor for TrainingTablePrinter(0);
  if (!__swift_getEnumTagSinglePayload(v7, 1, v8))
  {
    uint64_t v9 = type metadata accessor for Date(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(v7, v9);

    swift_bridgeObjectRelease(*(void *)(v7 + *(int *)(v8 + 24)));
  }
  uint64_t v65 = v6;
  uint64_t v68 = v7;
  uint64_t v10 = v7 + v1[5];
  uint64_t v11 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v10, v11);
  if (EnumCaseMultiPayload == 2)
  {
LABEL_7:
    uint64_t v14 = *(void *)v10;
LABEL_8:
    swift_bridgeObjectRelease(v14);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v13 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(v10, v13))
    {
      case 0u:
      case 1u:
        (*(void (**)(uint64_t, uint64_t))(v70 + 8))(v10, v69);
        break;
      case 2u:
        goto LABEL_7;
      case 3u:
        outlined consume of Result<_DataTable, Error>(*(void *)v10, *(unsigned char *)(v10 + 8));
        swift_bridgeObjectRelease(*(void *)(v10 + 24));
        uint64_t v14 = *(void *)(v10 + 40);
        goto LABEL_8;
      case 4u:
        uint64_t v25 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v25 - 8) + 8))(v10, v25);
        uint64_t v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        swift_bridgeObjectRelease(*(void *)(v10 + *(int *)(v26 + 48) + 8));
        uint64_t v14 = *(void *)(v10 + *(int *)(v26 + 64) + 8);
        goto LABEL_8;
      default:
        break;
    }
  }
  uint64_t v15 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  uint64_t v16 = *(int *)(v15 + 28);
  if (*(void *)(v10 + v16 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(v10 + v16));
  }
  uint64_t v17 = *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20) + v10;
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  uint64_t v19 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (swift_getEnumCaseMultiPayload(v17, v18) == 1) {
    uint64_t v19 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(v19);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v20 - 8) + 8))(v17, v20);

  Swift::Bool v63 = v1;
  uint64_t v21 = v68 + v1[7];
  int v22 = swift_getEnumCaseMultiPayload(v21, v11);
  if (v22 == 2)
  {
    swift_bridgeObjectRelease(*(void *)v21);
    uint64_t v23 = v68;
  }
  else
  {
    uint64_t v23 = v68;
    if (v22 == 1)
    {
      uint64_t v24 = type metadata accessor for MLSoundClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(v21, v24))
      {
        case 0u:
        case 1u:
          (*(void (**)(uint64_t, uint64_t))(v70 + 8))(v21, v69);
          break;
        case 2u:
          uint64_t v27 = *(void *)v21;
          goto LABEL_23;
        case 3u:
          outlined consume of Result<_DataTable, Error>(*(void *)v21, *(_DWORD *)(v21 + 8));
          swift_bridgeObjectRelease(*(void *)(v21 + 24));
          uint64_t v27 = *(void *)(v21 + 40);
          goto LABEL_23;
        case 4u:
          uint64_t v28 = type metadata accessor for DataFrame(0);
          (*(void (**)(uint64_t, uint64_t))(*(void *)(v28 - 8) + 8))(v21, v28);
          uint64_t v29 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
          swift_bridgeObjectRelease(*(void *)(v21 + *(int *)(v29 + 48) + 8));
          uint64_t v30 = *(int *)(v29 + 64);
          uint64_t v23 = v68;
          uint64_t v27 = *(void *)(v21 + v30 + 8);
LABEL_23:
          swift_bridgeObjectRelease(v27);
          break;
        default:
          break;
      }
    }
  }
  uint64_t v31 = *(int *)(v15 + 28);
  if (*(void *)(v21 + v31 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(v31 + v21));
  }
  uint64_t v32 = (char *)(v23 + v1[8]);
  uint64_t v33 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int v34 = swift_getEnumCaseMultiPayload(v32, v33);
  switch(v34)
  {
    case 2:
      swift_errorRelease(*(void *)v32);
      break;
    case 1:
      uint64_t v62 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v66 = v3;
      uint64_t v37 = &v32[*(int *)(v62 + 20)];
      uint64_t v38 = type metadata accessor for DataFrame(0);
      uint64_t v39 = *(void (**)(char *, uint64_t))(*(void *)(v38 - 8) + 8);
      uint64_t v40 = v37;
      uint64_t v3 = v66;
      v39(v40, v38);
      uint64_t v41 = v38;
      uint64_t v23 = v68;
      v39(&v32[*(int *)(v62 + 24)], v41);
      uint64_t v1 = v63;
      break;
    case 0:
      uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload(v32, v35) == 1) {
        uint64_t v36 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v36 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v42 = __swift_instantiateConcreteTypeFromMangledName(v36);
      (*(void (**)(char *, uint64_t))(*(void *)(v42 - 8) + 8))(v32, v42);
      break;
  }
  uint64_t v43 = (char *)(v1[9] + v23);
  int v44 = swift_getEnumCaseMultiPayload(v43, v33);
  if (v44 == 2)
  {
    swift_errorRelease(*(void *)v43);
LABEL_42:
    uint64_t v45 = v64;
    uint64_t v46 = v65;
    goto LABEL_45;
  }
  if (v44 == 1)
  {
    uint64_t v49 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v50 = &v43[*(int *)(v49 + 20)];
    uint64_t v67 = v3;
    uint64_t v51 = type metadata accessor for DataFrame(0);
    uint64_t v52 = *(void (**)(char *, uint64_t))(*(void *)(v51 - 8) + 8);
    v52(v50, v51);
    uint64_t v53 = v51;
    uint64_t v3 = v67;
    v52(&v43[*(int *)(v49 + 24)], v53);
    goto LABEL_42;
  }
  uint64_t v45 = v64;
  uint64_t v46 = v65;
  if (!v44)
  {
    uint64_t v47 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    if (swift_getEnumCaseMultiPayload(v43, v47) == 1) {
      uint64_t v48 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    else {
      uint64_t v48 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    }
    uint64_t v54 = __swift_instantiateConcreteTypeFromMangledName(v48);
    (*(void (**)(char *, uint64_t))(*(void *)(v54 - 8) + 8))(v43, v54);
  }
LABEL_45:
  uint64_t v55 = v46 | v3 | 7;
  unint64_t v56 = (v61 + v60 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v57 = (v56 + v46 + 8) & ~v46;
  swift_bridgeObjectRelease(*(void *)(v59 + v56));
  (*(void (**)(uint64_t, uint64_t))(v70 + 8))(v59 + v57, v69);
  return swift_deallocObject(v59, v57 + v45, v55);
}

uint64_t partial apply for closure #1 in MLSoundClassifier.predictions(from:overlapFactor:predictionTimeWindowSize:)(uint64_t a1)
{
  uint64_t v3 = *(void *)(type metadata accessor for MLSoundClassifier(0) - 8);
  uint64_t v4 = ~*(unsigned __int8 *)(v3 + 80) & (*(unsigned __int8 *)(v3 + 80) + 16);
  unint64_t v5 = (*(void *)(v3 + 64) + v4 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v6 = *(unsigned __int8 *)(*(void *)(type metadata accessor for URL(0) - 8) + 80);
  uint64_t v7 = (v5 + v6 + 8) & ~v6;
  uint64_t v8 = *(void *)(v1 + v5);
  uint64_t v9 = (void *)swift_task_alloc(dword_3ACDFC);
  *(void *)(v2 + 16) = v9;
  *uint64_t v9 = v2;
  v9[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLSoundClassifier.predictions(from:overlapFactor:predictionTimeWindowSize:)(a1, v1 + v4, v8, v1 + v7);
}

id sub_24B8E0()
{
  uint64_t v1 = v0;
  id result = MLSoundClassifier.model.getter();
  *uint64_t v1 = result;
  return result;
}

void sub_24B8FA(id *a1)
{
}

char *initializeBufferWithCopyOfBuffer for MLSoundClassifier(char *__dst, char *__src, int *a3)
{
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v8 = *(void *)__src;
    *(void *)__dst = *(void *)__src;
    uint64_t v9 = (char *)(v8 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    unint64_t v5 = a3;
    uint64_t v6 = type metadata accessor for TrainingTablePrinter(0);
    v121 = v5;
    if (__swift_getEnumTagSinglePayload((uint64_t)__src, 1, v6))
    {
      uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingTablePrinter?);
      memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
    }
    else
    {
      uint64_t v10 = type metadata accessor for Date(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 16))(__dst, __src, v10);
      uint64_t v11 = *(int *)(v6 + 20);
      uint64_t v12 = *(void **)&__src[v11];
      *(void *)&__dst[v11] = v12;
      uint64_t v13 = *(int *)(v6 + 24);
      uint64_t v14 = *(void *)&__src[v13];
      *(void *)&__dst[v13] = v14;
      v12;
      LOBYTE(v12) = v14;
      unint64_t v5 = v121;
      swift_bridgeObjectRetain((_BYTE)v12);
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v6);
    }
    uint64_t v15 = v5[5];
    uint64_t v16 = &__dst[v15];
    uint64_t v17 = &__src[v15];
    uint64_t v18 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v17, v18);
    uint64_t v127 = v18;
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v25 = *(void *)v17;
      *(void *)uint64_t v16 = *(void *)v17;
      swift_bridgeObjectRetain(v25);
      swift_storeEnumTagMultiPayload(v16, v18, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v20 = type metadata accessor for MLSoundClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(v17, v20))
      {
        case 0u:
          uint64_t v21 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v21 - 8) + 16))(v16, v17, v21);
          int v22 = v16;
          uint64_t v23 = v20;
          uint64_t v24 = 0;
          goto LABEL_17;
        case 1u:
          uint64_t v26 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v26 - 8) + 16))(v16, v17, v26);
          uint64_t v117 = 1;
          goto LABEL_16;
        case 2u:
          uint64_t v27 = *(void *)v17;
          *(void *)uint64_t v16 = *(void *)v17;
          swift_bridgeObjectRetain(v27);
          uint64_t v117 = 2;
          goto LABEL_16;
        case 3u:
          uint64_t v28 = *(void *)v17;
          uint64_t v129 = v20;
          char v29 = v17[8];
          outlined copy of Result<_DataTable, Error>(*(void *)v17, v29);
          *(void *)uint64_t v16 = v28;
          v16[8] = v29;
          *((void *)v16 + 2) = *((void *)v17 + 2);
          uint64_t v30 = *((void *)v17 + 3);
          *((void *)v16 + 3) = v30;
          *((void *)v16 + 4) = *((void *)v17 + 4);
          uint64_t v31 = *((void *)v17 + 5);
          *((void *)v16 + 5) = v31;
          long long v32 = *((_OWORD *)v17 + 4);
          *((_OWORD *)v16 + 3) = *((_OWORD *)v17 + 3);
          *((_OWORD *)v16 + 4) = v32;
          v16[80] = v17[80];
          swift_bridgeObjectRetain(v30);
          LOBYTE(v30) = v31;
          uint64_t v18 = v127;
          swift_bridgeObjectRetain(v30);
          uint64_t v24 = 3;
          int v22 = v16;
          uint64_t v23 = v129;
          goto LABEL_17;
        case 4u:
          uint64_t v33 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v33 - 8) + 16))(v16, v17, v33);
          int v34 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
          uint64_t v35 = v34[12];
          *(void *)&v16[v35] = *(void *)&v17[v35];
          uint64_t v36 = *(void *)&v17[v35 + 8];
          *(void *)&v16[v35 + 8] = v36;
          uint64_t v37 = v34[16];
          *(void *)&v16[v37] = *(void *)&v17[v37];
          uint64_t v38 = *(void *)&v17[v37 + 8];
          *(void *)&v16[v37 + 8] = v38;
          uint64_t v39 = v34[20];
          v16[v39 + 32] = v17[v39 + 32];
          long long v40 = *(_OWORD *)&v17[v39];
          *(_OWORD *)&v16[v39 + 16] = *(_OWORD *)&v17[v39 + 16];
          *(_OWORD *)&v16[v39] = v40;
          swift_bridgeObjectRetain(v36);
          LOBYTE(v36) = v38;
          uint64_t v18 = v127;
          swift_bridgeObjectRetain(v36);
          uint64_t v117 = 4;
LABEL_16:
          uint64_t v24 = v117;
          int v22 = v16;
          uint64_t v23 = v20;
LABEL_17:
          swift_storeEnumTagMultiPayload(v22, v23, v24);
          swift_storeEnumTagMultiPayload(v16, v18, 1);
          break;
      }
    }
    else
    {
      memcpy(v16, v17, *(void *)(*(void *)(v18 - 8) + 64));
    }
    uint64_t v41 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
    *(void *)&v16[v41[5]] = *(void *)&v17[v41[5]];
    *(void *)&v16[v41[6]] = *(void *)&v17[v41[6]];
    uint64_t v42 = v41[7];
    uint64_t v43 = &v16[v42];
    int v44 = &v17[v42];
    uint64_t v45 = *(void *)&v17[v42 + 24];
    v130 = __dst;
    if (v45)
    {
      *((void *)v43 + 3) = v45;
      (**(void (***)(char *, char *))(v45 - 8))(v43, v44);
    }
    else
    {
      long long v46 = *(_OWORD *)v44;
      *((_OWORD *)v43 + 1) = *((_OWORD *)v44 + 1);
      *(_OWORD *)uint64_t v43 = v46;
    }
    uint64_t v47 = v41[8];
    v16[v47 + 8] = v17[v47 + 8];
    *(void *)&v16[v47] = *(void *)&v17[v47];
    *(void *)&v16[v41[9]] = *(void *)&v17[v41[9]];
    uint64_t v48 = *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
    uint64_t v49 = &v16[v48];
    uint64_t v50 = &v17[v48];
    uint64_t v51 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    int v52 = swift_getEnumCaseMultiPayload(v50, v51);
    BOOL v53 = v52 == 1;
    uint64_t v54 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
    if (v52 == 1) {
      uint64_t v54 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
    }
    uint64_t v55 = __swift_instantiateConcreteTypeFromMangledName(v54);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v55 - 8) + 16))(v49, v50, v55);
    swift_storeEnumTagMultiPayload(v49, v51, v53);
    uint64_t v56 = v121[6];
    uint64_t v57 = *(void **)&__src[v56];
    unint64_t v58 = v130;
    *(void *)&v130[v56] = v57;
    uint64_t v59 = v121[7];
    uint64_t v60 = &v130[v59];
    uint64_t v61 = &__src[v59];
    v57;
    uint64_t v62 = v127;
    int v63 = swift_getEnumCaseMultiPayload(v61, v127);
    if (v63 == 2)
    {
      uint64_t v65 = *(void *)v61;
      *(void *)uint64_t v60 = *(void *)v61;
      swift_bridgeObjectRetain(v65);
      swift_storeEnumTagMultiPayload(v60, v127, 2);
    }
    else if (v63 == 1)
    {
      uint64_t v124 = type metadata accessor for MLSoundClassifier.DataSource(0);
      unsigned int v119 = swift_getEnumCaseMultiPayload(v61, v124);
      switch(v119)
      {
        case 0u:
        case 1u:
          uint64_t v64 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v64 - 8) + 16))(v60, v61, v64);
          goto LABEL_34;
        case 2u:
          uint64_t v66 = *(void *)v61;
          *(void *)uint64_t v60 = *(void *)v61;
          goto LABEL_33;
        case 3u:
          uint64_t v67 = *(void *)v61;
          char v68 = v61[8];
          outlined copy of Result<_DataTable, Error>(*(void *)v61, v68);
          *(void *)uint64_t v60 = v67;
          v60[8] = v68;
          uint64_t v62 = v127;
          *((void *)v60 + 2) = *((void *)v61 + 2);
          uint64_t v66 = *((void *)v61 + 3);
          *((void *)v60 + 3) = v66;
          *((void *)v60 + 4) = *((void *)v61 + 4);
          uint64_t v69 = *((void *)v61 + 5);
          *((void *)v60 + 5) = v69;
          long long v70 = *((_OWORD *)v61 + 4);
          *((_OWORD *)v60 + 3) = *((_OWORD *)v61 + 3);
          *((_OWORD *)v60 + 4) = v70;
          v60[80] = v61[80];
          goto LABEL_32;
        case 4u:
          uint64_t v71 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v71 - 8) + 16))(v60, v61, v71);
          uint64_t v72 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
          uint64_t v73 = v72[12];
          *(void *)&v60[v73] = *(void *)&v61[v73];
          uint64_t v66 = *(void *)&v61[v73 + 8];
          *(void *)&v60[v73 + 8] = v66;
          uint64_t v74 = v72[16];
          *(void *)&v60[v74] = *(void *)&v61[v74];
          uint64_t v69 = *(void *)&v61[v74 + 8];
          *(void *)&v60[v74 + 8] = v69;
          uint64_t v75 = v72[20];
          v60[v75 + 32] = v61[v75 + 32];
          long long v76 = *(_OWORD *)&v61[v75];
          *(_OWORD *)&v60[v75 + 16] = *(_OWORD *)&v61[v75 + 16];
          *(_OWORD *)&v60[v75] = v76;
LABEL_32:
          swift_bridgeObjectRetain(v66);
          LOBYTE(v66) = v69;
          unint64_t v58 = v130;
LABEL_33:
          swift_bridgeObjectRetain(v66);
LABEL_34:
          swift_storeEnumTagMultiPayload(v60, v124, v119);
          swift_storeEnumTagMultiPayload(v60, v62, 1);
          break;
        case 5u:
          JUMPOUT(0x24C144);
      }
    }
    else
    {
      memcpy(v60, v61, *(void *)(*(void *)(v127 - 8) + 64));
    }
    *(void *)&v60[v41[5]] = *(void *)&v61[v41[5]];
    *(void *)&v60[v41[6]] = *(void *)&v61[v41[6]];
    uint64_t v77 = v41[7];
    char v78 = &v60[v77];
    uint64_t v79 = &v61[v77];
    uint64_t v80 = *(void *)&v61[v77 + 24];
    if (v80)
    {
      *((void *)v78 + 3) = v80;
      (**(void (***)(char *, char *))(v80 - 8))(v78, v79);
    }
    else
    {
      long long v81 = *(_OWORD *)v79;
      *((_OWORD *)v78 + 1) = *((_OWORD *)v79 + 1);
      *(_OWORD *)char v78 = v81;
    }
    uint64_t v82 = v41[8];
    v60[v82 + 8] = v61[v82 + 8];
    *(void *)&v60[v82] = *(void *)&v61[v82];
    *(void *)&v60[v41[9]] = *(void *)&v61[v41[9]];
    uint64_t v83 = v121;
    uint64_t v84 = v121[8];
    int64_t v85 = &v58[v84];
    uint64_t v86 = &__src[v84];
    uint64_t v128 = type metadata accessor for MLClassifierMetrics.Contents(0);
    unsigned int v87 = swift_getEnumCaseMultiPayload(v86, v128);
    if (v87 == 2)
    {
      uint64_t v92 = *(void *)v86;
      swift_errorRetain(*(void *)v86);
      *(void *)int64_t v85 = v92;
    }
    else if (v87 == 1)
    {
      *(void *)int64_t v85 = *(void *)v86;
      uint64_t v120 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v88 = *(int *)(v120 + 20);
      v118 = &v85[v88];
      uint64_t v89 = type metadata accessor for DataFrame(0);
      v125 = v85;
      uint64_t v90 = *(void (**)(char *, char *, uint64_t))(*(void *)(v89 - 8) + 16);
      uint64_t v91 = &v86[v88];
      uint64_t v83 = v121;
      v90(v118, v91, v89);
      v90(&v125[*(int *)(v120 + 24)], &v86[*(int *)(v120 + 24)], v89);
      int64_t v85 = v125;
    }
    else
    {
      uint64_t v126 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      int v93 = swift_getEnumCaseMultiPayload(v86, v126);
      BOOL v94 = v93 == 1;
      uint64_t v95 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      if (v93 == 1) {
        uint64_t v95 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      uint64_t v96 = __swift_instantiateConcreteTypeFromMangledName(v95);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v96 - 8) + 16))(v85, v86, v96);
      swift_storeEnumTagMultiPayload(v85, v126, v94);
    }
    swift_storeEnumTagMultiPayload(v85, v128, v87);
    uint64_t v97 = v83[9];
    long long v98 = &v130[v97];
    uint64_t v99 = &__src[v97];
    int v100 = swift_getEnumCaseMultiPayload(&__src[v97], v128);
    if (v100 == 2)
    {
      uint64_t v110 = *(void *)v99;
      swift_errorRetain(*(void *)v99);
      *(void *)long long v98 = v110;
      uint64_t v9 = v130;
      uint64_t v107 = 2;
      uint64_t v108 = v98;
      uint64_t v109 = v128;
      goto LABEL_49;
    }
    if (v100 == 1)
    {
      *(void *)long long v98 = *(void *)v99;
      uint64_t v101 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v102 = *(int *)(v101 + 20);
      v123 = &v98[v102];
      uint64_t v103 = type metadata accessor for DataFrame(0);
      v104 = &v99[v102];
      v105 = *(void (**)(char *, char *, uint64_t))(*(void *)(v103 - 8) + 16);
      v105(v123, v104, v103);
      uint64_t v106 = *(int *)(v101 + 24);
      uint64_t v9 = v130;
      v105(&v98[v106], &v99[v106], v103);
      uint64_t v107 = 1;
      uint64_t v108 = v98;
      uint64_t v109 = v128;
LABEL_49:
      swift_storeEnumTagMultiPayload(v108, v109, v107);
      return v9;
    }
    uint64_t v111 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v112 = swift_getEnumCaseMultiPayload(v99, v111);
    BOOL v113 = v112 == 1;
    double v114 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v112 == 1) {
      double v114 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v115 = __swift_instantiateConcreteTypeFromMangledName(v114);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v115 - 8) + 16))(v98, v99, v115);
    swift_storeEnumTagMultiPayload(v98, v111, v113);
    swift_storeEnumTagMultiPayload(v98, v128, 0);
    return v130;
  }
  return v9;
}

uint64_t destroy for MLSoundClassifier(uint64_t a1, int *a2)
{
  uint64_t v2 = a2;
  uint64_t v3 = a1;
  uint64_t v4 = type metadata accessor for TrainingTablePrinter(0);
  if (!__swift_getEnumTagSinglePayload(a1, 1, v4))
  {
    uint64_t v5 = type metadata accessor for Date(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8))(a1, v5);

    swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(v4 + 24)));
  }
  uint64_t v6 = a1 + a2[5];
  uint64_t v7 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v6, v7);
  if (EnumCaseMultiPayload == 2)
  {
LABEL_7:
    uint64_t v11 = *(void *)v6;
LABEL_8:
    swift_bridgeObjectRelease(v11);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v9 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(v6, v9))
    {
      case 0u:
      case 1u:
        uint64_t v10 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v10 - 8) + 8))(v6, v10);
        break;
      case 2u:
        goto LABEL_7;
      case 3u:
        outlined consume of Result<_DataTable, Error>(*(void *)v6, *(unsigned char *)(v6 + 8));
        swift_bridgeObjectRelease(*(void *)(v6 + 24));
        uint64_t v11 = *(void *)(v6 + 40);
        goto LABEL_8;
      case 4u:
        uint64_t v45 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v45 - 8) + 8))(v6, v45);
        uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        swift_bridgeObjectRelease(*(void *)(v6 + *(int *)(v46 + 48) + 8));
        uint64_t v11 = *(void *)(v6 + *(int *)(v46 + 64) + 8);
        goto LABEL_8;
      default:
        break;
    }
  }
  uint64_t v12 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  uint64_t v13 = *(int *)(v12 + 28);
  if (*(void *)(v6 + v13 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(v6 + v13));
  }
  uint64_t v14 = *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20) + v6;
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  uint64_t v16 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (swift_getEnumCaseMultiPayload(v14, v15) == 1) {
    uint64_t v16 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(v16);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v17 - 8) + 8))(v14, v17);

  uint64_t v18 = v3 + a2[7];
  int v19 = swift_getEnumCaseMultiPayload(v18, v7);
  if (v19 == 2)
  {
LABEL_17:
    uint64_t v22 = *(void *)v18;
LABEL_18:
    swift_bridgeObjectRelease(v22);
  }
  else if (v19 == 1)
  {
    uint64_t v20 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(v18, v20))
    {
      case 0u:
      case 1u:
        uint64_t v21 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v21 - 8) + 8))(v18, v21);
        break;
      case 2u:
        goto LABEL_17;
      case 3u:
        outlined consume of Result<_DataTable, Error>(*(void *)v18, *(_DWORD *)(v18 + 8));
        swift_bridgeObjectRelease(*(void *)(v18 + 24));
        uint64_t v22 = *(void *)(v18 + 40);
        goto LABEL_18;
      case 4u:
        uint64_t v47 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v47 - 8) + 8))(v18, v47);
        uint64_t v48 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        swift_bridgeObjectRelease(*(void *)(v18 + *(int *)(v48 + 48) + 8));
        uint64_t v22 = *(void *)(v18 + *(int *)(v48 + 64) + 8);
        goto LABEL_18;
      default:
        break;
    }
  }
  uint64_t v23 = *(int *)(v12 + 28);
  if (*(void *)(v18 + v23 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(v23 + v18));
  }
  uint64_t v24 = (char *)(v3 + a2[8]);
  uint64_t v25 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int v26 = swift_getEnumCaseMultiPayload(v24, v25);
  switch(v26)
  {
    case 2:
      swift_errorRelease(*(void *)v24);
      break;
    case 1:
      uint64_t v50 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      char v29 = &v24[*(int *)(v50 + 20)];
      uint64_t v49 = v3;
      uint64_t v30 = type metadata accessor for DataFrame(0);
      uint64_t v31 = *(void (**)(char *, uint64_t))(*(void *)(v30 - 8) + 8);
      long long v32 = v29;
      uint64_t v2 = a2;
      v31(v32, v30);
      uint64_t v33 = v30;
      uint64_t v3 = v49;
      v31(&v24[*(int *)(v50 + 24)], v33);
      break;
    case 0:
      uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload(v24, v27) == 1) {
        uint64_t v28 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v28 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(v28);
      (*(void (**)(char *, uint64_t))(*(void *)(v34 - 8) + 8))(v24, v34);
      break;
  }
  uint64_t v35 = (void *)(v2[9] + v3);
  uint64_t result = swift_getEnumCaseMultiPayload(v35, v25);
  switch(result)
  {
    case 2:
      return swift_errorRelease(*v35);
    case 1:
      uint64_t v39 = v35;
      uint64_t v40 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v41 = (char *)v39 + *(int *)(v40 + 20);
      uint64_t v42 = type metadata accessor for DataFrame(0);
      uint64_t v43 = *(void (**)(char *, uint64_t))(*(void *)(v42 - 8) + 8);
      v43(v41, v42);
      return ((uint64_t (*)(char *, uint64_t))v43)((char *)v39 + *(int *)(v40 + 24), v42);
    case 0:
      uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload(v35, v37) == 1) {
        uint64_t v38 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v38 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v44 = __swift_instantiateConcreteTypeFromMangledName(v38);
      return (*(uint64_t (**)(void *, uint64_t))(*(void *)(v44 - 8) + 8))(v35, v44);
  }
  return result;
}

char *initializeWithCopy for MLSoundClassifier(char *__dst, char *__src, int *a3)
{
  uint64_t v3 = __src;
  uint64_t v5 = type metadata accessor for TrainingTablePrinter(0);
  if (__swift_getEnumTagSinglePayload((uint64_t)__src, 1, v5))
  {
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingTablePrinter?);
    memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
  }
  else
  {
    uint64_t v7 = type metadata accessor for Date(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
    uint64_t v8 = *(int *)(v5 + 20);
    uint64_t v9 = *(void **)&__src[v8];
    *(void *)&__dst[v8] = v9;
    uint64_t v10 = *(int *)(v5 + 24);
    uint64_t v11 = *(void *)&__src[v10];
    *(void *)&__dst[v10] = v11;
    v9;
    LOBYTE(v9) = v11;
    uint64_t v3 = __src;
    swift_bridgeObjectRetain((_BYTE)v9);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v5);
  }
  uint64_t v12 = a3[5];
  uint64_t v117 = __dst;
  uint64_t v13 = &__dst[v12];
  uint64_t v14 = &v3[v12];
  uint64_t v15 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v14, v15);
  uint64_t v124 = v15;
  if (EnumCaseMultiPayload == 2)
  {
    uint64_t v22 = *(void *)v14;
    *(void *)uint64_t v13 = *(void *)v14;
    swift_bridgeObjectRetain(v22);
    swift_storeEnumTagMultiPayload(v13, v15, 2);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v17 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(v14, v17))
    {
      case 0u:
        uint64_t v18 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 16))(v13, v14, v18);
        int v19 = v13;
        uint64_t v20 = v17;
        uint64_t v21 = 0;
        goto LABEL_15;
      case 1u:
        uint64_t v23 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v23 - 8) + 16))(v13, v14, v23);
        uint64_t v114 = 1;
        goto LABEL_14;
      case 2u:
        uint64_t v24 = *(void *)v14;
        *(void *)uint64_t v13 = *(void *)v14;
        swift_bridgeObjectRetain(v24);
        uint64_t v114 = 2;
        goto LABEL_14;
      case 3u:
        uint64_t v25 = *(void *)v14;
        char v26 = v14[8];
        outlined copy of Result<_DataTable, Error>(*(void *)v14, v26);
        *(void *)uint64_t v13 = v25;
        v13[8] = v26;
        *((void *)v13 + 2) = *((void *)v14 + 2);
        uint64_t v27 = *((void *)v14 + 3);
        *((void *)v13 + 3) = v27;
        *((void *)v13 + 4) = *((void *)v14 + 4);
        uint64_t v28 = *((void *)v14 + 5);
        *((void *)v13 + 5) = v28;
        long long v29 = *((_OWORD *)v14 + 4);
        *((_OWORD *)v13 + 3) = *((_OWORD *)v14 + 3);
        *((_OWORD *)v13 + 4) = v29;
        v13[80] = v14[80];
        swift_bridgeObjectRetain(v27);
        LOBYTE(v27) = v28;
        uint64_t v15 = v124;
        swift_bridgeObjectRetain(v27);
        uint64_t v114 = 3;
        goto LABEL_14;
      case 4u:
        uint64_t v30 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v30 - 8) + 16))(v13, v14, v30);
        uint64_t v31 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        uint64_t v32 = v31[12];
        *(void *)&v13[v32] = *(void *)&v14[v32];
        uint64_t v33 = *(void *)&v14[v32 + 8];
        *(void *)&v13[v32 + 8] = v33;
        uint64_t v34 = v31[16];
        *(void *)&v13[v34] = *(void *)&v14[v34];
        uint64_t v35 = *(void *)&v14[v34 + 8];
        *(void *)&v13[v34 + 8] = v35;
        uint64_t v36 = v31[20];
        v13[v36 + 32] = v14[v36 + 32];
        long long v37 = *(_OWORD *)&v14[v36];
        *(_OWORD *)&v13[v36 + 16] = *(_OWORD *)&v14[v36 + 16];
        *(_OWORD *)&v13[v36] = v37;
        swift_bridgeObjectRetain(v33);
        LOBYTE(v33) = v35;
        uint64_t v15 = v124;
        swift_bridgeObjectRetain(v33);
        uint64_t v114 = 4;
LABEL_14:
        uint64_t v21 = v114;
        int v19 = v13;
        uint64_t v20 = v17;
LABEL_15:
        swift_storeEnumTagMultiPayload(v19, v20, v21);
        swift_storeEnumTagMultiPayload(v13, v15, 1);
        break;
    }
  }
  else
  {
    memcpy(v13, v14, *(void *)(*(void *)(v15 - 8) + 64));
  }
  uint64_t v38 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  *(void *)&v13[v38[5]] = *(void *)&v14[v38[5]];
  *(void *)&v13[v38[6]] = *(void *)&v14[v38[6]];
  uint64_t v39 = v38[7];
  uint64_t v40 = &v13[v39];
  uint64_t v41 = &v14[v39];
  uint64_t v42 = *(void *)&v14[v39 + 24];
  if (v42)
  {
    *((void *)v40 + 3) = v42;
    (**(void (***)(char *, char *))(v42 - 8))(v40, v41);
  }
  else
  {
    long long v43 = *(_OWORD *)v41;
    *((_OWORD *)v40 + 1) = *((_OWORD *)v41 + 1);
    *(_OWORD *)uint64_t v40 = v43;
  }
  uint64_t v44 = v38[8];
  v13[v44 + 8] = v14[v44 + 8];
  *(void *)&v13[v44] = *(void *)&v14[v44];
  *(void *)&v13[v38[9]] = *(void *)&v14[v38[9]];
  uint64_t v45 = *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  uint64_t v46 = &v13[v45];
  uint64_t v47 = &v14[v45];
  uint64_t v48 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int v49 = swift_getEnumCaseMultiPayload(v47, v48);
  BOOL v50 = v49 == 1;
  uint64_t v51 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (v49 == 1) {
    uint64_t v51 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v52 = __swift_instantiateConcreteTypeFromMangledName(v51);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v52 - 8) + 16))(v46, v47, v52);
  swift_storeEnumTagMultiPayload(v46, v48, v50);
  uint64_t v53 = a3[6];
  uint64_t v54 = __src;
  uint64_t v55 = *(void **)&__src[v53];
  *(void *)&v117[v53] = v55;
  uint64_t v56 = a3[7];
  uint64_t v57 = &v117[v56];
  unint64_t v58 = &__src[v56];
  v55;
  uint64_t v59 = v124;
  int v60 = swift_getEnumCaseMultiPayload(v58, v124);
  if (v60 == 2)
  {
    uint64_t v62 = *(void *)v58;
    *(void *)uint64_t v57 = *(void *)v58;
    swift_bridgeObjectRetain(v62);
    swift_storeEnumTagMultiPayload(v57, v124, 2);
  }
  else if (v60 == 1)
  {
    uint64_t v118 = type metadata accessor for MLSoundClassifier.DataSource(0);
    unsigned int v115 = swift_getEnumCaseMultiPayload(v58, v118);
    switch(v115)
    {
      case 0u:
      case 1u:
        uint64_t v61 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v61 - 8) + 16))(v57, v58, v61);
        goto LABEL_32;
      case 2u:
        uint64_t v63 = *(void *)v58;
        *(void *)uint64_t v57 = *(void *)v58;
        goto LABEL_31;
      case 3u:
        uint64_t v64 = *(void *)v58;
        char v65 = v58[8];
        outlined copy of Result<_DataTable, Error>(*(void *)v58, v65);
        *(void *)uint64_t v57 = v64;
        v57[8] = v65;
        uint64_t v54 = __src;
        *((void *)v57 + 2) = *((void *)v58 + 2);
        uint64_t v63 = *((void *)v58 + 3);
        *((void *)v57 + 3) = v63;
        *((void *)v57 + 4) = *((void *)v58 + 4);
        uint64_t v66 = *((void *)v58 + 5);
        *((void *)v57 + 5) = v66;
        long long v67 = *((_OWORD *)v58 + 4);
        *((_OWORD *)v57 + 3) = *((_OWORD *)v58 + 3);
        *((_OWORD *)v57 + 4) = v67;
        v57[80] = v58[80];
        goto LABEL_30;
      case 4u:
        uint64_t v68 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v68 - 8) + 16))(v57, v58, v68);
        uint64_t v69 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        uint64_t v70 = v69[12];
        *(void *)&v57[v70] = *(void *)&v58[v70];
        uint64_t v63 = *(void *)&v58[v70 + 8];
        *(void *)&v57[v70 + 8] = v63;
        uint64_t v71 = v69[16];
        *(void *)&v57[v71] = *(void *)&v58[v71];
        uint64_t v66 = *(void *)&v58[v71 + 8];
        *(void *)&v57[v71 + 8] = v66;
        uint64_t v72 = v69[20];
        v57[v72 + 32] = v58[v72 + 32];
        long long v73 = *(_OWORD *)&v58[v72];
        *(_OWORD *)&v57[v72 + 16] = *(_OWORD *)&v58[v72 + 16];
        *(_OWORD *)&v57[v72] = v73;
LABEL_30:
        swift_bridgeObjectRetain(v63);
        LOBYTE(v63) = v66;
        uint64_t v59 = v124;
LABEL_31:
        swift_bridgeObjectRetain(v63);
LABEL_32:
        swift_storeEnumTagMultiPayload(v57, v118, v115);
        swift_storeEnumTagMultiPayload(v57, v59, 1);
        break;
    }
  }
  else
  {
    memcpy(v57, v58, *(void *)(*(void *)(v124 - 8) + 64));
  }
  *(void *)&v57[v38[5]] = *(void *)&v58[v38[5]];
  *(void *)&v57[v38[6]] = *(void *)&v58[v38[6]];
  uint64_t v74 = v38[7];
  uint64_t v75 = &v57[v74];
  long long v76 = &v58[v74];
  uint64_t v77 = *(void *)&v58[v74 + 24];
  if (v77)
  {
    *((void *)v75 + 3) = v77;
    (**(void (***)(char *, char *))(v77 - 8))(v75, v76);
  }
  else
  {
    long long v78 = *(_OWORD *)v76;
    *((_OWORD *)v75 + 1) = *((_OWORD *)v76 + 1);
    *(_OWORD *)uint64_t v75 = v78;
  }
  uint64_t v79 = v38[8];
  v57[v79 + 8] = v58[v79 + 8];
  *(void *)&v57[v79] = *(void *)&v58[v79];
  *(void *)&v57[v38[9]] = *(void *)&v58[v38[9]];
  uint64_t v80 = a3[8];
  long long v81 = v117;
  uint64_t v82 = &v117[v80];
  uint64_t v83 = &v54[v80];
  uint64_t v125 = type metadata accessor for MLClassifierMetrics.Contents(0);
  unsigned int v84 = swift_getEnumCaseMultiPayload(v83, v125);
  if (v84 == 2)
  {
    uint64_t v90 = *(void *)v83;
    swift_errorRetain(v90);
    *(void *)uint64_t v82 = v90;
  }
  else if (v84 == 1)
  {
    *(void *)uint64_t v82 = *(void *)v83;
    uint64_t v119 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v85 = *(int *)(v119 + 20);
    long long v116 = &v82[v85];
    uint64_t v86 = type metadata accessor for DataFrame(0);
    unsigned int v87 = &v83[v85];
    uint64_t v88 = *(void (**)(char *, char *, uint64_t))(*(void *)(v86 - 8) + 16);
    v88(v116, v87, v86);
    uint64_t v89 = v86;
    uint64_t v54 = __src;
    v88(&v82[*(int *)(v119 + 24)], &v83[*(int *)(v119 + 24)], v89);
    long long v81 = v117;
  }
  else
  {
    uint64_t v120 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v91 = swift_getEnumCaseMultiPayload(v83, v120);
    BOOL v92 = v91 == 1;
    int v93 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v91 == 1) {
      int v93 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v94 = __swift_instantiateConcreteTypeFromMangledName(v93);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v94 - 8) + 16))(v82, v83, v94);
    swift_storeEnumTagMultiPayload(v82, v120, v92);
    uint64_t v54 = __src;
  }
  swift_storeEnumTagMultiPayload(v82, v125, v84);
  uint64_t v95 = a3[9];
  uint64_t v96 = &v81[v95];
  uint64_t v97 = &v54[v95];
  int v98 = swift_getEnumCaseMultiPayload(v97, v125);
  if (v98 == 2)
  {
    uint64_t v106 = *(void *)v97;
    swift_errorRetain(*(void *)v97);
    *(void *)uint64_t v96 = v106;
    uint64_t v103 = 2;
    v104 = v96;
    uint64_t v105 = v125;
  }
  else if (v98 == 1)
  {
    *(void *)uint64_t v96 = *(void *)v97;
    uint64_t v122 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v99 = v97;
    uint64_t v100 = *(int *)(v122 + 20);
    uint64_t v101 = type metadata accessor for DataFrame(0);
    uint64_t v102 = *(void (**)(char *, char *, uint64_t))(*(void *)(v101 - 8) + 16);
    v102(&v96[v100], &v99[v100], v101);
    v102(&v96[*(int *)(v122 + 24)], &v99[*(int *)(v122 + 24)], v101);
    long long v81 = v117;
    uint64_t v103 = 1;
    v104 = v96;
    uint64_t v105 = v125;
  }
  else
  {
    uint64_t v107 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v108 = swift_getEnumCaseMultiPayload(v97, v107);
    uint64_t v109 = v97;
    BOOL v110 = v108 == 1;
    uint64_t v111 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v108 == 1) {
      uint64_t v111 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v112 = __swift_instantiateConcreteTypeFromMangledName(v111);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v112 - 8) + 16))(v96, v109, v112);
    swift_storeEnumTagMultiPayload(v96, v107, v110);
    v104 = v96;
    uint64_t v105 = v125;
    uint64_t v103 = 0;
  }
  swift_storeEnumTagMultiPayload(v104, v105, v103);
  return v81;
}

char *assignWithCopy for MLSoundClassifier(char *__dst, char *__src, int *a3)
{
  uint64_t v4 = type metadata accessor for TrainingTablePrinter(0);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)__dst, 1, v4);
  int v6 = __swift_getEnumTagSinglePayload((uint64_t)__src, 1, v4);
  if (EnumTagSinglePayload)
  {
    if (!v6)
    {
      uint64_t v7 = type metadata accessor for Date(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
      uint64_t v8 = *(int *)(v4 + 20);
      uint64_t v9 = *(void **)&__src[v8];
      *(void *)&__dst[v8] = v9;
      uint64_t v10 = *(int *)(v4 + 24);
      uint64_t v11 = *(void *)&__src[v10];
      *(void *)&__dst[v10] = v11;
      v9;
      swift_bridgeObjectRetain(v11);
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v4);
      goto LABEL_7;
    }
    goto LABEL_6;
  }
  if (v6)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)__dst, type metadata accessor for TrainingTablePrinter);
LABEL_6:
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingTablePrinter?);
    memcpy(__dst, __src, *(void *)(*(void *)(v12 - 8) + 64));
    goto LABEL_7;
  }
  uint64_t v24 = type metadata accessor for Date(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v24 - 8) + 24))(__dst, __src, v24);
  uint64_t v25 = *(int *)(v4 + 20);
  char v26 = *(void **)&__src[v25];
  uint64_t v27 = *(void **)&__dst[v25];
  *(void *)&__dst[v25] = v26;
  v26;

  uint64_t v28 = *(int *)(v4 + 24);
  uint64_t v29 = *(void *)&__src[v28];
  uint64_t v30 = *(void *)&__dst[v28];
  *(void *)&__dst[v28] = v29;
  swift_bridgeObjectRetain(v29);
  swift_bridgeObjectRelease(v30);
LABEL_7:
  uint64_t v13 = a3[5];
  uint64_t v14 = &__dst[v13];
  uint64_t v15 = &__src[v13];
  v132 = __dst;
  if (__dst != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v14, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v16 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v15, v16);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v23 = *(void *)v15;
      *(void *)uint64_t v14 = *(void *)v15;
      swift_bridgeObjectRetain(v23);
      swift_storeEnumTagMultiPayload(v14, v16, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v18 = type metadata accessor for MLSoundClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(v15, v18))
      {
        case 0u:
          uint64_t v19 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16))(v14, v15, v19);
          uint64_t v20 = v14;
          uint64_t v21 = v18;
          uint64_t v22 = 0;
          goto LABEL_20;
        case 1u:
          uint64_t v31 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v31 - 8) + 16))(v14, v15, v31);
          uint64_t v123 = 1;
          goto LABEL_19;
        case 2u:
          uint64_t v32 = *(void *)v15;
          *(void *)uint64_t v14 = *(void *)v15;
          swift_bridgeObjectRetain(v32);
          uint64_t v123 = 2;
          goto LABEL_19;
        case 3u:
          uint64_t v33 = *(void *)v15;
          uint64_t v133 = v18;
          char v34 = v15[8];
          outlined copy of Result<_DataTable, Error>(*(void *)v15, v34);
          *(void *)uint64_t v14 = v33;
          v14[8] = v34;
          *((void *)v14 + 2) = *((void *)v15 + 2);
          uint64_t v35 = *((void *)v15 + 3);
          *((void *)v14 + 3) = v35;
          *((void *)v14 + 4) = *((void *)v15 + 4);
          uint64_t v36 = *((void *)v15 + 5);
          *((void *)v14 + 5) = v36;
          long long v37 = *((_OWORD *)v15 + 4);
          *((_OWORD *)v14 + 3) = *((_OWORD *)v15 + 3);
          *((_OWORD *)v14 + 4) = v37;
          v14[80] = v15[80];
          swift_bridgeObjectRetain(v35);
          swift_bridgeObjectRetain(v36);
          uint64_t v22 = 3;
          uint64_t v20 = v14;
          uint64_t v21 = v133;
          goto LABEL_20;
        case 4u:
          uint64_t v38 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v38 - 8) + 16))(v14, v15, v38);
          uint64_t v39 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
          uint64_t v40 = v39[12];
          *(void *)&v14[v40] = *(void *)&v15[v40];
          uint64_t v41 = *(void *)&v15[v40 + 8];
          *(void *)&v14[v40 + 8] = v41;
          uint64_t v42 = v39[16];
          *(void *)&v14[v42] = *(void *)&v15[v42];
          uint64_t v43 = *(void *)&v15[v42 + 8];
          *(void *)&v14[v42 + 8] = v43;
          uint64_t v44 = v39[20];
          v14[v44 + 32] = v15[v44 + 32];
          long long v45 = *(_OWORD *)&v15[v44];
          *(_OWORD *)&v14[v44 + 16] = *(_OWORD *)&v15[v44 + 16];
          *(_OWORD *)&v14[v44] = v45;
          swift_bridgeObjectRetain(v41);
          swift_bridgeObjectRetain(v43);
          uint64_t v123 = 4;
LABEL_19:
          uint64_t v22 = v123;
          uint64_t v20 = v14;
          uint64_t v21 = v18;
LABEL_20:
          swift_storeEnumTagMultiPayload(v20, v21, v22);
          swift_storeEnumTagMultiPayload(v14, v16, 1);
          break;
      }
    }
    else
    {
      memcpy(v14, v15, *(void *)(*(void *)(v16 - 8) + 64));
    }
  }
  uint64_t v46 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  *(void *)&v14[v46[5]] = *(void *)&v15[v46[5]];
  *(void *)&v14[v46[6]] = *(void *)&v15[v46[6]];
  uint64_t v47 = v46[7];
  uint64_t v48 = &v14[v47];
  int v49 = &v15[v47];
  uint64_t v50 = *(void *)&v15[v47 + 24];
  if (*(void *)&v14[v47 + 24])
  {
    if (v50)
    {
      __swift_assign_boxed_opaque_existential_0((uint64_t *)&v14[v47], (uint64_t *)&v15[v47]);
      goto LABEL_28;
    }
    __swift_destroy_boxed_opaque_existential_1Tm(&v14[v47]);
  }
  else if (v50)
  {
    *((void *)v48 + 3) = v50;
    (**(void (***)(char *, char *))(v50 - 8))(v48, v49);
    goto LABEL_28;
  }
  long long v51 = *(_OWORD *)v49;
  *((_OWORD *)v48 + 1) = *((_OWORD *)v49 + 1);
  *(_OWORD *)uint64_t v48 = v51;
LABEL_28:
  uint64_t v52 = v46[8];
  v14[v52 + 8] = v15[v52 + 8];
  *(void *)&v14[v52] = *(void *)&v15[v52];
  *(void *)&v14[v46[9]] = *(void *)&v15[v46[9]];
  uint64_t v53 = type metadata accessor for MLSoundClassifier.Model(0);
  if (v132 != __src)
  {
    uint64_t v54 = *(int *)(v53 + 20);
    uint64_t v55 = &v15[v54];
    uint64_t v56 = (uint64_t)&v14[v54];
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v56, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    uint64_t v57 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    int v58 = swift_getEnumCaseMultiPayload(v55, v57);
    BOOL v59 = v58 == 1;
    int v60 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
    if (v58 == 1) {
      int v60 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
    }
    uint64_t v61 = __swift_instantiateConcreteTypeFromMangledName(v60);
    (*(void (**)(uint64_t, char *, uint64_t))(*(void *)(v61 - 8) + 16))(v56, v55, v61);
    swift_storeEnumTagMultiPayload(v56, v57, v59);
  }
  uint64_t v62 = a3[6];
  uint64_t v63 = *(void **)&__src[v62];
  uint64_t v64 = *(void **)&v132[v62];
  *(void *)&v132[v62] = v63;
  v63;

  uint64_t v65 = a3[7];
  uint64_t v66 = &v132[v65];
  long long v67 = &__src[v65];
  if (v132 != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v66, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v68 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
    int v69 = swift_getEnumCaseMultiPayload(v67, v68);
    if (v69 == 2)
    {
      uint64_t v72 = *(void *)v67;
      *(void *)uint64_t v66 = *(void *)v67;
      swift_bridgeObjectRetain(v72);
      swift_storeEnumTagMultiPayload(v66, v68, 2);
    }
    else if (v69 == 1)
    {
      uint64_t v70 = type metadata accessor for MLSoundClassifier.DataSource(0);
      unsigned int v124 = swift_getEnumCaseMultiPayload(v67, v70);
      switch(v124)
      {
        case 0u:
        case 1u:
          uint64_t v71 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v71 - 8) + 16))(v66, v67, v71);
          goto LABEL_44;
        case 2u:
          uint64_t v73 = *(void *)v67;
          *(void *)uint64_t v66 = *(void *)v67;
          goto LABEL_43;
        case 3u:
          uint64_t v128 = v70;
          uint64_t v74 = *(void *)v67;
          uint64_t v126 = v68;
          char v75 = v67[8];
          outlined copy of Result<_DataTable, Error>(*(void *)v67, v75);
          *(void *)uint64_t v66 = v74;
          v66[8] = v75;
          uint64_t v68 = v126;
          *((void *)v66 + 2) = *((void *)v67 + 2);
          uint64_t v73 = *((void *)v67 + 3);
          *((void *)v66 + 3) = v73;
          *((void *)v66 + 4) = *((void *)v67 + 4);
          uint64_t v76 = *((void *)v67 + 5);
          *((void *)v66 + 5) = v76;
          long long v77 = *((_OWORD *)v67 + 4);
          *((_OWORD *)v66 + 3) = *((_OWORD *)v67 + 3);
          *((_OWORD *)v66 + 4) = v77;
          v66[80] = v67[80];
          goto LABEL_42;
        case 4u:
          uint64_t v78 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v78 - 8) + 16))(v66, v67, v78);
          uint64_t v79 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
          uint64_t v80 = v79[12];
          *(void *)&v66[v80] = *(void *)&v67[v80];
          uint64_t v73 = *(void *)&v67[v80 + 8];
          *(void *)&v66[v80 + 8] = v73;
          uint64_t v81 = v79[16];
          *(void *)&v66[v81] = *(void *)&v67[v81];
          uint64_t v128 = v70;
          uint64_t v76 = *(void *)&v67[v81 + 8];
          *(void *)&v66[v81 + 8] = v76;
          uint64_t v82 = v79[20];
          v66[v82 + 32] = v67[v82 + 32];
          long long v83 = *(_OWORD *)&v67[v82];
          *(_OWORD *)&v66[v82 + 16] = *(_OWORD *)&v67[v82 + 16];
          *(_OWORD *)&v66[v82] = v83;
LABEL_42:
          swift_bridgeObjectRetain(v73);
          LOBYTE(v73) = v76;
          uint64_t v70 = v128;
LABEL_43:
          swift_bridgeObjectRetain(v73);
LABEL_44:
          swift_storeEnumTagMultiPayload(v66, v70, v124);
          swift_storeEnumTagMultiPayload(v66, v68, 1);
          break;
        case 5u:
          JUMPOUT(0x24D768);
      }
    }
    else
    {
      memcpy(v66, v67, *(void *)(*(void *)(v68 - 8) + 64));
    }
  }
  *(void *)&v66[v46[5]] = *(void *)&v67[v46[5]];
  *(void *)&v66[v46[6]] = *(void *)&v67[v46[6]];
  uint64_t v84 = v46[7];
  uint64_t v85 = &v66[v84];
  uint64_t v86 = &v67[v84];
  uint64_t v87 = *(void *)&v67[v84 + 24];
  if (*(void *)&v66[v84 + 24])
  {
    if (v87)
    {
      __swift_assign_boxed_opaque_existential_0((uint64_t *)&v66[v84], (uint64_t *)&v67[v84]);
      goto LABEL_52;
    }
    __swift_destroy_boxed_opaque_existential_1Tm(&v66[v84]);
  }
  else if (v87)
  {
    *((void *)v85 + 3) = v87;
    (**(void (***)(char *, char *))(v87 - 8))(v85, v86);
    goto LABEL_52;
  }
  long long v88 = *(_OWORD *)v86;
  *((_OWORD *)v85 + 1) = *((_OWORD *)v86 + 1);
  *(_OWORD *)uint64_t v85 = v88;
LABEL_52:
  uint64_t v89 = v46[8];
  v66[v89 + 8] = v67[v89 + 8];
  *(void *)&v66[v89] = *(void *)&v67[v89];
  *(void *)&v66[v46[9]] = *(void *)&v67[v46[9]];
  uint64_t result = v132;
  if (v132 != __src)
  {
    uint64_t v91 = a3[8];
    BOOL v92 = &v132[v91];
    int v93 = &__src[v91];
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v92, type metadata accessor for MLClassifierMetrics.Contents);
    uint64_t v94 = type metadata accessor for MLClassifierMetrics.Contents(0);
    unsigned int v95 = swift_getEnumCaseMultiPayload(v93, v94);
    uint64_t v134 = v94;
    if (v95 == 2)
    {
      uint64_t v100 = *(void *)v93;
      swift_errorRetain(*(void *)v93);
      *(void *)BOOL v92 = v100;
    }
    else if (v95 == 1)
    {
      *(void *)BOOL v92 = *(void *)v93;
      uint64_t v125 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v96 = *(int *)(v125 + 20);
      uint64_t v127 = &v92[v96];
      uint64_t v97 = type metadata accessor for DataFrame(0);
      int v98 = *(void (**)(char *, char *, uint64_t))(*(void *)(v97 - 8) + 16);
      uint64_t v99 = &v93[v96];
      uint64_t v94 = v134;
      v98(v127, v99, v97);
      v98(&v92[*(int *)(v125 + 24)], &v93[*(int *)(v125 + 24)], v97);
      unsigned int v95 = 1;
    }
    else
    {
      uint64_t v101 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      int v102 = swift_getEnumCaseMultiPayload(v93, v101);
      BOOL v103 = v102 == 1;
      v104 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      if (v102 == 1) {
        v104 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      uint64_t v105 = __swift_instantiateConcreteTypeFromMangledName(v104);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v105 - 8) + 16))(v92, v93, v105);
      swift_storeEnumTagMultiPayload(v92, v101, v103);
      uint64_t v94 = v134;
    }
    swift_storeEnumTagMultiPayload(v92, v94, v95);
    uint64_t v106 = a3[9];
    uint64_t v107 = &v132[v106];
    int v108 = &__src[v106];
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v132[v106], type metadata accessor for MLClassifierMetrics.Contents);
    int v109 = swift_getEnumCaseMultiPayload(v108, v94);
    if (v109 == 2)
    {
      uint64_t v116 = *(void *)v108;
      swift_errorRetain(*(void *)v108);
      *(void *)uint64_t v107 = v116;
      uint64_t v113 = 2;
      uint64_t v114 = v107;
      uint64_t v115 = v94;
    }
    else if (v109 == 1)
    {
      *(void *)uint64_t v107 = *(void *)v108;
      uint64_t v130 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v110 = *(int *)(v130 + 20);
      uint64_t v111 = type metadata accessor for DataFrame(0);
      uint64_t v112 = *(void (**)(char *, char *, uint64_t))(*(void *)(v111 - 8) + 16);
      v112(&v107[v110], &v108[v110], v111);
      v112(&v107[*(int *)(v130 + 24)], &v108[*(int *)(v130 + 24)], v111);
      uint64_t v113 = 1;
      uint64_t v114 = v107;
      uint64_t v115 = v134;
    }
    else
    {
      uint64_t v117 = v94;
      uint64_t v118 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      int v119 = swift_getEnumCaseMultiPayload(v108, v118);
      BOOL v120 = v119 == 1;
      v121 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      if (v119 == 1) {
        v121 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      uint64_t v122 = __swift_instantiateConcreteTypeFromMangledName(v121);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v122 - 8) + 16))(v107, v108, v122);
      swift_storeEnumTagMultiPayload(v107, v118, v120);
      uint64_t v114 = v107;
      uint64_t v115 = v117;
      uint64_t v113 = 0;
    }
    swift_storeEnumTagMultiPayload(v114, v115, v113);
    return v132;
  }
  return result;
}

char *initializeWithTake for MLSoundClassifier(char *__dst, char *__src, int *a3)
{
  uint64_t v3 = type metadata accessor for TrainingTablePrinter(0);
  if (__swift_getEnumTagSinglePayload((uint64_t)__src, 1, v3))
  {
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingTablePrinter?);
    memcpy(__dst, __src, *(void *)(*(void *)(v4 - 8) + 64));
  }
  else
  {
    uint64_t v5 = type metadata accessor for Date(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v5 - 8) + 32))(__dst, __src, v5);
    *(void *)&__dst[*(int *)(v3 + 20)] = *(void *)&__src[*(int *)(v3 + 20)];
    *(void *)&__dst[*(int *)(v3 + 24)] = *(void *)&__src[*(int *)(v3 + 24)];
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v3);
  }
  uint64_t v6 = a3[5];
  uint64_t v7 = &__dst[v6];
  uint64_t v8 = &__src[v6];
  uint64_t v9 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  uint64_t v92 = v9;
  if (swift_getEnumCaseMultiPayload(v8, v9) != 1)
  {
    memcpy(v7, v8, *(void *)(*(void *)(v9 - 8) + 64));
    goto LABEL_16;
  }
  uint64_t v10 = type metadata accessor for MLSoundClassifier.DataSource(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v8, v10);
  if (EnumCaseMultiPayload == 4)
  {
    uint64_t v16 = type metadata accessor for DataFrame(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 32))(v7, v8, v16);
    uint64_t v17 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
    *(_OWORD *)&v7[v17[12]] = *(_OWORD *)&v8[v17[12]];
    *(_OWORD *)&v7[v17[16]] = *(_OWORD *)&v8[v17[16]];
    uint64_t v18 = v17[20];
    long long v19 = *(_OWORD *)&v8[v18 + 16];
    *(_OWORD *)&v7[v18] = *(_OWORD *)&v8[v18];
    *(_OWORD *)&v7[v18 + 16] = v19;
    v7[v18 + 32] = v8[v18 + 32];
    uint64_t v88 = 4;
LABEL_12:
    uint64_t v15 = v88;
    uint64_t v13 = v7;
    uint64_t v14 = v10;
    goto LABEL_13;
  }
  if (EnumCaseMultiPayload == 1)
  {
    uint64_t v20 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v20 - 8) + 32))(v7, v8, v20);
    uint64_t v88 = 1;
    goto LABEL_12;
  }
  if (EnumCaseMultiPayload)
  {
    memcpy(v7, v8, *(void *)(*(void *)(v10 - 8) + 64));
    goto LABEL_15;
  }
  uint64_t v12 = type metadata accessor for URL(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(v7, v8, v12);
  uint64_t v13 = v7;
  uint64_t v14 = v10;
  uint64_t v15 = 0;
LABEL_13:
  swift_storeEnumTagMultiPayload(v13, v14, v15);
LABEL_15:
  swift_storeEnumTagMultiPayload(v7, v9, 1);
LABEL_16:
  uint64_t v21 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  *(void *)&v7[v21[5]] = *(void *)&v8[v21[5]];
  *(void *)&v7[v21[6]] = *(void *)&v8[v21[6]];
  uint64_t v22 = v21[7];
  long long v23 = *(_OWORD *)&v8[v22];
  *(_OWORD *)&v7[v22 + 16] = *(_OWORD *)&v8[v22 + 16];
  *(_OWORD *)&v7[v22] = v23;
  uint64_t v24 = v21[8];
  *(void *)&v7[v24] = *(void *)&v8[v24];
  v7[v24 + 8] = v8[v24 + 8];
  *(void *)&v7[v21[9]] = *(void *)&v8[v21[9]];
  uint64_t v25 = *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  char v26 = &v7[v25];
  uint64_t v27 = &v8[v25];
  uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int v29 = swift_getEnumCaseMultiPayload(v27, v28);
  BOOL v30 = v29 == 1;
  uint64_t v31 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (v29 == 1) {
    uint64_t v31 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(v31);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v32 - 8) + 32))(v26, v27, v32);
  swift_storeEnumTagMultiPayload(v26, v28, v30);
  uint64_t v33 = __dst;
  *(void *)&__dst[a3[6]] = *(void *)&__src[a3[6]];
  uint64_t v34 = a3[7];
  uint64_t v35 = &__dst[v34];
  uint64_t v36 = &__src[v34];
  if (swift_getEnumCaseMultiPayload(v36, v92) != 1)
  {
    memcpy(v35, v36, *(void *)(*(void *)(v92 - 8) + 64));
    goto LABEL_30;
  }
  uint64_t v98 = type metadata accessor for MLSoundClassifier.DataSource(0);
  int v37 = swift_getEnumCaseMultiPayload(v36, v98);
  if (v37 == 4)
  {
    uint64_t v42 = type metadata accessor for DataFrame(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v42 - 8) + 32))(v35, v36, v42);
    uint64_t v43 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
    *(_OWORD *)&v35[v43[12]] = *(_OWORD *)&v36[v43[12]];
    *(_OWORD *)&v35[v43[16]] = *(_OWORD *)&v36[v43[16]];
    uint64_t v44 = v43[20];
    long long v45 = *(_OWORD *)&v36[v44 + 16];
    *(_OWORD *)&v35[v44] = *(_OWORD *)&v36[v44];
    *(_OWORD *)&v35[v44 + 16] = v45;
    v35[v44 + 32] = v36[v44 + 32];
    uint64_t v89 = 4;
LABEL_26:
    uint64_t v41 = v89;
    uint64_t v39 = v35;
    uint64_t v40 = v98;
    goto LABEL_27;
  }
  if (v37 == 1)
  {
    uint64_t v46 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v46 - 8) + 32))(v35, v36, v46);
    uint64_t v89 = 1;
    goto LABEL_26;
  }
  if (v37)
  {
    memcpy(v35, v36, *(void *)(*(void *)(v98 - 8) + 64));
    goto LABEL_29;
  }
  uint64_t v38 = type metadata accessor for URL(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v38 - 8) + 32))(v35, v36, v38);
  uint64_t v39 = v35;
  uint64_t v40 = v98;
  uint64_t v41 = 0;
LABEL_27:
  swift_storeEnumTagMultiPayload(v39, v40, v41);
LABEL_29:
  swift_storeEnumTagMultiPayload(v35, v92, 1);
LABEL_30:
  *(void *)&v35[v21[5]] = *(void *)&v36[v21[5]];
  *(void *)&v35[v21[6]] = *(void *)&v36[v21[6]];
  uint64_t v47 = v21[7];
  long long v48 = *(_OWORD *)&v36[v47];
  *(_OWORD *)&v35[v47 + 16] = *(_OWORD *)&v36[v47 + 16];
  *(_OWORD *)&v35[v47] = v48;
  uint64_t v49 = v21[8];
  *(void *)&v35[v49] = *(void *)&v36[v49];
  v35[v49 + 8] = v36[v49 + 8];
  *(void *)&v35[v21[9]] = *(void *)&v36[v21[9]];
  uint64_t v50 = a3[8];
  long long v51 = &__dst[v50];
  uint64_t v52 = __src;
  uint64_t v53 = &__src[v50];
  uint64_t v54 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int v55 = swift_getEnumCaseMultiPayload(v53, v54);
  uint64_t v93 = v54;
  if (v55 == 1)
  {
    *(void *)long long v51 = *(void *)v53;
    uint64_t v99 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v66 = *(int *)(v99 + 20);
    uint64_t v90 = &v51[v66];
    uint64_t v67 = type metadata accessor for DataFrame(0);
    uint64_t v68 = *(void (**)(char *, char *, uint64_t))(*(void *)(v67 - 8) + 32);
    int v69 = &v53[v66];
    uint64_t v52 = __src;
    v68(v90, v69, v67);
    uint64_t v70 = v67;
    uint64_t v54 = v93;
    v68(&v51[*(int *)(v99 + 24)], &v53[*(int *)(v99 + 24)], v70);
    uint64_t v33 = __dst;
    uint64_t v65 = 1;
    uint64_t v63 = v51;
    uint64_t v64 = v93;
LABEL_36:
    swift_storeEnumTagMultiPayload(v63, v64, v65);
    goto LABEL_38;
  }
  if (!v55)
  {
    uint64_t v56 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v57 = swift_getEnumCaseMultiPayload(v53, v56);
    BOOL v58 = v57 == 1;
    BOOL v59 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v57 == 1) {
      BOOL v59 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v60 = __swift_instantiateConcreteTypeFromMangledName(v59);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v60 - 8) + 32))(v51, v53, v60);
    uint64_t v61 = v56;
    uint64_t v52 = __src;
    BOOL v62 = v58;
    uint64_t v33 = __dst;
    swift_storeEnumTagMultiPayload(v51, v61, v62);
    uint64_t v63 = v51;
    uint64_t v64 = v54;
    uint64_t v65 = 0;
    goto LABEL_36;
  }
  memcpy(v51, v53, *(void *)(*(void *)(v54 - 8) + 64));
LABEL_38:
  uint64_t v71 = a3[9];
  uint64_t v72 = &v33[v71];
  uint64_t v73 = &v52[v71];
  int v74 = swift_getEnumCaseMultiPayload(v73, v54);
  if (v74 == 1)
  {
    *(void *)uint64_t v72 = *(void *)v73;
    uint64_t v95 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v83 = *(int *)(v95 + 20);
    uint64_t v97 = &v72[v83];
    uint64_t v84 = type metadata accessor for DataFrame(0);
    uint64_t v85 = *(void (**)(char *, char *, uint64_t))(*(void *)(v84 - 8) + 32);
    uint64_t v86 = &v73[v83];
    uint64_t v33 = __dst;
    v85(v97, v86, v84);
    v85(&v72[*(int *)(v95 + 24)], &v73[*(int *)(v95 + 24)], v84);
    uint64_t v82 = 1;
    uint64_t v80 = v72;
    uint64_t v81 = v93;
  }
  else
  {
    if (v74)
    {
      memcpy(v72, v73, *(void *)(*(void *)(v54 - 8) + 64));
      return v33;
    }
    uint64_t v75 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v76 = swift_getEnumCaseMultiPayload(v73, v75);
    BOOL v77 = v76 == 1;
    uint64_t v78 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v76 == 1) {
      uint64_t v78 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v79 = __swift_instantiateConcreteTypeFromMangledName(v78);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v79 - 8) + 32))(v72, v73, v79);
    swift_storeEnumTagMultiPayload(v72, v75, v77);
    uint64_t v80 = v72;
    uint64_t v81 = v93;
    uint64_t v82 = 0;
  }
  swift_storeEnumTagMultiPayload(v80, v81, v82);
  return v33;
}

char *assignWithTake for MLSoundClassifier(char *__dst, char *a2, int *a3)
{
  uint64_t v4 = type metadata accessor for TrainingTablePrinter(0);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)__dst, 1, v4);
  int v6 = __swift_getEnumTagSinglePayload((uint64_t)a2, 1, v4);
  if (EnumTagSinglePayload)
  {
    if (!v6)
    {
      uint64_t v7 = type metadata accessor for Date(0);
      uint64_t v8 = a2;
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 32))(__dst, a2, v7);
      *(void *)&__dst[*(int *)(v4 + 20)] = *(void *)&a2[*(int *)(v4 + 20)];
      *(void *)&__dst[*(int *)(v4 + 24)] = *(void *)&a2[*(int *)(v4 + 24)];
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v4);
      goto LABEL_7;
    }
    goto LABEL_6;
  }
  if (v6)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)__dst, type metadata accessor for TrainingTablePrinter);
LABEL_6:
    uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingTablePrinter?);
    uint64_t v8 = a2;
    memcpy(__dst, a2, *(void *)(*(void *)(v9 - 8) + 64));
    goto LABEL_7;
  }
  uint64_t v20 = type metadata accessor for Date(0);
  uint64_t v8 = a2;
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v20 - 8) + 40))(__dst, a2, v20);
  uint64_t v21 = *(int *)(v4 + 20);
  uint64_t v22 = *(void **)&__dst[v21];
  *(void *)&__dst[v21] = *(void *)&a2[v21];

  uint64_t v23 = *(int *)(v4 + 24);
  uint64_t v24 = *(void *)&__dst[v23];
  *(void *)&__dst[v23] = *(void *)&a2[v23];
  swift_bridgeObjectRelease(v24);
LABEL_7:
  uint64_t v10 = a3[5];
  uint64_t v11 = &__dst[v10];
  uint64_t v12 = &v8[v10];
  if (__dst == v8) {
    goto LABEL_21;
  }
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v11, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
  uint64_t v13 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  if (swift_getEnumCaseMultiPayload(v12, v13) != 1)
  {
    memcpy(v11, v12, *(void *)(*(void *)(v13 - 8) + 64));
    goto LABEL_21;
  }
  uint64_t v14 = type metadata accessor for MLSoundClassifier.DataSource(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v12, v14);
  if (EnumCaseMultiPayload == 4)
  {
    uint64_t v25 = type metadata accessor for DataFrame(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v25 - 8) + 32))(v11, v12, v25);
    char v26 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
    *(_OWORD *)&v11[v26[12]] = *(_OWORD *)&v12[v26[12]];
    *(_OWORD *)&v11[v26[16]] = *(_OWORD *)&v12[v26[16]];
    uint64_t v27 = v26[20];
    long long v28 = *(_OWORD *)&v12[v27 + 16];
    *(_OWORD *)&v11[v27] = *(_OWORD *)&v12[v27];
    *(_OWORD *)&v11[v27 + 16] = v28;
    v11[v27 + 32] = v12[v27 + 32];
    uint64_t v111 = 4;
LABEL_17:
    uint64_t v19 = v111;
    uint64_t v17 = v11;
    uint64_t v18 = v14;
    goto LABEL_18;
  }
  if (EnumCaseMultiPayload == 1)
  {
    uint64_t v29 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v29 - 8) + 32))(v11, v12, v29);
    uint64_t v111 = 1;
    goto LABEL_17;
  }
  if (EnumCaseMultiPayload)
  {
    memcpy(v11, v12, *(void *)(*(void *)(v14 - 8) + 64));
    goto LABEL_20;
  }
  uint64_t v16 = type metadata accessor for URL(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 32))(v11, v12, v16);
  uint64_t v17 = v11;
  uint64_t v18 = v14;
  uint64_t v19 = 0;
LABEL_18:
  swift_storeEnumTagMultiPayload(v17, v18, v19);
LABEL_20:
  swift_storeEnumTagMultiPayload(v11, v13, 1);
LABEL_21:
  int v119 = __dst;
  BOOL v30 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  *(void *)&v11[v30[5]] = *(void *)&v12[v30[5]];
  *(void *)&v11[v30[6]] = *(void *)&v12[v30[6]];
  uint64_t v31 = v30[7];
  uint64_t v32 = &v11[v31];
  uint64_t v33 = &v12[v31];
  if (*(void *)&v11[v31 + 24]) {
    __swift_destroy_boxed_opaque_existential_1Tm(&v11[v31]);
  }
  long long v34 = *(_OWORD *)v33;
  *((_OWORD *)v32 + 1) = *((_OWORD *)v33 + 1);
  *(_OWORD *)uint64_t v32 = v34;
  uint64_t v35 = v30[8];
  *(void *)&v11[v35] = *(void *)&v12[v35];
  v11[v35 + 8] = v12[v35 + 8];
  *(void *)&v11[v30[9]] = *(void *)&v12[v30[9]];
  uint64_t v36 = type metadata accessor for MLSoundClassifier.Model(0);
  int v37 = v119;
  if (v119 != a2)
  {
    uint64_t v38 = *(int *)(v36 + 20);
    uint64_t v39 = &v12[v38];
    uint64_t v40 = (uint64_t)&v11[v38];
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v40, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    int v42 = swift_getEnumCaseMultiPayload(v39, v41);
    BOOL v43 = v42 == 1;
    uint64_t v44 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
    if (v42 == 1) {
      uint64_t v44 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
    }
    uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(v44);
    (*(void (**)(uint64_t, char *, uint64_t))(*(void *)(v45 - 8) + 32))(v40, v39, v45);
    uint64_t v46 = v41;
    int v37 = v119;
    swift_storeEnumTagMultiPayload(v40, v46, v43);
  }
  uint64_t v47 = a3[6];
  long long v48 = *(void **)&v37[v47];
  *(void *)&v37[v47] = *(void *)&a2[v47];

  uint64_t v49 = a3[7];
  uint64_t v50 = &v37[v49];
  long long v51 = &a2[v49];
  if (v37 != a2)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v50, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v52 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
    if (swift_getEnumCaseMultiPayload(v51, v52) != 1)
    {
      memcpy(v50, v51, *(void *)(*(void *)(v52 - 8) + 64));
      goto LABEL_40;
    }
    uint64_t v53 = type metadata accessor for MLSoundClassifier.DataSource(0);
    int v54 = swift_getEnumCaseMultiPayload(v51, v53);
    if (v54 == 4)
    {
      uint64_t v59 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v59 - 8) + 32))(v50, v51, v59);
      uint64_t v60 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
      *(_OWORD *)&v50[v60[12]] = *(_OWORD *)&v51[v60[12]];
      *(_OWORD *)&v50[v60[16]] = *(_OWORD *)&v51[v60[16]];
      uint64_t v61 = v60[20];
      long long v62 = *(_OWORD *)&v51[v61 + 16];
      *(_OWORD *)&v50[v61] = *(_OWORD *)&v51[v61];
      *(_OWORD *)&v50[v61 + 16] = v62;
      v50[v61 + 32] = v51[v61 + 32];
      uint64_t v112 = 4;
    }
    else
    {
      if (v54 != 1)
      {
        if (v54)
        {
          memcpy(v50, v51, *(void *)(*(void *)(v53 - 8) + 64));
          goto LABEL_39;
        }
        uint64_t v55 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v55 - 8) + 32))(v50, v51, v55);
        uint64_t v56 = v50;
        uint64_t v57 = v53;
        uint64_t v58 = 0;
LABEL_37:
        swift_storeEnumTagMultiPayload(v56, v57, v58);
LABEL_39:
        swift_storeEnumTagMultiPayload(v50, v52, 1);
        goto LABEL_40;
      }
      uint64_t v63 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v63 - 8) + 32))(v50, v51, v63);
      uint64_t v112 = 1;
    }
    uint64_t v58 = v112;
    uint64_t v56 = v50;
    uint64_t v57 = v53;
    goto LABEL_37;
  }
LABEL_40:
  *(void *)&v50[v30[5]] = *(void *)&v51[v30[5]];
  *(void *)&v50[v30[6]] = *(void *)&v51[v30[6]];
  uint64_t v64 = v30[7];
  uint64_t v65 = &v50[v64];
  uint64_t v66 = &v51[v64];
  if (*(void *)&v50[v64 + 24]) {
    __swift_destroy_boxed_opaque_existential_1Tm(&v50[v64]);
  }
  long long v67 = *(_OWORD *)v66;
  *((_OWORD *)v65 + 1) = *((_OWORD *)v66 + 1);
  *(_OWORD *)uint64_t v65 = v67;
  uint64_t v68 = v30[8];
  *(void *)&v50[v68] = *(void *)&v51[v68];
  v50[v68 + 8] = v51[v68 + 8];
  *(void *)&v50[v30[9]] = *(void *)&v51[v30[9]];
  int v69 = v119;
  uint64_t v70 = a2;
  if (v119 == a2) {
    return v69;
  }
  uint64_t v71 = a3[8];
  uint64_t v72 = &v119[v71];
  uint64_t v73 = &a2[v71];
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v72, type metadata accessor for MLClassifierMetrics.Contents);
  uint64_t v74 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int v75 = swift_getEnumCaseMultiPayload(v73, v74);
  if (v75 == 1)
  {
    *(void *)uint64_t v72 = *(void *)v73;
    uint64_t v113 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v86 = *(int *)(v113 + 20);
    uint64_t v114 = &v72[v86];
    uint64_t v115 = v74;
    uint64_t v87 = type metadata accessor for DataFrame(0);
    uint64_t v88 = *(void (**)(char *, char *, uint64_t))(*(void *)(v87 - 8) + 32);
    uint64_t v89 = &v73[v86];
    int v69 = v119;
    v88(v114, v89, v87);
    uint64_t v90 = v87;
    uint64_t v74 = v115;
    v88(&v72[*(int *)(v113 + 24)], &v73[*(int *)(v113 + 24)], v90);
    uint64_t v70 = a2;
    uint64_t v85 = 1;
    uint64_t v83 = v72;
    uint64_t v84 = v115;
  }
  else
  {
    if (v75)
    {
      memcpy(v72, v73, *(void *)(*(void *)(v74 - 8) + 64));
      goto LABEL_51;
    }
    uint64_t v76 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v77 = swift_getEnumCaseMultiPayload(v73, v76);
    BOOL v78 = v77 == 1;
    uint64_t v79 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v77 == 1) {
      uint64_t v79 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v80 = __swift_instantiateConcreteTypeFromMangledName(v79);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v80 - 8) + 32))(v72, v73, v80);
    uint64_t v81 = v76;
    uint64_t v70 = a2;
    BOOL v82 = v78;
    int v69 = v119;
    swift_storeEnumTagMultiPayload(v72, v81, v82);
    uint64_t v83 = v72;
    uint64_t v84 = v74;
    uint64_t v85 = 0;
  }
  swift_storeEnumTagMultiPayload(v83, v84, v85);
LABEL_51:
  uint64_t v91 = a3[9];
  uint64_t v92 = &v69[v91];
  uint64_t v93 = &v70[v91];
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v69[v91], type metadata accessor for MLClassifierMetrics.Contents);
  int v94 = swift_getEnumCaseMultiPayload(v93, v74);
  if (v94 == 1)
  {
    *(void *)uint64_t v92 = *(void *)v93;
    __srca = (int *)type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v106 = __srca[5];
    uint64_t v118 = &v92[v106];
    uint64_t v107 = type metadata accessor for DataFrame(0);
    uint64_t v116 = v74;
    int v108 = *(void (**)(char *, char *, uint64_t))(*(void *)(v107 - 8) + 32);
    int v109 = &v93[v106];
    int v69 = v119;
    v108(v118, v109, v107);
    v108(&v92[__srca[6]], &v93[__srca[6]], v107);
    uint64_t v105 = 1;
    BOOL v103 = v92;
    uint64_t v104 = v116;
  }
  else
  {
    if (v94)
    {
      memcpy(v92, v93, *(void *)(*(void *)(v74 - 8) + 64));
      return v69;
    }
    uint64_t v95 = v74;
    uint64_t v96 = v93;
    uint64_t v97 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v98 = swift_getEnumCaseMultiPayload(v96, v97);
    BOOL v99 = v98 == 1;
    uint64_t v100 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v98 == 1) {
      uint64_t v100 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v101 = __swift_instantiateConcreteTypeFromMangledName(v100);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v101 - 8) + 32))(v92, v96, v101);
    BOOL v102 = v99;
    int v69 = v119;
    swift_storeEnumTagMultiPayload(v92, v97, v102);
    BOOL v103 = v92;
    uint64_t v104 = v95;
    uint64_t v105 = 0;
  }
  swift_storeEnumTagMultiPayload(v103, v104, v105);
  return v69;
}

uint64_t getEnumTagSinglePayload for MLSoundClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_24E606);
}

uint64_t sub_24E606(uint64_t a1, unsigned int a2, int *a3)
{
  uint64_t v4 = a1;
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingTablePrinter?);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(v4, a2, v5);
  }
  uint64_t v5 = type metadata accessor for MLSoundClassifier.Model(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2)
  {
    uint64_t v6 = a3[5];
LABEL_11:
    uint64_t v4 = v6 + a1;
    return __swift_getEnumTagSinglePayload(v4, a2, v5);
  }
  if (a2 != 0x7FFFFFFF)
  {
    uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
    if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2)
    {
      uint64_t v6 = a3[7];
    }
    else
    {
      uint64_t v5 = type metadata accessor for MLClassifierMetrics(0);
      uint64_t v6 = a3[8];
    }
    goto LABEL_11;
  }
  uint64_t result = 0;
  if ((*(void *)(a1 + a3[6]) & 0xFFFFFFFF00000001) == 0) {
    return (*(void *)(a1 + a3[6]) >> 1) + 1;
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLSoundClassifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_24E6C4);
}

uint64_t sub_24E6C4(uint64_t a1, unsigned int a2, int a3, int *a4)
{
  uint64_t v6 = a1;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingTablePrinter?);
  if (*(_DWORD *)(*(void *)(v7 - 8) + 84) != a3)
  {
    uint64_t v7 = type metadata accessor for MLSoundClassifier.Model(0);
    if (*(_DWORD *)(*(void *)(v7 - 8) + 84) == a3)
    {
      uint64_t v8 = a4[5];
    }
    else
    {
      if (a3 == 0x7FFFFFFF)
      {
        uint64_t result = a4[6];
        *(void *)(a1 + result) = 2 * (a2 - 1);
        return result;
      }
      uint64_t v7 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
      if (*(_DWORD *)(*(void *)(v7 - 8) + 84) == a3)
      {
        uint64_t v8 = a4[7];
      }
      else
      {
        uint64_t v7 = type metadata accessor for MLClassifierMetrics(0);
        uint64_t v8 = a4[8];
      }
    }
    uint64_t v6 = v8 + a1;
  }
  return __swift_storeEnumTagSinglePayload(v6, a2, a2, v7);
}

uint64_t type metadata completion function for MLSoundClassifier(uint64_t a1)
{
  uint64_t result = type metadata accessor for TrainingTablePrinter?(319);
  if (v2 <= 0x3F)
  {
    v6[0] = *(void *)(result - 8) + 64;
    uint64_t result = type metadata accessor for MLSoundClassifier.Model(319);
    if (v3 <= 0x3F)
    {
      v6[1] = *(void *)(result - 8) + 64;
      v6[2] = (char *)&value witness table for Builtin.UnknownObject + 64;
      uint64_t result = type metadata accessor for MLSoundClassifier.ModelParameters(319);
      if (v4 <= 0x3F)
      {
        v6[3] = *(void *)(result - 8) + 64;
        uint64_t result = type metadata accessor for MLClassifierMetrics.Contents(319);
        if (v5 <= 0x3F)
        {
          uint64_t v7 = *(void *)(result - 8) + 64;
          uint64_t v8 = v7;
          swift_initStructMetadata(a1, 256, 6, v6, a1 + 16);
          return 0;
        }
      }
    }
  }
  return result;
}

uint64_t type metadata accessor for TrainingTablePrinter?(uint64_t a1)
{
  uint64_t result = lazy cache variable for type metadata for TrainingTablePrinter?;
  if (!lazy cache variable for type metadata for TrainingTablePrinter?)
  {
    uint64_t v2 = type metadata accessor for TrainingTablePrinter(255);
    uint64_t result = type metadata accessor for Optional(a1, v2);
    if (!v3) {
      lazy cache variable for type metadata for TrainingTablePrinter? = result;
    }
  }
  return result;
}

void *sub_24E872()
{
  return &protocol witness table for String;
}

uint64_t sub_24E87F()
{
  return key path getter for ClassificationDistribution.mostLikelyLabel : ClassificationDistribution<String>();
}

char _sSRsRi_zrlE17withMemoryRebound2to_qd_1_qd__m_qd_1_SRyqd__Gqd_0_YKXEtqd_0_YKs5ErrorRd_0_Ri_d__Ri_d_1_r1_lFSRyxGq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lys4Int8VsAD_pqd_1_Isgyrzr_SRys5UInt8VGqd_1_sAD_pAIRszAGRsd__sAD_pRsd_0_Ri_d_1_r_1_lIetMgyrzo_Tpq5Sb_Tg507_sSRys4f5VGxs5E34_pIgyrzo_ACxsAD_pIegyrzr_lTRSb_TG5SRyAGGSbsAD_pIgyrzo_Tf1cn_n(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t))
{
  __int16 v6 = HIWORD(v3);
  if (a1)
  {
    char result = a3(a1);
    if (!v4) {
      return HIBYTE(v6);
    }
  }
  else
  {
    char result = ((uint64_t (*)(void, void))a3)(0, 0);
    if (!v4) {
      return v6;
    }
  }
  return result;
}

BOOL closure #1 in closure #1 in Float.init<A>(_:)(unsigned __int8 *a1)
{
  uint64_t v2 = v1;
  unint64_t v3 = *a1;
  result = (v3 > 0x20 || (uint64_t v4 = 0x100003E01, !_bittest64(&v4, v3)))
        && (__int16 v6 = (unsigned char *)_swift_stdlib_strtof_clocale()) != 0
        && *v6 == 0;
  BOOL *v2 = result;
  return result;
}

char specialized closure #1 in _StringGuts.withCString<A>(_:)(uint64_t a1, uint64_t a2, uint64_t (*a3)(void))
{
  unint64_t v5 = v3;
  char result = a3();
  if (!v4)
  {
    char result = v7;
    *unint64_t v5 = v7;
  }
  return result;
}

uint64_t specialized closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v7 = *a3;
  uint64_t v8 = (void *)swift_task_alloc(dword_3ACF1C);
  *(void *)(v5 + 16) = v8;
  void *v8 = v5;
  v8[1] = protocol witness for SupervisedEstimator.fitted<A>(to:eventHandler:) in conformance MLImageClassifier.Classifier;
  return specialized closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(a1, a2, v7, a4, a5);
}

uint64_t specialized closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t *a4, uint64_t a5, uint64_t a6)
{
  uint64_t v7 = *a3;
  uint64_t v8 = *a4;
  uint64_t v9 = (void *)swift_task_alloc(dword_3ACF24);
  *(void *)(v6 + 16) = v9;
  *uint64_t v9 = v6;
  v9[1] = protocol witness for SupervisedEstimator.fitted<A, B>(to:validateOn:eventHandler:) in conformance MLImageClassifier.Classifier;
  return specialized closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(a1, a2, v7, v8, a5, a6);
}

uint64_t specialized closure #1 in MLSoundClassifier.evaluate<A>(on:)(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  *(void *)(v3 + 16) = a1;
  uint64_t v4 = *a3;
  uint64_t v5 = (void *)swift_task_alloc(dword_3ACEBC);
  *(void *)(v3 + 24) = v5;
  *uint64_t v5 = v3;
  v5[1] = specialized closure #1 in MLSoundClassifier.evaluate<A>(on:);
  return specialized closure #1 in MLSoundClassifier.evaluate<A>(on:)(a2, v4);
}

uint64_t sub_24EAF0()
{
  uint64_t v1 = (int *)type metadata accessor for MLSoundClassifier(0);
  uint64_t v2 = *((void *)v1 - 1);
  uint64_t v3 = *(unsigned __int8 *)(v2 + 80);
  uint64_t v60 = *(void *)(v2 + 64);
  uint64_t v59 = ~*(unsigned __int8 *)(v2 + 80) & (v3 + 16);
  uint64_t v55 = v0;
  uint64_t v4 = v59 + v0;
  uint64_t v5 = type metadata accessor for TrainingTablePrinter(0);
  if (!__swift_getEnumTagSinglePayload(v59 + v0, 1, v5))
  {
    uint64_t v6 = type metadata accessor for Date(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8))(v4, v6);

    swift_bridgeObjectRelease(*(void *)(v4 + *(int *)(v5 + 24)));
  }
  uint64_t v57 = v59 + v0;
  uint64_t v7 = v4 + v1[5];
  uint64_t v8 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v7, v8);
  if (EnumCaseMultiPayload == 2)
  {
LABEL_7:
    uint64_t v12 = *(void *)v7;
LABEL_8:
    swift_bridgeObjectRelease(v12);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v10 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(v7, v10))
    {
      case 0u:
      case 1u:
        uint64_t v11 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v11 - 8) + 8))(v7, v11);
        break;
      case 2u:
        goto LABEL_7;
      case 3u:
        outlined consume of Result<_DataTable, Error>(*(void *)v7, *(unsigned char *)(v7 + 8));
        swift_bridgeObjectRelease(*(void *)(v7 + 24));
        uint64_t v12 = *(void *)(v7 + 40);
        goto LABEL_8;
      case 4u:
        uint64_t v23 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v23 - 8) + 8))(v7, v23);
        uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        swift_bridgeObjectRelease(*(void *)(v7 + *(int *)(v24 + 48) + 8));
        uint64_t v12 = *(void *)(v7 + *(int *)(v24 + 64) + 8);
        goto LABEL_8;
      default:
        break;
    }
  }
  uint64_t v13 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  uint64_t v14 = *(int *)(v13 + 28);
  if (*(void *)(v7 + v14 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(v7 + v14));
  }
  uint64_t v15 = *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20) + v7;
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  uint64_t v17 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (swift_getEnumCaseMultiPayload(v15, v16) == 1) {
    uint64_t v17 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(v17);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v18 - 8) + 8))(v15, v18);

  uint64_t v58 = v1;
  uint64_t v19 = (uint64_t *)(v57 + v1[7]);
  int v20 = swift_getEnumCaseMultiPayload(v19, v8);
  if (v20 == 2)
  {
    swift_bridgeObjectRelease(*v19);
  }
  else if (v20 == 1)
  {
    uint64_t v21 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(v19, v21))
    {
      case 0u:
      case 1u:
        uint64_t v22 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t *, uint64_t))(*(void *)(v22 - 8) + 8))(v19, v22);
        break;
      case 2u:
        uint64_t v25 = *v19;
        goto LABEL_23;
      case 3u:
        outlined consume of Result<_DataTable, Error>(*v19, *((_DWORD *)v19 + 2));
        swift_bridgeObjectRelease(v19[3]);
        uint64_t v25 = v19[5];
        goto LABEL_23;
      case 4u:
        uint64_t v26 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t *, uint64_t))(*(void *)(v26 - 8) + 8))(v19, v26);
        uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        swift_bridgeObjectRelease(*(uint64_t *)((char *)v19 + *(int *)(v27 + 48) + 8));
        uint64_t v25 = *(uint64_t *)((char *)v19 + *(int *)(v27 + 64) + 8);
LABEL_23:
        swift_bridgeObjectRelease(v25);
        break;
      default:
        break;
    }
  }
  uint64_t v28 = *(int *)(v13 + 28);
  if (*(uint64_t *)((char *)v19 + v28 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((uint64_t *)((char *)v19 + v28));
  }
  uint64_t v29 = v57;
  BOOL v30 = (char *)(v57 + v1[8]);
  uint64_t v31 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int v32 = swift_getEnumCaseMultiPayload(v30, v31);
  switch(v32)
  {
    case 2:
      swift_errorRelease(*(void *)v30);
      break;
    case 1:
      uint64_t v56 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v61 = v3;
      uint64_t v35 = &v30[*(int *)(v56 + 20)];
      uint64_t v36 = type metadata accessor for DataFrame(0);
      int v37 = *(void (**)(char *, uint64_t))(*(void *)(v36 - 8) + 8);
      uint64_t v38 = v35;
      uint64_t v3 = v61;
      v37(v38, v36);
      uint64_t v39 = v36;
      uint64_t v1 = v58;
      v37(&v30[*(int *)(v56 + 24)], v39);
      uint64_t v29 = v57;
      break;
    case 0:
      uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload(v30, v33) == 1) {
        long long v34 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        long long v34 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(v34);
      (*(void (**)(char *, uint64_t))(*(void *)(v40 - 8) + 8))(v30, v40);
      break;
  }
  uint64_t v41 = (char *)(v1[9] + v29);
  int v42 = swift_getEnumCaseMultiPayload(v41, v31);
  if (v42 == 2)
  {
    swift_errorRelease(*(void *)v41);
LABEL_42:
    uint64_t v43 = v59;
    uint64_t v44 = v60;
    goto LABEL_45;
  }
  if (v42 == 1)
  {
    uint64_t v47 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    long long v48 = &v41[*(int *)(v47 + 20)];
    uint64_t v62 = v3;
    uint64_t v49 = type metadata accessor for DataFrame(0);
    uint64_t v50 = *(void (**)(char *, uint64_t))(*(void *)(v49 - 8) + 8);
    v50(v48, v49);
    uint64_t v51 = v49;
    uint64_t v3 = v62;
    v50(&v41[*(int *)(v47 + 24)], v51);
    goto LABEL_42;
  }
  uint64_t v43 = v59;
  uint64_t v44 = v60;
  if (!v42)
  {
    uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    if (swift_getEnumCaseMultiPayload(v41, v45) == 1) {
      uint64_t v46 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    else {
      uint64_t v46 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    }
    uint64_t v52 = __swift_instantiateConcreteTypeFromMangledName(v46);
    (*(void (**)(char *, uint64_t))(*(void *)(v52 - 8) + 8))(v41, v52);
  }
LABEL_45:
  unint64_t v53 = (v44 + v43 + 7) & 0xFFFFFFFFFFFFFFF8;
  swift_bridgeObjectRelease(*(void *)(v55 + v53));
  return swift_deallocObject(v55, v53 + 8, v3 | 7);
}

uint64_t partial apply for specialized closure #1 in MLSoundClassifier.evaluate<A>(on:)(uint64_t a1)
{
  uint64_t v3 = *(void *)(type metadata accessor for MLSoundClassifier(0) - 8);
  uint64_t v4 = ~*(unsigned __int8 *)(v3 + 80) & (*(unsigned __int8 *)(v3 + 80) + 16);
  unint64_t v5 = (*(void *)(v3 + 64) + v4 + 7) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v6 = (void *)swift_task_alloc(dword_3ACEAC);
  *(void *)(v2 + 16) = v6;
  void *v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return ((uint64_t (*)(uint64_t, uint64_t, unint64_t))((char *)&async function pointer to specialized closure #1 in MLSoundClassifier.evaluate<A>(on:)
                                                                     + async function pointer to specialized closure #1 in MLSoundClassifier.evaluate<A>(on:)))(a1, v1 + v4, v1 + v5);
}

uint64_t sub_24F05E(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3);
}

uint64_t sub_24F068(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, a4);
}

uint64_t sub_24F072()
{
  return key path getter for AnnotatedPrediction.prediction : AnnotatedPrediction<ClassificationDistribution<String>, String>();
}

uint64_t sub_24F07C(uint64_t a1)
{
  return key path setter for AnnotatedPrediction.prediction : AnnotatedPrediction<ClassificationDistribution<String>, String>(a1);
}

uint64_t sub_24F086()
{
  return key path getter for ClassificationDistribution.mostLikelyLabel : ClassificationDistribution<String>();
}

uint64_t sub_24F09F()
{
  swift_unknownObjectRelease(v0[2]);
  swift_release(v0[4]);
  swift_release(v0[6]);
  return swift_deallocObject(v0, 56, 7);
}

uint64_t partial apply for closure #1 in static MLSoundClassifier.handleResult(_:session:fulfill:)(uint64_t a1)
{
  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v5 = v1[6];
  uint64_t v6 = (void *)swift_task_alloc(dword_3ACEDC);
  *(void *)(v2 + 16) = v6;
  void *v6 = v2;
  v6[1] = partial apply for specialized closure #1 in blockAwait<A>(_:);
  return closure #1 in static MLSoundClassifier.handleResult(_:session:fulfill:)(a1, v3, v4, v8, v9, v5);
}

uint64_t sub_24F15E()
{
  uint64_t v1 = v0;
  uint64_t v2 = type metadata accessor for MLSoundClassifier.Classifier(0);
  uint64_t v3 = *(void *)(v2 - 8);
  uint64_t v30 = *(unsigned __int8 *)(v3 + 80);
  uint64_t v4 = ~*(unsigned __int8 *)(v3 + 80) & (v30 + 16);
  uint64_t v29 = *(void *)(v3 + 64);
  uint64_t v28 = type metadata accessor for TrainingTablePrinter(0);
  uint64_t v5 = *(void *)(v28 - 8);
  uint64_t v6 = *(unsigned __int8 *)(v5 + 80);
  uint64_t v31 = *(void *)(v5 + 64);
  uint64_t v27 = v1;
  uint64_t v7 = v1 + v4;
  uint64_t v8 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v1 + v4, v8);
  if (EnumCaseMultiPayload == 2)
  {
LABEL_5:
    uint64_t v12 = *(void *)v7;
LABEL_6:
    swift_bridgeObjectRelease(v12);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v10 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(v1 + v4, v10))
    {
      case 0u:
      case 1u:
        uint64_t v11 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v11 - 8) + 8))(v1 + v4, v11);
        break;
      case 2u:
        goto LABEL_5;
      case 3u:
        outlined consume of Result<_DataTable, Error>(*(void *)v7, *(unsigned char *)(v7 + 8));
        swift_bridgeObjectRelease(*(void *)(v7 + 24));
        uint64_t v12 = *(void *)(v7 + 40);
        goto LABEL_6;
      case 4u:
        uint64_t v25 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v25 - 8) + 8))(v1 + v4, v25);
        uint64_t v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        swift_bridgeObjectRelease(*(void *)(v7 + *(int *)(v26 + 48) + 8));
        uint64_t v12 = *(void *)(v7 + *(int *)(v26 + 64) + 8);
        goto LABEL_6;
      default:
        break;
    }
  }
  uint64_t v13 = *(int *)(type metadata accessor for MLSoundClassifier.ModelParameters(0) + 28);
  if (*(void *)(v7 + v13 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(v7 + v13));
  }
  uint64_t v14 = *(int *)(v2 + 20) + v7;
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  uint64_t v16 = &demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>;
  if (swift_getEnumCaseMultiPayload(v14, v15) == 1) {
    uint64_t v16 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>;
  }
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(v16);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v17 - 8) + 8))(v14, v17);
  uint64_t v18 = v6 | v30 | 7;
  unint64_t v19 = (v4 + v29 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v20 = (v19 + 15) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v21 = (v6 + ((v20 + 15) & 0xFFFFFFFFFFFFFFF8) + 8) & ~v6;
  uint64_t v32 = v21 + v31;
  swift_bridgeObjectRelease(*(void *)(v27 + v19));
  swift_bridgeObjectRelease(*(void *)(v27 + v20));
  swift_release();
  uint64_t v22 = v27 + v21;
  uint64_t v23 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v23 - 8) + 8))(v22, v23);

  swift_bridgeObjectRelease(*(void *)(*(int *)(v28 + 24) + v22));
  return swift_deallocObject(v27, v32, v18);
}

uint64_t partial apply for specialized closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1)
{
  uint64_t v12 = v1;
  uint64_t v11 = v2;
  uint64_t v3 = *(void *)(type metadata accessor for MLSoundClassifier.Classifier(0) - 8);
  uint64_t v4 = ~*(unsigned __int8 *)(v3 + 80) & (*(unsigned __int8 *)(v3 + 80) + 16);
  unint64_t v5 = (*(void *)(v3 + 64) + v4 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v6 = (v5 + 15) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v7 = (v6 + 15) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v8 = *(unsigned __int8 *)(*(void *)(type metadata accessor for TrainingTablePrinter(0) - 8) + 80);
  uint64_t v13 = *(void *)(v12 + v7);
  uint64_t v9 = (void *)swift_task_alloc(dword_3ACEFC);
  *(void *)(v11 + 16) = v9;
  *uint64_t v9 = v11;
  v9[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return ((uint64_t (*)(uint64_t, uint64_t, unint64_t, unint64_t, uint64_t, unint64_t))((char *)&async function pointer to specialized closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:) + async function pointer to specialized closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:)))(a1, v12 + v4, v12 + v5, v12 + v6, v13, v12 + ((v8 + v7 + 8) & ~v8));
}

uint64_t sub_24F4A5()
{
  uint64_t v28 = type metadata accessor for MLSoundClassifier.Classifier(0);
  uint64_t v1 = *(void *)(v28 - 8);
  uint64_t v2 = *(unsigned __int8 *)(v1 + 80);
  uint64_t v3 = ~*(unsigned __int8 *)(v1 + 80) & (v2 + 16);
  uint64_t v27 = *(void *)(v1 + 64);
  uint64_t v26 = type metadata accessor for TrainingTablePrinter(0);
  uint64_t v4 = *(void *)(v26 - 8);
  uint64_t v5 = *(unsigned __int8 *)(v4 + 80);
  uint64_t v25 = *(void *)(v4 + 64);
  uint64_t v6 = v3 + v0;
  uint64_t v7 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v3 + v0, v7);
  if (EnumCaseMultiPayload == 2)
  {
LABEL_5:
    uint64_t v11 = *(void *)v6;
LABEL_6:
    swift_bridgeObjectRelease(v11);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v9 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(v3 + v0, v9))
    {
      case 0u:
      case 1u:
        uint64_t v10 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v10 - 8) + 8))(v3 + v0, v10);
        break;
      case 2u:
        goto LABEL_5;
      case 3u:
        outlined consume of Result<_DataTable, Error>(*(void *)v6, *(unsigned char *)(v6 + 8));
        swift_bridgeObjectRelease(*(void *)(v6 + 24));
        uint64_t v11 = *(void *)(v6 + 40);
        goto LABEL_6;
      case 4u:
        uint64_t v24 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v24 - 8) + 8))(v3 + v0, v24);
        uint64_t v29 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        swift_bridgeObjectRelease(*(void *)(v6 + *(int *)(v29 + 48) + 8));
        uint64_t v11 = *(void *)(v6 + *(int *)(v29 + 64) + 8);
        goto LABEL_6;
      default:
        break;
    }
  }
  uint64_t v12 = *(int *)(type metadata accessor for MLSoundClassifier.ModelParameters(0) + 28);
  if (*(void *)(v6 + v12 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(v6 + v12));
  }
  uint64_t v13 = *(int *)(v28 + 20) + v6;
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  uint64_t v15 = &demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>;
  if (swift_getEnumCaseMultiPayload(v13, v14) == 1) {
    uint64_t v15 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>;
  }
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(v15);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v16 - 8) + 8))(v13, v16);
  uint64_t v17 = v5 | v2 | 7;
  unint64_t v18 = (v3 + v27 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v19 = (v5 + ((v18 + 15) & 0xFFFFFFFFFFFFFFF8) + 8) & ~v5;
  uint64_t v20 = v19 + v25;
  swift_bridgeObjectRelease(*(void *)(v0 + v18));
  swift_release();
  uint64_t v21 = v0 + v19;
  uint64_t v22 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v22 - 8) + 8))(v21, v22);

  swift_bridgeObjectRelease(*(void *)(*(int *)(v26 + 24) + v21));
  return swift_deallocObject(v0, v20, v17);
}

uint64_t partial apply for specialized closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1)
{
  uint64_t v10 = v1;
  uint64_t v3 = *(void *)(type metadata accessor for MLSoundClassifier.Classifier(0) - 8);
  uint64_t v4 = ~*(unsigned __int8 *)(v3 + 80) & (*(unsigned __int8 *)(v3 + 80) + 16);
  unint64_t v5 = (*(void *)(v3 + 64) + v4 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v6 = (v5 + 15) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v7 = *(unsigned __int8 *)(*(void *)(type metadata accessor for TrainingTablePrinter(0) - 8) + 80);
  uint64_t v11 = *(void *)(v10 + v6);
  uint64_t v8 = (void *)swift_task_alloc(dword_3ACF0C);
  *(void *)(v2 + 16) = v8;
  void *v8 = v2;
  v8[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return ((uint64_t (*)(uint64_t, uint64_t, unint64_t, uint64_t, unint64_t))((char *)&async function pointer to specialized closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:)
                                                                                                + async function pointer to specialized closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:)))(a1, v10 + v4, v10 + v5, v11, v10 + ((v7 + v6 + 8) & ~v7));
}

uint64_t sub_24F7AD()
{
  return objectdestroyTm_1();
}

uint64_t partial apply for closure #1 in closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1)
{
  return partial apply for closure #1 in closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(a1, (uint64_t (*)(uint64_t, void, uint64_t))closure #1 in closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:));
}

uint64_t sub_24F7C8()
{
  return objectdestroyTm_1();
}

uint64_t partial apply for closure #1 in closure #3 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1)
{
  return partial apply for closure #1 in closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(a1, (uint64_t (*)(uint64_t, void, uint64_t))closure #2 in SoundClassifierTrainingSessionDelegate.train(from:));
}

uint64_t partial apply for closure #1 in closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1, uint64_t (*a2)(uint64_t, void, uint64_t))
{
  uint64_t v3 = type metadata accessor for TrainingTablePrinter(0);
  return a2(a1, *(void *)(v2 + 16), v2+ (~*(unsigned __int8 *)(*(void *)(v3 - 8) + 80) & (*(unsigned __int8 *)(*(void *)(v3 - 8)+ 80)+ 24)));
}

uint64_t partial apply for closure #8 in static MLSoundClassifier.convertFeatures(_:)(uint64_t *a1)
{
  return closure #8 in static MLSoundClassifier.convertFeatures(_:)(a1);
}

uint64_t partial apply for closure #5 in static MLSoundClassifier.convertFeatures(_:)(uint64_t *a1)
{
  return closure #5 in static MLSoundClassifier.convertFeatures(_:)(a1);
}

BOOL partial apply for closure #1 in closure #1 in Float.init<A>(_:)(unsigned __int8 *a1)
{
  return closure #1 in closure #1 in Float.init<A>(_:)(a1);
}

char _ss11_StringGutsV11withCStringyxxSPys4Int8VGKXEKlFxSRyAEGKXEfU_Sb_TG5TA_0()
{
  uint64_t v3 = v0;
  char result = (*(uint64_t (**)(void))(v2 + 16))();
  if (!v1)
  {
    char result = v5;
    unsigned char *v3 = v5;
  }
  return result;
}

uint64_t closure #1 in closure #4 in MLSoundClassifier.init<A, B>(training:validation:parameters:)(uint64_t a1, __m128 a2)
{
  return closure #2 in SoundClassifierTrainingSessionDelegate.train(from:)(a1, a2);
}

void *MLWordEmbedding.ModelParameters.init(language:revision:)(uint64_t a1, uint64_t a2)
{
  *char result = a1;
  result[1] = a2;
  return result;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> MLWordEmbedding.ModelParameters.validateRevision()()
{
  uint64_t v23 = type metadata accessor for IndexSet(0);
  uint64_t v22 = *(void *)(v23 - 8);
  int64_t v2 = *(void *)(v22 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  char v5 = *(NSString **)v1;
  v21[0] = *(void *)(v1 + 8);
  uint64_t v20 = v0;
  if (v5)
  {
    unint64_t v6 = v5;
  }
  else
  {
    unint64_t v6 = NLLanguageUndetermined;
    char v5 = 0;
  }
  uint64_t v7 = objc_opt_self(NLEmbedding);
  v5;
  id v8 = [v7 supportedRevisionsForLanguage:v6];
  id v9 = v8;

  static IndexSet._unconditionallyBridgeFromObjectiveC(_:)(v9);
  Swift::Int v10 = v21[0];
  if (!IndexSet.contains(_:)(v21[0]))
  {
    *(void *)&long long v18 = 0;
    *((void *)&v18 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(29);
    swift_bridgeObjectRelease(BYTE8(v18));
    *(void *)&long long v18 = 0x6E6F697369766552;
    *((void *)&v18 + 1) = 0xE900000000000020;
    Swift::Int v19 = v10;
    v11._countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char object = (char)v11._object;
    String.append(_:)(v11);
    swift_bridgeObjectRelease(object);
    v13._char object = "und in the model." + 0x8000000000000000;
    v13._countAndFlagsBits = 0xD000000000000012;
    String.append(_:)(v13);
    *(_OWORD *)uint64_t v21 = v18;
    v13._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v13._object, 0, 0);
    *(_OWORD *)uint64_t v14 = *(_OWORD *)v21;
    *(_OWORD *)(v14 + 16) = 0;
    *(_OWORD *)(v14 + 32) = 0;
    *(unsigned char *)(v14 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v13._object, v14, v15, v16, v17);
  }
  (*(void (**)(long long *, uint64_t))(v22 + 8))(&v18, v23);
}

uint64_t MLWordEmbedding.ModelParameters.description.getter()
{
  uint64_t v8 = *v0;
  (id)v8;
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NLLanguage?);
  uint64_t v8 = String.init<A>(describing:)(&v8, v1);
  unint64_t v9 = v2;
  v3._char object = (void *)0xE100000000000000;
  v3._countAndFlagsBits = 10;
  String.append(_:)(v3);
  v3._countAndFlagsBits = v8;
  uint64_t v4 = (void *)v9;
  uint64_t v8 = 0x65676175676E614CLL;
  unint64_t v9 = 0xEA0000000000203ALL;
  v3._char object = v4;
  String.append(_:)(v3);
  swift_bridgeObjectRelease((_BYTE)v4);
  v7._countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  v7._char object = v5;
  v3._countAndFlagsBits = 10;
  v3._char object = (void *)0xE100000000000000;
  String.append(_:)(v3);
  String.append(_:)(v7);
  swift_bridgeObjectRelease(v7._object);
  v3._countAndFlagsBits = 0x6E6F697369766552;
  v3._char object = (void *)0xEA0000000000203ALL;
  String.append(_:)(v3);
  swift_bridgeObjectRelease(58);
  return v8;
}

id MLWordEmbedding.ModelParameters.language.getter()
{
  id v1 = *v0;
  *v0;
  return v1;
}

void MLWordEmbedding.ModelParameters.language.setter(void *a1)
{
  *id v1 = a1;
}

void (*MLWordEmbedding.ModelParameters.language.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLWordEmbedding.ModelParameters.revision.getter()
{
  return *(void *)(v0 + 8);
}

void MLWordEmbedding.ModelParameters.revision.setter(uint64_t a1)
{
  *(void *)(v1 + 8) = a1;
}

void (*MLWordEmbedding.ModelParameters.revision.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLWordEmbedding.ModelParameters.debugDescription.getter(uint64_t a1, uint64_t a2)
{
  return MLWordEmbedding.ModelParameters.description.getter(a1, a2);
}

uint64_t MLWordEmbedding.ModelParameters.playgroundDescription.getter(uint64_t a1, uint64_t a2)
{
  Swift::String v3 = v2;
  uint64_t result = MLWordEmbedding.ModelParameters.description.getter(a1, a2);
  v3[3] = (uint64_t)&type metadata for String;
  uint64_t *v3 = result;
  v3[1] = v5;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLWordEmbedding.ModelParameters()
{
  return MLWordEmbedding.ModelParameters.description.getter();
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLWordEmbedding.ModelParameters(uint64_t a1, uint64_t a2)
{
  return MLWordEmbedding.ModelParameters.debugDescription.getter(a1, a2);
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLWordEmbedding.ModelParameters(uint64_t a1, uint64_t a2)
{
  return MLWordEmbedding.ModelParameters.playgroundDescription.getter(a1, a2);
}

void *initializeBufferWithCopyOfBuffer for MLWordEmbedding.ModelParameters(void *a1, uint64_t a2)
{
  Swift::String v3 = *(void **)a2;
  *a1 = *(void *)a2;
  a1[1] = *(void *)(a2 + 8);
  v3;
  return a1;
}

uint64_t assignWithCopy for MLWordEmbedding.ModelParameters(uint64_t a1, uint64_t a2)
{
  Swift::String v3 = *(void **)a1;
  uint64_t v4 = *(void **)a2;
  *(void *)a1 = *(void *)a2;
  v4;

  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  return a1;
}

uint64_t assignWithTake for MLWordEmbedding.ModelParameters(uint64_t a1, void *a2)
{
  Swift::String v3 = *(void **)a1;
  *(void *)a1 = *a2;

  *(void *)(a1 + 8) = a2[1];
  return a1;
}

uint64_t getEnumTagSinglePayload for MLWordEmbedding.ModelParameters(uint64_t a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 >= 0x7FFFFFFF && *(unsigned char *)(a1 + 16))
    {
      int v2 = *(_DWORD *)a1 + 2147483646;
    }
    else
    {
      int v3 = -1;
      if ((int)((*(void *)a1 >> 1) - 1) >= 0) {
        int v3 = (*(void *)a1 >> 1) - 1;
      }
      int v2 = (*(void *)a1 & 0xFFFFFFFF00000001) != 0 ? -1 : v3;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

uint64_t storeEnumTagSinglePayload for MLWordEmbedding.ModelParameters(uint64_t a1, unsigned int a2, unsigned int a3)
{
  if (a2 > 0x7FFFFFFE)
  {
    *(void *)(a1 + 8) = 0;
    *(void *)a1 = a2 - 0x7FFFFFFF;
    if (a3 >= 0x7FFFFFFF) {
      *(unsigned char *)(a1 + 16) = 1;
    }
  }
  else
  {
    if (a3 >= 0x7FFFFFFF) {
      *(unsigned char *)(a1 + 16) = 0;
    }
    if (a2)
    {
      uint64_t result = 2 * a2;
      *(void *)a1 = result;
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for MLWordEmbedding.ModelParameters()
{
  return &type metadata for MLWordEmbedding.ModelParameters;
}

void *initializeWithCopy for MLWordEmbedding.ModelParameters(void *a1, uint64_t a2)
{
  return initializeBufferWithCopyOfBuffer for MLWordEmbedding.ModelParameters(a1, a2);
}

char *initializeBufferWithCopyOfBuffer for MLSoundClassifier.Classifier(char *__dst, char *__src, uint64_t a3)
{
  uint64_t v4 = __dst;
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v13 = *(void *)__src;
    *(void *)uint64_t v4 = *(void *)__src;
    uint64_t v4 = (char *)(v13 + ((v5 + 16) & ~v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v7);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v14 = *(void *)__src;
      *(void *)uint64_t v4 = *(void *)__src;
      swift_bridgeObjectRetain(v14);
      swift_storeEnumTagMultiPayload(v4, v7, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v9 = type metadata accessor for MLSoundClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v9))
      {
        case 0u:
          uint64_t v10 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 16))(__dst, __src, v10);
          uint64_t v11 = v9;
          uint64_t v12 = 0;
          goto LABEL_15;
        case 1u:
          uint64_t v15 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 16))(__dst, __src, v15);
          uint64_t v46 = 1;
          goto LABEL_11;
        case 2u:
          uint64_t v16 = *(void *)__src;
          *(void *)uint64_t v4 = *(void *)__src;
          swift_bridgeObjectRetain(v16);
          uint64_t v46 = 2;
LABEL_11:
          uint64_t v12 = v46;
          __dst = v4;
          uint64_t v11 = v9;
          goto LABEL_15;
        case 3u:
          uint64_t v49 = v9;
          uint64_t v17 = *(void *)__src;
          char v48 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v48);
          *(void *)__dst = v17;
          __dst[8] = v48;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v18 = *((void *)__src + 3);
          *((void *)v4 + 3) = v18;
          *((void *)v4 + 4) = *((void *)__src + 4);
          uint64_t v19 = *((void *)__src + 5);
          *((void *)v4 + 5) = v19;
          long long v20 = *((_OWORD *)__src + 4);
          *((_OWORD *)v4 + 3) = *((_OWORD *)__src + 3);
          *((_OWORD *)v4 + 4) = v20;
          v4[80] = __src[80];
          swift_bridgeObjectRetain(v18);
          swift_bridgeObjectRetain(v19);
          uint64_t v47 = 3;
          goto LABEL_14;
        case 4u:
          uint64_t v21 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v21 - 8) + 16))(__dst, __src, v21);
          uint64_t v22 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
          uint64_t v23 = v22[12];
          *(void *)&__dst[v23] = *(void *)&__src[v23];
          uint64_t v24 = *(void *)&__src[v23 + 8];
          *(void *)&v4[v23 + 8] = v24;
          uint64_t v25 = v22[16];
          *(void *)&v4[v25] = *(void *)&__src[v25];
          uint64_t v49 = v9;
          uint64_t v26 = *(void *)&__src[v25 + 8];
          *(void *)&v4[v25 + 8] = v26;
          uint64_t v27 = v22[20];
          v4[v27 + 32] = __src[v27 + 32];
          long long v28 = *(_OWORD *)&__src[v27];
          *(_OWORD *)&v4[v27 + 16] = *(_OWORD *)&__src[v27 + 16];
          *(_OWORD *)&v4[v27] = v28;
          swift_bridgeObjectRetain(v24);
          swift_bridgeObjectRetain(v26);
          uint64_t v47 = 4;
LABEL_14:
          uint64_t v12 = v47;
          __dst = v4;
          uint64_t v11 = v49;
LABEL_15:
          swift_storeEnumTagMultiPayload(__dst, v11, v12);
          swift_storeEnumTagMultiPayload(v4, v7, 1);
          break;
        case 5u:
          JUMPOUT(0x25014CLL);
      }
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
    }
    uint64_t v29 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
    *(void *)&v4[v29[5]] = *(void *)&__src[v29[5]];
    *(void *)&v4[v29[6]] = *(void *)&__src[v29[6]];
    uint64_t v30 = v29[7];
    uint64_t v31 = &v4[v30];
    uint64_t v32 = &__src[v30];
    uint64_t v33 = *(void *)&__src[v30 + 24];
    if (v33)
    {
      *((void *)v31 + 3) = v33;
      (**(void (***)(char *, char *))(v33 - 8))(v31, v32);
    }
    else
    {
      long long v34 = *(_OWORD *)v32;
      *((_OWORD *)v31 + 1) = *((_OWORD *)v32 + 1);
      *(_OWORD *)uint64_t v31 = v34;
    }
    uint64_t v35 = v29[8];
    v4[v35 + 8] = __src[v35 + 8];
    *(void *)&v4[v35] = *(void *)&__src[v35];
    *(void *)&v4[v29[9]] = *(void *)&__src[v29[9]];
    uint64_t v36 = *(int *)(a3 + 20);
    int v37 = &v4[v36];
    uint64_t v38 = &__src[v36];
    uint64_t v39 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    if (swift_getEnumCaseMultiPayload(v38, v39) == 1)
    {
      uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v40 - 8) + 16))(v37, v38, v40);
      uint64_t v41 = 1;
      int v42 = v37;
      uint64_t v43 = v39;
    }
    else
    {
      uint64_t v44 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v44 - 8) + 16))(v37, v38, v44);
      int v42 = v37;
      uint64_t v43 = v39;
      uint64_t v41 = 0;
    }
    swift_storeEnumTagMultiPayload(v42, v43, v41);
  }
  return v4;
}

uint64_t destroy for MLSoundClassifier.Classifier(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a1, v3);
  if (EnumCaseMultiPayload == 2)
  {
LABEL_5:
    uint64_t v7 = *(void *)a1;
LABEL_6:
    swift_bridgeObjectRelease(v7);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v5 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(a1, v5))
    {
      case 0u:
      case 1u:
        uint64_t v6 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8))(a1, v6);
        break;
      case 2u:
        goto LABEL_5;
      case 3u:
        outlined consume of Result<_DataTable, Error>(*(void *)a1, *(unsigned char *)(a1 + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + 24));
        uint64_t v7 = *(void *)(a1 + 40);
        goto LABEL_6;
      case 4u:
        uint64_t v14 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v14 - 8) + 8))(a1, v14);
        uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(v15 + 48) + 8));
        uint64_t v7 = *(void *)(a1 + *(int *)(v15 + 64) + 8);
        goto LABEL_6;
      default:
        break;
    }
  }
  uint64_t v8 = *(int *)(type metadata accessor for MLSoundClassifier.ModelParameters(0) + 28);
  if (*(void *)(a1 + v8 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + v8));
  }
  uint64_t v9 = *(int *)(a2 + 20) + a1;
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  uint64_t v11 = &demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>;
  if (swift_getEnumCaseMultiPayload(v9, v10) == 1) {
    uint64_t v11 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>;
  }
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(v11);
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v12 - 8) + 8))(v9, v12);
}

char *initializeWithCopy for MLSoundClassifier.Classifier(char *__dst, char *__src, uint64_t a3)
{
  uint64_t v5 = __dst;
  uint64_t v6 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v6);
  if (EnumCaseMultiPayload == 2)
  {
    uint64_t v12 = *(void *)__src;
    *(void *)uint64_t v5 = *(void *)__src;
    swift_bridgeObjectRetain(v12);
    swift_storeEnumTagMultiPayload(v5, v6, 2);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v8 = type metadata accessor for MLSoundClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(__src, v8))
    {
      case 0u:
        uint64_t v9 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))(__dst, __src, v9);
        uint64_t v10 = v8;
        uint64_t v11 = 0;
        goto LABEL_13;
      case 1u:
        uint64_t v13 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v13 - 8) + 16))(__dst, __src, v13);
        uint64_t v43 = 1;
        goto LABEL_9;
      case 2u:
        uint64_t v14 = *(void *)__src;
        *(void *)uint64_t v5 = *(void *)__src;
        swift_bridgeObjectRetain(v14);
        uint64_t v43 = 2;
LABEL_9:
        uint64_t v11 = v43;
        __dst = v5;
        uint64_t v10 = v8;
        goto LABEL_13;
      case 3u:
        uint64_t v46 = v8;
        uint64_t v15 = *(void *)__src;
        char v45 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v45);
        *(void *)__dst = v15;
        __dst[8] = v45;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v16 = *((void *)__src + 3);
        *((void *)v5 + 3) = v16;
        *((void *)v5 + 4) = *((void *)__src + 4);
        uint64_t v17 = *((void *)__src + 5);
        *((void *)v5 + 5) = v17;
        long long v18 = *((_OWORD *)__src + 4);
        *((_OWORD *)v5 + 3) = *((_OWORD *)__src + 3);
        *((_OWORD *)v5 + 4) = v18;
        v5[80] = __src[80];
        swift_bridgeObjectRetain(v16);
        swift_bridgeObjectRetain(v17);
        uint64_t v44 = 3;
        goto LABEL_12;
      case 4u:
        uint64_t v19 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16))(__dst, __src, v19);
        long long v20 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
        uint64_t v21 = v20[12];
        *(void *)&__dst[v21] = *(void *)&__src[v21];
        uint64_t v22 = *(void *)&__src[v21 + 8];
        *(void *)&v5[v21 + 8] = v22;
        uint64_t v23 = v20[16];
        *(void *)&v5[v23] = *(void *)&__src[v23];
        uint64_t v46 = v8;
        uint64_t v24 = *(void *)&__src[v23 + 8];
        *(void *)&v5[v23 + 8] = v24;
        uint64_t v25 = v20[20];
        v5[v25 + 32] = __src[v25 + 32];
        long long v26 = *(_OWORD *)&__src[v25];
        *(_OWORD *)&v5[v25 + 16] = *(_OWORD *)&__src[v25 + 16];
        *(_OWORD *)&v5[v25] = v26;
        swift_bridgeObjectRetain(v22);
        swift_bridgeObjectRetain(v24);
        uint64_t v44 = 4;
LABEL_12:
        uint64_t v11 = v44;
        __dst = v5;
        uint64_t v10 = v46;
LABEL_13:
        swift_storeEnumTagMultiPayload(__dst, v10, v11);
        swift_storeEnumTagMultiPayload(v5, v6, 1);
        break;
    }
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
  }
  uint64_t v27 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  *(void *)&v5[v27[5]] = *(void *)&__src[v27[5]];
  *(void *)&v5[v27[6]] = *(void *)&__src[v27[6]];
  uint64_t v28 = v27[7];
  uint64_t v29 = &v5[v28];
  uint64_t v30 = &__src[v28];
  uint64_t v31 = *(void *)&__src[v28 + 24];
  if (v31)
  {
    *((void *)v29 + 3) = v31;
    (**(void (***)(char *, char *))(v31 - 8))(v29, v30);
  }
  else
  {
    long long v32 = *(_OWORD *)v30;
    *((_OWORD *)v29 + 1) = *((_OWORD *)v30 + 1);
    *(_OWORD *)uint64_t v29 = v32;
  }
  uint64_t v33 = v27[8];
  v5[v33 + 8] = __src[v33 + 8];
  *(void *)&v5[v33] = *(void *)&__src[v33];
  *(void *)&v5[v27[9]] = *(void *)&__src[v27[9]];
  uint64_t v34 = *(int *)(a3 + 20);
  uint64_t v35 = &v5[v34];
  uint64_t v36 = &__src[v34];
  uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  int v38 = swift_getEnumCaseMultiPayload(v36, v37);
  BOOL v39 = v38 == 1;
  uint64_t v40 = &demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>;
  if (v38 == 1) {
    uint64_t v40 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>;
  }
  uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(v40);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v41 - 8) + 16))(v35, v36, v41);
  swift_storeEnumTagMultiPayload(v35, v37, v39);
  return v5;
}

char *assignWithCopy for MLSoundClassifier.Classifier(char *__dst, char *__src, uint64_t a3)
{
  uint64_t v4 = __dst;
  if (__dst != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)__dst, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v5);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v11 = *(void *)__src;
      *(void *)uint64_t v4 = *(void *)__src;
      swift_bridgeObjectRetain(v11);
      swift_storeEnumTagMultiPayload(v4, v5, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v7 = type metadata accessor for MLSoundClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v7))
      {
        case 0u:
          uint64_t v8 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 16))(__dst, __src, v8);
          uint64_t v9 = v7;
          uint64_t v10 = 0;
          goto LABEL_13;
        case 1u:
          uint64_t v12 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 16))(__dst, __src, v12);
          uint64_t v43 = 1;
          goto LABEL_12;
        case 2u:
          uint64_t v13 = *(void *)__src;
          *(void *)uint64_t v4 = *(void *)__src;
          swift_bridgeObjectRetain(v13);
          uint64_t v43 = 2;
          goto LABEL_12;
        case 3u:
          uint64_t v14 = *(void *)__src;
          uint64_t v45 = v7;
          char v15 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v15);
          *(void *)__dst = v14;
          __dst[8] = v15;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v16 = *((void *)__src + 3);
          *((void *)v4 + 3) = v16;
          *((void *)v4 + 4) = *((void *)__src + 4);
          uint64_t v17 = *((void *)__src + 5);
          *((void *)v4 + 5) = v17;
          long long v18 = *((_OWORD *)__src + 4);
          *((_OWORD *)v4 + 3) = *((_OWORD *)__src + 3);
          *((_OWORD *)v4 + 4) = v18;
          v4[80] = __src[80];
          swift_bridgeObjectRetain(v16);
          swift_bridgeObjectRetain(v17);
          uint64_t v10 = 3;
          __dst = v4;
          uint64_t v9 = v45;
          goto LABEL_13;
        case 4u:
          uint64_t v19 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16))(__dst, __src, v19);
          long long v20 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
          uint64_t v21 = v20[12];
          *(void *)&__dst[v21] = *(void *)&__src[v21];
          uint64_t v22 = *(void *)&__src[v21 + 8];
          *(void *)&v4[v21 + 8] = v22;
          uint64_t v23 = v20[16];
          *(void *)&v4[v23] = *(void *)&__src[v23];
          uint64_t v24 = *(void *)&__src[v23 + 8];
          *(void *)&v4[v23 + 8] = v24;
          uint64_t v25 = v20[20];
          v4[v25 + 32] = __src[v25 + 32];
          long long v26 = *(_OWORD *)&__src[v25];
          *(_OWORD *)&v4[v25 + 16] = *(_OWORD *)&__src[v25 + 16];
          *(_OWORD *)&v4[v25] = v26;
          swift_bridgeObjectRetain(v22);
          swift_bridgeObjectRetain(v24);
          uint64_t v43 = 4;
LABEL_12:
          uint64_t v10 = v43;
          __dst = v4;
          uint64_t v9 = v7;
LABEL_13:
          swift_storeEnumTagMultiPayload(__dst, v9, v10);
          swift_storeEnumTagMultiPayload(v4, v5, 1);
          break;
        case 5u:
          JUMPOUT(0x2508F0);
      }
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
    }
  }
  uint64_t v27 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  *(void *)&v4[v27[5]] = *(void *)&__src[v27[5]];
  *(void *)&v4[v27[6]] = *(void *)&__src[v27[6]];
  uint64_t v28 = v27[7];
  uint64_t v29 = &v4[v28];
  uint64_t v30 = &__src[v28];
  uint64_t v31 = *(void *)&__src[v28 + 24];
  if (*(void *)&v4[v28 + 24])
  {
    if (v31)
    {
      __swift_assign_boxed_opaque_existential_0((uint64_t *)&v4[v28], (uint64_t *)&__src[v28]);
      goto LABEL_21;
    }
    __swift_destroy_boxed_opaque_existential_1Tm(&v4[v28]);
  }
  else if (v31)
  {
    *((void *)v29 + 3) = v31;
    (**(void (***)(char *, char *))(v31 - 8))(v29, v30);
    goto LABEL_21;
  }
  long long v32 = *(_OWORD *)v30;
  *((_OWORD *)v29 + 1) = *((_OWORD *)v30 + 1);
  *(_OWORD *)uint64_t v29 = v32;
LABEL_21:
  uint64_t v33 = v27[8];
  v4[v33 + 8] = __src[v33 + 8];
  *(void *)&v4[v33] = *(void *)&__src[v33];
  *(void *)&v4[v27[9]] = *(void *)&__src[v27[9]];
  if (v4 != __src)
  {
    uint64_t v34 = *(int *)(a3 + 20);
    uint64_t v35 = &__src[v34];
    uint64_t v36 = (uint64_t)&v4[v34];
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v36, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    int v38 = swift_getEnumCaseMultiPayload(v35, v37);
    BOOL v39 = v38 == 1;
    uint64_t v40 = &demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>;
    if (v38 == 1) {
      uint64_t v40 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>;
    }
    uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(v40);
    (*(void (**)(uint64_t, char *, uint64_t))(*(void *)(v41 - 8) + 16))(v36, v35, v41);
    swift_storeEnumTagMultiPayload(v36, v37, v39);
  }
  return v4;
}

char *initializeWithTake for MLSoundClassifier.Classifier(char *__dst, char *__src, uint64_t a3)
{
  uint64_t v6 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  if (swift_getEnumCaseMultiPayload(__src, v6) != 1)
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
    goto LABEL_13;
  }
  uint64_t v7 = type metadata accessor for MLSoundClassifier.DataSource(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v7);
  if (EnumCaseMultiPayload == 4)
  {
    uint64_t v12 = type metadata accessor for DataFrame(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
    uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
    *(_OWORD *)&__dst[v13[12]] = *(_OWORD *)&__src[v13[12]];
    *(_OWORD *)&__dst[v13[16]] = *(_OWORD *)&__src[v13[16]];
    uint64_t v14 = v13[20];
    long long v15 = *(_OWORD *)&__src[v14 + 16];
    *(_OWORD *)&__dst[v14] = *(_OWORD *)&__src[v14];
    *(_OWORD *)&__dst[v14 + 16] = v15;
    __dst[v14 + 32] = __src[v14 + 32];
    uint64_t v30 = 4;
LABEL_9:
    uint64_t v11 = v30;
    uint64_t v10 = v7;
    goto LABEL_10;
  }
  if (EnumCaseMultiPayload == 1)
  {
    uint64_t v16 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 32))(__dst, __src, v16);
    uint64_t v30 = 1;
    goto LABEL_9;
  }
  if (EnumCaseMultiPayload)
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
    goto LABEL_12;
  }
  uint64_t v9 = type metadata accessor for URL(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
  uint64_t v10 = v7;
  uint64_t v11 = 0;
LABEL_10:
  swift_storeEnumTagMultiPayload(__dst, v10, v11);
LABEL_12:
  swift_storeEnumTagMultiPayload(__dst, v6, 1);
LABEL_13:
  uint64_t v17 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  *(void *)&__dst[v17[5]] = *(void *)&__src[v17[5]];
  *(void *)&__dst[v17[6]] = *(void *)&__src[v17[6]];
  uint64_t v18 = v17[7];
  long long v19 = *(_OWORD *)&__src[v18];
  *(_OWORD *)&__dst[v18 + 16] = *(_OWORD *)&__src[v18 + 16];
  *(_OWORD *)&__dst[v18] = v19;
  uint64_t v20 = v17[8];
  *(void *)&__dst[v20] = *(void *)&__src[v20];
  __dst[v20 + 8] = __src[v20 + 8];
  *(void *)&__dst[v17[9]] = *(void *)&__src[v17[9]];
  uint64_t v21 = *(int *)(a3 + 20);
  uint64_t v22 = &__dst[v21];
  uint64_t v23 = &__src[v21];
  uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  int v25 = swift_getEnumCaseMultiPayload(v23, v24);
  BOOL v26 = v25 == 1;
  uint64_t v27 = &demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>;
  if (v25 == 1) {
    uint64_t v27 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>;
  }
  uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(v27);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v28 - 8) + 32))(v22, v23, v28);
  swift_storeEnumTagMultiPayload(v22, v24, v26);
  return __dst;
}

char *assignWithTake for MLSoundClassifier.Classifier(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)__dst, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
    if (swift_getEnumCaseMultiPayload(__src, v5) != 1)
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
      goto LABEL_14;
    }
    uint64_t v6 = type metadata accessor for MLSoundClassifier.DataSource(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v6);
    if (EnumCaseMultiPayload == 4)
    {
      uint64_t v11 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 32))(__dst, __src, v11);
      uint64_t v12 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, featureColumn: String, labelColumn: String, parameters: MLSoundClassifier.FeatureExtractionParameters));
      *(_OWORD *)&__dst[v12[12]] = *(_OWORD *)&__src[v12[12]];
      *(_OWORD *)&__dst[v12[16]] = *(_OWORD *)&__src[v12[16]];
      uint64_t v13 = v12[20];
      long long v14 = *(_OWORD *)&__src[v13 + 16];
      *(_OWORD *)&__dst[v13] = *(_OWORD *)&__src[v13];
      *(_OWORD *)&__dst[v13 + 16] = v14;
      __dst[v13 + 32] = __src[v13 + 32];
      uint64_t v31 = 4;
    }
    else
    {
      if (EnumCaseMultiPayload != 1)
      {
        if (EnumCaseMultiPayload)
        {
          memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
          goto LABEL_13;
        }
        uint64_t v8 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
        uint64_t v9 = v6;
        uint64_t v10 = 0;
LABEL_11:
        swift_storeEnumTagMultiPayload(__dst, v9, v10);
LABEL_13:
        swift_storeEnumTagMultiPayload(__dst, v5, 1);
        goto LABEL_14;
      }
      uint64_t v15 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 32))(__dst, __src, v15);
      uint64_t v31 = 1;
    }
    uint64_t v10 = v31;
    uint64_t v9 = v6;
    goto LABEL_11;
  }
LABEL_14:
  uint64_t v16 = (int *)type metadata accessor for MLSoundClassifier.ModelParameters(0);
  *(void *)&__dst[v16[5]] = *(void *)&__src[v16[5]];
  *(void *)&__dst[v16[6]] = *(void *)&__src[v16[6]];
  uint64_t v17 = v16[7];
  uint64_t v18 = &__dst[v17];
  long long v19 = &__src[v17];
  if (*(void *)&__dst[v17 + 24]) {
    __swift_destroy_boxed_opaque_existential_1Tm(&__dst[v17]);
  }
  long long v20 = *(_OWORD *)v19;
  *((_OWORD *)v18 + 1) = *((_OWORD *)v19 + 1);
  *(_OWORD *)uint64_t v18 = v20;
  uint64_t v21 = v16[8];
  *(void *)&__dst[v21] = *(void *)&__src[v21];
  __dst[v21 + 8] = __src[v21 + 8];
  *(void *)&__dst[v16[9]] = *(void *)&__src[v16[9]];
  if (__dst != __src)
  {
    uint64_t v22 = *(int *)(a3 + 20);
    uint64_t v23 = &__src[v22];
    uint64_t v24 = &__dst[v22];
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v24, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    int v26 = swift_getEnumCaseMultiPayload(v23, v25);
    BOOL v27 = v26 == 1;
    uint64_t v28 = &demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>;
    if (v26 == 1) {
      uint64_t v28 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>;
    }
    uint64_t v29 = __swift_instantiateConcreteTypeFromMangledName(v28);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v29 - 8) + 32))(v24, v23, v29);
    swift_storeEnumTagMultiPayload(v24, v25, v27);
  }
  return __dst;
}

uint64_t getEnumTagSinglePayload for MLSoundClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_250D8C);
}

uint64_t sub_250D8C(uint64_t a1, unsigned int a2, uint64_t a3)
{
  uint64_t v4 = a1;
  uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) != a2)
  {
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    uint64_t v4 = *(int *)(a3 + 20) + a1;
  }
  return __swift_getEnumTagSinglePayload(v4, a2, v5);
}

uint64_t storeEnumTagSinglePayload for MLSoundClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_250DF8);
}

uint64_t sub_250DF8(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = a1;
  uint64_t v7 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  if (*(_DWORD *)(*(void *)(v7 - 8) + 84) != a3)
  {
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    uint64_t v6 = *(int *)(a4 + 20) + a1;
  }
  return __swift_storeEnumTagSinglePayload(v6, a2, a2, v7);
}

uint64_t type metadata accessor for MLSoundClassifier.Classifier(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLSoundClassifier.Classifier;
  if (!type metadata singleton initialization cache for MLSoundClassifier.Classifier) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLSoundClassifier.Classifier);
  }
  return result;
}

uint64_t type metadata completion function for MLSoundClassifier.Classifier(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLSoundClassifier.ModelParameters(319);
  if (v2 <= 0x3F)
  {
    v4[0] = *(void *)(result - 8) + 64;
    uint64_t result = type metadata accessor for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(319);
    if (v3 <= 0x3F)
    {
      v4[1] = *(void *)(result - 8) + 64;
      swift_initStructMetadata(a1, 256, 2, v4, a1 + 16);
      return 0;
    }
  }
  return result;
}

uint64_t associated type witness table accessor for SupervisedEstimator.Transformer : Transformer in MLSoundClassifier.Classifier()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLSoundClassifier.Model and conformance MLSoundClassifier.Model, type metadata accessor for MLSoundClassifier.Model, (uint64_t)&protocol conformance descriptor for MLSoundClassifier.Model);
}

uint64_t MLSoundClassifier.Classifier.init(labels:parameters:)(uint64_t a1, uint64_t a2)
{
  uint64_t v54 = a1;
  uint64_t v3 = v2;
  uint64_t v48 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  uint64_t v56 = *(void *)(v48 - 8);
  int64_t v4 = *(void *)(v56 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v49 = v40;
  uint64_t v50 = type metadata accessor for FullyConnectedNetworkConfiguration(0);
  uint64_t v57 = *(void *)(v50 - 8);
  int64_t v7 = *(void *)(v57 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v52 = v40;
  uint64_t v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  uint64_t v51 = v40;
  uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  uint64_t v44 = *(void *)(v45 - 8);
  int64_t v12 = *(void *)(v44 + 64);
  uint64_t v13 = alloca(v12);
  long long v14 = alloca(v12);
  uint64_t v46 = v40;
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>.Configuration);
  uint64_t v47 = *(void *)(v15 - 8);
  int64_t v16 = *(void *)(v47 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  long long v19 = alloca(v16);
  long long v20 = alloca(v16);
  uint64_t v53 = v3;
  outlined init with copy of MLSoundClassifier.ModelParameters(a2, v3);
  uint64_t v21 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  uint64_t v22 = *(int *)(v21 + 28);
  uint64_t v55 = a2;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a2 + v22, (uint64_t)v42, &demangling cache variable for type metadata for Any?);
  if (!v43)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v42, &demangling cache variable for type metadata for Any?);
LABEL_6:
    uint64_t v57 = lazy protocol witness table accessor for type Float and conformance Float();
    LogisticRegressionClassifier.Configuration.init()(&type metadata for Float, &type metadata for String, &protocol witness table for Float, v57, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String);
    uint64_t v34 = *(int *)(v21 + 20);
    uint64_t v35 = v55;
    LogisticRegressionClassifier.Configuration.maximumIterations.setter(*(void *)(v55 + v34), v15);
    uint64_t v36 = v47;
    (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v47 + 16))(v40, v40, v15);
    uint64_t v56 = v15;
    uint64_t v37 = v46;
    LogisticRegressionClassifier.init(labels:configuration:)(v54, v40, &type metadata for Float, &type metadata for String, &protocol witness table for Float, v57, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String);
    outlined destroy of MLActivityClassifier.ModelParameters(v35, type metadata accessor for MLSoundClassifier.ModelParameters);
    (*(void (**)(unsigned char *, uint64_t))(v36 + 8))(v40, v56);
    uint64_t v38 = *(int *)(type metadata accessor for MLSoundClassifier.Classifier(0) + 20) + v53;
    (*(void (**)(uint64_t, unsigned char *, uint64_t))(v44 + 32))(v38, v37, v45);
    uint64_t v32 = v38;
    uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    uint64_t v31 = 0;
    return swift_storeEnumTagMultiPayload(v32, v33, v31);
  }
  if (!swift_dynamicCast(v40, v42, (char *)&type metadata for Any + 8, &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType, 6))goto LABEL_6; {
  uint64_t v23 = v41;
  }
  if (!v41) {
    goto LABEL_6;
  }
  swift_bridgeObjectRetain(v41);
  uint64_t v24 = v51;
  FullyConnectedNetworkConfiguration.init()();
  FullyConnectedNetworkConfiguration.maximumIterations.setter(*(void *)(v55 + *(int *)(v21 + 20)));
  FullyConnectedNetworkConfiguration.hiddenUnitCounts.setter(v23);
  FullyConnectedNetworkConfiguration.batchSize.setter(32);
  uint64_t v25 = v52;
  uint64_t v26 = v50;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v57 + 16))(v52, v24, v50);
  uint64_t v27 = lazy protocol witness table accessor for type Float and conformance Float();
  uint64_t v28 = v49;
  FullyConnectedNetworkClassifier.init(labels:configuration:)(v54, v25, &type metadata for Float, &type metadata for String, &protocol witness table for Float, v27, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String);
  swift_bridgeObjectRelease(v23);
  outlined destroy of MLActivityClassifier.ModelParameters(v55, type metadata accessor for MLSoundClassifier.ModelParameters);
  (*(void (**)(unsigned char *, uint64_t))(v57 + 8))(v24, v26);
  uint64_t v29 = *(int *)(type metadata accessor for MLSoundClassifier.Classifier(0) + 20) + v53;
  (*(void (**)(uint64_t, unsigned char *, uint64_t))(v56 + 32))(v29, v28, v48);
  uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  uint64_t v31 = 1;
  uint64_t v32 = v29;
  uint64_t v33 = v30;
  return swift_storeEnumTagMultiPayload(v32, v33, v31);
}

uint64_t MLSoundClassifier.Classifier.makeTransformer()()
{
  uint64_t v51 = v0;
  uint64_t v42 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  uint64_t v41 = *(void *)(v42 - 8);
  int64_t v2 = *(void *)(v41 + 64);
  uint64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  uint64_t v43 = &v41;
  uint64_t v47 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  uint64_t v44 = *(void *)(v47 - 8);
  int64_t v5 = *(void *)(v44 + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v49 = &v41;
  uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  uint64_t v46 = *(void *)(v45 - 8);
  int64_t v8 = *(void *)(v46 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v48 = &v41;
  int64_t v11 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.ModelParameters(0) - 8) + 64);
  int64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v52 = &v41;
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  uint64_t v15 = *(void *)(v14 - 8);
  int64_t v16 = *(void *)(v15 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v50 = &v41;
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  int64_t v20 = *(void *)(*(void *)(v19 - 8) + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v23 = *(int *)(type metadata accessor for MLSoundClassifier.Classifier(0) + 20);
  uint64_t v53 = v1;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1 + v23, (uint64_t)&v41, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  if (swift_getEnumCaseMultiPayload(&v41, v19) == 1)
  {
    uint64_t v24 = v49;
    uint64_t v25 = v47;
    uint64_t v26 = v44;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v44 + 32))(v49, &v41, v47);
    uint64_t v27 = (uint64_t)v52;
    outlined init with copy of MLSoundClassifier.ModelParameters(v53, (uint64_t)v52);
    uint64_t v28 = v43;
    FullyConnectedNetworkClassifier.makeTransformer()(v25);
    (*(void (**)(uint64_t *, uint64_t))(v26 + 8))(v24, v25);
    uint64_t v29 = type metadata accessor for MLSoundClassifier.Model(0);
    uint64_t v30 = v51;
    uint64_t v31 = v51 + *(int *)(v29 + 20);
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v41 + 32))(v31, v28, v42);
    uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    uint64_t v33 = 1;
    uint64_t v34 = v31;
    uint64_t v35 = v32;
  }
  else
  {
    uint64_t v36 = v50;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v15 + 32))(v50, &v41, v14);
    uint64_t v27 = (uint64_t)v52;
    outlined init with copy of MLSoundClassifier.ModelParameters(v53, (uint64_t)v52);
    uint64_t v37 = v48;
    LogisticRegressionClassifier.makeTransformer()(v14);
    (*(void (**)(uint64_t *, uint64_t))(v15 + 8))(v36, v14);
    uint64_t v38 = type metadata accessor for MLSoundClassifier.Model(0);
    uint64_t v30 = v51;
    uint64_t v39 = v51 + *(int *)(v38 + 20);
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v46 + 32))(v39, v37, v45);
    uint64_t v34 = v39;
    uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    uint64_t v33 = 0;
  }
  swift_storeEnumTagMultiPayload(v34, v35, v33);
  return outlined init with take of MLSoundClassifier.ModelParameters(v27, v30);
}

uint64_t MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v7[8] = v6;
  v7[7] = a6;
  v7[6] = a5;
  v7[5] = a4;
  v7[4] = a3;
  v7[3] = a2;
  v7[2] = a1;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v7[9] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v7[10] = v9;
  v7[11] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  v7[12] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v7[13] = v11;
  v7[14] = swift_task_alloc((*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v7[15] = v12;
  uint64_t v13 = *(void *)(v12 - 8);
  v7[16] = v13;
  v7[17] = swift_task_alloc((*(void *)(v13 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  v7[18] = v14;
  uint64_t v15 = *(void *)(v14 - 8);
  v7[19] = v15;
  v7[20] = swift_task_alloc((*(void *)(v15 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  v7[21] = v16;
  v7[22] = swift_task_alloc((*(void *)(*(void *)(v16 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:), 0, 0);
}

uint64_t MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:)()
{
  uint64_t v1 = v0[22];
  uint64_t v2 = v0[8];
  uint64_t v3 = v0[21];
  uint64_t v4 = type metadata accessor for MLSoundClassifier.Classifier(0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v2 + *(int *)(v4 + 20), v1, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v1, v3);
  uint64_t v6 = v0[22];
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(v0[13] + 32))(v0[14], v6, v0[12]);
    int64_t v7 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifier.fitted<A>(to:eventHandler:)[1]);
    v0[25] = v7;
    *int64_t v7 = v0;
    v7[1] = MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
    return FullyConnectedNetworkClassifier.fitted<A>(to:eventHandler:)(v0[11], v0[3], v0[4], v0[5], v0[12], v0[6], v0[7]);
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(v0[19] + 32))(v0[20], v6, v0[18]);
    uint64_t v9 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifier.fitted<A>(to:eventHandler:)[1]);
    v0[23] = v9;
    *uint64_t v9 = v0;
    v9[1] = MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
    return LogisticRegressionClassifier.fitted<A>(to:eventHandler:)(v0[17], v0[3], v0[4], v0[5], v0[18], v0[6], v0[7]);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 184);
  *(void *)(*(void *)v1 + 192) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLImageClassifier.Classifier.fitted<A>(to:eventHandler:);
  }
  else {
    uint64_t v3 = MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;

  uint64_t v1 = *(void *)(v0 + 160);
  uint64_t v2 = *(void *)(v0 + 136);
  uint64_t v11 = *(void *)(v0 + 128);
  uint64_t v12 = *(void *)(v0 + 120);
  uint64_t v10 = *(void *)(v0 + 176);
  uint64_t v9 = *(void *)(v0 + 112);
  uint64_t v8 = *(void *)(v0 + 88);
  uint64_t v3 = *(void *)(v0 + 16);
  uint64_t v4 = *(void *)(v0 + 64);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 152) + 8))(v1, *(void *)(v0 + 144));
  outlined init with copy of MLSoundClassifier.ModelParameters(v4, v3);
  int64_t v5 = v3 + *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v11 + 32))(v5, v2, v12);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload(v5, v6, 0);
  swift_task_dealloc(v10);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 200);
  *(void *)(*(void *)v1 + 208) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLImageClassifier.Classifier.fitted<A>(to:eventHandler:);
  }
  else {
    uint64_t v3 = MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;

  uint64_t v9 = *(void *)(v0 + 112);
  uint64_t v1 = *(void *)(v0 + 88);
  uint64_t v12 = *(void *)(v0 + 80);
  uint64_t v2 = *(void *)(v0 + 72);
  uint64_t v11 = *(void *)(v0 + 176);
  uint64_t v10 = *(void *)(v0 + 160);
  uint64_t v8 = *(void *)(v0 + 136);
  uint64_t v3 = *(void *)(v0 + 16);
  uint64_t v4 = *(void *)(v0 + 64);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 104) + 8))(v9, *(void *)(v0 + 96));
  outlined init with copy of MLSoundClassifier.ModelParameters(v4, v3);
  int64_t v5 = v3 + *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v12 + 32))(v5, v1, v2);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload(v5, v6, 1);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  *(void *)(v8 + 88) = v7;
  *(void *)(v8 + 80) = a7;
  *(_OWORD *)(v8 + 64) = *(_OWORD *)&v20;
  *(void *)(v8 + 56) = a6;
  *(void *)(v8 + 48) = a5;
  *(void *)(v8 + 40) = a4;
  *(void *)(v8 + 32) = a3;
  *(void *)(v8 + 24) = a2;
  *(void *)(v8 + 16) = a1;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  *(void *)(v8 + 96) = v9;
  uint64_t v10 = *(void *)(v9 - 8);
  *(void *)(v8 + 104) = v10;
  *(void *)(v8 + 112) = swift_task_alloc((*(void *)(v10 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  *(void *)(v8 + 120) = v11;
  uint64_t v12 = *(void *)(v11 - 8);
  *(void *)(v8 + 128) = v12;
  *(void *)(v8 + 136) = swift_task_alloc((*(void *)(v12 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  *(void *)(v8 + 144) = v13;
  uint64_t v14 = *(void *)(v13 - 8);
  *(void *)(v8 + 152) = v14;
  *(void *)(v8 + 160) = swift_task_alloc((*(void *)(v14 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  *(void *)(v8 + 168) = v15;
  uint64_t v16 = *(void *)(v15 - 8);
  *(void *)(v8 + 176) = v16;
  *(void *)(v8 + 184) = swift_task_alloc((*(void *)(v16 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  *(void *)(v8 + 192) = v17;
  *(void *)(v8 + 200) = swift_task_alloc((*(void *)(*(void *)(v17 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  retaddr = v19;
  return swift_task_switch(MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:), 0, 0);
}

uint64_t MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)()
{
  uint64_t v1 = *(void *)(v0 + 200);
  uint64_t v2 = *(void *)(v0 + 88);
  uint64_t v3 = *(void *)(v0 + 192);
  uint64_t v4 = type metadata accessor for MLSoundClassifier.Classifier(0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v2 + *(int *)(v4 + 20), v1, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v1, v3);
  uint64_t v6 = *(void *)(v0 + 200);
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 128) + 32))(*(void *)(v0 + 136), v6, *(void *)(v0 + 120));
    uint64_t v7 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifier.fitted<A, B>(to:validateOn:eventHandler:)[1]);
    *(void *)(v0 + 224) = v7;
    *uint64_t v7 = v0;
    v7[1] = MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
    *(_OWORD *)&uint64_t v10 = *(_OWORD *)(v0 + 72);
    return FullyConnectedNetworkClassifier.fitted<A, B>(to:validateOn:eventHandler:)(*(void *)(v0 + 112), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 120));
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 176) + 32))(*(void *)(v0 + 184), v6, *(void *)(v0 + 168));
    uint64_t v9 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifier.fitted<A, B>(to:validateOn:eventHandler:)[1]);
    *(void *)(v0 + 208) = v9;
    *uint64_t v9 = v0;
    v9[1] = MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
    *(_OWORD *)&uint64_t v10 = *(_OWORD *)(v0 + 72);
    return LogisticRegressionClassifier.fitted<A, B>(to:validateOn:eventHandler:)(*(void *)(v0 + 160), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 168));
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 208);
  *(void *)(*(void *)v1 + 216) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  }
  else {
    uint64_t v3 = MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;

  uint64_t v1 = *(void *)(v0 + 184);
  uint64_t v2 = *(void *)(v0 + 160);
  uint64_t v11 = *(void *)(v0 + 152);
  uint64_t v12 = *(void *)(v0 + 144);
  uint64_t v10 = *(void *)(v0 + 200);
  uint64_t v9 = *(void *)(v0 + 136);
  uint64_t v8 = *(void *)(v0 + 112);
  uint64_t v3 = *(void *)(v0 + 16);
  uint64_t v4 = *(void *)(v0 + 88);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 176) + 8))(v1, *(void *)(v0 + 168));
  outlined init with copy of MLSoundClassifier.ModelParameters(v4, v3);
  int64_t v5 = v3 + *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v11 + 32))(v5, v2, v12);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload(v5, v6, 0);
  swift_task_dealloc(v10);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 224);
  *(void *)(*(void *)v1 + 232) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  }
  else {
    uint64_t v3 = MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;

  uint64_t v9 = *(void *)(v0 + 136);
  uint64_t v1 = *(void *)(v0 + 112);
  uint64_t v12 = *(void *)(v0 + 104);
  uint64_t v2 = *(void *)(v0 + 96);
  uint64_t v11 = *(void *)(v0 + 200);
  uint64_t v10 = *(void *)(v0 + 184);
  uint64_t v8 = *(void *)(v0 + 160);
  uint64_t v3 = *(void *)(v0 + 16);
  uint64_t v4 = *(void *)(v0 + 88);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 128) + 8))(v9, *(void *)(v0 + 120));
  outlined init with copy of MLSoundClassifier.ModelParameters(v4, v3);
  int64_t v5 = v3 + *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v12 + 32))(v5, v1, v2);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload(v5, v6, 1);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLSoundClassifier.Classifier.encode(_:to:)(uint64_t a1, uint64_t a2)
{
  uint64_t v52 = v2;
  uint64_t v4 = v3;
  uint64_t v53 = a2;
  uint64_t v46 = a1;
  uint64_t v55 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  uint64_t v54 = *(void *)(v55 - 8);
  int64_t v5 = *(void *)(v54 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v48 = &v46;
  uint64_t v59 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  uint64_t v60 = *(void *)(v59 - 8);
  int64_t v8 = *(void *)(v60 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v56 = &v46;
  uint64_t v58 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  uint64_t v57 = *(void *)(v58 - 8);
  int64_t v11 = *(void *)(v57 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v49 = &v46;
  uint64_t v61 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  uint64_t v62 = *(void *)(v61 - 8);
  int64_t v14 = *(void *)(v62 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v63 = &v46;
  uint64_t v47 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  int64_t v17 = *(void *)(*(void *)(v47 - 8) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v50 = &v46;
  uint64_t v20 = alloca(v17);
  uint64_t v21 = alloca(v17);
  uint64_t v51 = &v46;
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>, Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>));
  int64_t v23 = *(void *)(*(void *)(v22 - 8) + 64);
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  uint64_t v26 = v4 + *(int *)(type metadata accessor for MLSoundClassifier.Classifier(0) + 20);
  uint64_t v27 = v46 + *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  uint64_t v28 = (char *)&v46 + *(int *)(v22 + 48);
  uint64_t v29 = v26;
  uint64_t v30 = &v46;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v29, (uint64_t)&v46, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v27, (uint64_t)v28, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload(&v46, v47) != 1)
  {
    uint64_t v39 = (uint64_t)v51;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v46, (uint64_t)v51, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    if (swift_getEnumCaseMultiPayload(v28, v40) != 1)
    {
      uint64_t v41 = v39;
      uint64_t v42 = v61;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v62 + 32))(v63, v41, v61);
      uint64_t v43 = v49;
      (*(void (**)(uint64_t *, char *, uint64_t))(v57 + 32))(v49, v28, v58);
      LogisticRegressionClassifier.encode(_:to:)(v43, v53, v42);
      (*(void (**)(uint64_t *, uint64_t))(v57 + 8))(v43, v58);
      (*(void (**)(uint64_t *, uint64_t))(v62 + 8))(v63, v42);
      return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v30, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    }
    uint64_t v45 = v39;
LABEL_9:
    (*(void (**)(uint64_t, uint64_t))(v62 + 8))(v45, v61);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000002FLL, "Classifier.Classifier.swift" + 0x8000000000000000, "CreateML/MLSoundClassifier.Classifier.swift", 43, 2, 91, 0);
    BUG();
  }
  uint64_t v63 = &v46;
  uint64_t v31 = (uint64_t)v50;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v46, (uint64_t)v50, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload(v28, v32) != 1)
  {
    uint64_t v62 = v60;
    uint64_t v61 = v59;
    uint64_t v45 = v31;
    goto LABEL_9;
  }
  uint64_t v33 = v59;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v60 + 32))(v56, v31, v59);
  uint64_t v34 = v48;
  (*(void (**)(uint64_t *, char *, uint64_t))(v54 + 32))(v48, v28, v55);
  uint64_t v35 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>, &demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>, (uint64_t)&protocol conformance descriptor for FullyConnectedNetworkClassifier<A, B>);
  uint64_t v36 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FullyConnectedNetworkClassifierModel<Float, String> and conformance FullyConnectedNetworkClassifierModel<A, B>, &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>, (uint64_t)&protocol conformance descriptor for FullyConnectedNetworkClassifierModel<A, B>);
  uint64_t v37 = v35;
  uint64_t v38 = v56;
  SupervisedEstimator<>.encode(_:to:)(v34, v53, v33, v37, v36);
  (*(void (**)(uint64_t *, uint64_t))(v54 + 8))(v34, v55);
  (*(void (**)(uint64_t *, uint64_t))(v60 + 8))(v38, v33);
  uint64_t v30 = v63;
  return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v30, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
}

uint64_t protocol witness for SupervisedEstimator.fitted<A>(to:eventHandler:) in conformance MLSoundClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v9 = (void *)swift_task_alloc(dword_3AD00C);
  *(void *)(v6 + 16) = v9;
  *uint64_t v9 = v6;
  v9[1] = protocol witness for SupervisedEstimator.fitted<A>(to:eventHandler:) in conformance MLImageClassifier.Classifier;
  retaddr = v13;
  return MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:)(a1, a2, a3, a4, a5, a6);
}

uint64_t protocol witness for SupervisedEstimator.fitted<A, B>(to:validateOn:eventHandler:) in conformance MLSoundClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  int64_t v8 = (void *)swift_task_alloc(dword_3AD004);
  *(void *)(v6 + 16) = v8;
  void *v8 = v6;
  v8[1] = protocol witness for SupervisedEstimator.fitted<A, B>(to:validateOn:eventHandler:) in conformance MLImageClassifier.Classifier;
  retaddr = v13;
  return MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)(a1, a2, a3, a4, a5, a6, v14);
}

uint64_t protocol witness for SupervisedEstimator.encode(_:to:) in conformance MLSoundClassifier.Classifier(uint64_t a1, uint64_t a2)
{
  return MLSoundClassifier.Classifier.encode(_:to:)(a1, a2);
}

uint64_t protocol witness for SupervisedEstimator.decode(from:) in conformance MLSoundClassifier.Classifier(uint64_t a1)
{
  return MLSoundClassifier.Classifier.decode(from:)(a1, (void (*)(uint64_t, uint64_t))&LogisticRegressionClassifier.decode(from:), (void (*)(uint64_t, uint64_t))&FullyConnectedNetworkClassifier.decode(from:));
}

uint64_t base witness table accessor for SupervisedEstimator in MLSoundClassifier.Classifier()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier, type metadata accessor for MLSoundClassifier.Classifier, (uint64_t)&protocol conformance descriptor for MLSoundClassifier.Classifier);
}

uint64_t MLSoundClassifier.Classifier.update<A>(_:with:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v7[8] = v6;
  v7[7] = a6;
  v7[6] = a5;
  v7[5] = a4;
  v7[4] = a3;
  v7[3] = a2;
  v7[2] = a1;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v7[9] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v7[10] = v9;
  unint64_t v10 = (*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v7[11] = swift_task_alloc(v10);
  v7[12] = swift_task_alloc(v10);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  v7[13] = v11;
  uint64_t v12 = *(void *)(v11 - 8);
  v7[14] = v12;
  v7[15] = swift_task_alloc((*(void *)(v12 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v7[16] = v13;
  uint64_t v14 = *(void *)(v13 - 8);
  v7[17] = v14;
  unint64_t v15 = (*(void *)(v14 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v7[18] = swift_task_alloc(v15);
  v7[19] = swift_task_alloc(v15);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  v7[20] = v16;
  uint64_t v17 = *(void *)(v16 - 8);
  v7[21] = v17;
  v7[22] = swift_task_alloc((*(void *)(v17 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  v7[23] = v18;
  unint64_t v19 = (*(void *)(*(void *)(v18 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v7[24] = swift_task_alloc(v19);
  v7[25] = swift_task_alloc(v19);
  uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>, Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>));
  v7[26] = v20;
  v7[27] = swift_task_alloc((*(void *)(*(void *)(v20 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLSoundClassifier.Classifier.update<A>(_:with:eventHandler:), 0, 0);
}

uint64_t MLSoundClassifier.Classifier.update<A>(_:with:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v8 = *(void *)(v7 + 216);
  uint64_t v34 = *(void *)(v7 + 208);
  uint64_t v33 = *(void *)(v7 + 184);
  uint64_t v9 = *(void *)(v7 + 16);
  uint64_t v10 = *(void *)(v7 + 64);
  uint64_t v11 = v10 + *(int *)(type metadata accessor for MLSoundClassifier.Classifier(0) + 20);
  uint64_t v12 = *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  *(_DWORD *)(v7 + 288) = v12;
  uint64_t v13 = v12 + v9;
  uint64_t v14 = v8 + *(int *)(v34 + 48);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v11, v8, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v13, v14, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v8, v33);
  uint64_t v16 = *(void *)(v7 + 216);
  if (EnumCaseMultiPayload == 1)
  {
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v16, *(void *)(v7 + 192), &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    *(void *)(v7 + 256) = v17;
    if (swift_getEnumCaseMultiPayload(v14, v17) == 1)
    {
      uint64_t v18 = *(void *)(v7 + 96);
      uint64_t v19 = *(void *)(v7 + 72);
      uint64_t v20 = *(void *)(v7 + 80);
      (*(void (**)(void, void, void))(*(void *)(v7 + 112) + 32))(*(void *)(v7 + 120), *(void *)(v7 + 192), *(void *)(v7 + 104));
      uint64_t v21 = *(void (**)(uint64_t, uint64_t, uint64_t))(v20 + 32);
      *(void *)(v7 + 264) = v21;
      v21(v18, v14, v19);
      uint64_t v22 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifier.update<A>(_:with:eventHandler:)[1]);
      *(void *)(v7 + 272) = v22;
      *uint64_t v22 = v7;
      v22[1] = MLSoundClassifier.Classifier.update<A>(_:with:eventHandler:);
      return FullyConnectedNetworkClassifier.update<A>(_:with:eventHandler:)(*(void *)(v7 + 96), *(void *)(v7 + 24), *(void *)(v7 + 32), *(void *)(v7 + 40), *(void *)(v7 + 104), *(void *)(v7 + 48), *(void *)(v7 + 56));
    }
    uint64_t v25 = (void *)(v7 + 192);
    uint64_t v26 = 104;
    uint64_t v27 = 112;
    goto LABEL_7;
  }
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v16, *(void *)(v7 + 200), &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  *(void *)(v7 + 224) = v24;
  if (swift_getEnumCaseMultiPayload(v14, v24) == 1)
  {
    uint64_t v25 = (void *)(v7 + 200);
    uint64_t v26 = 160;
    uint64_t v27 = 168;
LABEL_7:
    (*(void (**)(void, void))(*(void *)(v7 + v27) + 8))(*v25, *(void *)(v7 + v26));
    return _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000002FLL, "Classifier.Classifier.swift" + 0x8000000000000000, "CreateML/MLSoundClassifier.Classifier.swift", 43, 2, 135, 0);
  }
  uint64_t v28 = *(void *)(v7 + 152);
  uint64_t v29 = *(void *)(v7 + 128);
  uint64_t v30 = *(void *)(v7 + 136);
  (*(void (**)(void, void, void))(*(void *)(v7 + 168) + 32))(*(void *)(v7 + 176), *(void *)(v7 + 200), *(void *)(v7 + 160));
  uint64_t v31 = *(void (**)(uint64_t, uint64_t, uint64_t))(v30 + 32);
  *(void *)(v7 + 232) = v31;
  v31(v28, v14, v29);
  uint64_t v32 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifier.update<A>(_:with:eventHandler:)[1]);
  *(void *)(v7 + 240) = v32;
  *uint64_t v32 = v7;
  v32[1] = MLSoundClassifier.Classifier.update<A>(_:with:eventHandler:);
  return LogisticRegressionClassifier.update<A>(_:with:eventHandler:)(*(void *)(v7 + 152), *(void *)(v7 + 24), *(void *)(v7 + 32), *(void *)(v7 + 40), *(void *)(v7 + 160), *(void *)(v7 + 48), *(void *)(v7 + 56));
}

uint64_t MLSoundClassifier.Classifier.update<A>(_:with:eventHandler:)()
{
  uint64_t v2 = *(void *)(*(void *)v1 + 240);
  *(void *)(*(void *)v1 + 248) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLImageClassifier.Classifier.update<A>(_:with:eventHandler:);
  }
  else {
    uint64_t v3 = MLSoundClassifier.Classifier.update<A>(_:with:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  void (*v14)(uint64_t, uint64_t, uint64_t);

  uint64_t v14 = *(void (**)(uint64_t, uint64_t, uint64_t))(v0 + 232);
  uint64_t v12 = *(void *)(v0 + 224);
  uint64_t v10 = *(void *)(v0 + 176);
  uint64_t v1 = *(void *)(v0 + 152);
  uint64_t v2 = *(void *)(v0 + 144);
  uint64_t v3 = *(void *)(v0 + 128);
  uint64_t v13 = *(void *)(v0 + 216);
  uint64_t v9 = *(void *)(v0 + 200);
  uint64_t v4 = *(void *)(v0 + 16) + *(int *)(v0 + 288);
  uint64_t v11 = *(void *)(v0 + 192);
  uint64_t v8 = *(void *)(v0 + 120);
  uint64_t v6 = *(void *)(v0 + 88);
  uint64_t v7 = *(void *)(v0 + 96);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 168) + 8))(v10, *(void *)(v0 + 160));
  v14(v2, v1, v3);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v4, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  v14(v4, v2, v3);
  swift_storeEnumTagMultiPayload(v4, v12, 0);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v13, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  swift_task_dealloc(v13);
  swift_task_dealloc(v9);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 272);
  *(void *)(*(void *)v1 + 280) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLImageClassifier.Classifier.update<A>(_:with:eventHandler:);
  }
  else {
    uint64_t v3 = MLSoundClassifier.Classifier.update<A>(_:with:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  void (*v14)(uint64_t, uint64_t, uint64_t);

  uint64_t v14 = *(void (**)(uint64_t, uint64_t, uint64_t))(v0 + 264);
  uint64_t v12 = *(void *)(v0 + 256);
  uint64_t v6 = *(void *)(v0 + 120);
  uint64_t v1 = *(void *)(v0 + 96);
  uint64_t v2 = *(void *)(v0 + 72);
  uint64_t v3 = *(void *)(v0 + 88);
  uint64_t v13 = *(void *)(v0 + 216);
  uint64_t v10 = *(void *)(v0 + 200);
  uint64_t v4 = *(void *)(v0 + 16) + *(int *)(v0 + 288);
  uint64_t v11 = *(void *)(v0 + 192);
  uint64_t v9 = *(void *)(v0 + 176);
  uint64_t v8 = *(void *)(v0 + 152);
  uint64_t v7 = *(void *)(v0 + 144);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 112) + 8))(v6, *(void *)(v0 + 104));
  v14(v3, v1, v2);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v4, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  v14(v4, v3, v2);
  swift_storeEnumTagMultiPayload(v4, v12, 1);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v13, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  swift_task_dealloc(v13);
  swift_task_dealloc(v10);
  swift_task_dealloc(v11);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  swift_task_dealloc(v1);
  swift_task_dealloc(v3);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLSoundClassifier.Classifier.encodeWithOptimizer(_:to:)(uint64_t a1, uint64_t a2)
{
  uint64_t v49 = v2;
  uint64_t v4 = v3;
  uint64_t v50 = a2;
  uint64_t v42 = a1;
  uint64_t v52 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  uint64_t v51 = *(void *)(v52 - 8);
  int64_t v5 = *(void *)(v51 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v44 = &v42;
  uint64_t v55 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  uint64_t v56 = *(void *)(v55 - 8);
  int64_t v8 = *(void *)(v56 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v45 = &v42;
  uint64_t v54 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  uint64_t v53 = *(void *)(v54 - 8);
  int64_t v11 = *(void *)(v53 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v46 = &v42;
  uint64_t v57 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  uint64_t v58 = *(void *)(v57 - 8);
  int64_t v14 = *(void *)(v58 + 64);
  unint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v59 = &v42;
  uint64_t v43 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  int64_t v17 = *(void *)(*(void *)(v43 - 8) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v47 = &v42;
  uint64_t v20 = alloca(v17);
  uint64_t v21 = alloca(v17);
  uint64_t v48 = &v42;
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>, Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>));
  int64_t v23 = *(void *)(*(void *)(v22 - 8) + 64);
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  uint64_t v26 = v4 + *(int *)(type metadata accessor for MLSoundClassifier.Classifier(0) + 20);
  uint64_t v27 = v42 + *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  uint64_t v28 = (char *)&v42 + *(int *)(v22 + 48);
  uint64_t v29 = v26;
  uint64_t v30 = &v42;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v29, (uint64_t)&v42, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v27, (uint64_t)v28, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload(&v42, v43) != 1)
  {
    uint64_t v36 = (uint64_t)v48;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v42, (uint64_t)v48, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    if (swift_getEnumCaseMultiPayload(v28, v37) != 1)
    {
      uint64_t v38 = v57;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v58 + 32))(v59, v36, v57);
      uint64_t v39 = v46;
      (*(void (**)(uint64_t *, char *, uint64_t))(v53 + 32))(v46, v28, v54);
      LogisticRegressionClassifier.encodeWithOptimizer(_:to:)(v39, v50, v38);
      (*(void (**)(uint64_t *, uint64_t))(v53 + 8))(v39, v54);
      (*(void (**)(uint64_t *, uint64_t))(v58 + 8))(v59, v38);
      return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v30, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
    }
    uint64_t v41 = v36;
LABEL_9:
    (*(void (**)(uint64_t, uint64_t))(v58 + 8))(v41, v57);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000002FLL, "Classifier.Classifier.swift" + 0x8000000000000000, "CreateML/MLSoundClassifier.Classifier.swift", 43, 2, 146, 0);
    BUG();
  }
  uint64_t v59 = &v42;
  uint64_t v31 = (uint64_t)v47;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v42, (uint64_t)v47, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload(v28, v32) != 1)
  {
    uint64_t v58 = v56;
    uint64_t v57 = v55;
    uint64_t v41 = v31;
    goto LABEL_9;
  }
  uint64_t v33 = v45;
  uint64_t v34 = v55;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v56 + 32))(v45, v31, v55);
  uint64_t v35 = v44;
  (*(void (**)(uint64_t *, char *, uint64_t))(v51 + 32))(v44, v28, v52);
  FullyConnectedNetworkClassifier.encodeWithOptimizer(_:to:)(v35, v50, v34);
  (*(void (**)(uint64_t *, uint64_t))(v51 + 8))(v35, v52);
  (*(void (**)(uint64_t *, uint64_t))(v56 + 8))(v33, v34);
  uint64_t v30 = v59;
  return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v30, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
}

uint64_t MLSoundClassifier.Classifier.decode(from:)(uint64_t a1, void (*a2)(uint64_t, uint64_t), void (*a3)(uint64_t, uint64_t))
{
  uint64_t v50 = a3;
  uint64_t v51 = a2;
  uint64_t v62 = v4;
  uint64_t v63 = a1;
  uint64_t v55 = v3;
  uint64_t v57 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  uint64_t v56 = *(void *)(v57 - 8);
  int64_t v6 = *(void *)(v56 + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v52 = &v50;
  uint64_t v67 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  uint64_t v66 = *(void *)(v67 - 8);
  int64_t v9 = *(void *)(v66 + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v68 = &v50;
  uint64_t v59 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  uint64_t v60 = *(void *)(v59 - 8);
  int64_t v12 = *(void *)(v60 + 64);
  uint64_t v13 = alloca(v12);
  int64_t v14 = alloca(v12);
  uint64_t v64 = &v50;
  uint64_t v65 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int64_t v15 = *(void *)(*(void *)(v65 - 8) + 64);
  uint64_t v16 = alloca(v15);
  int64_t v17 = alloca(v15);
  uint64_t v61 = &v50;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  uint64_t v58 = &v50;
  int64_t v20 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.ModelParameters(0) - 8) + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v53 = &v50;
  int64_t v23 = alloca(v20);
  uint64_t v24 = alloca(v20);
  uint64_t v54 = &v50;
  uint64_t v70 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  uint64_t v69 = *(void *)(v70 - 8);
  int64_t v25 = *(void *)(v69 + 64);
  uint64_t v26 = alloca(v25);
  uint64_t v27 = alloca(v25);
  uint64_t v71 = &v50;
  uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  int64_t v29 = *(void *)(*(void *)(v28 - 8) + 64);
  uint64_t v30 = alloca(v29);
  uint64_t v31 = alloca(v29);
  uint64_t v32 = type metadata accessor for MLSoundClassifier.Classifier(0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v5 + *(int *)(v32 + 20), (uint64_t)&v50, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  if (swift_getEnumCaseMultiPayload(&v50, v28) == 1)
  {
    uint64_t v33 = v67;
    (*(void (**)(void (**)(uint64_t, uint64_t), void (**)(uint64_t, uint64_t), uint64_t))(v66 + 32))(v68, &v50, v67);
    uint64_t v34 = (uint64_t)v53;
    outlined init with copy of MLSoundClassifier.ModelParameters(v5, (uint64_t)v53);
    uint64_t v35 = v52;
    uint64_t v36 = v62;
    v50(v63, v33);
    if (v36)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v34, type metadata accessor for MLSoundClassifier.ModelParameters);
      uint64_t v37 = v68;
      uint64_t v38 = v67;
      uint64_t v39 = v66;
      return (*(uint64_t (**)(void, uint64_t))(v39 + 8))(v37, v38);
    }
    (*(void (**)(void, uint64_t))(v66 + 8))(v68, v67);
    uint64_t v45 = v34;
    uint64_t v46 = (uint64_t)v61;
    (*(void (**)(void (**)(uint64_t, uint64_t), void (**)(uint64_t, uint64_t), uint64_t))(v56 + 32))(v61, v35, v57);
    swift_storeEnumTagMultiPayload(v46, v65, 1);
    uint64_t v43 = v45;
  }
  else
  {
    uint64_t v40 = v70;
    (*(void (**)(void (**)(uint64_t, uint64_t), void (**)(uint64_t, uint64_t), uint64_t))(v69 + 32))(v71, &v50, v70);
    uint64_t v41 = (uint64_t)v54;
    outlined init with copy of MLSoundClassifier.ModelParameters(v5, (uint64_t)v54);
    uint64_t v42 = v62;
    v51(v63, v40);
    uint64_t v43 = v41;
    if (v42)
    {
      outlined destroy of MLActivityClassifier.ModelParameters(v41, type metadata accessor for MLSoundClassifier.ModelParameters);
      uint64_t v37 = v71;
      uint64_t v38 = v70;
      uint64_t v39 = v69;
      return (*(uint64_t (**)(void, uint64_t))(v39 + 8))(v37, v38);
    }
    (*(void (**)(void, uint64_t))(v69 + 8))(v71, v70);
    uint64_t v46 = (uint64_t)v58;
    (*(void (**)(void (**)(uint64_t, uint64_t), void (**)(uint64_t, uint64_t), uint64_t))(v60 + 32))(v58, v64, v59);
    swift_storeEnumTagMultiPayload(v46, v65, 0);
  }
  uint64_t v47 = v43;
  uint64_t v48 = v55;
  outlined init with take of MLSoundClassifier.ModelParameters(v47, v55);
  uint64_t v49 = type metadata accessor for MLSoundClassifier.Model(0);
  return outlined init with take of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(v46, v48 + *(int *)(v49 + 20));
}

uint64_t protocol witness for UpdatableSupervisedEstimator.makeTransformer() in conformance MLSoundClassifier.Classifier()
{
  return MLSoundClassifier.Classifier.makeTransformer()();
}

uint64_t protocol witness for UpdatableSupervisedEstimator.update<A>(_:with:eventHandler:) in conformance MLSoundClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  int64_t v9 = (void *)swift_task_alloc(dword_3ACFFC);
  *(void *)(v6 + 16) = v9;
  *int64_t v9 = v6;
  v9[1] = protocol witness for UpdatableSupervisedEstimator.update<A>(_:with:eventHandler:) in conformance MLSoundClassifier.Classifier;
  retaddr = v13;
  return MLSoundClassifier.Classifier.update<A>(_:with:eventHandler:)(a1, a2, a3, a4, a5, a6);
}

uint64_t protocol witness for UpdatableSupervisedEstimator.encodeWithOptimizer(_:to:) in conformance MLSoundClassifier.Classifier(uint64_t a1, uint64_t a2)
{
  return MLSoundClassifier.Classifier.encodeWithOptimizer(_:to:)(a1, a2);
}

uint64_t protocol witness for UpdatableSupervisedEstimator.decodeWithOptimizer(from:) in conformance MLSoundClassifier.Classifier(uint64_t a1)
{
  return MLSoundClassifier.Classifier.decode(from:)(a1, (void (*)(uint64_t, uint64_t))&LogisticRegressionClassifier.decodeWithOptimizer(from:), (void (*)(uint64_t, uint64_t))&FullyConnectedNetworkClassifier.decodeWithOptimizer(from:));
}

uint64_t outlined init with copy of MLSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined init with take of MLSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t outlined init with take of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t lazy protocol witness table accessor for type Float and conformance Float()
{
  uint64_t result = lazy protocol witness table cache variable for type Float and conformance Float;
  if (!lazy protocol witness table cache variable for type Float and conformance Float)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for Float, &type metadata for Float);
    lazy protocol witness table cache variable for type Float and conformance Float = result;
  }
  return result;
}

uint64_t protocol witness for UpdatableSupervisedEstimator.update<A>(_:with:eventHandler:) in conformance MLSoundClassifier.Classifier()
{
  return protocol witness for SupervisedEstimator.fitted<A, B>(to:validateOn:eventHandler:) in conformance MLImageClassifier.Classifier();
}

void *MLHandActionClassifier.VideoAugmentationOptions.init(rawValue:)(uint64_t a1)
{
  *uint64_t result = a1;
  return result;
}

uint64_t MLHandActionClassifier.VideoAugmentationOptions.rawValue.getter()
{
  return *(void *)v0;
}

void *static MLHandActionClassifier.VideoAugmentationOptions.horizontallyFlip.getter()
{
  *uint64_t result = 1;
  return result;
}

void *static MLHandActionClassifier.VideoAugmentationOptions.rotate.getter()
{
  *uint64_t result = 2;
  return result;
}

void *static MLHandActionClassifier.VideoAugmentationOptions.translate.getter()
{
  *uint64_t result = 4;
  return result;
}

void *static MLHandActionClassifier.VideoAugmentationOptions.scale.getter()
{
  *uint64_t result = 8;
  return result;
}

void *static MLHandActionClassifier.VideoAugmentationOptions.interpolateFrames.getter()
{
  *uint64_t result = 16;
  return result;
}

void *static MLHandActionClassifier.VideoAugmentationOptions.dropFrames.getter()
{
  *uint64_t result = 32;
  return result;
}

uint64_t base witness table accessor for RawRepresentable in MLHandActionClassifier.VideoAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions();
}

uint64_t lazy protocol witness table accessor for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions()
{
  uint64_t result = lazy protocol witness table cache variable for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLHandActionClassifier.VideoAugmentationOptions, &type metadata for MLHandActionClassifier.VideoAugmentationOptions);
    lazy protocol witness table cache variable for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLHandActionClassifier.VideoAugmentationOptions, &type metadata for MLHandActionClassifier.VideoAugmentationOptions);
    lazy protocol witness table cache variable for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLHandActionClassifier.VideoAugmentationOptions, &type metadata for MLHandActionClassifier.VideoAugmentationOptions);
    lazy protocol witness table cache variable for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLHandActionClassifier.VideoAugmentationOptions, &type metadata for MLHandActionClassifier.VideoAugmentationOptions);
    lazy protocol witness table cache variable for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions = result;
  }
  return result;
}

uint64_t base witness table accessor for SetAlgebra in MLHandActionClassifier.VideoAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions();
}

void *protocol witness for OptionSet.init(rawValue:) in conformance MLHandActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
  return MLHandActionClassifier.VideoAugmentationOptions.init(rawValue:)(*a1);
}

uint64_t protocol witness for Decodable.init(from:) in conformance MLHandActionClassifier.VideoAugmentationOptions(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = lazy protocol witness table accessor for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions();
  return RawRepresentable<>.init(from:)(a1, a2, a3, v3);
}

uint64_t protocol witness for Encodable.encode(to:) in conformance MLHandActionClassifier.VideoAugmentationOptions(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = lazy protocol witness table accessor for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions();
  return RawRepresentable<>.encode(to:)(a1, a2, a3, v4);
}

uint64_t base witness table accessor for Equatable in MLHandActionClassifier.VideoAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions();
}

uint64_t base witness table accessor for ExpressibleByArrayLiteral in MLHandActionClassifier.VideoAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLHandActionClassifier.VideoAugmentationOptions and conformance MLHandActionClassifier.VideoAugmentationOptions();
}

uint64_t *protocol witness for SetAlgebra.intersection(_:) in conformance MLHandActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet.intersection(_:)(*a1, *v1);
}

void *protocol witness for RawRepresentable.init(rawValue:) in conformance MLHandActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
  uint64_t v2 = v1;
  uint64_t result = MLHandActionClassifier.VideoAugmentationOptions.init(rawValue:)(*a1);
  *(unsigned char *)(v2 + 8) = 0;
  return result;
}

uint64_t protocol witness for RawRepresentable.rawValue.getter in conformance MLHandActionClassifier.VideoAugmentationOptions(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t result = MLHandActionClassifier.VideoAugmentationOptions.rawValue.getter(a1);
  uint64_t *v2 = result;
  return result;
}

ValueMetadata *type metadata accessor for MLHandActionClassifier.VideoAugmentationOptions()
{
  return &type metadata for MLHandActionClassifier.VideoAugmentationOptions;
}

uint64_t MLHandActionClassifier.DataSource.videosWithAnnotations()(__m128 a1)
{
  *(void *)&long long v165 = v2;
  v174._countAndFlagsBits = v3;
  v163 = v1;
  v169 = (void *)type metadata accessor for DataFrame(0);
  v174._char object = (void *)*(v169 - 1);
  int64_t v4 = *((void *)v174._object + 8);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  v166 = (uint64_t *)&v136;
  uint64_t v7 = alloca(v4);
  int64_t v8 = alloca(v4);
  uint64_t named = (uint64_t)&v136;
  int64_t v9 = (void *)type metadata accessor for UTType(0);
  uint64_t v10 = *(v9 - 1);
  int64_t v11 = *(void *)(v10 + 64);
  int64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  v168._char object = &v136;
  int64_t v14 = alloca(v11);
  int64_t v15 = alloca(v11);
  *(void *)v167 = &v136;
  uint64_t v173 = type metadata accessor for URL(0);
  *(void *)v177 = *(void *)(v173 - 8);
  int64_t v16 = *(void *)(*(void *)v177 + 64);
  int64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  v162 = (uint64_t *)&v136;
  uint64_t v19 = alloca(v16);
  int64_t v20 = alloca(v16);
  v161 = (uint64_t *)&v136;
  uint64_t v21 = alloca(v16);
  uint64_t v22 = alloca(v16);
  v170 = (uint64_t *)&v136;
  int64_t v23 = alloca(v16);
  uint64_t v24 = alloca(v16);
  *(void *)v171 = &v136;
  int64_t v25 = alloca(v16);
  uint64_t v26 = alloca(v16);
  v168._countAndFlagsBits = (uint64_t)&v136;
  uint64_t v27 = alloca(v16);
  uint64_t v28 = alloca(v16);
  v172._countAndFlagsBits = (uint64_t)&v136;
  uint64_t v29 = type metadata accessor for MLHandActionClassifier.DataSource(0);
  int64_t v30 = *(void *)(*(void *)(v29 - 8) + 64);
  uint64_t v31 = alloca(v30);
  uint64_t v32 = alloca(v30);
  outlined init with copy of MLHandActionClassifier.DataSource(v174._countAndFlagsBits, (uint64_t)&v136);
  switch(swift_getEnumCaseMultiPayload(&v136, v29))
  {
    case 0u:
      uint64_t v33 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      uint64_t v34 = (uint64_t **)((char *)&v136 + v33[12]);
      uint64_t v35 = v33[16];
      v168._char object = *(uint64_t **)((char *)&v136 + v35);
      v174._countAndFlagsBits = *(uint64_t *)((char *)&v136 + v35 + 8);
      uint64_t v36 = v33[20];
      *(void *)v167 = *(uint64_t **)((char *)&v136 + v36);
      v174._char object = *(uint64_t **)((char *)&v136 + v36 + 8);
      uint64_t v37 = v33[24];
      v172._countAndFlagsBits = *(uint64_t *)((char *)&v136 + v37);
      uint64_t named = *(uint64_t *)((char *)&v136 + v37 + 8);
      uint64_t v38 = v33[28];
      v168._countAndFlagsBits = *(uint64_t *)((char *)&v136 + v38);
      v169 = *(uint64_t **)((char *)&v136 + v38 + 8);
      uint64_t v39 = *(void (**)(uint64_t *, uint64_t **, uint64_t))(*(void *)v177 + 32);
      uint64_t v40 = v173;
      v39(*(uint64_t **)v171, &v136, v173);
      uint64_t v41 = (uint64_t)v170;
      v39(v170, v34, v40);
      uint64_t v42 = v161;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(*(void *)v177 + 16))(v161, v41, v40);
      LOBYTE(v137) = 1;
      *(_DWORD *)((char *)&v137 + 1) = *(_DWORD *)v155;
      DWORD1(v137) = *(_DWORD *)&v155[3];
      *((void *)&v137 + 1) = 44;
      unint64_t v138 = 0xE100000000000000;
      uint64_t v139 = 0;
      LOBYTE(v172._object) = 1;
      unint64_t v140 = 0xE000000000000000;
      v141 = &stru_20 + 60;
      v142 = (void *)0xE100000000000000;
      LOBYTE(v143) = 1;
      *(_DWORD *)((char *)&v143 + 1) = *(_DWORD *)v156;
      HIDWORD(v143) = *(_DWORD *)&v156[3];
      uint64_t v144 = 34;
      unint64_t v145 = 0xE100000000000000;
      char v146 = 1;
      *(_DWORD *)&v147[3] = *(_DWORD *)&v157[3];
      *(_DWORD *)v147 = *(_DWORD *)v157;
      v148 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
      uint64_t v149 = 10;
      unint64_t v150 = 0xE100000000000000;
      long long v151 = 0;
      char v152 = 1;
      *(_DWORD *)v153 = *(_DWORD *)v158;
      *(_DWORD *)&v153[3] = *(_DWORD *)&v158[3];
      uint64_t v154 = 0;
      uint64_t v43 = v165;
      MLDataTable.init(contentsOf:options:)(v42, &v137);
      if (v43)
      {
        uint64_t v44 = *(void (**)(uint64_t *, uint64_t))(*(void *)v177 + 8);
        v44(v170, v40);
        swift_bridgeObjectRelease(v174._object);
        swift_bridgeObjectRelease(v174._countAndFlagsBits);
        swift_bridgeObjectRelease(named);
        swift_bridgeObjectRelease((_BYTE)v169);
        return ((uint64_t (*)(void, uint64_t))v44)(*(void *)v171, v40);
      }
      *(void *)&long long v165 = 0;
      *(void *)v175 = v159;
      LOBYTE(v176) = v160;
      v78._countAndFlagsBits = (uint64_t)v168._object;
      countAndFlagsBits = (void *)v174._countAndFlagsBits;
      v78._char object = (void *)v174._countAndFlagsBits;
      MLDataTable.subscript.getter(v78);
      uint64_t v80 = v137;
      char v81 = BYTE8(v137);
      if (BYTE8(v137)
        || (outlined copy of Result<_DataTable, Error>(v137, 0),
            v166 = (uint64_t *)v80,
            _UntypedColumn.type.getter(),
            uint64_t v80 = (uint64_t)v166,
            outlined consume of Result<_DataTable, Error>((uint64_t)v166, 0),
            (_BYTE)v159 != 2))
      {
        outlined consume of Result<_DataTable, Error>(v80, v81);
        swift_bridgeObjectRelease(v174._object);
        swift_bridgeObjectRelease(named);
        swift_bridgeObjectRelease((_BYTE)v169);
        *(void *)&long long v137 = 0;
        *((void *)&v137 + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(26);
        swift_bridgeObjectRelease(BYTE8(v137));
        *(void *)&long long v137 = 0x206E6D756C6F43;
        *((void *)&v137 + 1) = 0xE700000000000000;
        v119._countAndFlagsBits = (uint64_t)v168._object;
        v119._char object = countAndFlagsBits;
        String.append(_:)(v119);
        swift_bridgeObjectRelease((_BYTE)countAndFlagsBits);
        v119._countAndFlagsBits = 0xD000000000000011;
        String.append(_:)(v119);
        long long v165 = v137;
        v119._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v119._object, 0, 0);
        *(_OWORD *)uint64_t v120 = v165;
        *(_OWORD *)(v120 + 16) = 0;
        *(_OWORD *)(v120 + 32) = 0;
        *(unsigned char *)(v120 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v119._object, v120, v121, v122, v123);
        uint64_t v111 = *(void (**)(uint64_t *, uint64_t))(*(void *)v177 + 8);
        uint64_t v113 = (uint64_t)v170;
        uint64_t v112 = v173;
        goto LABEL_30;
      }
      outlined copy of Result<_DataTable, Error>(v80, 0);
      _UntypedColumn.valueAtIndex(index:)(0, 0.0);
      unint64_t v83 = *((void *)&v137 + 1);
      uint64_t v82 = v137;
      if ((_BYTE)v138 != 2)
      {
        outlined consume of MLDataValue((void *)v137, *((void **)&v137 + 1), v138);
        uint64_t v82 = 0;
        unint64_t v83 = 0xE000000000000000;
      }
      outlined consume of Result<_DataTable, Error>((uint64_t)v166, 0);
      *(void *)&long long v137 = v82;
      *((void *)&v137 + 1) = v83;
      uint64_t v84 = String.init<A>(_:)(&v137, &type metadata for String, &protocol witness table for String, &protocol witness table for String);
      char v86 = v85;
      URL.init(fileURLWithPath:)(v84, v85);
      swift_bridgeObjectRelease(v86);
      uint64_t v87 = objc_opt_self(NSFileManager);
      id v88 = [v87 defaultManager];
      id v89 = v88;
      URL.path.getter(v88);
      char v91 = v90;
      NSString v92 = String._bridgeToObjectiveC()();
      swift_bridgeObjectRelease(v91);
      unsigned __int8 v93 = [v89 fileExistsAtPath:v92];

      if (!v93)
      {
        uint64_t v94 = (uint64_t)v166;
        outlined copy of Result<_DataTable, Error>((uint64_t)v166, 0);
        uint64_t v95 = specialized Array<A>.init(_:)(v94, 0, 0.0);
        uint64_t v96 = alloca(24);
        uint64_t v97 = alloca(32);
        *((void *)&v137 + 1) = *(void *)v171;
        uint64_t v98 = v165;
        BOOL v99 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_SSs5NeverOTg5((void (*)(void *))partial apply for closure #1 in static _VideoUtilities.getVideoURLsAndAnnotations(from:), (uint64_t)&v136, (uint64_t)v95);
        *(void *)&long long v165 = v98;
        swift_bridgeObjectRelease((_BYTE)v95);
        v161 = (uint64_t *)&v136;
        *(void *)&long long v137 = v99;
        uint64_t v100 = alloca(24);
        uint64_t v101 = alloca(24);
        *((void *)&v137 + 1) = &v137;
        uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
        char v104 = v103;
        swift_bridgeObjectRelease(v137);
        uint64_t v105 = v174._countAndFlagsBits;
        swift_bridgeObjectRetain(v174._countAndFlagsBits);
        MLDataTable.willMutate()();
        *(void *)&long long v137 = ML14_UntypedColumnC_s5Error_pTgm5;
        BYTE8(v137) = v104 & 1;
        MLDataTable.setColumnImpl(newColumn:named:)((uint64_t)&v137, (uint64_t)v168._object, v105);
        swift_bridgeObjectRelease(v105);
        outlined consume of Result<_DataTable, Error>(ML14_UntypedColumnC_s5Error_pTgm5, v104);
        if (!(_BYTE)v176)
        {
          uint64_t v106 = *(void *)v175;
          outlined copy of Result<_DataTable, Error>(*(uint64_t *)v175, 0);
          _DataTable.columnNamesDidChange()();
          outlined consume of Result<_DataTable, Error>(v106, 0);
        }
      }
      uint64_t v107 = v165;
      char v108 = v174._countAndFlagsBits;
      char v109 = (char)v169;
      v134._char object = v169;
      v134._countAndFlagsBits = v168._countAndFlagsBits;
      char v110 = named;
      static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v175, (uint64_t)v168._object, (void *)v174._countAndFlagsBits, *(void **)v167, v174._object, v172._countAndFlagsBits, 0.0, (void *)named, v134);
      if (v107)
      {
        swift_bridgeObjectRelease(v108);
        swift_bridgeObjectRelease(v174._object);
        swift_bridgeObjectRelease(v110);
        swift_bridgeObjectRelease(v109);
        outlined consume of Result<_DataTable, Error>((uint64_t)v166, 0);
        uint64_t v111 = *(void (**)(uint64_t *, uint64_t))(*(void *)v177 + 8);
        uint64_t v112 = v173;
        v111(v162, v173);
        uint64_t v113 = (uint64_t)v170;
LABEL_30:
        v111((uint64_t *)v113, v112);
        v111(*(uint64_t **)v171, v112);
        return outlined consume of Result<_DataTable, Error>(*(uint64_t *)v175, v176);
      }
      swift_bridgeObjectRelease(v108);
      swift_bridgeObjectRelease(v174._object);
      swift_bridgeObjectRelease(v110);
      swift_bridgeObjectRelease(v109);
      outlined consume of Result<_DataTable, Error>((uint64_t)v166, 0);
      uint64_t v129 = *(void (**)(uint64_t *, uint64_t))(*(void *)v177 + 8);
      uint64_t v130 = v173;
      v129(v162, v173);
      v129(v170, v130);
      v129(*(uint64_t **)v171, v130);
LABEL_34:
      v131 = v163;
      uint64_t result = *(void *)v175;
      char v132 = v176;
      void *v163 = *(void *)v175;
      *((unsigned char *)v131 + 8) = v132;
      return result;
    case 1u:
      v174._char object = v9;
      v174._countAndFlagsBits = v10;
      uint64_t v46 = v168._countAndFlagsBits;
      uint64_t v47 = v173;
      uint64_t v48 = *(void *)v177;
      (*(void (**)(uint64_t, uint64_t **, uint64_t))(*(void *)v177 + 32))(v168._countAndFlagsBits, &v136, v173);
      char object = v168._object;
      static UTType.movie.getter();
      uint64_t v50 = v165;
      uint64_t v51 = static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)(v46, (uint64_t)object);
      if (v50)
      {
        (*(void (**)(void *, void *))(v174._countAndFlagsBits + 8))(v168._object, v174._object);
        uint64_t v52 = v168._countAndFlagsBits;
        return (*(uint64_t (**)(uint64_t, uint64_t))(v48 + 8))(v52, v47);
      }
      uint64_t v114 = (uint64_t)v51;
      (*(void (**)(void *, void *))(v174._countAndFlagsBits + 8))(v168._object, v174._object);
      static _VideoUtilities.generateVideoTable(_:)(v114);
      swift_bridgeObjectRelease(v114);
      uint64_t v126 = v137;
      char v127 = BYTE8(v137);
      *(void *)v175 = v137;
      LOBYTE(v176) = BYTE8(v137) & 1;
      BYTE8(v137) &= 1u;
      outlined copy of Result<_DataTable, Error>(v137, v127);
      static _VideoUtilities.validateVideoInput(trainingData:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)&v137, 0x7461506F65646976, 0xE900000000000068, 0x6C6562616CLL, 0xE500000000000000, 0, 0.0, 0, 0, 0);
      outlined consume of Result<_DataTable, Error>(v126, v127);
      uint64_t v128 = v168._countAndFlagsBits;
      goto LABEL_32;
    case 2u:
      v174._char object = v9;
      v174._countAndFlagsBits = v10;
      uint64_t v53 = v172._countAndFlagsBits;
      uint64_t v47 = v173;
      uint64_t v48 = *(void *)v177;
      (*(void (**)(uint64_t, uint64_t **, uint64_t))(*(void *)v177 + 32))(v172._countAndFlagsBits, &v136, v173);
      uint64_t v54 = *(void **)v167;
      static UTType.movie.getter();
      uint64_t v55 = v165;
      uint64_t v56 = static _FileUtilities.collectFilesLabeledByFileName(at:type:)(v53, (uint64_t)v54);
      if (v55)
      {
        (*(void (**)(void, void *))(v174._countAndFlagsBits + 8))(*(void *)v167, v174._object);
        uint64_t v52 = v172._countAndFlagsBits;
        return (*(uint64_t (**)(uint64_t, uint64_t))(v48 + 8))(v52, v47);
      }
      uint64_t v115 = v56;
      (*(void (**)(void, void *))(v174._countAndFlagsBits + 8))(*(void *)v167, v174._object);
      static _VideoUtilities.generateVideoTable(_:)(v115);
      swift_bridgeObjectRelease(v115);
      uint64_t v124 = v137;
      char v125 = BYTE8(v137);
      *(void *)v175 = v137;
      LOBYTE(v176) = BYTE8(v137) & 1;
      BYTE8(v137) &= 1u;
      outlined copy of Result<_DataTable, Error>(v137, v125);
      static _VideoUtilities.validateVideoInput(trainingData:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)&v137, 0x7461506F65646976, 0xE900000000000068, 0x6C6562616CLL, 0xE500000000000000, 0, 0.0, 0, 0, 0);
      outlined consume of Result<_DataTable, Error>(v124, v125);
      uint64_t v128 = v172._countAndFlagsBits;
LABEL_32:
      (*(void (**)(uint64_t, uint64_t))(*(void *)v177 + 8))(v128, v173);
      goto LABEL_34;
    case 3u:
      char v57 = v138;
      char v58 = v140;
      char v59 = (char)v142;
      outlined consume of Result<_DataTable, Error>((uint64_t)v136, v137);
      swift_bridgeObjectRelease(v59);
      swift_bridgeObjectRelease(v58);
      swift_bridgeObjectRelease(v57);
      return MLDataTable.init()();
    case 4u:
      *(void *)v177 = *((void *)&v137 + 1);
      uint64_t v60 = (void *)v138;
      uint64_t v173 = v139;
      uint64_t v61 = (void *)v140;
      v174._char object = v141;
      v169 = v142;
      v174._countAndFlagsBits = v143;
      uint64_t v62 = (void *)v144;
      *(void *)v175 = v136;
      LOBYTE(v176) = v137 & 1;
      v170 = v136;
      v171[0] = v137;
      outlined copy of Result<_DataTable, Error>((uint64_t)v136, v137);
      uint64_t v63 = *(void *)v177;
      *(void *)v177 = v61;
      uint64_t v64 = v61;
      uint64_t v65 = v165;
      v133._char object = v62;
      v133._countAndFlagsBits = v174._countAndFlagsBits;
      char v66 = (char)v169;
      static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v175, v63, v60, (void *)v173, v64, (uint64_t)v174._object, *(double *)a1.i64, v169, v133);
      if (!v65)
      {
        swift_bridgeObjectRelease((_BYTE)v60);
        swift_bridgeObjectRelease(v177[0]);
        swift_bridgeObjectRelease((_BYTE)v62);
        swift_bridgeObjectRelease(v66);
        outlined consume of Result<_DataTable, Error>((uint64_t)v170, v171[0]);
        goto LABEL_34;
      }
      swift_bridgeObjectRelease((_BYTE)v60);
      swift_bridgeObjectRelease(v177[0]);
      swift_bridgeObjectRelease((_BYTE)v62);
      swift_bridgeObjectRelease(v66);
      outlined consume of Result<_DataTable, Error>((uint64_t)v170, v171[0]);
      return outlined consume of Result<_DataTable, Error>(*(uint64_t *)v175, v176);
    case 5u:
      uint64_t v67 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      swift_bridgeObjectRelease(*(uint64_t **)((char *)&v136 + v67[12] + 8));
      swift_bridgeObjectRelease(*(uint64_t **)((char *)&v136 + v67[16] + 8));
      swift_bridgeObjectRelease(*(uint64_t **)((char *)&v136 + v67[20] + 8));
      MLDataTable.init()();
      return (*((uint64_t (**)(uint64_t **, void *))v174._object + 1))(&v136, v169);
    case 6u:
      uint64_t v68 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      uint64_t v69 = v68[12];
      *(void *)v171 = *(uint64_t **)((char *)&v136 + v69);
      *(void *)v177 = *(uint64_t **)((char *)&v136 + v69 + 8);
      uint64_t v70 = v68[16];
      v168._char object = *(uint64_t **)((char *)&v136 + v70);
      v174._countAndFlagsBits = *(uint64_t *)((char *)&v136 + v70 + 8);
      uint64_t v71 = v68[20];
      *(void *)v167 = *(uint64_t **)((char *)&v136 + v71);
      uint64_t v173 = *(uint64_t *)((char *)&v136 + v71 + 8);
      uint64_t v72 = v68[24];
      v172._countAndFlagsBits = *(uint64_t *)((char *)&v136 + v72);
      v170 = *(uint64_t **)((char *)&v136 + v72 + 8);
      uint64_t v73 = named;
      uint64_t v74 = v169;
      int v75 = (double (**)(uint64_t *, uint64_t, void *))v174._object;
      (*((void (**)(uint64_t, uint64_t **, void *))v174._object + 4))(named, &v136, v169);
      uint64_t v76 = (uint64_t)v166;
      *(double *)a1.i64 = v75[2](v166, v73, v74);
      uint64_t v77 = v165;
      MLDataTable.init(_:convertArraysToShapedArrays:)(v76, 0, a1);
      if (v77)
      {
        (*((void (**)(uint64_t, void *))v174._object + 1))(named, v169);
        swift_bridgeObjectRelease(v174._countAndFlagsBits);
        swift_bridgeObjectRelease(v177[0]);
        swift_bridgeObjectRelease(v173);
        return swift_bridgeObjectRelease((_BYTE)v170);
      }
      uint64_t v116 = named;
      *(void *)v175 = v137;
      LOBYTE(v176) = BYTE8(v137);
      char v117 = (char)v170;
      v135._char object = v170;
      v135._countAndFlagsBits = v172._countAndFlagsBits;
      char v118 = v173;
      static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v175, *(uint64_t *)v171, *(void **)v177, v168._object, (void *)v174._countAndFlagsBits, *(uint64_t *)v167, *(double *)a1.i64, (void *)v173, v135);
      (*((void (**)(uint64_t, void *))v174._object + 1))(v116, v169);
      swift_bridgeObjectRelease(v177[0]);
      swift_bridgeObjectRelease(v174._countAndFlagsBits);
      swift_bridgeObjectRelease(v117);
      swift_bridgeObjectRelease(v118);
      goto LABEL_34;
  }
}

uint64_t type metadata accessor for MLHandActionClassifier.DataSource(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLHandActionClassifier.DataSource;
  if (!type metadata singleton initialization cache for MLHandActionClassifier.DataSource) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLHandActionClassifier.DataSource);
  }
  return result;
}

uint64_t MLHandActionClassifier.DataSource.extractKeypoints(targetFrameRate:)(double a1)
{
  uint64_t v100 = v2;
  v105._uint64_t countAndFlagsBits = v3;
  double in = a1;
  uint64_t v91 = v1;
  uint64_t v88 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Data>);
  uint64_t v87 = *(void *)(v88 - 8);
  int64_t v4 = *(void *)(v87 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  NSString v92 = &v76;
  uint64_t v86 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v85 = *(void *)(v86 - 8);
  int64_t v7 = *(void *)(v85 + 64);
  int64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  uint64_t v79 = &v76;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?)
                              - 8)
                  + 64);
  int64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  uint64_t v80 = &v76;
  uint64_t v13 = alloca(v10);
  int64_t v14 = alloca(v10);
  Swift::String v78 = &v76;
  char v103 = (uint64_t *)type metadata accessor for AnyColumn(0);
  uint64_t v97 = *(v103 - 1);
  int64_t v15 = *(void *)(v97 + 64);
  int64_t v16 = alloca(v15);
  int64_t v17 = alloca(v15);
  uint64_t v94 = &v76;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  unsigned __int8 v93 = &v76;
  int64_t v20 = alloca(v15);
  uint64_t v21 = alloca(v15);
  uint64_t v84 = &v76;
  uint64_t v22 = type metadata accessor for DataFrame(0);
  uint64_t v23 = *(void *)(v22 - 8);
  int64_t v24 = *(void *)(v23 + 64);
  int64_t v25 = alloca(v24);
  uint64_t v26 = alloca(v24);
  BOOL v99 = &v76;
  uint64_t v27 = type metadata accessor for MLHandActionClassifier.DataSource(0);
  int64_t v28 = *(void *)(*(void *)(v27 - 8) + 64);
  uint64_t v29 = alloca(v28);
  int64_t v30 = alloca(v28);
  outlined init with copy of MLHandActionClassifier.DataSource(v105._countAndFlagsBits, (uint64_t)&v76);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v76, v27);
  if (EnumCaseMultiPayload == 5)
  {
    uint64_t v37 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
    uint64_t v38 = v37[12];
    uint64_t v82 = *(void **)((char *)&v76 + v38);
    uint64_t v98 = *(void **)((char *)&v76 + v38 + 8);
    uint64_t v39 = v37[16];
    char v81 = *(void **)((char *)&v76 + v39);
    id v89 = *(void **)((char *)&v76 + v39 + 8);
    uint64_t v40 = v37[20];
    v105._uint64_t countAndFlagsBits = *(uint64_t *)((char *)&v76 + v40);
    double v41 = *(double *)((char *)&v76 + v40 + 8);
    uint64_t v90 = v23;
    uint64_t v42 = *(void (**)(uint64_t, uint64_t, uint64_t))(v23 + 32);
    uint64_t v95 = v22;
    unint64_t v83 = v42;
    v42((uint64_t)v99, (uint64_t)&v76, v22);
    uint64_t v43 = v84;
    double in = v41;
    DataFrame.subscript.getter(v105._countAndFlagsBits, *(void *)&v41);
    uint64_t v44 = (void *)AnyColumn.wrappedElementType.getter();
    uint64_t v45 = *(void (**)(uint64_t *, uint64_t *))(v97 + 8);
    v45(v43, v103);
    uint64_t v96 = v45;
    if (v44 == &type metadata for String)
    {
      uint64_t v50 = v79;
      DataFrame.subscript.getter(v105._countAndFlagsBits, *(void *)&in, &type metadata for String);
      uint64_t v51 = (uint64_t)v78;
      uint64_t v52 = v100;
      Column<A>.parseAsJSONArrays()();
      if (v52)
      {
        swift_errorRelease(v52);
        (*(void (**)(uint64_t *, uint64_t))(v85 + 8))(v50, v86);
        __swift_storeEnumTagSinglePayload(v51, 1, 1, (uint64_t)v103);
        uint64_t v53 = v51;
      }
      else
      {
        uint64_t v100 = 0;
        (*(void (**)(uint64_t *, uint64_t))(v85 + 8))(v50, v86);
        uint64_t v53 = v51;
        uint64_t v58 = (uint64_t)v103;
        __swift_storeEnumTagSinglePayload(v51, 0, 1, (uint64_t)v103);
        if (__swift_getEnumTagSinglePayload(v51, 1, v58) != 1)
        {
          uint64_t v71 = v97;
          (*(void (**)(uint64_t *, uint64_t, uint64_t))(v97 + 32))(v93, v53, v58);
          uint64_t v72 = v84;
          (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v71 + 16))(v84, v93, v58);
          double v73 = in;
          swift_bridgeObjectRetain(LOBYTE(in));
          uint64_t v74 = v72;
          uint64_t countAndFlagsBits = v105._countAndFlagsBits;
          DataFrame.subscript.setter(v74, v105._countAndFlagsBits, *(void *)&v73);
          uint64_t v48 = countAndFlagsBits;
          double v47 = v73;
          v96(v93, v103);
          goto LABEL_21;
        }
      }
      double v47 = in;
      uint64_t v48 = v105._countAndFlagsBits;
      uint64_t v59 = v53;
    }
    else
    {
      DataFrame.subscript.getter(v105._countAndFlagsBits, *(void *)&in);
      uint64_t v46 = (void *)AnyColumn.wrappedElementType.getter();
      v96(v43, v103);
      if (v46 != &type metadata for Data)
      {
        double v47 = in;
        uint64_t v48 = v105._countAndFlagsBits;
LABEL_21:
        v64._uint64_t countAndFlagsBits = v48;
        *(double *)&v64._char object = v47;
        uint64_t v65 = v48;
        uint64_t v66 = (uint64_t)v99;
        DataFrame.flattenNestedArrays(in:shape:)(v64, (Swift::OpaquePointer)&outlined read-only object #0 of MLHandActionClassifier.DataSource.extractKeypoints(targetFrameRate:));
        if (v67)
        {
          (*(void (**)(uint64_t, uint64_t))(v90 + 8))(v66, v95);
          swift_bridgeObjectRelease((_BYTE)v98);
          char v68 = (char)v89;
        }
        else
        {
          uint64_t v69 = v65;
          char v70 = (char)v89;
          static _VideoUtilities.renameFeatureColumns(dataFrame:sessionIdColumn:featureColumn:labelColumn:)(v66, (uint64_t)v82, v98, v69, *(void **)&v47, v81, v89);
          v83(v91, v66, v95);
          swift_bridgeObjectRelease((_BYTE)v98);
          char v68 = v70;
        }
        swift_bridgeObjectRelease(v68);
        char v36 = LOBYTE(v47);
        return swift_bridgeObjectRelease(v36);
      }
      DataFrame.subscript.getter(v105._countAndFlagsBits, *(void *)&in, &type metadata for Data);
      uint64_t v54 = (uint64_t)v80;
      uint64_t v55 = v100;
      Column<A>.parseAsJSONArrays()();
      if (v55)
      {
        swift_errorRelease(v55);
        (*(void (**)(uint64_t *, uint64_t))(v87 + 8))(v92, v88);
        __swift_storeEnumTagSinglePayload(v54, 1, 1, (uint64_t)v103);
        uint64_t v56 = v54;
        double v47 = in;
        uint64_t v48 = v105._countAndFlagsBits;
      }
      else
      {
        (*(void (**)(uint64_t *, uint64_t))(v87 + 8))(v92, v88);
        uint64_t v60 = v54;
        uint64_t v61 = v54;
        uint64_t v62 = (uint64_t)v103;
        __swift_storeEnumTagSinglePayload(v60, 0, 1, (uint64_t)v103);
        int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v61, 1, v62);
        uint64_t v56 = v61;
        double v47 = in;
        uint64_t v48 = v105._countAndFlagsBits;
        if (EnumTagSinglePayload != 1)
        {
          (*(void (**)(uint64_t *, uint64_t, uint64_t *))(v97 + 32))(v94, v56, v103);
          (*(void (**)(uint64_t *, uint64_t *, uint64_t *))(v97 + 16))(v43, v94, v103);
          swift_bridgeObjectRetain(LOBYTE(v47));
          DataFrame.subscript.setter(v43, v48, *(void *)&v47);
          uint64_t v48 = v105._countAndFlagsBits;
          double v47 = in;
          v96(v94, v103);
          goto LABEL_21;
        }
      }
      uint64_t v59 = v56;
    }
    outlined destroy of AnyColumn?(v59);
    goto LABEL_21;
  }
  if (EnumCaseMultiPayload == 3)
  {
    BOOL v99 = v78;
    v105._uint64_t countAndFlagsBits = (uint64_t)v79;
    char v103 = v80;
    uint64_t v32 = v81;
    uint64_t v33 = v82;
    uint64_t v34 = v83;
    uint64_t v101 = v76;
    LOBYTE(v102) = v77;
    uint64_t v35 = v100;
    static MLHandActionClassifier.reformatKeypointsDataTable(table:featureColumn:)(&v101, (uint64_t)v82, v83, a1);
    if (!v35)
    {
      static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)((uint64_t)&v101, (uint64_t)v99, (void *)v105._countAndFlagsBits, v33, v34, (uint64_t)v103, v32);
      swift_bridgeObjectRelease((_BYTE)v34);
      swift_bridgeObjectRelease((_BYTE)v32);
      swift_bridgeObjectRelease(v105._countAndFlagsBits);
      uint64_t v76 = v101;
      char v77 = v102;
      return DataFrame.init(_:)((uint64_t)&v76);
    }
    outlined consume of Result<_DataTable, Error>(v101, v102);
    swift_bridgeObjectRelease(v105._countAndFlagsBits);
    swift_bridgeObjectRelease((_BYTE)v32);
    char v36 = (char)v34;
    return swift_bridgeObjectRelease(v36);
  }
  type metadata accessor for MLHandActionClassifier.FeatureExtractor();
  uint64_t v49 = v100;
  static MLHandActionClassifier.FeatureExtractor.extractFeatures(from:targetFrameRate:startingSessionId:)(v105._countAndFlagsBits, 0, (__m128)*(unint64_t *)&in);
  if (!v49)
  {
    uint64_t v76 = v101;
    char v77 = v102;
    DataFrame.init(_:)((uint64_t)&v76);
  }
  return outlined destroy of MLHandActionClassifier.DataSource((uint64_t)&v76);
}

uint64_t MLHandActionClassifier.DataSource.keypointsWithAnnotations(targetFrameRate:)(__m128 a1)
{
  uint64_t v85 = v2;
  uint64_t v91 = v3;
  uint64_t v88 = (void *)a1.i64[0];
  Swift::String v78 = v1;
  uint64_t v76 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v75 = *(void *)(v76 - 8);
  int64_t v4 = *(void *)(v75 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  char v70 = (uint64_t *)&v68;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?)
                             - 8)
                 + 64);
  int64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  uint64_t v69 = &v68;
  uint64_t v86 = (void *)type metadata accessor for AnyColumn(0);
  char v81 = (uint64_t *)*(v86 - 1);
  int64_t v10 = v81[8];
  int64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  uint64_t v71 = (uint64_t *)&v68;
  uint64_t v13 = alloca(v10);
  int64_t v14 = alloca(v10);
  uint64_t v84 = (uint64_t *)&v68;
  uint64_t v15 = type metadata accessor for DataFrame(0);
  uint64_t v16 = *(void *)(v15 - 8);
  int64_t v17 = *(void *)(v16 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  char v77 = (uint64_t *)&v68;
  int64_t v20 = alloca(v17);
  uint64_t v21 = alloca(v17);
  uint64_t v90 = (uint64_t *)&v68;
  uint64_t v22 = type metadata accessor for MLHandActionClassifier.DataSource(0);
  int64_t v23 = *(void *)(*(void *)(v22 - 8) + 64);
  int64_t v24 = alloca(v23);
  int64_t v25 = alloca(v23);
  outlined init with copy of MLHandActionClassifier.DataSource((uint64_t)v91, (uint64_t)&v68);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v68, v22);
  if (EnumCaseMultiPayload != 5)
  {
    if (EnumCaseMultiPayload == 3)
    {
      char v27 = (char)v69;
      char v81 = v70;
      uint64_t v91 = v71;
      uint64_t v84 = v72;
      uint64_t v86 = v73;
      int64_t v28 = v74;
      uint64_t v29 = (void *)v75;
      uint64_t v92 = (uint64_t)v68;
      LOBYTE(v93) = v69 & 1;
      uint64_t v90 = v68;
      outlined copy of Result<_DataTable, Error>((uint64_t)v68, (char)v69);
      uint64_t v88 = v28;
      uint64_t v30 = v85;
      static MLHandActionClassifier.reformatKeypointsDataTable(table:featureColumn:)(&v92, (uint64_t)v28, v29, *(double *)a1.i64);
      if (v30)
      {
        outlined consume of Result<_DataTable, Error>(v92, v93);
        swift_bridgeObjectRelease((_BYTE)v91);
        swift_bridgeObjectRelease((_BYTE)v86);
        swift_bridgeObjectRelease((_BYTE)v29);
        return outlined consume of Result<_DataTable, Error>((uint64_t)v90, v27);
      }
      char v48 = (char)v86;
      static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)((uint64_t)&v92, (uint64_t)v81, v91, v88, v29, (uint64_t)v84, v86);
      swift_bridgeObjectRelease((_BYTE)v91);
      swift_bridgeObjectRelease(v48);
      swift_bridgeObjectRelease((_BYTE)v29);
      outlined consume of Result<_DataTable, Error>((uint64_t)v90, v27);
    }
    else
    {
      type metadata accessor for MLHandActionClassifier.FeatureExtractor();
      uint64_t v47 = v85;
      static MLHandActionClassifier.FeatureExtractor.extractFeatures(from:targetFrameRate:startingSessionId:)((uint64_t)v91, 0, (__m128)(unint64_t)v88);
      if (v47) {
        return outlined destroy of MLHandActionClassifier.DataSource((uint64_t)&v68);
      }
      uint64_t v92 = v82;
      LOBYTE(v93) = v83;
      outlined destroy of MLHandActionClassifier.DataSource((uint64_t)&v68);
    }
    goto LABEL_19;
  }
  uint64_t v31 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
  uint64_t v32 = v31[12];
  double v73 = *(uint64_t **)((char *)&v68 + v32);
  uint64_t v79 = *(uint64_t **)((char *)&v68 + v32 + 8);
  uint64_t v33 = v31[16];
  uint64_t v72 = *(uint64_t **)((char *)&v68 + v33);
  uint64_t v88 = *(uint64_t **)((char *)&v68 + v33 + 8);
  uint64_t v34 = v31[20];
  uint64_t v35 = v15;
  uint64_t v36 = *(uint64_t *)((char *)&v68 + v34);
  uint64_t v37 = *(uint64_t **)((char *)&v68 + v34 + 8);
  uint64_t v89 = v35;
  uint64_t v87 = v16;
  (*(void (**)(uint64_t *, uint64_t **))(v16 + 32))(v90, &v68);
  uint64_t v38 = (uint64_t)v84;
  uint64_t v80 = v36;
  uint64_t v91 = v37;
  uint64_t v39 = v37;
  uint64_t v40 = (uint64_t)v90;
  DataFrame.subscript.getter(v36, v39);
  double v41 = (void *)AnyColumn.wrappedElementType.getter();
  uint64_t v42 = (void (*)(uint64_t, void *))v81[1];
  v42(v38, v86);
  uint64_t v43 = v40;
  if (v41 != &type metadata for String) {
    goto LABEL_6;
  }
  uint64_t v74 = (void (*)(void, void))v42;
  uint64_t v49 = v70;
  DataFrame.subscript.getter(v80, v91, &type metadata for String);
  uint64_t v50 = (uint64_t)v69;
  uint64_t v51 = v85;
  Column<A>.parseAsJSONArrays()();
  if (v51)
  {
    swift_errorRelease(v51);
    (*(void (**)(uint64_t *, uint64_t))(v75 + 8))(v49, v76);
    __swift_storeEnumTagSinglePayload(v50, 1, 1, (uint64_t)v86);
    uint64_t v52 = v50;
LABEL_14:
    uint64_t v45 = v89;
    uint64_t v85 = 0;
    outlined destroy of AnyColumn?(v52);
    uint64_t v46 = (uint64_t)v77;
    uint64_t v44 = v87;
    uint64_t v43 = (uint64_t)v90;
    goto LABEL_15;
  }
  (*(void (**)(uint64_t *, uint64_t))(v75 + 8))(v49, v76);
  uint64_t v53 = v50;
  uint64_t v52 = v50;
  uint64_t v54 = v86;
  __swift_storeEnumTagSinglePayload(v53, 0, 1, (uint64_t)v86);
  if (__swift_getEnumTagSinglePayload(v52, 1, (uint64_t)v54) == 1) {
    goto LABEL_14;
  }
  uint64_t v61 = v71;
  uint64_t v62 = v52;
  uint64_t v63 = (uint64_t)v81;
  ((void (*)(uint64_t *, uint64_t, void *))v81[4])(v71, v62, v54);
  (*(void (**)(uint64_t *, uint64_t *, void *))(v63 + 16))(v84, v61, v54);
  Swift::String v64 = v91;
  swift_bridgeObjectRetain((_BYTE)v91);
  uint64_t v85 = 0;
  uint64_t v65 = (uint64_t)v90;
  DataFrame.subscript.setter(v84, v80, v64);
  v74(v61, v54);
  uint64_t v43 = v65;
LABEL_6:
  uint64_t v44 = v87;
  uint64_t v45 = v89;
  uint64_t v46 = (uint64_t)v77;
LABEL_15:
  *(double *)a1.i64 = (*(double (**)(uint64_t, uint64_t, uint64_t))(v44 + 16))(v46, v43, v45);
  uint64_t v55 = v85;
  MLDataTable.init(_:convertArraysToShapedArrays:)(v46, 0, a1);
  if (v55)
  {
    (*(void (**)(uint64_t, uint64_t))(v44 + 8))(v43, v45);
    swift_bridgeObjectRelease((_BYTE)v91);
    swift_bridgeObjectRelease((_BYTE)v88);
    return swift_bridgeObjectRelease((_BYTE)v79);
  }
  uint64_t v92 = v82;
  LOBYTE(v93) = v83;
  uint64_t v56 = v80;
  char v57 = v91;
  static MLHandActionClassifier.reformatKeypointsDataTable(table:featureColumn:)(&v92, v80, v91, *(double *)a1.i64);
  char v58 = (char)v79;
  uint64_t v59 = (void *)v56;
  LOBYTE(v56) = (_BYTE)v88;
  static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)((uint64_t)&v92, (uint64_t)v73, v79, v59, v57, (uint64_t)v72, v88);
  (*(void (**)(uint64_t *, uint64_t))(v87 + 8))(v90, v89);
  swift_bridgeObjectRelease(v58);
  swift_bridgeObjectRelease(v56);
  swift_bridgeObjectRelease((_BYTE)v57);
LABEL_19:
  uint64_t v66 = v78;
  uint64_t result = v92;
  char v67 = v93;
  *Swift::String v78 = v92;
  *((unsigned char *)v66 + 8) = v67;
  return result;
}

void *MLHandActionClassifier.DataSource.labeledMedia()(__m128 a1)
{
  return static _VideoUtilities.videoURLsPerClass(from:)(v1, a1);
}

uint64_t MLHandActionClassifier.DataSource.gatherAnnotatedFileNames()()
{
  uint64_t v96 = v1;
  uint64_t v94 = v0;
  int v102 = (void *)type metadata accessor for DataFrame(0);
  uint64_t v97 = *(v102 - 1);
  int64_t v3 = *(void *)(v97 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  BOOL v99 = (uint64_t *)&v90;
  uint64_t v6 = alloca(v3);
  int64_t v7 = alloca(v3);
  char v103 = (uint64_t *)&v90;
  uint64_t v101 = (void *)type metadata accessor for UTType(0);
  uint64_t v8 = *(v101 - 1);
  int64_t v9 = *(void *)(v8 + 64);
  int64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  char v104 = (uint64_t *)&v90;
  int64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v95 = (uint64_t *)&v90;
  uint64_t v106 = (uint64_t *)type metadata accessor for URL(0);
  uint64_t v107 = (void *)*(v106 - 1);
  int64_t v14 = v107[8];
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v100 = (uint64_t *)&v90;
  int64_t v17 = alloca(v14);
  uint64_t v18 = alloca(v14);
  Swift::String v105 = (uint64_t *)&v90;
  uint64_t v19 = alloca(v14);
  int64_t v20 = alloca(v14);
  uint64_t v98 = (uint64_t *)&v90;
  uint64_t v21 = alloca(v14);
  uint64_t v22 = alloca(v14);
  int v93 = (uint64_t *)&v90;
  uint64_t v23 = type metadata accessor for MLHandActionClassifier.DataSource(0);
  int64_t v24 = *(void *)(*(void *)(v23 - 8) + 64);
  int64_t v25 = alloca(v24);
  uint64_t v26 = alloca(v24);
  uint64_t v92 = (uint64_t *)v2;
  outlined init with copy of MLHandActionClassifier.DataSource(v2, (uint64_t)&v90);
  switch(swift_getEnumCaseMultiPayload(&v90, v23))
  {
    case 0u:
      char v27 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      int64_t v28 = (uint64_t **)((char *)&v90 + v27[12]);
      uint64_t v29 = v27[16];
      BOOL v99 = *(uint64_t **)((char *)&v90 + v29);
      uint64_t v101 = *(uint64_t **)((char *)&v90 + v29 + 8);
      uint64_t v30 = v27[20];
      char v103 = *(uint64_t **)((char *)&v90 + v30);
      char v104 = *(uint64_t **)((char *)&v90 + v30 + 8);
      uint64_t v31 = v27[24];
      uint64_t v97 = *(uint64_t *)((char *)&v90 + v31);
      uint64_t v95 = *(uint64_t **)((char *)&v90 + v31 + 8);
      uint64_t v32 = v27[28];
      uint64_t v98 = *(uint64_t **)((char *)&v90 + v32);
      int v102 = *(uint64_t **)((char *)&v90 + v32 + 8);
      uint64_t v33 = (void (*)(uint64_t *, uint64_t **, uint64_t *))v107[4];
      uint64_t v34 = v106;
      v33(v105, &v90, v106);
      uint64_t v35 = (uint64_t)v100;
      uint64_t v36 = v34;
      uint64_t v37 = v101;
      v33(v100, v28, v36);
      LOBYTE(v33) = (_BYTE)v95;
      uint64_t v38 = v35;
      LOBYTE(v35) = (_BYTE)v104;
      MLHandActionClassifier.DataSource.gatherAnnotatedFileNamesForDirectory(url:annotationFile:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v105, v38, (uint64_t)v99, v37, (uint64_t)v103, v104, v97, v95, (uint64_t)v98, v102);
      swift_bridgeObjectRelease(v35);
      swift_bridgeObjectRelease((_BYTE)v37);
      swift_bridgeObjectRelease((_BYTE)v33);
      swift_bridgeObjectRelease((_BYTE)v102);
      uint64_t v39 = (void (*)(uint64_t *, uint64_t *))v107[1];
      uint64_t v40 = v106;
      v39(v100, v106);
      return ((uint64_t (*)(uint64_t *, uint64_t *))v39)(v105, v40);
    case 1u:
      uint64_t v42 = (uint64_t)v98;
      ((void (*)(uint64_t *, uint64_t **, uint64_t *))v107[4])(v98, &v90, v106);
      uint64_t v43 = v104;
      static UTType.movie.getter();
      uint64_t v44 = v96;
      uint64_t v45 = static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)(v42, (uint64_t)v43);
      if (v44)
      {
        (*(void (**)(uint64_t *, void *))(v8 + 8))(v104, v101);
        uint64_t v46 = (uint64_t)v98;
        return ((uint64_t (*)(uint64_t, uint64_t *))v107[1])(v46, v106);
      }
      uint64_t v79 = (uint64_t)v45;
      (*(void (**)(uint64_t *, void *))(v8 + 8))(v104, v101);
      uint64_t v80 = specialized _NativeDictionary.mapValues<A>(_:)(v79);
      swift_bridgeObjectRelease(v79);
      uint64_t v81 = v94;
      specialized DataFrame.init<A>(expanding:keysColumnName:valuesColumnName:)((uint64_t)v80, 0x6C6562616CLL, (uint64_t *)0xE500000000000000, (void *)0x7461506F65646976, 0xE900000000000068);
      uint64_t v82 = (uint64_t)v98;
      goto LABEL_20;
    case 2u:
      uint64_t v47 = (uint64_t)v93;
      ((void (*)(uint64_t *, uint64_t **, uint64_t *))v107[4])(v93, &v90, v106);
      char v48 = v95;
      static UTType.movie.getter();
      uint64_t v49 = v96;
      uint64_t v50 = static _FileUtilities.collectFilesLabeledByFileName(at:type:)(v47, (uint64_t)v48);
      if (v49)
      {
        (*(void (**)(uint64_t *, void *))(v8 + 8))(v95, v101);
        uint64_t v46 = (uint64_t)v93;
        return ((uint64_t (*)(uint64_t, uint64_t *))v107[1])(v46, v106);
      }
      uint64_t v83 = v50;
      (*(void (**)(uint64_t *, void *))(v8 + 8))(v95, v101);
      uint64_t v84 = specialized _NativeDictionary.mapValues<A>(_:)(v83);
      swift_bridgeObjectRelease(v83);
      uint64_t v81 = v94;
      specialized DataFrame.init<A>(expanding:keysColumnName:valuesColumnName:)((uint64_t)v84, 0x6C6562616CLL, (uint64_t *)0xE500000000000000, (void *)0x7461506F65646976, 0xE900000000000068);
      uint64_t v82 = (uint64_t)v93;
LABEL_20:
      ((void (*)(uint64_t, uint64_t *))v107[1])(v82, v106);
      uint64_t v87 = v81;
      uint64_t v88 = (uint64_t)v102;
      return __swift_storeEnumTagSinglePayload(v87, 0, 1, v88);
    case 3u:
      char v51 = (char)v93;
      char v52 = (char)v95;
      char v53 = v97;
      outlined consume of Result<_DataTable, Error>((uint64_t)v90, v91);
      swift_bridgeObjectRelease(v53);
      swift_bridgeObjectRelease(v52);
      swift_bridgeObjectRelease(v51);
      return __swift_storeEnumTagSinglePayload(v94, 1, 1, (uint64_t)v102);
    case 4u:
      int v54 = v91;
      uint64_t v98 = v92;
      uint64_t v95 = v93;
      uint64_t v55 = v94;
      uint64_t v56 = v93;
      uint64_t v101 = v96;
      uint64_t v107 = (void *)v97;
      BOOL v99 = v92;
      uint64_t v106 = v92;
      LOBYTE(v91) = v91 & 1;
      uint64_t v100 = v90;
      LODWORD(v104) = v54;
      outlined copy of Result<_DataTable, Error>((uint64_t)v90, v54);
      char v57 = v103;
      DataFrame.init(_:)((uint64_t)&v90);
      uint64_t v58 = (uint64_t)v57;
      uint64_t v59 = v95;
      uint64_t v60 = (uint64_t)v98;
      int v93 = (uint64_t *)v55;
      uint64_t v61 = v55;
      Swift::String v105 = v56;
      uint64_t v62 = (void (*)(void, void, void))v101;
      uint64_t v63 = v96;
      static _VideoUtilities.validateVideoInput(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(v58, (uint64_t)v98, v95, v61, v56, (uint64_t)v101, (uint64_t)v107, (uint64_t)v99, (uint64_t)v106);
      if (!v63)
      {
        static _VideoUtilities.renameVideoColumns(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v103, v60, v59, (uint64_t)v93, v105, (uint64_t)v62, v107, (uint64_t)v99, v106);
        outlined consume of Result<_DataTable, Error>((uint64_t)v100, (char)v104);
        swift_bridgeObjectRelease((_BYTE)v105);
        swift_bridgeObjectRelease((_BYTE)v59);
        swift_bridgeObjectRelease((_BYTE)v107);
        swift_bridgeObjectRelease((_BYTE)v106);
        uint64_t v85 = v94;
        uint64_t v86 = v102;
        (*(void (**)(uint64_t, uint64_t *, void *))(v97 + 32))(v94, v103, v102);
        uint64_t v87 = v85;
        uint64_t v88 = (uint64_t)v86;
        return __swift_storeEnumTagSinglePayload(v87, 0, 1, v88);
      }
      (*(void (**)(uint64_t *, void *))(v97 + 8))(v103, v102);
      outlined consume of Result<_DataTable, Error>((uint64_t)v100, (char)v104);
      swift_bridgeObjectRelease((_BYTE)v105);
      swift_bridgeObjectRelease((_BYTE)v59);
      swift_bridgeObjectRelease((_BYTE)v107);
      char v64 = (char)v106;
      return swift_bridgeObjectRelease(v64);
    case 5u:
      uint64_t v65 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      swift_bridgeObjectRelease(*(uint64_t **)((char *)&v90 + v65[12] + 8));
      swift_bridgeObjectRelease(*(uint64_t **)((char *)&v90 + v65[16] + 8));
      swift_bridgeObjectRelease(*(uint64_t **)((char *)&v90 + v65[20] + 8));
      uint64_t v66 = v102;
      __swift_storeEnumTagSinglePayload(v94, 1, 1, (uint64_t)v102);
      return (*(uint64_t (**)(uint64_t **, void *))(v97 + 8))(&v90, v66);
    case 6u:
      char v67 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      uint64_t v68 = v67[12];
      uint64_t v100 = *(uint64_t **)((char *)&v90 + v68);
      uint64_t v106 = *(uint64_t **)((char *)&v90 + v68 + 8);
      uint64_t v69 = v67[16];
      char v104 = *(uint64_t **)((char *)&v90 + v69);
      char v70 = *(uint64_t **)((char *)&v90 + v69 + 8);
      uint64_t v71 = v67[20];
      uint64_t v98 = *(uint64_t **)((char *)&v90 + v71);
      uint64_t v107 = *(uint64_t **)((char *)&v90 + v71 + 8);
      uint64_t v72 = v67[24];
      double v73 = *(void (**)(void, void, void))((char *)&v90 + v72);
      Swift::String v105 = *(uint64_t **)((char *)&v90 + v72 + 8);
      uint64_t v74 = (uint64_t)v99;
      uint64_t v75 = v102;
      uint64_t v101 = *(void **)(v97 + 32);
      ((void (*)(uint64_t *, uint64_t **, void *))v101)(v99, &v90, v102);
      uint64_t v76 = v74;
      uint64_t v77 = (uint64_t)v98;
      char v103 = v70;
      Swift::String v78 = v96;
      uint64_t v96 = v73;
      static _VideoUtilities.validateVideoInput(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(v76, (uint64_t)v100, v106, (uint64_t)v104, v70, (uint64_t)v98, (uint64_t)v107, (uint64_t)v73, (uint64_t)v105);
      if (v78)
      {
        (*(void (**)(uint64_t *, void *))(v97 + 8))(v99, v75);
        swift_bridgeObjectRelease((_BYTE)v106);
        swift_bridgeObjectRelease((_BYTE)v103);
        swift_bridgeObjectRelease((_BYTE)v105);
        char v64 = (char)v107;
        return swift_bridgeObjectRelease(v64);
      }
      else
      {
        static _VideoUtilities.renameVideoColumns(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v99, (uint64_t)v100, v106, (uint64_t)v104, v103, v77, v107, (uint64_t)v96, v105);
        swift_bridgeObjectRelease((_BYTE)v103);
        swift_bridgeObjectRelease((_BYTE)v106);
        swift_bridgeObjectRelease((_BYTE)v107);
        swift_bridgeObjectRelease((_BYTE)v105);
        uint64_t v89 = v94;
        ((void (*)(uint64_t, uint64_t *, void *))v101)(v94, v99, v75);
        uint64_t v87 = v89;
        uint64_t v88 = (uint64_t)v75;
        return __swift_storeEnumTagSinglePayload(v87, 0, 1, v88);
      }
  }
}

uint64_t MLHandActionClassifier.DataSource.gatherAnnotatedFileNamesForDirectory(url:annotationFile:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, uint64_t a5, void *a6, uint64_t a7, void *a8, uint64_t a9, void *a10)
{
  v148 = a4;
  uint64_t v131 = v10;
  uint64_t v154 = a2;
  uint64_t v132 = v11;
  uint64_t v124 = a1;
  uint64_t v125 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v126 = *(void *)(v125 - 8);
  int64_t v15 = *(void *)(v126 + 64);
  uint64_t v16 = alloca(v15);
  int64_t v17 = alloca(v15);
  char v127 = v122;
  uint64_t v135 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  uint64_t v134 = *(void *)(v135 - 8);
  int64_t v18 = *(void *)(v134 + 64);
  uint64_t v19 = alloca(v18);
  int64_t v20 = alloca(v18);
  unint64_t v138 = v122;
  unint64_t v150 = (void *)type metadata accessor for CSVType(0);
  uint64_t v130 = *(v150 - 1);
  int64_t v21 = *(void *)(v130 + 64);
  uint64_t v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  uint64_t v128 = v122;
  int64_t v24 = *(void *)(*(void *)(type metadata accessor for CSVReadingOptions(0) - 8) + 64);
  int64_t v25 = alloca(v24);
  uint64_t v26 = alloca(v24);
  unint64_t v140 = v122;
  int64_t v27 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CSVType?)
                              - 8)
                  + 64);
  int64_t v28 = alloca(v27);
  uint64_t v29 = alloca(v27);
  uint64_t v146 = (uint64_t)v122;
  int64_t v30 = *(void *)(*(void *)(type metadata accessor for JSONReadingOptions(0) - 8) + 64);
  uint64_t v31 = alloca(v30);
  uint64_t v32 = alloca(v30);
  long long v151 = v122;
  uint64_t v133 = type metadata accessor for URL(0);
  uint64_t v144 = *(void **)(v133 - 8);
  int64_t v33 = v144[8];
  uint64_t v34 = alloca(v33);
  uint64_t v35 = alloca(v33);
  v153 = v122;
  uint64_t v36 = alloca(v33);
  uint64_t v37 = alloca(v33);
  char v152 = v122;
  int64_t v38 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for JSONType?)
                              - 8)
                  + 64);
  uint64_t v39 = alloca(v38);
  uint64_t v40 = alloca(v38);
  uint64_t v123 = v122;
  uint64_t v145 = type metadata accessor for DataFrame(0);
  uint64_t v139 = *(void *)(v145 - 8);
  int64_t v41 = *(void *)(v139 + 64);
  uint64_t v42 = alloca(v41);
  uint64_t v43 = alloca(v41);
  uint64_t v129 = v122;
  uint64_t v44 = alloca(v41);
  uint64_t v45 = alloca(v41);
  long long v137 = v122;
  uint64_t v46 = alloca(v41);
  uint64_t v47 = alloca(v41);
  v147 = v122;
  uint64_t v48 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t v49 = (void *)swift_allocObject(v48, 64, 7);
  v49[2] = 2;
  v49[3] = 4;
  uint64_t v142 = a3;
  v49[4] = a3;
  LOBYTE(a3) = (_BYTE)v148;
  v49[5] = v148;
  uint64_t v136 = a5;
  v49[6] = a5;
  v49[7] = a6;
  uint64_t v143 = a6;
  swift_bridgeObjectRetain(a3);
  swift_bridgeObjectRetain((_BYTE)a6);
  if (a8)
  {
    swift_bridgeObjectRetain((_BYTE)a8);
    unint64_t v50 = 3;
    char v51 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(1, 3, 1, (uint64_t)v49);
    v51[2] = 3;
    v51[8] = a7;
    v51[9] = a8;
  }
  else
  {
    unint64_t v50 = 2;
    char v51 = v49;
  }
  if (a10)
  {
    char v52 = v51;
    unint64_t v53 = v51[3];
    uint64_t v149 = (void *)(v50 + 1);
    swift_bridgeObjectRetain((_BYTE)a10);
    if (v53 >> 1 <= v50)
    {
      char v121 = v53 >= 2;
      int64_t v54 = (int64_t)v149;
      char v52 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v121, (int64_t)v149, 1, (uint64_t)v52);
    }
    else
    {
      int64_t v54 = (int64_t)v149;
    }
    v52[2] = v54;
    uint64_t v55 = 2 * v50;
    v52[v55 + 4] = a9;
    uint64_t v149 = v52;
    v52[v55 + 5] = a10;
  }
  else
  {
    uint64_t v149 = v51;
  }
  uint64_t v56 = URL.pathExtension.getter();
  char v58 = v57;
  if (v56 == 1852797802 && v57 == 0xE400000000000000)
  {
    swift_bridgeObjectRelease(0);
LABEL_13:
    uint64_t v60 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, JSONType)>);
    v153 = (char *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, JSONType));
    uint64_t v61 = *((void *)v153 - 1);
    uint64_t v146 = *(void *)(v61 + 72);
    uint64_t v62 = *(unsigned __int8 *)(v61 + 80);
    uint64_t v63 = ((int)v62 + 32) & ~*(unsigned __int8 *)(v61 + 80);
    uint64_t v64 = swift_allocObject(v60, v63 + 2 * v146, v62 | 7);
    *(void *)(v64 + 16) = 2;
    *(void *)(v64 + 24) = 4;
    uint64_t v65 = v64 + v63;
    uint64_t v66 = v64 + v63 + *((int *)v153 + 12);
    *(void *)(v64 + v63) = v142;
    *(void *)(v64 + v63 + 8) = v148;
    LODWORD(v150) = enum case for JSONType.string(_:);
    unint64_t v140 = (char *)type metadata accessor for JSONType(0);
    char v67 = *(unsigned char **)(*((void *)v140 - 1) + 104);
    ((void (*)(uint64_t, void, char *))v67)(v66, v150, v140);
    uint64_t v68 = v146;
    uint64_t v69 = (unsigned char *)(v65 + v146 + *((int *)v153 + 12));
    *(void *)(v146 + v65) = v136;
    LOBYTE(v66) = (_BYTE)v143;
    *(void *)(v68 + v65 + 8) = v143;
    uint64_t v70 = (uint64_t)v140;
    v153 = v67;
    ((void (*)(unsigned char *, void, char *))v67)(v69, v150, v140);
    swift_bridgeObjectRetain((_BYTE)v148);
    swift_bridgeObjectRetain(v66);
    v141[0] = Dictionary.init(dictionaryLiteral:)(v64, &type metadata for String, v70, &protocol witness table for String);
    uint64_t v71 = (uint64_t)v123;
    if (a8)
    {
      ((void (*)(char *, void, uint64_t))v153)(v123, enum case for JSONType.double(_:), v70);
      __swift_storeEnumTagSinglePayload(v71, 0, 1, v70);
      swift_bridgeObjectRetain((_BYTE)a8);
      specialized Dictionary.subscript.setter(v71, a7, (uint64_t)a8);
    }
    uint64_t v72 = v153;
    if (a10)
    {
      ((void (*)(uint64_t, void, uint64_t))v153)(v71, enum case for JSONType.double(_:), v70);
      __swift_storeEnumTagSinglePayload(v71, 0, 1, v70);
      swift_bridgeObjectRetain((_BYTE)a10);
      specialized Dictionary.subscript.setter(v71, a9, (uint64_t)a10);
    }
    double v73 = v152;
    ((void (*)(char *, uint64_t, uint64_t, char *))v144[2])(v152, v154, v133, v72);
    uint64_t v154 = v141[0];
    int64_t v74 = (int64_t)v149;
    swift_bridgeObjectRetain((_BYTE)v149);
    uint64_t v75 = v151;
    JSONReadingOptions.init()();
    uint64_t v76 = v137;
    uint64_t v77 = v132;
    DataFrame.init(contentsOfJSONFile:columns:types:options:)(v73, v74, v154, v75);
    if (v77)
    {
      char v78 = v74;
      return swift_bridgeObjectRelease(v78);
    }
    uint64_t v154 = 0;
    uint64_t v79 = *(char **)(v139 + 32);
    uint64_t v80 = (uint64_t)v147;
    uint64_t v81 = v76;
    goto LABEL_28;
  }
  char v59 = _stringCompareWithSmolCheck(_:_:expecting:)(v56, v57, 1852797802, 0xE400000000000000, 0);
  swift_bridgeObjectRelease(v58);
  if (v59) {
    goto LABEL_13;
  }
  uint64_t v82 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, CSVType)>);
  uint64_t v83 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, CSVType));
  uint64_t v84 = *(void *)(v83 - 8);
  uint64_t v85 = v83;
  char v152 = (char *)v83;
  long long v151 = *(char **)(v84 + 72);
  uint64_t v86 = *(unsigned __int8 *)(v84 + 80);
  uint64_t v87 = ((int)v86 + 32) & ~*(unsigned __int8 *)(v84 + 80);
  uint64_t v88 = swift_allocObject(v82, v87 + 2 * (void)v151, v86 | 7);
  *(void *)(v88 + 16) = 2;
  *(void *)(v88 + 24) = 4;
  uint64_t v89 = v88 + v87;
  uint64_t v90 = v88 + v87 + *(int *)(v85 + 48);
  *(void *)(v88 + v87) = v142;
  *(void *)(v88 + v87 + 8) = v148;
  LODWORD(v137) = enum case for CSVType.string(_:);
  int v91 = *(unsigned char **)(v130 + 104);
  uint64_t v92 = (uint64_t)v150;
  ((void (*)(uint64_t, void, void *))v91)(v90, enum case for CSVType.string(_:), v150);
  int v93 = v151;
  uint64_t v94 = &v151[*((int *)v152 + 12) + v89];
  *(void *)&v151[v89] = v136;
  *(void *)&v93[v89 + 8] = v143;
  uint64_t v95 = v92;
  long long v151 = v91;
  ((void (*)(char *, void, uint64_t))v91)(v94, v137, v92);
  swift_bridgeObjectRetain((_BYTE)v148);
  swift_bridgeObjectRetain((_BYTE)v143);
  v141[0] = Dictionary.init(dictionaryLiteral:)(v88, &type metadata for String, v92, &protocol witness table for String);
  LODWORD(v152) = enum case for CSVType.double(_:);
  if (a8)
  {
    uint64_t v96 = v146;
    ((void (*)(uint64_t, void, uint64_t))v151)(v146, v152, v92);
    __swift_storeEnumTagSinglePayload(v96, 0, 1, v92);
    swift_bridgeObjectRetain((_BYTE)a8);
    specialized Dictionary.subscript.setter(v96, a7, (uint64_t)a8);
    uint64_t v95 = (uint64_t)v150;
  }
  if (a10)
  {
    uint64_t v97 = v146;
    ((void (*)(uint64_t, void, uint64_t))v151)(v146, v152, v95);
    __swift_storeEnumTagSinglePayload(v97, 0, 1, v95);
    swift_bridgeObjectRetain((_BYTE)a10);
    specialized Dictionary.subscript.setter(v97, a9, (uint64_t)a10);
  }
  ((void (*)(char *, uint64_t, uint64_t))v144[2])(v153, v154, v133);
  uint64_t v154 = v141[0];
  int64_t v98 = (int64_t)v149;
  swift_bridgeObjectRetain((_BYTE)v149);
  unint64_t v150 = default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
  uint64_t v144 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 2 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
  BOOL v99 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 3 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
  uint64_t v100 = v128;
  ((void (*)(char *, void, uint64_t))v151)(v128, v152, v95);
  uint64_t v101 = v140;
  CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)(1, v150, v144, v99, v100, 1, 1, 0, 44, 0xE100000000000000, 92, 0xE100000000000000);
  int v102 = v129;
  uint64_t v103 = v132;
  DataFrame.init(contentsOfCSVFile:columns:rows:types:options:)(v153, v98, 0, 0, 1, v154, v101);
  if (v103)
  {
    char v78 = v98;
    return swift_bridgeObjectRelease(v78);
  }
  uint64_t v154 = 0;
  uint64_t v79 = *(char **)(v139 + 32);
  uint64_t v80 = (uint64_t)v147;
  uint64_t v81 = v102;
LABEL_28:
  v153 = v79;
  ((void (*)(uint64_t, char *, uint64_t))v79)(v80, v81, v145);
  Swift::String v105 = v127;
  DataFrame.subscript.getter(v142, v148, &type metadata for String);
  v141[0] = 0;
  v141[1] = 0xE000000000000000;
  uint64_t v106 = lazy protocol witness table accessor for type Column<String> and conformance Column<A>();
  uint64_t v107 = v125;
  OptionalColumnProtocol.filled(with:)(v141, v125, v106);
  (*(void (**)(char *, uint64_t))(v126 + 8))(v105, v107);
  char v108 = alloca(24);
  char v109 = alloca(32);
  uint64_t v110 = v154;
  uint64_t v111 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lF11TabularData12FilledColumnVyAF0G0VySSGG_SSSgs5NeverOTg5((void (*)(void *))partial apply for closure #3 in MLObjectDetector.DataSource.gatherAnnotatedFileNames(), (uint64_t)v122);
  uint64_t v154 = v110;
  swift_bridgeObjectRelease((_BYTE)v149);
  uint64_t v112 = v148;
  swift_bridgeObjectRetain((_BYTE)v148);
  uint64_t v113 = v111;
  uint64_t v114 = v142;
  uint64_t v115 = v112;
  DataFrame.subscript.setter(v113, v142, v112, &type metadata for String, &type metadata for String);
  uint64_t v116 = (uint64_t)v147;
  uint64_t v117 = v154;
  static _VideoUtilities.renameVideoColumns(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v147, v114, v115, v136, v143, a7, a8, a9, a10);
  (*(void (**)(char *, uint64_t))(v134 + 8))(v138, v135);
  if (v117) {
    return (*(uint64_t (**)(uint64_t, uint64_t))(v139 + 8))(v116, v145);
  }
  uint64_t v118 = v131;
  uint64_t v119 = v116;
  uint64_t v120 = v145;
  ((void (*)(uint64_t, uint64_t, uint64_t))v153)(v131, v119, v145);
  return __swift_storeEnumTagSinglePayload(v118, 0, 1, v120);
}

uint64_t MLHandActionClassifier.DataSource.stratifiedSplit(proportions:seed:labelColumn:)(void *a1, uint64_t a2, uint64_t a3, void *a4, __m128 a5)
{
  uint64_t v8 = v6;
  uint64_t v34 = a4;
  v35._uint64_t countAndFlagsBits = a3;
  uint64_t v39 = a2;
  v35._char object = a1;
  uint64_t v36 = v5;
  uint64_t v9 = type metadata accessor for MLHandActionClassifier.DataSource(0);
  int64_t v10 = *(void *)(*(void *)(v9 - 8) + 64);
  uint64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  outlined init with copy of MLHandActionClassifier.DataSource(v7, (uint64_t)&v32);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v32, v9);
  if (EnumCaseMultiPayload == 5)
  {
    int64_t v17 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
    uint64_t v18 = v17[12];
    *(void *)uint64_t v37 = *(uint64_t *)((char *)&v32 + v18);
    *(void *)uint64_t v42 = *(uint64_t *)((char *)&v32 + v18 + 8);
    swift_bridgeObjectRelease(*(uint64_t *)((char *)&v32 + v17[16] + 8));
    swift_bridgeObjectRelease(*(uint64_t *)((char *)&v32 + v17[20] + 8));
    uint64_t v19 = type metadata accessor for DataFrame(0);
    (*(void (**)(uint64_t *, uint64_t))(*(void *)(v19 - 8) + 8))(&v32, v19);
LABEL_5:
    MLHandActionClassifier.DataSource.keypointsWithAnnotations(targetFrameRate:)((__m128)0x403E000000000000uLL);
    if (v8) {
      return swift_bridgeObjectRelease(v42[0]);
    }
    uint64_t v21 = v39;
    if (v39 >= 0)
    {
      uint64_t v22 = v40;
      int64_t v33 = v40;
      LOBYTE(v38) = v41;
      uint64_t v23 = type metadata accessor for MersenneTwisterGenerator();
      swift_allocObject(v23, 136, 7);
      uint64_t v40 = MersenneTwisterGenerator.init(seed:)(v21);
      char v24 = v38;
      uint64_t v25 = (uint64_t)v22;
      LOBYTE(v22) = v42[0];
      v31._char object = v34;
      v31._uint64_t countAndFlagsBits = v35._countAndFlagsBits;
      specialized stratifiedSplitBySequenceGenerator<A>(proportions:generator:dataTable:by:on:)((uint64_t)v35._object, (uint64_t)&v40, v25, v38, *(uint64_t *)v37, *(void **)v42, 30.0, v31);
      swift_bridgeObjectRelease((_BYTE)v22);
      swift_release();
      return outlined consume of Result<_DataTable, Error>((uint64_t)v33, v24);
    }
LABEL_13:
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, "Negative value is not representable", 35, 2, "Swift/Integers.swift", 20, 2, 3451, 1);
    BUG();
  }
  if (EnumCaseMultiPayload == 3)
  {
    uint64_t v38 = v32;
    *(void *)uint64_t v37 = v34;
    *(void *)uint64_t v42 = v35._countAndFlagsBits;
    char v14 = v32;
    char v15 = (char)v33;
    swift_bridgeObjectRelease(v36);
    char v16 = v14;
    uint64_t v8 = v6;
    swift_bridgeObjectRelease(v16);
    outlined consume of Result<_DataTable, Error>(v38, v15);
    goto LABEL_5;
  }
  MLHandActionClassifier.DataSource.videosWithAnnotations()(a5);
  if (v6) {
    return outlined destroy of MLHandActionClassifier.DataSource((uint64_t)&v32);
  }
  uint64_t v26 = v39;
  if (v39 < 0) {
    goto LABEL_13;
  }
  *(void *)uint64_t v42 = v40;
  unsigned __int8 v27 = v41;
  uint64_t v28 = type metadata accessor for MersenneTwisterGenerator();
  swift_allocObject(v28, 136, 7);
  uint64_t v40 = MersenneTwisterGenerator.init(seed:)(v26);
  int v29 = v27;
  LODWORD(v39) = v27;
  int64_t v30 = *(void **)v42;
  specialized stratifiedSplitGenerator<A>(proportions:generator:dataTable:on:)((uint64_t)v35._object, (uint64_t)&v40, *(void **)v42, v29, v35._countAndFlagsBits, v34, *(double *)a5.i64);
  swift_release();
  outlined consume of Result<_DataTable, Error>((uint64_t)v30, v39);
  return outlined destroy of MLHandActionClassifier.DataSource((uint64_t)&v32);
}

uint64_t outlined destroy of AnyColumn?(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

void *initializeBufferWithCopyOfBuffer for MLHandActionClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  int64_t v3 = (void *)a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v18 = *(void *)a2;
    void *v3 = *(void *)a2;
    int64_t v3 = (void *)(v18 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    switch(swift_getEnumCaseMultiPayload(a2, a3))
    {
      case 0u:
        uint64_t v6 = type metadata accessor for URL(0);
        char v52 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16);
        v52(a1, a2, v6);
        uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v52(a1 + v7[12], a2 + v7[12], v6);
        uint64_t v8 = v7[16];
        *(void *)(a1 + v8) = *(void *)(a2 + v8);
        uint64_t v9 = *(void *)(a2 + v8 + 8);
        *(void *)((char *)v3 + v8 + 8) = v9;
        uint64_t v10 = v7[20];
        *(void *)((char *)v3 + v10) = *(void *)(a2 + v10);
        uint64_t v53 = *(void *)(a2 + v10 + 8);
        *(void *)((char *)v3 + v10 + 8) = v53;
        uint64_t v11 = v7[24];
        *(void *)((char *)v3 + v11) = *(void *)(a2 + v11);
        uint64_t v12 = *(void *)(a2 + v11 + 8);
        *(void *)((char *)v3 + v11 + 8) = v12;
        uint64_t v13 = v7[28];
        *(void *)((char *)v3 + v13) = *(void *)(a2 + v13);
        uint64_t v14 = *(void *)(a2 + v13 + 8);
        *(void *)((char *)v3 + v13 + 8) = v14;
        swift_bridgeObjectRetain(v9);
        swift_bridgeObjectRetain(v53);
        swift_bridgeObjectRetain(v12);
        swift_bridgeObjectRetain(v14);
        char v15 = v3;
        uint64_t v16 = a3;
        uint64_t v17 = 0;
        goto LABEL_12;
      case 1u:
        uint64_t v19 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v19 - 8) + 16))(a1, a2, v19);
        uint64_t v51 = 1;
        goto LABEL_11;
      case 2u:
        uint64_t v20 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v20 - 8) + 16))(a1, a2, v20);
        uint64_t v51 = 2;
        goto LABEL_11;
      case 3u:
        uint64_t v21 = *(void *)a2;
        char v22 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(void *)a2, v22);
        *(void *)a1 = v21;
        *(unsigned char *)(a1 + 8) = v22;
        *(void *)(a1 + 16) = *(void *)(a2 + 16);
        uint64_t v23 = *(void *)(a2 + 24);
        v3[3] = v23;
        v3[4] = *(void *)(a2 + 32);
        uint64_t v24 = *(void *)(a2 + 40);
        v3[5] = v24;
        v3[6] = *(void *)(a2 + 48);
        uint64_t v25 = *(void *)(a2 + 56);
        v3[7] = v25;
        swift_bridgeObjectRetain(v23);
        swift_bridgeObjectRetain(v24);
        swift_bridgeObjectRetain(v25);
        uint64_t v51 = 3;
        goto LABEL_11;
      case 4u:
        uint64_t v26 = *(void *)a2;
        char v27 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(void *)a2, v27);
        *(void *)a1 = v26;
        *(unsigned char *)(a1 + 8) = v27;
        *(void *)(a1 + 16) = *(void *)(a2 + 16);
        uint64_t v28 = *(void *)(a2 + 24);
        v3[3] = v28;
        v3[4] = *(void *)(a2 + 32);
        uint64_t v29 = *(void *)(a2 + 40);
        v3[5] = v29;
        v3[6] = *(void *)(a2 + 48);
        uint64_t v30 = *(void *)(a2 + 56);
        v3[7] = v30;
        v3[8] = *(void *)(a2 + 64);
        uint64_t v31 = *(void *)(a2 + 72);
        v3[9] = v31;
        swift_bridgeObjectRetain(v28);
        swift_bridgeObjectRetain(v29);
        swift_bridgeObjectRetain(v30);
        swift_bridgeObjectRetain(v31);
        uint64_t v51 = 4;
        goto LABEL_11;
      case 5u:
        uint64_t v32 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v32 - 8) + 16))(a1, a2, v32);
        int64_t v33 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v34 = v33[12];
        *(void *)(a1 + v34) = *(void *)(a2 + v34);
        uint64_t v35 = *(void *)(a2 + v34 + 8);
        *(void *)((char *)v3 + v34 + 8) = v35;
        uint64_t v36 = v33[16];
        *(void *)((char *)v3 + v36) = *(void *)(a2 + v36);
        uint64_t v37 = *(void *)(a2 + v36 + 8);
        *(void *)((char *)v3 + v36 + 8) = v37;
        uint64_t v38 = v33[20];
        *(void *)((char *)v3 + v38) = *(void *)(a2 + v38);
        uint64_t v39 = *(void *)(a2 + v38 + 8);
        *(void *)((char *)v3 + v38 + 8) = v39;
        swift_bridgeObjectRetain(v35);
        swift_bridgeObjectRetain(v37);
        swift_bridgeObjectRetain(v39);
        uint64_t v51 = 5;
        goto LABEL_11;
      case 6u:
        uint64_t v40 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v40 - 8) + 16))(a1, a2, v40);
        unsigned __int8 v41 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        uint64_t v42 = v41[12];
        *(void *)(a1 + v42) = *(void *)(a2 + v42);
        uint64_t v43 = *(void *)(a2 + v42 + 8);
        *(void *)((char *)v3 + v42 + 8) = v43;
        uint64_t v44 = v41[16];
        *(void *)((char *)v3 + v44) = *(void *)(a2 + v44);
        uint64_t v45 = *(void *)(a2 + v44 + 8);
        *(void *)((char *)v3 + v44 + 8) = v45;
        uint64_t v46 = v41[20];
        *(void *)((char *)v3 + v46) = *(void *)(a2 + v46);
        uint64_t v47 = *(void *)(a2 + v46 + 8);
        *(void *)((char *)v3 + v46 + 8) = v47;
        uint64_t v48 = v41[24];
        *(void *)((char *)v3 + v48) = *(void *)(a2 + v48);
        uint64_t v49 = *(void *)(a2 + v48 + 8);
        *(void *)((char *)v3 + v48 + 8) = v49;
        swift_bridgeObjectRetain(v43);
        swift_bridgeObjectRetain(v45);
        swift_bridgeObjectRetain(v47);
        swift_bridgeObjectRetain(v49);
        uint64_t v51 = 6;
LABEL_11:
        uint64_t v17 = v51;
        char v15 = v3;
        uint64_t v16 = a3;
LABEL_12:
        swift_storeEnumTagMultiPayload(v15, v16, v17);
        break;
    }
  }
  return v3;
}

uint64_t destroy for MLHandActionClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t result = swift_getEnumCaseMultiPayload(a1, a2);
  switch((int)result)
  {
    case 0:
      uint64_t v4 = type metadata accessor for URL(0);
      uint64_t v5 = *(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8);
      v5(a1, v4);
      uint64_t v6 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      v5(a1 + v6[12], v4);
      swift_bridgeObjectRelease(*(void *)(a1 + v6[16] + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + v6[20] + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + v6[24] + 8));
      uint64_t v7 = v6[28];
      goto LABEL_8;
    case 1:
    case 2:
      uint64_t v3 = type metadata accessor for URL(0);
      return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8))(a1, v3);
    case 3:
      outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + 24));
      swift_bridgeObjectRelease(*(void *)(a1 + 40));
      return swift_bridgeObjectRelease(*(void *)(a1 + 56));
    case 4:
      outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + 24));
      swift_bridgeObjectRelease(*(void *)(a1 + 40));
      swift_bridgeObjectRelease(*(void *)(a1 + 56));
      return swift_bridgeObjectRelease(*(void *)(a1 + 72));
    case 5:
      uint64_t v8 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v8 - 8) + 8))(a1, v8);
      uint64_t v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      swift_bridgeObjectRelease(*(void *)(a1 + v9[12] + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + v9[16] + 8));
      uint64_t v7 = v9[20];
      goto LABEL_8;
    case 6:
      uint64_t v10 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v10 - 8) + 8))(a1, v10);
      uint64_t v11 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      swift_bridgeObjectRelease(*(void *)(a1 + v11[12] + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + v11[16] + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + v11[20] + 8));
      uint64_t v7 = v11[24];
LABEL_8:
      uint64_t result = swift_bridgeObjectRelease(*(void *)(a1 + v7 + 8));
      break;
    default:
      return result;
  }
  return result;
}

uint64_t initializeWithCopy for MLHandActionClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  switch(swift_getEnumCaseMultiPayload(a2, a3))
  {
    case 0u:
      uint64_t v5 = type metadata accessor for URL(0);
      uint64_t v6 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16);
      v6(a1, a2, v5);
      uint64_t v52 = a3;
      uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      v6(a1 + v7[12], a2 + v7[12], v5);
      uint64_t v8 = v7[16];
      *(void *)(a1 + v8) = *(void *)(a2 + v8);
      uint64_t v9 = *(void *)(a2 + v8 + 8);
      *(void *)(a1 + v8 + 8) = v9;
      uint64_t v10 = v7[20];
      *(void *)(a1 + v10) = *(void *)(a2 + v10);
      uint64_t v11 = *(void *)(a2 + v10 + 8);
      *(void *)(a1 + v10 + 8) = v11;
      uint64_t v12 = v7[24];
      *(void *)(a1 + v12) = *(void *)(a2 + v12);
      uint64_t v13 = *(void *)(a2 + v12 + 8);
      *(void *)(a1 + v12 + 8) = v13;
      uint64_t v14 = v7[28];
      *(void *)(a1 + v14) = *(void *)(a2 + v14);
      uint64_t v15 = *(void *)(a2 + v14 + 8);
      *(void *)(a1 + v14 + 8) = v15;
      swift_bridgeObjectRetain(v9);
      swift_bridgeObjectRetain(v11);
      swift_bridgeObjectRetain(v13);
      swift_bridgeObjectRetain(v15);
      uint64_t v16 = a1;
      uint64_t v17 = v52;
      uint64_t v18 = 0;
      goto LABEL_10;
    case 1u:
      uint64_t v19 = type metadata accessor for URL(0);
      (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v19 - 8) + 16))(a1, a2, v19);
      uint64_t v51 = 1;
      goto LABEL_9;
    case 2u:
      uint64_t v20 = type metadata accessor for URL(0);
      (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v20 - 8) + 16))(a1, a2, v20);
      uint64_t v51 = 2;
      goto LABEL_9;
    case 3u:
      uint64_t v21 = *(void *)a2;
      char v22 = *(unsigned char *)(a2 + 8);
      outlined copy of Result<_DataTable, Error>(*(void *)a2, v22);
      *(void *)a1 = v21;
      *(unsigned char *)(a1 + 8) = v22;
      *(void *)(a1 + 16) = *(void *)(a2 + 16);
      uint64_t v23 = *(void *)(a2 + 24);
      *(void *)(a1 + 24) = v23;
      *(void *)(a1 + 32) = *(void *)(a2 + 32);
      uint64_t v24 = *(void *)(a2 + 40);
      *(void *)(a1 + 40) = v24;
      *(void *)(a1 + 48) = *(void *)(a2 + 48);
      uint64_t v25 = *(void *)(a2 + 56);
      *(void *)(a1 + 56) = v25;
      swift_bridgeObjectRetain(v23);
      swift_bridgeObjectRetain(v24);
      swift_bridgeObjectRetain(v25);
      uint64_t v51 = 3;
      goto LABEL_9;
    case 4u:
      uint64_t v26 = *(void *)a2;
      char v27 = *(unsigned char *)(a2 + 8);
      outlined copy of Result<_DataTable, Error>(*(void *)a2, v27);
      *(void *)a1 = v26;
      *(unsigned char *)(a1 + 8) = v27;
      *(void *)(a1 + 16) = *(void *)(a2 + 16);
      uint64_t v28 = *(void *)(a2 + 24);
      *(void *)(a1 + 24) = v28;
      *(void *)(a1 + 32) = *(void *)(a2 + 32);
      uint64_t v29 = *(void *)(a2 + 40);
      *(void *)(a1 + 40) = v29;
      *(void *)(a1 + 48) = *(void *)(a2 + 48);
      uint64_t v30 = *(void *)(a2 + 56);
      *(void *)(a1 + 56) = v30;
      *(void *)(a1 + 64) = *(void *)(a2 + 64);
      uint64_t v31 = *(void *)(a2 + 72);
      *(void *)(a1 + 72) = v31;
      swift_bridgeObjectRetain(v28);
      swift_bridgeObjectRetain(v29);
      swift_bridgeObjectRetain(v30);
      swift_bridgeObjectRetain(v31);
      uint64_t v51 = 4;
      goto LABEL_9;
    case 5u:
      uint64_t v32 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v32 - 8) + 16))(a1, a2, v32);
      int64_t v33 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      uint64_t v34 = v33[12];
      *(void *)(a1 + v34) = *(void *)(a2 + v34);
      uint64_t v35 = *(void *)(a2 + v34 + 8);
      *(void *)(a1 + v34 + 8) = v35;
      uint64_t v36 = v33[16];
      *(void *)(a1 + v36) = *(void *)(a2 + v36);
      uint64_t v37 = *(void *)(a2 + v36 + 8);
      *(void *)(a1 + v36 + 8) = v37;
      uint64_t v38 = v33[20];
      *(void *)(a1 + v38) = *(void *)(a2 + v38);
      uint64_t v39 = *(void *)(a2 + v38 + 8);
      *(void *)(a1 + v38 + 8) = v39;
      swift_bridgeObjectRetain(v35);
      swift_bridgeObjectRetain(v37);
      swift_bridgeObjectRetain(v39);
      uint64_t v51 = 5;
      goto LABEL_9;
    case 6u:
      uint64_t v40 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v40 - 8) + 16))(a1, a2, v40);
      unsigned __int8 v41 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      uint64_t v42 = v41[12];
      *(void *)(a1 + v42) = *(void *)(a2 + v42);
      uint64_t v43 = *(void *)(a2 + v42 + 8);
      *(void *)(a1 + v42 + 8) = v43;
      uint64_t v44 = v41[16];
      *(void *)(a1 + v44) = *(void *)(a2 + v44);
      uint64_t v45 = *(void *)(a2 + v44 + 8);
      *(void *)(a1 + v44 + 8) = v45;
      uint64_t v46 = v41[20];
      *(void *)(a1 + v46) = *(void *)(a2 + v46);
      uint64_t v47 = *(void *)(a2 + v46 + 8);
      *(void *)(a1 + v46 + 8) = v47;
      uint64_t v48 = v41[24];
      *(void *)(a1 + v48) = *(void *)(a2 + v48);
      uint64_t v49 = *(void *)(a2 + v48 + 8);
      *(void *)(a1 + v48 + 8) = v49;
      swift_bridgeObjectRetain(v43);
      swift_bridgeObjectRetain(v45);
      swift_bridgeObjectRetain(v47);
      swift_bridgeObjectRetain(v49);
      uint64_t v51 = 6;
LABEL_9:
      uint64_t v18 = v51;
      uint64_t v16 = a1;
      uint64_t v17 = a3;
LABEL_10:
      swift_storeEnumTagMultiPayload(v16, v17, v18);
      return a1;
  }
}

uint64_t assignWithCopy for MLHandActionClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLHandActionClassifier.DataSource(a1);
    switch(swift_getEnumCaseMultiPayload(a2, a3))
    {
      case 0u:
        uint64_t v5 = type metadata accessor for URL(0);
        unint64_t v50 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16);
        v50(a1, a2, v5);
        uint64_t v6 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v50(a1 + v6[12], a2 + v6[12], v5);
        uint64_t v7 = v6[16];
        *(void *)(a1 + v7) = *(void *)(a2 + v7);
        uint64_t v8 = *(void *)(a2 + v7 + 8);
        *(void *)(a1 + v7 + 8) = v8;
        uint64_t v9 = v6[20];
        *(void *)(a1 + v9) = *(void *)(a2 + v9);
        uint64_t v51 = *(void *)(a2 + v9 + 8);
        *(void *)(a1 + v9 + 8) = v51;
        uint64_t v10 = v6[24];
        *(void *)(a1 + v10) = *(void *)(a2 + v10);
        uint64_t v11 = *(void *)(a2 + v10 + 8);
        *(void *)(a1 + v10 + 8) = v11;
        uint64_t v12 = v6[28];
        *(void *)(a1 + v12) = *(void *)(a2 + v12);
        uint64_t v13 = *(void *)(a2 + v12 + 8);
        *(void *)(a1 + v12 + 8) = v13;
        swift_bridgeObjectRetain(v8);
        swift_bridgeObjectRetain(v51);
        swift_bridgeObjectRetain(v11);
        swift_bridgeObjectRetain(v13);
        uint64_t v14 = a1;
        uint64_t v15 = a3;
        uint64_t v16 = 0;
        goto LABEL_11;
      case 1u:
        uint64_t v17 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v17 - 8) + 16))(a1, a2, v17);
        uint64_t v49 = 1;
        goto LABEL_10;
      case 2u:
        uint64_t v18 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v18 - 8) + 16))(a1, a2, v18);
        uint64_t v49 = 2;
        goto LABEL_10;
      case 3u:
        uint64_t v19 = *(void *)a2;
        char v20 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(void *)a2, v20);
        *(void *)a1 = v19;
        *(unsigned char *)(a1 + 8) = v20;
        *(void *)(a1 + 16) = *(void *)(a2 + 16);
        uint64_t v21 = *(void *)(a2 + 24);
        *(void *)(a1 + 24) = v21;
        *(void *)(a1 + 32) = *(void *)(a2 + 32);
        uint64_t v22 = *(void *)(a2 + 40);
        *(void *)(a1 + 40) = v22;
        *(void *)(a1 + 48) = *(void *)(a2 + 48);
        uint64_t v23 = *(void *)(a2 + 56);
        *(void *)(a1 + 56) = v23;
        swift_bridgeObjectRetain(v21);
        swift_bridgeObjectRetain(v22);
        swift_bridgeObjectRetain(v23);
        uint64_t v49 = 3;
        goto LABEL_10;
      case 4u:
        uint64_t v24 = *(void *)a2;
        char v25 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(void *)a2, v25);
        *(void *)a1 = v24;
        *(unsigned char *)(a1 + 8) = v25;
        *(void *)(a1 + 16) = *(void *)(a2 + 16);
        uint64_t v26 = *(void *)(a2 + 24);
        *(void *)(a1 + 24) = v26;
        *(void *)(a1 + 32) = *(void *)(a2 + 32);
        uint64_t v27 = *(void *)(a2 + 40);
        *(void *)(a1 + 40) = v27;
        *(void *)(a1 + 48) = *(void *)(a2 + 48);
        uint64_t v28 = *(void *)(a2 + 56);
        *(void *)(a1 + 56) = v28;
        *(void *)(a1 + 64) = *(void *)(a2 + 64);
        uint64_t v29 = *(void *)(a2 + 72);
        *(void *)(a1 + 72) = v29;
        swift_bridgeObjectRetain(v26);
        swift_bridgeObjectRetain(v27);
        swift_bridgeObjectRetain(v28);
        swift_bridgeObjectRetain(v29);
        uint64_t v49 = 4;
        goto LABEL_10;
      case 5u:
        uint64_t v30 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v30 - 8) + 16))(a1, a2, v30);
        uint64_t v31 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v32 = v31[12];
        *(void *)(a1 + v32) = *(void *)(a2 + v32);
        uint64_t v33 = *(void *)(a2 + v32 + 8);
        *(void *)(a1 + v32 + 8) = v33;
        uint64_t v34 = v31[16];
        *(void *)(a1 + v34) = *(void *)(a2 + v34);
        uint64_t v35 = *(void *)(a2 + v34 + 8);
        *(void *)(a1 + v34 + 8) = v35;
        uint64_t v36 = v31[20];
        *(void *)(a1 + v36) = *(void *)(a2 + v36);
        uint64_t v37 = *(void *)(a2 + v36 + 8);
        *(void *)(a1 + v36 + 8) = v37;
        swift_bridgeObjectRetain(v33);
        swift_bridgeObjectRetain(v35);
        swift_bridgeObjectRetain(v37);
        uint64_t v49 = 5;
        goto LABEL_10;
      case 6u:
        uint64_t v38 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v38 - 8) + 16))(a1, a2, v38);
        uint64_t v39 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        uint64_t v40 = v39[12];
        *(void *)(a1 + v40) = *(void *)(a2 + v40);
        uint64_t v41 = *(void *)(a2 + v40 + 8);
        *(void *)(a1 + v40 + 8) = v41;
        uint64_t v42 = v39[16];
        *(void *)(a1 + v42) = *(void *)(a2 + v42);
        uint64_t v43 = *(void *)(a2 + v42 + 8);
        *(void *)(a1 + v42 + 8) = v43;
        uint64_t v44 = v39[20];
        *(void *)(a1 + v44) = *(void *)(a2 + v44);
        uint64_t v45 = *(void *)(a2 + v44 + 8);
        *(void *)(a1 + v44 + 8) = v45;
        uint64_t v46 = v39[24];
        *(void *)(a1 + v46) = *(void *)(a2 + v46);
        uint64_t v47 = *(void *)(a2 + v46 + 8);
        *(void *)(a1 + v46 + 8) = v47;
        swift_bridgeObjectRetain(v41);
        swift_bridgeObjectRetain(v43);
        swift_bridgeObjectRetain(v45);
        swift_bridgeObjectRetain(v47);
        uint64_t v49 = 6;
LABEL_10:
        uint64_t v16 = v49;
        uint64_t v14 = a1;
        uint64_t v15 = a3;
LABEL_11:
        swift_storeEnumTagMultiPayload(v14, v15, v16);
        break;
    }
  }
  return a1;
}

char *initializeWithTake for MLHandActionClassifier.DataSource(char *__dst, char *__src, uint64_t a3)
{
  switch(swift_getEnumCaseMultiPayload(__src, a3))
  {
    case 0u:
      uint64_t v4 = type metadata accessor for URL(0);
      uint64_t v16 = *(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 32);
      v16(__dst, __src, v4);
      uint64_t v5 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      v16(&__dst[v5[12]], &__src[v5[12]], v4);
      *(_OWORD *)&__dst[v5[16]] = *(_OWORD *)&__src[v5[16]];
      *(_OWORD *)&__dst[v5[20]] = *(_OWORD *)&__src[v5[20]];
      *(_OWORD *)&__dst[v5[24]] = *(_OWORD *)&__src[v5[24]];
      *(_OWORD *)&__dst[v5[28]] = *(_OWORD *)&__src[v5[28]];
      uint64_t v6 = a3;
      uint64_t v7 = 0;
      goto LABEL_9;
    case 1u:
      uint64_t v8 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
      uint64_t v15 = 1;
      goto LABEL_8;
    case 2u:
      uint64_t v9 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
      uint64_t v15 = 2;
      goto LABEL_8;
    case 5u:
      uint64_t v10 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
      uint64_t v11 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      *(_OWORD *)&__dst[v11[12]] = *(_OWORD *)&__src[v11[12]];
      *(_OWORD *)&__dst[v11[16]] = *(_OWORD *)&__src[v11[16]];
      *(_OWORD *)&__dst[v11[20]] = *(_OWORD *)&__src[v11[20]];
      uint64_t v15 = 5;
      goto LABEL_8;
    case 6u:
      uint64_t v12 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
      uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      *(_OWORD *)&__dst[v13[12]] = *(_OWORD *)&__src[v13[12]];
      *(_OWORD *)&__dst[v13[16]] = *(_OWORD *)&__src[v13[16]];
      *(_OWORD *)&__dst[v13[20]] = *(_OWORD *)&__src[v13[20]];
      *(_OWORD *)&__dst[v13[24]] = *(_OWORD *)&__src[v13[24]];
      uint64_t v15 = 6;
LABEL_8:
      uint64_t v7 = v15;
      uint64_t v6 = a3;
LABEL_9:
      swift_storeEnumTagMultiPayload(__dst, v6, v7);
      break;
    default:
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
      break;
  }
  return __dst;
}

char *assignWithTake for MLHandActionClassifier.DataSource(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLHandActionClassifier.DataSource((uint64_t)__dst);
    switch(swift_getEnumCaseMultiPayload(__src, a3))
    {
      case 0u:
        uint64_t v4 = type metadata accessor for URL(0);
        uint64_t v16 = *(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 32);
        v16(__dst, __src, v4);
        uint64_t v5 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v16(&__dst[v5[12]], &__src[v5[12]], v4);
        *(_OWORD *)&__dst[v5[16]] = *(_OWORD *)&__src[v5[16]];
        *(_OWORD *)&__dst[v5[20]] = *(_OWORD *)&__src[v5[20]];
        *(_OWORD *)&__dst[v5[24]] = *(_OWORD *)&__src[v5[24]];
        *(_OWORD *)&__dst[v5[28]] = *(_OWORD *)&__src[v5[28]];
        uint64_t v6 = a3;
        uint64_t v7 = 0;
        goto LABEL_10;
      case 1u:
        uint64_t v8 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
        uint64_t v15 = 1;
        goto LABEL_9;
      case 2u:
        uint64_t v9 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
        uint64_t v15 = 2;
        goto LABEL_9;
      case 5u:
        uint64_t v10 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
        uint64_t v11 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        *(_OWORD *)&__dst[v11[12]] = *(_OWORD *)&__src[v11[12]];
        *(_OWORD *)&__dst[v11[16]] = *(_OWORD *)&__src[v11[16]];
        *(_OWORD *)&__dst[v11[20]] = *(_OWORD *)&__src[v11[20]];
        uint64_t v15 = 5;
        goto LABEL_9;
      case 6u:
        uint64_t v12 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
        uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        *(_OWORD *)&__dst[v13[12]] = *(_OWORD *)&__src[v13[12]];
        *(_OWORD *)&__dst[v13[16]] = *(_OWORD *)&__src[v13[16]];
        *(_OWORD *)&__dst[v13[20]] = *(_OWORD *)&__src[v13[20]];
        *(_OWORD *)&__dst[v13[24]] = *(_OWORD *)&__src[v13[24]];
        uint64_t v15 = 6;
LABEL_9:
        uint64_t v7 = v15;
        uint64_t v6 = a3;
LABEL_10:
        swift_storeEnumTagMultiPayload(__dst, v6, v7);
        break;
      default:
        memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
        break;
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLHandActionClassifier.DataSource(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for URL(319);
  uint64_t v2 = v1;
  if (v3 <= 0x3F)
  {
    uint64_t v21 = a1;
    uint64_t v4 = *(void *)(v1 - 8) + 64;
    uint64_t v13 = v4;
    uint64_t v14 = (void *)v4;
    uint64_t v15 = &unk_350010;
    uint64_t v16 = &unk_350010;
    uint64_t v17 = &unk_350028;
    uint64_t v18 = &unk_350028;
    swift_getTupleTypeLayout(v11, 0, 6);
    v20[0] = v11;
    v20[1] = v4;
    v20[2] = v4;
    v20[3] = &unk_350040;
    void v20[4] = &unk_350058;
    uint64_t v5 = type metadata accessor for DataFrame(319);
    uint64_t v2 = v5;
    if (v6 <= 0x3F)
    {
      uint64_t v13 = *(void *)(v5 - 8) + 64;
      uint64_t v7 = v13;
      uint64_t v14 = &unk_350010;
      uint64_t v15 = &unk_350010;
      uint64_t v16 = &unk_350010;
      uint64_t v2 = 0;
      swift_getTupleTypeLayout(v19, 0, 4);
      v20[5] = v19;
      uint64_t v13 = v7;
      uint64_t v14 = &unk_350010;
      uint64_t v15 = &unk_350010;
      uint64_t v16 = &unk_350028;
      uint64_t v17 = &unk_350028;
      swift_getTupleTypeLayout(v12, 0, 5);
      v20[6] = v12;
      swift_initEnumMetadataMultiPayload(v21, 256, 7, v20, v8, v9);
    }
  }
  return v2;
}

uint64_t MLPhase.rawValue.getter()
{
  switch(*v0)
  {
    case 0:
      uint64_t result = 0x696C616974696E69;
      break;
    case 1:
      uint64_t result = 0x6974636172747865;
      break;
    case 2:
      uint64_t result = 0x676E696E69617274;
      break;
    case 3:
      uint64_t result = 0x697461756C617665;
      break;
    case 4:
      uint64_t result = 0x636E657265666E69;
      break;
  }
  return result;
}

CreateML::MLPhase_optional __swiftcall MLPhase.init(rawValue:)(Swift::String rawValue)
{
  uint64_t v2 = v1;
  unint64_t v3 = _findStringSwitchCase(cases:string:)((Swift::OpaquePointer)&outlined read-only object #0 of MLPhase.init(rawValue:), rawValue);
  swift_bridgeObjectRelease(rawValue._object);
  result.value = CreateML_MLPhase_unknownDefault;
  if (v3 < 5) {
    result.value = (char)v3;
  }
  v2->value = result.value;
  return result;
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance MLPhase(unsigned __int8 *a1, char *a2)
{
  return specialized == infix<A>(_:_:)(*a1, *a2);
}

uint64_t base witness table accessor for Equatable in MLPhase()
{
  return lazy protocol witness table accessor for type MLPhase and conformance MLPhase();
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLPhase()
{
  return specialized RawRepresentable<>.hashValue.getter(*v0);
}

uint64_t protocol witness for Hashable.hash(into:) in conformance MLPhase(uint64_t a1)
{
  return specialized RawRepresentable<>.hash(into:)(a1, *v1);
}

Swift::Int protocol witness for Hashable._rawHashValue(seed:) in conformance MLPhase(uint64_t a1)
{
  return specialized RawRepresentable<>._rawHashValue(seed:)(a1, *v1);
}

CreateML::MLPhase_optional protocol witness for RawRepresentable.init(rawValue:) in conformance MLPhase(Swift::String *a1)
{
  return MLPhase.init(rawValue:)(*a1);
}

uint64_t protocol witness for RawRepresentable.rawValue.getter in conformance MLPhase(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t result = MLPhase.rawValue.getter(a1);
  uint64_t *v2 = result;
  v2[1] = v4;
  return result;
}

uint64_t protocol witness for Decodable.init(from:) in conformance MLPhase(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = lazy protocol witness table accessor for type MLPhase and conformance MLPhase();
  return RawRepresentable<>.init(from:)(a1, a2, a3, v3);
}

uint64_t protocol witness for Encodable.encode(to:) in conformance MLPhase(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = lazy protocol witness table accessor for type MLPhase and conformance MLPhase();
  return RawRepresentable<>.encode(to:)(a1, a2, a3, v4);
}

uint64_t getEnumTagSinglePayload for MLPhase(unsigned __int8 *a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 < 0xFC) {
      goto LABEL_13;
    }
    unsigned int v2 = a2 + 4;
    int v3 = 1;
    if (v2 >= 0xFF00) {
      int v3 = 2 * (v2 >= 0xFFFF00) + 2;
    }
    if (v3 == 4) {
      int v4 = *(_DWORD *)(a1 + 1);
    }
    else {
      int v4 = v3 == 2 ? *(unsigned __int16 *)(a1 + 1) : a1[1];
    }
    if (v4)
    {
      int v5 = *a1 + (v4 << 8) - 5;
    }
    else
    {
LABEL_13:
      unsigned int v6 = *a1;
      int v7 = v6 - 5;
      BOOL v8 = v6 < 5;
      int v5 = -1;
      if (!v8) {
        int v5 = v7;
      }
    }
  }
  else
  {
    int v5 = -1;
  }
  return (v5 + 1);
}

uint64_t storeEnumTagSinglePayload for MLPhase(unsigned char *a1, unsigned int a2, unsigned int a3)
{
  LODWORD(result) = 0;
  if (a3 >= 0xFC)
  {
    unsigned int v4 = a3 + 4;
    LODWORD(result) = 1;
    if (v4 >= 0xFF00) {
      LODWORD(result) = 2 * (v4 >= 0xFFFF00) + 2;
    }
  }
  if (a2 > 0xFB)
  {
    unsigned int v5 = a2 - 252;
    int v6 = (v5 >> 8) + 1;
    *a1 = v5;
    uint64_t result = result;
    switch((int)result)
    {
      case 0:
        return result;
      case 1:
        a1[1] = v6;
        break;
      case 2:
        *(_WORD *)(a1 + 1) = v6;
        break;
      case 3:
LABEL_16:
        BUG();
      case 4:
        *(_DWORD *)(a1 + 1) = v6;
        break;
    }
  }
  else
  {
    uint64_t result = result;
    switch((int)result)
    {
      case 0:
        goto LABEL_11;
      case 1:
        a1[1] = 0;
        goto LABEL_11;
      case 2:
        *(_WORD *)(a1 + 1) = 0;
        goto LABEL_11;
      case 3:
        goto LABEL_16;
      case 4:
        *(_DWORD *)(a1 + 1) = 0;
LABEL_11:
        if (a2) {
          *a1 = a2 + 4;
        }
        break;
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for MLPhase()
{
  return &type metadata for MLPhase;
}

char static MLBoundingBoxUnits.== infix(_:_:)(unsigned char *a1, unsigned char *a2)
{
  return *a2 ^ *a1 ^ 1;
}

void MLBoundingBoxUnits.hash(into:)()
{
  Hasher._combine(_:)(*v0);
}

Swift::Int MLBoundingBoxUnits.hashValue.getter()
{
  Swift::UInt v1 = *v0;
  Hasher.init(_seed:)(0);
  Hasher._combine(_:)(v1);
  return Hasher._finalize()();
}

char protocol witness for static Equatable.== infix(_:_:) in conformance MLBoundingBoxUnits(unsigned char *a1, unsigned char *a2)
{
  return static MLBoundingBoxUnits.== infix(_:_:)(a1, a2);
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLBoundingBoxUnits()
{
  return MLBoundingBoxUnits.hashValue.getter();
}

void protocol witness for Hashable.hash(into:) in conformance MLBoundingBoxUnits()
{
}

uint64_t base witness table accessor for Equatable in MLBoundingBoxUnits()
{
  return lazy protocol witness table accessor for type MLBoundingBoxUnits and conformance MLBoundingBoxUnits();
}

uint64_t lazy protocol witness table accessor for type MLBoundingBoxUnits and conformance MLBoundingBoxUnits()
{
  uint64_t result = lazy protocol witness table cache variable for type MLBoundingBoxUnits and conformance MLBoundingBoxUnits;
  if (!lazy protocol witness table cache variable for type MLBoundingBoxUnits and conformance MLBoundingBoxUnits)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLBoundingBoxUnits, &type metadata for MLBoundingBoxUnits);
    lazy protocol witness table cache variable for type MLBoundingBoxUnits and conformance MLBoundingBoxUnits = result;
  }
  return result;
}

ValueMetadata *type metadata accessor for MLBoundingBoxUnits()
{
  return &type metadata for MLBoundingBoxUnits;
}

uint64_t Column<A>.parseAsJSONArrays()()
{
  return Column<A>.parseAsJSONArrays()(&demangling cache variable for type metadata for Column<String>, (uint64_t)closure #1 in Column<A>.parseAsJSONArrays());
}

{
  return Column<A>.parseAsJSONArrays()(&demangling cache variable for type metadata for Column<Data>, (uint64_t)closure #1 in Column<A>.parseAsJSONArrays());
}

uint64_t AnyColumn.convertedToFloats()()
{
  uint64_t v67 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  uint64_t v66 = *(void *)(v67 - 8);
  int64_t v0 = *(void *)(v66 + 64);
  Swift::UInt v1 = alloca(v0);
  unsigned int v2 = alloca(v0);
  uint64_t v68 = v55;
  uint64_t v64 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Float>);
  uint64_t v63 = *(void *)(v64 - 8);
  int64_t v3 = *(void *)(v63 + 64);
  unsigned int v4 = alloca(v3);
  unsigned int v5 = alloca(v3);
  uint64_t v65 = v55;
  uint64_t v62 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v61 = *(void *)(v62 - 8);
  int64_t v6 = *(void *)(v61 + 64);
  int v7 = alloca(v6);
  BOOL v8 = alloca(v6);
  uint64_t v56 = v55;
  uint64_t v60 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int64>);
  uint64_t v59 = *(void *)(v60 - 8);
  int64_t v9 = *(void *)(v59 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v57 = v55;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int32>);
  uint64_t v13 = *(void *)(v12 - 8);
  int64_t v14 = *(void *)(v13 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  char v58 = v55;
  uint64_t v69 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int8>);
  uint64_t v70 = *(void *)(v69 - 8);
  int64_t v17 = *(void *)(v70 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v20 = AnyColumn.wrappedElementType.getter();
  if (swift_dynamicCastMetatype(v20, &type metadata for Int8))
  {
    double v21 = AnyColumn.assumingType<A>(_:)(&type metadata for Int8, &type metadata for Int8);
    uint64_t v22 = AnyColumn.count.getter(v21);
    uint64_t v23 = alloca(24);
    uint64_t v24 = alloca(32);
    uint64_t v56 = v55;
    uint64_t v25 = specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(v22, (void (*)(void *, uint64_t *))partial apply for closure #1 in AnyColumn.convertedToFloats(), (uint64_t)v55, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
    uint64_t v26 = v55;
    uint64_t v27 = v69;
    uint64_t v28 = v70;
  }
  else
  {
    uint64_t v29 = v58;
    uint64_t v70 = v12;
    uint64_t v69 = v13;
    uint64_t v30 = v57;
    uint64_t v31 = v56;
    if (swift_dynamicCastMetatype(v20, &type metadata for Int32))
    {
      double v32 = AnyColumn.assumingType<A>(_:)(&type metadata for Int32, &type metadata for Int32);
      uint64_t v33 = AnyColumn.count.getter(v32);
      uint64_t v34 = alloca(24);
      uint64_t v35 = alloca(32);
      uint64_t v56 = v29;
      uint64_t v25 = specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(v33, (void (*)(void *, uint64_t *))partial apply for closure #2 in AnyColumn.convertedToFloats(), (uint64_t)v55, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
      uint64_t v26 = v29;
      uint64_t v27 = v70;
      uint64_t v28 = v69;
    }
    else if (swift_dynamicCastMetatype(v20, &type metadata for Int64))
    {
      double v36 = AnyColumn.assumingType<A>(_:)(&type metadata for Int64, &type metadata for Int64);
      uint64_t v37 = AnyColumn.count.getter(v36);
      uint64_t v38 = alloca(24);
      uint64_t v39 = alloca(32);
      uint64_t v56 = v30;
      uint64_t v25 = specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(v37, (void (*)(void *, uint64_t *))partial apply for closure #3 in AnyColumn.convertedToFloats(), (uint64_t)v55, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
      uint64_t v26 = v30;
      uint64_t v27 = v60;
      uint64_t v28 = v59;
    }
    else if (swift_dynamicCastMetatype(v20, &type metadata for Int))
    {
      double v40 = AnyColumn.assumingType<A>(_:)(&type metadata for Int, &type metadata for Int);
      uint64_t v41 = AnyColumn.count.getter(v40);
      uint64_t v42 = alloca(24);
      uint64_t v43 = alloca(32);
      uint64_t v56 = v31;
      uint64_t v25 = specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(v41, (void (*)(void *, uint64_t *))partial apply for closure #4 in AnyColumn.convertedToFloats(), (uint64_t)v55, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
      uint64_t v26 = v31;
      uint64_t v27 = v62;
      uint64_t v28 = v61;
    }
    else if (swift_dynamicCastMetatype(v20, &type metadata for Float))
    {
      uint64_t v44 = v65;
      double v45 = AnyColumn.assumingType<A>(_:)(&type metadata for Float, &type metadata for Float);
      uint64_t v46 = AnyColumn.count.getter(v45);
      uint64_t v47 = alloca(24);
      uint64_t v48 = alloca(32);
      uint64_t v56 = v44;
      uint64_t v25 = specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(v46, (void (*)(void *, uint64_t *))partial apply for closure #5 in AnyColumn.convertedToFloats(), (uint64_t)v55, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
      uint64_t v26 = v44;
      uint64_t v27 = v64;
      uint64_t v28 = v63;
    }
    else
    {
      if (!swift_dynamicCastMetatype(v20, &type metadata for Double)) {
        return 0;
      }
      uint64_t v49 = v68;
      double v50 = AnyColumn.assumingType<A>(_:)(&type metadata for Double, &type metadata for Double);
      uint64_t v51 = AnyColumn.count.getter(v50);
      uint64_t v52 = alloca(24);
      uint64_t v53 = alloca(32);
      uint64_t v56 = v49;
      uint64_t v25 = specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(v51, (void (*)(void *, uint64_t *))partial apply for closure #6 in AnyColumn.convertedToFloats(), (uint64_t)v55, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
      uint64_t v26 = v49;
      uint64_t v27 = v67;
      uint64_t v28 = v66;
    }
  }
  (*(void (**)(unsigned char *, uint64_t))(v28 + 8))(v26, v27);
  return v25;
}

uint64_t AnyColumn.convertedToDoubles()()
{
  uint64_t v67 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  uint64_t v66 = *(void *)(v67 - 8);
  int64_t v0 = *(void *)(v66 + 64);
  Swift::UInt v1 = alloca(v0);
  unsigned int v2 = alloca(v0);
  uint64_t v68 = v55;
  uint64_t v64 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Float>);
  uint64_t v63 = *(void *)(v64 - 8);
  int64_t v3 = *(void *)(v63 + 64);
  unsigned int v4 = alloca(v3);
  unsigned int v5 = alloca(v3);
  uint64_t v65 = v55;
  uint64_t v62 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v61 = *(void *)(v62 - 8);
  int64_t v6 = *(void *)(v61 + 64);
  int v7 = alloca(v6);
  BOOL v8 = alloca(v6);
  uint64_t v56 = v55;
  uint64_t v60 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int64>);
  uint64_t v59 = *(void *)(v60 - 8);
  int64_t v9 = *(void *)(v59 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v57 = v55;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int32>);
  uint64_t v13 = *(void *)(v12 - 8);
  int64_t v14 = *(void *)(v13 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  char v58 = v55;
  uint64_t v69 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int8>);
  uint64_t v70 = *(void *)(v69 - 8);
  int64_t v17 = *(void *)(v70 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v20 = AnyColumn.wrappedElementType.getter();
  if (swift_dynamicCastMetatype(v20, &type metadata for Int8))
  {
    double v21 = AnyColumn.assumingType<A>(_:)(&type metadata for Int8, &type metadata for Int8);
    uint64_t v22 = AnyColumn.count.getter(v21);
    uint64_t v23 = alloca(24);
    uint64_t v24 = alloca(32);
    uint64_t v56 = v55;
    uint64_t v25 = specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(v22, (void (*)(void *, uint64_t *))partial apply for closure #1 in AnyColumn.convertedToDoubles(), (uint64_t)v55, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
    uint64_t v26 = v55;
    uint64_t v27 = v69;
    uint64_t v28 = v70;
  }
  else
  {
    uint64_t v29 = v58;
    uint64_t v70 = v12;
    uint64_t v69 = v13;
    uint64_t v30 = v57;
    uint64_t v31 = v56;
    if (swift_dynamicCastMetatype(v20, &type metadata for Int32))
    {
      double v32 = AnyColumn.assumingType<A>(_:)(&type metadata for Int32, &type metadata for Int32);
      uint64_t v33 = AnyColumn.count.getter(v32);
      uint64_t v34 = alloca(24);
      uint64_t v35 = alloca(32);
      uint64_t v56 = v29;
      uint64_t v25 = specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(v33, (void (*)(void *, uint64_t *))partial apply for closure #2 in AnyColumn.convertedToDoubles(), (uint64_t)v55, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
      uint64_t v26 = v29;
      uint64_t v27 = v70;
      uint64_t v28 = v69;
    }
    else if (swift_dynamicCastMetatype(v20, &type metadata for Int64))
    {
      double v36 = AnyColumn.assumingType<A>(_:)(&type metadata for Int64, &type metadata for Int64);
      uint64_t v37 = AnyColumn.count.getter(v36);
      uint64_t v38 = alloca(24);
      uint64_t v39 = alloca(32);
      uint64_t v56 = v30;
      uint64_t v25 = specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(v37, (void (*)(void *, uint64_t *))partial apply for closure #3 in AnyColumn.convertedToDoubles(), (uint64_t)v55, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
      uint64_t v26 = v30;
      uint64_t v27 = v60;
      uint64_t v28 = v59;
    }
    else if (swift_dynamicCastMetatype(v20, &type metadata for Int))
    {
      double v40 = AnyColumn.assumingType<A>(_:)(&type metadata for Int, &type metadata for Int);
      uint64_t v41 = AnyColumn.count.getter(v40);
      uint64_t v42 = alloca(24);
      uint64_t v43 = alloca(32);
      uint64_t v56 = v31;
      uint64_t v25 = specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(v41, (void (*)(void *, uint64_t *))partial apply for closure #4 in AnyColumn.convertedToDoubles(), (uint64_t)v55, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
      uint64_t v26 = v31;
      uint64_t v27 = v62;
      uint64_t v28 = v61;
    }
    else if (swift_dynamicCastMetatype(v20, &type metadata for Float))
    {
      uint64_t v44 = v65;
      double v45 = AnyColumn.assumingType<A>(_:)(&type metadata for Float, &type metadata for Float);
      uint64_t v46 = AnyColumn.count.getter(v45);
      uint64_t v47 = alloca(24);
      uint64_t v48 = alloca(32);
      uint64_t v56 = v44;
      uint64_t v25 = specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(v46, (void (*)(void *, uint64_t *))partial apply for closure #5 in AnyColumn.convertedToDoubles(), (uint64_t)v55, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
      uint64_t v26 = v44;
      uint64_t v27 = v64;
      uint64_t v28 = v63;
    }
    else
    {
      if (!swift_dynamicCastMetatype(v20, &type metadata for Double)) {
        return 0;
      }
      uint64_t v49 = v68;
      double v50 = AnyColumn.assumingType<A>(_:)(&type metadata for Double, &type metadata for Double);
      uint64_t v51 = AnyColumn.count.getter(v50);
      uint64_t v52 = alloca(24);
      uint64_t v53 = alloca(32);
      uint64_t v56 = v49;
      uint64_t v25 = specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(v51, (void (*)(void *, uint64_t *))partial apply for closure #6 in AnyColumn.convertedToDoubles(), (uint64_t)v55, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
      uint64_t v26 = v49;
      uint64_t v27 = v67;
      uint64_t v28 = v66;
    }
  }
  (*(void (**)(unsigned char *, uint64_t))(v28 + 8))(v26, v27);
  return v25;
}

uint64_t AnyColumn.convertedToDoubleArrays()()
{
  uint64_t v73 = v0;
  uint64_t v70 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Float]>);
  uint64_t v69 = *(void *)(v70 - 8);
  int64_t v1 = *(void *)(v69 + 64);
  unsigned int v2 = alloca(v1);
  int64_t v3 = alloca(v1);
  uint64_t v71 = v58;
  uint64_t v67 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int]>);
  uint64_t v66 = *(void *)(v67 - 8);
  int64_t v4 = *(void *)(v66 + 64);
  unsigned int v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v68 = v58;
  uint64_t v64 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int64]>);
  uint64_t v63 = *(void *)(v64 - 8);
  int64_t v7 = *(void *)(v63 + 64);
  BOOL v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  uint64_t v65 = v58;
  uint64_t v60 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int32]>);
  uint64_t v62 = *(void *)(v60 - 8);
  int64_t v10 = *(void *)(v62 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v61 = v58;
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int8]>);
  uint64_t v59 = *(void *)(v13 - 8);
  int64_t v14 = *(void *)(v59 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v17 = AnyColumn.wrappedElementType.getter();
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int8]);
  uint64_t v72 = v17;
  if (swift_dynamicCastMetatype(v17, v18))
  {
    double v19 = AnyColumn.assumingType<A>(_:)(v18, v18);
    uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
    uint64_t v21 = v73;
    Column.mapNonNil<A>(_:)(closure #1 in AnyColumn.convertedToDoubleArrays(), 0, v13, v20, v19);
    uint64_t v22 = v58;
    uint64_t v23 = v13;
    uint64_t v24 = v59;
LABEL_3:
    (*(void (**)(unsigned char *, uint64_t))(v24 + 8))(v22, v23);
    uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Double]>);
    uint64_t v26 = v21;
    return __swift_storeEnumTagSinglePayload(v26, 0, 1, v25);
  }
  uint64_t v27 = v61;
  uint64_t v28 = v60;
  uint64_t v29 = v73;
  uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int32]);
  if (swift_dynamicCastMetatype(v72, v30))
  {
    double v31 = AnyColumn.assumingType<A>(_:)(v30, v30);
    uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
    Column.mapNonNil<A>(_:)(closure #2 in AnyColumn.convertedToDoubleArrays(), 0, v28, v32, v31);
    (*(void (**)(unsigned char *, uint64_t))(v62 + 8))(v27, v28);
    uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Double]>);
    uint64_t v26 = v29;
    return __swift_storeEnumTagSinglePayload(v26, 0, 1, v25);
  }
  uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int64]);
  if (swift_dynamicCastMetatype(v72, v33))
  {
    uint64_t v34 = v65;
    double v35 = AnyColumn.assumingType<A>(_:)(v33, v33);
    uint64_t v36 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
    uint64_t v37 = v73;
    uint64_t v38 = v64;
    Column.mapNonNil<A>(_:)(closure #3 in AnyColumn.convertedToDoubleArrays(), 0, v64, v36, v35);
    uint64_t v39 = v34;
    uint64_t v40 = v38;
    uint64_t v41 = v63;
LABEL_10:
    (*(void (**)(unsigned char *, uint64_t))(v41 + 8))(v39, v40);
    uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Double]>);
    uint64_t v26 = v37;
    return __swift_storeEnumTagSinglePayload(v26, 0, 1, v25);
  }
  uint64_t v42 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int]);
  if (swift_dynamicCastMetatype(v72, v42))
  {
    uint64_t v37 = v73;
    uint64_t v43 = v68;
    double v44 = AnyColumn.assumingType<A>(_:)(v42, v42);
    uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
    uint64_t v46 = v67;
    Column.mapNonNil<A>(_:)(closure #3 in AnyColumn.convertedToDoubleArrays(), 0, v67, v45, v44);
    uint64_t v39 = v43;
    uint64_t v40 = v46;
    uint64_t v41 = v66;
    goto LABEL_10;
  }
  uint64_t v48 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  if (swift_dynamicCastMetatype(v72, v48))
  {
    uint64_t v49 = v71;
    double v50 = AnyColumn.assumingType<A>(_:)(v48, v48);
    uint64_t v51 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
    uint64_t v21 = v73;
    uint64_t v52 = v70;
    Column.mapNonNil<A>(_:)(closure #5 in AnyColumn.convertedToDoubleArrays(), 0, v70, v51, v50);
    uint64_t v22 = v49;
    uint64_t v23 = v52;
    uint64_t v24 = v69;
    goto LABEL_3;
  }
  uint64_t v53 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
  if (swift_dynamicCastMetatype(v72, v53))
  {
    uint64_t v54 = v73;
    AnyColumn.assumingType<A>(_:)(v53, v53);
    uint64_t v55 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Double]>);
    uint64_t v56 = v54;
    uint64_t v57 = 0;
  }
  else
  {
    uint64_t v55 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Double]>);
    uint64_t v56 = v73;
    uint64_t v57 = 1;
  }
  return __swift_storeEnumTagSinglePayload(v56, v57, 1, v55);
}

void AnyColumn.convertedToStrings()()
{
  uint64_t v62 = v0;
  uint64_t v58 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  uint64_t v56 = *(void *)(v58 - 8);
  int64_t v2 = *(void *)(v56 + 64);
  int64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  uint64_t v57 = &v45;
  uint64_t v55 = (char *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Float>);
  uint64_t v5 = *((void *)v55 - 1);
  int64_t v6 = *(void *)(v5 + 64);
  int64_t v7 = alloca(v6);
  BOOL v8 = alloca(v6);
  uint64_t v54 = &v45;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v10 = *(void *)(v9 - 8);
  int64_t v11 = *(void *)(v10 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v59 = &v45;
  uint64_t v14 = v1;
  uint64_t v15 = AnyColumn.wrappedElementType.getter();
  if (swift_dynamicCastMetatype(v15, &type metadata for String))
  {
    AnyColumn.assumingType<A>(_:)(&type metadata for String, &type metadata for String);
    return;
  }
  uint64_t v51 = v10;
  uint64_t v52 = v5;
  uint64_t v16 = v58;
  uint64_t v61 = v14;
  if (swift_dynamicCastMetatype(v15, &type metadata for Int))
  {
    uint64_t v17 = v59;
    double v18 = AnyColumn.assumingType<A>(_:)(&type metadata for Int, &type metadata for Int);
    Column.mapNonNil<A>(_:)(specialized thunk for @escaping @callee_guaranteed (@unowned Int) -> (@owned String), 0, v9, &type metadata for String, v18);
    double v19 = v17;
    uint64_t v20 = v9;
    uint64_t v21 = v51;
LABEL_9:
    (*(void (**)(uint64_t *, uint64_t))(v21 + 8))(v19, v20);
    return;
  }
  if (swift_dynamicCastMetatype(v15, &type metadata for Float))
  {
    uint64_t v22 = v54;
    double v23 = AnyColumn.assumingType<A>(_:)(&type metadata for Float, &type metadata for Float);
    uint64_t v24 = v55;
    Column.mapNonNil<A>(_:)(closure #1 in AnyColumn.convertedToStrings(), 0, v55, &type metadata for String, v23);
    double v19 = v22;
    uint64_t v20 = (uint64_t)v24;
    uint64_t v21 = v52;
    goto LABEL_9;
  }
  if (swift_dynamicCastMetatype(v15, &type metadata for Double))
  {
    uint64_t v25 = v57;
    double v26 = AnyColumn.assumingType<A>(_:)(&type metadata for Double, &type metadata for Double);
    Column.mapNonNil<A>(_:)(closure #2 in AnyColumn.convertedToStrings(), 0, v16, &type metadata for String, v26);
    double v19 = v25;
    uint64_t v20 = v16;
    uint64_t v21 = v56;
    goto LABEL_9;
  }
  uint64_t v56 = AnyColumn.name.getter();
  uint64_t v57 = v27;
  uint64_t v28 = type metadata accessor for AnyColumn(0);
  uint64_t v29 = lazy protocol witness table accessor for type AnyColumn and conformance AnyColumn();
  uint64_t v30 = dispatch thunk of Collection.count.getter(v28, v29);
  if (v30)
  {
    uint64_t v31 = v30;
    uint64_t v60 = _swiftEmptyArrayStorage;
    int64_t v32 = 0;
    if (v30 > 0) {
      int64_t v32 = v30;
    }
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v32, 0);
    uint64_t v58 = v28;
    uint64_t v59 = (uint64_t *)v29;
    dispatch thunk of Collection.startIndex.getter(v28, v29);
    uint64_t v54 = (uint64_t *)v31;
    if (v31 < 0) {
      BUG();
    }
    uint64_t v55 = (char *)&type metadata for Any + 8;
    uint64_t v33 = v58;
    uint64_t v34 = v59;
    do
    {
      double v35 = (void (*)(long long *, void))dispatch thunk of Collection.subscript.read(&v49, v53, v33, v34);
      outlined init with copy of Any?(v36, (uint64_t)v48);
      v35(&v49, 0);
      outlined init with copy of Any?((uint64_t)v48, (uint64_t)&v49);
      if (v50)
      {
        outlined init with take of Any(&v49, v46);
        outlined init with copy of Any((uint64_t)v46, (uint64_t)v47);
        uint64_t v37 = String.init<A>(describing:)(v47, v55);
        uint64_t v39 = v38;
        __swift_destroy_boxed_opaque_existential_1Tm(v46);
      }
      else
      {
        uint64_t v37 = 0;
        uint64_t v39 = 0;
      }
      outlined destroy of Any?((uint64_t)v48);
      uint64_t v40 = v60;
      if (!swift_isUniquelyReferenced_nonNull_native(v60))
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v40[2] + 1, 1);
        uint64_t v40 = v60;
      }
      unint64_t v41 = v40[2];
      if (v40[3] >> 1 <= v41)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v40[3] >= 2uLL, v41 + 1, 1);
        uint64_t v40 = v60;
      }
      v40[2] = v41 + 1;
      uint64_t v42 = 2 * v41;
      v40[v42 + 4] = v37;
      v40[v42 + 5] = v39;
      uint64_t v33 = v58;
      uint64_t v34 = v59;
      dispatch thunk of Collection.formIndex(after:)(v53, v58, v59);
      uint64_t v54 = (uint64_t *)((char *)v54 - 1);
    }
    while (v54);
  }
  else
  {
    uint64_t v40 = _swiftEmptyArrayStorage;
  }
  *(void *)&long long v49 = v40;
  uint64_t v43 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String?]);
  uint64_t v44 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [String?] and conformance [A], &demangling cache variable for type metadata for [String?], (uint64_t)&protocol conformance descriptor for [A]);
  Column.init<A>(name:contents:)(v56, v57, &v49, &type metadata for String, v43, v44);
}

uint64_t AnyColumn.convertedToFloatArrays()()
{
  uint64_t v65 = v0;
  uint64_t v66 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Double]>);
  uint64_t v63 = *(void *)(v66 - 8);
  int64_t v1 = *(void *)(v63 + 64);
  int64_t v2 = alloca(v1);
  int64_t v3 = alloca(v1);
  uint64_t v64 = v52;
  uint64_t v61 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int]>);
  uint64_t v60 = *(void *)(v61 - 8);
  int64_t v4 = *(void *)(v60 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v62 = v52;
  uint64_t v58 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int64]>);
  uint64_t v57 = *(void *)(v58 - 8);
  int64_t v7 = *(void *)(v57 + 64);
  BOOL v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v59 = v52;
  uint64_t v54 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int32]>);
  uint64_t v56 = *(void *)(v54 - 8);
  int64_t v10 = *(void *)(v56 + 64);
  int64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v55 = v52;
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int8]>);
  uint64_t v53 = *(void *)(v13 - 8);
  int64_t v14 = *(void *)(v53 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v17 = AnyColumn.wrappedElementType.getter();
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int8]);
  uint64_t v67 = v17;
  if (swift_dynamicCastMetatype(v17, v18))
  {
    double v19 = AnyColumn.assumingType<A>(_:)(v18, v18);
    uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
    uint64_t v21 = v65;
    Column.mapNonNil<A>(_:)(closure #1 in AnyColumn.convertedToFloatArrays(), 0, v13, v20, v19);
    uint64_t v22 = v52;
    uint64_t v23 = v13;
    uint64_t v24 = v53;
LABEL_3:
    (*(void (**)(unsigned char *, uint64_t))(v24 + 8))(v22, v23);
    uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Float]>);
    uint64_t v26 = v21;
    return __swift_storeEnumTagSinglePayload(v26, 0, 1, v25);
  }
  uint64_t v27 = v55;
  uint64_t v28 = v54;
  uint64_t v29 = v65;
  uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int32]);
  if (swift_dynamicCastMetatype(v67, v30))
  {
    double v31 = AnyColumn.assumingType<A>(_:)(v30, v30);
    uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
    Column.mapNonNil<A>(_:)(closure #2 in AnyColumn.convertedToFloatArrays(), 0, v28, v32, v31);
    (*(void (**)(unsigned char *, uint64_t))(v56 + 8))(v27, v28);
    uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Float]>);
    uint64_t v26 = v29;
    return __swift_storeEnumTagSinglePayload(v26, 0, 1, v25);
  }
  uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int64]);
  uint64_t v35 = v29;
  if (swift_dynamicCastMetatype(v67, v34))
  {
    uint64_t v36 = v59;
    double v37 = AnyColumn.assumingType<A>(_:)(v34, v34);
    uint64_t v38 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
    uint64_t v21 = v35;
    uint64_t v39 = v58;
    Column.mapNonNil<A>(_:)(closure #3 in AnyColumn.convertedToFloatArrays(), 0, v58, v38, v37);
    uint64_t v22 = v36;
    uint64_t v23 = v39;
    uint64_t v24 = v57;
    goto LABEL_3;
  }
  uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int]);
  if (swift_dynamicCastMetatype(v67, v40))
  {
    uint64_t v21 = v29;
    unint64_t v41 = v62;
    double v42 = AnyColumn.assumingType<A>(_:)(v40, v40);
    uint64_t v43 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
    uint64_t v44 = v61;
    Column.mapNonNil<A>(_:)(closure #3 in AnyColumn.convertedToFloatArrays(), 0, v61, v43, v42);
    uint64_t v22 = v41;
    uint64_t v23 = v44;
    uint64_t v24 = v60;
    goto LABEL_3;
  }
  uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  if (swift_dynamicCastMetatype(v67, v45))
  {
    AnyColumn.assumingType<A>(_:)(v45, v45);
    uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Float]>);
    uint64_t v47 = v29;
    uint64_t v48 = 0;
  }
  else
  {
    uint64_t v49 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
    if (swift_dynamicCastMetatype(v67, v49))
    {
      uint64_t v50 = v64;
      double v51 = AnyColumn.assumingType<A>(_:)(v49, v49);
      uint64_t v21 = v35;
      Column.mapNonNil<A>(_:)(closure #5 in AnyColumn.convertedToFloatArrays(), 0, v66, v45, v51);
      uint64_t v22 = v50;
      uint64_t v23 = v66;
      uint64_t v24 = v63;
      goto LABEL_3;
    }
    uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Float]>);
    uint64_t v47 = v29;
    uint64_t v48 = 1;
  }
  return __swift_storeEnumTagSinglePayload(v47, v48, 1, v46);
}

uint64_t Column<A>.parseAsJSONArrays()(uint64_t *a1, uint64_t a2)
{
  uint64_t v30 = a2;
  uint64_t v23 = v2;
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Any]>);
  uint64_t v28 = *(void *)(v22 - 8);
  int64_t v4 = *(void *)(v28 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v25 = &v21;
  int64_t v7 = alloca(v4);
  BOOL v8 = alloca(v4);
  uint64_t v24 = &v21;
  uint64_t v9 = alloca(v4);
  int64_t v10 = alloca(v4);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(a1);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Any]);
  uint64_t v13 = v30;
  uint64_t v30 = v12;
  uint64_t result = Column.map<A>(_:)(v13, 0, v11);
  if (!v3)
  {
    uint64_t v29 = Column.name.getter(v11);
    uint64_t v27 = v15;
    uint64_t v16 = v25;
    uint64_t v26 = &v21;
    uint64_t v17 = v22;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v28 + 16))(v25, &v21, v22);
    uint64_t v18 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Any]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Any]>, (uint64_t)&protocol conformance descriptor for Column<A>);
    double v19 = v24;
    Column.init<A>(name:contents:)(v29, v27, v16, v30, v17, v18);
    Column.eraseToAnyColumn()(v17);
    uint64_t v20 = *(void (**)(uint64_t *, uint64_t))(v28 + 8);
    v20(v19, v17);
    return ((uint64_t (*)(uint64_t *, uint64_t))v20)(v26, v17);
  }
  return result;
}

uint64_t implicit closure #1 in AnyColumn.convertedToStrings()()
{
  return dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
}

uint64_t specialized thunk for @escaping @callee_guaranteed (@unowned Int) -> (@owned String)()
{
  int64_t v1 = v0;
  uint64_t result = implicit closure #1 in AnyColumn.convertedToStrings()();
  *int64_t v1 = result;
  v1[1] = v3;
  return result;
}

uint64_t closure #1 in AnyColumn.convertedToStrings()(float *a1)
{
  uint64_t v2 = v1;
  uint64_t result = Float.description.getter(*a1);
  uint64_t *v2 = result;
  v2[1] = v4;
  return result;
}

uint64_t closure #2 in AnyColumn.convertedToStrings()(double *a1)
{
  uint64_t v2 = v1;
  uint64_t result = Double.description.getter(*a1);
  uint64_t *v2 = result;
  v2[1] = v4;
  return result;
}

uint64_t closure #1 in AnyColumn.convertedToDoubles()(uint64_t *a1, uint64_t *a2)
{
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int8>);
  uint64_t result = Column.count.getter(v7);
  *a2 = result;
  if (result < 0) {
    BUG();
  }
  if (result)
  {
    uint64_t v3 = result;
    uint64_t v4 = *a1;
    for (uint64_t i = 0; i != v3; ++i)
    {
      uint64_t result = Column.subscript.getter(i, v7);
      double v6 = NAN;
      if (!v9)
      {
        uint64_t result = v8;
        double v6 = (double)(int)result;
      }
      *(double *)(v4 + 8 * i) = v6;
    }
  }
  return result;
}

uint64_t closure #2 in AnyColumn.convertedToDoubles()(uint64_t *a1, uint64_t *a2)
{
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int32>);
  uint64_t result = Column.count.getter(v7);
  *a2 = result;
  if (result < 0) {
    BUG();
  }
  if (result)
  {
    uint64_t v3 = result;
    uint64_t v4 = *a1;
    for (uint64_t i = 0; i != v3; ++i)
    {
      uint64_t result = Column.subscript.getter(i, v7);
      double v6 = NAN;
      if (!v9) {
        double v6 = (double)v8;
      }
      *(double *)(v4 + 8 * i) = v6;
    }
  }
  return result;
}

uint64_t closure #3 in AnyColumn.convertedToDoubles()(uint64_t *a1, uint64_t *a2, uint64_t a3, uint64_t *a4)
{
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(a4);
  uint64_t result = Column.count.getter(v9);
  *a2 = result;
  if (result < 0) {
    BUG();
  }
  if (result)
  {
    uint64_t v5 = result;
    uint64_t v6 = *a1;
    for (uint64_t i = 0; i != v5; ++i)
    {
      uint64_t result = Column.subscript.getter(i, v9);
      double v8 = NAN;
      if (!v11) {
        double v8 = (double)v10;
      }
      *(double *)(v6 + 8 * i) = v8;
    }
  }
  return result;
}

uint64_t closure #5 in AnyColumn.convertedToDoubles()(uint64_t *a1, uint64_t *a2)
{
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Float>);
  uint64_t result = Column.count.getter(v7);
  *a2 = result;
  if (result < 0) {
    BUG();
  }
  if (result)
  {
    uint64_t v3 = result;
    uint64_t v4 = *a1;
    for (uint64_t i = 0; i != v3; ++i)
    {
      uint64_t result = Column.subscript.getter(i, v7);
      double v6 = NAN;
      if (!v9) {
        double v6 = v8;
      }
      *(double *)(v4 + 8 * i) = v6;
    }
  }
  return result;
}

uint64_t closure #6 in AnyColumn.convertedToDoubles()(uint64_t *a1, uint64_t *a2)
{
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  uint64_t result = Column.count.getter(v7);
  *a2 = result;
  if (result < 0) {
    BUG();
  }
  if (result)
  {
    uint64_t v3 = result;
    uint64_t v4 = *a1;
    for (uint64_t i = 0; i != v3; ++i)
    {
      uint64_t result = Column.subscript.getter(i, v7);
      uint64_t v6 = 0x7FF8000000000000;
      if (!v9) {
        uint64_t v6 = v8;
      }
      *(void *)(v4 + 8 * i) = v6;
    }
  }
  return result;
}

uint64_t closure #1 in AnyColumn.convertedToFloats()(uint64_t *a1, uint64_t *a2)
{
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int8>);
  uint64_t result = Column.count.getter(v7);
  *a2 = result;
  if (result < 0) {
    BUG();
  }
  if (result)
  {
    uint64_t v3 = result;
    uint64_t v4 = *a1;
    for (uint64_t i = 0; i != v3; ++i)
    {
      uint64_t result = Column.subscript.getter(i, v7);
      float v6 = NAN;
      if (!v9)
      {
        uint64_t result = v8;
        float v6 = (float)(int)result;
      }
      *(float *)(v4 + 4 * i) = v6;
    }
  }
  return result;
}

uint64_t closure #2 in AnyColumn.convertedToFloats()(uint64_t *a1, uint64_t *a2)
{
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int32>);
  uint64_t result = Column.count.getter(v7);
  *a2 = result;
  if (result < 0) {
    BUG();
  }
  if (result)
  {
    uint64_t v3 = result;
    uint64_t v4 = *a1;
    for (uint64_t i = 0; i != v3; ++i)
    {
      uint64_t result = Column.subscript.getter(i, v7);
      float v6 = NAN;
      if (!v9) {
        float v6 = (float)v8;
      }
      *(float *)(v4 + 4 * i) = v6;
    }
  }
  return result;
}

uint64_t closure #3 in AnyColumn.convertedToFloats()(uint64_t *a1, uint64_t *a2, uint64_t a3, uint64_t *a4)
{
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(a4);
  uint64_t result = Column.count.getter(v9);
  *a2 = result;
  if (result < 0) {
    BUG();
  }
  if (result)
  {
    uint64_t v5 = result;
    uint64_t v6 = *a1;
    for (uint64_t i = 0; i != v5; ++i)
    {
      uint64_t result = Column.subscript.getter(i, v9);
      float v8 = NAN;
      if (!v11) {
        float v8 = (float)v10;
      }
      *(float *)(v6 + 4 * i) = v8;
    }
  }
  return result;
}

uint64_t closure #5 in AnyColumn.convertedToFloats()(uint64_t *a1, uint64_t *a2)
{
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Float>);
  uint64_t result = Column.count.getter(v7);
  *a2 = result;
  if (result < 0) {
    BUG();
  }
  if (result)
  {
    uint64_t v3 = result;
    uint64_t v4 = *a1;
    for (uint64_t i = 0; i != v3; ++i)
    {
      uint64_t result = Column.subscript.getter(i, v7);
      int v6 = 2143289344;
      if (!v9) {
        int v6 = v8;
      }
      *(_DWORD *)(v4 + 4 * i) = v6;
    }
  }
  return result;
}

uint64_t closure #6 in AnyColumn.convertedToFloats()(uint64_t *a1, uint64_t *a2)
{
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  uint64_t result = Column.count.getter(v7);
  *a2 = result;
  if (result < 0) {
    BUG();
  }
  if (result)
  {
    uint64_t v3 = result;
    uint64_t v4 = *a1;
    for (uint64_t i = 0; i != v3; ++i)
    {
      uint64_t result = Column.subscript.getter(i, v7);
      float v6 = NAN;
      if (!v9) {
        float v6 = v8;
      }
      *(float *)(v4 + 4 * i) = v6;
    }
  }
  return result;
}

uint64_t partial apply for closure #6 in AnyColumn.convertedToFloats()(uint64_t *a1, uint64_t *a2)
{
  return closure #6 in AnyColumn.convertedToFloats()(a1, a2);
}

void *closure #1 in AnyColumn.convertedToFloatArrays()(uint64_t *a1)
{
  int64_t v2 = *(void *)(*a1 + 16);
  if (v2)
  {
    double v8 = result;
    uint64_t v3 = 0;
    uint64_t v9 = *a1;
    int64_t v10 = *(void *)(*a1 + 16);
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    int64_t v4 = v2;
    uint64_t v5 = v9;
    unint64_t v6 = _swiftEmptyArrayStorage[2];
    do
    {
      char v7 = *(unsigned char *)(v5 + v3 + 32);
      if (_swiftEmptyArrayStorage[3] >> 1 <= v6)
      {
        char v11 = *(unsigned char *)(v5 + v3 + 32);
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v6 + 1, 1);
        char v7 = v11;
        int64_t v4 = v10;
        uint64_t v5 = v9;
      }
      ++v3;
      _swiftEmptyArrayStorage[2] = v6 + 1;
      *((float *)&_swiftEmptyArrayStorage[4] + v6++) = (float)v7;
    }
    while (v4 != v3);
    uint64_t result = v8;
  }
  *uint64_t result = _swiftEmptyArrayStorage;
  return result;
}

void *closure #2 in AnyColumn.convertedToFloatArrays()(uint64_t *a1)
{
  int64_t v2 = *(void *)(*a1 + 16);
  if (v2)
  {
    double v8 = result;
    uint64_t v3 = 0;
    uint64_t v9 = *a1;
    int64_t v10 = *(void *)(*a1 + 16);
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    int64_t v4 = v2;
    uint64_t v5 = v9;
    unint64_t v6 = _swiftEmptyArrayStorage[2];
    do
    {
      int v7 = *(_DWORD *)(v5 + 4 * v3 + 32);
      if (_swiftEmptyArrayStorage[3] >> 1 <= v6)
      {
        int v11 = *(_DWORD *)(v5 + 4 * v3 + 32);
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v6 + 1, 1);
        int v7 = v11;
        int64_t v4 = v10;
        uint64_t v5 = v9;
      }
      ++v3;
      _swiftEmptyArrayStorage[2] = v6 + 1;
      *((float *)&_swiftEmptyArrayStorage[4] + v6++) = (float)v7;
    }
    while (v4 != v3);
    uint64_t result = v8;
  }
  *uint64_t result = _swiftEmptyArrayStorage;
  return result;
}

void *closure #3 in AnyColumn.convertedToFloatArrays()(uint64_t *a1)
{
  return closure #3 in AnyColumn.convertedToFloatArrays()(a1);
}

{
  void *result;
  int64_t v2;
  uint64_t v3;
  int64_t v4;
  uint64_t v5;
  unint64_t v6;
  uint64_t v7;
  void *v8;
  uint64_t v9;
  uint64_t v10;
  int64_t v11;

  int64_t v2 = *(void *)(*a1 + 16);
  if (v2)
  {
    double v8 = result;
    uint64_t v3 = 0;
    int64_t v10 = *a1;
    int v11 = *(void *)(*a1 + 16);
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    int64_t v4 = v2;
    uint64_t v5 = v10;
    unint64_t v6 = _swiftEmptyArrayStorage[2];
    do
    {
      int v7 = *(void *)(v5 + 8 * v3 + 32);
      if (_swiftEmptyArrayStorage[3] >> 1 <= v6)
      {
        uint64_t v9 = *(void *)(v5 + 8 * v3 + 32);
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v6 + 1, 1);
        LODWORD(v7) = v9;
        int64_t v4 = v11;
        uint64_t v5 = v10;
      }
      ++v3;
      _swiftEmptyArrayStorage[2] = v6 + 1;
      *((float *)&_swiftEmptyArrayStorage[4] + v6++) = (float)(int)v7;
    }
    while (v4 != v3);
    uint64_t result = v8;
  }
  *uint64_t result = _swiftEmptyArrayStorage;
  return result;
}

void *closure #5 in AnyColumn.convertedToFloatArrays()(uint64_t *a1)
{
  int64_t v2 = *(void *)(*a1 + 16);
  if (v2)
  {
    uint64_t v9 = result;
    uint64_t v3 = 0;
    uint64_t v10 = *a1;
    int64_t v11 = *(void *)(*a1 + 16);
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    int64_t v4 = v2;
    uint64_t v5 = v10;
    unint64_t v6 = _swiftEmptyArrayStorage[2];
    do
    {
      double v7 = *(double *)(v5 + 8 * v3 + 32);
      if (_swiftEmptyArrayStorage[3] >> 1 <= v6)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v6 + 1, 1);
        int64_t v4 = v11;
        uint64_t v5 = v10;
      }
      ++v3;
      float v8 = v7;
      _swiftEmptyArrayStorage[2] = v6 + 1;
      *((float *)&_swiftEmptyArrayStorage[4] + v6++) = v8;
    }
    while (v4 != v3);
    uint64_t result = v9;
  }
  *uint64_t result = _swiftEmptyArrayStorage;
  return result;
}

void *closure #1 in AnyColumn.convertedToDoubleArrays()(uint64_t *a1)
{
  int64_t v2 = *(void *)(*a1 + 16);
  if (v2)
  {
    float v8 = result;
    uint64_t v3 = 0;
    uint64_t v9 = *a1;
    int64_t v10 = *(void *)(*a1 + 16);
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    int64_t v4 = v2;
    uint64_t v5 = v9;
    unint64_t v6 = _swiftEmptyArrayStorage[2];
    do
    {
      char v7 = *(unsigned char *)(v5 + v3 + 32);
      if (_swiftEmptyArrayStorage[3] >> 1 <= v6)
      {
        char v11 = *(unsigned char *)(v5 + v3 + 32);
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v6 + 1, 1);
        char v7 = v11;
        int64_t v4 = v10;
        uint64_t v5 = v9;
      }
      ++v3;
      _swiftEmptyArrayStorage[2] = v6 + 1;
      *(double *)&_swiftEmptyArrayStorage[v6++ + 4] = (double)v7;
    }
    while (v4 != v3);
    uint64_t result = v8;
  }
  *uint64_t result = _swiftEmptyArrayStorage;
  return result;
}

void *closure #2 in AnyColumn.convertedToDoubleArrays()(uint64_t *a1)
{
  int64_t v2 = *(void *)(*a1 + 16);
  if (v2)
  {
    float v8 = result;
    uint64_t v3 = 0;
    uint64_t v9 = *a1;
    int64_t v10 = *(void *)(*a1 + 16);
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    int64_t v4 = v2;
    uint64_t v5 = v9;
    unint64_t v6 = _swiftEmptyArrayStorage[2];
    do
    {
      int v7 = *(_DWORD *)(v5 + 4 * v3 + 32);
      if (_swiftEmptyArrayStorage[3] >> 1 <= v6)
      {
        int v11 = *(_DWORD *)(v5 + 4 * v3 + 32);
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v6 + 1, 1);
        int v7 = v11;
        int64_t v4 = v10;
        uint64_t v5 = v9;
      }
      ++v3;
      _swiftEmptyArrayStorage[2] = v6 + 1;
      *(double *)&_swiftEmptyArrayStorage[v6++ + 4] = (double)v7;
    }
    while (v4 != v3);
    uint64_t result = v8;
  }
  *uint64_t result = _swiftEmptyArrayStorage;
  return result;
}

void *closure #3 in AnyColumn.convertedToDoubleArrays()(uint64_t *a1)
{
  return closure #3 in AnyColumn.convertedToDoubleArrays()(a1);
}

{
  void *result;
  int64_t v2;
  uint64_t v3;
  int64_t v4;
  uint64_t v5;
  unint64_t v6;
  uint64_t v7;
  void *v8;
  uint64_t v9;
  uint64_t v10;
  int64_t v11;

  int64_t v2 = *(void *)(*a1 + 16);
  if (v2)
  {
    float v8 = result;
    uint64_t v3 = 0;
    int64_t v10 = *a1;
    int v11 = *(void *)(*a1 + 16);
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    int64_t v4 = v2;
    uint64_t v5 = v10;
    unint64_t v6 = _swiftEmptyArrayStorage[2];
    do
    {
      int v7 = *(void *)(v5 + 8 * v3 + 32);
      if (_swiftEmptyArrayStorage[3] >> 1 <= v6)
      {
        uint64_t v9 = *(void *)(v5 + 8 * v3 + 32);
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v6 + 1, 1);
        LODWORD(v7) = v9;
        int64_t v4 = v11;
        uint64_t v5 = v10;
      }
      ++v3;
      _swiftEmptyArrayStorage[2] = v6 + 1;
      *(double *)&_swiftEmptyArrayStorage[v6++ + 4] = (double)(int)v7;
    }
    while (v4 != v3);
    uint64_t result = v8;
  }
  *uint64_t result = _swiftEmptyArrayStorage;
  return result;
}

void *closure #5 in AnyColumn.convertedToDoubleArrays()(uint64_t *a1)
{
  int64_t v2 = *(void *)(*a1 + 16);
  if (v2)
  {
    float v8 = result;
    uint64_t v3 = 0;
    uint64_t v9 = *a1;
    int64_t v10 = *(void *)(*a1 + 16);
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    int64_t v4 = v2;
    uint64_t v5 = v9;
    unint64_t v6 = _swiftEmptyArrayStorage[2];
    do
    {
      float v7 = *(float *)(v5 + 4 * v3 + 32);
      if (_swiftEmptyArrayStorage[3] >> 1 <= v6)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v6 + 1, 1);
        int64_t v4 = v10;
        uint64_t v5 = v9;
      }
      ++v3;
      _swiftEmptyArrayStorage[2] = v6 + 1;
      *(double *)&_swiftEmptyArrayStorage[v6++ + 4] = v7;
    }
    while (v4 != v3);
    uint64_t result = v8;
  }
  *uint64_t result = _swiftEmptyArrayStorage;
  return result;
}

NSURL *closure #1 in Column<A>.parseAsJSONArrays()(uint64_t *a1)
{
  uint64_t v25 = v2;
  uint64_t v26 = v1;
  uint64_t v3 = type metadata accessor for String.Encoding(0);
  int64_t v4 = *(void *)(*(void *)(v3 - 8) + 64);
  uint64_t v5 = alloca(v4);
  unint64_t v6 = alloca(v4);
  uint64_t v7 = a1[1];
  if (v7
    && (uint64_t v8 = *a1,
        uint64_t v27 = *(void *)(v3 - 8),
        static String.Encoding.utf8.getter(),
        uint64_t v9 = String.data(using:allowLossyConversion:)(&v25, 0, v8, v7),
        unint64_t v11 = v10,
        (*(void (**)(uint64_t *, uint64_t))(v27 + 8))(&v25, v3),
        HIBYTE(v11) < 0xFF))
  {
    uint64_t v13 = objc_opt_self(NSJSONSerialization);
    uint64_t v27 = v9;
    Class isa = Data._bridgeToObjectiveC()().super.isa;
    v28[0] = 0;
    id v15 = [v13 JSONObjectWithData:isa options:0 error:v28];
    id v16 = v15;

    id v17 = v28[0];
    if (v16)
    {
      v28[0];
      _bridgeAnyObjectToAny(_:)(v16);
      outlined consume of Data?(v27, v11);
      swift_unknownObjectRelease(v16);
      uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Any]);
      double v19 = v26;
      if (!swift_dynamicCast(v26, v28, (char *)&type metadata for Any + 8, v18, 6)) {
        *double v19 = 0;
      }
    }
    else
    {
      id v20 = v28[0];
      _convertNSErrorToError(_:)(v17);

      swift_willThrow(v20, "JSONObjectWithData:options:error:", v21, v22, v23, v24);
      outlined consume of Data?(v27, v11);
    }
  }
  else
  {
    *uint64_t v26 = 0;
  }
  return __stack_chk_guard;
}

{
  void *v1;
  unint64_t v2;
  uint64_t v3;
  void *v4;
  Class isa;
  id v6;
  id v7;
  id v8;
  uint64_t v9;
  id v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  void *v16;
  uint64_t v17;
  id v18[4];

  uint64_t v2 = a1[1];
  if (HIBYTE(v2) < 0xFF)
  {
    id v16 = v1;
    uint64_t v3 = *a1;
    int64_t v4 = objc_opt_self(NSJSONSerialization);
    outlined copy of Data._Representation(v3, v2);
    id v17 = v3;
    Class isa = Data._bridgeToObjectiveC()().super.isa;
    v18[0] = 0;
    unint64_t v6 = [v4 JSONObjectWithData:isa options:0 error:v18];
    uint64_t v7 = v6;

    uint64_t v8 = v18[0];
    if (v7)
    {
      v18[0];
      _bridgeAnyObjectToAny(_:)(v7);
      outlined consume of Data?(v17, v2);
      swift_unknownObjectRelease(v7);
      uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Any]);
      if (!swift_dynamicCast(v16, v18, (char *)&type metadata for Any + 8, v9, 6)) {
        *id v16 = 0;
      }
    }
    else
    {
      unint64_t v10 = v18[0];
      _convertNSErrorToError(_:)(v8);

      swift_willThrow(v10, "JSONObjectWithData:options:error:", v11, v12, v13, v14);
      outlined consume of Data?(v17, v2);
    }
  }
  else
  {
    *int64_t v1 = 0;
  }
  return __stack_chk_guard;
}

uint64_t specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(uint64_t a1, void (*a2)(void *, uint64_t *), uint64_t a3)
{
  return specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(a1, a2, a3, (uint64_t (*)(void))specialized static Array._allocateUninitialized(_:));
}

uint64_t specialized Array.init(_unsafeUninitializedCapacity:initializingWith:)(uint64_t a1, void (*a2)(void *, uint64_t *), uint64_t a3, uint64_t (*a4)(void))
{
  uint64_t v11 = a4();
  uint64_t v10 = 0;
  uint64_t v6 = v5;
  v9[0] = v5;
  v9[1] = a1;
  a2(v9, &v10);
  if (v4)
  {
    if (v10 > a1) {
      BUG();
    }
    if (!v9[0]) {
      BUG();
    }
    if (v6 != v9[0]) {
      BUG();
    }
    uint64_t v7 = v11;
    *(void *)(v11 + 16) = v10;
    swift_bridgeObjectRelease(v7);
  }
  else
  {
    if (v10 > a1) {
      BUG();
    }
    if (!v9[0]) {
      BUG();
    }
    if (v6 != v9[0]) {
      BUG();
    }
    uint64_t v7 = v11;
    *(void *)(v11 + 16) = v10;
  }
  return v7;
}

uint64_t partial apply for closure #5 in AnyColumn.convertedToFloats()(uint64_t *a1, uint64_t *a2)
{
  return closure #5 in AnyColumn.convertedToFloats()(a1, a2);
}

uint64_t partial apply for closure #4 in AnyColumn.convertedToFloats()(uint64_t *a1, uint64_t *a2)
{
  return closure #3 in AnyColumn.convertedToFloats()(a1, a2, *(void *)(v2 + 16), &demangling cache variable for type metadata for Column<Int>);
}

uint64_t partial apply for closure #3 in AnyColumn.convertedToFloats()(uint64_t *a1, uint64_t *a2)
{
  return closure #3 in AnyColumn.convertedToFloats()(a1, a2, *(void *)(v2 + 16), &demangling cache variable for type metadata for Column<Int64>);
}

uint64_t partial apply for closure #2 in AnyColumn.convertedToFloats()(uint64_t *a1, uint64_t *a2)
{
  return closure #2 in AnyColumn.convertedToFloats()(a1, a2);
}

uint64_t partial apply for closure #1 in AnyColumn.convertedToFloats()(uint64_t *a1, uint64_t *a2)
{
  return closure #1 in AnyColumn.convertedToFloats()(a1, a2);
}

uint64_t partial apply for closure #6 in AnyColumn.convertedToDoubles()(uint64_t *a1, uint64_t *a2)
{
  return closure #6 in AnyColumn.convertedToDoubles()(a1, a2);
}

uint64_t partial apply for closure #5 in AnyColumn.convertedToDoubles()(uint64_t *a1, uint64_t *a2)
{
  return closure #5 in AnyColumn.convertedToDoubles()(a1, a2);
}

uint64_t partial apply for closure #4 in AnyColumn.convertedToDoubles()(uint64_t *a1, uint64_t *a2)
{
  return closure #3 in AnyColumn.convertedToDoubles()(a1, a2, *(void *)(v2 + 16), &demangling cache variable for type metadata for Column<Int>);
}

uint64_t partial apply for closure #3 in AnyColumn.convertedToDoubles()(uint64_t *a1, uint64_t *a2)
{
  return closure #3 in AnyColumn.convertedToDoubles()(a1, a2, *(void *)(v2 + 16), &demangling cache variable for type metadata for Column<Int64>);
}

uint64_t partial apply for closure #2 in AnyColumn.convertedToDoubles()(uint64_t *a1, uint64_t *a2)
{
  return closure #2 in AnyColumn.convertedToDoubles()(a1, a2);
}

uint64_t partial apply for closure #1 in AnyColumn.convertedToDoubles()(uint64_t *a1, uint64_t *a2)
{
  return closure #1 in AnyColumn.convertedToDoubles()(a1, a2);
}

unint64_t outlined consume of Data?(uint64_t a1, unint64_t a2)
{
  unint64_t result = HIBYTE(a2);
  if (HIBYTE(a2) <= 0xFE) {
    return outlined consume of Data._Representation(a1, a2);
  }
  return result;
}

uint64_t MLObjectDetector.write(to:metadata:)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 64);
  v4[0] = *(_OWORD *)a2;
  v4[1] = *(_OWORD *)(a2 + 16);
  v4[2] = *(_OWORD *)(a2 + 32);
  v4[3] = *(_OWORD *)(a2 + 48);
  uint64_t v5 = v2;
  return _Model.write(to:metadata:)(a1, (uint64_t *)v4);
}

uint64_t MLObjectDetector.write(toFile:metadata:)(Swift::String string, long long *a2)
{
  uint64_t v17 = v2;
  uint64_t v19 = v3;
  stringa = string._object;
  uint64_t v5 = type metadata accessor for URL(0);
  uint64_t v6 = *(void *)(v5 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  long long v13 = *a2;
  long long v14 = a2[1];
  long long v15 = a2[2];
  long long v16 = a2[3];
  uint64_t v20 = *((void *)a2 + 8);
  uint64_t v21 = v11;
  uint64_t result = static _ValidationUtilities.validateWriteLocation(atPath:defaultName:)(string, 0x65447463656A624FLL, (void *)0xEE00726F74636574);
  if (!v2)
  {
    v11[0] = v13;
    v11[1] = v14;
    v11[2] = v15;
    v11[3] = v16;
    uint64_t v12 = v20;
    _Model.write(to:metadata:)((uint64_t)v21, (uint64_t *)v11);
    return (*(uint64_t (**)(_OWORD *, uint64_t))(v6 + 8))(v21, v5);
  }
  return result;
}

unsigned char *assignWithCopy for MLLinearRegressor.ModelParameters.ValidationData(unsigned char *__dst, unsigned char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)__dst);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v7 = type metadata accessor for DataFrame(0);
      (*(void (**)(unsigned char *, unsigned char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v5 = *(void *)__src;
      char v6 = __src[8];
      outlined copy of Result<_DataTable, Error>(*(void *)__src, v6);
      *(void *)__dst = v5;
      __dst[8] = v6;
      swift_storeEnumTagMultiPayload(__dst, a3, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLLinearRegressor.ModelParameters.ValidationData;
  if (!type metadata singleton initialization cache for MLLinearRegressor.ModelParameters.ValidationData) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLLinearRegressor.ModelParameters.ValidationData);
  }
  return result;
}

void *assignWithTake for MLLinearRegressor.ModelParameters.ValidationData(void *__dst, void *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)__dst);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 2)
    {
      uint64_t v4 = type metadata accessor for DataFrame(0);
      (*(void (**)(void *, void *, uint64_t))(*(void *)(v4 - 8) + 32))(__dst, __src, v4);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLLinearRegressor.ModelParameters.ValidationData(uint64_t a1)
{
  v5[0] = &unk_350240;
  v5[1] = &unk_350258;
  uint64_t result = type metadata accessor for DataFrame(319);
  if (v4 <= 0x3F)
  {
    v5[2] = *(void *)(result - 8) + 64;
    swift_initEnumMetadataMultiPayload(a1, 256, 3, v5, v2, v3);
    return 0;
  }
  return result;
}

uint64_t MLLinearRegressor.ModelParameters.ValidationData.asTable()(__m128 a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = type metadata accessor for DataFrame(0);
  uint64_t v27 = *(void *)(v4 - 8);
  int64_t v5 = *(void *)(v27 + 64);
  char v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v29 = &v25;
  uint64_t v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v28 = &v25;
  uint64_t v10 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  int64_t v11 = *(void *)(*(void *)(v10 - 8) + 64);
  uint64_t v12 = alloca(v11);
  long long v13 = alloca(v11);
  outlined init with copy of MLLinearRegressor.ModelParameters.ValidationData(v2, (uint64_t)&v25);
  uint64_t result = swift_getEnumCaseMultiPayload(&v25, v10);
  switch((int)result)
  {
    case 0:
      *(void *)uint64_t v3 = 0;
      *(unsigned char *)(v3 + 8) = -1;
      break;
    case 1:
      uint64_t result = v25;
      char v15 = v26;
      goto LABEL_7;
    case 2:
      long long v16 = v28;
      uint64_t v17 = v27;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v27 + 32))(v28, &v25, v4);
      uint64_t v18 = (uint64_t)v29;
      *(double *)a1.i64 = (*(double (**)(uint64_t *, uint64_t *, uint64_t))(v17 + 16))(v29, v16, v4);
      MLDataTable.init(_:convertArraysToShapedArrays:)(v18, 1, a1);
      (*(void (**)(uint64_t *, uint64_t))(v17 + 8))(v16, v4);
      uint64_t result = v30;
      char v15 = v31;
LABEL_7:
      *(void *)uint64_t v3 = result;
      *(unsigned char *)(v3 + 8) = v15;
      break;
    case 3:
      uint64_t v19 = v3;
      uint64_t empty = tc_v1_sframe_create_empty(0);
      if (!empty) {
        BUG();
      }
      uint64_t v21 = empty;
      uint64_t v22 = type metadata accessor for CMLTable();
      uint64_t v23 = swift_allocObject(v22, 24, 7);
      *(void *)(v23 + 16) = v21;
      uint64_t v24 = type metadata accessor for _DataTable();
      swift_allocObject(v24, 40, 7);
      uint64_t result = _DataTable.init(impl:)(v23);
      *(void *)uint64_t v19 = result;
      *(unsigned char *)(v19 + 8) = 0;
      break;
  }
  return result;
}

uint64_t MLLinearRegressor.ModelParameters.ValidationData.generateDataFrames(trainingData:)(uint64_t a1, uint64_t a2, void (*a3)(uint64_t *, uint64_t, uint64_t))
{
  uint64_t v55 = v3;
  uint64_t v57 = a3;
  uint64_t v56 = (uint64_t *)a2;
  uint64_t v54 = a1;
  uint64_t v5 = type metadata accessor for DataFrame(0);
  uint64_t v58 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v58 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v50 = &v44;
  uint64_t v46 = type metadata accessor for DataFrame.Slice(0);
  uint64_t v51 = *(void *)(v46 - 8);
  int64_t v9 = *(void *)(v51 + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v48 = &v44;
  uint64_t v12 = alloca(v9);
  long long v13 = alloca(v9);
  uint64_t v53 = &v44;
  long long v14 = alloca(v9);
  char v15 = alloca(v9);
  uint64_t v52 = &v44;
  int64_t v16 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame.Slice?)
                              - 8)
                  + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v47 = &v44;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v49 = &v44;
  uint64_t v21 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  int64_t v22 = *(void *)(*(void *)(v21 - 8) + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  outlined init with copy of MLLinearRegressor.ModelParameters.ValidationData(v4, (uint64_t)&v44);
  switch(swift_getEnumCaseMultiPayload(&v44, v21))
  {
    case 0u:
      uint64_t v58 = v5;
      uint64_t v25 = (uint64_t)v49;
      uint64_t v26 = (uint64_t)v52;
      DataFrame.randomSplit(strategy:)((uint64_t)v49, (uint64_t)v52, (uint64_t)&v44);
      uint64_t v27 = v53;
      uint64_t v28 = v46;
      uint64_t v57 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 16);
      v57(v53, v26, v46);
      DataFrame.init(_:)(v27);
      uint64_t v29 = (uint64_t)v47;
      outlined init with copy of DataFrame.Slice?(v25, (uint64_t)v47);
      if (__swift_getEnumTagSinglePayload(v29, 1, v28) == 1)
      {
        __swift_storeEnumTagSinglePayload((uint64_t)v56, 1, 1, v58);
        uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v51 + 8);
      }
      else
      {
        uint64_t v40 = v53;
        uint64_t v41 = v51;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 32))(v53, v29, v28);
        double v42 = v48;
        v57(v48, (uint64_t)v40, v28);
        uint64_t v43 = (uint64_t)v56;
        DataFrame.init(_:)(v42);
        uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v41 + 8);
        v30(v53, v28);
        __swift_storeEnumTagSinglePayload(v43, 0, 1, v58);
      }
      v30(v52, v28);
      return outlined destroy of DataFrame.Slice?((uint64_t)v49);
    case 1u:
      uint64_t v35 = v44;
      char v36 = v45;
      (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
      uint64_t v44 = v35;
      char v45 = v36;
      uint64_t v37 = (uint64_t)v56;
      DataFrame.init(_:)((uint64_t)&v44);
      uint64_t v33 = v37;
      goto LABEL_10;
    case 2u:
      char v31 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v58 + 32);
      v31(v50, &v44, v5);
      if (DataFrameProtocol.isEmpty.getter(v5, &protocol witness table for DataFrame))
      {
        uint64_t v32 = v58;
        (*(void (**)(uint64_t *, uint64_t))(v58 + 8))(v50, v5);
        (*(void (**)(uint64_t, void, uint64_t))(v32 + 16))(v54, v57, v5);
LABEL_7:
        uint64_t v33 = (uint64_t)v56;
        uint64_t v34 = 1;
      }
      else
      {
        (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
        uint64_t v38 = (uint64_t)v56;
        v31(v56, v50, v5);
        uint64_t v33 = v38;
LABEL_10:
        uint64_t v34 = 0;
      }
      return __swift_storeEnumTagSinglePayload(v33, v34, 1, v5);
    case 3u:
      (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
      goto LABEL_7;
  }
}

float MLFewShotSoundClassifier.ModelParameters.learningRate.getter()
{
  return *(float *)(v0 + 8);
}

uint64_t MLFewShotSoundClassifier.ModelParameters.batchSize.getter()
{
  return *(void *)(v0 + 16);
}

uint64_t MLFewShotSoundClassifier.ModelParameters.lossParameters.getter()
{
  int v2 = *(_DWORD *)(v1 + 32);
  *(void *)uint64_t result = *(void *)(v1 + 24);
  *(_DWORD *)(result + 8) = v2;
  return result;
}

float MLFewShotSoundClassifier.ModelParameters.LossParameters.gamma.getter()
{
  return *(float *)v0;
}

void MLFewShotSoundClassifier.ModelParameters.LossParameters.gamma.setter(float a1)
{
  *uint64_t v1 = a1;
}

void (*MLFewShotSoundClassifier.ModelParameters.LossParameters.gamma.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

float MLFewShotSoundClassifier.ModelParameters.LossParameters.epsilon.getter()
{
  return *(float *)(v0 + 4);
}

void MLFewShotSoundClassifier.ModelParameters.LossParameters.epsilon.setter(float a1)
{
  *(float *)(v1 + 4) = a1;
}

void (*MLFewShotSoundClassifier.ModelParameters.LossParameters.epsilon.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

float MLFewShotSoundClassifier.ModelParameters.LossParameters.alpha.getter()
{
  return *(float *)(v0 + 8);
}

void MLFewShotSoundClassifier.ModelParameters.LossParameters.alpha.setter(float a1)
{
  *(float *)(v1 + 8) = a1;
}

void (*MLFewShotSoundClassifier.ModelParameters.LossParameters.alpha.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

float static MLFewShotSoundClassifier.__Defaults.gamma.getter()
{
  return 10000.0;
}

float static MLFewShotSoundClassifier.__Defaults.epsilon.getter()
{
  return 0.0000001;
}

float static MLFewShotSoundClassifier.__Defaults.alpha.getter()
{
  return 2.0;
}

float *MLFewShotSoundClassifier.ModelParameters.LossParameters.init(gamma:epsilon:alpha:)(float a1, float a2, float a3)
{
  *uint64_t result = a1;
  result[1] = a2;
  result[2] = a3;
  return result;
}

uint64_t MLFewShotSoundClassifier.ModelParameters.maxIterations.getter()
{
  return *(void *)v0;
}

void MLFewShotSoundClassifier.ModelParameters.maxIterations.setter(uint64_t a1)
{
  *uint64_t v1 = a1;
}

void (*MLFewShotSoundClassifier.ModelParameters.maxIterations.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

void MLFewShotSoundClassifier.ModelParameters.learningRate.setter(float a1)
{
  *(float *)(v1 + 8) = a1;
}

uint64_t (*MLFewShotSoundClassifier.ModelParameters.learningRate.modify(uint64_t a1))(_DWORD *a1)
{
  *(void *)a1 = v1;
  *(_DWORD *)(a1 + 8) = *(_DWORD *)(v1 + 8);
  return MLFewShotSoundClassifier.ModelParameters.learningRate.modify;
}

uint64_t MLFewShotSoundClassifier.ModelParameters.learningRate.modify(_DWORD *a1)
{
  uint64_t result = *(void *)a1;
  *(_DWORD *)(*(void *)a1 + 8) = a1[2];
  return result;
}

void MLFewShotSoundClassifier.ModelParameters.batchSize.setter(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
}

uint64_t (*MLFewShotSoundClassifier.ModelParameters.batchSize.modify(void *a1))(uint64_t *a1)
{
  a1[1] = v1;
  *a1 = *(void *)(v1 + 16);
  return MLFewShotSoundClassifier.ModelParameters.batchSize.modify;
}

uint64_t MLFewShotSoundClassifier.ModelParameters.batchSize.modify(uint64_t *a1)
{
  uint64_t result = *a1;
  *(void *)(a1[1] + 16) = *a1;
  return result;
}

uint64_t (*MLFewShotSoundClassifier.ModelParameters.lossParamters.modify(uint64_t a1))(uint64_t *a1)
{
  *(void *)a1 = v1;
  int v2 = *(_DWORD *)(v1 + 32);
  *(void *)(a1 + 8) = *(void *)(v1 + 24);
  *(_DWORD *)(a1 + 16) = v2;
  return MLFewShotSoundClassifier.ModelParameters.lossParamters.modify;
}

uint64_t MLFewShotSoundClassifier.ModelParameters.lossParamters.modify(uint64_t *a1)
{
  return MLFewShotSoundClassifier.ModelParameters.lossParamters.modify(a1);
}

{
  uint64_t result;
  int v2;

  uint64_t result = *a1;
  int v2 = *((_DWORD *)a1 + 4);
  *(void *)(result + 24) = a1[1];
  *(_DWORD *)(result + 32) = v2;
  return result;
}

uint64_t key path getter for MLFewShotSoundClassifier.ModelParameters.lossParamters : MLFewShotSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t (*a4)(void))
{
  uint64_t v5 = v4;
  uint64_t result = a4();
  *(void *)uint64_t v5 = v7;
  *(_DWORD *)(v5 + 8) = v8;
  return result;
}

uint64_t key path setter for MLFewShotSoundClassifier.ModelParameters.lossParamters : MLFewShotSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t (*a5)(void))
{
  return a5();
}

void MLFewShotSoundClassifier.ModelParameters.lossParameters.setter(uint64_t a1)
{
  int v2 = *(_DWORD *)(a1 + 8);
  *(void *)(v1 + 24) = *(void *)a1;
  *(_DWORD *)(v1 + 32) = v2;
}

uint64_t (*MLFewShotSoundClassifier.ModelParameters.lossParameters.modify(uint64_t a1))(uint64_t *a1)
{
  *(void *)a1 = v1;
  int v2 = *(_DWORD *)(v1 + 32);
  *(void *)(a1 + 8) = *(void *)(v1 + 24);
  *(_DWORD *)(a1 + 16) = v2;
  return MLFewShotSoundClassifier.ModelParameters.lossParamters.modify;
}

uint64_t MLFewShotSoundClassifier.ModelParameters.hallucinator.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = v1 + *(int *)(type metadata accessor for MLFewShotSoundClassifier.ModelParameters(0) + 32);
  uint64_t v4 = type metadata accessor for URL(0);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(v2, v3, v4);
}

uint64_t type metadata accessor for MLFewShotSoundClassifier.ModelParameters(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLFewShotSoundClassifier.ModelParameters;
  if (!type metadata singleton initialization cache for MLFewShotSoundClassifier.ModelParameters) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLFewShotSoundClassifier.ModelParameters);
  }
  return result;
}

uint64_t MLFewShotSoundClassifier.ModelParameters.hallucinator.setter(uint64_t a1)
{
  uint64_t v2 = v1 + *(int *)(type metadata accessor for MLFewShotSoundClassifier.ModelParameters(0) + 32);
  uint64_t v3 = type metadata accessor for URL(0);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v3 - 8) + 40))(v2, a1, v3);
}

void (*MLFewShotSoundClassifier.ModelParameters.hallucinator.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLFewShotSoundClassifier.ModelParameters.pretrainedModel.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLFewShotSoundClassifier.ModelParameters(0);
  return outlined init with copy of URL?(v1 + *(int *)(v3 + 36), v2);
}

uint64_t MLFewShotSoundClassifier.ModelParameters.pretrainedModel.setter(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLFewShotSoundClassifier.ModelParameters(0);
  return outlined assign with take of URL?(a1, v1 + *(int *)(v2 + 36));
}

void (*MLFewShotSoundClassifier.ModelParameters.pretrainedModel.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t static MLFewShotSoundClassifier.__Defaults.batchSize.getter()
{
  return 128;
}

float static MLFewShotSoundClassifier.__Defaults.learningRate.getter()
{
  return 0.0099999998;
}

uint64_t MLFewShotSoundClassifier.ModelParameters.init(maxIterations:batchSize:learningRate:lossParameters:hallucinator:pretrainedModel:)(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t a4, uint64_t a5, float a6)
{
  uint64_t v8 = v6;
  int v16 = *((_DWORD *)a3 + 2);
  *(_DWORD *)(v6 + 8) = 1008981770;
  *(void *)(v6 + 16) = 128;
  *(void *)(v6 + 24) = 0x33D6BF95461C4000;
  *(_DWORD *)(v6 + 32) = 0x40000000;
  uint64_t v9 = type metadata accessor for MLFewShotSoundClassifier.ModelParameters(0);
  uint64_t v10 = v8 + *(int *)(v9 + 36);
  uint64_t v11 = type metadata accessor for URL(0);
  uint64_t v15 = *a3;
  __swift_storeEnumTagSinglePayload(v10, 1, 1, v11);
  *(void *)uint64_t v8 = a1;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v11 - 8) + 32))(v8 + *(int *)(v9 + 32), a4, v11);
  outlined assign with take of URL?(a5, v10);
  uint64_t result = a2;
  *(void *)(v8 + 16) = a2;
  *(float *)(v8 + 8) = a6;
  *(void *)(v8 + 24) = v15;
  *(_DWORD *)(v8 + 32) = v16;
  return result;
}

uint64_t MLFewShotSoundClassifier.ModelParameters.init(maxIterations:hallucinator:pretrainedModel:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  *(_DWORD *)(v3 + 8) = 1008981770;
  *(void *)(v3 + 16) = 128;
  *(void *)(v3 + 24) = 0x33D6BF95461C4000;
  *(_DWORD *)(v3 + 32) = 0x40000000;
  uint64_t v5 = type metadata accessor for MLFewShotSoundClassifier.ModelParameters(0);
  uint64_t v6 = v4 + *(int *)(v5 + 36);
  uint64_t v7 = type metadata accessor for URL(0);
  __swift_storeEnumTagSinglePayload(v6, 1, 1, v7);
  *(void *)uint64_t v4 = a1;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v7 - 8) + 32))(v4 + *(int *)(v5 + 32), a2, v7);
  outlined assign with take of URL?(a3, v6);
  *(_DWORD *)(v4 + 8) = 1008981770;
  *(void *)(v4 + 16) = 128;
  *(void *)(v4 + 24) = 0x33D6BF95461C4000;
  uint64_t result = 0x40000000;
  *(_DWORD *)(v4 + 32) = 0x40000000;
  return result;
}

uint64_t static MLFewShotSoundClassifier.__Defaults.maxIterations.getter()
{
  return 25;
}

void sub_25BBF4()
{
  float *v0 = MLFewShotSoundClassifier.ModelParameters.learningRate.getter();
}

void sub_25BC0F(float *a1)
{
}

uint64_t sub_25BC2A()
{
  uint64_t v1 = v0;
  uint64_t result = MLFewShotSoundClassifier.ModelParameters.batchSize.getter();
  *uint64_t v1 = result;
  return result;
}

void sub_25BC44(uint64_t *a1)
{
}

uint64_t sub_25BC5E(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return key path getter for MLFewShotSoundClassifier.ModelParameters.lossParamters : MLFewShotSoundClassifier.ModelParameters(a1, a2, a3, MLFewShotSoundClassifier.ModelParameters.lossParamters.getter);
}

uint64_t sub_25BC70(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for MLFewShotSoundClassifier.ModelParameters.lossParamters : MLFewShotSoundClassifier.ModelParameters(a1, a2, a3, a4, (uint64_t (*)(void))MLFewShotSoundClassifier.ModelParameters.lossParamters.setter);
}

uint64_t sub_25BC82(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return key path getter for MLFewShotSoundClassifier.ModelParameters.lossParamters : MLFewShotSoundClassifier.ModelParameters(a1, a2, a3, MLFewShotSoundClassifier.ModelParameters.lossParameters.getter);
}

uint64_t sub_25BC94(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for MLFewShotSoundClassifier.ModelParameters.lossParamters : MLFewShotSoundClassifier.ModelParameters(a1, a2, a3, a4, (uint64_t (*)(void))MLFewShotSoundClassifier.ModelParameters.lossParameters.setter);
}

void *initializeBufferWithCopyOfBuffer for MLFewShotSoundClassifier.ModelParameters(uint64_t a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v4 = (void *)a1;
  int v5 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v15 = *a2;
    void *v4 = *a2;
    uint64_t v4 = (void *)(v15 + ((v5 + 16) & ~v5));
    swift_retain();
  }
  else
  {
    *(void *)a1 = *a2;
    *(_DWORD *)(a1 + 8) = *((_DWORD *)a2 + 2);
    *(void *)(a1 + 16) = a2[2];
    *(void *)(a1 + 24) = a2[3];
    *(_DWORD *)(a1 + 32) = *((_DWORD *)a2 + 8);
    uint64_t v7 = *(int *)(a3 + 32);
    uint64_t v17 = a1 + v7;
    uint64_t v8 = type metadata accessor for URL(0);
    uint64_t v9 = (uint64_t)a2 + v7;
    uint64_t v10 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v8 - 8) + 16);
    v10(v17, v9, v8);
    uint64_t v11 = *(int *)(a3 + 36);
    uint64_t v12 = (void *)(a1 + v11);
    long long v13 = (char *)a2 + v11;
    if (__swift_getEnumTagSinglePayload((uint64_t)v13, 1, v8))
    {
      uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
      memcpy(v12, v13, *(void *)(*(void *)(v14 - 8) + 64));
    }
    else
    {
      v10((uint64_t)v12, (uint64_t)v13, v8);
      __swift_storeEnumTagSinglePayload((uint64_t)v12, 0, 1, v8);
    }
  }
  return v4;
}

uint64_t destroy for MLFewShotSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a1 + *(int *)(a2 + 32);
  uint64_t v4 = type metadata accessor for URL(0);
  uint64_t v5 = v3;
  uint64_t v6 = *(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8);
  v6(v5, v4);
  uint64_t v7 = a1 + *(int *)(a2 + 36);
  uint64_t result = __swift_getEnumTagSinglePayload(v7, 1, v4);
  if (!result) {
    return v6(v7, v4);
  }
  return result;
}

uint64_t initializeWithCopy for MLFewShotSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  *(_DWORD *)(a1 + 8) = *(_DWORD *)(a2 + 8);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  *(_DWORD *)(a1 + 32) = *(_DWORD *)(a2 + 32);
  uint64_t v5 = *(int *)(a3 + 32);
  uint64_t v14 = (void *)(a1 + v5);
  uint64_t v6 = type metadata accessor for URL(0);
  uint64_t v7 = (const void *)(a2 + v5);
  uint64_t v8 = *(void (**)(void *, const void *, uint64_t))(*(void *)(v6 - 8) + 16);
  v8(v14, v7, v6);
  uint64_t v9 = *(int *)(a3 + 36);
  uint64_t v10 = (void *)(a1 + v9);
  uint64_t v11 = (const void *)(v9 + a2);
  if (__swift_getEnumTagSinglePayload((uint64_t)v11, 1, v6))
  {
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v10, v11, *(void *)(*(void *)(v12 - 8) + 64));
  }
  else
  {
    v8(v10, v11, v6);
    __swift_storeEnumTagSinglePayload((uint64_t)v10, 0, 1, v6);
  }
  return a1;
}

uint64_t assignWithCopy for MLFewShotSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  *(_DWORD *)(a1 + 8) = *(_DWORD *)(a2 + 8);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(_DWORD *)(a1 + 24) = *(_DWORD *)(a2 + 24);
  *(_DWORD *)(a1 + 28) = *(_DWORD *)(a2 + 28);
  *(_DWORD *)(a1 + 32) = *(_DWORD *)(a2 + 32);
  uint64_t v4 = *(int *)(a3 + 32);
  uint64_t v5 = type metadata accessor for URL(0);
  uint64_t v15 = *(void *)(v5 - 8);
  uint64_t v14 = *(void (**)(void *, const void *, uint64_t))(v15 + 24);
  v14((void *)(a1 + v4), (const void *)(a2 + v4), v5);
  uint64_t v6 = *(int *)(a3 + 36);
  uint64_t v7 = (const void *)(v6 + a2);
  __dst = (void *)(a1 + v6);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(a1 + v6, 1, v5);
  int v9 = __swift_getEnumTagSinglePayload((uint64_t)v7, 1, v5);
  if (EnumTagSinglePayload)
  {
    if (!v9)
    {
      (*(void (**)(void *, const void *, uint64_t))(v15 + 16))(__dst, v7, v5);
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v5);
      return a1;
    }
    size_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                                - 8)
                    + 64);
    uint64_t v12 = __dst;
  }
  else
  {
    if (!v9)
    {
      v14(__dst, v7, v5);
      return a1;
    }
    (*(void (**)(void *, uint64_t, uint64_t, void (*)(void *, const void *, uint64_t)))(v15 + 8))(__dst, v5, v10, v14);
    size_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                                - 8)
                    + 64);
    uint64_t v12 = __dst;
  }
  memcpy(v12, v7, v11);
  return a1;
}

uint64_t initializeWithTake for MLFewShotSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  *(_DWORD *)(a1 + 8) = *(_DWORD *)(a2 + 8);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  *(_DWORD *)(a1 + 32) = *(_DWORD *)(a2 + 32);
  uint64_t v5 = *(int *)(a3 + 32);
  uint64_t v14 = (void *)(a1 + v5);
  uint64_t v6 = type metadata accessor for URL(0);
  uint64_t v7 = (const void *)(a2 + v5);
  uint64_t v8 = *(void (**)(void *, const void *, uint64_t))(*(void *)(v6 - 8) + 32);
  v8(v14, v7, v6);
  uint64_t v9 = *(int *)(a3 + 36);
  uint64_t v10 = (void *)(a1 + v9);
  size_t v11 = (const void *)(v9 + a2);
  if (__swift_getEnumTagSinglePayload((uint64_t)v11, 1, v6))
  {
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v10, v11, *(void *)(*(void *)(v12 - 8) + 64));
  }
  else
  {
    v8(v10, v11, v6);
    __swift_storeEnumTagSinglePayload((uint64_t)v10, 0, 1, v6);
  }
  return a1;
}

uint64_t assignWithTake for MLFewShotSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = a3;
  *(void *)a1 = *(void *)a2;
  *(_DWORD *)(a1 + 8) = *(_DWORD *)(a2 + 8);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  *(_DWORD *)(a1 + 32) = *(_DWORD *)(a2 + 32);
  uint64_t v5 = *(int *)(a3 + 32);
  uint64_t v6 = type metadata accessor for URL(0);
  uint64_t v15 = *(void *)(v6 - 8);
  uint64_t v14 = *(void (**)(void *, const void *, uint64_t))(v15 + 40);
  v14((void *)(a1 + v5), (const void *)(a2 + v5), v6);
  uint64_t v7 = *(int *)(v3 + 36);
  uint64_t v8 = (const void *)(v7 + a2);
  __dst = (void *)(a1 + v7);
  LODWORD(v3) = __swift_getEnumTagSinglePayload(a1 + v7, 1, v6);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v8, 1, v6);
  if (v3)
  {
    if (!EnumTagSinglePayload)
    {
      (*(void (**)(void *, const void *, uint64_t))(v15 + 32))(__dst, v8, v6);
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v6);
      return a1;
    }
    size_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                                - 8)
                    + 64);
    uint64_t v12 = __dst;
  }
  else
  {
    if (!EnumTagSinglePayload)
    {
      v14(__dst, v8, v6);
      return a1;
    }
    (*(void (**)(void *, uint64_t, uint64_t, void (*)(void *, const void *, uint64_t)))(v15 + 8))(__dst, v6, v10, v14);
    size_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                                - 8)
                    + 64);
    uint64_t v12 = __dst;
  }
  memcpy(v12, v8, v11);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLFewShotSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_25C26F);
}

uint64_t sub_25C26F(uint64_t a1, unsigned int a2, uint64_t a3)
{
  uint64_t v4 = type metadata accessor for URL(0);
  if (*(_DWORD *)(*(void *)(v4 - 8) + 84) == a2)
  {
    uint64_t v5 = *(int *)(a3 + 32);
  }
  else
  {
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    uint64_t v5 = *(int *)(a3 + 36);
  }
  return __swift_getEnumTagSinglePayload(v5 + a1, a2, v4);
}

uint64_t storeEnumTagSinglePayload for MLFewShotSoundClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_25C2D2);
}

uint64_t sub_25C2D2(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = type metadata accessor for URL(0);
  if (*(_DWORD *)(*(void *)(v6 - 8) + 84) == a3)
  {
    uint64_t v7 = *(int *)(a4 + 32);
  }
  else
  {
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    uint64_t v7 = *(int *)(a4 + 36);
  }
  return __swift_storeEnumTagSinglePayload(v7 + a1, a2, a2, v6);
}

uint64_t type metadata completion function for MLFewShotSoundClassifier.ModelParameters(uint64_t a1)
{
  v4[0] = (char *)&value witness table for Builtin.Int64 + 64;
  v4[1] = (char *)&value witness table for Builtin.Int32 + 64;
  v4[2] = (char *)&value witness table for Builtin.Int64 + 64;
  v4[3] = &unk_3502D0;
  uint64_t result = type metadata accessor for URL(319);
  if (v2 <= 0x3F)
  {
    _OWORD v4[4] = *(void *)(result - 8) + 64;
    uint64_t result = type metadata accessor for URL?(319);
    if (v3 <= 0x3F)
    {
      v4[5] = *(void *)(result - 8) + 64;
      swift_initStructMetadata(a1, 256, 6, v4, a1 + 16);
      return 0;
    }
  }
  return result;
}

uint64_t __swift_memcpy12_4(uint64_t a1, uint64_t a2)
{
  uint64_t result = a1;
  *(_DWORD *)(a1 + 8) = *(_DWORD *)(a2 + 8);
  *(void *)a1 = *(void *)a2;
  return result;
}

uint64_t getEnumTagSinglePayload for MLFewShotSoundClassifier.ModelParameters.LossParameters(uint64_t a1, int a2)
{
  uint64_t result = 0;
  if (a2)
  {
    if (*(unsigned char *)(a1 + 12)) {
      return (*(_DWORD *)a1 + 1);
    }
  }
  return result;
}

void storeEnumTagSinglePayload for MLFewShotSoundClassifier.ModelParameters.LossParameters(uint64_t a1, int a2, int a3)
{
  if (!a2)
  {
    if (!a3) {
      return;
    }
    char v3 = 0;
    goto LABEL_6;
  }
  *(_DWORD *)(a1 + 8) = 0;
  *(void *)a1 = (a2 - 1);
  char v3 = 1;
  if (a3) {
LABEL_6:
  }
    *(unsigned char *)(a1 + 12) = v3;
}

ValueMetadata *type metadata accessor for MLFewShotSoundClassifier.ModelParameters.LossParameters()
{
  return &type metadata for MLFewShotSoundClassifier.ModelParameters.LossParameters;
}

ValueMetadata *type metadata accessor for MLFewShotSoundClassifier.__Defaults()
{
  return &type metadata for MLFewShotSoundClassifier.__Defaults;
}

uint64_t MLFewShotSoundClassifier.ModelParameters.lossParamters.getter()
{
  return MLFewShotSoundClassifier.ModelParameters.lossParameters.getter();
}

void MLFewShotSoundClassifier.ModelParameters.lossParamters.setter(uint64_t a1)
{
}

uint64_t MLActivityClassifier.Model.writeMLModel(to:metadata:)(uint64_t a1, uint64_t a2)
{
  uint64_t v34 = v2;
  uint64_t v29 = v3;
  uint64_t v31 = type metadata accessor for Model(0);
  uint64_t v30 = *(void *)(v31 - 8);
  int64_t v4 = *(void *)(v30 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v35 = &v16;
  uint64_t v33 = type metadata accessor for URL(0);
  uint64_t v7 = *(void *)(v33 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v23 = *(void *)a2;
  uint64_t v24 = *(void *)(a2 + 8);
  uint64_t v25 = *(void *)(a2 + 16);
  uint64_t v26 = *(void *)(a2 + 24);
  long long v22 = *(_OWORD *)(a2 + 32);
  uint64_t v27 = *(void *)(a2 + 48);
  uint64_t v28 = *(void *)(a2 + 56);
  uint64_t v11 = *(void *)(a2 + 64);
  uint64_t v12 = v34;
  uint64_t result = static _ValidationUtilities.validateWriteLocation(atURL:defaultName:fileExtension:)(a1, 0xD000000000000012, (unint64_t)("Classifier.Classifier.swift" + 0x8000000000000000), 0x6C65646F6D6C6DLL, (void *)0xE700000000000000);
  if (!v12)
  {
    uint64_t v34 = &v16;
    uint64_t v32 = v7;
    MLActivityClassifier.Model.asModelSpecification()();
    v17[0] = v23;
    v17[1] = v24;
    v17[2] = v25;
    v17[3] = v26;
    long long v18 = v22;
    uint64_t v19 = v27;
    uint64_t v20 = v28;
    uint64_t v21 = v11;
    MLActivityClassifier.Model.addMetadata(to:_:)((uint64_t)v35, v17);
    uint64_t v14 = v34;
    Model.write(to:)(v34);
    uint64_t v15 = v32;
    (*(void (**)(uint64_t *, uint64_t))(v30 + 8))(v35, v31);
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v15 + 8))(v14, v33);
  }
  return result;
}

uint64_t MLActivityClassifier.Model.asModelSpecification()()
{
  uint64_t v82 = v1;
  uint64_t v72 = v0;
  uint64_t v61 = type metadata accessor for ModelKind(0);
  uint64_t v60 = *(void *)(v61 - 8);
  int64_t v3 = *(void *)(v60 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v62 = v56;
  uint64_t v80 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType(0);
  uint64_t v83 = *(void *)(v80 - 8);
  int64_t v6 = *(void *)(v83 + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v81 = v56;
  uint64_t v58 = type metadata accessor for FeatureType(0);
  uint64_t v59 = *(void *)(v58 - 8);
  int64_t v9 = *(void *)(v59 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v68 = v56;
  uint64_t v69 = type metadata accessor for FeatureDescription(0);
  uint64_t v12 = *(void *)(v69 - 8);
  int64_t v13 = *(void *)(v12 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v73 = v56;
  uint64_t v75 = type metadata accessor for NeuralNetworkClassifier.ClassLabels(0);
  uint64_t v76 = *(void *)(v75 - 8);
  int64_t v16 = *(void *)(v76 + 64);
  uint64_t v17 = alloca(v16);
  long long v18 = alloca(v16);
  uint64_t v77 = v56;
  uint64_t v19 = type metadata accessor for NeuralNetworkClassifier(0);
  uint64_t v20 = *(void *)(v19 - 8);
  int64_t v21 = *(void *)(v20 + 64);
  long long v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  int64_t v74 = v56;
  uint64_t v71 = v2;
  uint64_t v24 = v82;
  uint64_t result = MLActivityClassifier.Model.asModelLayers()();
  if (!v24)
  {
    uint64_t v66 = v19;
    uint64_t v65 = v20;
    uint64_t v70 = v12;
    uint64_t v82 = 0;
    NeuralNetworkClassifier.init(layers:preprocessors:)(result, _swiftEmptyArrayStorage);
    uint64_t v26 = type metadata accessor for MLActivityClassifier.Model(0);
    uint64_t v27 = *(int *)(v26 + 60);
    uint64_t v28 = v26;
    uint64_t v78 = v26;
    uint64_t v29 = *(void *)(v71 + v27);
    uint64_t v30 = v77;
    *(void *)uint64_t v77 = v29;
    (*(void (**)(char *, void, uint64_t))(v76 + 104))(v30, enum case for NeuralNetworkClassifier.ClassLabels.string(_:), v75);
    swift_bridgeObjectRetain(v29);
    NeuralNetworkClassifier.classLabels.setter(v30);
    Model.init()();
    Model.specificationVersion.setter(4);
    uint64_t v31 = v71;
    uint64_t v32 = *(void *)(v71 + *(int *)(v28 + 64) + 40);
    uint64_t v33 = alloca(24);
    uint64_t v34 = alloca(32);
    uint64_t v58 = v71;
    swift_bridgeObjectRetain(v32);
    uint64_t v35 = v82;
    uint64_t v79 = (char *)_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg5((void (*)(void *))partial apply for closure #1 in MLActivityClassifier.Model.asModelSpecification(), (uint64_t)v56, v32, (uint64_t)v56);
    uint64_t v82 = v35;
    swift_bridgeObjectRelease(v32);
    uint64_t v36 = v83;
    uint64_t v37 = *(void (**)(char *, void, uint64_t))(v83 + 104);
    LODWORD(v76) = enum case for FeatureType.ShapedArrayParameters.DataType.double(_:);
    uint64_t v63 = v37;
    v37(v81, enum case for FeatureType.ShapedArrayParameters.DataType.double(_:), v80);
    uint64_t v77 = (char *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
    uint64_t v38 = (void *)swift_allocObject(v77, 40, 7);
    v38[2] = 1;
    v38[3] = 2;
    uint64_t v39 = *(int *)(v78 + 32);
    uint64_t v40 = *(void *)(v31 + v39);
    uint64_t v75 = 0x4000000000000000;
    if (v40 + 0x4000000000000000 < 0) {
      BUG();
    }
    v38[4] = 2 * v40;
    uint64_t v41 = v68;
    double v42 = v81;
    uint64_t v78 = v39;
    static FeatureType.shapedArray(dataType:shape:optional:)(v81, v38, 0);
    swift_bridgeObjectRelease((_BYTE)v38);
    uint64_t v67 = *(void (**)(char *, uint64_t))(v36 + 8);
    v67(v42, v80);
    FeatureDescription.init(name:type:description:)(0x6E496574617473, 0xE700000000000000, v41, 0xD000000000000010, "o recognize motions." + 0x8000000000000000);
    uint64_t v83 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
    uint64_t v43 = v70;
    uint64_t v64 = *(void *)(v70 + 72);
    uint64_t v44 = *(unsigned __int8 *)(v70 + 80);
    uint64_t v45 = ((int)v44 + 32) & ~*(unsigned __int8 *)(v70 + 80);
    v44 |= 7uLL;
    uint64_t v46 = swift_allocObject(v83, v45 + v64, v44);
    *(void *)(v46 + 16) = 1;
    *(void *)(v46 + 24) = 2;
    (*(void (**)(uint64_t, char *, uint64_t))(v43 + 16))(v45 + v46, v73, v69);
    uint64_t v57 = v79;
    specialized Array.append<A>(contentsOf:)(v46);
    uint64_t v47 = v68;
    Model.inputs.setter(v57);
    uint64_t v48 = swift_allocObject(v83, v45 + 3 * v64, v44);
    *(void *)(v48 + 16) = 3;
    *(void *)(v48 + 24) = 6;
    uint64_t v83 = v48;
    static FeatureType.dictionaryWithStringKeys(optional:)(0);
    uint64_t v79 = "labelProbabilityRaw" + 0x8000000000000000;
    FeatureDescription.init(name:type:description:)(0xD000000000000010, "labelProbabilityRaw" + 0x8000000000000000, v47, 0xD000000000000021, "LSTM state input" + 0x8000000000000000);
    FeatureType.StringParameters.init(optional:)(0);
    (*(void (**)(char *, void, uint64_t))(v59 + 104))(v47, enum case for FeatureType.string(_:), v58);
    FeatureDescription.init(name:type:description:)(0x6C6562616CLL, 0xE500000000000000, v47, 0xD00000000000001DLL, "ion probabilities" + 0x8000000000000000);
    v63(v81, v76, v80);
    uint64_t v49 = (void *)swift_allocObject(v77, 40, 7);
    v49[2] = 1;
    v49[3] = 2;
    uint64_t v50 = *(void *)(v71 + v78);
    v75 += v50;
    if (v75 < 0) {
      BUG();
    }
    v49[4] = 2 * v50;
    uint64_t v51 = v47;
    uint64_t v52 = v81;
    static FeatureType.shapedArray(dataType:shape:optional:)(v81, v49, 0);
    swift_bridgeObjectRelease((_BYTE)v49);
    v67(v52, v80);
    FeatureDescription.init(name:type:description:)(0x74754F6574617473, 0xE800000000000000, v51, 0xD000000000000011, "Class label of top prediction" + 0x8000000000000000);
    Model.outputs.setter(v83);
    Model.predictedFeatureName.setter(0x6C6562616CLL, 0xE500000000000000);
    Model.predictedProbabilitiesName.setter(0xD000000000000010, v79);
    uint64_t v53 = v62;
    uint64_t v54 = v66;
    uint64_t v55 = v65;
    (*(void (**)(char *, char *, uint64_t))(v65 + 16))(v62, v74, v66);
    (*(void (**)(char *, void, uint64_t))(v60 + 104))(v53, enum case for ModelKind.neuralNetworkClassifier(_:), v61);
    Model.kind.setter(v53);
    (*(void (**)(char *, uint64_t))(v70 + 8))(v73, v69);
    return (*(uint64_t (**)(char *, uint64_t))(v55 + 8))(v74, v54);
  }
  return result;
}

uint64_t MLActivityClassifier.Model.addMetadata(to:_:)(uint64_t a1, uint64_t *a2)
{
  uint64_t v48 = v2;
  uint64_t v49 = a1;
  uint64_t v3 = *a2;
  unint64_t v4 = a2[1];
  unint64_t v50 = a2[2];
  unint64_t v5 = a2[3];
  uint64_t v45 = a2[4];
  uint64_t v51 = (void (*)(void *, void))a2[5];
  uint64_t v44 = a2[6];
  uint64_t v6 = HIBYTE(v4) & 0xF;
  if ((v4 & 0x2000000000000000) == 0) {
    uint64_t v6 = v3 & 0xFFFFFFFFFFFFLL;
  }
  unint64_t v7 = a2[7];
  uint64_t v43 = a2[8];
  if (v6)
  {
    swift_bridgeObjectRetain(v4);
  }
  else
  {
    int64_t v8 = NSFullUserName();
    uint64_t v46 = v8;
    uint64_t v3 = static String._unconditionallyBridgeFromObjectiveC(_:)(v46);
    unint64_t v4 = v9;
  }
  Model.author.setter(v3, v4);
  uint64_t v10 = HIBYTE(v5) & 0xF;
  if ((v5 & 0x2000000000000000) == 0) {
    uint64_t v10 = v50 & 0xFFFFFFFFFFFFLL;
  }
  if (v10)
  {
    swift_bridgeObjectRetain(v5);
    unint64_t v11 = v50;
  }
  else
  {
    unint64_t v5 = (unint64_t)("ActivityClassifier" + 0x8000000000000000);
    unint64_t v11 = 0xD000000000000044;
  }
  Model.modelDescription.setter(v11, v5);
  uint64_t v12 = HIBYTE(v7) & 0xF;
  uint64_t v13 = v44;
  if ((v7 & 0x2000000000000000) == 0) {
    uint64_t v12 = v44 & 0xFFFFFFFFFFFFLL;
  }
  if (v12)
  {
    swift_bridgeObjectRetain(v7);
  }
  else
  {
    unint64_t v7 = 0xE300000000000000;
    uint64_t v13 = 3157553;
  }
  Model.versionString.setter(v13, v7);
  if (v51)
  {
    swift_bridgeObjectRetain((_BYTE)v51);
    Model.license.setter(v45, v51);
  }
  unint64_t v50 = *(int *)(type metadata accessor for MLActivityClassifier.Model(0) + 64);
  v47[0] = *(void *)(v48 + v50 + 40);
  swift_bridgeObjectRetain(v47[0]);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  uint64_t v15 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [String] and conformance [A], &demangling cache variable for type metadata for [String], (uint64_t)&protocol conformance descriptor for [A]);
  uint64_t v16 = BidirectionalCollection<>.joined(separator:)(44, 0xE100000000000000, v14, v15);
  uint64_t v18 = v17;
  swift_bridgeObjectRelease(v47[0]);
  uint64_t v19 = (void (*)(void *, void))Model.metadata.modify(v47);
  specialized Dictionary._Variant.setValue(_:forKey:)(v16, v18, 0x7365727574616566, 0xE800000000000000);
  v19(v47, 0);
  uint64_t v20 = v48;
  v47[0] = *(void *)(v48 + v50);
  uint64_t v21 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  uint64_t v23 = v22;
  uint64_t v24 = (void (*)(void *, void))Model.metadata.modify(v47);
  specialized Dictionary._Variant.setValue(_:forKey:)(v21, v23, 0x726574695F78616DLL, 0xEE00736E6F697461);
  v24(v47, 0);
  unint64_t v25 = v50;
  v47[0] = *(void *)(v20 + v50 + 32);
  uint64_t v26 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  uint64_t v28 = v27;
  uint64_t v51 = (void (*)(void *, void))Model.metadata.modify(v47);
  specialized Dictionary._Variant.setValue(_:forKey:)(v26, v28, 0xD000000000000011, (uint64_t)("annotation_scale" + 0x8000000000000000));
  v51(v47, 0);
  uint64_t v29 = v48;
  uint64_t v51 = *(void (**)(void *, void))(v48 + v25 + 64);
  uint64_t v30 = *(void *)(v48 + v25 + 72);
  swift_bridgeObjectRetain(v30);
  uint64_t v31 = (void (*)(void *, void))Model.metadata.modify(v47);
  specialized Dictionary._Variant.setValue(_:forKey:)((uint64_t)v51, v30, 0x5F6E6F6973736573, 0xEA00000000006469);
  v31(v47, 0);
  uint64_t v51 = *(void (**)(void *, void))(v29 + v25 + 48);
  uint64_t v32 = *(void *)(v29 + v25 + 56);
  swift_bridgeObjectRetain(v32);
  uint64_t v33 = (void (*)(void *, void))Model.metadata.modify(v47);
  specialized Dictionary._Variant.setValue(_:forKey:)((uint64_t)v51, v32, 0x746567726174, 0xE600000000000000);
  v33(v47, 0);
  uint64_t v34 = (void (*)(void *, void))Model.metadata.modify(v47);
  specialized Dictionary._Variant.setValue(_:forKey:)(0xD000000000000013, (uint64_t)("ot found in Configuration" + 0x8000000000000000), 1701869940, 0xE400000000000000);
  v34(v47, 0);
  uint64_t v35 = (void (*)(void *, void))Model.metadata.modify(v47);
  specialized Dictionary._Variant.setValue(_:forKey:)(50, 0xE100000000000000, 0x6E6F6973726576, 0xE700000000000000);
  v35(v47, 0);
  if (v43)
  {
    swift_bridgeObjectRetain(v43);
    uint64_t v36 = (void (*)(void *, void))Model.metadata.modify(v47);
    specialized Dictionary._Variant.merge<A>(_:uniquingKeysWith:)(v43, (uint64_t)specialized thunk for @escaping @callee_guaranteed (@in_guaranteed A, @in_guaranteed B) -> (@out A, @out B), 0, v37);
    v36(v47, 0);
  }
  Swift::String v38 = getOSVersion()();
  uint64_t countAndFlagsBits = v38._countAndFlagsBits;
  char object = v38._object;
  uint64_t v41 = (uint64_t (*)(void *, void))Model.metadata.modify(v47);
  specialized Dictionary._Variant.setValue(_:forKey:)(countAndFlagsBits, (uint64_t)object, 0xD00000000000001ALL, (uint64_t)("Recommender Model" + 0x8000000000000000));
  return v41(v47, 0);
}

uint64_t MLActivityClassifier.Model.asModelLayers()()
{
  uint64_t v49 = v0;
  uint64_t v41 = type metadata accessor for NeuralNetwork.Layer.ReshapeParameters.ChannelLayout(0);
  uint64_t v34 = *(void *)(v41 - 8);
  int64_t v1 = *(void *)(v34 + 64);
  uint64_t v2 = alloca(v1);
  uint64_t v3 = alloca(v1);
  uint64_t v35 = &v32;
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for NeuralNetwork.Layer.Kind(0) - 8) + 64);
  unint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v40 = &v32;
  uint64_t v47 = type metadata accessor for NeuralNetwork.Layer.SliceParameters.Axis(0);
  int64_t v7 = *(void *)(*(void *)(v47 - 8) + 64);
  uint64_t v48 = *(uint64_t **)(v47 - 8);
  int64_t v8 = v48;
  unint64_t v9 = alloca(v7);
  uint64_t v10 = alloca(v7);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<NeuralNetwork.Layer>);
  uint64_t v12 = *(void *)(type metadata accessor for NeuralNetwork.Layer(0) - 8);
  uint64_t v13 = *(unsigned __int8 *)(v12 + 80);
  uint64_t v14 = (v13 + 32) & ~v13;
  uint64_t v43 = *(void *)(v12 + 72);
  uint64_t v15 = swift_allocObject(v11, v14 + 13 * v43, v13 | 7);
  *(void *)(v15 + 16) = 13;
  *(void *)(v15 + 24) = 26;
  uint64_t v33 = v15;
  uint64_t v16 = v15 + v14;
  uint64_t v46 = type metadata accessor for MLActivityClassifier.Model(0);
  uint64_t v17 = *(int *)(v46 + 32);
  uint64_t v45 = *(void (**)(uint64_t *, uint64_t))(v49 + v17);
  uint64_t v18 = (void (*)(uint64_t *, void, uint64_t))v8[13];
  unsigned int v42 = enum case for NeuralNetwork.Layer.SliceParameters.Axis.channel(_:);
  uint64_t v19 = v47;
  uint64_t v36 = v18;
  v18(&v32, enum case for NeuralNetwork.Layer.SliceParameters.Axis.channel(_:), v47);
  static NeuralNetwork.Layer.slice(name:inputName:outputName:startIndex:endIndex:stride:axis:)(0x6E496E6564646968, 0xE800000000000000, 0x6E496574617473, 0xE700000000000000, 0x6E496E6564646968, 0xE800000000000000, 0, v45, 1, &v32);
  uint64_t v20 = (void (*)(uint64_t *, uint64_t))v48[1];
  uint64_t v48 = &v32;
  uint64_t v45 = v20;
  v20(&v32, v19);
  uint64_t v21 = *(void *)(v49 + v17);
  if (v21 + 0x4000000000000000 < 0) {
    BUG();
  }
  uint64_t v37 = v49 + v17;
  uint64_t v38 = 2 * v21;
  uint64_t v39 = v16 + v43;
  uint64_t v22 = v48;
  uint64_t v23 = v47;
  v36(v48, v42, v47);
  static NeuralNetwork.Layer.slice(name:inputName:outputName:startIndex:endIndex:stride:axis:)(0x6E496C6C6563, 0xE600000000000000, 0x6E496574617473, 0xE700000000000000, 0x6E496C6C6563, 0xE600000000000000, v21, v38, 1, v22);
  v45(v22, v23);
  uint64_t v48 = (uint64_t *)(v16 + 2 * v43);
  uint64_t v47 = *(int *)(v46 + 64);
  uint64_t v24 = *(void *)(v49 + v47 + 40);
  swift_bridgeObjectRetain(v24);
  unint64_t v25 = v40;
  static NeuralNetwork.Layer.Kind.concatenate(alongSequenceAxis:)(0);
  NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)(0x7365727574616566, 0xE800000000000000, v24, &outlined read-only object #0 of MLActivityClassifier.Model.asModelLayers(), v25);
  uint64_t v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v27 = (void *)swift_allocObject(v26, 64, 7);
  v27[2] = 4;
  v27[3] = 8;
  v27[4] = 1;
  v27[5] = *(void *)(v24 + 16);
  v27[6] = 1;
  v27[7] = *(void *)(v49 + v47 + 32);
  uint64_t v28 = v35;
  uint64_t v44 = v16;
  uint64_t v29 = v34;
  (*(void (**)(uint64_t *, void, uint64_t))(v34 + 104))(v35, enum case for NeuralNetwork.Layer.ReshapeParameters.ChannelLayout.channelFirst(_:), v41);
  static NeuralNetwork.Layer.reshape(name:inputName:outputName:targetShape:targetChannelLayout:)(0x65706168736572, 0xE700000000000000, 0x7365727574616566, 0xE800000000000000, 0x65706168736572, 0xE700000000000000, v27, v28);
  swift_bridgeObjectRelease((_BYTE)v27);
  (*(void (**)(uint64_t *, uint64_t))(v29 + 8))(v28, v41);
  Conv2D.asModelLayer(name:inputName:inputSize:)(1986948963, 0xE400000000000000, 0x65706168736572, 0xE700000000000000);
  static NeuralNetwork.Layer.relu(name:inputName:outputName:)(0x31756C6572, 0xE500000000000000, 1986948963, 0xE400000000000000, 0x31756C6572, 0xE500000000000000);
  MLActivityClassifier.LSTMBlock.asModelLayer(name:inputNames:outputNames:)(1836348268, 0xE400000000000000, (uint64_t)&outlined read-only object #1 of MLActivityClassifier.Model.asModelLayers(), (uint64_t)&outlined read-only object #2 of MLActivityClassifier.Model.asModelLayers());
  uint64_t v30 = v40;
  static NeuralNetwork.Layer.Kind.concatenate(alongSequenceAxis:)(0);
  NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)(0x74754F6574617473, 0xE800000000000000, &outlined read-only object #3 of MLActivityClassifier.Model.asModelLayers(), &outlined read-only object #4 of MLActivityClassifier.Model.asModelLayers(), v30);
  Conv2D.asModelLayer(name:inputName:inputSize:)(0x3065736E6564, 0xE600000000000000, 1836348268, 0xE400000000000000);
  BatchNorm.asModelLayer(name:inputName:)(28258, 0xE200000000000000, 0x3065736E6564, 0xE600000000000000);
  static NeuralNetwork.Layer.relu(name:inputName:outputName:)(0x36756C6572, 0xE500000000000000, 28258, 0xE200000000000000, 0x36756C6572, 0xE500000000000000);
  Conv2D.asModelLayer(name:inputName:inputSize:)(0x3165736E6564, 0xE600000000000000, 0x36756C6572, 0xE500000000000000);
  static NeuralNetwork.Layer.softmax(name:inputName:outputName:)(0xD000000000000010, "labelProbabilityRaw" + 0x8000000000000000, 0x3165736E6564, 0xE600000000000000, 0xD000000000000010, "labelProbabilityRaw" + 0x8000000000000000);
  return v33;
}

uint64_t closure #1 in MLActivityClassifier.Model.asModelSpecification()(uint64_t *a1, uint64_t a2)
{
  uint64_t v22 = a2;
  uint64_t v21 = v2;
  uint64_t v3 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType(0);
  uint64_t v4 = *(void *)(v3 - 8);
  uint64_t v24 = v3;
  int64_t v5 = *(void *)(v4 + 64);
  uint64_t v6 = v4;
  int64_t v7 = alloca(v5);
  int64_t v8 = alloca(v5);
  int64_t v9 = *(void *)(*(void *)(type metadata accessor for FeatureType(0) - 8) + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  unint64_t v25 = &v19;
  uint64_t v23 = *a1;
  uint64_t v12 = a1[1];
  (*(void (**)(uint64_t *, void, uint64_t))(v6 + 104))(&v19, enum case for FeatureType.ShapedArrayParameters.DataType.double(_:), v3);
  uint64_t v13 = v6;
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v15 = (void *)swift_allocObject(v14, 40, 7);
  v15[2] = 1;
  v15[3] = 2;
  v15[4] = *(void *)(v22 + *(int *)(type metadata accessor for MLActivityClassifier.Model(0) + 64) + 32);
  swift_bridgeObjectRetain(v12);
  static FeatureType.shapedArray(dataType:shape:optional:)(&v19, v15, 0);
  swift_bridgeObjectRelease((_BYTE)v15);
  (*(void (**)(uint64_t *, uint64_t))(v13 + 8))(&v19, v24);
  uint64_t v16 = v23;
  uint64_t v19 = v23;
  uint64_t v20 = v12;
  swift_bridgeObjectRetain(v12);
  v17._uint64_t countAndFlagsBits = 0x20776F646E697720;
  v17._char object = (void *)0xED00007475706E69;
  String.append(_:)(v17);
  return FeatureDescription.init(name:type:description:)(v16, v12, v25, v19, v20);
}

uint64_t Conv2D.asModelLayer(name:inputName:inputSize:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v66 = a4;
  uint64_t v67 = a3;
  uint64_t v68 = a2;
  uint64_t v69 = a1;
  uint64_t v79 = v4;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?)
                             - 8)
                 + 64);
  int64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v63 = &v59;
  uint64_t v81 = type metadata accessor for NeuralNetwork.Layer.Kind(0);
  uint64_t v82 = *(void *)(v81 - 8);
  int64_t v9 = *(void *)(v82 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v62 = &v59;
  uint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v70 = &v59;
  uint64_t v64 = type metadata accessor for NeuralNetwork.Layer.ConvolutionParameters(0);
  uint64_t v80 = *(void *)(v64 - 8);
  int64_t v14 = *(void *)(v80 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v65 = &v59;
  int64_t v17 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?)
                              - 8)
                  + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  int64_t v74 = &v59;
  uint64_t v72 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.Extent<Int>);
  uint64_t v73 = *(void *)(v72 - 8);
  int64_t v20 = *(void *)(v73 + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v85 = &v59;
  uint64_t v23 = alloca(v20);
  uint64_t v24 = alloca(v20);
  uint64_t v83 = &v59;
  uint64_t v84 = type metadata accessor for TensorShape(0);
  uint64_t v77 = *(void *)(v84 - 8);
  int64_t v25 = *(void *)(v77 + 64);
  uint64_t v26 = alloca(v25);
  uint64_t v27 = alloca(v25);
  uint64_t v28 = type metadata accessor for Tensor(0);
  uint64_t v29 = *(void *)(v28 - 8);
  int64_t v30 = *(void *)(v29 + 64);
  uint64_t v31 = alloca(v30);
  uint64_t v32 = alloca(v30);
  uint64_t v78 = v5;
  uint64_t v75 = Conv2D.filterCount.getter();
  Conv2D.weight.getter();
  Tensor.shape.getter(0, a2, v33);
  uint64_t v71 = v28;
  (*(void (**)(uint64_t *, uint64_t))(v29 + 8))(&v59, v28);
  uint64_t v76 = TensorShape.subscript.getter(1);
  (*(void (**)(uint64_t *, uint64_t))(v77 + 8))(&v59, v84);
  uint64_t v84 = Conv2D.groupCount.getter();
  uint64_t v60 = Conv2D.kernelSize.getter();
  uint64_t v61 = v34;
  NeuralNetwork.Extent.init(height:width:)(&v60, &v61, &type metadata for Int, &protocol witness table for Int);
  uint64_t v60 = Conv2D.stride.getter();
  uint64_t v61 = v35;
  NeuralNetwork.Extent.init(height:width:)(&v60, &v61, &type metadata for Int, &protocol witness table for Int);
  uint64_t v36 = Conv2D.padding.getter();
  uint64_t v37 = Conv2D.padding.getter();
  Conv2D.padding.getter();
  uint64_t v39 = v38;
  Conv2D.padding.getter();
  uint64_t v40 = (uint64_t)v74;
  static NeuralNetwork.Layer.ConvolutionParameters.PaddingKind.valid(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(v36, v37, v39, v41);
  uint64_t v42 = type metadata accessor for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind(0);
  __swift_storeEnumTagSinglePayload(v40, 0, 1, v42);
  uint64_t v43 = v85;
  uint64_t v44 = v83;
  static NeuralNetwork.Layer.convolution(name:inputName:outputName:outputChannelCount:kernelChannelCount:groupCount:kernelSize:strides:padding:)(v69, v68, v67, v66, v69, v68, v75, v76, v84, v83, v85, v40);
  outlined destroy of Adam<MLFewShotSoundClassifier.TemporalClassifier>(v40, &demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?);
  uint64_t v45 = *(void (**)(uint64_t *, uint64_t))(v73 + 8);
  uint64_t v46 = v72;
  v45(v43, v72);
  v45(v44, v46);
  uint64_t v47 = v70;
  NeuralNetwork.Layer.kind.getter();
  uint64_t v48 = v81;
  uint64_t v49 = v82;
  LODWORD(v85) = (*(uint64_t (**)(uint64_t *))(v82 + 88))(v47);
  if (v85 != enum case for NeuralNetwork.Layer.Kind.convolution(_:))
  {
    (*(void (**)(uint64_t *, uint64_t))(v49 + 8))(v47, v48);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000001ALL, "ModelExport.swift" + 0x8000000000000000, "CreateML/MLActivityClassifier+MLModelExport.swift", 49, 2, 178, 0);
    BUG();
  }
  (*(void (**)(uint64_t *, uint64_t))(v49 + 96))(v47, v48);
  uint64_t v50 = (uint64_t)v65;
  uint64_t v51 = v47;
  uint64_t v52 = v64;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v80 + 32))(v65, v51, v64);
  uint64_t v53 = (uint64_t)v63;
  uint64_t v54 = v78;
  Conv2D.bias.getter();
  BOOL v55 = __swift_getEnumTagSinglePayload(v53, 1, v71) != 1;
  outlined destroy of Adam<MLFewShotSoundClassifier.TemporalClassifier>(v53, &demangling cache variable for type metadata for Tensor?);
  NeuralNetwork.Layer.loadConv2DFromNeuralNetworks(_:useBias:into:)(v54, v55, v50);
  uint64_t v56 = v62;
  uint64_t v57 = v80;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v80 + 16))(v62, v50, v52);
  (*(void (**)(uint64_t *, void, uint64_t))(v82 + 104))(v56, v85, v81);
  NeuralNetwork.Layer.kind.setter(v56);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v57 + 8))(v50, v52);
}

uint64_t MLActivityClassifier.LSTMBlock.asModelLayer(name:inputNames:outputNames:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v135 = v5;
  uint64_t v111 = a4;
  uint64_t v112 = a3;
  uint64_t v113 = a2;
  uint64_t v114 = a1;
  uint64_t v115 = v4;
  int64_t v6 = *(void *)(*(void *)(type metadata accessor for NeuralNetwork.WeightParameters(0) - 8) + 64);
  int64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v130 = v110;
  int64_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?)
                             - 8)
                 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v132 = v110;
  uint64_t v134 = type metadata accessor for Tensor(0);
  uint64_t v133 = *(void *)(v134 - 8);
  int64_t v12 = *(void *)(v133 + 64);
  uint64_t v13 = alloca(v12);
  int64_t v14 = alloca(v12);
  uint64_t v128 = v110;
  uint64_t v15 = alloca(v12);
  uint64_t v16 = alloca(v12);
  char v127 = v110;
  int64_t v17 = alloca(v12);
  uint64_t v18 = alloca(v12);
  uint64_t v125 = v110;
  uint64_t v19 = type metadata accessor for NeuralNetwork.Layer.UnidirectionalLSTMParameters(0);
  uint64_t v123 = *(void *)(v19 - 8);
  int64_t v20 = *(void *)(v123 + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v131 = v110;
  uint64_t v23 = type metadata accessor for NeuralNetwork.Layer.Kind(0);
  uint64_t v24 = *(void *)(v23 - 8);
  int64_t v25 = *(void *)(v24 + 64);
  uint64_t v26 = alloca(v25);
  uint64_t v27 = alloca(v25);
  uint64_t v117 = v110;
  uint64_t v28 = alloca(v25);
  uint64_t v29 = alloca(v25);
  int64_t v30 = alloca(v25);
  uint64_t v31 = alloca(v25);
  unint64_t v32 = v135[1];
  uint64_t v124 = *v135;
  static NeuralNetwork.Layer.Kind.unidirectionalLSTM(inputSize:outputSize:sequenceOutput:)(v32, v124, 0);
  uint64_t v118 = *(void (**)(unsigned char *, unsigned char *, uint64_t))(v24 + 16);
  v118(v110, v110, v23);
  unsigned int v122 = (*(uint64_t (**)(unsigned char *, uint64_t))(v24 + 88))(v110, v23);
  if (v122 != enum case for NeuralNetwork.Layer.Kind.unidirectionalLSTM(_:))
  {
    (*(void (**)(unsigned char *, uint64_t))(v24 + 8))(v110, v23);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000001ALL, "ModelExport.swift" + 0x8000000000000000, "CreateML/MLActivityClassifier+MLModelExport.swift", 49, 2, 198, 0);
    BUG();
  }
  uint64_t v116 = v110;
  uint64_t v121 = v23;
  (*(void (**)(unsigned char *, uint64_t))(v24 + 96))(v110, v23);
  uint64_t v120 = v19;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v123 + 32))(v131, v110, v19);
  type metadata accessor for MLActivityClassifier.LSTMBlock(0);
  uint64_t v33 = (uint64_t)v132;
  LSTM.inputWeight.getter();
  if (__swift_getEnumTagSinglePayload(v33, 1, v134) == 1) {
    BUG();
  }
  uint64_t v34 = v24;
  (*(void (**)(unsigned char *, uint64_t, uint64_t))(v133 + 32))(v125, v33, v134);
  LSTM.recurrentWeight.getter();
  uint64_t v126 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<TensorRangeExpression?>);
  uint64_t v35 = (void *)swift_allocObject(v126, 72, 7);
  v35[2] = 1;
  v35[3] = 2;
  uint64_t v132 = (unsigned char *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Range<Int>);
  v35[7] = v132;
  uint64_t v36 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Range<Int> and conformance <> Range<A>, &demangling cache variable for type metadata for Range<Int>, (uint64_t)&protocol conformance descriptor for <> Range<A>);
  v35[8] = v36;
  uint64_t v37 = v124;
  uint64_t v38 = v130;
  if (v124 < 0) {
    BUG();
  }
  uint64_t v129 = v36;
  uint64_t v119 = v34;
  v35[4] = 0;
  v35[5] = v37;
  uint64_t v39 = v128;
  Tensor.subscript.getter(v35);
  swift_bridgeObjectRelease((_BYTE)v35);
  uint64_t v40 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  uint64_t v133 = *(void *)(v133 + 8);
  ((void (*)(unsigned char *, uint64_t))v133)(v39, v134);
  NeuralNetwork.WeightParameters.init(_:updatable:)(v40, 0);
  uint64_t v41 = (void (*)(unsigned char *, void))NeuralNetwork.Layer.UnidirectionalLSTMParameters.weights.modify(v110);
  NeuralNetwork.Layer.LSTMWeightParameters.inputGate.setter(v38);
  v41(v110, 0);
  uint64_t v42 = (void *)swift_allocObject(v126, 72, 7);
  int v42[2] = 1;
  v42[3] = 2;
  uint64_t v43 = *v135;
  unint64_t v44 = *v135;
  uint64_t v124 = 0x4000000000000000;
  if ((uint64_t)(v44 + 0x4000000000000000) < 0) {
    BUG();
  }
  v42[7] = v132;
  v42[8] = v129;
  if (2 * v43 < v43) {
    BUG();
  }
  v42[4] = v43;
  v42[5] = 2 * v43;
  uint64_t v45 = v128;
  Tensor.subscript.getter(v42);
  swift_bridgeObjectRelease((_BYTE)v42);
  uint64_t v46 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  ((void (*)(unsigned char *, uint64_t))v133)(v45, v134);
  uint64_t v47 = v130;
  NeuralNetwork.WeightParameters.init(_:updatable:)(v46, 0);
  uint64_t v48 = (void (*)(unsigned char *, void))NeuralNetwork.Layer.UnidirectionalLSTMParameters.weights.modify(v110);
  NeuralNetwork.Layer.LSTMWeightParameters.forgetGate.setter(v47);
  v48(v110, 0);
  uint64_t v49 = (void *)swift_allocObject(v126, 72, 7);
  v49[2] = 1;
  v49[3] = 2;
  uint64_t v50 = 3 * *v135;
  if (!is_mul_ok(3uLL, *v135)) {
    BUG();
  }
  uint64_t v51 = 2 * *v135;
  v49[7] = v132;
  v49[8] = v129;
  if (v50 < v51) {
    BUG();
  }
  v49[4] = v51;
  v49[5] = v50;
  uint64_t v52 = v128;
  Tensor.subscript.getter(v49);
  swift_bridgeObjectRelease((_BYTE)v49);
  uint64_t v53 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  uint64_t v54 = v52;
  BOOL v55 = (void (*)(unsigned char *, uint64_t))v133;
  ((void (*)(unsigned char *, uint64_t))v133)(v54, v134);
  uint64_t v56 = v130;
  NeuralNetwork.WeightParameters.init(_:updatable:)(v53, 0);
  uint64_t v57 = (void (*)(unsigned char *, void))NeuralNetwork.Layer.UnidirectionalLSTMParameters.weights.modify(v110);
  NeuralNetwork.Layer.LSTMWeightParameters.blockInput.setter(v56);
  v57(v110, 0);
  uint64_t v58 = (void *)swift_allocObject(v126, 72, 7);
  v58[2] = 1;
  v58[3] = 2;
  unint64_t v59 = *v135;
  if (((*v135 - 0x2000000000000000) >> 62) < 3) {
    BUG();
  }
  uint64_t v60 = 3 * v59;
  uint64_t v61 = 4 * v59;
  v58[7] = v132;
  v58[8] = v129;
  if (v61 < v60) {
    BUG();
  }
  v58[4] = v60;
  v58[5] = v61;
  uint64_t v62 = v55;
  uint64_t v63 = v128;
  Tensor.subscript.getter(v58);
  swift_bridgeObjectRelease((_BYTE)v58);
  uint64_t v64 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  v62(v63, v134);
  uint64_t v65 = v130;
  NeuralNetwork.WeightParameters.init(_:updatable:)(v64, 0);
  uint64_t v66 = (void (*)(unsigned char *, void))NeuralNetwork.Layer.UnidirectionalLSTMParameters.weights.modify(v110);
  NeuralNetwork.Layer.LSTMWeightParameters.outputGate.setter(v65);
  v66(v110, 0);
  uint64_t v67 = (void *)swift_allocObject(v126, 72, 7);
  v67[2] = 1;
  v67[3] = 2;
  uint64_t v68 = *v135;
  v67[7] = v132;
  v67[8] = v129;
  if (v68 < 0) {
    BUG();
  }
  v67[4] = 0;
  v67[5] = v68;
  Tensor.subscript.getter(v67);
  swift_bridgeObjectRelease((_BYTE)v67);
  uint64_t v69 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  ((void (*)(unsigned char *, uint64_t))v133)(v63, v134);
  uint64_t v70 = v130;
  NeuralNetwork.WeightParameters.init(_:updatable:)(v69, 0);
  uint64_t v71 = (void (*)(unsigned char *, void))NeuralNetwork.Layer.UnidirectionalLSTMParameters.weights.modify(v110);
  NeuralNetwork.Layer.LSTMWeightParameters.inputGateRecursion.setter(v70);
  v71(v110, 0);
  uint64_t v72 = (void *)swift_allocObject(v126, 72, 7);
  v72[2] = 1;
  v72[3] = 2;
  uint64_t v73 = *v135;
  BOOL v74 = (uint64_t)(*v135 + v124) < 0;
  v124 += *v135;
  uint64_t v75 = (void (*)(unsigned char *, uint64_t))v133;
  if (v74) {
    BUG();
  }
  v72[7] = v132;
  v72[8] = v129;
  if (2 * v73 < v73) {
    BUG();
  }
  v72[4] = v73;
  v72[5] = 2 * v73;
  uint64_t v76 = v75;
  uint64_t v77 = v128;
  Tensor.subscript.getter(v72);
  swift_bridgeObjectRelease((_BYTE)v72);
  uint64_t v78 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  v76(v77, v134);
  uint64_t v79 = v130;
  NeuralNetwork.WeightParameters.init(_:updatable:)(v78, 0);
  uint64_t v80 = (void (*)(unsigned char *, void))NeuralNetwork.Layer.UnidirectionalLSTMParameters.weights.modify(v110);
  NeuralNetwork.Layer.LSTMWeightParameters.forgetGateRecursion.setter(v79);
  uint64_t v81 = v135;
  v80(v110, 0);
  uint64_t v82 = v126;
  uint64_t v83 = (void *)swift_allocObject(v126, 72, 7);
  v83[2] = 1;
  v83[3] = 2;
  uint64_t v84 = 3 * *v81;
  if (!is_mul_ok(3uLL, *v81)) {
    BUG();
  }
  uint64_t v85 = 2 * *v81;
  v83[7] = v132;
  unsigned char v83[8] = v129;
  if (v84 < v85) {
    BUG();
  }
  v83[4] = v85;
  v83[5] = v84;
  uint64_t v86 = v128;
  Tensor.subscript.getter(v83);
  swift_bridgeObjectRelease((_BYTE)v83);
  uint64_t v87 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  ((void (*)(unsigned char *, uint64_t))v133)(v86, v134);
  uint64_t v88 = v130;
  NeuralNetwork.WeightParameters.init(_:updatable:)(v87, 0);
  uint64_t v89 = v82;
  uint64_t v90 = (void (*)(unsigned char *, void))NeuralNetwork.Layer.UnidirectionalLSTMParameters.weights.modify(v110);
  NeuralNetwork.Layer.LSTMWeightParameters.blockInputRecursion.setter(v88);
  v90(v110, 0);
  int v91 = (void *)swift_allocObject(v89, 72, 7);
  v91[2] = 1;
  v91[3] = 2;
  unint64_t v92 = *v135;
  if (*v135 - 0x2000000000000000 < 0xC000000000000000) {
    BUG();
  }
  uint64_t v93 = 3 * v92;
  uint64_t v94 = 4 * v92;
  v91[7] = v132;
  v91[8] = v129;
  if (v94 < v93) {
    BUG();
  }
  v91[4] = v93;
  v91[5] = v94;
  uint64_t v95 = v128;
  Tensor.subscript.getter(v91);
  swift_bridgeObjectRelease((_BYTE)v91);
  uint64_t v96 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  ((void (*)(unsigned char *, uint64_t))v133)(v95, v134);
  uint64_t v97 = v130;
  NeuralNetwork.WeightParameters.init(_:updatable:)(v96, 0);
  int64_t v98 = v131;
  BOOL v99 = (void (*)(unsigned char *, void))NeuralNetwork.Layer.UnidirectionalLSTMParameters.weights.modify(v110);
  NeuralNetwork.Layer.LSTMWeightParameters.outputGateRecursion.setter(v97);
  v99(v110, 0);
  uint64_t v100 = v119;
  uint64_t v135 = *(unint64_t **)(v119 + 8);
  uint64_t v101 = v116;
  uint64_t v102 = v121;
  ((void (*)(unsigned char *, uint64_t))v135)(v116, v121);
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v123 + 16))(v101, v98, v120);
  (*(void (**)(unsigned char *, void, uint64_t))(v100 + 104))(v101, v122, v102);
  uint64_t v103 = v117;
  v118(v117, v101, v102);
  uint64_t v104 = v113;
  swift_bridgeObjectRetain(v113);
  uint64_t v105 = v112;
  swift_bridgeObjectRetain(v112);
  uint64_t v106 = v111;
  swift_bridgeObjectRetain(v111);
  NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)(v114, v104, v105, v106, v103);
  uint64_t v107 = v134;
  char v108 = (void (*)(unsigned char *, uint64_t))v133;
  ((void (*)(unsigned char *, uint64_t))v133)(v127, v134);
  v108(v125, v107);
  (*(void (**)(unsigned char *, uint64_t))(v123 + 8))(v131, v120);
  return ((uint64_t (*)(unsigned char *, uint64_t))v135)(v101, v121);
}

uint64_t BatchNorm.asModelLayer(name:inputName:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v54 = a4;
  uint64_t v48 = a3;
  uint64_t v45 = a2;
  uint64_t v46 = a1;
  uint64_t v47 = v4;
  uint64_t v64 = (void (*)(uint64_t *, uint64_t))type metadata accessor for Tensor(0);
  uint64_t v63 = *((void *)v64 - 1);
  int64_t v6 = *(void *)(v63 + 64);
  int64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v51 = &v44;
  int64_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.WeightParameters?)
                             - 8)
                 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v50 = &v44;
  uint64_t v58 = type metadata accessor for NeuralNetwork.Layer.BatchNormalizeParameters(0);
  uint64_t v57 = *(void *)(v58 - 8);
  int64_t v12 = *(void *)(v57 + 64);
  uint64_t v13 = alloca(v12);
  int64_t v14 = alloca(v12);
  uint64_t v62 = &v44;
  uint64_t v15 = type metadata accessor for NeuralNetwork.Layer.Kind(0);
  uint64_t v16 = *(void *)(v15 - 8);
  int64_t v17 = *(void *)(v16 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v49 = &v44;
  int64_t v20 = alloca(v17);
  uint64_t v21 = alloca(v17);
  uint64_t v22 = alloca(v17);
  uint64_t v23 = alloca(v17);
  uint64_t v60 = v5;
  uint64_t v24 = BatchNorm.featureCount.getter();
  static NeuralNetwork.Layer.Kind.batchNormalize(inputChannelCount:)(v24);
  int64_t v25 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v16 + 16);
  unint64_t v59 = &v44;
  uint64_t v52 = v25;
  v25(&v44, &v44, v15);
  unsigned int v56 = (*(uint64_t (**)(uint64_t *, uint64_t))(v16 + 88))(&v44, v15);
  if (v56 != enum case for NeuralNetwork.Layer.Kind.batchNormalize(_:))
  {
    (*(void (**)(uint64_t *, uint64_t))(v16 + 8))(&v44, v15);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000001ALL, "ModelExport.swift" + 0x8000000000000000, "CreateML/MLActivityClassifier+MLModelExport.swift", 49, 2, 240, 0);
    BUG();
  }
  (*(void (**)(uint64_t *, uint64_t))(v16 + 96))(&v44, v15);
  uint64_t v53 = v16;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v57 + 32))(v62, &v44, v58);
  uint64_t v26 = v51;
  uint64_t v61 = v15;
  BatchNorm.scale.getter();
  uint64_t v27 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  BOOL v55 = *(void (**)(uint64_t *, void *))(v63 + 8);
  v55(v26, v64);
  uint64_t v28 = (uint64_t)v50;
  NeuralNetwork.WeightParameters.init(_:updatable:)(v27, 0);
  uint64_t v63 = type metadata accessor for NeuralNetwork.WeightParameters(0);
  __swift_storeEnumTagSinglePayload(v28, 0, 1, v63);
  NeuralNetwork.Layer.BatchNormalizeParameters.scale.setter(v28);
  BatchNorm.offset.getter();
  uint64_t v29 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  v55(v26, v64);
  NeuralNetwork.WeightParameters.init(_:updatable:)(v29, 0);
  __swift_storeEnumTagSinglePayload(v28, 0, 1, v63);
  NeuralNetwork.Layer.BatchNormalizeParameters.offset.setter(v28);
  BatchNorm.runningMean.getter();
  uint64_t v30 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  uint64_t v31 = v55;
  v55(v26, v64);
  NeuralNetwork.WeightParameters.init(_:updatable:)(v30, 0);
  __swift_storeEnumTagSinglePayload(v28, 0, 1, v63);
  NeuralNetwork.Layer.BatchNormalizeParameters.mean.setter(v28);
  BatchNorm.runningVariance.getter();
  uint64_t v32 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  v31(v26, v64);
  NeuralNetwork.WeightParameters.init(_:updatable:)(v32, 0);
  __swift_storeEnumTagSinglePayload(v28, 0, 1, v63);
  uint64_t v33 = v62;
  NeuralNetwork.Layer.BatchNormalizeParameters.variance.setter(v28);
  uint64_t v34 = v53;
  uint64_t v64 = *(void (**)(uint64_t *, uint64_t))(v53 + 8);
  uint64_t v35 = v59;
  uint64_t v36 = v61;
  v64(v59, v61);
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v57 + 16))(v35, v33, v58);
  (*(void (**)(uint64_t *, void, uint64_t))(v34 + 104))(v35, v56, v36);
  uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t v38 = (void *)swift_allocObject(v37, 48, 7);
  v38[2] = 1;
  v38[3] = 2;
  v38[4] = v48;
  v38[5] = v54;
  uint64_t v39 = (void *)swift_allocObject(v37, 48, 7);
  v39[2] = 1;
  v39[3] = 2;
  uint64_t v40 = v46;
  v39[4] = v46;
  uint64_t v41 = v45;
  v39[5] = v45;
  uint64_t v42 = v49;
  v52(v49, v59, v61);
  swift_bridgeObjectRetain_n(v41, 2);
  swift_bridgeObjectRetain(v54);
  NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)(v40, v41, v38, v39, v42);
  (*(void (**)(uint64_t *, uint64_t))(v57 + 8))(v62, v58);
  return ((uint64_t (*)(uint64_t *, uint64_t))v64)(v59, v61);
}

uint64_t partial apply for closure #1 in MLActivityClassifier.Model.asModelSpecification()(uint64_t *a1)
{
  return closure #1 in MLActivityClassifier.Model.asModelSpecification()(a1, *(void *)(v1 + 16));
}

uint64_t Array<A>.floatTensor(shape:)(uint64_t a1, uint64_t a2)
{
  uint64_t v31 = a2;
  uint64_t v30 = a1;
  v26[1] = v2;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?)
                             - 8)
                 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v27 = v26;
  uint64_t v28 = type metadata accessor for ScalarType(0);
  uint64_t v29 = *(void *)(v28 - 8);
  int64_t v6 = *(void *)(v29 + 64);
  int64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  int64_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TensorShape?)
                             - 8)
                 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v12 = type metadata accessor for TensorShape(0);
  uint64_t v13 = *(void *)(v12 - 8);
  int64_t v14 = *(void *)(v13 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  outlined init with copy of TensorShape?(v30, (uint64_t)v26);
  if (__swift_getEnumTagSinglePayload((uint64_t)v26, 1, v12) == 1)
  {
    uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
    uint64_t v18 = (void *)swift_allocObject(v17, 40, 7);
    v18[2] = 1;
    v18[3] = 2;
    uint64_t v19 = v31;
    v18[4] = *(void *)(v31 + 16);
    TensorShape.init(_:)();
    outlined destroy of TensorShape?((uint64_t)v26);
    uint64_t v20 = v19;
  }
  else
  {
    (*(void (**)(void *, void *, uint64_t))(v13 + 32))(v26, v26, v12);
    uint64_t v20 = v31;
  }
  (*(void (**)(void *, void, uint64_t))(v29 + 104))(v26, enum case for ScalarType.float32(_:), v28);
  uint64_t v21 = type metadata accessor for ComputeDevice(0);
  uint64_t v22 = (uint64_t)v27;
  __swift_storeEnumTagSinglePayload((uint64_t)v27, 1, 1, v21);
  uint64_t v23 = alloca(24);
  uint64_t v24 = alloca(32);
  uint64_t v27 = (void *)v20;
  return Tensor.init(unsafeUninitializedShape:scalarType:computeDevice:initializingWith:)(v26, v26, v22, _sSa8CreateMLSdRszlE11floatTensor5shape14NeuralNetworks0D0VAD0D5ShapeVSg_tFySwXEfU_TA_0);
}

void closure #1 in Array<A>.floatTensor(shape:)(float *a1, uint64_t a2, uint64_t a3)
{
  if (*(void *)(a3 + 16) >> 60) {
    BUG();
  }
  closure #1 in closure #1 in Array<A>.floatTensor(shape:)((const double *)(a3 + 32), a3 + 8 * *(void *)(a3 + 16) + 32, a1, a2);
}

void closure #1 in closure #1 in Array<A>.floatTensor(shape:)(const double *a1, uint64_t a2, float *a3, uint64_t a4)
{
  if (a3) {
    uint64_t v4 = (a4 - (uint64_t)a3) / 4;
  }
  else {
    uint64_t v4 = 0;
  }
  if (!a1)
  {
    if (v4 >= 0) {
      BUG();
    }
LABEL_12:
    BUG();
  }
  int64_t v5 = (a2 - (uint64_t)a1) / 8;
  if (v4 < v5) {
    int64_t v5 = v4;
  }
  if (v5 < 0) {
    goto LABEL_12;
  }
  if (!a3) {
    BUG();
  }
  vDSP_vdpsp(a1, 1, a3, 1, v5);
}

uint64_t outlined init with copy of TensorShape?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TensorShape?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

void _sSa8CreateMLSdRszlE11floatTensor5shape14NeuralNetworks0D0VAD0D5ShapeVSg_tFySwXEfU_TA_0(float *a1, uint64_t a2)
{
  closure #1 in Array<A>.floatTensor(shape:)(a1, a2, *(void *)(v2 + 16));
}

uint64_t static BundleUtilities.getMLModelURL(at:)(uint64_t a1, uint64_t a2)
{
  uint64_t v25 = v3;
  uint64_t v26 = v2;
  uint64_t v4 = type metadata accessor for URL(0);
  v23._char object = *(void **)(v4 - 8);
  int64_t v5 = *((void *)v23._object + 8);
  int64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v24 = &v21;
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  if (one-time initialization token for bundle != -1) {
    swift_once(&one-time initialization token for bundle, one-time initialization function for bundle);
  }
  v23._uint64_t countAndFlagsBits = a1;
  *(void *)&long long v27 = a2;
  id v11 = outlined bridged method (mbgbnn) of @objc NSBundle.url(forResource:withExtension:)(a1, a2, 0x6C65646F6D6C6DLL, 0xE700000000000000, (void *)static BundleUtilities.bundle);
  if (v11)
  {
    uint64_t v12 = v11;
    uint64_t v13 = v24;
    static URL._unconditionallyBridgeFromObjectiveC(_:)(v11);

    int64_t v14 = (void (*)(uint64_t *, uint64_t *, uint64_t))*((void *)v23._object + 4);
    v14(&v21, v13, v4);
    __swift_storeEnumTagSinglePayload((uint64_t)&v21, 0, 1, v4);
    if (__swift_getEnumTagSinglePayload((uint64_t)&v21, 1, v4) != 1) {
      return ((uint64_t (*)(uint64_t, uint64_t *, uint64_t))v14)(v26, &v21, v4);
    }
  }
  else
  {
    __swift_storeEnumTagSinglePayload((uint64_t)&v21, 1, 1, v4);
  }
  outlined destroy of URL?((uint64_t)&v21);
  *(void *)&long long v22 = 0xD000000000000015;
  *((void *)&v22 + 1) = "BCE13BundleWitness" + 0x8000000000000000;
  v16._uint64_t countAndFlagsBits = v23._countAndFlagsBits;
  v16._char object = (void *)v27;
  String.append(_:)(v16);
  long long v27 = v22;
  v16._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  swift_allocError(&type metadata for MLCreateError, v16._object, 0, 0);
  *(_OWORD *)uint64_t v17 = v27;
  *(_OWORD *)(v17 + 16) = 0;
  *(_OWORD *)(v17 + 32) = 0;
  *(unsigned char *)(v17 + 48) = 0;
  return swift_willThrow(&type metadata for MLCreateError, v16._object, v17, v18, v19, v20);
}

uint64_t type metadata accessor for BundleUtilities.BundleWitness()
{
  return objc_opt_self(_TtCV8CreateML15BundleUtilitiesP33_3AA6A595399C2D1303049CB3FF4C5BCE13BundleWitness);
}

id one-time initialization function for bundle()
{
  type metadata accessor for BundleUtilities.BundleWitness();
  uint64_t ObjCClassFromMetadata = swift_getObjCClassFromMetadata();
  uint64_t v1 = objc_opt_self(NSBundle);
  id v2 = [v1 bundleForClass:ObjCClassFromMetadata];
  id result = v2;
  static BundleUtilities.bundle = (uint64_t)result;
  return result;
}

id outlined bridged method (mbgbnn) of @objc NSBundle.url(forResource:withExtension:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void *a5)
{
  NSString v7 = String._bridgeToObjectiveC()();
  NSString v8 = String._bridgeToObjectiveC()();
  swift_bridgeObjectRelease(a4);
  id v9 = [a5 URLForResource:v7 withExtension:v8];
  id v10 = v9;

  return v10;
}

Swift::Void __swiftcall MLProgram.addClassifierSpecification(classLabels:probabilityTensorName:outputProbabilityName:outputLabelName:)(Swift::OpaquePointer classLabels, Swift::String probabilityTensorName, Swift::String outputProbabilityName, Swift::String outputLabelName)
{
  uint64_t countAndFlagsBits = outputLabelName._countAndFlagsBits;
  char object = outputProbabilityName._object;
  uint64_t v187 = outputProbabilityName._countAndFlagsBits;
  Swift::String v174 = probabilityTensorName._object;
  uint64_t v175 = probabilityTensorName._countAndFlagsBits;
  rawValue = classLabels._rawValue;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLProgram.Block?)
                             - 8)
                 + 64);
  int64_t v6 = alloca(v5);
  NSString v7 = alloca(v5);
  v170 = v161;
  uint64_t v179 = type metadata accessor for MLProgram.Argument.Binding(0);
  uint64_t v167 = *(void *)(v179 - 8);
  int64_t v8 = *(void *)(v167 + 64);
  id v9 = alloca(v8);
  id v10 = alloca(v8);
  v166 = v161;
  uint64_t v184 = type metadata accessor for MLProgram.Operation(0);
  uint64_t v185 = *(void *)(v184 - 8);
  int64_t v11 = *(void *)(v185 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  v186 = v161;
  uint64_t v209 = type metadata accessor for MLProgram.Value.Tensor(0);
  uint64_t v163 = *(void *)(v209 - 8);
  int64_t v14 = *(void *)(v163 + 64);
  uint64_t v15 = alloca(v14);
  Swift::String v16 = alloca(v14);
  v164 = v161;
  uint64_t v180 = type metadata accessor for MLProgram.ShapeDimension(0);
  uint64_t v181 = *(void *)(v180 - 8);
  int64_t v17 = *(void *)(v181 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  v182 = (int64_t *)v161;
  uint64_t v195 = type metadata accessor for MLProgram.DataType(0);
  uint64_t v210 = *(void *)(v195 - 8);
  int64_t v20 = *(void *)(v210 + 64);
  uint64_t v21 = alloca(v20);
  long long v22 = alloca(v20);
  v196 = v161;
  uint64_t v176 = type metadata accessor for MLProgram.ValueType(0);
  uint64_t v168 = *(void *)(v176 - 8);
  int64_t v23 = *(void *)(v168 + 64);
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  long long v165 = v161;
  uint64_t v26 = alloca(v23);
  long long v27 = alloca(v23);
  v177 = v161;
  uint64_t v28 = alloca(v23);
  uint64_t v29 = alloca(v23);
  v178 = v161;
  uint64_t v30 = alloca(v23);
  uint64_t v31 = alloca(v23);
  v183 = v161;
  uint64_t v205 = type metadata accessor for MLProgram.Value(0);
  uint64_t v206 = *(void *)(v205 - 8);
  int64_t v32 = *(void *)(v206 + 64);
  uint64_t v33 = alloca(v32);
  uint64_t v34 = alloca(v32);
  v211 = v161;
  uint64_t v35 = alloca(v32);
  uint64_t v36 = alloca(v32);
  v197 = v161;
  uint64_t v200 = type metadata accessor for MLProgram.Block(0);
  uint64_t v189 = *(void *)(v200 - 8);
  int64_t v37 = *(void *)(v189 + 64);
  uint64_t v38 = alloca(v37);
  uint64_t v39 = alloca(v37);
  v207 = v161;
  uint64_t v40 = alloca(v37);
  uint64_t v41 = alloca(v37);
  v199 = v161;
  int64_t v42 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: String, value: MLProgram.Block)?)
                              - 8)
                  + 64);
  uint64_t v43 = alloca(v42);
  uint64_t v44 = alloca(v42);
  v208 = v161;
  uint64_t v45 = alloca(v42);
  uint64_t v46 = alloca(v42);
  v198 = (uint64_t *)v161;
  int64_t v47 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLProgram.Function?)
                              - 8)
                  + 64);
  uint64_t v48 = alloca(v47);
  uint64_t v49 = alloca(v47);
  uint64_t v173 = v161;
  uint64_t v50 = alloca(v47);
  uint64_t v51 = alloca(v47);
  uint64_t v52 = type metadata accessor for MLProgram.Function(0);
  uint64_t v53 = *(void *)(v52 - 8);
  int64_t v54 = *(void *)(v53 + 64);
  BOOL v55 = alloca(v54);
  unsigned int v56 = alloca(v54);
  uint64_t v169 = v4;
  MLProgram.mainFunction.getter();
  if (__swift_getEnumTagSinglePayload((uint64_t)v161, 1, v52) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v161, &demangling cache variable for type metadata for MLProgram.Function?);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000020, "Specification+Classifiers.swift" + 0x8000000000000000, "CreateML/MLModelSpecification+Classifiers.swift", 47, 2, 22, 0);
    goto LABEL_22;
  }
  uint64_t v172 = v53;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v53 + 32))(v161, v161, v52);
  uint64_t v57 = MLProgram.Function.blockSpecializations.getter();
  uint64_t v58 = *(void *)(v57 + 16);
  swift_bridgeObjectRelease(v57);
  if (v58 != 1)
  {
LABEL_21:
    v202 = 0;
    unint64_t v203 = 0xE000000000000000;
    _StringGuts.grow(_:)(61);
    v156._uint64_t countAndFlagsBits = 0xD00000000000003BLL;
    v156._char object = "a main function." + 0x8000000000000000;
    String.append(_:)(v156);
    uint64_t v157 = MLProgram.Function.blockSpecializations.getter();
    uint64_t v158 = Dictionary.Keys.description.getter(v157, &type metadata for String, v200, &protocol witness table for String);
    char v160 = (char)v159;
    v156._uint64_t countAndFlagsBits = v158;
    v156._char object = v159;
    String.append(_:)(v156);
    swift_bridgeObjectRelease(v157);
    swift_bridgeObjectRelease(v160);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v202, v203, "CreateML/MLModelSpecification+Classifiers.swift", 47, 2, 29, 0);
LABEL_22:
    BUG();
  }
  uint64_t v171 = v52;
  uint64_t v59 = MLProgram.Function.blockSpecializations.getter();
  char v60 = v59;
  uint64_t v61 = v198;
  specialized Collection.first.getter(v59);
  swift_bridgeObjectRelease(v60);
  uint64_t v62 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: String, value: MLProgram.Block));
  if (__swift_getEnumTagSinglePayload((uint64_t)v61, 1, v62) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v61, &demangling cache variable for type metadata for (key: String, value: MLProgram.Block)?);
    goto LABEL_21;
  }
  v190 = (char *)*v61;
  uint64_t v201 = v61[1];
  uint64_t v63 = v189;
  uint64_t v64 = (char *)v61 + *(int *)(v62 + 48);
  uint64_t v65 = v200;
  v191 = *(void (**)(char *, uint64_t))(v189 + 8);
  v191(v64, v200);
  v194 = v161;
  uint64_t v66 = MLProgram.Function.blockSpecializations.getter();
  uint64_t v67 = (uint64_t)v208;
  specialized Collection.first.getter(v66);
  swift_bridgeObjectRelease(v66);
  if (__swift_getEnumTagSinglePayload(v67, 1, v62) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v67, &demangling cache variable for type metadata for (key: String, value: MLProgram.Block)?);
LABEL_20:
    swift_bridgeObjectRelease(v201);
    goto LABEL_21;
  }
  swift_bridgeObjectRelease(*(void *)(v67 + 8));
  uint64_t v68 = *(int *)(v62 + 48) + v67;
  uint64_t v69 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v63 + 32);
  uint64_t v70 = v207;
  v69(v207, v68, v65);
  v69(v199, (uint64_t)v70, v65);
  v202 = v190;
  unint64_t v203 = v201;
  v162[0] = 0x4C4D65726F43;
  v162[1] = 0xE600000000000000;
  uint64_t v71 = lazy protocol witness table accessor for type String and conformance String();
  uint64_t v72 = lazy protocol witness table accessor for type String and conformance String();
  if ((BidirectionalCollection<>.starts<A>(with:)(v162, &type metadata for String, &type metadata for String, v71, v72) & 1) == 0)
  {
    v191(v199, v200);
    goto LABEL_20;
  }
  uint64_t v73 = v210;
  BOOL v74 = *(unsigned char **)(v210 + 104);
  uint64_t v75 = v196;
  LODWORD(v208) = enum case for MLProgram.DataType.string(_:);
  uint64_t v76 = v195;
  v207 = v74;
  ((void (*)(unsigned char *, void, uint64_t))v74)(v196, enum case for MLProgram.DataType.string(_:), v195);
  uint64_t v77 = (char *)_swiftEmptyArrayStorage;
  static MLProgram.ValueType.tensor(dataType:shape:)(v75, _swiftEmptyArrayStorage);
  v198 = *(uint64_t **)(v73 + 8);
  ((void (*)(unsigned char *, uint64_t))v198)(v75, v76);
  uint64_t v78 = rawValue;
  int64_t v79 = rawValue[2];
  uint64_t v80 = v182;
  int64_t *v182 = v79;
  (*(void (**)(int64_t *, void, uint64_t))(v181 + 104))(v80, enum case for MLProgram.ShapeDimension.constant(_:), v180);
  if (v79)
  {
    v202 = (char *)_swiftEmptyArrayStorage;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v79, 0);
    unsigned int v192 = enum case for MLProgram.Value.Tensor.strings(_:);
    uint64_t v81 = v78 + 5;
    do
    {
      uint64_t v210 = v79;
      uint64_t v82 = *(v81 - 1);
      rawValue = v81;
      uint64_t v83 = *v81;
      ((void (*)(unsigned char *, void, uint64_t))v207)(v196, v208, v195);
      uint64_t v84 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
      uint64_t v85 = (void *)swift_allocObject(v84, 48, 7);
      v85[2] = 1;
      v85[3] = 2;
      v85[4] = v82;
      v85[5] = v83;
      uint64_t v86 = v164;
      void *v164 = v85;
      uint64_t v87 = v209;
      uint64_t v88 = v163;
      (*(void (**)(void *, void, uint64_t))(v163 + 104))(v86, v192, v209);
      swift_bridgeObjectRetain_n(v83, 2);
      uint64_t v89 = v196;
      static MLProgram.Value.immediateTensor(dataType:shape:contents:)(v196, _swiftEmptyArrayStorage, v86);
      (*(void (**)(void *, uint64_t))(v88 + 8))(v86, v87);
      ((void (*)(unsigned char *, uint64_t))v198)(v89, v195);
      swift_bridgeObjectRelease(v83);
      uint64_t v77 = v202;
      if (!swift_isUniquelyReferenced_nonNull_native(v202))
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v77 + 2) + 1, 1);
        uint64_t v77 = v202;
      }
      uint64_t v90 = v205;
      uint64_t v91 = v206;
      unint64_t v92 = *((void *)v77 + 2);
      uint64_t v93 = rawValue;
      uint64_t v94 = v211;
      if (*((void *)v77 + 3) >> 1 <= v92)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v77 + 3) >= 2uLL, v92 + 1, 1);
        uint64_t v94 = v211;
        uint64_t v91 = v206;
        uint64_t v90 = v205;
        uint64_t v77 = v202;
      }
      *((void *)v77 + 2) = v92 + 1;
      (*(void (**)(char *, unsigned char *, uint64_t))(v91 + 32))(&v77[((*(unsigned __int8 *)(v91 + 80) + 32) & ~*(unsigned __int8 *)(v91 + 80)) + *(void *)(v91 + 72) * v92], v94, v90);
      v202 = v77;
      uint64_t v81 = v93 + 2;
      int64_t v79 = v210 - 1;
    }
    while (v210 != 1);
  }
  v202 = v77;
  uint64_t v95 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLProgram.Value]);
  uint64_t v96 = lazy protocol witness table accessor for type [MLProgram.Value] and conformance [A]();
  uint64_t v97 = v183;
  int64_t v98 = v182;
  static MLProgram.Value.immediateList<A>(type:length:contents:)(v183, v182, &v202, v95, v96);
  swift_bridgeObjectRelease((_BYTE)v77);
  (*(void (**)(int64_t *, uint64_t))(v181 + 8))(v98, v180);
  rawValue = *(void **)(v168 + 8);
  ((void (*)(unsigned char *, uint64_t))rawValue)(v97, v176);
  uint64_t v99 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MLProgram.Argument)>);
  uint64_t v100 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, MLProgram.Argument));
  uint64_t v101 = *(void *)(v100 - 8);
  uint64_t v209 = v100;
  uint64_t v210 = *(void *)(v101 + 72);
  uint64_t v102 = *(unsigned __int8 *)(v101 + 80);
  uint64_t v103 = ((int)v102 + 32) & ~*(unsigned __int8 *)(v101 + 80);
  uint64_t v104 = swift_allocObject(v99, v103 + 2 * v210, v102 | 7);
  v211 = (unsigned char *)v104;
  *(void *)(v104 + 16) = 2;
  *(void *)(v104 + 24) = 4;
  uint64_t v105 = v104 + v103;
  strcpy((char *)(v104 + v103), "probabilities");
  *(_WORD *)(v104 + v103 + 14) = -4864;
  uint64_t v106 = v166;
  void *v166 = v175;
  LOBYTE(v103) = (_BYTE)v174;
  v106[1] = v174;
  uint64_t v107 = *(void (**)(void *, void, uint64_t))(v167 + 104);
  v107(v106, enum case for MLProgram.Argument.Binding.name(_:), v179);
  swift_bridgeObjectRetain(v103);
  MLProgram.Argument.init(binding:)(v106);
  uint64_t v108 = v210;
  *(void *)(v210 + v105) = 0x73657373616C63;
  *(void *)(v108 + v105 + 8) = 0xE700000000000000;
  (*(void (**)(void *, unsigned char *, uint64_t))(v206 + 16))(v106, v197, v205);
  v107(v106, enum case for MLProgram.Argument.Binding.value(_:), v179);
  MLProgram.Argument.init(binding:)(v106);
  uint64_t v109 = type metadata accessor for MLProgram.Argument(0);
  uint64_t v210 = Dictionary.init(dictionaryLiteral:)(v211, &type metadata for String, v109, &protocol witness table for String);
  uint64_t v110 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLProgram.NamedValueType>);
  uint64_t v111 = *(void *)(type metadata accessor for MLProgram.NamedValueType(0) - 8);
  uint64_t v209 = *(void *)(v111 + 72);
  uint64_t v112 = swift_allocObject(v110, ((*(unsigned __int8 *)(v111 + 80) + 32) & ~*(unsigned __int8 *)(v111 + 80)) + 2 * v209, *(unsigned __int8 *)(v111 + 80) | 7);
  v211 = (unsigned char *)v112;
  *(void *)(v112 + 16) = 2;
  *(void *)(v112 + 24) = 4;
  uint64_t v113 = v196;
  uint64_t v114 = v195;
  ((void (*)(unsigned char *, void, uint64_t))v207)(v196, v208, v195);
  swift_bridgeObjectRetain(outputLabelName._object);
  uint64_t v115 = v178;
  static MLProgram.ValueType.tensor(dataType:shape:)(v113, _swiftEmptyArrayStorage);
  uint64_t v116 = v198;
  ((void (*)(unsigned char *, uint64_t))v198)(v113, v114);
  MLProgram.NamedValueType.init(name:type:)(countAndFlagsBits, outputLabelName._object, v115);
  uint64_t v117 = (void (*)(unsigned char *, void, uint64_t))v207;
  ((void (*)(unsigned char *, void, uint64_t))v207)(v113, v208, v114);
  swift_bridgeObjectRetain((_BYTE)object);
  static MLProgram.ValueType.tensor(dataType:shape:)(v113, _swiftEmptyArrayStorage);
  ((void (*)(unsigned char *, uint64_t))v116)(v113, v114);
  v117(v113, enum case for MLProgram.DataType.float64(_:), v114);
  uint64_t v118 = v165;
  static MLProgram.ValueType.tensor(dataType:shape:)(v113, _swiftEmptyArrayStorage);
  ((void (*)(unsigned char *, uint64_t))v116)(v113, v114);
  uint64_t v119 = v178;
  uint64_t v120 = v177;
  static MLProgram.ValueType.dictionary(keyType:valueType:)(v177, v118);
  uint64_t v121 = v118;
  uint64_t v122 = v176;
  uint64_t v123 = (void (*)(unsigned char *, uint64_t))rawValue;
  ((void (*)(unsigned char *, uint64_t))rawValue)(v121, v176);
  v123(v120, v122);
  MLProgram.NamedValueType.init(name:type:)(v187, object, v119);
  uint64_t v124 = v186;
  MLProgram.Operation.init(name:inputs:outputs:)(0x7966697373616C63, 0xE800000000000000, v210, v211);
  uint64_t v125 = v199;
  uint64_t v126 = (void (*)(char **, void))MLProgram.Block.operations.modify(&v202);
  uint64_t v128 = v127;
  specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
  uint64_t v129 = *(void *)(*v128 + 16);
  specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v129);
  uint64_t v130 = *v128;
  *(void *)(v130 + 16) = v129 + 1;
  (*(void (**)(uint64_t, unsigned char *, uint64_t))(v185 + 16))(v130 + ((*(unsigned __int8 *)(v185 + 80) + 32) & ~*(unsigned __int8 *)(v185 + 80)) + *(void *)(v185 + 72) * v129, v124, v184);
  v126(&v202, 0);
  uint64_t v131 = v125;
  uint64_t v132 = (uint64_t)v174;
  swift_bridgeObjectRetain((_BYTE)v174);
  uint64_t v133 = (void (*)(char **, void))MLProgram.Block.outputs.modify(&v202);
  uint64_t v135 = v134;
  int64_t v136 = specialized MutableCollection._halfStablePartition(isSuffixElement:)(v134, v175, v132);
  uint64_t v137 = *(void *)(*v135 + 16);
  if (v137 < v136) {
    BUG();
  }
  specialized Array.replaceSubrange<A>(_:with:)(v136, v137);
  v133(&v202, 0);
  swift_bridgeObjectRetain(outputLabelName._object);
  unint64_t v138 = (void (*)(char **, void))MLProgram.Block.outputs.modify(&v202);
  unint64_t v140 = v139;
  specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
  uint64_t v141 = *(void *)(*v140 + 16);
  specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v141);
  uint64_t v142 = *v140;
  *(void *)(v142 + 16) = v141 + 1;
  v141 *= 16;
  *(void *)(v142 + v141 + 32) = countAndFlagsBits;
  *(void *)(v142 + v141 + 40) = outputLabelName._object;
  v138(&v202, 0);
  uint64_t v143 = object;
  swift_bridgeObjectRetain((_BYTE)object);
  uint64_t v144 = (void (*)(char **, void))MLProgram.Block.outputs.modify(&v202);
  uint64_t v146 = v145;
  specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
  uint64_t v147 = *(void *)(*v146 + 16);
  specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v147);
  uint64_t v148 = *v146;
  *(void *)(v148 + 16) = v147 + 1;
  v147 *= 16;
  *(void *)(v148 + v147 + 32) = v187;
  *(void *)(v148 + v147 + 40) = v143;
  v144(&v202, 0);
  uint64_t v149 = (uint64_t)v170;
  uint64_t v150 = v200;
  (*(void (**)(unsigned char *, char *, uint64_t))(v189 + 16))(v170, v131, v200);
  __swift_storeEnumTagSinglePayload(v149, 0, 1, v150);
  long long v151 = v194;
  char v152 = (void (*)(char **, void))MLProgram.Function.blockSpecializations.modify(&v202);
  specialized Dictionary.subscript.setter(v149, (uint64_t)v190, v201);
  v152(&v202, 0);
  uint64_t v153 = (uint64_t)v173;
  uint64_t v154 = v171;
  uint64_t v155 = v172;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v172 + 16))(v173, v151, v171);
  __swift_storeEnumTagSinglePayload(v153, 0, 1, v154);
  MLProgram.mainFunction.setter(v153);
  (*(void (**)(unsigned char *, uint64_t))(v185 + 8))(v186, v184);
  (*(void (**)(unsigned char *, uint64_t))(v206 + 8))(v197, v205);
  v191(v199, v150);
  (*(void (**)(unsigned char *, uint64_t))(v155 + 8))(v151, v154);
}

uint64_t lazy protocol witness table accessor for type [MLProgram.Value] and conformance [A]()
{
  uint64_t result = lazy protocol witness table cache variable for type [MLProgram.Value] and conformance [A];
  if (!lazy protocol witness table cache variable for type [MLProgram.Value] and conformance [A])
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [MLProgram.Value]);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for [A], v1);
    lazy protocol witness table cache variable for type [MLProgram.Value] and conformance [A] = result;
  }
  return result;
}

unint64_t specialized MutableCollection._halfStablePartition(isSuffixElement:)(uint64_t *a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = *a1;
  uint64_t v5 = *(void *)(*a1 + 16);
  if (v5)
  {
    uint64_t v6 = a2;
    uint64_t v7 = 56;
    unint64_t v8 = 0;
    uint64_t v30 = a3;
    while (1)
    {
      uint64_t v9 = *(void *)(v4 + v7 - 24);
      uint64_t v10 = *(void *)(v4 + v7 - 16);
      if (v9 == v6 && v10 == a3) {
        break;
      }
      uint64_t v11 = v4;
      char v12 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, a2, v30, 0);
      uint64_t v6 = a2;
      a3 = v30;
      BOOL v13 = (v12 & 1) == 0;
      uint64_t v4 = v11;
      if (!v13) {
        break;
      }
      ++v8;
      v7 += 16;
      if (v5 == v8)
      {
        unint64_t v8 = *(void *)(v11 + 16);
        goto LABEL_27;
      }
    }
    unint64_t v14 = v8 + 1;
    if (__OFADD__(1, v8)) {
      BUG();
    }
    unint64_t v15 = *(void *)(v4 + 16);
    while (v14 != v15)
    {
      if (v14 >= v15) {
        BUG();
      }
      uint64_t v16 = *(void *)(v4 + v7 - 8);
      uint64_t v17 = *(void *)(v4 + v7);
      if (v16 != v6 || v17 != a3)
      {
        uint64_t v32 = v4;
        if (_stringCompareWithSmolCheck(_:_:expecting:)(v16, v17, v6, a3, 0))
        {
          a3 = v30;
          uint64_t v6 = a2;
          uint64_t v4 = v32;
        }
        else
        {
          if (v14 == v8)
          {
            a3 = v30;
            uint64_t v6 = a2;
            uint64_t v4 = v32;
          }
          else
          {
            if (v8 >= v15) {
              BUG();
            }
            uint64_t v18 = 2 * v8;
            uint64_t v27 = *(void *)(v32 + 32 + 16 * v8);
            uint64_t v26 = *(void *)(v32 + v7 - 8);
            uint64_t v29 = *(void *)(v32 + v7);
            uint64_t v28 = *(void *)(v32 + 32 + 16 * v8 + 8);
            swift_bridgeObjectRetain(v28);
            swift_bridgeObjectRetain(v29);
            if (swift_isUniquelyReferenced_nonNull_native(v32)) {
              uint64_t v19 = (void *)v32;
            }
            else {
              uint64_t v19 = specialized _ArrayBuffer._consumeAndCreateNew()(v32);
            }
            uint64_t v20 = v19[v18 + 5];
            v19[v18 + 4] = v26;
            v19[v18 + 5] = v29;
            uint64_t v21 = v19;
            swift_bridgeObjectRelease(v20);
            if (v14 >= v21[2]) {
              BUG();
            }
            uint64_t v22 = v21[(unint64_t)v7 / 8];
            v21[(unint64_t)v7 / 8 - 1] = v27;
            v21[(unint64_t)v7 / 8] = v28;
            swift_bridgeObjectRelease(v22);
            *a1 = (uint64_t)v21;
            uint64_t v4 = (uint64_t)v21;
            a3 = v30;
            uint64_t v6 = a2;
          }
          if (__OFADD__(1, v8++)) {
            BUG();
          }
        }
      }
      ++v14;
      unint64_t v15 = *(void *)(v4 + 16);
      v7 += 16;
    }
  }
  else
  {
    unint64_t v8 = 0;
  }
LABEL_27:
  swift_bridgeObjectRelease(a3);
  return v8;
}

unsigned char *assignWithCopy for MLBoostedTreeRegressor.ModelParameters.ValidationData(unsigned char *__dst, unsigned char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLBoostedTreeRegressor.ModelParameters.ValidationData((uint64_t)__dst);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v7 = type metadata accessor for DataFrame(0);
      (*(void (**)(unsigned char *, unsigned char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v5 = *(void *)__src;
      char v6 = __src[8];
      outlined copy of Result<_DataTable, Error>(*(void *)__src, v6);
      *(void *)__dst = v5;
      __dst[8] = v6;
      swift_storeEnumTagMultiPayload(__dst, a3, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLBoostedTreeRegressor.ModelParameters.ValidationData;
  if (!type metadata singleton initialization cache for MLBoostedTreeRegressor.ModelParameters.ValidationData) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLBoostedTreeRegressor.ModelParameters.ValidationData);
  }
  return result;
}

void *assignWithTake for MLBoostedTreeRegressor.ModelParameters.ValidationData(void *__dst, void *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLBoostedTreeRegressor.ModelParameters.ValidationData((uint64_t)__dst);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 2)
    {
      uint64_t v4 = type metadata accessor for DataFrame(0);
      (*(void (**)(void *, void *, uint64_t))(*(void *)(v4 - 8) + 32))(__dst, __src, v4);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLBoostedTreeRegressor.ModelParameters.ValidationData(uint64_t a1)
{
  v5[0] = &unk_350338;
  v5[1] = &unk_350350;
  uint64_t result = type metadata accessor for DataFrame(319);
  if (v4 <= 0x3F)
  {
    v5[2] = *(void *)(result - 8) + 64;
    swift_initEnumMetadataMultiPayload(a1, 256, 3, v5, v2, v3);
    return 0;
  }
  return result;
}

uint64_t MLBoostedTreeRegressor.ModelParameters.ValidationData.table.getter(__m128 a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = type metadata accessor for DataFrame(0);
  uint64_t v27 = *(void *)(v4 - 8);
  int64_t v5 = *(void *)(v27 + 64);
  char v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v29 = &v25;
  unint64_t v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v28 = &v25;
  uint64_t v10 = type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData(0);
  int64_t v11 = *(void *)(*(void *)(v10 - 8) + 64);
  char v12 = alloca(v11);
  BOOL v13 = alloca(v11);
  outlined init with copy of MLBoostedTreeRegressor.ModelParameters.ValidationData(v2, (uint64_t)&v25);
  uint64_t result = swift_getEnumCaseMultiPayload(&v25, v10);
  switch((int)result)
  {
    case 0:
      *(void *)uint64_t v3 = 0;
      *(unsigned char *)(v3 + 8) = -1;
      break;
    case 1:
      uint64_t result = v25;
      char v15 = v26;
      goto LABEL_7;
    case 2:
      uint64_t v16 = v28;
      uint64_t v17 = v27;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v27 + 32))(v28, &v25, v4);
      uint64_t v18 = (uint64_t)v29;
      *(double *)a1.i64 = (*(double (**)(uint64_t *, uint64_t *, uint64_t))(v17 + 16))(v29, v16, v4);
      MLDataTable.init(_:convertArraysToShapedArrays:)(v18, 1, a1);
      (*(void (**)(uint64_t *, uint64_t))(v17 + 8))(v16, v4);
      uint64_t result = v30;
      char v15 = v31;
LABEL_7:
      *(void *)uint64_t v3 = result;
      *(unsigned char *)(v3 + 8) = v15;
      break;
    case 3:
      uint64_t v19 = v3;
      uint64_t empty = tc_v1_sframe_create_empty(0);
      if (!empty) {
        BUG();
      }
      uint64_t v21 = empty;
      uint64_t v22 = type metadata accessor for CMLTable();
      uint64_t v23 = swift_allocObject(v22, 24, 7);
      *(void *)(v23 + 16) = v21;
      uint64_t v24 = type metadata accessor for _DataTable();
      swift_allocObject(v24, 40, 7);
      uint64_t result = _DataTable.init(impl:)(v23);
      *(void *)uint64_t v19 = result;
      *(unsigned char *)(v19 + 8) = 0;
      break;
  }
  return result;
}

uint64_t MLBoostedTreeRegressor.ModelParameters.ValidationData.generateDataFrames(trainingData:)(uint64_t a1, uint64_t a2, void (*a3)(uint64_t *, uint64_t, uint64_t))
{
  uint64_t v55 = v3;
  uint64_t v57 = a3;
  unsigned int v56 = (uint64_t *)a2;
  uint64_t v54 = a1;
  uint64_t v5 = type metadata accessor for DataFrame(0);
  uint64_t v58 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v58 + 64);
  uint64_t v7 = alloca(v6);
  unint64_t v8 = alloca(v6);
  uint64_t v50 = &v44;
  uint64_t v46 = type metadata accessor for DataFrame.Slice(0);
  uint64_t v51 = *(void *)(v46 - 8);
  int64_t v9 = *(void *)(v51 + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v48 = &v44;
  char v12 = alloca(v9);
  BOOL v13 = alloca(v9);
  uint64_t v53 = &v44;
  unint64_t v14 = alloca(v9);
  char v15 = alloca(v9);
  uint64_t v52 = &v44;
  int64_t v16 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame.Slice?)
                              - 8)
                  + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  int64_t v47 = &v44;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v49 = &v44;
  uint64_t v21 = type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData(0);
  int64_t v22 = *(void *)(*(void *)(v21 - 8) + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  outlined init with copy of MLBoostedTreeRegressor.ModelParameters.ValidationData(v4, (uint64_t)&v44);
  switch(swift_getEnumCaseMultiPayload(&v44, v21))
  {
    case 0u:
      uint64_t v58 = v5;
      uint64_t v25 = (uint64_t)v49;
      uint64_t v26 = (uint64_t)v52;
      DataFrame.randomSplit(strategy:)((uint64_t)v49, (uint64_t)v52, (uint64_t)&v44);
      uint64_t v27 = v53;
      uint64_t v28 = v46;
      uint64_t v57 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 16);
      v57(v53, v26, v46);
      DataFrame.init(_:)(v27);
      uint64_t v29 = (uint64_t)v47;
      outlined init with copy of DataFrame.Slice?(v25, (uint64_t)v47);
      if (__swift_getEnumTagSinglePayload(v29, 1, v28) == 1)
      {
        __swift_storeEnumTagSinglePayload((uint64_t)v56, 1, 1, v58);
        uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v51 + 8);
      }
      else
      {
        uint64_t v40 = v53;
        uint64_t v41 = v51;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 32))(v53, v29, v28);
        int64_t v42 = v48;
        v57(v48, (uint64_t)v40, v28);
        uint64_t v43 = (uint64_t)v56;
        DataFrame.init(_:)(v42);
        uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v41 + 8);
        v30(v53, v28);
        __swift_storeEnumTagSinglePayload(v43, 0, 1, v58);
      }
      v30(v52, v28);
      return outlined destroy of DataFrame.Slice?((uint64_t)v49);
    case 1u:
      uint64_t v35 = v44;
      char v36 = v45;
      (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
      uint64_t v44 = v35;
      char v45 = v36;
      uint64_t v37 = (uint64_t)v56;
      DataFrame.init(_:)((uint64_t)&v44);
      uint64_t v33 = v37;
      goto LABEL_10;
    case 2u:
      char v31 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v58 + 32);
      v31(v50, &v44, v5);
      if (DataFrameProtocol.isEmpty.getter(v5, &protocol witness table for DataFrame))
      {
        uint64_t v32 = v58;
        (*(void (**)(uint64_t *, uint64_t))(v58 + 8))(v50, v5);
        (*(void (**)(uint64_t, void, uint64_t))(v32 + 16))(v54, v57, v5);
LABEL_7:
        uint64_t v33 = (uint64_t)v56;
        uint64_t v34 = 1;
      }
      else
      {
        (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
        uint64_t v38 = (uint64_t)v56;
        v31(v56, v50, v5);
        uint64_t v33 = v38;
LABEL_10:
        uint64_t v34 = 0;
      }
      return __swift_storeEnumTagSinglePayload(v33, v34, 1, v5);
    case 3u:
      (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
      goto LABEL_7;
  }
}

uint64_t outlined init with copy of MLBoostedTreeRegressor.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

void *initializeBufferWithCopyOfBuffer for MLTextClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  uint64_t v3 = __dst;
  uint64_t v4 = *(void *)(a3 - 8);
  int v5 = *(_DWORD *)(v4 + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v11 = *(void *)__src;
    void *v3 = *(void *)__src;
    uint64_t v3 = (void *)(v11 + ((v5 + 16) & ~v5));
    swift_retain();
  }
  else
  {
    switch(swift_getEnumCaseMultiPayload(__src, a3))
    {
      case 1u:
        uint64_t v7 = *(void *)__src;
        char v8 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v8);
        *(void *)__dst = v7;
        __dst[8] = v8;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v9 = *((void *)__src + 3);
        v3[3] = v9;
        v3[4] = *((void *)__src + 4);
        uint64_t v10 = *((void *)__src + 5);
        v3[5] = v10;
        swift_bridgeObjectRetain(v9);
        swift_bridgeObjectRetain(v10);
        swift_storeEnumTagMultiPayload(v3, a3, 1);
        break;
      case 2u:
        uint64_t v12 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 16))(__dst, __src, v12);
        uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, textColumn: String, labelColumn: String));
        uint64_t v14 = *(int *)(v13 + 48);
        *(void *)&__dst[v14] = *(void *)&__src[v14];
        uint64_t v15 = *(void *)&__src[v14 + 8];
        *(void *)((char *)v3 + v14 + 8) = v15;
        uint64_t v16 = *(int *)(v13 + 64);
        *(void *)((char *)v3 + v16) = *(void *)&__src[v16];
        uint64_t v17 = *(void *)&__src[v16 + 8];
        *(void *)((char *)v3 + v16 + 8) = v17;
        swift_bridgeObjectRetain(v15);
        swift_bridgeObjectRetain(v17);
        swift_storeEnumTagMultiPayload(v3, a3, 2);
        break;
      case 3u:
        uint64_t v18 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 16))(__dst, __src, v18);
        swift_storeEnumTagMultiPayload(__dst, a3, 3);
        break;
      case 4u:
        uint64_t v19 = *(void *)__src;
        void *v3 = *(void *)__src;
        swift_bridgeObjectRetain(v19);
        swift_storeEnumTagMultiPayload(v3, a3, 4);
        break;
      default:
        memcpy(__dst, __src, *(void *)(v4 + 64));
        break;
    }
  }
  return v3;
}

uint64_t destroy for MLTextClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t result = swift_getEnumCaseMultiPayload(a1, a2) - 1;
  switch((int)result)
  {
    case 0:
      outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + 24));
      uint64_t result = swift_bridgeObjectRelease(*(void *)(a1 + 40));
      break;
    case 1:
      uint64_t v3 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8))(a1, v3);
      uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, textColumn: String, labelColumn: String));
      swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(v4 + 48) + 8));
      uint64_t result = swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(v4 + 64) + 8));
      break;
    case 2:
      uint64_t v5 = type metadata accessor for URL(0);
      uint64_t result = (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8))(a1, v5);
      break;
    case 3:
      uint64_t result = swift_bridgeObjectRelease(*(void *)a1);
      break;
    default:
      return result;
  }
  return result;
}

char *initializeWithCopy for MLTextClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  switch(swift_getEnumCaseMultiPayload(__src, a3))
  {
    case 1u:
      uint64_t v5 = *(void *)__src;
      char v6 = __src[8];
      outlined copy of Result<_DataTable, Error>(*(void *)__src, v6);
      *(void *)__dst = v5;
      __dst[8] = v6;
      *((void *)__dst + 2) = *((void *)__src + 2);
      uint64_t v7 = *((void *)__src + 3);
      *((void *)__dst + 3) = v7;
      *((void *)__dst + 4) = *((void *)__src + 4);
      uint64_t v8 = *((void *)__src + 5);
      *((void *)__dst + 5) = v8;
      swift_bridgeObjectRetain(v7);
      swift_bridgeObjectRetain(v8);
      swift_storeEnumTagMultiPayload(__dst, a3, 1);
      break;
    case 2u:
      uint64_t v9 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))(__dst, __src, v9);
      uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, textColumn: String, labelColumn: String));
      uint64_t v11 = *(int *)(v10 + 48);
      *(void *)&__dst[v11] = *(void *)&__src[v11];
      uint64_t v12 = *(void *)&__src[v11 + 8];
      *(void *)&__dst[v11 + 8] = v12;
      uint64_t v13 = *(int *)(v10 + 64);
      *(void *)&__dst[v13] = *(void *)&__src[v13];
      uint64_t v14 = *(void *)&__src[v13 + 8];
      *(void *)&__dst[v13 + 8] = v14;
      swift_bridgeObjectRetain(v12);
      swift_bridgeObjectRetain(v14);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
      break;
    case 3u:
      uint64_t v15 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 16))(__dst, __src, v15);
      swift_storeEnumTagMultiPayload(__dst, a3, 3);
      break;
    case 4u:
      uint64_t v16 = *(void *)__src;
      *(void *)__dst = *(void *)__src;
      swift_bridgeObjectRetain(v16);
      swift_storeEnumTagMultiPayload(__dst, a3, 4);
      break;
    default:
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
      break;
  }
  return __dst;
}

char *assignWithCopy for MLTextClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)__dst, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
    switch(swift_getEnumCaseMultiPayload(__src, a3))
    {
      case 1u:
        uint64_t v5 = *(void *)__src;
        char v6 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v6);
        *(void *)__dst = v5;
        __dst[8] = v6;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v7 = *((void *)__src + 3);
        *((void *)__dst + 3) = v7;
        *((void *)__dst + 4) = *((void *)__src + 4);
        uint64_t v8 = *((void *)__src + 5);
        *((void *)__dst + 5) = v8;
        swift_bridgeObjectRetain(v7);
        swift_bridgeObjectRetain(v8);
        swift_storeEnumTagMultiPayload(__dst, a3, 1);
        break;
      case 2u:
        uint64_t v9 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))(__dst, __src, v9);
        uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, textColumn: String, labelColumn: String));
        uint64_t v11 = *(int *)(v10 + 48);
        *(void *)&__dst[v11] = *(void *)&__src[v11];
        uint64_t v12 = *(void *)&__src[v11 + 8];
        *(void *)&__dst[v11 + 8] = v12;
        uint64_t v13 = *(int *)(v10 + 64);
        *(void *)&__dst[v13] = *(void *)&__src[v13];
        uint64_t v14 = *(void *)&__src[v13 + 8];
        *(void *)&__dst[v13 + 8] = v14;
        swift_bridgeObjectRetain(v12);
        swift_bridgeObjectRetain(v14);
        swift_storeEnumTagMultiPayload(__dst, a3, 2);
        break;
      case 3u:
        uint64_t v15 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 16))(__dst, __src, v15);
        swift_storeEnumTagMultiPayload(__dst, a3, 3);
        break;
      case 4u:
        uint64_t v16 = *(void *)__src;
        *(void *)__dst = *(void *)__src;
        swift_bridgeObjectRetain(v16);
        swift_storeEnumTagMultiPayload(__dst, a3, 4);
        break;
      default:
        memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
        break;
    }
  }
  return __dst;
}

uint64_t type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLTextClassifier.ModelParameters.ValidationData;
  if (!type metadata singleton initialization cache for MLTextClassifier.ModelParameters.ValidationData) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLTextClassifier.ModelParameters.ValidationData);
  }
  return result;
}

char *initializeWithTake for MLTextClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
  if (EnumCaseMultiPayload == 3)
  {
    uint64_t v7 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 32))(__dst, __src, v7);
    swift_storeEnumTagMultiPayload(__dst, a3, 3);
  }
  else if (EnumCaseMultiPayload == 2)
  {
    uint64_t v5 = type metadata accessor for DataFrame(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v5 - 8) + 32))(__dst, __src, v5);
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, textColumn: String, labelColumn: String));
    *(_OWORD *)&__dst[*(int *)(v6 + 48)] = *(_OWORD *)&__src[*(int *)(v6 + 48)];
    *(_OWORD *)&__dst[*(int *)(v6 + 64)] = *(_OWORD *)&__src[*(int *)(v6 + 64)];
    swift_storeEnumTagMultiPayload(__dst, a3, 2);
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
  }
  return __dst;
}

char *assignWithTake for MLTextClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)__dst, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
    if (EnumCaseMultiPayload == 3)
    {
      uint64_t v7 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 32))(__dst, __src, v7);
      swift_storeEnumTagMultiPayload(__dst, a3, 3);
    }
    else if (EnumCaseMultiPayload == 2)
    {
      uint64_t v5 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v5 - 8) + 32))(__dst, __src, v5);
      uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, textColumn: String, labelColumn: String));
      *(_OWORD *)&__dst[*(int *)(v6 + 48)] = *(_OWORD *)&__src[*(int *)(v6 + 48)];
      *(_OWORD *)&__dst[*(int *)(v6 + 64)] = *(_OWORD *)&__src[*(int *)(v6 + 64)];
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLTextClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  v7[0] = &unk_350388;
  v7[1] = &unk_3503A0;
  uint64_t result = type metadata accessor for DataFrame(319);
  if (v2 <= 0x3F)
  {
    swift_getTupleTypeLayout3(v6, *(void *)(result - 8) + 64, &unk_3503B8, &unk_3503B8);
    v7[2] = v6;
    uint64_t result = type metadata accessor for URL(319);
    if (v5 <= 0x3F)
    {
      v7[3] = *(void *)(result - 8) + 64;
      v7[4] = (char *)&value witness table for Builtin.BridgeObject + 64;
      swift_initEnumMetadataMultiPayload(a1, 256, 5, v7, v3, v4);
      return 0;
    }
  }
  return result;
}

uint64_t MLTextClassifier.ModelParameters.ValidationData.createValidationData(trainingData:textColumn:labelColumn:)(void **a1, uint64_t a2, void *a3, uint64_t a4, void *a5, double a6)
{
  v102._uint64_t countAndFlagsBits = a4;
  to = a3;
  uint64_t v106 = v6;
  v104._uint64_t countAndFlagsBits = a2;
  uint64_t v109 = v7;
  v108._char object = v8;
  v102._char object = a5;
  uint64_t v97 = a1;
  int64_t v9 = *(void *)(*(void *)(type metadata accessor for MLTextClassifier.DataSource(0) - 8) + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  _ = (void **)&v94;
  uint64_t v111 = type metadata accessor for DataFrame(0);
  uint64_t v12 = *(void *)(v111 - 8);
  int64_t v13 = *(void *)(v12 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  v105._char object = &v94;
  uint64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  v104._char object = &v94;
  uint64_t v98 = type metadata accessor for DataFrame.Slice(0);
  uint64_t v18 = *(void *)(v98 - 8);
  int64_t v19 = *(void *)(v18 + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  uint64_t v99 = (void **)&v94;
  int64_t v22 = alloca(v19);
  uint64_t v23 = alloca(v19);
  uint64_t v101 = (void **)&v94;
  uint64_t v24 = alloca(v19);
  uint64_t v25 = alloca(v19);
  uint64_t v110 = (void **)&v94;
  int64_t v26 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame.Slice?)
                              - 8)
                  + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  v105._uint64_t countAndFlagsBits = (uint64_t)&v94;
  uint64_t v29 = alloca(v26);
  uint64_t v30 = alloca(v26);
  v108._uint64_t countAndFlagsBits = (uint64_t)&v94;
  uint64_t v31 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  int64_t v32 = *(void *)(*(void *)(v31 - 8) + 64);
  uint64_t v33 = alloca(v32);
  uint64_t v34 = alloca(v32);
  outlined init with copy of MLTextClassifier.ModelParameters.ValidationData((uint64_t)v108._object, (uint64_t)&v94);
  switch(swift_getEnumCaseMultiPayload(&v94, v31))
  {
    case 0u:
      v108._char object = (void *)v12;
      uint64_t v35 = v111;
      uint64_t countAndFlagsBits = v108._countAndFlagsBits;
      uint64_t v37 = v97;
      DataFrame.randomSplit(strategy:)(v108._countAndFlagsBits, (uint64_t)v110, (uint64_t)&v94);
      uint64_t v38 = countAndFlagsBits;
      uint64_t v39 = v105._countAndFlagsBits;
      outlined init with copy of DataFrame.Slice?(v38, v105._countAndFlagsBits);
      uint64_t v40 = v39;
      uint64_t v41 = v98;
      if (__swift_getEnumTagSinglePayload(v40, 1, v98) == 1)
      {
        (*(void (**)(void **, uint64_t))(v18 + 8))(v110, v41);
        outlined destroy of DataFrame.Slice?(v108._countAndFlagsBits);
        outlined destroy of DataFrame.Slice?(v105._countAndFlagsBits);
        uint64_t v42 = v106;
        uint64_t v43 = 1;
        uint64_t v44 = v35;
        return __swift_storeEnumTagSinglePayload(v42, v43, 1, v44);
      }
      (*((void (**)(void **, uint64_t))v108._object + 1))(v37, v35);
      uint64_t v100 = v18;
      (*(void (**)(void **, uint64_t, uint64_t))(v18 + 32))(v101, v105._countAndFlagsBits, v41);
      uint64_t v76 = *(void (**)(void **, void **, uint64_t))(v18 + 16);
      uint64_t v77 = v99;
      v76(v99, v110, v41);
      DataFrame.init(_:)(v77);
      v76(v77, v101, v41);
      uint64_t v78 = v41;
      uint64_t v79 = v106;
      DataFrame.init(_:)(v77);
      uint64_t v80 = *(void (**)(void **, uint64_t))(v100 + 8);
      v80(v101, v78);
      v80(v110, v78);
      outlined destroy of DataFrame.Slice?(v108._countAndFlagsBits);
      uint64_t v42 = v79;
      uint64_t v43 = 0;
      goto LABEL_17;
    case 1u:
      v108._char object = (void *)v12;
      int v45 = v95;
      uint64_t v46 = v96;
      _ = v97;
      v108._uint64_t countAndFlagsBits = v98;
      int64_t v47 = v99;
      LOBYTE(v95) = v95 & 1;
      uint64_t v110 = v94;
      LODWORD(v105._object) = v45;
      outlined copy of Result<_DataTable, Error>((uint64_t)v94, v45);
      char object = v104._object;
      DataFrame.init(_:)((uint64_t)&v94);
      uint64_t v49 = (uint64_t)object;
      uint64_t v50 = v47;
      uint64_t v51 = _;
      v105._uint64_t countAndFlagsBits = v46;
      uint64_t v52 = v46;
      uint64_t v53 = v108._countAndFlagsBits;
      uint64_t v54 = v109;
      static MLTextClassifier.validateDataFrame(_:textColumn:labelColumn:)(v49, v52, _, v108._countAndFlagsBits, v50);
      if (v54)
      {
        (*((void (**)(void *, uint64_t))v108._object + 1))(v104._object, v111);
        outlined consume of Result<_DataTable, Error>((uint64_t)v110, (char)v105._object);
        char v55 = (char)v50;
        goto LABEL_8;
      }
      v81._uint64_t countAndFlagsBits = v105._countAndFlagsBits;
      v81._char object = v51;
      v82._uint64_t countAndFlagsBits = v104._countAndFlagsBits;
      v82._char object = to;
      uint64_t v109 = v50;
      uint64_t v83 = v104._object;
      DataFrame.renameColumn(_:to:)(v81, v82);
      swift_bridgeObjectRelease((_BYTE)v51);
      v81._uint64_t countAndFlagsBits = v53;
      char v84 = (char)v109;
      v81._char object = v109;
      DataFrame.renameColumn(_:to:)(v81, v102);
      outlined consume of Result<_DataTable, Error>((uint64_t)v110, (char)v105._object);
      swift_bridgeObjectRelease(v84);
      uint64_t v85 = v106;
      uint64_t v86 = v111;
      (*((void (**)(uint64_t, void *, uint64_t))v108._object + 4))(v106, v83, v111);
      uint64_t v87 = v85;
      uint64_t v88 = v86;
      goto LABEL_23;
    case 2u:
      uint64_t v56 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, textColumn: String, labelColumn: String));
      uint64_t v57 = *(int *)(v56 + 48);
      v108._char object = *(void ***)((char *)&v94 + v57);
      uint64_t v110 = *(void ***)((char *)&v94 + v57 + 8);
      uint64_t v58 = *(int *)(v56 + 64);
      uint64_t v59 = *(uint64_t *)((char *)&v94 + v58);
      v104._char object = *(void ***)((char *)&v94 + v58 + 8);
      char v60 = v105._object;
      _ = *(void ***)(v12 + 32);
      ((void (*)(void *, void ***, uint64_t))_)(v105._object, &v94, v111);
      uint64_t v61 = (uint64_t)v60;
      uint64_t v62 = v110;
      v108._uint64_t countAndFlagsBits = v59;
      uint64_t v63 = v59;
      uint64_t v51 = v104._object;
      uint64_t v64 = v109;
      static MLTextClassifier.validateDataFrame(_:textColumn:labelColumn:)(v61, (uint64_t)v108._object, v110, v63, v104._object);
      if (!v64)
      {
        v89._uint64_t countAndFlagsBits = (uint64_t)v108._object;
        v89._char object = v62;
        v90._uint64_t countAndFlagsBits = v104._countAndFlagsBits;
        v90._char object = to;
        uint64_t v91 = v105._object;
        DataFrame.renameColumn(_:to:)(v89, v90);
        swift_bridgeObjectRelease((_BYTE)v62);
        v89._uint64_t countAndFlagsBits = v108._countAndFlagsBits;
        v89._char object = v51;
        DataFrame.renameColumn(_:to:)(v89, v102);
        swift_bridgeObjectRelease((_BYTE)v51);
        uint64_t v92 = v106;
        uint64_t v67 = v111;
        ((void (*)(uint64_t, void *, uint64_t))_)(v106, v91, v111);
        uint64_t v87 = v92;
        goto LABEL_22;
      }
      (*(void (**)(void *, uint64_t))(v12 + 8))(v105._object, v111);
      char v55 = (char)v62;
LABEL_8:
      swift_bridgeObjectRelease(v55);
      char v65 = (char)v51;
LABEL_14:
      uint64_t result = swift_bridgeObjectRelease(v65);
      break;
    case 3u:
      uint64_t v66 = v106;
      uint64_t v67 = v111;
      uint64_t v68 = _;
      outlined init with take of MLTextClassifier.DataSource((uint64_t)&v94, (uint64_t)_);
      uint64_t v69 = v109;
      uint64_t v70 = static _TextUtilities.getTextLabeledDictionary(from:)((uint64_t)v68, a6);
      if (v69)
      {
        uint64_t result = outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)_, type metadata accessor for MLTextClassifier.DataSource);
      }
      else
      {
        char v93 = (char)v70;
        specialized generateTextDataFrame<A>(_:textColumn:labelColumn:using:)((uint64_t)v70, v104._countAndFlagsBits, (uint64_t)to, v102._countAndFlagsBits, (uint64_t)v102._object);
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)_, type metadata accessor for MLTextClassifier.DataSource);
        swift_bridgeObjectRelease(v93);
        uint64_t v87 = v66;
LABEL_22:
        uint64_t v88 = v67;
LABEL_23:
        uint64_t result = __swift_storeEnumTagSinglePayload(v87, 0, 1, v88);
      }
      break;
    case 4u:
      uint64_t v72 = v111;
      char v73 = (char)v94;
      uint64_t v74 = v106;
      uint64_t v75 = v109;
      specialized generateTextDataFrame<A>(_:textColumn:labelColumn:using:)((uint64_t)v94, v104._countAndFlagsBits, (uint64_t)to, v102._countAndFlagsBits, (uint64_t)v102._object);
      if (!v75) {
        __swift_storeEnumTagSinglePayload(v74, 0, 1, v72);
      }
      char v65 = v73;
      goto LABEL_14;
    case 5u:
      uint64_t v42 = v106;
      uint64_t v43 = 1;
LABEL_17:
      uint64_t v44 = v111;
      return __swift_storeEnumTagSinglePayload(v42, v43, 1, v44);
  }
  return result;
}

uint64_t MLTextClassifier.ModelParameters.ValidationData.table.getter(__m128 a1)
{
  uint64_t v41 = v1;
  int64_t v3 = *(void *)(*(void *)(type metadata accessor for MLTextClassifier.DataSource(0) - 8) + 64);
  uint64_t v4 = alloca(v3);
  unint64_t v5 = alloca(v3);
  uint64_t v38 = &v35;
  uint64_t v6 = type metadata accessor for DataFrame(0);
  uint64_t v7 = *(void *)(v6 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v37 = &v35;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  char v36 = &v35;
  uint64_t v13 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  int64_t v14 = *(void *)(*(void *)(v13 - 8) + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  outlined init with copy of MLTextClassifier.ModelParameters.ValidationData(v2, (uint64_t)&v35);
  switch(swift_getEnumCaseMultiPayload(&v35, v13))
  {
    case 0u:
      uint64_t result = (uint64_t)v41;
      *uint64_t v41 = 0;
      *(unsigned char *)(result + 8) = -1;
      return result;
    case 1u:
      uint64_t v17 = v35;
      char v18 = (char)v36;
      char v19 = v40;
      swift_bridgeObjectRelease((_BYTE)v38);
      swift_bridgeObjectRelease(v19);
      uint64_t result = (uint64_t)v41;
      *uint64_t v41 = v17;
      *(unsigned char *)(result + 8) = v18;
      return result;
    case 2u:
      uint64_t v21 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, textColumn: String, labelColumn: String));
      swift_bridgeObjectRelease(*(uint64_t *)((char *)&v35 + *(int *)(v21 + 48) + 8));
      swift_bridgeObjectRelease(*(uint64_t *)((char *)&v35 + *(int *)(v21 + 64) + 8));
      int64_t v22 = v36;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v7 + 32))(v36, &v35, v6);
      uint64_t v23 = (uint64_t)v37;
      *(double *)a1.i64 = (*(double (**)(uint64_t *, uint64_t *, uint64_t))(v7 + 16))(v37, v22, v6);
      MLDataTable.init(_:convertArraysToShapedArrays:)(v23, 0, a1);
      (*(void (**)(uint64_t *, uint64_t))(v7 + 8))(v22, v6);
      goto LABEL_10;
    case 3u:
      uint64_t v24 = (uint64_t)v38;
      outlined init with take of MLTextClassifier.DataSource((uint64_t)&v35, (uint64_t)v38);
      uint64_t v25 = static _TextUtilities.getTextLabeledDictionary(from:)(v24, *(double *)a1.i64);
      char v26 = (char)v25;
      specialized generateTextTable<A>(_:textColumn:labelColumn:using:)((uint64_t)v25, 1954047348, 0xE400000000000000, 0x6C6562616CLL, 0xE500000000000000);
      outlined destroy of MLActivityClassifier.ModelParameters(v24, type metadata accessor for MLTextClassifier.DataSource);
      goto LABEL_9;
    case 4u:
      char v26 = v35;
      specialized generateTextTable<A>(_:textColumn:labelColumn:using:)(v35, 1954047348, 0xE400000000000000, 0x6C6562616CLL, 0xE500000000000000);
LABEL_9:
      swift_bridgeObjectRelease(v26);
LABEL_10:
      uint64_t result = v39;
      char v33 = v40;
      uint64_t v34 = v41;
      *uint64_t v41 = v39;
      *((unsigned char *)v34 + 8) = v33;
      break;
    case 5u:
      uint64_t empty = tc_v1_sframe_create_empty(0);
      if (!empty) {
        BUG();
      }
      uint64_t v28 = empty;
      uint64_t v29 = type metadata accessor for CMLTable();
      uint64_t v30 = swift_allocObject(v29, 24, 7);
      *(void *)(v30 + 16) = v28;
      uint64_t v31 = type metadata accessor for _DataTable();
      swift_allocObject(v31, 40, 7);
      uint64_t result = _DataTable.init(impl:)(v30);
      int64_t v32 = v41;
      *uint64_t v41 = result;
      *((unsigned char *)v32 + 8) = 0;
      break;
  }
  return result;
}

uint64_t outlined init with copy of MLTextClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined init with take of MLTextClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLTextClassifier.DataSource(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t MLActionClassifier.ModelParameters.init(validation:batchSize:maximumIterations:predictionWindowSize:augmentationOptions:algorithm:targetFrameRate:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t *a5, double a6)
{
  uint64_t v9 = v6;
  uint64_t v10 = *a5;
  outlined init with take of MLClassifierMetrics(a1, v6, type metadata accessor for MLActionClassifier.ModelParameters.ValidationData);
  uint64_t v11 = (int *)type metadata accessor for MLActionClassifier.ModelParameters(0);
  *(void *)(v9 + v11[5]) = a2;
  *(void *)(v9 + v11[6]) = a3;
  *(void *)(v9 + v11[7]) = a4;
  *(void *)(v9 + v11[8]) = v10;
  uint64_t result = v11[10];
  *(double *)(v9 + result) = a6;
  return result;
}

uint64_t type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLActionClassifier.ModelParameters.ValidationData, (uint64_t)&nominal type descriptor for MLActionClassifier.ModelParameters.ValidationData);
}

uint64_t type metadata accessor for MLActionClassifier.ModelParameters(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLActionClassifier.ModelParameters, (uint64_t)&nominal type descriptor for MLActionClassifier.ModelParameters);
}

char MLActionClassifier.ModelParameters.ValidationData.extractAnnotations(trainingData:)(uint64_t *a1, void *a2, __m128 a3)
{
  uint64_t v53 = v3;
  uint64_t v54 = v4;
  uint64_t v51 = a2;
  uint64_t v52 = a1;
  uint64_t v5 = type metadata accessor for MLActionClassifier.DataSource(0);
  int64_t v6 = *(void *)(*(void *)(v5 - 8) + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  *(void *)&long long v45 = &v40;
  uint64_t v9 = type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(0);
  int64_t v10 = *(void *)(*(void *)(v9 - 8) + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v13 = v53;
  LOBYTE(v14) = MLActionClassifier.DataSource.videosWithAnnotations()(a3);
  if (!v13)
  {
    uint64_t v46 = v5;
    uint64_t v50 = v47;
    LOBYTE(v53) = BYTE8(v47);
    outlined init with copy of MLActionClassifier.ModelParameters.ValidationData(v54, (uint64_t)&v40);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v40, v9);
    if (EnumCaseMultiPayload)
    {
      if (EnumCaseMultiPayload == 1)
      {
        uint64_t v54 = 0;
        if (swift_getEnumCaseMultiPayload(&v40, v46) == 3)
        {
          outlined consume of Result<_DataTable, Error>(v50, v53);
          char v16 = v42;
          char v17 = v44;
          char v18 = BYTE8(v45);
          outlined consume of Result<_DataTable, Error>(v40, SBYTE8(v40));
          swift_bridgeObjectRelease(v18);
          swift_bridgeObjectRelease(v17);
          swift_bridgeObjectRelease(v16);
LABEL_13:
          int64_t v32 = v52;
          uint64_t *v52 = 0;
          LOBYTE(v14) = -1;
          *((unsigned char *)v32 + 8) = -1;
          char v33 = v51;
          *uint64_t v51 = 0;
          *((unsigned char *)v33 + 8) = -1;
          return (char)v14;
        }
        uint64_t v30 = v45;
        outlined init with take of MLClassifierMetrics((uint64_t)&v40, v45, type metadata accessor for MLActionClassifier.DataSource);
        uint64_t v31 = v54;
        MLActionClassifier.DataSource.videosWithAnnotations()(a3);
        outlined destroy of MLActionClassifier.ModelParameters.ValidationData(v30, type metadata accessor for MLActionClassifier.DataSource);
        if (v31)
        {
          LOBYTE(v14) = outlined consume of Result<_DataTable, Error>(v50, v53);
        }
        else
        {
          int64_t v14 = (void *)v47;
          char v36 = BYTE8(v47);
          uint64_t v37 = v52;
          uint64_t *v52 = v50;
          *((unsigned char *)v37 + 8) = v53;
          uint64_t v38 = v51;
          *uint64_t v51 = v14;
          *((unsigned char *)v38 + 8) = v36;
        }
      }
      else
      {
        uint64_t v26 = v50;
        *(void *)&long long v47 = v50;
        char v27 = v53;
        BYTE8(v47) = v53;
        MLDataTable.size.getter();
        if (v28)
        {
          uint64_t v29 = v52;
          uint64_t *v52 = v26;
          *((unsigned char *)v29 + 8) = v27;
          int64_t v14 = v51;
          *uint64_t v51 = 0;
          *((unsigned char *)v14 + 8) = -1;
        }
        else
        {
          outlined consume of Result<_DataTable, Error>(v26, v27);
          uint64_t v34 = v52;
          uint64_t *v52 = 0;
          LOBYTE(v14) = -1;
          *((unsigned char *)v34 + 8) = -1;
          uint64_t v35 = v51;
          *uint64_t v51 = 0;
          *((unsigned char *)v35 + 8) = -1;
        }
      }
    }
    else
    {
      uint64_t v54 = 0;
      long long v45 = v40;
      char v19 = BYTE1(v41);
      LOBYTE(v46) = v41;
      uint64_t v20 = v50;
      *(void *)&long long v47 = v50;
      char v21 = v53;
      BYTE8(v47) = v53;
      if (MLDataTable.size.getter() <= 0)
      {
        outlined consume of Result<_DataTable, Error>(v20, v21);
        goto LABEL_13;
      }
      uint64_t v41 = v20;
      char v42 = v21;
      long long v47 = v45;
      char v48 = v46;
      char v49 = v19 & 1;
      MLDataTable.randomSplitBySequence(strategy:by:on:)(&v40, &v43, (uint64_t)&v47, 0x7461506F65646976, (void *)0xE900000000000068, 0x6C6562616CLL, (void *)0xE500000000000000);
      outlined consume of Result<_DataTable, Error>(v20, v21);
      int64_t v14 = (void *)v40;
      char v22 = BYTE8(v40);
      char v23 = v44;
      uint64_t v24 = v52;
      uint64_t *v52 = v43;
      *((unsigned char *)v24 + 8) = v23;
      uint64_t v25 = v51;
      *uint64_t v51 = v14;
      *((unsigned char *)v25 + 8) = v22;
    }
  }
  return (char)v14;
}

uint64_t MLActionClassifier.ModelParameters.getOptions()()
{
  uint64_t v2 = tc_v1_flex_dict_create(0);
  if (!v2) {
    BUG();
  }
  uint64_t v3 = v2;
  uint64_t v4 = type metadata accessor for CMLDictionary();
  uint64_t v5 = swift_allocObject(v4, 24, 7);
  *(void *)(v5 + 16) = v3;
  if ((*(unsigned char *)(v1 + *(int *)(type metadata accessor for MLActionClassifier.ModelParameters(0) + 32)) & 1) == 0)
  {
    uint64_t v6 = specialized handling<A, B>(_:_:)(0);
    if (!v0)
    {
      uint64_t v7 = v6;
      if (!v6) {
        BUG();
      }
      uint64_t v8 = type metadata accessor for CMLFeatureValue();
      swift_initStackObject(v8, v15);
      uint64_t v9 = CMLFeatureValue.init(rawValue:ownsValue:)(v7, 1);
      CMLDictionary.add(key:value:)(0xD000000000000011, (uint64_t)("entationOptions.swift" + 0x8000000000000000), v9);
      goto LABEL_10;
    }
LABEL_14:
    swift_unexpectedError(v0, "CreateML/MLActionClassifier.AugmentationOptions.swift", 53, 1);
    BUG();
  }
  uint64_t v10 = specialized handling<A, B>(_:_:)(1);
  if (v0) {
    goto LABEL_14;
  }
  uint64_t v11 = v10;
  if (!v10) {
    BUG();
  }
  uint64_t v12 = type metadata accessor for CMLFeatureValue();
  swift_initStackObject(v12, v16);
  uint64_t v13 = CMLFeatureValue.init(rawValue:ownsValue:)(v11, 1);
  CMLDictionary.add(key:value:)(0xD000000000000011, (uint64_t)("entationOptions.swift" + 0x8000000000000000), v13);
LABEL_10:
  swift_release();
  return v5;
}

unint64_t MLActionClassifier.ModelParameters.debugDescription.getter()
{
  return MLActionClassifier.ModelParameters.description.getter();
}

uint64_t MLActionClassifier.ModelParameters.validation.getter()
{
  return outlined init with copy of MLActionClassifier.ModelParameters.ValidationData(v1, v0);
}

uint64_t MLActionClassifier.ModelParameters.validation.setter(uint64_t a1)
{
  return outlined assign with take of MLActionClassifier.ModelParameters.ValidationData(a1, v1);
}

void (*MLActionClassifier.ModelParameters.validation.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLActionClassifier.ModelParameters.batchSize.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLActionClassifier.ModelParameters(0) + 20));
}

uint64_t MLActionClassifier.ModelParameters.batchSize.setter(uint64_t a1)
{
  uint64_t result = *(int *)(type metadata accessor for MLActionClassifier.ModelParameters(0) + 20);
  *(void *)(v1 + result) = a1;
  return result;
}

void (*MLActionClassifier.ModelParameters.batchSize.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLActionClassifier.ModelParameters.maximumIterations.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLActionClassifier.ModelParameters(0) + 24));
}

uint64_t MLActionClassifier.ModelParameters.maximumIterations.setter(uint64_t a1)
{
  uint64_t result = *(int *)(type metadata accessor for MLActionClassifier.ModelParameters(0) + 24);
  *(void *)(v1 + result) = a1;
  return result;
}

void (*MLActionClassifier.ModelParameters.maximumIterations.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLActionClassifier.ModelParameters.predictionWindowSize.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLActionClassifier.ModelParameters(0) + 28));
}

uint64_t MLActionClassifier.ModelParameters.predictionWindowSize.setter(uint64_t a1)
{
  uint64_t result = *(int *)(type metadata accessor for MLActionClassifier.ModelParameters(0) + 28);
  *(void *)(v1 + result) = a1;
  return result;
}

void (*MLActionClassifier.ModelParameters.predictionWindowSize.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLActionClassifier.ModelParameters.augmentationOptions.getter()
{
  uint64_t v2 = v0;
  uint64_t result = *(void *)(v1 + *(int *)(type metadata accessor for MLActionClassifier.ModelParameters(0) + 32));
  void *v2 = result;
  return result;
}

uint64_t MLActionClassifier.ModelParameters.augmentationOptions.setter(uint64_t *a1)
{
  uint64_t v2 = *a1;
  uint64_t result = *(int *)(type metadata accessor for MLActionClassifier.ModelParameters(0) + 32);
  *(void *)(v1 + result) = v2;
  return result;
}

void (*MLActionClassifier.ModelParameters.augmentationOptions.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

void (*MLActionClassifier.ModelParameters.algorithm.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLActionClassifier.ModelParameters.targetFrameRate.getter()
{
  return *(double *)(v0 + *(int *)(type metadata accessor for MLActionClassifier.ModelParameters(0) + 40));
}

uint64_t MLActionClassifier.ModelParameters.targetFrameRate.setter(double a1)
{
  uint64_t result = *(int *)(type metadata accessor for MLActionClassifier.ModelParameters(0) + 40);
  *(double *)(v1 + result) = a1;
  return result;
}

void (*MLActionClassifier.ModelParameters.targetFrameRate.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

void MLActionClassifier.ModelParameters.ModelAlgorithmType.hash(into:)()
{
}

char static MLActionClassifier.ModelParameters.ModelAlgorithmType.== infix(_:_:)()
{
  return 1;
}

Swift::Int MLActionClassifier.ModelParameters.ModelAlgorithmType.hashValue.getter()
{
  return Hasher._finalize()();
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLActionClassifier.ModelParameters.ModelAlgorithmType()
{
  return MLActionClassifier.ModelParameters.ModelAlgorithmType.hashValue.getter();
}

void protocol witness for Hashable.hash(into:) in conformance MLActionClassifier.ModelParameters.ModelAlgorithmType()
{
}

unint64_t MLActionClassifier.ModelParameters.description.getter()
{
  _StringGuts.grow(_:)(23);
  swift_bridgeObjectRelease(0);
  uint64_t v1 = type metadata accessor for MLActionClassifier.ModelParameters(0);
  v2._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  char object = (char)v2._object;
  String.append(_:)(v2);
  swift_bridgeObjectRelease(object);
  v4._uint64_t countAndFlagsBits = 10;
  v4._char object = (void *)0xE100000000000000;
  String.append(_:)(v4);
  strcpy((char *)&v15, "Batch Size: ");
  BYTE5(v15._object) = 0;
  HIWORD(v15._object) = -5120;
  v5._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  char v6 = (char)v5._object;
  String.append(_:)(v5);
  swift_bridgeObjectRelease(v6);
  v4._uint64_t countAndFlagsBits = 10;
  v4._char object = (void *)0xE100000000000000;
  String.append(_:)(v4);
  String.append(_:)(v15);
  swift_bridgeObjectRelease(v15._object);
  _StringGuts.grow(_:)(27);
  swift_bridgeObjectRelease(0);
  v7._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  char v8 = (char)v7._object;
  String.append(_:)(v7);
  swift_bridgeObjectRelease(v8);
  v4._uint64_t countAndFlagsBits = 10;
  v4._char object = (void *)0xE100000000000000;
  String.append(_:)(v4);
  v4._uint64_t countAndFlagsBits = 0xD000000000000018;
  v4._char object = "Maximum Iterations: " + 0x8000000000000000;
  String.append(_:)(v4);
  swift_bridgeObjectRelease(("Maximum Iterations: " + 0x8000000000000000));
  _StringGuts.grow(_:)(22);
  swift_bridgeObjectRelease(0);
  v15._uint64_t countAndFlagsBits = 0xD000000000000013;
  v15._char object = "Prediction Window Time: " + 0x8000000000000000;
  v9._uint64_t countAndFlagsBits = Double.description.getter(*(double *)(v0 + *(int *)(v1 + 40)));
  char v10 = (char)v9._object;
  String.append(_:)(v9);
  swift_bridgeObjectRelease(v10);
  v4._uint64_t countAndFlagsBits = 10;
  v4._char object = (void *)0xE100000000000000;
  String.append(_:)(v4);
  v4._uint64_t countAndFlagsBits = 0xD000000000000013;
  v11._char object = "Prediction Window Time: " + 0x8000000000000000;
  String.append(_:)(v11);
  swift_bridgeObjectRelease(("Prediction Window Time: " + 0x8000000000000000));
  _StringGuts.grow(_:)(25);
  swift_bridgeObjectRelease(0);
  v15._uint64_t countAndFlagsBits = 0xD000000000000016;
  v15._char object = "Target Frame Rate: " + 0x8000000000000000;
  v11._uint64_t countAndFlagsBits = 0x746E6F7A69726F48;
  if (*(void *)(v0 + *(int *)(v1 + 32)) != 1) {
    v11._uint64_t countAndFlagsBits = 0;
  }
  unint64_t v12 = 0xEF70696C46206C61;
  if (*(void *)(v0 + *(int *)(v1 + 32)) != 1) {
    unint64_t v12 = 0xE000000000000000;
  }
  v11._char object = (void *)v12;
  String.append(_:)(v11);
  swift_bridgeObjectRelease(v12);
  v13._uint64_t countAndFlagsBits = 10;
  v13._char object = (void *)0xE100000000000000;
  String.append(_:)(v13);
  String.append(_:)(v15);
  swift_bridgeObjectRelease(v15._object);
  _StringGuts.grow(_:)(20);
  swift_bridgeObjectRelease(0);
  v13._uint64_t countAndFlagsBits = 0xD000000000000017;
  v13._char object = "ization for CoreML. Found: " + 0x8000000000000000;
  String.append(_:)(v13);
  return 0xD000000000000014;
}

uint64_t outlined init with copy of MLActionClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined assign with take of MLActionClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 40))(a2, a1, v2);
  return a2;
}

unint64_t MLActionClassifier.ModelParameters.playgroundDescription.getter()
{
  uint64_t v1 = v0;
  unint64_t result = MLActionClassifier.ModelParameters.description.getter();
  v1[3] = (unint64_t)&type metadata for String;
  *uint64_t v1 = result;
  v1[1] = v3;
  return result;
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLActionClassifier.ModelParameters()
{
  return MLActionClassifier.ModelParameters.description.getter();
}

unint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLActionClassifier.ModelParameters()
{
  return MLActionClassifier.ModelParameters.debugDescription.getter();
}

unint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLActionClassifier.ModelParameters()
{
  return MLActionClassifier.ModelParameters.playgroundDescription.getter();
}

uint64_t base witness table accessor for Equatable in MLActionClassifier.ModelParameters.ModelAlgorithmType()
{
  return lazy protocol witness table accessor for type MLActionClassifier.ModelParameters.ModelAlgorithmType and conformance MLActionClassifier.ModelParameters.ModelAlgorithmType();
}

uint64_t lazy protocol witness table accessor for type MLActionClassifier.ModelParameters.ModelAlgorithmType and conformance MLActionClassifier.ModelParameters.ModelAlgorithmType()
{
  uint64_t result = lazy protocol witness table cache variable for type MLActionClassifier.ModelParameters.ModelAlgorithmType and conformance MLActionClassifier.ModelParameters.ModelAlgorithmType;
  if (!lazy protocol witness table cache variable for type MLActionClassifier.ModelParameters.ModelAlgorithmType and conformance MLActionClassifier.ModelParameters.ModelAlgorithmType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLActionClassifier.ModelParameters.ModelAlgorithmType, &type metadata for MLActionClassifier.ModelParameters.ModelAlgorithmType);
    lazy protocol witness table cache variable for type MLActionClassifier.ModelParameters.ModelAlgorithmType and conformance MLActionClassifier.ModelParameters.ModelAlgorithmType = result;
  }
  return result;
}

char *initializeBufferWithCopyOfBuffer for MLActionClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  Swift::String v4 = __dst;
  int v5 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v18 = *(void *)__src;
    *(void *)Swift::String v4 = *(void *)__src;
    Swift::String v4 = (char *)(v18 + ((v5 + 16) & ~v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(0);
    if (swift_getEnumCaseMultiPayload(__src, v7) == 1)
    {
      uint64_t v8 = type metadata accessor for MLActionClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v8))
      {
        case 0u:
          uint64_t v45 = type metadata accessor for URL(0);
          uint64_t v51 = *(void (**)(char *, char *, uint64_t))(*(void *)(v45 - 8) + 16);
          v51(__dst, __src, v45);
          uint64_t v49 = v8;
          Swift::String v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
          v51(&__dst[v9[12]], &__src[v9[12]], v45);
          uint64_t v10 = v9[16];
          *(void *)&__dst[v10] = *(void *)&__src[v10];
          uint64_t v11 = *(void *)&__src[v10 + 8];
          *(void *)&v4[v10 + 8] = v11;
          uint64_t v12 = v9[20];
          *(void *)&v4[v12] = *(void *)&__src[v12];
          uint64_t v52 = *(void *)&__src[v12 + 8];
          *(void *)&v4[v12 + 8] = v52;
          uint64_t v13 = v9[24];
          *(void *)&v4[v13] = *(void *)&__src[v13];
          uint64_t v46 = *(void *)&__src[v13 + 8];
          *(void *)&v4[v13 + 8] = v46;
          uint64_t v14 = v9[28];
          *(void *)&v4[v14] = *(void *)&__src[v14];
          uint64_t v15 = *(void *)&__src[v14 + 8];
          *(void *)&v4[v14 + 8] = v15;
          swift_bridgeObjectRetain(v11);
          swift_bridgeObjectRetain(v52);
          swift_bridgeObjectRetain(v46);
          swift_bridgeObjectRetain(v15);
          __dst = v4;
          uint64_t v16 = v49;
          uint64_t v17 = 0;
          goto LABEL_15;
        case 1u:
          uint64_t v19 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16))(__dst, __src, v19);
          uint64_t v43 = 1;
          goto LABEL_9;
        case 2u:
          uint64_t v20 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v20 - 8) + 16))(__dst, __src, v20);
          uint64_t v43 = 2;
LABEL_9:
          uint64_t v17 = v43;
          uint64_t v16 = v8;
          goto LABEL_15;
        case 3u:
          uint64_t v50 = v8;
          uint64_t v21 = *(void *)__src;
          char v53 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v53);
          *(void *)__dst = v21;
          __dst[8] = v53;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v22 = *((void *)__src + 3);
          *((void *)v4 + 3) = v22;
          *((void *)v4 + 4) = *((void *)__src + 4);
          uint64_t v23 = *((void *)__src + 5);
          *((void *)v4 + 5) = v23;
          *((void *)v4 + 6) = *((void *)__src + 6);
          uint64_t v54 = *((void *)__src + 7);
          *((void *)v4 + 7) = v54;
          swift_bridgeObjectRetain(v22);
          swift_bridgeObjectRetain(v23);
          swift_bridgeObjectRetain(v54);
          uint64_t v44 = 3;
          goto LABEL_14;
        case 4u:
          uint64_t v50 = v8;
          uint64_t v24 = *(void *)__src;
          char v55 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v55);
          *(void *)__dst = v24;
          __dst[8] = v55;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v25 = *((void *)__src + 3);
          *((void *)v4 + 3) = v25;
          *((void *)v4 + 4) = *((void *)__src + 4);
          uint64_t v26 = *((void *)__src + 5);
          *((void *)v4 + 5) = v26;
          *((void *)v4 + 6) = *((void *)__src + 6);
          uint64_t v56 = *((void *)__src + 7);
          *((void *)v4 + 7) = v56;
          *((void *)v4 + 8) = *((void *)__src + 8);
          uint64_t v47 = *((void *)__src + 9);
          *((void *)v4 + 9) = v47;
          swift_bridgeObjectRetain(v25);
          swift_bridgeObjectRetain(v26);
          swift_bridgeObjectRetain(v56);
          swift_bridgeObjectRetain(v47);
          uint64_t v44 = 4;
          goto LABEL_14;
        case 5u:
          uint64_t v27 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v27 - 8) + 16))(__dst, __src, v27);
          uint64_t v28 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          uint64_t v29 = v28[12];
          *(void *)&__dst[v29] = *(void *)&__src[v29];
          uint64_t v30 = *(void *)&__src[v29 + 8];
          *(void *)&v4[v29 + 8] = v30;
          uint64_t v31 = v28[16];
          *(void *)&v4[v31] = *(void *)&__src[v31];
          uint64_t v57 = *(void *)&__src[v31 + 8];
          *(void *)&v4[v31 + 8] = v57;
          uint64_t v32 = v28[20];
          *(void *)&v4[v32] = *(void *)&__src[v32];
          uint64_t v50 = v8;
          uint64_t v33 = *(void *)&__src[v32 + 8];
          *(void *)&v4[v32 + 8] = v33;
          swift_bridgeObjectRetain(v30);
          swift_bridgeObjectRetain(v57);
          swift_bridgeObjectRetain(v33);
          uint64_t v44 = 5;
          goto LABEL_14;
        case 6u:
          uint64_t v34 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v34 - 8) + 16))(__dst, __src, v34);
          uint64_t v35 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
          uint64_t v36 = v35[12];
          *(void *)&__dst[v36] = *(void *)&__src[v36];
          uint64_t v37 = *(void *)&__src[v36 + 8];
          *(void *)&v4[v36 + 8] = v37;
          uint64_t v38 = v35[16];
          *(void *)&v4[v38] = *(void *)&__src[v38];
          uint64_t v58 = *(void *)&__src[v38 + 8];
          *(void *)&v4[v38 + 8] = v58;
          uint64_t v39 = v35[20];
          *(void *)&v4[v39] = *(void *)&__src[v39];
          uint64_t v48 = *(void *)&__src[v39 + 8];
          *(void *)&v4[v39 + 8] = v48;
          uint64_t v40 = v35[24];
          *(void *)&v4[v40] = *(void *)&__src[v40];
          uint64_t v50 = v8;
          uint64_t v41 = *(void *)&__src[v40 + 8];
          *(void *)&v4[v40 + 8] = v41;
          swift_bridgeObjectRetain(v37);
          swift_bridgeObjectRetain(v58);
          swift_bridgeObjectRetain(v48);
          swift_bridgeObjectRetain(v41);
          uint64_t v44 = 6;
LABEL_14:
          uint64_t v17 = v44;
          __dst = v4;
          uint64_t v16 = v50;
LABEL_15:
          swift_storeEnumTagMultiPayload(__dst, v16, v17);
          swift_storeEnumTagMultiPayload(v4, v7, 1);
          break;
        case 7u:
          JUMPOUT(0x262C1CLL);
      }
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
    }
    *(void *)&v4[a3[5]] = *(void *)&__src[a3[5]];
    *(void *)&v4[a3[6]] = *(void *)&__src[a3[6]];
    *(void *)&v4[a3[7]] = *(void *)&__src[a3[7]];
    *(void *)&v4[a3[8]] = *(void *)&__src[a3[8]];
    *(void *)&v4[a3[10]] = *(void *)&__src[a3[10]];
  }
  return v4;
}

uint64_t destroy for MLActionClassifier.ModelParameters(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(0);
  uint64_t result = swift_getEnumCaseMultiPayload(a1, v1);
  if (result == 1)
  {
    uint64_t v3 = type metadata accessor for MLActionClassifier.DataSource(0);
    uint64_t result = swift_getEnumCaseMultiPayload(a1, v3);
    switch((int)result)
    {
      case 0:
        uint64_t v5 = type metadata accessor for URL(0);
        char v6 = *(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8);
        v6(a1, v5);
        uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v6(a1 + v7[12], v5);
        swift_bridgeObjectRelease(*(void *)(a1 + v7[16] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v7[20] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v7[24] + 8));
        uint64_t v8 = v7[28];
        goto LABEL_10;
      case 1:
      case 2:
        uint64_t v4 = type metadata accessor for URL(0);
        return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
      case 3:
        outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + 24));
        swift_bridgeObjectRelease(*(void *)(a1 + 40));
        return swift_bridgeObjectRelease(*(void *)(a1 + 56));
      case 4:
        outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + 24));
        swift_bridgeObjectRelease(*(void *)(a1 + 40));
        swift_bridgeObjectRelease(*(void *)(a1 + 56));
        return swift_bridgeObjectRelease(*(void *)(a1 + 72));
      case 5:
        uint64_t v9 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(a1, v9);
        uint64_t v10 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        swift_bridgeObjectRelease(*(void *)(a1 + v10[12] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v10[16] + 8));
        uint64_t v8 = v10[20];
        goto LABEL_10;
      case 6:
        uint64_t v11 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v11 - 8) + 8))(a1, v11);
        uint64_t v12 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        swift_bridgeObjectRelease(*(void *)(a1 + v12[12] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v12[16] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v12[20] + 8));
        uint64_t v8 = v12[24];
LABEL_10:
        uint64_t result = swift_bridgeObjectRelease(*(void *)(a1 + v8 + 8));
        break;
      default:
        return result;
    }
  }
  return result;
}

char *initializeWithCopy for MLActionClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v5 = __dst;
  uint64_t v6 = type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(0);
  if (swift_getEnumCaseMultiPayload(__src, v6) == 1)
  {
    uint64_t v7 = type metadata accessor for MLActionClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(__src, v7))
    {
      case 0u:
        uint64_t v43 = type metadata accessor for URL(0);
        uint64_t v49 = *(void (**)(char *, char *, uint64_t))(*(void *)(v43 - 8) + 16);
        v49(__dst, __src, v43);
        uint64_t v47 = v7;
        uint64_t v8 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v49(&__dst[v8[12]], &__src[v8[12]], v43);
        uint64_t v9 = v8[16];
        *(void *)&__dst[v9] = *(void *)&__src[v9];
        uint64_t v10 = *(void *)&__src[v9 + 8];
        *(void *)&v5[v9 + 8] = v10;
        uint64_t v11 = v8[20];
        *(void *)&v5[v11] = *(void *)&__src[v11];
        uint64_t v50 = *(void *)&__src[v11 + 8];
        *(void *)&v5[v11 + 8] = v50;
        uint64_t v12 = v8[24];
        *(void *)&v5[v12] = *(void *)&__src[v12];
        uint64_t v44 = *(void *)&__src[v12 + 8];
        *(void *)&v5[v12 + 8] = v44;
        uint64_t v13 = v8[28];
        *(void *)&v5[v13] = *(void *)&__src[v13];
        uint64_t v14 = *(void *)&__src[v13 + 8];
        *(void *)&v5[v13 + 8] = v14;
        swift_bridgeObjectRetain(v10);
        swift_bridgeObjectRetain(v50);
        swift_bridgeObjectRetain(v44);
        swift_bridgeObjectRetain(v14);
        __dst = v5;
        uint64_t v15 = v47;
        uint64_t v16 = 0;
        goto LABEL_13;
      case 1u:
        uint64_t v17 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 16))(__dst, __src, v17);
        uint64_t v41 = 1;
        goto LABEL_7;
      case 2u:
        uint64_t v18 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 16))(__dst, __src, v18);
        uint64_t v41 = 2;
LABEL_7:
        uint64_t v16 = v41;
        uint64_t v15 = v7;
        goto LABEL_13;
      case 3u:
        uint64_t v48 = v7;
        uint64_t v19 = *(void *)__src;
        char v51 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v51);
        *(void *)__dst = v19;
        __dst[8] = v51;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v20 = *((void *)__src + 3);
        *((void *)v5 + 3) = v20;
        *((void *)v5 + 4) = *((void *)__src + 4);
        uint64_t v21 = *((void *)__src + 5);
        *((void *)v5 + 5) = v21;
        *((void *)v5 + 6) = *((void *)__src + 6);
        uint64_t v52 = *((void *)__src + 7);
        *((void *)v5 + 7) = v52;
        swift_bridgeObjectRetain(v20);
        swift_bridgeObjectRetain(v21);
        swift_bridgeObjectRetain(v52);
        uint64_t v42 = 3;
        goto LABEL_12;
      case 4u:
        uint64_t v48 = v7;
        uint64_t v22 = *(void *)__src;
        char v53 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v53);
        *(void *)__dst = v22;
        __dst[8] = v53;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v23 = *((void *)__src + 3);
        *((void *)v5 + 3) = v23;
        *((void *)v5 + 4) = *((void *)__src + 4);
        uint64_t v24 = *((void *)__src + 5);
        *((void *)v5 + 5) = v24;
        *((void *)v5 + 6) = *((void *)__src + 6);
        uint64_t v54 = *((void *)__src + 7);
        *((void *)v5 + 7) = v54;
        *((void *)v5 + 8) = *((void *)__src + 8);
        uint64_t v45 = *((void *)__src + 9);
        *((void *)v5 + 9) = v45;
        swift_bridgeObjectRetain(v23);
        swift_bridgeObjectRetain(v24);
        swift_bridgeObjectRetain(v54);
        swift_bridgeObjectRetain(v45);
        uint64_t v42 = 4;
        goto LABEL_12;
      case 5u:
        uint64_t v25 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v25 - 8) + 16))(__dst, __src, v25);
        uint64_t v26 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v27 = v26[12];
        *(void *)&__dst[v27] = *(void *)&__src[v27];
        uint64_t v28 = *(void *)&__src[v27 + 8];
        *(void *)&v5[v27 + 8] = v28;
        uint64_t v29 = v26[16];
        *(void *)&v5[v29] = *(void *)&__src[v29];
        uint64_t v55 = *(void *)&__src[v29 + 8];
        *(void *)&v5[v29 + 8] = v55;
        uint64_t v30 = v26[20];
        *(void *)&v5[v30] = *(void *)&__src[v30];
        uint64_t v48 = v7;
        uint64_t v31 = *(void *)&__src[v30 + 8];
        *(void *)&v5[v30 + 8] = v31;
        swift_bridgeObjectRetain(v28);
        swift_bridgeObjectRetain(v55);
        swift_bridgeObjectRetain(v31);
        uint64_t v42 = 5;
        goto LABEL_12;
      case 6u:
        uint64_t v32 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v32 - 8) + 16))(__dst, __src, v32);
        uint64_t v33 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        uint64_t v34 = v33[12];
        *(void *)&__dst[v34] = *(void *)&__src[v34];
        uint64_t v35 = *(void *)&__src[v34 + 8];
        *(void *)&v5[v34 + 8] = v35;
        uint64_t v36 = v33[16];
        *(void *)&v5[v36] = *(void *)&__src[v36];
        uint64_t v56 = *(void *)&__src[v36 + 8];
        *(void *)&v5[v36 + 8] = v56;
        uint64_t v37 = v33[20];
        *(void *)&v5[v37] = *(void *)&__src[v37];
        uint64_t v46 = *(void *)&__src[v37 + 8];
        *(void *)&v5[v37 + 8] = v46;
        uint64_t v38 = v33[24];
        *(void *)&v5[v38] = *(void *)&__src[v38];
        uint64_t v48 = v7;
        uint64_t v39 = *(void *)&__src[v38 + 8];
        *(void *)&v5[v38 + 8] = v39;
        swift_bridgeObjectRetain(v35);
        swift_bridgeObjectRetain(v56);
        swift_bridgeObjectRetain(v46);
        swift_bridgeObjectRetain(v39);
        uint64_t v42 = 6;
LABEL_12:
        uint64_t v16 = v42;
        __dst = v5;
        uint64_t v15 = v48;
LABEL_13:
        swift_storeEnumTagMultiPayload(__dst, v15, v16);
        swift_storeEnumTagMultiPayload(v5, v6, 1);
        break;
    }
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
  }
  *(void *)&v5[a3[5]] = *(void *)&__src[a3[5]];
  *(void *)&v5[a3[6]] = *(void *)&__src[a3[6]];
  *(void *)&v5[a3[7]] = *(void *)&__src[a3[7]];
  *(void *)&v5[a3[8]] = *(void *)&__src[a3[8]];
  *(void *)&v5[a3[10]] = *(void *)&__src[a3[10]];
  return v5;
}

char *assignWithCopy for MLActionClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActionClassifier.ModelParameters.ValidationData((uint64_t)__dst, type metadata accessor for MLActionClassifier.ModelParameters.ValidationData);
    uint64_t v5 = type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(0);
    if (swift_getEnumCaseMultiPayload(__src, v5) == 1)
    {
      uint64_t v6 = type metadata accessor for MLActionClassifier.DataSource(0);
      unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v6);
      switch(EnumCaseMultiPayload)
      {
        case 0u:
          uint64_t v36 = type metadata accessor for URL(0);
          uint64_t v42 = *(void (**)(char *, char *, uint64_t))(*(void *)(v36 - 8) + 16);
          v42(__dst, __src, v36);
          uint64_t v39 = v6;
          uint64_t v8 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
          v42(&__dst[v8[12]], &__src[v8[12]], v36);
          uint64_t v9 = v8[16];
          *(void *)&__dst[v9] = *(void *)&__src[v9];
          uint64_t v10 = *(void *)&__src[v9 + 8];
          *(void *)&__dst[v9 + 8] = v10;
          uint64_t v11 = v8[20];
          *(void *)&__dst[v11] = *(void *)&__src[v11];
          uint64_t v43 = *(void *)&__src[v11 + 8];
          *(void *)&__dst[v11 + 8] = v43;
          uint64_t v12 = v8[24];
          *(void *)&__dst[v12] = *(void *)&__src[v12];
          uint64_t v37 = *(void *)&__src[v12 + 8];
          *(void *)&__dst[v12 + 8] = v37;
          uint64_t v13 = v8[28];
          *(void *)&__dst[v13] = *(void *)&__src[v13];
          goto LABEL_11;
        case 1u:
        case 2u:
          uint64_t v7 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
          goto LABEL_14;
        case 3u:
          uint64_t v40 = v6;
          uint64_t v14 = *(void *)__src;
          char v44 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v44);
          *(void *)__dst = v14;
          __dst[8] = v44;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v15 = *((void *)__src + 3);
          *((void *)__dst + 3) = v15;
          *((void *)__dst + 4) = *((void *)__src + 4);
          uint64_t v16 = *((void *)__src + 5);
          *((void *)__dst + 5) = v16;
          *((void *)__dst + 6) = *((void *)__src + 6);
          uint64_t v45 = *((void *)__src + 7);
          *((void *)__dst + 7) = v45;
          swift_bridgeObjectRetain(v15);
          LOBYTE(v15) = v16;
          uint64_t v6 = v40;
          swift_bridgeObjectRetain(v15);
          char v17 = v45;
          goto LABEL_13;
        case 4u:
          uint64_t v41 = v6;
          uint64_t v18 = *(void *)__src;
          char v46 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v46);
          *(void *)__dst = v18;
          __dst[8] = v46;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v19 = *((void *)__src + 3);
          *((void *)__dst + 3) = v19;
          *((void *)__dst + 4) = *((void *)__src + 4);
          uint64_t v20 = *((void *)__src + 5);
          *((void *)__dst + 5) = v20;
          *((void *)__dst + 6) = *((void *)__src + 6);
          uint64_t v47 = *((void *)__src + 7);
          *((void *)__dst + 7) = v47;
          *((void *)__dst + 8) = *((void *)__src + 8);
          uint64_t v38 = *((void *)__src + 9);
          *((void *)__dst + 9) = v38;
          swift_bridgeObjectRetain(v19);
          LOBYTE(v19) = v20;
          uint64_t v6 = v41;
          swift_bridgeObjectRetain(v19);
          swift_bridgeObjectRetain(v47);
          char v17 = v38;
          goto LABEL_13;
        case 5u:
          uint64_t v21 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v21 - 8) + 16))(__dst, __src, v21);
          uint64_t v22 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          uint64_t v23 = v22[12];
          *(void *)&__dst[v23] = *(void *)&__src[v23];
          uint64_t v24 = *(void *)&__src[v23 + 8];
          *(void *)&__dst[v23 + 8] = v24;
          uint64_t v25 = v22[16];
          *(void *)&__dst[v25] = *(void *)&__src[v25];
          uint64_t v48 = *(void *)&__src[v25 + 8];
          *(void *)&__dst[v25 + 8] = v48;
          uint64_t v26 = v22[20];
          *(void *)&__dst[v26] = *(void *)&__src[v26];
          uint64_t v39 = v6;
          uint64_t v27 = *(void *)&__src[v26 + 8];
          *(void *)&__dst[v26 + 8] = v27;
          swift_bridgeObjectRetain(v24);
          char v28 = v48;
          goto LABEL_12;
        case 6u:
          uint64_t v29 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v29 - 8) + 16))(__dst, __src, v29);
          uint64_t v30 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
          uint64_t v31 = v30[12];
          *(void *)&__dst[v31] = *(void *)&__src[v31];
          uint64_t v10 = *(void *)&__src[v31 + 8];
          *(void *)&__dst[v31 + 8] = v10;
          uint64_t v32 = v30[16];
          *(void *)&__dst[v32] = *(void *)&__src[v32];
          uint64_t v43 = *(void *)&__src[v32 + 8];
          *(void *)&__dst[v32 + 8] = v43;
          uint64_t v33 = v30[20];
          *(void *)&__dst[v33] = *(void *)&__src[v33];
          uint64_t v37 = *(void *)&__src[v33 + 8];
          *(void *)&__dst[v33 + 8] = v37;
          uint64_t v13 = v30[24];
          *(void *)&__dst[v13] = *(void *)&__src[v13];
          uint64_t v39 = v6;
LABEL_11:
          uint64_t v27 = *(void *)&__src[v13 + 8];
          *(void *)&__dst[v13 + 8] = v27;
          swift_bridgeObjectRetain(v10);
          swift_bridgeObjectRetain(v43);
          char v28 = v37;
LABEL_12:
          swift_bridgeObjectRetain(v28);
          char v17 = v27;
          uint64_t v6 = v39;
LABEL_13:
          swift_bridgeObjectRetain(v17);
LABEL_14:
          swift_storeEnumTagMultiPayload(__dst, v6, EnumCaseMultiPayload);
          swift_storeEnumTagMultiPayload(__dst, v5, 1);
          break;
      }
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
    }
  }
  *(void *)&__dst[a3[5]] = *(void *)&__src[a3[5]];
  *(void *)&__dst[a3[6]] = *(void *)&__src[a3[6]];
  *(void *)&__dst[a3[7]] = *(void *)&__src[a3[7]];
  *(void *)&__dst[a3[8]] = *(void *)&__src[a3[8]];
  *(void *)&__dst[a3[10]] = *(void *)&__src[a3[10]];
  return __dst;
}

char *initializeWithTake for MLActionClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v5 = type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(0);
  if (swift_getEnumCaseMultiPayload(__src, v5) == 1)
  {
    uint64_t v6 = type metadata accessor for MLActionClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(__src, v6))
    {
      case 0u:
        uint64_t v19 = type metadata accessor for URL(0);
        uint64_t v20 = *(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 32);
        v20(__dst, __src, v19);
        uint64_t v18 = v6;
        uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v20(&__dst[v7[12]], &__src[v7[12]], v19);
        *(_OWORD *)&__dst[v7[16]] = *(_OWORD *)&__src[v7[16]];
        *(_OWORD *)&__dst[v7[20]] = *(_OWORD *)&__src[v7[20]];
        *(_OWORD *)&__dst[v7[24]] = *(_OWORD *)&__src[v7[24]];
        *(_OWORD *)&__dst[v7[28]] = *(_OWORD *)&__src[v7[28]];
        uint64_t v8 = v18;
        uint64_t v9 = 0;
        goto LABEL_11;
      case 1u:
        uint64_t v10 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
        uint64_t v17 = 1;
        goto LABEL_10;
      case 2u:
        uint64_t v11 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 32))(__dst, __src, v11);
        uint64_t v17 = 2;
        goto LABEL_10;
      case 5u:
        uint64_t v12 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
        uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        *(_OWORD *)&__dst[v13[12]] = *(_OWORD *)&__src[v13[12]];
        *(_OWORD *)&__dst[v13[16]] = *(_OWORD *)&__src[v13[16]];
        *(_OWORD *)&__dst[v13[20]] = *(_OWORD *)&__src[v13[20]];
        uint64_t v17 = 5;
        goto LABEL_10;
      case 6u:
        uint64_t v14 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 32))(__dst, __src, v14);
        uint64_t v15 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        *(_OWORD *)&__dst[v15[12]] = *(_OWORD *)&__src[v15[12]];
        *(_OWORD *)&__dst[v15[16]] = *(_OWORD *)&__src[v15[16]];
        *(_OWORD *)&__dst[v15[20]] = *(_OWORD *)&__src[v15[20]];
        *(_OWORD *)&__dst[v15[24]] = *(_OWORD *)&__src[v15[24]];
        uint64_t v17 = 6;
LABEL_10:
        uint64_t v9 = v17;
        uint64_t v8 = v6;
LABEL_11:
        swift_storeEnumTagMultiPayload(__dst, v8, v9);
        break;
      default:
        memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
        break;
    }
    swift_storeEnumTagMultiPayload(__dst, v5, 1);
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
  }
  *(void *)&__dst[a3[5]] = *(void *)&__src[a3[5]];
  *(void *)&__dst[a3[6]] = *(void *)&__src[a3[6]];
  *(void *)&__dst[a3[7]] = *(void *)&__src[a3[7]];
  *(void *)&__dst[a3[8]] = *(void *)&__src[a3[8]];
  *(void *)&__dst[a3[10]] = *(void *)&__src[a3[10]];
  return __dst;
}

char *assignWithTake for MLActionClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActionClassifier.ModelParameters.ValidationData((uint64_t)__dst, type metadata accessor for MLActionClassifier.ModelParameters.ValidationData);
    uint64_t v5 = type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(0);
    if (swift_getEnumCaseMultiPayload(__src, v5) == 1)
    {
      uint64_t v6 = type metadata accessor for MLActionClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v6))
      {
        case 0u:
          uint64_t v19 = type metadata accessor for URL(0);
          uint64_t v20 = *(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 32);
          v20(__dst, __src, v19);
          uint64_t v18 = v6;
          uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
          v20(&__dst[v7[12]], &__src[v7[12]], v19);
          *(_OWORD *)&__dst[v7[16]] = *(_OWORD *)&__src[v7[16]];
          *(_OWORD *)&__dst[v7[20]] = *(_OWORD *)&__src[v7[20]];
          *(_OWORD *)&__dst[v7[24]] = *(_OWORD *)&__src[v7[24]];
          *(_OWORD *)&__dst[v7[28]] = *(_OWORD *)&__src[v7[28]];
          uint64_t v8 = v18;
          uint64_t v9 = 0;
          goto LABEL_12;
        case 1u:
          uint64_t v10 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
          uint64_t v17 = 1;
          goto LABEL_11;
        case 2u:
          uint64_t v11 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 32))(__dst, __src, v11);
          uint64_t v17 = 2;
          goto LABEL_11;
        case 5u:
          uint64_t v12 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
          uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          *(_OWORD *)&__dst[v13[12]] = *(_OWORD *)&__src[v13[12]];
          *(_OWORD *)&__dst[v13[16]] = *(_OWORD *)&__src[v13[16]];
          *(_OWORD *)&__dst[v13[20]] = *(_OWORD *)&__src[v13[20]];
          uint64_t v17 = 5;
          goto LABEL_11;
        case 6u:
          uint64_t v14 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 32))(__dst, __src, v14);
          uint64_t v15 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
          *(_OWORD *)&__dst[v15[12]] = *(_OWORD *)&__src[v15[12]];
          *(_OWORD *)&__dst[v15[16]] = *(_OWORD *)&__src[v15[16]];
          *(_OWORD *)&__dst[v15[20]] = *(_OWORD *)&__src[v15[20]];
          *(_OWORD *)&__dst[v15[24]] = *(_OWORD *)&__src[v15[24]];
          uint64_t v17 = 6;
LABEL_11:
          uint64_t v9 = v17;
          uint64_t v8 = v6;
LABEL_12:
          swift_storeEnumTagMultiPayload(__dst, v8, v9);
          break;
        default:
          memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
          break;
      }
      swift_storeEnumTagMultiPayload(__dst, v5, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
    }
  }
  *(void *)&__dst[a3[5]] = *(void *)&__src[a3[5]];
  *(void *)&__dst[a3[6]] = *(void *)&__src[a3[6]];
  *(void *)&__dst[a3[7]] = *(void *)&__src[a3[7]];
  *(void *)&__dst[a3[8]] = *(void *)&__src[a3[8]];
  *(void *)&__dst[a3[10]] = *(void *)&__src[a3[10]];
  return __dst;
}

uint64_t getEnumTagSinglePayload for MLActionClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_263BC9);
}

uint64_t sub_263BC9(uint64_t a1, unsigned int a2)
{
  uint64_t v2 = type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(0);
  return __swift_getEnumTagSinglePayload(a1, a2, v2);
}

uint64_t storeEnumTagSinglePayload for MLActionClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_263C0D);
}

uint64_t sub_263C0D(uint64_t a1, unsigned int a2)
{
  uint64_t v2 = type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(0);
  return __swift_storeEnumTagSinglePayload(a1, a2, a2, v2);
}

uint64_t type metadata completion function for MLActionClassifier.ModelParameters(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLActionClassifier.ModelParameters.ValidationData(319);
  if (v2 <= 0x3F)
  {
    v3[0] = *(void *)(result - 8) + 64;
    v3[1] = (char *)&value witness table for Builtin.Int64 + 64;
    v3[2] = (char *)&value witness table for Builtin.Int64 + 64;
    v3[3] = (char *)&value witness table for Builtin.Int64 + 64;
    v3[4] = (char *)&value witness table for Builtin.Int64 + 64;
    v3[5] = (char *)&value witness table for () + 64;
    v3[6] = (char *)&value witness table for Builtin.Int64 + 64;
    swift_initStructMetadata(a1, 256, 7, v3, a1 + 16);
    return 0;
  }
  return result;
}

ValueMetadata *type metadata accessor for MLActionClassifier.ModelParameters.ModelAlgorithmType()
{
  return &type metadata for MLActionClassifier.ModelParameters.ModelAlgorithmType;
}

void *initializeBufferWithCopyOfBuffer for MLActionClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  uint64_t v3 = __dst;
  uint64_t v4 = *(void *)(a3 - 8);
  int v5 = *(_DWORD *)(v4 + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v20 = *(void *)__src;
    void *v3 = *(void *)__src;
    uint64_t v3 = (void *)(v20 + ((v5 + 16) & ~v5));
    swift_retain();
  }
  else if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
  {
    uint64_t v7 = type metadata accessor for MLActionClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(__src, v7))
    {
      case 0u:
        uint64_t v57 = v7;
        uint64_t v8 = type metadata accessor for URL(0);
        uint64_t v55 = *(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 16);
        v55(__dst, __src, v8);
        uint64_t v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v55(&__dst[v9[12]], &__src[v9[12]], v8);
        uint64_t v10 = v9[16];
        *(void *)&__dst[v10] = *(void *)&__src[v10];
        uint64_t v11 = *(void *)&__src[v10 + 8];
        *(void *)((char *)v3 + v10 + 8) = v11;
        uint64_t v12 = v9[20];
        *(void *)((char *)v3 + v12) = *(void *)&__src[v12];
        uint64_t v56 = *(void *)&__src[v12 + 8];
        *(void *)((char *)v3 + v12 + 8) = v56;
        uint64_t v13 = v9[24];
        *(void *)((char *)v3 + v13) = *(void *)&__src[v13];
        uint64_t v14 = *(void *)&__src[v13 + 8];
        *(void *)((char *)v3 + v13 + 8) = v14;
        uint64_t v15 = v9[28];
        *(void *)((char *)v3 + v15) = *(void *)&__src[v15];
        uint64_t v16 = *(void *)&__src[v15 + 8];
        *(void *)((char *)v3 + v15 + 8) = v16;
        swift_bridgeObjectRetain(v11);
        swift_bridgeObjectRetain(v56);
        swift_bridgeObjectRetain(v14);
        swift_bridgeObjectRetain(v16);
        uint64_t v17 = v3;
        uint64_t v18 = v57;
        uint64_t v19 = 0;
        break;
      case 1u:
        uint64_t v21 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v21 - 8) + 16))(__dst, __src, v21);
        uint64_t v53 = 1;
        goto LABEL_12;
      case 2u:
        uint64_t v22 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v22 - 8) + 16))(__dst, __src, v22);
        uint64_t v53 = 2;
        goto LABEL_12;
      case 3u:
        uint64_t v23 = *(void *)__src;
        uint64_t v58 = v7;
        char v24 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v24);
        *(void *)__dst = v23;
        __dst[8] = v24;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v25 = *((void *)__src + 3);
        v3[3] = v25;
        v3[4] = *((void *)__src + 4);
        uint64_t v26 = *((void *)__src + 5);
        v3[5] = v26;
        v3[6] = *((void *)__src + 6);
        uint64_t v27 = *((void *)__src + 7);
        v3[7] = v27;
        swift_bridgeObjectRetain(v25);
        swift_bridgeObjectRetain(v26);
        swift_bridgeObjectRetain(v27);
        uint64_t v54 = 3;
        goto LABEL_14;
      case 4u:
        uint64_t v28 = *(void *)__src;
        uint64_t v58 = v7;
        char v29 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v29);
        *(void *)__dst = v28;
        __dst[8] = v29;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v30 = *((void *)__src + 3);
        v3[3] = v30;
        v3[4] = *((void *)__src + 4);
        uint64_t v31 = *((void *)__src + 5);
        v3[5] = v31;
        v3[6] = *((void *)__src + 6);
        uint64_t v32 = *((void *)__src + 7);
        v3[7] = v32;
        void v3[8] = *((void *)__src + 8);
        uint64_t v33 = *((void *)__src + 9);
        v3[9] = v33;
        swift_bridgeObjectRetain(v30);
        swift_bridgeObjectRetain(v31);
        swift_bridgeObjectRetain(v32);
        swift_bridgeObjectRetain(v33);
        uint64_t v54 = 4;
        goto LABEL_14;
      case 5u:
        uint64_t v34 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v34 - 8) + 16))(__dst, __src, v34);
        uint64_t v35 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v36 = v35[12];
        *(void *)&__dst[v36] = *(void *)&__src[v36];
        uint64_t v37 = *(void *)&__src[v36 + 8];
        *(void *)((char *)v3 + v36 + 8) = v37;
        uint64_t v38 = v35[16];
        *(void *)((char *)v3 + v38) = *(void *)&__src[v38];
        uint64_t v39 = *(void *)&__src[v38 + 8];
        *(void *)((char *)v3 + v38 + 8) = v39;
        uint64_t v40 = v35[20];
        *(void *)((char *)v3 + v40) = *(void *)&__src[v40];
        uint64_t v41 = *(void *)&__src[v40 + 8];
        *(void *)((char *)v3 + v40 + 8) = v41;
        swift_bridgeObjectRetain(v37);
        swift_bridgeObjectRetain(v39);
        swift_bridgeObjectRetain(v41);
        uint64_t v53 = 5;
LABEL_12:
        uint64_t v19 = v53;
        uint64_t v17 = v3;
        uint64_t v18 = v7;
        break;
      case 6u:
        uint64_t v42 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v42 - 8) + 16))(__dst, __src, v42);
        uint64_t v43 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        uint64_t v44 = v43[12];
        *(void *)&__dst[v44] = *(void *)&__src[v44];
        uint64_t v45 = *(void *)&__src[v44 + 8];
        *(void *)((char *)v3 + v44 + 8) = v45;
        uint64_t v46 = v43[16];
        *(void *)((char *)v3 + v46) = *(void *)&__src[v46];
        uint64_t v47 = *(void *)&__src[v46 + 8];
        *(void *)((char *)v3 + v46 + 8) = v47;
        uint64_t v48 = v43[20];
        *(void *)((char *)v3 + v48) = *(void *)&__src[v48];
        uint64_t v58 = v7;
        uint64_t v49 = *(void *)&__src[v48 + 8];
        *(void *)((char *)v3 + v48 + 8) = v49;
        uint64_t v50 = v43[24];
        *(void *)((char *)v3 + v50) = *(void *)&__src[v50];
        uint64_t v51 = *(void *)&__src[v50 + 8];
        *(void *)((char *)v3 + v50 + 8) = v51;
        swift_bridgeObjectRetain(v45);
        swift_bridgeObjectRetain(v47);
        swift_bridgeObjectRetain(v49);
        swift_bridgeObjectRetain(v51);
        uint64_t v54 = 6;
LABEL_14:
        uint64_t v19 = v54;
        uint64_t v17 = v3;
        uint64_t v18 = v58;
        break;
    }
    swift_storeEnumTagMultiPayload(v17, v18, v19);
    swift_storeEnumTagMultiPayload(v3, a3, 1);
  }
  else
  {
    memcpy(__dst, __src, *(void *)(v4 + 64));
  }
  return v3;
}

uint64_t destroy for MLActionClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t result = swift_getEnumCaseMultiPayload(a1, a2);
  if (result == 1)
  {
    uint64_t v3 = type metadata accessor for MLActionClassifier.DataSource(0);
    uint64_t result = swift_getEnumCaseMultiPayload(a1, v3);
    switch((int)result)
    {
      case 0:
        uint64_t v5 = type metadata accessor for URL(0);
        uint64_t v6 = *(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8);
        v6(a1, v5);
        uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v6(a1 + v7[12], v5);
        swift_bridgeObjectRelease(*(void *)(a1 + v7[16] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v7[20] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v7[24] + 8));
        uint64_t v8 = v7[28];
        goto LABEL_10;
      case 1:
      case 2:
        uint64_t v4 = type metadata accessor for URL(0);
        return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
      case 3:
        outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + 24));
        swift_bridgeObjectRelease(*(void *)(a1 + 40));
        return swift_bridgeObjectRelease(*(void *)(a1 + 56));
      case 4:
        outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + 24));
        swift_bridgeObjectRelease(*(void *)(a1 + 40));
        swift_bridgeObjectRelease(*(void *)(a1 + 56));
        return swift_bridgeObjectRelease(*(void *)(a1 + 72));
      case 5:
        uint64_t v9 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(a1, v9);
        uint64_t v10 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        swift_bridgeObjectRelease(*(void *)(a1 + v10[12] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v10[16] + 8));
        uint64_t v8 = v10[20];
        goto LABEL_10;
      case 6:
        uint64_t v11 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v11 - 8) + 8))(a1, v11);
        uint64_t v12 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        swift_bridgeObjectRelease(*(void *)(a1 + v12[12] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v12[16] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v12[20] + 8));
        uint64_t v8 = v12[24];
LABEL_10:
        uint64_t result = swift_bridgeObjectRelease(*(void *)(a1 + v8 + 8));
        break;
      default:
        return result;
    }
  }
  return result;
}

char *initializeWithCopy for MLActionClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
  {
    uint64_t v5 = type metadata accessor for MLActionClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(__src, v5))
    {
      case 0u:
        uint64_t v54 = v5;
        uint64_t v6 = type metadata accessor for URL(0);
        uint64_t v52 = *(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16);
        v52(__dst, __src, v6);
        uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v52(&__dst[v7[12]], &__src[v7[12]], v6);
        uint64_t v8 = v7[16];
        *(void *)&__dst[v8] = *(void *)&__src[v8];
        uint64_t v9 = *(void *)&__src[v8 + 8];
        *(void *)&__dst[v8 + 8] = v9;
        uint64_t v10 = v7[20];
        *(void *)&__dst[v10] = *(void *)&__src[v10];
        uint64_t v53 = *(void *)&__src[v10 + 8];
        *(void *)&__dst[v10 + 8] = v53;
        uint64_t v11 = v7[24];
        *(void *)&__dst[v11] = *(void *)&__src[v11];
        uint64_t v12 = *(void *)&__src[v11 + 8];
        *(void *)&__dst[v11 + 8] = v12;
        uint64_t v13 = v7[28];
        *(void *)&__dst[v13] = *(void *)&__src[v13];
        uint64_t v14 = *(void *)&__src[v13 + 8];
        *(void *)&__dst[v13 + 8] = v14;
        swift_bridgeObjectRetain(v9);
        swift_bridgeObjectRetain(v53);
        swift_bridgeObjectRetain(v12);
        swift_bridgeObjectRetain(v14);
        uint64_t v15 = __dst;
        uint64_t v16 = v54;
        uint64_t v17 = 0;
        break;
      case 1u:
        uint64_t v18 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 16))(__dst, __src, v18);
        uint64_t v50 = 1;
        goto LABEL_10;
      case 2u:
        uint64_t v19 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16))(__dst, __src, v19);
        uint64_t v50 = 2;
        goto LABEL_10;
      case 3u:
        uint64_t v20 = *(void *)__src;
        uint64_t v55 = v5;
        char v21 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v21);
        *(void *)__dst = v20;
        __dst[8] = v21;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v22 = *((void *)__src + 3);
        *((void *)__dst + 3) = v22;
        *((void *)__dst + 4) = *((void *)__src + 4);
        uint64_t v23 = *((void *)__src + 5);
        *((void *)__dst + 5) = v23;
        *((void *)__dst + 6) = *((void *)__src + 6);
        uint64_t v24 = *((void *)__src + 7);
        *((void *)__dst + 7) = v24;
        swift_bridgeObjectRetain(v22);
        swift_bridgeObjectRetain(v23);
        swift_bridgeObjectRetain(v24);
        uint64_t v51 = 3;
        goto LABEL_12;
      case 4u:
        uint64_t v25 = *(void *)__src;
        uint64_t v55 = v5;
        char v26 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v26);
        *(void *)__dst = v25;
        __dst[8] = v26;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v27 = *((void *)__src + 3);
        *((void *)__dst + 3) = v27;
        *((void *)__dst + 4) = *((void *)__src + 4);
        uint64_t v28 = *((void *)__src + 5);
        *((void *)__dst + 5) = v28;
        *((void *)__dst + 6) = *((void *)__src + 6);
        uint64_t v29 = *((void *)__src + 7);
        *((void *)__dst + 7) = v29;
        *((void *)__dst + 8) = *((void *)__src + 8);
        uint64_t v30 = *((void *)__src + 9);
        *((void *)__dst + 9) = v30;
        swift_bridgeObjectRetain(v27);
        swift_bridgeObjectRetain(v28);
        swift_bridgeObjectRetain(v29);
        swift_bridgeObjectRetain(v30);
        uint64_t v51 = 4;
        goto LABEL_12;
      case 5u:
        uint64_t v31 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v31 - 8) + 16))(__dst, __src, v31);
        uint64_t v32 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v33 = v32[12];
        *(void *)&__dst[v33] = *(void *)&__src[v33];
        uint64_t v34 = *(void *)&__src[v33 + 8];
        *(void *)&__dst[v33 + 8] = v34;
        uint64_t v35 = v32[16];
        *(void *)&__dst[v35] = *(void *)&__src[v35];
        uint64_t v36 = *(void *)&__src[v35 + 8];
        *(void *)&__dst[v35 + 8] = v36;
        uint64_t v37 = v32[20];
        *(void *)&__dst[v37] = *(void *)&__src[v37];
        uint64_t v38 = *(void *)&__src[v37 + 8];
        *(void *)&__dst[v37 + 8] = v38;
        swift_bridgeObjectRetain(v34);
        swift_bridgeObjectRetain(v36);
        swift_bridgeObjectRetain(v38);
        uint64_t v50 = 5;
LABEL_10:
        uint64_t v17 = v50;
        uint64_t v15 = __dst;
        uint64_t v16 = v5;
        break;
      case 6u:
        uint64_t v39 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v39 - 8) + 16))(__dst, __src, v39);
        uint64_t v40 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        uint64_t v41 = v40[12];
        *(void *)&__dst[v41] = *(void *)&__src[v41];
        uint64_t v42 = *(void *)&__src[v41 + 8];
        *(void *)&__dst[v41 + 8] = v42;
        uint64_t v43 = v40[16];
        *(void *)&__dst[v43] = *(void *)&__src[v43];
        uint64_t v44 = *(void *)&__src[v43 + 8];
        *(void *)&__dst[v43 + 8] = v44;
        uint64_t v45 = v40[20];
        *(void *)&__dst[v45] = *(void *)&__src[v45];
        uint64_t v55 = v5;
        uint64_t v46 = *(void *)&__src[v45 + 8];
        *(void *)&__dst[v45 + 8] = v46;
        uint64_t v47 = v40[24];
        *(void *)&__dst[v47] = *(void *)&__src[v47];
        uint64_t v48 = *(void *)&__src[v47 + 8];
        *(void *)&__dst[v47 + 8] = v48;
        swift_bridgeObjectRetain(v42);
        swift_bridgeObjectRetain(v44);
        swift_bridgeObjectRetain(v46);
        swift_bridgeObjectRetain(v48);
        uint64_t v51 = 6;
LABEL_12:
        uint64_t v17 = v51;
        uint64_t v15 = __dst;
        uint64_t v16 = v55;
        break;
    }
    swift_storeEnumTagMultiPayload(v15, v16, v17);
    swift_storeEnumTagMultiPayload(__dst, a3, 1);
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
  }
  return __dst;
}

char *assignWithCopy for MLActionClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActionClassifier.ModelParameters.ValidationData((uint64_t)__dst, type metadata accessor for MLActionClassifier.ModelParameters.ValidationData);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
    {
      uint64_t v5 = type metadata accessor for MLActionClassifier.DataSource(0);
      unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v5);
      switch(EnumCaseMultiPayload)
      {
        case 0u:
          uint64_t v43 = v5;
          uint64_t v41 = type metadata accessor for URL(0);
          uint64_t v8 = *(void (**)(char *, char *, uint64_t))(*(void *)(v41 - 8) + 16);
          v8(__dst, __src, v41);
          unsigned int v45 = EnumCaseMultiPayload;
          uint64_t v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
          v8(&__dst[v9[12]], &__src[v9[12]], v41);
          uint64_t v10 = v9[16];
          *(void *)&__dst[v10] = *(void *)&__src[v10];
          uint64_t v16 = *(void *)&__src[v10 + 8];
          *(void *)&__dst[v10 + 8] = v16;
          uint64_t v11 = v9[20];
          *(void *)&__dst[v11] = *(void *)&__src[v11];
          uint64_t v42 = *(void *)&__src[v11 + 8];
          *(void *)&__dst[v11 + 8] = v42;
          uint64_t v12 = v9[24];
          *(void *)&__dst[v12] = *(void *)&__src[v12];
          uint64_t v13 = *(void *)&__src[v12 + 8];
          *(void *)&__dst[v12 + 8] = v13;
          uint64_t v14 = v9[28];
          *(void *)&__dst[v14] = *(void *)&__src[v14];
          uint64_t v15 = *(void *)&__src[v14 + 8];
          *(void *)&__dst[v14 + 8] = v15;
          swift_bridgeObjectRetain(v16);
          LOBYTE(v16) = v42;
          goto LABEL_10;
        case 1u:
        case 2u:
          uint64_t v7 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
          goto LABEL_14;
        case 3u:
          uint64_t v43 = v5;
          uint64_t v17 = *(void *)__src;
          unsigned int v45 = EnumCaseMultiPayload;
          char v18 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v18);
          *(void *)__dst = v17;
          __dst[8] = v18;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v16 = *((void *)__src + 3);
          *((void *)__dst + 3) = v16;
          *((void *)__dst + 4) = *((void *)__src + 4);
          uint64_t v13 = *((void *)__src + 5);
          *((void *)__dst + 5) = v13;
          *((void *)__dst + 6) = *((void *)__src + 6);
          uint64_t v15 = *((void *)__src + 7);
          *((void *)__dst + 7) = v15;
          goto LABEL_10;
        case 4u:
          uint64_t v44 = v5;
          uint64_t v19 = *(void *)__src;
          unsigned int v46 = EnumCaseMultiPayload;
          char v20 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v20);
          *(void *)__dst = v19;
          __dst[8] = v20;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v21 = *((void *)__src + 3);
          *((void *)__dst + 3) = v21;
          *((void *)__dst + 4) = *((void *)__src + 4);
          uint64_t v22 = *((void *)__src + 5);
          *((void *)__dst + 5) = v22;
          *((void *)__dst + 6) = *((void *)__src + 6);
          uint64_t v23 = *((void *)__src + 7);
          *((void *)__dst + 7) = v23;
          *((void *)__dst + 8) = *((void *)__src + 8);
          uint64_t v24 = *((void *)__src + 9);
          *((void *)__dst + 9) = v24;
          goto LABEL_12;
        case 5u:
          uint64_t v25 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v25 - 8) + 16))(__dst, __src, v25);
          char v26 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          uint64_t v27 = v26[12];
          *(void *)&__dst[v27] = *(void *)&__src[v27];
          uint64_t v16 = *(void *)&__src[v27 + 8];
          *(void *)&__dst[v27 + 8] = v16;
          uint64_t v28 = v26[16];
          *(void *)&__dst[v28] = *(void *)&__src[v28];
          uint64_t v43 = v5;
          uint64_t v13 = *(void *)&__src[v28 + 8];
          *(void *)&__dst[v28 + 8] = v13;
          uint64_t v29 = v26[20];
          *(void *)&__dst[v29] = *(void *)&__src[v29];
          unsigned int v45 = EnumCaseMultiPayload;
          uint64_t v15 = *(void *)&__src[v29 + 8];
          *(void *)&__dst[v29 + 8] = v15;
LABEL_10:
          swift_bridgeObjectRetain(v16);
          char v30 = v13;
          uint64_t v5 = v43;
          swift_bridgeObjectRetain(v30);
          char v31 = v15;
          unsigned int EnumCaseMultiPayload = v45;
          break;
        case 6u:
          uint64_t v32 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v32 - 8) + 16))(__dst, __src, v32);
          uint64_t v33 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
          uint64_t v34 = v33[12];
          *(void *)&__dst[v34] = *(void *)&__src[v34];
          uint64_t v21 = *(void *)&__src[v34 + 8];
          *(void *)&__dst[v34 + 8] = v21;
          uint64_t v35 = v33[16];
          *(void *)&__dst[v35] = *(void *)&__src[v35];
          uint64_t v44 = v5;
          uint64_t v22 = *(void *)&__src[v35 + 8];
          *(void *)&__dst[v35 + 8] = v22;
          uint64_t v36 = v33[20];
          *(void *)&__dst[v36] = *(void *)&__src[v36];
          unsigned int v46 = EnumCaseMultiPayload;
          uint64_t v23 = *(void *)&__src[v36 + 8];
          *(void *)&__dst[v36 + 8] = v23;
          uint64_t v37 = v33[24];
          *(void *)&__dst[v37] = *(void *)&__src[v37];
          uint64_t v24 = *(void *)&__src[v37 + 8];
          *(void *)&__dst[v37 + 8] = v24;
LABEL_12:
          swift_bridgeObjectRetain(v21);
          char v38 = v22;
          uint64_t v5 = v44;
          swift_bridgeObjectRetain(v38);
          char v39 = v23;
          unsigned int EnumCaseMultiPayload = v46;
          swift_bridgeObjectRetain(v39);
          char v31 = v24;
          break;
      }
      swift_bridgeObjectRetain(v31);
LABEL_14:
      swift_storeEnumTagMultiPayload(__dst, v5, EnumCaseMultiPayload);
      swift_storeEnumTagMultiPayload(__dst, a3, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

char *initializeWithTake for MLActionClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
  {
    uint64_t v4 = type metadata accessor for MLActionClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(__src, v4))
    {
      case 0u:
        uint64_t v16 = type metadata accessor for URL(0);
        uint64_t v17 = *(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 32);
        v17(__dst, __src, v16);
        uint64_t v5 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v17(&__dst[v5[12]], &__src[v5[12]], v16);
        *(_OWORD *)&__dst[v5[16]] = *(_OWORD *)&__src[v5[16]];
        *(_OWORD *)&__dst[v5[20]] = *(_OWORD *)&__src[v5[20]];
        *(_OWORD *)&__dst[v5[24]] = *(_OWORD *)&__src[v5[24]];
        *(_OWORD *)&__dst[v5[28]] = *(_OWORD *)&__src[v5[28]];
        uint64_t v6 = v4;
        uint64_t v7 = 0;
        goto LABEL_11;
      case 1u:
        uint64_t v8 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
        uint64_t v15 = 1;
        goto LABEL_10;
      case 2u:
        uint64_t v9 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
        uint64_t v15 = 2;
        goto LABEL_10;
      case 5u:
        uint64_t v10 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
        uint64_t v11 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        *(_OWORD *)&__dst[v11[12]] = *(_OWORD *)&__src[v11[12]];
        *(_OWORD *)&__dst[v11[16]] = *(_OWORD *)&__src[v11[16]];
        *(_OWORD *)&__dst[v11[20]] = *(_OWORD *)&__src[v11[20]];
        uint64_t v15 = 5;
        goto LABEL_10;
      case 6u:
        uint64_t v12 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
        uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        *(_OWORD *)&__dst[v13[12]] = *(_OWORD *)&__src[v13[12]];
        *(_OWORD *)&__dst[v13[16]] = *(_OWORD *)&__src[v13[16]];
        *(_OWORD *)&__dst[v13[20]] = *(_OWORD *)&__src[v13[20]];
        *(_OWORD *)&__dst[v13[24]] = *(_OWORD *)&__src[v13[24]];
        uint64_t v15 = 6;
LABEL_10:
        uint64_t v7 = v15;
        uint64_t v6 = v4;
LABEL_11:
        swift_storeEnumTagMultiPayload(__dst, v6, v7);
        break;
      default:
        memcpy(__dst, __src, *(void *)(*(void *)(v4 - 8) + 64));
        break;
    }
    swift_storeEnumTagMultiPayload(__dst, a3, 1);
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
  }
  return __dst;
}

char *assignWithTake for MLActionClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActionClassifier.ModelParameters.ValidationData((uint64_t)__dst, type metadata accessor for MLActionClassifier.ModelParameters.ValidationData);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
    {
      uint64_t v4 = type metadata accessor for MLActionClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v4))
      {
        case 0u:
          uint64_t v16 = type metadata accessor for URL(0);
          uint64_t v17 = *(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 32);
          v17(__dst, __src, v16);
          uint64_t v5 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
          v17(&__dst[v5[12]], &__src[v5[12]], v16);
          *(_OWORD *)&__dst[v5[16]] = *(_OWORD *)&__src[v5[16]];
          *(_OWORD *)&__dst[v5[20]] = *(_OWORD *)&__src[v5[20]];
          *(_OWORD *)&__dst[v5[24]] = *(_OWORD *)&__src[v5[24]];
          *(_OWORD *)&__dst[v5[28]] = *(_OWORD *)&__src[v5[28]];
          uint64_t v6 = v4;
          uint64_t v7 = 0;
          goto LABEL_12;
        case 1u:
          uint64_t v8 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
          uint64_t v15 = 1;
          goto LABEL_11;
        case 2u:
          uint64_t v9 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
          uint64_t v15 = 2;
          goto LABEL_11;
        case 5u:
          uint64_t v10 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
          uint64_t v11 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          *(_OWORD *)&__dst[v11[12]] = *(_OWORD *)&__src[v11[12]];
          *(_OWORD *)&__dst[v11[16]] = *(_OWORD *)&__src[v11[16]];
          *(_OWORD *)&__dst[v11[20]] = *(_OWORD *)&__src[v11[20]];
          uint64_t v15 = 5;
          goto LABEL_11;
        case 6u:
          uint64_t v12 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
          uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
          *(_OWORD *)&__dst[v13[12]] = *(_OWORD *)&__src[v13[12]];
          *(_OWORD *)&__dst[v13[16]] = *(_OWORD *)&__src[v13[16]];
          *(_OWORD *)&__dst[v13[20]] = *(_OWORD *)&__src[v13[20]];
          *(_OWORD *)&__dst[v13[24]] = *(_OWORD *)&__src[v13[24]];
          uint64_t v15 = 6;
LABEL_11:
          uint64_t v7 = v15;
          uint64_t v6 = v4;
LABEL_12:
          swift_storeEnumTagMultiPayload(__dst, v6, v7);
          break;
        default:
          memcpy(__dst, __src, *(void *)(*(void *)(v4 - 8) + 64));
          break;
      }
      swift_storeEnumTagMultiPayload(__dst, a3, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLActionClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  v5[0] = &unk_350548;
  uint64_t result = type metadata accessor for MLActionClassifier.DataSource(319);
  if (v4 <= 0x3F)
  {
    v5[1] = *(void *)(result - 8) + 64;
    swift_initEnumMetadataMultiPayload(a1, 256, 2, v5, v2, v3);
    return 0;
  }
  return result;
}

uint64_t outlined destroy of MLActionClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t (*a2)(void))
{
  uint64_t v2 = a2(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySo8NSNumberCG_Sis5NeverOTg5093_s14NeuralNetworks6TensorV8CreateMLE_6deviceACSo12MLMultiArrayC_AA13ComputeDeviceVSgtcfcSiSo8D55Ccfu1_33_5bdac5b40c7411f20a64c1277f8fd44fALSiTf3nnnpk_nTf1cn_n(uint64_t a1)
{
  if ((a1 & 0x4000000000000001) != 0)
  {
    uint64_t v10 = a1 & 0xFFFFFFFFFFFFF8;
    if (a1) {
      uint64_t v10 = a1;
    }
    swift_bridgeObjectRetain(a1);
    uint64_t v1 = _CocoaArrayWrapper.endIndex.getter(v10);
    swift_bridgeObjectRelease(a1);
  }
  else
  {
    uint64_t v1 = *(void *)((char *)&dword_10 + (a1 & 0xFFFFFFFFFFFFF8));
  }
  if (v1)
  {
    int64_t v2 = 0;
    if (v1 > 0) {
      int64_t v2 = v1;
    }
    uint64_t v12 = v1;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    uint64_t v3 = v1;
    if (v1 < 0) {
      BUG();
    }
    uint64_t v4 = 0;
    do
    {
      if (v3 == v4) {
        BUG();
      }
      if ((a1 & 0xC000000000000003) != 0) {
        id v5 = (id)specialized _ArrayBuffer._getElementSlowPath(_:)(v4, a1);
      }
      else {
        id v5 = *(id *)(a1 + 8 * v4 + 32);
      }
      uint64_t v6 = v5;
      id v11 = [v5 integerValue];

      unint64_t v7 = _swiftEmptyArrayStorage[2];
      unint64_t v8 = v7 + 1;
      if (_swiftEmptyArrayStorage[3] >> 1 <= v7)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v7 + 1, 1);
        unint64_t v8 = v7 + 1;
      }
      ++v4;
      _swiftEmptyArrayStorage[2] = v8;
      _swiftEmptyArrayStorage[v7 + 4] = v11;
      uint64_t v3 = v12;
    }
    while (v12 != v4);
  }
  return _swiftEmptyArrayStorage;
}

void Tensor.init(_:device:)(id a1, id a2, double a3, double a4)
{
  uint64_t v5 = v4;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?)
                             - 8)
                 + 64);
  unint64_t v7 = alloca(v6);
  unint64_t v8 = alloca(v6);
  int64_t v9 = *(void *)(*(void *)(type metadata accessor for ScalarType(0) - 8) + 64);
  uint64_t v10 = alloca(v9);
  id v11 = alloca(v9);
  uint64_t v34 = &v30;
  int64_t v12 = *(void *)(*(void *)(type metadata accessor for TensorShape(0) - 8) + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v35 = &v30;
  uint64_t v15 = (char *)[a1 dataType];
  uint64_t v16 = v15;
  id v31 = a2;
  uint64_t v32 = v5;
  uint64_t v33 = &v30;
  if (v15 == (unsigned char *)&loc_1001D + 3)
  {
LABEL_5:
    uint64_t v29 = 4;
    goto LABEL_6;
  }
  if (v15 != (unsigned char *)&loc_1003E + 2)
  {
    if (v15 != (unsigned char *)&loc_2001D + 3)
    {
      if (v15 == (char *)&loc_10010) {
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000041, "i-array data type" + 0x8000000000000000, "CreateML/_CoreML+NeuralNetworks.swift", 37, 2, 63, 0);
      }
      else {
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000021, "+NeuralNetworks.swift" + 0x8000000000000000, "CreateML/_CoreML+NeuralNetworks.swift", 37, 2, 72, 0);
      }
      BUG();
    }
    goto LABEL_5;
  }
  uint64_t v29 = 8;
LABEL_6:
  uint64_t v39 = v29;
  id v36 = a1;
  id v17 = [a1 shape];
  id v18 = v17;
  uint64_t v19 = type metadata accessor for NSNumber();
  uint64_t v20 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v18, v19);

  MLE_6deviceACSo12MLMultiArrayC_AA13ComputeDeviceVSgtcfcSiSo8D55Ccfu1_33_5bdac5b40c7411f20a64c1277f8fd44fALSiTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySo8NSNumberCG_Sis5NeverOTg5093_s14NeuralNetworks6TensorV8CreateMLE_6deviceACSo12MLMultiArrayC_AA13ComputeDeviceVSgtcfcSiSo8D55Ccfu1_33_5bdac5b40c7411f20a64c1277f8fd44fALSiTf3nnnpk_nTf1cn_n(v20);
  uint64_t v37 = 0;
  swift_bridgeObjectRelease(v20);
  uint64_t v22 = v35;
  TensorShape.init(_:)(MLE_6deviceACSo12MLMultiArrayC_AA13ComputeDeviceVSgtcfcSiSo8D55Ccfu1_33_5bdac5b40c7411f20a64c1277f8fd44fALSiTf3nnnpk_nTf1cn_n, a3, a4);
  uint64_t v23 = v34;
  MLMultiArrayDataType.dataType.getter(v16);
  uint64_t v24 = (uint64_t)v31;
  uint64_t v25 = (uint64_t)v33;
  outlined init with copy of ComputeDevice?((uint64_t)v31, (uint64_t)v33);
  char v38 = &v30;
  char v26 = alloca(32);
  uint64_t v27 = alloca(32);
  id v28 = v36;
  id v31 = v36;
  uint64_t v32 = v39;
  Tensor.init(unsafeUninitializedShape:scalarType:computeDevice:initializingWith:)(v22, v23, v25, partial apply for closure #1 in Tensor.init(_:device:));
  outlined destroy of ComputeDevice?(v24);
}

uint64_t type metadata accessor for NSNumber()
{
  uint64_t result = lazy cache variable for type metadata for NSNumber;
  if (!lazy cache variable for type metadata for NSNumber)
  {
    uint64_t v1 = objc_opt_self(NSNumber);
    uint64_t result = swift_getObjCClassMetadata(v1);
    lazy cache variable for type metadata for NSNumber = result;
  }
  return result;
}

uint64_t MLMultiArrayDataType.dataType.getter(char *a1)
{
  uint64_t v2 = v1;
  if (a1 == (char *)&loc_10010)
  {
    uint64_t v3 = (unsigned int *)&enum case for ScalarType.float16(_:);
  }
  else if (a1 == (unsigned char *)&loc_1001D + 3)
  {
    uint64_t v3 = (unsigned int *)&enum case for ScalarType.float32(_:);
  }
  else if (a1 == (unsigned char *)&loc_1003E + 2)
  {
    uint64_t v3 = (unsigned int *)&enum case for ScalarType.float64(_:);
  }
  else
  {
    if (a1 != (unsigned char *)&loc_2001D + 3)
    {
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000021, "+NeuralNetworks.swift" + 0x8000000000000000, "CreateML/_CoreML+NeuralNetworks.swift", 37, 2, 20, 0);
      BUG();
    }
    uint64_t v3 = (unsigned int *)&enum case for ScalarType.int32(_:);
  }
  unsigned int v4 = *v3;
  uint64_t v5 = type metadata accessor for ScalarType(0);
  return (*(uint64_t (**)(uint64_t, void, uint64_t))(*(void *)(v5 - 8) + 104))(v2, v4, v5);
}

uint64_t outlined init with copy of ComputeDevice?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t closure #1 in Tensor.init(_:device:)(uint64_t a1, uint64_t a2, void *a3, unint64_t a4)
{
  id v5 = a3;
  int64_t v6 = (char *)[v5 dataPointer];
  unint64_t v7 = (unint64_t)[v5 count];
  if (!is_mul_ok(a4, v7)) {
    BUG();
  }
  return UnsafeMutableRawBufferPointer.copyMemory(from:)(v6, &v6[a4 * v7], a1, a2);
}

uint64_t partial apply for closure #1 in Tensor.init(_:device:)(uint64_t a1, uint64_t a2)
{
  return closure #1 in Tensor.init(_:device:)(a1, a2, *(void **)(v2 + 16), *(void *)(v2 + 24));
}

uint64_t outlined destroy of ComputeDevice?(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t MLDataTable.subscript.getter(Swift::String a1)
{
  uint64_t v3 = v1;
  if (v2[8])
  {
    swift_willThrow();
    _StringGuts.grow(_:)(34);
    swift_bridgeObjectRelease(0xE000000000000000);
    *(void *)&long long v12 = 0xD00000000000001FLL;
    *((void *)&v12 + 1) = "ml.activityclassifier" + 0x8000000000000000;
    String.append(_:)(a1);
    v5._char object = (void *)0xE100000000000000;
    v5._uint64_t countAndFlagsBits = 34;
    String.append(_:)(v5);
    uint64_t v6 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t result = swift_allocError(&type metadata for MLCreateError, v6, 0, 0);
    *(_OWORD *)uint64_t v8 = v12;
    *(_OWORD *)(v8 + 16) = 0;
    *(_OWORD *)(v8 + 32) = 0;
    *(unsigned char *)(v8 + 48) = 1;
    char v9 = 1;
  }
  else
  {
    uint64_t v4 = *(void *)(*(void *)v2 + 16);
    swift_retain(v4);
    uint64_t v10 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.column(name:), v4, a1._countAndFlagsBits, (uint64_t)a1._object, (uint64_t (*)(void))type metadata accessor for CMLColumn, (uint64_t (*)(uint64_t))partial apply for specialized closure #1 in _StringGuts.withCString<A>(_:));
    swift_release(v4);
    char v9 = 0;
    uint64_t v11 = type metadata accessor for _UntypedColumn();
    uint64_t result = swift_allocObject(v11, 24, 7);
    *(void *)(result + 16) = v10;
  }
  *(void *)uint64_t v3 = result;
  *(unsigned char *)(v3 + 8) = v9;
  return result;
}

Swift::Int MLDataTable.size.getter()
{
  uint64_t v1 = *(void *)v0;
  if (!*(unsigned char *)(v0 + 8))
  {
    swift_retain(v1);
    Swift::Int v5 = CMLTable.rows()();
    if (v6)
    {
      uint64_t v10 = 191;
    }
    else
    {
      Swift::Int v7 = v5;
      CMLTable.columns()();
      if (!v6)
      {
        outlined consume of Result<_DataTable, Error>(v1, 0);
        return v7;
      }
      uint64_t v10 = 192;
    }
    swift_unexpectedError(v6, "CreateML/MLDataTable.swift", 26, 1, v10);
    BUG();
  }
  v11[0] = *(void *)v0;
  outlined copy of Result<_DataTable, Error>(v1, 1);
  swift_errorRetain(v1);
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
  uint64_t v3 = _getErrorEmbeddedNSError<A>(_:)(v11, v2, &protocol self-conformance witness table for Error);
  if (v3)
  {
    uint64_t v4 = v3;
    outlined consume of Result<_DataTable, Error>(v1, 1);
  }
  else
  {
    uint64_t v4 = swift_allocError(v2, &protocol self-conformance witness table for Error, 0, 0);
    uint64_t *v8 = v11[0];
  }
  outlined consume of Result<_DataTable, Error>(v1, 1);
  outlined consume of Result<(Int, Int), Error>(v4, 1, 1);
  return 0;
}

uint64_t MLDataTable.init(namedColumns:)(uint64_t a1)
{
  uint64_t v3 = v1;
  uint64_t result = specialized MLDataTable.init<A>(uniqueKeysWithValues:)(a1);
  if (!v2)
  {
    uint64_t result = v5;
    *(void *)uint64_t v3 = v5;
    *(unsigned char *)(v3 + 8) = v6;
  }
  return result;
}

uint64_t MLDataTable.init()()
{
  uint64_t v1 = v0;
  uint64_t empty = tc_v1_sframe_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v3 = empty;
  uint64_t v4 = type metadata accessor for CMLTable();
  uint64_t v5 = swift_allocObject(v4, 24, 7);
  *(void *)(v5 + 16) = v3;
  uint64_t v6 = type metadata accessor for _DataTable();
  uint64_t result = swift_allocObject(v6, 40, 7);
  *(_OWORD *)(result + 24) = 0;
  *(void *)(result + 16) = v5;
  *(void *)uint64_t v1 = result;
  *(unsigned char *)(v1 + 8) = 0;
  return result;
}

uint64_t MLDataTable.subscript.getter(Swift::String a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v22 = v5;
  if (v6[8])
  {
    swift_willThrow(a1._countAndFlagsBits, a1._object, a2, a3, a4, a5);
    _StringGuts.grow(_:)(34);
    swift_bridgeObjectRelease(0);
    *(void *)&v23[0] = 0xD00000000000001FLL;
    *((void *)&v23[0] + 1) = " element at index " + 0x8000000000000000;
    String.append(_:)(a1);
    v8._uint64_t countAndFlagsBits = 39;
    v8._char object = (void *)0xE100000000000000;
    String.append(_:)(v8);
    uint64_t v9 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v10 = swift_allocError(&type metadata for MLCreateError, v9, 0, 0);
    *(_OWORD *)uint64_t v11 = v23[0];
    *(_OWORD *)(v11 + 16) = 0;
    *(_OWORD *)(v11 + 32) = 0;
    *(unsigned char *)(v11 + 48) = 1;
    *(void *)&v23[0] = v10;
    BYTE8(v23[0]) = 1;
    return MLDataColumn.init(from:)((uint64_t)v23);
  }
  uint64_t v7 = *(void *)(*(void *)v6 + 16);
  swift_retain();
  uint64_t v13 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.column(name:), v7, a1._countAndFlagsBits, (uint64_t)a1._object, (uint64_t (*)(void))type metadata accessor for CMLColumn, (uint64_t (*)(uint64_t))partial apply for specialized closure #1 in _StringGuts.withCString<A>(_:));
  swift_release();
  uint64_t v14 = type metadata accessor for _UntypedColumn();
  *(void *)(swift_allocObject(v14, 24, 7) + 16) = v13;
  swift_retain();
  MLUntypedColumn.column<A>(type:)(a2, a2, a3);
  swift_release();
  char v15 = BYTE8(v23[0]);
  if (BYTE8(v23[0]) == 0xFF)
  {
    _StringGuts.grow(_:)(49);
    swift_bridgeObjectRelease(0);
    strcpy((char *)v23, "Column named '");
    HIBYTE(v23[0]) = -18;
    String.append(_:)(a1);
    v16._uint64_t countAndFlagsBits = 0xD000000000000021;
    v16._char object = "DataTable has no column named '" + 0x8000000000000000;
    String.append(_:)(v16);
    uint64_t v17 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v18 = swift_allocError(&type metadata for MLCreateError, v17, 0, 0);
    *(_OWORD *)uint64_t v19 = v23[0];
    *(_OWORD *)(v19 + 16) = 0;
    *(_OWORD *)(v19 + 32) = 0;
    *(unsigned char *)(v19 + 48) = 1;
    swift_release();
    *(void *)&v23[0] = v18;
    BYTE8(v23[0]) = 1;
    return MLDataColumn.init(from:)((uint64_t)v23);
  }
  swift_release();
  uint64_t result = v22;
  *(void *)uint64_t v22 = *(void *)&v23[0];
  *(unsigned char *)(v22 + 8) = v15 & 1;
  return result;
}

uint64_t MLDataTable.subscript.setter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = *(void *)a1;
  char v6 = *(unsigned char *)(a1 + 8);
  MLDataTable.willMutate()();
  uint64_t v9 = v5;
  char v10 = v6;
  MLDataTable.setColumnImpl(newColumn:named:)((uint64_t)&v9, a2, a3);
  swift_bridgeObjectRelease(a3);
  uint64_t result = outlined consume of Result<_DataTable, Error>(v5, v6);
  if (!*(unsigned char *)(v3 + 8))
  {
    uint64_t v8 = *(void *)v3;
    outlined copy of Result<_DataTable, Error>(v8, 0);
    _DataTable.columnNamesDidChange()();
    return outlined consume of Result<_DataTable, Error>(v8, 0);
  }
  return result;
}

{
  uint64_t v3;
  uint64_t v5;
  char v6;
  uint64_t result;
  uint64_t v8;
  uint64_t v9;
  char v10;

  uint64_t v5 = *(void *)a1;
  char v6 = *(unsigned char *)(a1 + 8);
  MLDataTable.willMutate()();
  uint64_t v9 = v5;
  char v10 = v6;
  MLDataTable.setColumnImpl(newColumn:named:)((uint64_t)&v9, a2, a3);
  swift_bridgeObjectRelease(a3);
  uint64_t result = outlined consume of Result<_DataTable, Error>(v5, v6);
  if (!*(unsigned char *)(v3 + 8))
  {
    uint64_t v8 = *(void *)v3;
    outlined copy of Result<_DataTable, Error>(v8, 0);
    _DataTable.columnNamesDidChange()();
    return outlined consume of Result<_DataTable, Error>(v8, 0);
  }
  return result;
}

uint64_t MLDataTable.subscript.getter(uint64_t a1)
{
  uint64_t v3 = *(void *)a1;
  char v4 = *(unsigned char *)(a1 + 8);
  uint64_t v5 = *(void *)v2;
  char v21 = *(unsigned char *)(v2 + 8);
  uint64_t v16 = v1;
  char v20 = v4;
  if (v21)
  {
    uint64_t v6 = *(void *)v2;
    outlined copy of Result<_DataTable, Error>(v5, 1);
    uint64_t v7 = tc_v1_flex_list_create(0);
    if (!v7) {
      BUG();
    }
    uint64_t v8 = v7;
    uint64_t v9 = type metadata accessor for CMLSequence();
    uint64_t v10 = swift_allocObject(v9, 25, 7);
    *(void *)(v10 + 16) = v8;
    uint64_t v19 = v10;
    *(unsigned char *)(v10 + 24) = 1;
    outlined consume of Result<_DataTable, Error>(v5, 1);
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(v5, 0);
    uint64_t v6 = v5;
    _DataTable.columnNames.getter(v5);
    outlined consume of Result<_DataTable, Error>(v5, 0);
    uint64_t v19 = v17;
  }
  uint64_t v11 = swift_allocObject(&unk_39C338, 25, 7);
  *(void *)(v11 + 16) = v6;
  *(unsigned char *)(v11 + 24) = v21;
  uint64_t v12 = swift_allocObject(&unk_39C360, 25, 7);
  *(void *)(v12 + 16) = v3;
  *(unsigned char *)(v12 + 24) = v20 & 1;
  uint64_t v13 = (void *)swift_allocObject(&unk_39C388, 56, 7);
  v13[2] = partial apply for closure #2 in MLDataTable.subscript.getter;
  void v13[3] = v12;
  v13[4] = v19;
  v13[5] = partial apply for closure #1 in MLDataTable.subscript.getter;
  v13[6] = v11;
  outlined copy of Result<_DataTable, Error>(v6, v21);
  outlined copy of Result<_DataTable, Error>(v3, v20);
  swift_retain_n(v19, 3);
  swift_retain();
  swift_retain();
  uint64_t v14 = specialized Dictionary.init<A>(uniqueKeysWithValues:)(v19, (void (*)(unint64_t *))partial apply for specialized closure #1 in LazyMapSequence<>.map<A>(_:), (uint64_t)v13);
  specialized MLDataTable.init<A>(uniqueKeysWithValues:)((uint64_t)v14);
  swift_release();
  swift_release();
  swift_release_n(v19, 2);
  uint64_t result = v17;
  *(void *)uint64_t v16 = v17;
  *(unsigned char *)(v16 + 8) = v18;
  return result;
}

uint64_t MLDataTable.subscript.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v54._uint64_t countAndFlagsBits = a1;
  uint64_t v51 = v3;
  uint64_t v56 = 0;
  uint64_t AssociatedConformanceWitness = *(void *)(a2 - 8);
  int64_t v6 = *(void *)(AssociatedConformanceWitness + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v57 = v49;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, a2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v52 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v9 = *(void *)(v52 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v59 = v49;
  uint64_t v53 = *(void *)v4;
  char v63 = *(unsigned char *)(v4 + 8);
  uint64_t empty = tc_v1_sframe_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v13 = empty;
  uint64_t v14 = type metadata accessor for CMLTable();
  uint64_t v15 = swift_allocObject(v14, 24, 7);
  *(void *)(v15 + 16) = v13;
  uint64_t v16 = type metadata accessor for _DataTable();
  uint64_t v17 = swift_allocObject(v16, 40, 7);
  *(_OWORD *)(v17 + 24) = 0;
  *(void *)(v17 + 16) = v15;
  uint64_t v60 = v17;
  char v61 = 0;
  (*(void (**)(unsigned char *, uint64_t, uint64_t))(AssociatedConformanceWitness + 16))(v57, v54._countAndFlagsBits, a2);
  dispatch thunk of Sequence.makeIterator()(a2, a3);
  uint64_t v18 = AssociatedTypeWitness;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(a3, a2, AssociatedTypeWitness, &protocol requirements base descriptor for Sequence, &associated conformance descriptor for Sequence.Sequence.Iterator: IteratorProtocol);
  dispatch thunk of IteratorProtocol.next()(v18, AssociatedConformanceWitness);
  uint64_t object = (uint64_t)v62._object;
  if (v62._object)
  {
    char v20 = &v62;
    uint64_t countAndFlagsBits = v62._countAndFlagsBits;
    uint64_t v50 = "ml.activityclassifier" + 0x8000000000000000;
    do
    {
      v54._uint64_t countAndFlagsBits = countAndFlagsBits;
      if (v63)
      {
        uint64_t v22 = (void *)object;
        uint64_t v23 = v53;
        uint64_t v24 = v53;
        outlined copy of Result<_DataTable, Error>(v53, 1);
        swift_willThrow(v24, 1, v25, v26, v27, v28);
        uint64_t v56 = 0;
      }
      else
      {
        uint64_t v23 = v53;
        uint64_t v29 = *(void *)(v53 + 16);
        outlined copy of Result<_DataTable, Error>(v53, 0);
        swift_retain();
        uint64_t v30 = v54._countAndFlagsBits;
        uint64_t v31 = object;
        uint64_t v57 = (unsigned char *)object;
        uint64_t v32 = v56;
        uint64_t v33 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.column(name:), v29, v54._countAndFlagsBits, v31, (uint64_t (*)(void))type metadata accessor for CMLColumn, (uint64_t (*)(uint64_t))partial apply for specialized closure #1 in _StringGuts.withCString<A>(_:));
        if (!v32)
        {
          uint64_t v41 = v33;
          uint64_t v56 = 0;
          swift_release();
          outlined consume of Result<_DataTable, Error>(v23, 0);
          uint64_t v42 = type metadata accessor for _UntypedColumn();
          uint64_t v43 = swift_allocObject(v42, 24, 7);
          *(void *)(v43 + 16) = v41;
          outlined copy of Result<_DataTable, Error>(v43, 0);
          MLDataTable.willMutate()();
          v62._uint64_t countAndFlagsBits = v43;
          LOBYTE(v62._object) = 0;
          char v44 = (char)v57;
          MLDataTable.setColumnImpl(newColumn:named:)((uint64_t)&v62, v30, (uint64_t)v57);
          swift_bridgeObjectRelease(v44);
          outlined consume of Result<_DataTable, Error>(v43, 0);
          if (!v61)
          {
            uint64_t v45 = v60;
            outlined copy of Result<_DataTable, Error>(v60, 0);
            _DataTable.columnNamesDidChange()();
            outlined consume of Result<_DataTable, Error>(v45, 0);
          }
          outlined consume of Result<_DataTable, Error>(v43, 0);
          uint64_t v40 = AssociatedTypeWitness;
          uint64_t v37 = &v62;
          goto LABEL_9;
        }
        uint64_t v22 = v57;
        swift_errorRelease(v32);
        swift_release();
        uint64_t v56 = 0;
        char v20 = &v62;
      }
      v62._uint64_t countAndFlagsBits = 0;
      v62._uint64_t object = (void *)0xE000000000000000;
      _StringGuts.grow(_:)(34);
      swift_bridgeObjectRelease(v62._object);
      v62._uint64_t countAndFlagsBits = 0xD00000000000001FLL;
      v62._uint64_t object = v50;
      v34._uint64_t countAndFlagsBits = v54._countAndFlagsBits;
      char v35 = (char)v22;
      v34._uint64_t object = v22;
      String.append(_:)(v34);
      v34._uint64_t countAndFlagsBits = 34;
      v34._uint64_t object = (void *)0xE100000000000000;
      String.append(_:)(v34);
      Swift::String v54 = v62;
      uint64_t v36 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      uint64_t v37 = v20;
      uint64_t v38 = swift_allocError(&type metadata for MLCreateError, v36, 0, 0);
      *(Swift::String *)uint64_t v39 = v54;
      *(_OWORD *)(v39 + 16) = 0;
      *(_OWORD *)(v39 + 32) = 0;
      *(unsigned char *)(v39 + 48) = 1;
      outlined consume of Result<_DataTable, Error>(v23, v63);
      outlined consume of Result<_DataTable, Error>(v38, 1);
      swift_bridgeObjectRelease(v35);
      uint64_t v40 = AssociatedTypeWitness;
LABEL_9:
      dispatch thunk of IteratorProtocol.next()(v40, AssociatedConformanceWitness);
      uint64_t object = (uint64_t)v62._object;
      uint64_t countAndFlagsBits = v62._countAndFlagsBits;
      char v20 = v37;
    }
    while (v62._object);
  }
  (*(void (**)(unsigned char *, uint64_t))(v52 + 8))(v59, AssociatedTypeWitness);
  uint64_t result = v60;
  char v47 = v61;
  uint64_t v48 = v51;
  *uint64_t v51 = v60;
  *((unsigned char *)v48 + 8) = v47;
  return result;
}

{
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  char v8;
  Swift::Int v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  void v16[2];
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;

  uint64_t v19 = a2;
  char v20 = a1;
  int64_t v6 = v3;
  uint64_t v7 = *(void *)v4;
  uint64_t v8 = *(unsigned char *)(v4 + 8);
  uint64_t v17 = *(void *)v4;
  LOBYTE(v18) = v8;
  int64_t v9 = MLDataTable.size.getter();
  if (v9 < 0) {
    BUG();
  }
  v16[0] = 0;
  v16[1] = v9;
  char v21 = v6;
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Range<Int>);
  uint64_t v11 = lazy protocol witness table accessor for type Range<Int> and conformance <> Range<A>();
  ((void (*)(void *, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))dispatch thunk of RangeExpression.relative<A>(to:))(v16, v10, v11, v19, a3, v12);
  uint64_t v13 = v17;
  uint64_t v14 = v18;
  uint64_t v17 = v7;
  LOBYTE(v18) = v8;
  return MLDataTable.subscript.getter(v13, v14);
}

uint64_t MLDataTable.addColumn(_:named:)(uint64_t *a1, uint64_t a2, void *a3)
{
  uint64_t v5 = *a1;
  char v6 = *((unsigned char *)a1 + 8);
  MLDataTable.willMutate()();
  uint64_t v9 = v5;
  char v10 = v6;
  uint64_t result = MLDataTable.addImpl(newColumn:named:)((uint64_t)&v9, a2, a3);
  if (!*(unsigned char *)(v3 + 8))
  {
    uint64_t v8 = *(void *)v3;
    outlined copy of Result<_DataTable, Error>(v8, 0);
    _DataTable.columnNamesDidChange()();
    return outlined consume of Result<_DataTable, Error>(v8, 0);
  }
  return result;
}

void *specialized Dictionary.init<A>(uniqueKeysWithValues:)(uint64_t a1)
{
  return specialized Dictionary.init<A>(uniqueKeysWithValues:)(a1, &demangling cache variable for type metadata for _DictionaryStorage<String, Double>, (void (*)(uint64_t, uint64_t, void **))specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:));
}

{
  return specialized Dictionary.init<A>(uniqueKeysWithValues:)(a1, &demangling cache variable for type metadata for _DictionaryStorage<MLDataValue, MLDataValue>, (void (*)(uint64_t, uint64_t, void **))specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:));
}

{
  return specialized Dictionary.init<A>(uniqueKeysWithValues:)(a1, &demangling cache variable for type metadata for _DictionaryStorage<String, JSONType>, (void (*)(uint64_t, uint64_t, void **))specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:));
}

{
  return specialized Dictionary.init<A>(uniqueKeysWithValues:)(a1, &demangling cache variable for type metadata for _DictionaryStorage<String, CSVType>, (void (*)(uint64_t, uint64_t, void **))specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:));
}

void *specialized Dictionary.init<A>(uniqueKeysWithValues:)(uint64_t *a1)
{
  uint64_t v1 = *a1;
  uint64_t v2 = a1[2];
  uint64_t v3 = a1[4];
  uint64_t v4 = a1[6];
  char v6 = &_swiftEmptyDictionarySingleton;
  swift_retain(v1);
  swift_retain(v2);
  swift_retain(v3);
  swift_retain(v4);
  specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)(a1, 1, &v6);
  swift_release(v4);
  swift_release(v3);
  swift_release(v2);
  swift_release(v1);
  return v6;
}

void *specialized Dictionary.init<A>(uniqueKeysWithValues:)(uint64_t a1, uint64_t *a2, void (*a3)(uint64_t, uint64_t, void **))
{
  uint64_t v4 = *(void *)(a1 + 16);
  if (v4)
  {
    __swift_instantiateConcreteTypeFromMangledName(a2);
    uint64_t v5 = (void *)static _DictionaryStorage.allocate(capacity:)(v4);
  }
  else
  {
    uint64_t v5 = &_swiftEmptyDictionarySingleton;
  }
  uint64_t v7 = v5;
  swift_bridgeObjectRetain(a1);
  a3(a1, 1, &v7);
  swift_bridgeObjectRelease(a1);
  return v7;
}

void *specialized Dictionary.init<A>(uniqueKeysWithValues:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return specialized Dictionary.init<A>(uniqueKeysWithValues:)(a1, a2, a3, &demangling cache variable for type metadata for _DictionaryStorage<MLDataValue, Int>, (void (*)(uint64_t, uint64_t, uint64_t, uint64_t, void **))specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:));
}

{
  return specialized Dictionary.init<A>(uniqueKeysWithValues:)(a1, a2, a3, &demangling cache variable for type metadata for _DictionaryStorage<String, Int>, (void (*)(uint64_t, uint64_t, uint64_t, uint64_t, void **))specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:));
}

{
  return specialized Dictionary.init<A>(uniqueKeysWithValues:)(a1, a2, a3, &demangling cache variable for type metadata for _DictionaryStorage<MLRecommender.Identifier, Int>, (void (*)(uint64_t, uint64_t, uint64_t, uint64_t, void **))specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:));
}

void *specialized Dictionary.init<A>(uniqueKeysWithValues:)(uint64_t a1, void (*a2)(unint64_t *), uint64_t a3)
{
  uint64_t v4 = specialized Collection.underestimatedCount.getter();
  if (v4)
  {
    uint64_t v5 = v4;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _DictionaryStorage<String, MLUntypedColumn>);
    char v6 = (void *)static _DictionaryStorage.allocate(capacity:)(v5);
  }
  else
  {
    char v6 = _swiftEmptyDictionarySingleton;
  }
  uint64_t v8 = v6;
  swift_retain();
  swift_retain();
  specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)(a1, a2, a3, 1, &v8);
  swift_release();
  swift_release();
  return v8;
}

void *specialized Dictionary.init<A>(uniqueKeysWithValues:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4, void (*a5)(uint64_t, uint64_t, uint64_t, uint64_t, void **))
{
  if (__OFSUB__(a3, a2)) {
    BUG();
  }
  uint64_t v7 = *(void *)(a1 + 16);
  if (a3 - a2 < v7) {
    uint64_t v7 = a3 - a2;
  }
  if (v7)
  {
    __swift_instantiateConcreteTypeFromMangledName(a4);
    uint64_t v8 = (void *)static _DictionaryStorage.allocate(capacity:)(v7);
  }
  else
  {
    uint64_t v8 = _swiftEmptyDictionarySingleton;
  }
  char v10 = v8;
  swift_bridgeObjectRetain(a1);
  a5(a1, a2, a3, 1, &v10);
  swift_bridgeObjectRelease(a1);
  return v10;
}

Swift::Void __swiftcall MLDataTable.renameColumn(named:to:)(Swift::String named, Swift::String to)
{
  uint64_t object = to._object;
  uint64_t countAndFlagsBits = to._countAndFlagsBits;
  MLDataTable.willMutate()();
  v5._uint64_t countAndFlagsBits = countAndFlagsBits;
  v5._uint64_t object = object;
  MLDataTable.renameImpl(named:to:)(named, v5);
  if (!*(unsigned char *)(v2 + 8))
  {
    uint64_t v6 = *(void *)v2;
    outlined copy of Result<_DataTable, Error>(v6, 0);
    _DataTable.columnNamesDidChange()();
    outlined consume of Result<_DataTable, Error>(v6, 0);
  }
}

uint64_t specialized String.withCString<A>(_:)(uint64_t (*a1)(void), uint64_t a2, uint64_t a3, uint64_t a4)
{
  return specialized String.withCString<A>(_:)(a1, a2, a3, a4, (uint64_t (*)(void))type metadata accessor for CMLVariant, (uint64_t (*)(uint64_t))_ss11_StringGutsV11withCStringyxxSPys4Int8VGKXEKlFxSRyAEGKXEfU_s13OpaquePointerV_TG5TA_0);
}

{
  return specialized String.withCString<A>(_:)(a1, a2, a3, a4, (uint64_t (*)(void))type metadata accessor for CMLColumn, (uint64_t (*)(uint64_t))partial apply for specialized closure #1 in _StringGuts.withCString<A>(_:));
}

{
  return specialized String.withCString<A>(_:)(a1, a2, a3, a4, (uint64_t (*)(void))type metadata accessor for CMLFeatureValue, (uint64_t (*)(uint64_t))_ss11_StringGutsV11withCStringyxxSPys4Int8VGKXEKlFxSRyAEGKXEfU_s13OpaquePointerV_TG5TA_0);
}

{
  return specialized String.withCString<A>(_:)(a1, a2, a3, a4, (uint64_t (*)(void))type metadata accessor for CMLTable, (uint64_t (*)(uint64_t))_ss11_StringGutsV11withCStringyxxSPys4Int8VGKXEKlFxSRyAEGKXEfU_s13OpaquePointerV_TG5TA_0);
}

uint64_t specialized String.withCString<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if ((a2 & 0x1000000000000000) != 0 || !(a2 & 0x2000000000000000 | a1 & 0x1000000000000000))
  {
    _StringGuts._slowWithCString<A>(_:)(partial apply for closure #1 in CMLTable.removeColumn(name:), a3, a1, a2, (char *)&type metadata for () + 8);
    return swift_release();
  }
  if ((a2 & 0x2000000000000000) == 0)
  {
    if ((a1 & 0x1000000000000000) != 0)
    {
      uint64_t v3 = (a2 & 0xFFFFFFFFFFFFFFFLL) + 32;
      uint64_t v4 = a1 & 0xFFFFFFFFFFFFLL;
    }
    else
    {
      uint64_t v3 = _StringObject.sharedUTF8.getter(a1, a2);
      uint64_t v4 = v6;
    }
    _sSRsRi_zrlE17withMemoryRebound2to_qd_1_qd__m_qd_1_SRyqd__Gqd_0_YKXEtqd_0_YKs5ErrorRd_0_Ri_d__Ri_d_1_r1_lFSRyxGq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lys4Int8VsAD_pqd_1_Isgyrzr_SRys5UInt8VGqd_1_sAD_pAIRszAGRsd__sAD_pRsd_0_Ri_d_1_r_1_lIetMgyrzo_Tpq5yt_Tg507_sSRys4f5VGxs5E34_pIgyrzo_ACxsAD_pIegyrzr_lTRyt_TG5SRyAGGytsAD_pIgyrzo_Tf1ncn_n038_ss11_StringGutsV11withCStringyxxSPys4F27VGKXEKlFxSRyAEGKXEfU_yt_Tg5SPyAGGxsAD_pRi_zRi0_zlyytIsgyrzo_Tf1nnc_n(v3, v4, (uint64_t (*)(uint64_t))partial apply for closure #1 in CMLTable.removeColumn(name:));
    return swift_release();
  }
  v7[0] = a1;
  v7[1] = a2 & 0xFFFFFFFFFFFFFFLL;
  specialized handling<A, B, C>(_:_:_:)(*(void *)(a3 + 16), (uint64_t)v7);
  return swift_release();
}

char specialized String.withCString<A>(_:)(uint64_t (*a1)(void), uint64_t a2, uint64_t a3, uint64_t a4)
{
  if ((a4 & 0x1000000000000000) != 0 || !(a4 & 0x2000000000000000 | a3 & 0x1000000000000000))
  {
    char result = _StringGuts._slowWithCString<A>(_:)(a1, a2, a3, a4, &type metadata for CMLFeatureValueType);
    if (!v4) {
      return v10;
    }
  }
  else
  {
    Swift::String v5 = alloca(32);
    uint64_t v6 = alloca(32);
    if ((a4 & 0x2000000000000000) != 0)
    {
      char result = a1();
      if (!v4) {
        return HIBYTE(a2);
      }
    }
    else
    {
      if ((a3 & 0x1000000000000000) != 0)
      {
        uint64_t v7 = (a4 & 0xFFFFFFFFFFFFFFFLL) + 32;
        uint64_t v8 = a3 & 0xFFFFFFFFFFFFLL;
      }
      else
      {
        uint64_t v7 = _StringObject.sharedUTF8.getter(a3, a4);
      }
      return _sSRsRi_zrlE17withMemoryRebound2to_qd_1_qd__m_qd_1_SRyqd__Gqd_0_YKXEtqd_0_YKs5ErrorRd_0_Ri_d__Ri_d_1_r1_lFSRyxGq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lys4Int8VsAD_pqd_1_Isgyrzr_SRys5UInt8VGqd_1_sAD_pAIRszAGRsd__sAD_pRsd_0_Ri_d_1_r_1_lIetMgyrzo_Tpq5Sb_Tg507_sSRys4f5VGxs5E34_pIgyrzo_ACxsAD_pIegyrzr_lTRSb_TG5SRyAGGSbsAD_pIgyrzo_Tf1cn_n(v7, v8, (uint64_t (*)(uint64_t))_ss11_StringGutsV11withCStringyxxSPys4Int8VGKXEKlFxSRyAEGKXEfU_Sb_TG5TA_0);
    }
  }
  return result;
}

uint64_t specialized String.withCString<A>(_:)(uint64_t (*a1)(void), uint64_t a2, uint64_t a3, uint64_t a4, uint64_t (*a5)(void), uint64_t (*a6)(uint64_t))
{
  if ((a4 & 0x1000000000000000) != 0 || !(a4 & 0x2000000000000000 | a3 & 0x1000000000000000))
  {
    uint64_t v22 = v6;
    uint64_t v14 = a5(0);
    uint64_t result = _StringGuts._slowWithCString<A>(_:)(a1, a2, a3, a4, v14);
    if (!v6) {
      return v20;
    }
  }
  else
  {
    uint64_t v22 = v18;
    uint64_t v9 = alloca(32);
    char v10 = alloca(32);
    uint64_t v19 = (uint64_t)a1;
    uint64_t v20 = a2;
    if ((a4 & 0x2000000000000000) != 0)
    {
      v18[1] = a3;
      uint64_t v19 = a4 & 0xFFFFFFFFFFFFFFLL;
      uint64_t result = a1();
      if (!v6) {
        return v21;
      }
    }
    else
    {
      if ((a3 & 0x1000000000000000) != 0)
      {
        uint64_t v11 = (a4 & 0xFFFFFFFFFFFFFFFLL) + 32;
        uint64_t v12 = a3 & 0xFFFFFFFFFFFFLL;
      }
      else
      {
        uint64_t v15 = a6;
        uint64_t v16 = _StringObject.sharedUTF8.getter(a3, a4);
        a6 = v15;
        uint64_t v11 = v16;
        uint64_t v12 = v17;
      }
      return _sSRsRi_zrlE17withMemoryRebound2to_qd_1_qd__m_qd_1_SRyqd__Gqd_0_YKXEtqd_0_YKs5ErrorRd_0_Ri_d__Ri_d_1_r1_lFSRyxGq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lys4Int8VsAD_pqd_1_Isgyrzr_SRys5UInt8VGqd_1_sAD_pAIRszAGRsd__sAD_pRsd_0_Ri_d_1_r_1_lIetMgyrzo_Tpq5s13OpaquePointerV_Tg507_sSRys4f5VGxs5e31_pIgyrzo_ACxsAD_pIegyrzr_lTRs13hI5V_TG5SRyAGGALsAD_pIgyrzo_Tf1cn_n(v11, v12, a6);
    }
  }
  return result;
}

uint64_t specialized String.withCString<A>(_:)(uint64_t (*a1)(void, void, void), uint64_t a2, uint64_t a3, uint64_t a4)
{
  if ((a4 & 0x1000000000000000) != 0 || !(a4 & 0x2000000000000000 | a3 & 0x1000000000000000))
  {
    uint64_t result = _StringGuts._slowWithCString<A>(_:)(a1, a2, a3, a4, &type metadata for OpaquePointer);
    if (!v4) {
      return (uint64_t)v11;
    }
  }
  else
  {
    Swift::String v5 = alloca(32);
    uint64_t v6 = alloca(32);
    uint64_t v11 = a1;
    uint64_t v12 = a2;
    if ((a4 & 0x2000000000000000) != 0)
    {
      v10[0] = a3;
      v10[1] = a4 & 0xFFFFFFFFFFFFFFLL;
      uint64_t result = a1(v10, a1, a3);
      if (!v4) {
        return v12;
      }
    }
    else
    {
      if ((a3 & 0x1000000000000000) != 0)
      {
        uint64_t v7 = (a4 & 0xFFFFFFFFFFFFFFFLL) + 32;
        uint64_t v8 = a3 & 0xFFFFFFFFFFFFLL;
      }
      else
      {
        uint64_t v7 = _StringObject.sharedUTF8.getter(a3, a4);
      }
      return _sSRsRi_zrlE17withMemoryRebound2to_qd_1_qd__m_qd_1_SRyqd__Gqd_0_YKXEtqd_0_YKs5ErrorRd_0_Ri_d__Ri_d_1_r1_lFSRyxGq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lys4Int8VsAD_pqd_1_Isgyrzr_SRys5UInt8VGqd_1_sAD_pAIRszAGRsd__sAD_pRsd_0_Ri_d_1_r_1_lIetMgyrzo_Tpq5s13OpaquePointerV_Tg507_sSRys4f5VGxs5e31_pIgyrzo_ACxsAD_pIegyrzr_lTRs13hI5V_TG5SRyAGGALsAD_pIgyrzo_Tf1cn_n(v7, v8, (uint64_t (*)(uint64_t))partial apply for specialized closure #1 in _StringGuts.withCString<A>(_:));
    }
  }
  return result;
}

uint64_t MLDataTable.init(dictionary:)(uint64_t a1)
{
  uint64_t v47 = v2;
  uint64_t v43 = v1;
  uint64_t empty = tc_v1_sframe_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v5 = empty;
  int64_t v48 = 0;
  uint64_t v6 = type metadata accessor for CMLTable();
  uint64_t v7 = swift_allocObject(v6, 24, 7);
  *(void *)(v7 + 16) = v5;
  uint64_t v8 = type metadata accessor for _DataTable();
  uint64_t v9 = swift_allocObject(v8, 40, 7);
  *(_OWORD *)(v9 + 24) = 0;
  *(void *)(v9 + 16) = v7;
  uint64_t v10 = 1 << *(unsigned char *)(a1 + 32);
  uint64_t v11 = ~(-1 << v10);
  if (v10 >= 64) {
    uint64_t v11 = -1;
  }
  unint64_t v12 = *(void *)(a1 + 64) & v11;
  int64_t v50 = (unint64_t)(v10 + 63) >> 6;
  int64_t v44 = v50 - 1;
  uint64_t v49 = v9;
  swift_retain();
  uint64_t v13 = a1;
  uint64_t v46 = a1;
  while (1)
  {
    if (v12)
    {
      _BitScanForward64(&v14, v12);
      uint64_t v15 = (v12 - 1) & v12;
      int64_t v16 = v48;
      unint64_t v17 = v14 | (v48 << 6);
LABEL_7:
      unint64_t v45 = v15;
      uint64_t v18 = *(void *)(v13 + 48);
      uint64_t v19 = 40 * v17;
      uint64_t v20 = 16 * v17;
      uint64_t v21 = *(void *)(v18 + v20 + 8);
      *(void *)&long long v38 = *(void *)(v18 + v20);
      *((void *)&v38 + 1) = v21;
      outlined init with copy of TabularRegressionTask(*(void *)(v13 + 56) + v19, (uint64_t)&v39);
      swift_bridgeObjectRetain(v21);
      int64_t v22 = v16;
      goto LABEL_15;
    }
    int64_t v23 = v48 + 1;
    if (__OFADD__(1, v48)) {
      BUG();
    }
    if (v23 >= v50)
    {
      int64_t v23 = v48;
    }
    else
    {
      unint64_t i = *(void *)(v13 + 8 * v23 + 64);
      if (i)
      {
        int64_t v25 = v48 + 1;
LABEL_12:
        _BitScanForward64(&v26, i);
        uint64_t v15 = i & (i - 1);
        int64_t v16 = v25;
        unint64_t v17 = v26 + (v25 << 6);
        goto LABEL_7;
      }
      int64_t v25 = v48 + 2;
      if (v48 + 2 < v50)
      {
        unint64_t i = *(void *)(v13 + 8 * v23 + 72);
        if (i) {
          goto LABEL_12;
        }
        if (v48 + 3 >= v50)
        {
          int64_t v23 = v48 + 2;
        }
        else
        {
          unint64_t i = *(void *)(v13 + 8 * v23 + 80);
          if (i)
          {
            int64_t v25 = v48 + 3;
            goto LABEL_12;
          }
          int64_t v25 = v48 + 4;
          if (v48 + 4 < v50)
          {
            for (unint64_t i = *(void *)(v13 + 8 * v23 + 88); !i; unint64_t i = *(void *)(v13 + 8 * v25 + 64))
            {
              if (__OFADD__(1, v25++)) {
                BUG();
              }
              if (v25 >= v50)
              {
                int64_t v23 = v44;
                goto LABEL_14;
              }
            }
            goto LABEL_12;
          }
          int64_t v23 = v48 + 3;
        }
      }
    }
LABEL_14:
    long long v40 = 0;
    uint64_t v41 = 0;
    long long v39 = 0;
    long long v38 = 0;
    int64_t v22 = v23;
    unint64_t v45 = 0;
LABEL_15:
    outlined init with take of (key: String, value: MLDataValueConvertible)?((uint64_t)&v38, (uint64_t)&v35);
    uint64_t v27 = v36;
    if (!v36)
    {
      uint64_t v33 = v49;
      swift_release();
      swift_release();
      uint64_t result = (uint64_t)v43;
      *uint64_t v43 = v33;
      *(unsigned char *)(result + 8) = 0;
      return result;
    }
    int64_t v48 = v22;
    uint64_t v42 = v35;
    outlined init with take of MLIdentifier(&v37, (uint64_t)&v38);
    uint64_t v28 = *((void *)&v39 + 1);
    uint64_t v29 = v40;
    __swift_project_boxed_opaque_existential_0Tm(&v38, *((uint64_t *)&v39 + 1));
    uint64_t v30 = MLDataValueConvertible.featureColumn.getter(v28, v29);
    swift_retain();
    uint64_t v31 = v47;
    CMLTable.addColumn(name:_:)(v42, v27, v30);
    uint64_t v47 = v31;
    if (v31) {
      break;
    }
    swift_release();
    swift_release();
    swift_bridgeObjectRelease(v27);
    __swift_destroy_boxed_opaque_existential_1Tm(&v38);
    uint64_t v13 = v46;
    unint64_t v12 = v45;
  }
  swift_release();
  swift_release_n(v49);
  swift_release();
  swift_release();
  swift_bridgeObjectRelease(v27);
  return __swift_destroy_boxed_opaque_existential_1Tm(&v38);
}

void MLDataTable.append(contentsOf:)(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t v3 = *v1;
  char v4 = 1;
  if (*((unsigned char *)v2 + 8))
  {
    uint64_t v5 = v3;
  }
  else
  {
    uint64_t v5 = *(void *)a1;
    if (*(unsigned char *)(a1 + 8))
    {
      outlined copy of Result<_DataTable, Error>(*(void *)a1, 1);
      outlined consume of Result<_DataTable, Error>(v3, 0);
    }
    else
    {
      type metadata accessor for CMLTable();
      uint64_t v6 = *(void *)(v3 + 16);
      uint64_t v7 = *(void *)(v5 + 16);
      outlined copy of Result<_DataTable, Error>(v5, 0);
      outlined copy of Result<_DataTable, Error>(v3, 0);
      swift_retain();
      swift_retain();
      uint64_t v8 = CMLTable.__allocating_init(concatenating:and:)(v6, v7);
      uint64_t v9 = type metadata accessor for _DataTable();
      uint64_t v10 = swift_allocObject(v9, 40, 7);
      *(_OWORD *)(v10 + 24) = 0;
      *(void *)(v10 + 16) = v8;
      char v4 = 0;
      outlined consume of Result<_DataTable, Error>(v5, 0);
      outlined consume of Result<_DataTable, Error>(v3, 0);
      outlined consume of Result<_DataTable, Error>(v3, 0);
      uint64_t v5 = v10;
    }
  }
  uint64_t *v2 = v5;
  *((unsigned char *)v2 + 8) = v4;
}

uint64_t MLDataTable.addColumn<A>(_:named:)(uint64_t a1, uint64_t a2, void *a3)
{
  uint64_t v10 = a3;
  uint64_t v4 = *(void *)a1;
  char v5 = *(unsigned char *)(a1 + 8);
  MLDataTable.willMutate()();
  uint64_t v8 = v4;
  char v9 = v5;
  outlined copy of Result<_DataTable, Error>(v4, v5);
  MLDataTable.addImpl(newColumn:named:)((uint64_t)&v8, a2, v10);
  uint64_t result = outlined consume of Result<_DataTable, Error>(v4, v5);
  if (!*(unsigned char *)(v3 + 8))
  {
    uint64_t v7 = *(void *)v3;
    outlined copy of Result<_DataTable, Error>(v7, 0);
    _DataTable.columnNamesDidChange()();
    return outlined consume of Result<_DataTable, Error>(v7, 0);
  }
  return result;
}

uint64_t MLDataTable.columnTypes.getter()
{
  if (v0[8]) {
    return Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for MLDataValue.ValueType, &protocol witness table for String);
  }
  uint64_t v2 = *(void *)v0;
  uint64_t v3 = *(void *)(*(void *)v0 + 16);
  swift_retain();
  outlined copy of Result<_DataTable, Error>(v2, 0);
  uint64_t v94 = (void *)Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for MLDataValue.ValueType, &protocol witness table for String);
  swift_retain();
  _DataTable.columnNames.getter(v2);
  outlined consume of Result<_DataTable, Error>(v2, 0);
  swift_retain();
  uint64_t v4 = CMLSequence.size.getter();
  uint64_t v5 = specialized RandomAccessCollection<>.distance(from:to:)(0, v4);
  swift_release();
  if (v5)
  {
    uint64_t v92 = v3;
    uint64_t v91 = v2;
    uint64_t v6 = 0;
    do
    {
      CMLSequence.value(at:)(v6);
      Swift::String v7 = CMLFeatureValue.stringValue()();
      uint64_t countAndFlagsBits = v7._countAndFlagsBits;
      if (v8)
      {
        swift_errorRelease(v8);
        swift_release();
        _StringGuts.grow(_:)(37);
        swift_bridgeObjectRelease(0xE000000000000000);
        v88._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
        uint64_t object = v88._object;
        String.append(_:)(v88);
        swift_bridgeObjectRelease(object);
        v90._uint64_t countAndFlagsBits = 46;
        v90._uint64_t object = (void *)0xE100000000000000;
        String.append(_:)(v90);
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000022, "able.ColumnNames.swift" + 0x8000000000000000, "CreateML/MLDataTable.ColumnNames.swift", 38, 2, 17, 0);
        BUG();
      }
      char v9 = v7._object;
      swift_release();
      swift_retain();
      uint64_t v10 = CMLSequence.size.getter();
      uint64_t v11 = specialized RandomAccessCollection<>.distance(from:to:)(0, v10);
      swift_release();
      if (v6 >= v11) {
        BUG();
      }
      switch(specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.columnType(name:), v92, countAndFlagsBits, (uint64_t)v9))
      {
        case 0:
          char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v94);
          unint64_t v12 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
          char v102 = v13;
          BOOL v14 = (v13 & 1) == 0;
          BOOL v15 = __OFADD__(v94[2], v14);
          Swift::Int v16 = v94[2] + v14;
          if (v15) {
            BUG();
          }
          unint64_t v17 = v12;
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, MLDataValue.ValueType>);
          unint64_t v18 = v17;
          if (_NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v16))
          {
            unint64_t v18 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
            if ((v102 & 1) != (v19 & 1)) {
              goto LABEL_71;
            }
          }
          uint64_t v20 = v94;
          if ((v102 & 1) == 0)
          {
            v94[(v18 >> 6) + 8] |= 1 << v18;
            uint64_t v70 = v94[6];
            uint64_t v71 = 16 * v18;
            *(void *)(v70 + v71) = countAndFlagsBits;
            *(void *)(v70 + v71 + 8) = v9;
            *(unsigned char *)(v94[7] + v18) = 0;
            uint64_t v72 = v94[2];
            BOOL v15 = __OFADD__(1, v72);
            uint64_t v66 = v72 + 1;
            if (v15) {
              BUG();
            }
            goto LABEL_56;
          }
          *(unsigned char *)(v94[7] + v18) = 0;
          break;
        case 1:
          char v99 = swift_isUniquelyReferenced_nonNull_native(v94);
          unint64_t v42 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
          char v106 = v43;
          BOOL v44 = (v43 & 1) == 0;
          BOOL v15 = __OFADD__(v94[2], v44);
          Swift::Int v45 = v94[2] + v44;
          if (v15) {
            BUG();
          }
          unint64_t v46 = v42;
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, MLDataValue.ValueType>);
          unint64_t v47 = v46;
          if (_NativeDictionary.ensureUnique(isUnique:capacity:)(v99, v45))
          {
            unint64_t v47 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
            if ((v106 & 1) != (v48 & 1)) {
              goto LABEL_71;
            }
          }
          uint64_t v20 = v94;
          if ((v106 & 1) == 0)
          {
            v94[(v47 >> 6) + 8] |= 1 << v47;
            uint64_t v76 = v94[6];
            uint64_t v77 = 16 * v47;
            *(void *)(v76 + v77) = countAndFlagsBits;
            *(void *)(v76 + v77 + 8) = v9;
            *(unsigned char *)(v94[7] + v47) = 1;
            uint64_t v78 = v94[2];
            BOOL v15 = __OFADD__(1, v78);
            uint64_t v66 = v78 + 1;
            if (v15) {
              BUG();
            }
            goto LABEL_56;
          }
          *(unsigned char *)(v94[7] + v47) = 1;
          break;
        case 2:
          char v97 = swift_isUniquelyReferenced_nonNull_native(v94);
          unint64_t v28 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
          char v104 = v29;
          BOOL v30 = (v29 & 1) == 0;
          BOOL v15 = __OFADD__(v94[2], v30);
          Swift::Int v31 = v94[2] + v30;
          if (v15) {
            BUG();
          }
          unint64_t v32 = v28;
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, MLDataValue.ValueType>);
          unint64_t v33 = v32;
          if (_NativeDictionary.ensureUnique(isUnique:capacity:)(v97, v31))
          {
            unint64_t v33 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
            if ((v104 & 1) != (v34 & 1)) {
              goto LABEL_71;
            }
          }
          uint64_t v20 = v94;
          if ((v104 & 1) == 0)
          {
            v94[(v33 >> 6) + 8] |= 1 << v33;
            uint64_t v67 = v94[6];
            uint64_t v68 = 16 * v33;
            *(void *)(v67 + v68) = countAndFlagsBits;
            *(void *)(v67 + v68 + 8) = v9;
            *(unsigned char *)(v94[7] + v33) = 2;
            uint64_t v69 = v94[2];
            BOOL v15 = __OFADD__(1, v69);
            uint64_t v66 = v69 + 1;
            if (v15) {
              BUG();
            }
            goto LABEL_56;
          }
          *(unsigned char *)(v94[7] + v33) = 2;
          break;
        case 3:
          char v98 = swift_isUniquelyReferenced_nonNull_native(v94);
          unint64_t v35 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
          char v105 = v36;
          BOOL v37 = (v36 & 1) == 0;
          BOOL v15 = __OFADD__(v94[2], v37);
          Swift::Int v38 = v94[2] + v37;
          if (v15) {
            BUG();
          }
          unint64_t v39 = v35;
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, MLDataValue.ValueType>);
          unint64_t v40 = v39;
          if (_NativeDictionary.ensureUnique(isUnique:capacity:)(v98, v38))
          {
            unint64_t v40 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
            if ((v105 & 1) != (v41 & 1)) {
              goto LABEL_71;
            }
          }
          uint64_t v20 = v94;
          if ((v105 & 1) == 0)
          {
            v94[(v40 >> 6) + 8] |= 1 << v40;
            uint64_t v73 = v94[6];
            uint64_t v74 = 16 * v40;
            *(void *)(v73 + v74) = countAndFlagsBits;
            *(void *)(v73 + v74 + 8) = v9;
            *(unsigned char *)(v94[7] + v40) = 3;
            uint64_t v75 = v94[2];
            BOOL v15 = __OFADD__(1, v75);
            uint64_t v66 = v75 + 1;
            if (v15) {
              BUG();
            }
            goto LABEL_56;
          }
          *(unsigned char *)(v94[7] + v40) = 3;
          break;
        case 4:
          char v96 = swift_isUniquelyReferenced_nonNull_native(v94);
          unint64_t v21 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
          char v103 = v22;
          BOOL v23 = (v22 & 1) == 0;
          BOOL v15 = __OFADD__(v94[2], v23);
          Swift::Int v24 = v94[2] + v23;
          if (v15) {
            BUG();
          }
          unint64_t v25 = v21;
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, MLDataValue.ValueType>);
          unint64_t v26 = v25;
          if (_NativeDictionary.ensureUnique(isUnique:capacity:)(v96, v24))
          {
            unint64_t v26 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
            if ((v103 & 1) != (v27 & 1)) {
              goto LABEL_71;
            }
          }
          uint64_t v20 = v94;
          if ((v103 & 1) == 0)
          {
            v94[(v26 >> 6) + 8] |= 1 << v26;
            uint64_t v63 = v94[6];
            uint64_t v64 = 16 * v26;
            *(void *)(v63 + v64) = countAndFlagsBits;
            *(void *)(v63 + v64 + 8) = v9;
            *(unsigned char *)(v94[7] + v26) = 4;
            uint64_t v65 = v94[2];
            BOOL v15 = __OFADD__(1, v65);
            uint64_t v66 = v65 + 1;
            if (v15) {
              BUG();
            }
            goto LABEL_56;
          }
          *(unsigned char *)(v94[7] + v26) = 4;
          break;
        case 5:
          char v100 = swift_isUniquelyReferenced_nonNull_native(v94);
          unint64_t v49 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
          char v107 = v50;
          BOOL v51 = (v50 & 1) == 0;
          BOOL v15 = __OFADD__(v94[2], v51);
          Swift::Int v52 = v94[2] + v51;
          if (v15) {
            BUG();
          }
          unint64_t v53 = v49;
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, MLDataValue.ValueType>);
          unint64_t v54 = v53;
          if (_NativeDictionary.ensureUnique(isUnique:capacity:)(v100, v52))
          {
            unint64_t v54 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
            if ((v107 & 1) != (v55 & 1)) {
              goto LABEL_71;
            }
          }
          uint64_t v20 = v94;
          if ((v107 & 1) == 0)
          {
            v94[(v54 >> 6) + 8] |= 1 << v54;
            uint64_t v79 = v94[6];
            uint64_t v80 = 16 * v54;
            *(void *)(v79 + v80) = countAndFlagsBits;
            *(void *)(v79 + v80 + 8) = v9;
            *(unsigned char *)(v94[7] + v54) = 6;
            uint64_t v81 = v94[2];
            BOOL v15 = __OFADD__(1, v81);
            uint64_t v66 = v81 + 1;
            if (v15) {
              BUG();
            }
            goto LABEL_56;
          }
          *(unsigned char *)(v94[7] + v54) = 6;
          break;
        case 6:
          char v101 = swift_isUniquelyReferenced_nonNull_native(v94);
          unint64_t v56 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
          char v108 = v57;
          BOOL v58 = (v57 & 1) == 0;
          BOOL v15 = __OFADD__(v94[2], v58);
          Swift::Int v59 = v94[2] + v58;
          if (v15) {
            BUG();
          }
          unint64_t v60 = v56;
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, MLDataValue.ValueType>);
          unint64_t v61 = v60;
          if (_NativeDictionary.ensureUnique(isUnique:capacity:)(v101, v59))
          {
            unint64_t v61 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)v9);
            if ((v108 & 1) != (v62 & 1))
            {
LABEL_71:
              KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
              BUG();
            }
          }
          uint64_t v20 = v94;
          if (v108)
          {
            *(unsigned char *)(v94[7] + v61) = 5;
          }
          else
          {
            v94[(v61 >> 6) + 8] |= 1 << v61;
            uint64_t v82 = v94[6];
            uint64_t v83 = 16 * v61;
            *(void *)(v82 + v83) = countAndFlagsBits;
            *(void *)(v82 + v83 + 8) = v9;
            *(unsigned char *)(v94[7] + v61) = 5;
            uint64_t v84 = v94[2];
            BOOL v15 = __OFADD__(1, v84);
            uint64_t v66 = v84 + 1;
            if (v15) {
              BUG();
            }
LABEL_56:
            v20[2] = v66;
            swift_bridgeObjectRetain(v9);
          }
          break;
      }
      swift_bridgeObjectRelease(v9);
      swift_bridgeObjectRelease(0x8000000000000000);
      ++v6;
      swift_retain();
      uint64_t v85 = CMLSequence.size.getter();
      uint64_t v86 = specialized RandomAccessCollection<>.distance(from:to:)(0, v85);
      swift_release();
    }
    while (v6 != v86);
    swift_release();
    swift_release();
    uint64_t v87 = v91;
  }
  else
  {
    swift_release();
    swift_release();
    uint64_t v87 = v2;
  }
  outlined consume of Result<_DataTable, Error>(v87, 0);
  return (uint64_t)v94;
}

uint64_t MLDataTable.subscript.getter(Swift::String a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v5 = *(void *)v4;
  char v6 = *(unsigned char *)(v4 + 8);
  outlined copy of Result<_DataTable, Error>(*(void *)v4, v6);
  MLDataTable.subscript.getter(a1);
  outlined consume of Result<_DataTable, Error>(v5, v6);
  MLUntypedColumn.column<A>(type:)(a2, a3, a4);
  return outlined consume of Result<_DataTable, Error>(v8, v9);
}

uint64_t MLDataTable.subscript.getter(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = v2;
  uint64_t v5 = *(void *)v3;
  if (*(unsigned char *)(v3 + 8))
  {
    v19[0] = *(void *)v3;
    outlined copy of Result<_DataTable, Error>(v5, 1);
    swift_errorRetain(v5);
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v7 = _getErrorEmbeddedNSError<A>(_:)(v19, v6, &protocol self-conformance witness table for Error);
    if (v7)
    {
      uint64_t v8 = v7;
      outlined consume of Result<_DataTable, Error>(v5, 1);
    }
    else
    {
      uint64_t v8 = swift_allocError(v6, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v11 = v19[0];
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v5, 1);
    char v13 = 1;
  }
  else
  {
    uint64_t v9 = *(void *)(*(void *)(v5 + 16) + 16);
    swift_retain();
    uint64_t v10 = specialized handling<A, B, C, D, E>(_:_:_:_:_:)(v9, a1, 1, a2);
    uint64_t v14 = v10;
    if (!v10) {
      BUG();
    }
    char v13 = 0;
    uint64_t v15 = type metadata accessor for CMLTable();
    uint64_t v16 = swift_allocObject(v15, 24, 7);
    *(void *)(v16 + 16) = v14;
    uint64_t v17 = v16;
    uint64_t v18 = type metadata accessor for _DataTable();
    uint64_t v8 = swift_allocObject(v18, 40, 7);
    *(_OWORD *)(v8 + 24) = 0;
    *(void *)(v8 + 16) = v17;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v5, 0);
  }
  *(void *)uint64_t v4 = v8;
  *(unsigned char *)(v4 + 8) = v13;
  return result;
}

uint64_t MLDataTable.exclude<A>(_:of:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return MLDataTable.exclude<A>(_:of:)(a1, a2, a3, a4, a5, 1);
}

uint64_t _DataTable.columnNames.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = *(void *)(v1 + 24);
  if (!v3)
  {
    uint64_t v4 = specialized handling<A, B>(_:_:)(*(void *)(*(void *)(v1 + 16) + 16));
    if (!v4) {
      BUG();
    }
    uint64_t v5 = type metadata accessor for CMLSequence();
    uint64_t v6 = swift_allocObject(v5, 25, 7);
    *(void *)(v6 + 16) = v4;
    *(unsigned char *)(v6 + 24) = 1;
    uint64_t v7 = *(void *)(v1 + 24);
    *(void *)(v1 + 24) = v6;
    swift_release(v7);
    uint64_t v3 = *(void *)(v1 + 24);
    if (!v3) {
      BUG();
    }
  }
  void *v2 = v3;
  return swift_retain(v3);
}

uint64_t _DataTable.columnIndexes.getter()
{
  uint64_t v1 = *(void *)(v0 + 32);
  if (!v1)
  {
    uint64_t v29 = v0;
    _DataTable.columnNames.getter();
    swift_retain();
    uint64_t v2 = CMLSequence.size.getter();
    uint64_t v3 = specialized RandomAccessCollection<>.distance(from:to:)(0, v2);
    swift_release();
    if (v3)
    {
      uint64_t v4 = 0;
      do
      {
        CMLSequence.value(at:)(v4);
        Swift::String v5 = CMLFeatureValue.stringValue()();
        uint64_t countAndFlagsBits = v5._countAndFlagsBits;
        uint64_t object = v5._object;
        if (v6)
        {
          swift_release();
          swift_errorRelease(v6);
          _StringGuts.grow(_:)(37);
          swift_bridgeObjectRelease(0xE000000000000000);
          v26._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
          char v27 = v26._object;
          String.append(_:)(v26);
          swift_bridgeObjectRelease(v27);
          v28._uint64_t countAndFlagsBits = 46;
          v28._uint64_t object = (void *)0xE100000000000000;
          String.append(_:)(v28);
          _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000022, "able.ColumnNames.swift" + 0x8000000000000000, "CreateML/MLDataTable.ColumnNames.swift", 38, 2, 17, 0);
          BUG();
        }
        swift_release();
        swift_retain();
        uint64_t v7 = CMLSequence.size.getter();
        uint64_t v8 = specialized RandomAccessCollection<>.distance(from:to:)(0, v7);
        swift_release();
        if (v4 >= v8) {
          BUG();
        }
        uint64_t v31 = v4;
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
        unint64_t v11 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)object);
        BOOL v12 = (v10 & 1) == 0;
        BOOL v13 = __OFADD__(_swiftEmptyDictionarySingleton[2], v12);
        Swift::Int v14 = _swiftEmptyDictionarySingleton[2] + v12;
        if (v13) {
          BUG();
        }
        char v15 = v10;
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, Int>);
        if (_NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v14))
        {
          unint64_t v11 = specialized __RawDictionaryStorage.find<A>(_:)(countAndFlagsBits, (uint64_t)object);
          if ((v15 & 1) != (v16 & 1))
          {
            KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
            BUG();
          }
        }
        if (v15)
        {
          *(void *)(_swiftEmptyDictionarySingleton[7] + 8 * v11) = v31;
          uint64_t v17 = v31;
        }
        else
        {
          _swiftEmptyDictionarySingleton[(v11 >> 6) + 8] |= 1 << v11;
          uint64_t v18 = _swiftEmptyDictionarySingleton[6];
          uint64_t v19 = 16 * v11;
          *(void *)(v18 + v19) = countAndFlagsBits;
          *(void *)(v18 + v19 + 8) = object;
          *(void *)(_swiftEmptyDictionarySingleton[7] + 8 * v11) = v31;
          uint64_t v20 = _swiftEmptyDictionarySingleton[2];
          BOOL v13 = __OFADD__(1, v20);
          uint64_t v21 = v20 + 1;
          if (v13) {
            BUG();
          }
          uint64_t v17 = v31;
          _swiftEmptyDictionarySingleton[2] = v21;
          swift_bridgeObjectRetain(object);
        }
        uint64_t v4 = v17 + 1;
        swift_bridgeObjectRelease(object);
        swift_bridgeObjectRelease(0x8000000000000000);
        swift_retain();
        uint64_t v22 = CMLSequence.size.getter();
        uint64_t v23 = specialized RandomAccessCollection<>.distance(from:to:)(0, v22);
        swift_release();
      }
      while (v4 != v23);
    }
    swift_release();
    uint64_t v24 = *(void *)(v29 + 32);
    *(void *)(v29 + 32) = _swiftEmptyDictionarySingleton;
    swift_bridgeObjectRelease(v24);
    uint64_t v1 = *(void *)(v29 + 32);
    if (!v1) {
      BUG();
    }
  }
  return swift_bridgeObjectRetain(v1);
}

uint64_t _DataTable.init(impl:)(uint64_t a1)
{
  uint64_t result = v1;
  *(_OWORD *)(v1 + 24) = 0;
  *(void *)(v1 + 16) = a1;
  return result;
}

Swift::Void __swiftcall _DataTable.columnNamesDidChange()()
{
  uint64_t v1 = *(void *)(v0 + 24);
  *(void *)(v0 + 24) = 0;
  swift_release(v1);
  uint64_t v2 = *(void *)(v0 + 32);
  *(void *)(v0 + 32) = 0;
  swift_bridgeObjectRelease(v2);
}

void *_DataTable.deinit()
{
  swift_release(v0[2]);
  swift_release(v0[3]);
  swift_bridgeObjectRelease(v0[4]);
  return v0;
}

uint64_t _DataTable.__deallocating_deinit()
{
  _DataTable.deinit();
  return swift_deallocClassInstance(v0, 40, 7);
}

uint64_t MLDataTable.error.getter()
{
  if (*((unsigned char *)v0 + 8) != 1) {
    return 0;
  }
  uint64_t v1 = *v0;
  swift_errorRetain(*v0);
  return v1;
}

char MLDataTable.isValid.getter()
{
  return *(unsigned char *)(v0 + 8) ^ 1;
}

void MLDataTable.willMutate()()
{
  if (!*((unsigned char *)v0 + 8))
  {
    uint64_t v1 = *v0;
    swift_retain(*v0);
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v1);
    swift_release(v1);
    if (!isUniquelyReferenced_nonNull_native)
    {
      uint64_t v3 = *v0;
      int v4 = *((_DWORD *)v0 + 2);
      outlined copy of Result<_DataTable, Error>(*v0, v4);
      uint64_t empty = tc_v1_sframe_create_empty(0);
      if (!empty) {
        BUG();
      }
      uint64_t v6 = empty;
      uint64_t v7 = type metadata accessor for CMLTable();
      uint64_t v8 = swift_allocObject(v7, 24, 7);
      *(void *)(v8 + 16) = v6;
      uint64_t v9 = type metadata accessor for _DataTable();
      uint64_t v10 = swift_allocObject(v9, 40, 7);
      *(_OWORD *)(v10 + 24) = 0;
      *(void *)(v10 + 16) = v8;
      swift_retain(v10);
      char v56 = v4;
      outlined consume of Result<_DataTable, Error>(v3, v4);
      uint64_t v51 = v10;
      uint64_t *v0 = v10;
      BOOL v58 = v0;
      *((unsigned char *)v0 + 8) = 0;
      char v63 = v4;
      uint64_t v11 = v3;
      if (v4)
      {
        outlined copy of Result<_DataTable, Error>(v3, 1);
        uint64_t v12 = tc_v1_flex_list_create(0);
        if (!v12) {
          BUG();
        }
        uint64_t v13 = v12;
        outlined consume of Result<_DataTable, Error>(v3, 1);
        uint64_t v14 = type metadata accessor for CMLSequence();
        uint64_t v15 = swift_allocObject(v14, 25, 7);
        *(void *)(v15 + 16) = v13;
        *(unsigned char *)(v15 + 24) = 1;
      }
      else
      {
        outlined copy of Result<_DataTable, Error>(v3, 0);
        _DataTable.columnNames.getter();
        outlined consume of Result<_DataTable, Error>(v3, 0);
        uint64_t v15 = v65;
      }
      swift_retain(v15);
      uint64_t v16 = CMLSequence.size.getter();
      uint64_t v17 = specialized RandomAccessCollection<>.distance(from:to:)(0, v16);
      swift_release(v15);
      if (v17)
      {
        uint64_t v18 = 0;
        uint64_t v52 = v3;
        uint64_t v50 = v15;
        while (1)
        {
          uint64_t v19 = CMLSequence.value(at:)(v18);
          uint64_t v57 = v18;
          Swift::String v20 = CMLFeatureValue.stringValue()();
          uint64_t countAndFlagsBits = v20._countAndFlagsBits;
          uint64_t object = v20._object;
          if (v21)
          {
            swift_errorRelease(v21);
            swift_release(v19);
            *(void *)&long long v65 = 0;
            *((void *)&v65 + 1) = 0xE000000000000000;
            _StringGuts.grow(_:)(37);
            swift_bridgeObjectRelease(*((void *)&v65 + 1));
            *(void *)&long long v65 = 0xD000000000000022;
            *((void *)&v65 + 1) = "able.ColumnNames.swift" + 0x8000000000000000;
            v47._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
            char v48 = v47._object;
            String.append(_:)(v47);
            swift_bridgeObjectRelease(v48);
            v49._uint64_t countAndFlagsBits = 46;
            v49._uint64_t object = (void *)0xE100000000000000;
            String.append(_:)(v49);
            _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v65, *((void *)&v65 + 1), "CreateML/MLDataTable.ColumnNames.swift", 38, 2, 17, 0);
            BUG();
          }
          swift_release(v19);
          swift_retain(v15);
          uint64_t v22 = CMLSequence.size.getter();
          uint64_t v23 = specialized RandomAccessCollection<>.distance(from:to:)(0, v22);
          swift_release(v15);
          if (v57 >= v23) {
            BUG();
          }
          if ((v56 & 1) == 0) {
            break;
          }
          outlined copy of Result<_DataTable, Error>(v11, 1);
          swift_willThrow();
          *(void *)&long long v65 = 0;
          *((void *)&v65 + 1) = 0xE000000000000000;
          _StringGuts.grow(_:)(34);
          swift_bridgeObjectRelease(*((void *)&v65 + 1));
          *(void *)&long long v65 = 0xD00000000000001FLL;
          *((void *)&v65 + 1) = "ml.activityclassifier" + 0x8000000000000000;
          unint64_t v25 = object;
          String.append(_:)((Swift::String)__PAIR128__((unint64_t)object, countAndFlagsBits));
          v26._uint64_t countAndFlagsBits = 34;
          v26._uint64_t object = (void *)0xE100000000000000;
          String.append(_:)(v26);
          long long v53 = v65;
          uint64_t v27 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v59 = swift_allocError(&type metadata for MLCreateError, v27, 0, 0);
          *(_OWORD *)uint64_t v28 = v53;
          *(_OWORD *)(v28 + 16) = 0;
          *(_OWORD *)(v28 + 32) = 0;
          *(unsigned char *)(v28 + 48) = 1;
          outlined consume of Result<_DataTable, Error>(v52, v63);
          uint64_t v29 = *v58;
          if (*((unsigned char *)v58 + 8))
          {
            char v61 = 1;
LABEL_17:
            *(void *)&long long v65 = v29;
            uint64_t v30 = v29;
            outlined copy of Result<_DataTable, Error>(v29, 1);
            swift_errorRetain(v30);
            uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
            uint64_t v32 = _getErrorEmbeddedNSError<A>(_:)(&v65, v31, &protocol self-conformance witness table for Error);
            if (v32)
            {
              uint64_t v33 = v32;
              outlined consume of Result<_DataTable, Error>(v30, 1);
            }
            else
            {
              uint64_t v33 = swift_allocError(v31, &protocol self-conformance witness table for Error, 0, 0);
              *char v43 = v65;
            }
            outlined consume of Result<_DataTable, Error>(v30, 1);
            unint64_t v25 = object;
            char v36 = v61;
            goto LABEL_24;
          }
          *(void *)&long long v65 = 0;
          *((void *)&v65 + 1) = 0xE000000000000000;
          uint64_t v54 = v29;
          outlined copy of Result<_DataTable, Error>(v29, 0);
          _StringGuts.grow(_:)(36);
          swift_bridgeObjectRelease(*((void *)&v65 + 1));
          *(void *)&long long v65 = 0xD000000000000021;
          *((void *)&v65 + 1) = "Duplicate values for key: '" + 0x8000000000000000;
          String.append(_:)((Swift::String)__PAIR128__((unint64_t)object, countAndFlagsBits));
          v34._uint64_t countAndFlagsBits = 39;
          v34._uint64_t object = (void *)0xE100000000000000;
          String.append(_:)(v34);
          Swift::String v62 = (Swift::String)v65;
          uint64_t v33 = swift_allocError(&type metadata for MLCreateError, v27, 0, 0);
          *(Swift::String *)uint64_t v35 = v62;
          *(_OWORD *)(v35 + 16) = 0;
          *(_OWORD *)(v35 + 32) = 0;
          *(unsigned char *)(v35 + 48) = 1;
          swift_willThrow();
          outlined consume of Result<_DataTable, Error>(v54, 0);
          char v36 = 1;
LABEL_24:
          outlined consume of Result<_DataTable, Error>(*v58, *((_DWORD *)v58 + 2));
          swift_bridgeObjectRelease(v25);
          outlined consume of Result<_DataTable, Error>(v59, v36);
          *BOOL v58 = v33;
          *((unsigned char *)v58 + 8) = 1;
          uint64_t v15 = v50;
LABEL_25:
          uint64_t v18 = v57 + 1;
          swift_retain(v15);
          uint64_t v44 = CMLSequence.size.getter();
          uint64_t v45 = specialized RandomAccessCollection<>.distance(from:to:)(0, v44);
          swift_release(v15);
          uint64_t v11 = v52;
          if (v57 + 1 == v45) {
            goto LABEL_28;
          }
        }
        uint64_t v24 = *(void *)(v11 + 16);
        outlined copy of Result<_DataTable, Error>(v11, 0);
        swift_retain(v24);
        uint64_t v37 = v24;
        uint64_t v38 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.column(name:), v24, countAndFlagsBits, (uint64_t)object, (uint64_t (*)(void))type metadata accessor for CMLColumn, (uint64_t (*)(uint64_t))partial apply for specialized closure #1 in _StringGuts.withCString<A>(_:));
        swift_release(v37);
        outlined consume of Result<_DataTable, Error>(v11, 0);
        uint64_t v39 = type metadata accessor for _UntypedColumn();
        uint64_t v40 = swift_allocObject(v39, 24, 7);
        uint64_t v41 = v38;
        uint64_t v42 = v40;
        *(void *)(v40 + 16) = v41;
        uint64_t v29 = *v58;
        if (!*((unsigned char *)v58 + 8))
        {
          uint64_t v46 = v41;
          uint64_t v55 = *v58;
          outlined copy of Result<_DataTable, Error>(*v58, 0);
          outlined copy of Result<_DataTable, Error>(v42, 0);
          swift_retain(v46);
          CMLTable.addColumn(name:_:)(countAndFlagsBits, (uint64_t)object, v46);
          outlined consume of Result<_DataTable, Error>(v42, 0);
          swift_release(v46);
          outlined consume of Result<_DataTable, Error>(v55, 0);
          swift_bridgeObjectRelease(object);
          outlined consume of Result<_DataTable, Error>(v42, 0);
          goto LABEL_25;
        }
        char v61 = 0;
        uint64_t v59 = v40;
        goto LABEL_17;
      }
LABEL_28:
      swift_release(v15);
      _DataTable.columnNamesDidChange()();
      swift_release(v51);
      outlined consume of Result<_DataTable, Error>(v11, v63);
    }
  }
}

uint64_t MLDataTable.addImpl(newColumn:named:)(uint64_t a1, uint64_t a2, void *a3)
{
  uint64_t v4 = *(void *)v3;
  if (*(unsigned char *)(v3 + 8))
  {
    *(void *)&long long v19 = *(void *)v3;
    outlined copy of Result<_DataTable, Error>(v4, 1);
    swift_errorRetain(v4);
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v6 = _getErrorEmbeddedNSError<A>(_:)(&v19, v5, &protocol self-conformance witness table for Error);
    if (v6)
    {
      uint64_t v7 = v6;
      outlined consume of Result<_DataTable, Error>(v4, 1);
    }
    else
    {
      uint64_t v7 = swift_allocError(v5, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v17 = v19;
    }
    char v16 = 1;
    uint64_t v15 = v4;
  }
  else
  {
    if (!*(unsigned char *)(a1 + 8))
    {
      uint64_t v22 = (uint64_t)a3;
      uint64_t v11 = *(void *)a1;
      uint64_t v20 = *(void *)(v4 + 16);
      uint64_t v13 = *(void *)(v11 + 16);
      outlined copy of Result<_DataTable, Error>(v4, 0);
      outlined copy of Result<_DataTable, Error>(v11, 0);
      swift_retain();
      uint64_t v14 = v22;
      uint64_t v22 = v13;
      CMLTable.addColumn(name:_:)(a2, v14, v13);
      outlined consume of Result<_DataTable, Error>(v11, 0);
      swift_release();
      return outlined consume of Result<_DataTable, Error>(v4, 0);
    }
    outlined copy of Result<_DataTable, Error>(v4, 0);
    _StringGuts.grow(_:)(36);
    swift_bridgeObjectRelease(0xE000000000000000);
    *(void *)&long long v19 = 0xD000000000000021;
    *((void *)&v19 + 1) = "Duplicate values for key: '" + 0x8000000000000000;
    v9._uint64_t countAndFlagsBits = a2;
    v9._uint64_t object = a3;
    String.append(_:)(v9);
    v9._uint64_t countAndFlagsBits = 39;
    v9._uint64_t object = (void *)0xE100000000000000;
    String.append(_:)(v9);
    long long v21 = v19;
    v9._uint64_t object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v7 = swift_allocError(&type metadata for MLCreateError, v9._object, 0, 0);
    *(_OWORD *)uint64_t v10 = v19;
    *(_OWORD *)(v10 + 16) = 0;
    *(_OWORD *)(v10 + 32) = 0;
    *(unsigned char *)(v10 + 48) = 1;
    swift_willThrow();
    uint64_t v15 = v4;
    char v16 = 0;
  }
  outlined consume of Result<_DataTable, Error>(v15, v16);
  uint64_t result = outlined consume of Result<_DataTable, Error>(*(void *)v3, *(_DWORD *)(v3 + 8));
  *(void *)uint64_t v3 = v7;
  *(unsigned char *)(v3 + 8) = 1;
  return result;
}

uint64_t specialized MLDataTable.init<A>(uniqueKeysWithValues:)(uint64_t a1)
{
  *(void *)&long long v43 = v2;
  uint64_t v41 = v1;
  uint64_t empty = tc_v1_sframe_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v4 = empty;
  uint64_t v5 = type metadata accessor for CMLTable();
  uint64_t v6 = swift_allocObject(v5, 24, 7);
  *(void *)(v6 + 16) = v4;
  uint64_t v7 = type metadata accessor for _DataTable();
  uint64_t v8 = swift_allocObject(v7, 40, 7);
  *(_OWORD *)(v8 + 24) = 0;
  *(void *)(v8 + 16) = v6;
  specialized _NativeDictionary.makeIterator()(a1);
  uint64_t v9 = v32;
  uint64_t v47 = v33;
  int64_t v44 = v35;
  unint64_t v10 = v36;
  int64_t v46 = (unint64_t)(v34 + 64) >> 6;
  uint64_t v48 = a1;
  swift_bridgeObjectRetain(a1);
  swift_retain();
  uint64_t v42 = v8;
  uint64_t v45 = v32;
  while (1)
  {
    if (v10)
    {
      _BitScanForward64(&v11, v10);
      uint64_t v12 = (v10 - 1) & v10;
      int64_t v13 = v44;
      unint64_t v14 = v11 | (v44 << 6);
      goto LABEL_19;
    }
    int64_t v15 = v44 + 1;
    if (__OFADD__(1, v44)) {
      BUG();
    }
    if (v15 >= v46) {
      break;
    }
    unint64_t v16 = *(void *)(v47 + 8 * v15);
    if (v16)
    {
      int64_t v13 = v44 + 1;
    }
    else
    {
      int64_t v17 = v44 + 2;
      if (v44 + 2 >= v46) {
        break;
      }
      unint64_t v16 = *(void *)(v47 + 8 * v15 + 8);
      if (!v16)
      {
        int64_t v17 = v44 + 3;
        if (v44 + 3 >= v46) {
          break;
        }
        unint64_t v16 = *(void *)(v47 + 8 * v15 + 16);
        if (!v16)
        {
          int64_t v17 = v44 + 4;
          if (v44 + 4 >= v46) {
            break;
          }
          unint64_t v16 = *(void *)(v47 + 8 * v15 + 24);
          if (!v16)
          {
            int64_t v17 = v44 + 5;
            if (v44 + 5 >= v46) {
              break;
            }
            unint64_t v16 = *(void *)(v47 + 8 * v15 + 32);
            if (!v16)
            {
              int64_t v25 = v44 + 6;
              uint64_t v26 = v48;
              while (v25 < v46)
              {
                unint64_t v16 = *(void *)(v47 + 8 * v25++);
                if (v16)
                {
                  int64_t v13 = v25 - 1;
                  goto LABEL_18;
                }
              }
              goto LABEL_30;
            }
          }
        }
      }
      int64_t v13 = v17;
    }
LABEL_18:
    _BitScanForward64(&v18, v16);
    uint64_t v12 = v16 & (v16 - 1);
    unint64_t v14 = v18 + (v13 << 6);
LABEL_19:
    uint64_t v19 = *(void *)(v9 + 56);
    uint64_t v20 = 16 * v14;
    uint64_t v21 = *(void *)(v19 + v20);
    if (*(unsigned char *)(v19 + v20 + 8))
    {
      outlined copy of Result<_DataTable, Error>(*(void *)(v19 + v20), 1);
      swift_release();
      *(void *)&long long v37 = 0;
      *((void *)&v37 + 1) = 0xE000000000000000;
      uint64_t v38 = v21;
      uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
      _print_unlocked<A, B>(_:_:)(&v38, &v37, v27, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
      long long v43 = v37;
      uint64_t v28 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      uint64_t v29 = swift_allocError(&type metadata for MLCreateError, v28, 0, 0);
      *(_OWORD *)uint64_t v30 = v43;
      *(_OWORD *)(v30 + 16) = 0;
      *(_OWORD *)(v30 + 32) = 0;
      *(unsigned char *)(v30 + 48) = 0;
      *(void *)&long long v43 = v29;
      swift_willThrow();
      outlined consume of Result<_DataTable, Error>(v21, 1);
      swift_release();
      swift_bridgeObjectRelease(v48);
      return swift_release();
    }
    unint64_t v40 = v12;
    int64_t v44 = v13;
    uint64_t v22 = *(void *)(v9 + 48);
    uint64_t v23 = *(void *)(v22 + v20 + 8);
    uint64_t v39 = *(void *)(v22 + v20);
    uint64_t v24 = *(void *)(v21 + 16);
    outlined copy of Result<_DataTable, Error>(v21, 0);
    outlined copy of Result<_DataTable, Error>(v21, 0);
    swift_bridgeObjectRetain(v23);
    swift_retain();
    swift_retain();
    CMLTable.addColumn(name:_:)(v39, v23, v24);
    if ((void)v43)
    {
      swift_bridgeObjectRelease(v23);
      swift_release();
      swift_release();
      outlined consume of Result<_DataTable, Error>(v21, 0);
      outlined consume of Result<_DataTable, Error>(v21, 0);
      swift_release();
      swift_bridgeObjectRelease(v48);
      swift_release();
      return swift_release();
    }
    swift_release();
    swift_release();
    outlined consume of Result<_DataTable, Error>(v21, 0);
    outlined consume of Result<_DataTable, Error>(v21, 0);
    swift_bridgeObjectRelease(v23);
    uint64_t v8 = v42;
    uint64_t v9 = v45;
    unint64_t v10 = v40;
  }
  uint64_t v26 = v48;
LABEL_30:
  swift_bridgeObjectRelease(v26);
  swift_release();
  swift_release();
  uint64_t result = (uint64_t)v41;
  *uint64_t v41 = v8;
  *(unsigned char *)(result + 8) = 0;
  return result;
}

uint64_t key path getter for MLDataTable.subscript(_:) : MLDataTable(uint64_t a1, Swift::String *a2)
{
  uint64_t v3 = v2;
  uint64_t v4 = *(void *)a1;
  Swift::String v9 = *a2;
  char v8 = *(unsigned char *)(a1 + 8);
  outlined copy of Result<_DataTable, Error>(*(void *)a1, v8);
  MLDataTable.subscript.getter(v9);
  outlined consume of Result<_DataTable, Error>(v4, v8);
  uint64_t result = v6;
  *(void *)uint64_t v3 = v6;
  *(unsigned char *)(v3 + 8) = v7;
  return result;
}

uint64_t key path setter for MLDataTable.subscript(_:) : MLDataTable(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v9 = a2;
  uint64_t v3 = *a3;
  uint64_t v4 = a3[1];
  char v5 = *(unsigned char *)(a1 + 8);
  uint64_t v7 = *(void *)a1;
  char v8 = v5;
  swift_bridgeObjectRetain(v4);
  outlined copy of Result<_DataTable, Error>(v7, v5);
  return MLDataTable.subscript.setter((uint64_t)&v7, v3, v4);
}

uint64_t MLDataTable.setColumnImpl(newColumn:named:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  uint64_t v30 = a3;
  uint64_t v27 = a2;
  char v5 = *(unsigned char *)(a1 + 8);
  uint64_t v6 = *v3;
  BOOL v7 = *((unsigned char *)v4 + 8) == 0;
  uint64_t v28 = *(void *)a1;
  LOBYTE(v29) = v5;
  if (v7)
  {
    outlined copy of Result<_DataTable, Error>(v6, 0);
    _DataTable.columnNames.getter(v6);
    outlined consume of Result<_DataTable, Error>(v6, 0);
    uint64_t v11 = (uint64_t)v25;
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(v6, 1);
    uint64_t v8 = tc_v1_flex_list_create(0);
    if (!v8) {
      BUG();
    }
    uint64_t v9 = v8;
    uint64_t v10 = type metadata accessor for CMLSequence();
    uint64_t v11 = swift_allocObject(v10, 25, 7);
    *(void *)(v11 + 16) = v9;
    *(unsigned char *)(v11 + 24) = 1;
    outlined consume of Result<_DataTable, Error>(v6, 1);
  }
  v26[0] = v27;
  v26[1] = v30;
  uint64_t v12 = alloca(24);
  int64_t v13 = alloca(32);
  int64_t v25 = v26;
  char v14 = specialized Sequence.contains(where:)((uint64_t (*)(unint64_t *))partial apply for specialized closure #1 in Sequence<>.contains(_:), (uint64_t)&v24, v11);
  swift_release();
  if (v14) {
    MLDataTable.removeImpl(_:)(v27, v30);
  }
  uint64_t v15 = *v4;
  if (*((unsigned char *)v4 + 8))
  {
    v26[0] = *v4;
    outlined copy of Result<_DataTable, Error>(v15, 1);
    swift_errorRetain(v15);
    uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v17 = _getErrorEmbeddedNSError<A>(_:)(v26, v16, &protocol self-conformance witness table for Error);
    if (v17)
    {
      uint64_t v18 = v17;
      outlined consume of Result<_DataTable, Error>(v15, 1);
    }
    else
    {
      uint64_t v18 = swift_allocError(v16, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v22 = v26[0];
    }
    outlined consume of Result<_DataTable, Error>(v15, 1);
    uint64_t result = outlined consume of Result<_DataTable, Error>(*v4, *((_DWORD *)v4 + 2));
    uint64_t *v4 = v18;
    *((unsigned char *)v4 + 8) = 1;
  }
  else
  {
    if (v29)
    {
      swift_retain();
    }
    else
    {
      uint64_t v29 = *(void *)(v15 + 16);
      uint64_t v19 = v28;
      uint64_t v20 = *(void *)(v28 + 16);
      outlined copy of Result<_DataTable, Error>(v15, 0);
      outlined copy of Result<_DataTable, Error>(v19, 0);
      swift_retain();
      uint64_t v21 = v30;
      uint64_t v30 = v20;
      CMLTable.addColumn(name:_:)(v27, v21, v20);
      outlined consume of Result<_DataTable, Error>(v28, 0);
      swift_release();
    }
    return outlined consume of Result<_DataTable, Error>(v15, 0);
  }
  return result;
}

void (*MLDataTable.subscript.modify(void *a1, uint64_t a2, void *a3))(uint64_t **a1, char a2)
{
  char v5 = malloc(0x28uLL);
  *a1 = v5;
  void v5[4] = v3;
  void v5[3] = a3;
  v5[2] = a2;
  v6._uint64_t countAndFlagsBits = a2;
  v6._uint64_t object = a3;
  MLDataTable.subscript.getter(v6);
  return MLDataTable.subscript.modify;
}

void MLDataTable.subscript.modify(uint64_t **a1, char a2)
{
  uint64_t v2 = *a1;
  uint64_t v3 = (*a1)[3];
  uint64_t v14 = **a1;
  unsigned __int8 v4 = *((unsigned char *)v2 + 8);
  swift_bridgeObjectRetain(v3);
  uint64_t v15 = v2[2];
  uint64_t v5 = v2[4];
  if (a2)
  {
    int v16 = v4;
    uint64_t v6 = v14;
    outlined copy of Result<_DataTable, Error>(v14, v4);
    MLDataTable.willMutate()();
    uint64_t v12 = v14;
    char v13 = v4 & 1;
    MLDataTable.setColumnImpl(newColumn:named:)((uint64_t)&v12, v15, v3);
    swift_bridgeObjectRelease(v3);
    outlined consume of Result<_DataTable, Error>(v6, v16);
    if (!*(unsigned char *)(v5 + 8))
    {
      uint64_t v7 = *(void *)v2[4];
      outlined copy of Result<_DataTable, Error>(v7, 0);
      _DataTable.columnNamesDidChange()();
      outlined consume of Result<_DataTable, Error>(v7, 0);
    }
    uint64_t v8 = *v2;
    int v9 = *((_DWORD *)v2 + 2);
    goto LABEL_7;
  }
  MLDataTable.willMutate()();
  uint64_t v10 = v14;
  uint64_t v12 = v14;
  char v13 = v4 & 1;
  MLDataTable.setColumnImpl(newColumn:named:)((uint64_t)&v12, v15, v3);
  swift_bridgeObjectRelease(v3);
  outlined consume of Result<_DataTable, Error>(v10, v4);
  if (!*(unsigned char *)(v5 + 8))
  {
    uint64_t v11 = *(void *)v2[4];
    outlined copy of Result<_DataTable, Error>(v11, 0);
    _DataTable.columnNamesDidChange()();
    uint64_t v8 = v11;
    LOBYTE(v9) = 0;
LABEL_7:
    outlined consume of Result<_DataTable, Error>(v8, v9);
  }
  free(v2);
}

{
  uint64_t *v2;
  uint64_t v3;
  char v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  char v8;
  uint64_t v9;

  uint64_t v2 = *a1;
  uint64_t v3 = **a1;
  unsigned __int8 v4 = *((unsigned char *)*a1 + 8);
  int v9 = (*a1)[6];
  uint64_t v5 = v2[3];
  uint64_t v6 = v2[2];
  uint64_t v7 = v3;
  uint64_t v8 = v4 & 1;
  swift_bridgeObjectRetain(v5);
  if (a2)
  {
    outlined copy of Result<_DataTable, Error>(v3, v4);
    MLDataTable.subscript.setter((uint64_t)&v7, v6, v5);
    outlined consume of Result<_DataTable, Error>(*v2, *((_DWORD *)v2 + 2));
  }
  else
  {
    MLDataTable.subscript.setter((uint64_t)&v7, v6, v5);
  }
  free(v2);
}

uint64_t key path getter for MLDataTable.subscript<A>(_:) : <A>MLDataTableA(uint64_t a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v4 = v3;
  uint64_t v15 = *(uint64_t *)((char *)a2 + a3 - 16);
  uint64_t v16 = *(uint64_t *)((char *)a2 + a3 - 8);
  uint64_t v6 = *a2;
  uint64_t v7 = (void *)a2[1];
  uint64_t v5 = *(void *)a1;
  char v14 = *(unsigned char *)(a1 + 8);
  outlined copy of Result<_DataTable, Error>(*(void *)a1, v14);
  v8._uint64_t countAndFlagsBits = v6;
  v8._uint64_t object = v7;
  MLDataTable.subscript.getter(v8, v15, v16, v9, v10);
  outlined consume of Result<_DataTable, Error>(v5, v14);
  uint64_t result = v12;
  *(void *)uint64_t v4 = v12;
  *(unsigned char *)(v4 + 8) = v13;
  return result;
}

uint64_t key path setter for MLDataTable.subscript<A>(_:) : <A>MLDataTableA(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v9 = a2;
  uint64_t v3 = *a3;
  uint64_t v4 = a3[1];
  char v5 = *(unsigned char *)(a1 + 8);
  uint64_t v7 = *(void *)a1;
  char v8 = v5;
  swift_bridgeObjectRetain(v4);
  outlined copy of Result<_DataTable, Error>(v7, v5);
  return MLDataTable.subscript.setter((uint64_t)&v7, v3, v4);
}

void (*MLDataTable.subscript.modify(void *a1, uint64_t a2, void *a3, uint64_t a4, uint64_t a5))(uint64_t **a1, char a2)
{
  uint64_t v7 = malloc(0x38uLL);
  *a1 = v7;
  void v7[6] = v5;
  v7[5] = a5;
  v7[4] = a4;
  v7[3] = a3;
  v7[2] = a2;
  v8._uint64_t countAndFlagsBits = a2;
  v8._uint64_t object = a3;
  MLDataTable.subscript.getter(v8, a4, a5, v9, v10);
  return MLDataTable.subscript.modify;
}

uint64_t MLDataTable.removeImpl(_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(void *)v2;
  if (*(unsigned char *)(v2 + 8))
  {
    v12[0] = *(void *)v2;
    outlined copy of Result<_DataTable, Error>(v3, 1);
    swift_errorRetain(v3);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v5 = _getErrorEmbeddedNSError<A>(_:)(v12, v4, &protocol self-conformance witness table for Error);
    if (v5)
    {
      uint64_t v6 = v5;
      outlined consume of Result<_DataTable, Error>(v3, 1);
    }
    else
    {
      uint64_t v6 = swift_allocError(v4, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v10 = v12[0];
    }
    outlined consume of Result<_DataTable, Error>(v3, 1);
    char v9 = 1;
  }
  else
  {
    uint64_t v7 = *(void *)(v3 + 16);
    outlined copy of Result<_DataTable, Error>(*(void *)v2, 0);
    swift_retain();
    uint64_t v8 = v7;
    uint64_t v6 = 0;
    specialized String.withCString<A>(_:)(a1, a2, v8);
    char v9 = 0;
    outlined consume of Result<_DataTable, Error>(v3, 0);
  }
  return outlined consume of Result<(), Error>(v6, v9);
}

uint64_t MLDataTable.renameImpl(named:to:)(Swift::String named, Swift::String to)
{
  uint64_t v3 = *(void *)v2;
  if (*(unsigned char *)(v2 + 8))
  {
    v11[0] = *(void *)v2;
    outlined copy of Result<_DataTable, Error>(v3, 1);
    swift_errorRetain(v3);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v5 = _getErrorEmbeddedNSError<A>(_:)(v11, v4, &protocol self-conformance witness table for Error);
    if (v5)
    {
      uint64_t v6 = v5;
      outlined consume of Result<_DataTable, Error>(v3, 1);
    }
    else
    {
      uint64_t v6 = swift_allocError(v4, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v10 = v11[0];
    }
    outlined consume of Result<_DataTable, Error>(v3, 1);
    goto LABEL_8;
  }
  uint64_t countAndFlagsBits = to._countAndFlagsBits;
  v11[1] = *(void *)(v3 + 16);
  toa = to._object;
  swift_retain();
  v8._uint64_t countAndFlagsBits = countAndFlagsBits;
  v8._uint64_t object = toa;
  CMLTable.renameColumn(named:to:)(named, v8);
  uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 0);
  if (v6)
  {
LABEL_8:
    uint64_t result = outlined consume of Result<_DataTable, Error>(*(void *)v2, *(_DWORD *)(v2 + 8));
    *(void *)uint64_t v2 = v6;
    *(unsigned char *)(v2 + 8) = 1;
  }
  return result;
}

Swift::Void __swiftcall MLDataTable.removeColumn(named:)(Swift::String named)
{
  MLDataTable.willMutate()();
  MLDataTable.removeImpl(_:)(named._countAndFlagsBits, (uint64_t)named._object);
  if (!*(unsigned char *)(v1 + 8))
  {
    uint64_t v2 = *(void *)v1;
    outlined copy of Result<_DataTable, Error>(v2, 0);
    _DataTable.columnNamesDidChange()();
    outlined consume of Result<_DataTable, Error>(v2, 0);
  }
}

uint64_t MLDataTable.randomSample(by:seed:)(uint64_t a1, double a2)
{
  uint64_t v4 = v2;
  uint64_t v5 = *(void *)v3;
  if (*(unsigned char *)(v3 + 8))
  {
    v19[0] = *(void *)v3;
    outlined copy of Result<_DataTable, Error>(v5, 1);
    swift_errorRetain(v5);
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v7 = _getErrorEmbeddedNSError<A>(_:)(v19, v6, &protocol self-conformance witness table for Error);
    if (v7)
    {
      uint64_t v8 = v7;
      outlined consume of Result<_DataTable, Error>(v5, 1);
    }
    else
    {
      uint64_t v8 = swift_allocError(v6, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v11 = v19[0];
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v5, 1);
    char v13 = 1;
  }
  else
  {
    *(double *)&v19[1] = a2;
    if (a1 < 0)
    {
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, "Negative value is not representable", 35, 2, "Swift/Integers.swift", 20, 2, 3451, 1);
      BUG();
    }
    uint64_t v9 = *(void *)(*(void *)(v5 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(v5, 0);
    uint64_t v10 = specialized handling<A, B, C, D>(_:_:_:_:)(v9, a1);
    uint64_t v14 = v10;
    if (!v10) {
      BUG();
    }
    char v13 = 0;
    uint64_t v15 = type metadata accessor for CMLTable();
    uint64_t v16 = swift_allocObject(v15, 24, 7);
    *(void *)(v16 + 16) = v14;
    uint64_t v17 = v16;
    uint64_t v18 = type metadata accessor for _DataTable();
    uint64_t v8 = swift_allocObject(v18, 40, 7);
    *(_OWORD *)(v8 + 24) = 0;
    *(void *)(v8 + 16) = v17;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v5, 0);
  }
  *(void *)uint64_t v4 = v8;
  *(unsigned char *)(v4 + 8) = v13;
  return result;
}

uint64_t MLDataTable.intersect<A>(_:of:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return MLDataTable.exclude<A>(_:of:)(a1, a2, a3, a4, a5, 0);
}

uint64_t MLDataTable.exclude<A>(_:of:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, int a6)
{
  uint64_t v13 = a3;
  uint64_t v15 = v6;
  uint64_t v14 = a2;
  int v16 = a6;
  uint64_t v11 = a1;
  uint64_t v7 = type metadata accessor for Array(0, a4);
  swift_bridgeObjectRetain(a1);
  swift_getWitnessTable(&protocol conformance descriptor for [A], v7);
  MLUntypedColumn.init<A>(_:)((uint64_t)&v11, v7);
  uint64_t v11 = v9;
  char v12 = v10;
  MLDataTable.filtered(isExcluding:values:in:)(v16, (uint64_t)&v11, v14, v13);
  return outlined consume of Result<_DataTable, Error>(v9, v10);
}

char MLDataTable.filtered(isExcluding:values:in:)(char a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v17 = v4;
  uint64_t v6 = *(void *)v5;
  if (*(unsigned char *)(v5 + 8))
  {
    v19[0] = *(void *)v5;
    outlined copy of Result<_DataTable, Error>(v6, 1);
    swift_errorRetain(v6);
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v8 = _getErrorEmbeddedNSError<A>(_:)(v19, v7, &protocol self-conformance witness table for Error);
    if (v8)
    {
      uint64_t v9 = v8;
      outlined consume of Result<_DataTable, Error>(v6, 1);
    }
    else
    {
      uint64_t v9 = swift_allocError(v7, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v14 = v19[0];
    }
    outlined consume of Result<_DataTable, Error>(v6, 1);
    char result = 1;
  }
  else
  {
    uint64_t v18 = *(void *)a2;
    char v12 = *(unsigned char *)(a2 + 8);
    uint64_t v16 = v6;
    swift_retain();
    closure #1 in MLDataTable.filtered(isExcluding:values:in:)((uint64_t)&v16, v18, v12, a3, a4, a1);
    outlined consume of Result<_DataTable, Error>(v6, 0);
    uint64_t v9 = v19[0];
    char result = 0;
  }
  uint64_t v15 = v17;
  *uint64_t v17 = v9;
  *((unsigned char *)v15 + 8) = result;
  return result;
}

uint64_t closure #1 in MLDataTable.filtered(isExcluding:values:in:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, uint64_t a5, char a6)
{
  if (a3)
  {
    *(void *)&long long v24 = 0;
    *((void *)&v24 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(85);
    v14._char object = "el's set of labels." + 0x8000000000000000;
    v14._uint64_t countAndFlagsBits = 0xD000000000000052;
    String.append(_:)(v14);
    v23._uint64_t countAndFlagsBits = 0;
    v23._char object = (void *)0xE000000000000000;
    v25[0] = a2;
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    _print_unlocked<A, B>(_:_:)(v25, &v23, v15, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    char object = (char)v23._object;
    String.append(_:)(v23);
    swift_bridgeObjectRelease(object);
    v14._uint64_t countAndFlagsBits = 39;
    v14._char object = (void *)0xE100000000000000;
    String.append(_:)(v14);
    long long v28 = v24;
    v14._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v14._object, 0, 0);
    *(_OWORD *)uint64_t v17 = v28;
    *(_OWORD *)(v17 + 16) = 0;
    *(_OWORD *)(v17 + 32) = 0;
    *(unsigned char *)(v17 + 48) = 0;
    return swift_willThrow(&type metadata for MLCreateError, v14._object, v17, v18, v19, v20);
  }
  else
  {
    uint64_t v27 = v6;
    *(void *)&long long v28 = *(void *)(*(void *)a1 + 16);
    uint64_t v11 = *(void *)(a2 + 16);
    uint64_t v26 = a4;
    v25[1] = v7;
    outlined copy of Result<_DataTable, Error>(a2, 0);
    swift_retain();
    uint64_t v12 = CMLTable.filtered(_:columnName:isExcluding:)(v11, v26, a5, a6);
    if (v7)
    {
      swift_release();
      return outlined consume of Result<_DataTable, Error>(a2, 0);
    }
    else
    {
      uint64_t v21 = v12;
      outlined consume of Result<_DataTable, Error>(a2, 0);
      swift_release();
      uint64_t v22 = type metadata accessor for _DataTable();
      uint64_t result = swift_allocObject(v22, 40, 7);
      *(_OWORD *)(result + 24) = 0;
      *(void *)(result + 16) = v21;
      *uint64_t v27 = result;
    }
  }
  return result;
}

uint64_t MLDataTable.join(with:on:type:)(uint64_t a1, uint64_t a2, unsigned char *a3)
{
  uint64_t v6 = *(void *)a1;
  char v7 = *(unsigned char *)(a1 + 8);
  uint64_t v8 = *(void *)v4;
  char v9 = *(unsigned char *)(v4 + 8);
  uint64_t v16 = v3;
  switch(*a3)
  {
    case 0:
      char v10 = v7;
      uint64_t v11 = 0x72656E6E69;
      goto LABEL_6;
    case 1:
      char v10 = v7;
      uint64_t v11 = 0x726574756FLL;
      goto LABEL_6;
    case 2:
      char v10 = v7;
      v19[0] = 1952867692;
      uint64_t v12 = 0xE400000000000000;
      goto LABEL_7;
    case 3:
      char v10 = v7;
      uint64_t v11 = 0x7468676972;
LABEL_6:
      v19[0] = v11;
      uint64_t v12 = 0xE500000000000000;
LABEL_7:
      char v17 = v12;
      v19[1] = v12;
      swift_bridgeObjectRetain(a2);
      outlined copy of Result<_DataTable, Error>(v8, v9);
      outlined copy of Result<_DataTable, Error>(v6, v10);
      uint64_t v18 = specialized binaryDo<A, B, C>(_:_:_:)(v8, v9, v6, v10, a2, v19);
      char v14 = v13;
      outlined consume of Result<_DataTable, Error>(v6, v10);
      outlined consume of Result<_DataTable, Error>(v8, v9);
      swift_bridgeObjectRelease(v17);
      uint64_t result = v16;
      *(void *)uint64_t v16 = v18;
      *(unsigned char *)(v16 + 8) = v14 & 1;
      return result;
  }
}

uint64_t closure #1 in MLDataTable.join(with:on:type:)(uint64_t *a1, uint64_t *a2, uint64_t a3, uint64_t *a4)
{
  uint64_t v76 = a4;
  char v7 = v4;
  uint64_t v89 = v5;
  uint64_t v8 = *a1;
  uint64_t v82 = *a2;
  uint64_t v9 = tc_v1_flex_list_create(0);
  if (!v9) {
    BUG();
  }
  uint64_t v10 = v9;
  uint64_t v78 = v7;
  uint64_t v11 = type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject(v11, v71);
  uint64_t v86 = inited;
  *(void *)(inited + 16) = v10;
  *(unsigned char *)(inited + 24) = 1;
  uint64_t v13 = *(void *)(a3 + 16);
  uint64_t v77 = v8;
  if (v13)
  {
    uint64_t v87 = (uint64_t *)type metadata accessor for CMLFeatureValue();
    swift_bridgeObjectRetain(a3);
    uint64_t countAndFlagsBits = a3;
    char v14 = (uint64_t *)(a3 + 40);
    while (1)
    {
      uint64_t v88 = v13;
      uint64_t v15 = *(v14 - 1);
      uint64_t v16 = *v14;
      swift_bridgeObjectRetain_n(*v14, 2);
      uint64_t v17 = v89;
      uint64_t v18 = CMLFeatureValue.__allocating_init(_:)(v15, v16);
      uint64_t v19 = v17;
      if (v17) {
        break;
      }
      uint64_t v20 = v18;
      swift_bridgeObjectRelease(v16);
      CMLSequence.append(_:)(v20);
      uint64_t v89 = 0;
      swift_release();
      v14 += 2;
      uint64_t v13 = v88 - 1;
      if (v88 == 1)
      {
        swift_bridgeObjectRelease(countAndFlagsBits);
        goto LABEL_30;
      }
    }
    Swift::String v62 = "CreateML/MLDataValueConvertible.swift";
    uint64_t v63 = 37;
    uint64_t v64 = 170;
    goto LABEL_40;
  }
  _DataTable.columnNames.getter(v11);
  unint64_t v21 = v79;
  _DataTable.columnNames.getter(v11);
  uint64_t v88 = v79;
  swift_retain_n(v21);
  uint64_t v22 = CMLSequence.size.getter();
  uint64_t v23 = specialized RandomAccessCollection<>.distance(from:to:)(0, v22);
  swift_release();
  if (v23)
  {
    uint64_t v24 = 0;
    uint64_t v19 = v89;
    unint64_t v81 = v21;
    while (1)
    {
      uint64_t v25 = v19;
      CMLSequence.value(at:)(v24);
      if (v19)
      {
LABEL_36:
        Swift::String v62 = "CreateML/SequenceType.swift";
        uint64_t v63 = 27;
        uint64_t v64 = 76;
        uint64_t v65 = v25;
        goto LABEL_41;
      }
      uint64_t v84 = v24;
      Swift::String v26 = CMLFeatureValue.stringValue()();
      uint64_t countAndFlagsBits = v26._countAndFlagsBits;
      char object = v26._object;
      uint64_t v19 = v27;
      if (v27) {
        break;
      }
      swift_release();
      swift_retain();
      uint64_t v28 = CMLSequence.size.getter();
      uint64_t v29 = specialized RandomAccessCollection<>.distance(from:to:)(0, v28);
      swift_release();
      if (v84 >= v29) {
        BUG();
      }
      swift_retain_n(v88);
      uint64_t v30 = CMLSequence.size.getter();
      uint64_t v31 = specialized RandomAccessCollection<>.distance(from:to:)(0, v30);
      swift_release();
      if (!v31)
      {
LABEL_21:
        swift_bridgeObjectRelease((_BYTE)object);
        unint64_t v21 = v81;
        goto LABEL_26;
      }
      uint64_t v32 = 0;
      while (1)
      {
        uint64_t v25 = v19;
        CMLSequence.value(at:)(v32);
        if (v19) {
          goto LABEL_36;
        }
        uint64_t v87 = (uint64_t *)v32;
        Swift::String v33 = CMLFeatureValue.stringValue()();
        uint64_t v89 = v34;
        if (v34)
        {
          swift_errorRelease(v89);
          swift_release();
          unint64_t v79 = 0;
          uint64_t v80 = (char *)0xE000000000000000;
          _StringGuts.grow(_:)(37);
          swift_bridgeObjectRelease((_BYTE)v80);
          unint64_t v79 = 0xD000000000000022;
          uint64_t v80 = "able.ColumnNames.swift" + 0x8000000000000000;
          uint64_t v66 = v87;
          goto LABEL_38;
        }
        uint64_t v35 = v33._countAndFlagsBits;
        unint64_t v36 = v33._object;
        swift_release();
        swift_retain();
        uint64_t v37 = CMLSequence.size.getter();
        uint64_t v38 = specialized RandomAccessCollection<>.distance(from:to:)(0, v37);
        swift_release();
        if ((uint64_t)v87 >= v38) {
          BUG();
        }
        uint64_t v39 = (uint64_t)object;
        if (v35 == countAndFlagsBits && v36 == object)
        {
          swift_release();
          swift_bridgeObjectRelease(v39);
          uint64_t v43 = v89;
          goto LABEL_24;
        }
        char v40 = _stringCompareWithSmolCheck(_:_:expecting:)(v35, v36, countAndFlagsBits, object, 0);
        swift_bridgeObjectRelease((_BYTE)v36);
        if (v40) {
          break;
        }
        uint64_t v32 = (uint64_t)v87 + 1;
        swift_retain();
        uint64_t v41 = CMLSequence.size.getter();
        uint64_t v42 = specialized RandomAccessCollection<>.distance(from:to:)(0, v41);
        swift_release();
        uint64_t v19 = v89;
        if (v32 == v42) {
          goto LABEL_21;
        }
      }
      swift_release();
      uint64_t v43 = v89;
      uint64_t v39 = (uint64_t)object;
LABEL_24:
      type metadata accessor for CMLFeatureValue();
      swift_bridgeObjectRetain(v39);
      char v44 = v39;
      uint64_t v45 = CMLFeatureValue.__allocating_init(_:)(countAndFlagsBits, v39);
      uint64_t v89 = v43;
      unint64_t v21 = v81;
      if (v43)
      {
        Swift::String v62 = "CreateML/MLDataValueConvertible.swift";
        uint64_t v63 = 37;
        uint64_t v64 = 170;
        uint64_t v65 = v89;
LABEL_41:
        swift_unexpectedError(v65, v62, v63, 1, v64);
        BUG();
      }
      uint64_t v46 = v45;
      swift_bridgeObjectRelease(v44);
      uint64_t v87 = (uint64_t *)v46;
      uint64_t v47 = v89;
      CMLSequence.append(_:)(v46);
      uint64_t v19 = v47;
      if (v47)
      {
        swift_release();
        Swift::String v62 = "CreateML/MLDataTable.swift";
        uint64_t v63 = 26;
        uint64_t v64 = 891;
LABEL_40:
        uint64_t v65 = v19;
        goto LABEL_41;
      }
LABEL_26:
      uint64_t v24 = v84 + 1;
      swift_release();
      swift_retain();
      uint64_t v48 = CMLSequence.size.getter();
      uint64_t v49 = specialized RandomAccessCollection<>.distance(from:to:)(0, v48);
      swift_release();
      if (v24 == v49) {
        goto LABEL_29;
      }
    }
    swift_errorRelease(v27);
    swift_release();
    unint64_t v79 = 0;
    uint64_t v80 = (char *)0xE000000000000000;
    _StringGuts.grow(_:)(37);
    swift_bridgeObjectRelease((_BYTE)v80);
    unint64_t v79 = 0xD000000000000022;
    uint64_t v80 = "able.ColumnNames.swift" + 0x8000000000000000;
    uint64_t v66 = (void *)v84;
LABEL_38:
    uint64_t v75 = v66;
    v67._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char v68 = (char)v67._object;
    String.append(_:)(v67);
    swift_bridgeObjectRelease(v68);
    v69._uint64_t countAndFlagsBits = 46;
    v69._char object = (void *)0xE100000000000000;
    String.append(_:)(v69);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v79, v80, "CreateML/MLDataTable.ColumnNames.swift", 38, 2, 17, 0);
    BUG();
  }
  uint64_t v19 = v89;
LABEL_29:
  uint64_t v89 = v19;
  swift_release_n(v21);
  swift_release();
LABEL_30:
  uint64_t v87 = &v70;
  uint64_t v50 = *(void *)(v77 + 16);
  uint64_t v51 = *(void *)(v82 + 16);
  uint64_t v88 = *v76;
  uint64_t v52 = v76[1];
  long long v53 = alloca(40);
  uint64_t v54 = alloca(48);
  uint64_t v72 = v50;
  uint64_t v73 = v51;
  uint64_t v74 = v86;
  swift_retain();
  swift_retain();
  swift_bridgeObjectRetain(v52);
  uint64_t v55 = v89;
  uint64_t v56 = specialized String.withCString<A>(_:)((uint64_t (*)(void, void, void))partial apply for closure #1 in CMLTable.init(joiningMultiple:and:columnNames:method:), (uint64_t)&v70, v88, v52);
  if (v55)
  {
    swift_release();
    swift_release();
    swift_release();
    return swift_bridgeObjectRelease(v52);
  }
  else
  {
    uint64_t v58 = v56;
    swift_release();
    swift_release();
    swift_bridgeObjectRelease(v52);
    swift_release();
    uint64_t v59 = type metadata accessor for CMLTable();
    uint64_t v60 = swift_allocObject(v59, 24, 7);
    *(void *)(v60 + 16) = v58;
    uint64_t v61 = type metadata accessor for _DataTable();
    uint64_t result = swift_allocObject(v61, 40, 7);
    *(_OWORD *)(result + 24) = 0;
    *(void *)(result + 16) = v60;
    *uint64_t v78 = result;
  }
  return result;
}

BOOL static MLDataTable.JoinType.== infix(_:_:)(unsigned char *a1, unsigned char *a2)
{
  return *a1 == *a2;
}

void MLDataTable.JoinType.hash(into:)()
{
  Hasher._combine(_:)(*v0);
}

Swift::Int MLDataTable.JoinType.hashValue.getter()
{
  Swift::UInt v1 = *v0;
  Hasher.init(_seed:)(0);
  Hasher._combine(_:)(v1);
  return Hasher._finalize()();
}

BOOL protocol witness for static Equatable.== infix(_:_:) in conformance MLDataTable.JoinType(unsigned char *a1, unsigned char *a2)
{
  return static MLDataTable.JoinType.== infix(_:_:)(a1, a2);
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLDataTable.JoinType()
{
  return MLDataTable.JoinType.hashValue.getter();
}

void protocol witness for Hashable.hash(into:) in conformance MLDataTable.JoinType()
{
}

uint64_t closure #1 in MLDataTable.subscript.getter(uint64_t *a1, uint64_t a2, char a3)
{
  uint64_t v6 = *a1;
  char v7 = (void *)a1[1];
  uint64_t *v3 = *a1;
  v3[1] = (uint64_t)v7;
  swift_bridgeObjectRetain(v7);
  outlined copy of Result<_DataTable, Error>(a2, a3);
  v8._uint64_t countAndFlagsBits = v6;
  v8._char object = v7;
  MLDataTable.subscript.getter(v8);
  return outlined consume of Result<_DataTable, Error>(a2, a3);
}

uint64_t closure #2 in MLDataTable.subscript.getter(uint64_t *a1, uint64_t a2, char a3)
{
  uint64_t v12 = a2;
  uint64_t v5 = v3;
  uint64_t v14 = *a1;
  uint64_t v6 = a1[1];
  uint64_t v7 = a1[2];
  uint64_t v13 = v3 + 2;
  char v8 = *((unsigned char *)a1 + 24);
  swift_bridgeObjectRetain(v6);
  outlined copy of Result<_DataTable, Error>(v7, v8);
  outlined consume of Result<_DataTable, Error>(v7, v8);
  *uint64_t v5 = v14;
  v5[1] = v6;
  swift_bridgeObjectRetain(v6);
  outlined copy of Result<_DataTable, Error>(v7, v8);
  swift_bridgeObjectRelease(v6);
  uint64_t v10 = v12;
  char v11 = a3 & 1;
  MLUntypedColumn.subscript.getter(&v10);
  return outlined consume of Result<_DataTable, Error>(v7, v8);
}

uint64_t MLDataTable.subscript.getter(uint64_t *a1)
{
  char v1 = *((unsigned char *)a1 + 8);
  uint64_t v3 = *a1;
  char v4 = v1;
  return MLDataTable.subscript.getter((uint64_t)&v3);
}

uint64_t MLDataTable.map<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v26 = a4;
  uint64_t v6 = *(void *)v5;
  char v7 = *(unsigned char *)(v5 + 8);
  uint64_t v27 = a3;
  uint64_t v30 = v4;
  uint64_t v28 = v6;
  uint64_t v24 = a2;
  LOBYTE(v29) = v7;
  uint64_t v25 = a1;
  if (v7)
  {
    outlined copy of Result<_DataTable, Error>(v6, 1);
    uint64_t v8 = tc_v1_flex_list_create(0);
    if (!v8) {
      BUG();
    }
    uint64_t v9 = v8;
    uint64_t v10 = type metadata accessor for CMLSequence();
    uint64_t v11 = swift_allocObject(v10, 25, 7);
    *(void *)(v11 + 16) = v9;
    *(unsigned char *)(v11 + 24) = 1;
    outlined consume of Result<_DataTable, Error>(v6, 1);
    uint64_t v12 = _swiftEmptyDictionarySingleton;
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(v6, 0);
    _DataTable.columnNames.getter(v6);
    outlined consume of Result<_DataTable, Error>(v6, 0);
    uint64_t v11 = v31;
    outlined copy of Result<_DataTable, Error>(v6, 0);
    uint64_t v12 = (void *)_DataTable.columnIndexes.getter();
    outlined consume of Result<_DataTable, Error>(v6, 0);
  }
  uint64_t v13 = v26;
  uint64_t v14 = (void *)swift_allocObject(&unk_39C3B0, 64, 7);
  uint64_t v15 = v27;
  void v14[2] = v27;
  v14[3] = v13;
  v14[4] = v11;
  v14[5] = v12;
  v14[6] = v25;
  v14[7] = v24;
  if ((_BYTE)v29)
  {
    uint64_t v16 = v28;
    uint64_t v31 = v28;
    outlined copy of Result<_DataTable, Error>(v28, 1);
    outlined copy of Result<_DataTable, Error>(v28, 1);
    uint64_t v29 = v11;
    swift_retain();
    swift_retain();
    uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v18 = _getErrorEmbeddedNSError<A>(_:)(&v31, v17, &protocol self-conformance witness table for Error);
    if (v18)
    {
      uint64_t v19 = v18;
      outlined consume of Result<_DataTable, Error>(v28, 1);
    }
    else
    {
      uint64_t v19 = swift_allocError(v17, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v20 = v31;
    }
    swift_release();
    outlined consume of Result<_DataTable, Error>(v16, 1);
    swift_release();
    char v21 = 1;
  }
  else
  {
    uint64_t v23 = v28;
    outlined copy of Result<_DataTable, Error>(v28, 0);
    swift_retain();
    swift_retain();
    closure #2 in MLDataTable.map<A>(_:)((uint64_t)&v23, (uint64_t)partial apply for closure #1 in MLDataTable.map<A>(_:), (uint64_t)v14, v15, v13);
    swift_release();
    outlined consume of Result<_DataTable, Error>(v28, 0);
    swift_release();
    uint64_t v19 = v31;
    char v21 = 0;
  }
  uint64_t v31 = v19;
  char v32 = v21;
  return MLDataColumn.init(from:)((uint64_t)&v31);
}

{
  void *v6;

  uint64_t v6 = (void *)swift_allocObject(&unk_39C3D8, 48, 7);
  v6[2] = a3;
  v6[3] = a4;
  void v6[4] = a1;
  v6[5] = a2;
  swift_retain();
  MLDataTable.map<A>(_:)((uint64_t)partial apply for closure #1 in MLDataTable.map<A>(_:), (uint64_t)v6, a3, a4);
  return swift_release();
}

uint64_t closure #1 in MLDataTable.map<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, void (*a4)(void *, uint64_t), uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v25 = a5;
  uint64_t v24 = a4;
  uint64_t v29 = type metadata accessor for Optional(0, a6);
  uint64_t v30 = *(void *)(v29 - 8);
  int64_t v9 = *(void *)(v30 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v26 = v23;
  uint64_t v27 = *(void *)(a6 - 8);
  int64_t v12 = *(void *)(v27 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v28 = v23;
  v23[0] = a2;
  v23[1] = a3;
  v23[2] = a1;
  uint64_t v33 = a1;
  swift_retain_n(a1);
  uint64_t v31 = a2;
  swift_retain();
  uint64_t v32 = a3;
  char v15 = a3;
  uint64_t v16 = a6;
  uint64_t v17 = (uint64_t)v26;
  swift_bridgeObjectRetain(v15);
  v24(v23, 2);
  if (__swift_getEnumTagSinglePayload(v17, 1, v16) == 1)
  {
    (*(void (**)(uint64_t, uint64_t))(v30 + 8))(v17, v29);
    type metadata accessor for CMLFeatureValue();
    uint64_t v18 = CMLFeatureValue.__allocating_init()(0);
    swift_release_n(v33);
    swift_bridgeObjectRelease(v32);
    swift_release();
  }
  else
  {
    uint64_t v19 = v28;
    uint64_t v20 = v17;
    uint64_t v21 = v27;
    (*(void (**)(void *, uint64_t, uint64_t))(v27 + 32))(v28, v20, v16);
    uint64_t v18 = MLDataValueConvertible.featureValue.getter(v16, a7);
    swift_release_n(v33);
    swift_bridgeObjectRelease(v32);
    swift_release();
    (*(void (**)(void *, uint64_t))(v21 + 8))(v19, v16);
  }
  return v18;
}

uint64_t closure #2 in MLDataTable.map<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v11 = v5;
  (*(void (**)(uint64_t))(a5 + 8))(a4);
  uint64_t result = CMLTable.apply(transform:type:)(a2, a3, 0x5060403020100uLL >> (8 * v12));
  if (!v6)
  {
    uint64_t v8 = result;
    uint64_t v9 = type metadata accessor for _UntypedColumn();
    uint64_t result = swift_allocObject(v9, 24, 7);
    *(void *)(result + 16) = v8;
    *uint64_t v11 = result;
  }
  return result;
}

uint64_t closure #1 in MLDataTable.map<A>(_:)(long long *a1, void (*a2)(long long *, void, uint64_t), uint64_t a3, uint64_t a4)
{
  uint64_t v6 = v4;
  uint64_t v7 = *((void *)a1 + 2);
  long long v9 = *a1;
  uint64_t v10 = v7;
  a2(&v9, a2, a3);
  return __swift_storeEnumTagSinglePayload(v6, 0, 1, a4);
}

uint64_t MLDataTable.dropMissing()()
{
  uint64_t v2 = v0;
  uint64_t v3 = *(void *)v1;
  if (*(unsigned char *)(v1 + 8))
  {
    v18[0] = *(void *)v1;
    outlined copy of Result<_DataTable, Error>(v3, 1);
    swift_errorRetain(v3);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v5 = _getErrorEmbeddedNSError<A>(_:)(v18, v4, &protocol self-conformance witness table for Error);
    if (v5)
    {
      uint64_t v6 = v5;
      outlined consume of Result<_DataTable, Error>(v3, 1);
    }
    else
    {
      uint64_t v6 = swift_allocError(v4, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v10 = v18[0];
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 1);
    char v12 = 1;
  }
  else
  {
    uint64_t v7 = *(void *)(*(void *)(v3 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(*(void *)v1, 0);
    uint64_t v8 = tc_v1_flex_list_create(0);
    uint64_t v9 = specialized handling<A, B, C, D>(_:_:_:_:)(v7, v8, (uint64_t)"any");
    uint64_t v13 = v9;
    if (!v9) {
      BUG();
    }
    char v12 = 0;
    uint64_t v14 = type metadata accessor for CMLTable();
    uint64_t v15 = swift_allocObject(v14, 24, 7);
    *(void *)(v15 + 16) = v13;
    uint64_t v16 = v15;
    uint64_t v17 = type metadata accessor for _DataTable();
    uint64_t v6 = swift_allocObject(v17, 40, 7);
    *(_OWORD *)(v6 + 24) = 0;
    *(void *)(v6 + 16) = v16;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 0);
  }
  *(void *)uint64_t v2 = v6;
  *(unsigned char *)(v2 + 8) = v12;
  return result;
}

uint64_t MLDataTable.fillMissing(columnNamed:with:)(uint64_t a1, uint64_t a2, long long *a3)
{
  uint64_t v5 = v3;
  uint64_t v6 = *(void *)v4;
  if (*(unsigned char *)(v4 + 8))
  {
    v20[0] = *(void *)v4;
    outlined copy of Result<_DataTable, Error>(v6, 1);
    swift_errorRetain(v6);
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v8 = _getErrorEmbeddedNSError<A>(_:)(v20, v7, &protocol self-conformance witness table for Error);
    if (v8)
    {
      uint64_t v9 = v8;
      outlined consume of Result<_DataTable, Error>(v6, 1);
    }
    else
    {
      uint64_t v9 = swift_allocError(v7, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v15 = v20[0];
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v6, 1);
    char v17 = 1;
  }
  else
  {
    uint64_t v22 = v3;
    uint64_t v10 = *(void *)(v6 + 16);
    long long v11 = *a3;
    char v21 = *((unsigned char *)a3 + 16);
    swift_retain();
    uint64_t v23 = v19;
    char v12 = alloca(32);
    uint64_t v13 = alloca(32);
    v20[0] = v10;
    v20[1] = MLDataValue.featureValue.getter(*(double *)&v11);
    uint64_t v14 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.fillMissing(columnNamed:with:), (uint64_t)v19, a1, a2, (uint64_t (*)(void))type metadata accessor for CMLTable, (uint64_t (*)(uint64_t))_ss11_StringGutsV11withCStringyxxSPys4Int8VGKXEKlFxSRyAEGKXEfU_s13OpaquePointerV_TG5TA_0);
    swift_release();
    uint64_t v16 = type metadata accessor for _DataTable();
    uint64_t v9 = swift_allocObject(v16, 40, 7);
    *(_OWORD *)(v9 + 24) = 0;
    *(void *)(v9 + 16) = v14;
    char v17 = 0;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v6, 0);
    uint64_t v5 = v22;
  }
  *(void *)uint64_t v5 = v9;
  *(unsigned char *)(v5 + 8) = v17;
  return result;
}

uint64_t MLDataTable.dropDuplicates()()
{
  uint64_t v2 = v0;
  uint64_t v3 = *(void *)v1;
  if (*(unsigned char *)(v1 + 8))
  {
    v17[0] = *(void *)v1;
    outlined copy of Result<_DataTable, Error>(v3, 1);
    swift_errorRetain(v3);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v5 = _getErrorEmbeddedNSError<A>(_:)(v17, v4, &protocol self-conformance witness table for Error);
    if (v5)
    {
      uint64_t v6 = v5;
      outlined consume of Result<_DataTable, Error>(v3, 1);
    }
    else
    {
      uint64_t v6 = swift_allocError(v4, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v9 = v17[0];
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 1);
    char v11 = 1;
  }
  else
  {
    uint64_t v7 = *(void *)(*(void *)(v3 + 16) + 16);
    swift_retain();
    uint64_t v8 = specialized handling<A, B>(_:_:)(v7);
    uint64_t v12 = v8;
    if (!v8) {
      BUG();
    }
    char v11 = 0;
    uint64_t v13 = type metadata accessor for CMLTable();
    uint64_t v14 = swift_allocObject(v13, 24, 7);
    *(void *)(v14 + 16) = v12;
    uint64_t v15 = v14;
    uint64_t v16 = type metadata accessor for _DataTable();
    uint64_t v6 = swift_allocObject(v16, 40, 7);
    *(_OWORD *)(v6 + 24) = 0;
    *(void *)(v6 + 16) = v15;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 0);
  }
  *(void *)uint64_t v2 = v6;
  *(unsigned char *)(v2 + 8) = v11;
  return result;
}

char *MLDataTable.prefix(_:)(uint64_t a1)
{
  return MLDataTable.prefix(_:)(a1, specialized handling<A, B, C>(_:_:_:));
}

char *MLDataTable.suffix(_:)(uint64_t a1)
{
  return MLDataTable.prefix(_:)(a1, specialized handling<A, B, C>(_:_:_:));
}

char *MLDataTable.prefix(_:)(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t))
{
  uint64_t v4 = v2;
  if (a1 <= 0)
  {
    uint64_t v9 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v8 = swift_allocError(&type metadata for MLCreateError, v9, 0, 0);
    *(void *)uint64_t v10 = 0xD00000000000002BLL;
    uint64_t result = "Column initialized as invalid" + 0x8000000000000000;
    *(void *)(v10 + 8) = "Column initialized as invalid" + 0x8000000000000000;
    *(_OWORD *)(v10 + 16) = 0;
    *(_OWORD *)(v10 + 32) = 0;
    *(unsigned char *)(v10 + 48) = 0;
LABEL_9:
    char v15 = 1;
    goto LABEL_10;
  }
  uint64_t v5 = *(void *)v3;
  if (*(unsigned char *)(v3 + 8))
  {
    v21[0] = *(void *)v3;
    outlined copy of Result<_DataTable, Error>(v5, 1);
    swift_errorRetain(v5);
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v7 = _getErrorEmbeddedNSError<A>(_:)(v21, v6, &protocol self-conformance witness table for Error);
    if (v7)
    {
      uint64_t v8 = v7;
      outlined consume of Result<_DataTable, Error>(v5, 1);
    }
    else
    {
      uint64_t v8 = swift_allocError(v6, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v14 = v21[0];
    }
    uint64_t result = (char *)outlined consume of Result<_DataTable, Error>(v5, 1);
    goto LABEL_9;
  }
  uint64_t v12 = *(void *)(*(void *)(v5 + 16) + 16);
  swift_retain();
  uint64_t v13 = a2(v12, a1);
  uint64_t v16 = v13;
  if (!v13) {
    BUG();
  }
  char v15 = 0;
  uint64_t v17 = type metadata accessor for CMLTable();
  uint64_t v18 = swift_allocObject(v17, 24, 7);
  *(void *)(v18 + 16) = v16;
  uint64_t v19 = v18;
  uint64_t v20 = type metadata accessor for _DataTable();
  uint64_t v8 = swift_allocObject(v20, 40, 7);
  *(_OWORD *)(v8 + 24) = 0;
  *(void *)(v8 + 16) = v19;
  uint64_t result = (char *)outlined consume of Result<_DataTable, Error>(v5, 0);
LABEL_10:
  *(void *)uint64_t v4 = v8;
  *(unsigned char *)(v4 + 8) = v15;
  return result;
}

uint64_t MLDataTable.sort(columnNamed:byIncreasingOrder:)(uint64_t a1, uint64_t a2, char a3)
{
  uint64_t v5 = v3;
  uint64_t v6 = *(void *)v4;
  if (*(unsigned char *)(v4 + 8))
  {
    uint64_t v18 = *(void *)v4;
    outlined copy of Result<_DataTable, Error>(v6, 1);
    swift_errorRetain(v6);
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v8 = _getErrorEmbeddedNSError<A>(_:)(&v18, v7, &protocol self-conformance witness table for Error);
    if (v8)
    {
      uint64_t v9 = v8;
      outlined consume of Result<_DataTable, Error>(v6, 1);
    }
    else
    {
      uint64_t v9 = swift_allocError(v7, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v12 = v18;
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v6, 1);
    char v15 = 1;
  }
  else
  {
    uint64_t v19 = &v17;
    uint64_t v10 = alloca(25);
    char v11 = alloca(32);
    uint64_t v19 = *(uint64_t **)(v6 + 16);
    char v20 = a3 & 1;
    swift_retain();
    uint64_t v13 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.sorted(by:increasingOrder:), (uint64_t)&v17, a1, a2, (uint64_t (*)(void))type metadata accessor for CMLTable, (uint64_t (*)(uint64_t))_ss11_StringGutsV11withCStringyxxSPys4Int8VGKXEKlFxSRyAEGKXEfU_s13OpaquePointerV_TG5TA_0);
    uint64_t v14 = type metadata accessor for _DataTable();
    uint64_t v9 = swift_allocObject(v14, 40, 7);
    *(_OWORD *)(v9 + 24) = 0;
    *(void *)(v9 + 16) = v13;
    char v15 = 0;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v6, 0);
  }
  *(void *)uint64_t v5 = v9;
  *(unsigned char *)(v5 + 8) = v15;
  return result;
}

uint64_t *MLDataTable.expand(columnNamed:to:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4)
{
  return MLDataTable.expand(columnNamed:to:)(a1, a2, a3, a4, (uint64_t (*)(void))partial apply for closure #1 in CMLTable.stack(columnName:to:));
}

uint64_t *MLDataTable.condense(columnNamed:to:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4)
{
  return MLDataTable.expand(columnNamed:to:)(a1, a2, a3, a4, (uint64_t (*)(void))partial apply for closure #1 in CMLTable.unstack(columnName:newColumnName:));
}

uint64_t *MLDataTable.expand(columnNamed:to:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4, uint64_t (*a5)(void))
{
  uint64_t v23 = v5;
  uint64_t v7 = *(void *)v6;
  if (*(unsigned char *)(v6 + 8))
  {
    uint64_t v22 = *(void *)v6;
    outlined copy of Result<_DataTable, Error>(v7, 1);
    swift_errorRetain(v7);
    uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v9 = _getErrorEmbeddedNSError<A>(_:)(&v22, v8, &protocol self-conformance witness table for Error);
    if (v9)
    {
      uint64_t v10 = v9;
      outlined consume of Result<_DataTable, Error>(v7, 1);
    }
    else
    {
      uint64_t v10 = swift_allocError(v8, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v16 = v22;
    }
    outlined consume of Result<_DataTable, Error>(v7, 1);
    char v19 = 1;
  }
  else
  {
    uint64_t v24 = v21;
    uint64_t v13 = *(unsigned char **)(v7 + 16);
    uint64_t v14 = alloca(40);
    char v15 = alloca(48);
    uint64_t v22 = a3;
    uint64_t v23 = a4;
    uint64_t v24 = v13;
    swift_retain();
    uint64_t v17 = specialized String.withCString<A>(_:)(a5, (uint64_t)v21, a1, a2, (uint64_t (*)(void))type metadata accessor for CMLTable, (uint64_t (*)(uint64_t))_ss11_StringGutsV11withCStringyxxSPys4Int8VGKXEKlFxSRyAEGKXEfU_s13OpaquePointerV_TG5TA_0);
    uint64_t v18 = type metadata accessor for _DataTable();
    uint64_t v10 = swift_allocObject(v18, 40, 7);
    *(_OWORD *)(v10 + 24) = 0;
    *(void *)(v10 + 16) = v17;
    char v19 = 0;
    outlined consume of Result<_DataTable, Error>(v7, 0);
  }
  uint64_t result = v23;
  *uint64_t v23 = v10;
  *((unsigned char *)result + 8) = v19;
  return result;
}

uint64_t MLDataTable.show()()
{
  uint64_t v2 = v0;
  char v3 = *(unsigned char *)(v1 + 8);
  uint64_t v6 = *(void *)v1;
  char v7 = v3;
  outlined copy of Result<_DataTable, Error>(v6, v3);
  uint64_t v4 = MLDataTableVisualization.init(_:)((uint64_t)&v6);
  v2[3] = &type metadata for MLDataTableVisualization;
  uint64_t result = lazy protocol witness table accessor for type MLDataTableVisualization and conformance MLDataTableVisualization();
  v2[4] = result;
  void *v2 = v4;
  return result;
}

uint64_t MLDataTable.playgroundDescription.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = *(void *)v1;
  if (*(unsigned char *)(v1 + 8))
  {
    *(void *)&long long v39 = 0;
    *((void *)&v39 + 1) = 0xE000000000000000;
    v42[0] = v3;
    outlined copy of Result<_DataTable, Error>(v3, 1);
    uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    _print_unlocked<A, B>(_:_:)(v42, &v39, v4, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    long long v41 = v39;
    v2[3] = &type metadata for String;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v3, 1);
    *(_OWORD *)uint64_t v2 = v41;
  }
  else
  {
    *(void *)&long long v39 = 0;
    *((void *)&v39 + 1) = 0xE000000000000000;
    outlined copy of Result<_DataTable, Error>(v3, 0);
    _StringGuts.grow(_:)(36);
    swift_retain();
    Swift::Int v6 = CMLTable.rows()();
    swift_release();
    if (v7)
    {
      swift_unexpectedError(v7, "CreateML/MLDataTable.swift", 26, 1);
      BUG();
    }
    v42[0] = v6;
    v8._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char object = (char)v8._object;
    String.append(_:)(v8);
    swift_bridgeObjectRelease(object);
    v10._uint64_t countAndFlagsBits = 0x20582073776F7220;
    v10._char object = (void *)0xE800000000000000;
    String.append(_:)(v10);
    *(void *)&long long v41 = v3;
    _DataTable.columnNames.getter(0x20582073776F7220);
    swift_retain();
    uint64_t v11 = CMLSequence.size.getter();
    uint64_t v12 = specialized RandomAccessCollection<>.distance(from:to:)(0, v11);
    swift_release();
    swift_retain();
    uint64_t v13 = CMLSequence.size.getter();
    uint64_t v14 = specialized RandomAccessCollection<>.distance(from:to:)(0, v13);
    swift_release();
    if (v14 < 0) {
      BUG();
    }
    swift_retain();
    uint64_t v15 = CMLSequence.size.getter();
    uint64_t v16 = specialized RandomAccessCollection<>.distance(from:to:)(0, v15);
    swift_release_n(v42[0]);
    if (v12 < 0 || v16 < v12) {
      BUG();
    }
    v17._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char v18 = (char)v17._object;
    String.append(_:)(v17);
    swift_bridgeObjectRelease(v18);
    v19._char object = "ed on this device" + 0x8000000000000000;
    v19._uint64_t countAndFlagsBits = 0xD000000000000016;
    String.append(_:)(v19);
    _DataTable.columnNames.getter(0xD000000000000016);
    swift_retain();
    uint64_t v20 = CMLSequence.size.getter();
    uint64_t v21 = specialized RandomAccessCollection<>.distance(from:to:)(0, v20);
    swift_retain();
    uint64_t v22 = CMLSequence.size.getter();
    uint64_t v23 = specialized RandomAccessCollection<>.distance(from:to:)(0, v22);
    swift_release();
    if (v23 < 0) {
      BUG();
    }
    swift_retain();
    uint64_t v24 = CMLSequence.size.getter();
    uint64_t v25 = specialized RandomAccessCollection<>.distance(from:to:)(0, v24);
    swift_release_n(v42[0]);
    if (v21 < 0 || v25 < v21) {
      BUG();
    }
    char v40 = v2;
    swift_retain();
    ML11MLDataTableV11ColumnNamesV11descriptionSSvgSSSiXEfU_0F2ML0hI0V0kL0VTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SSs5NeverOTg565_s8CreateML11MLDataTableV11ColumnNamesV11descriptionSSvgSSSiXEfU_0F2ML0hI0V0kL0VTf1cn_n(0, v21);
    char v27 = (char)ML11MLDataTableV11ColumnNamesV11descriptionSSvgSSSiXEfU_0F2ML0hI0V0kL0VTf1cn_n;
    uint64_t v28 = Array.description.getter(ML11MLDataTableV11ColumnNamesV11descriptionSSvgSSSiXEfU_0F2ML0hI0V0kL0VTf1cn_n, &type metadata for String);
    uint64_t v30 = v29;
    swift_bridgeObjectRelease(v27);
    v31._uint64_t countAndFlagsBits = v28;
    v31._char object = v30;
    String.append(_:)(v31);
    swift_release();
    swift_bridgeObjectRelease((_BYTE)v30);
    swift_bridgeObjectRelease(BYTE8(v39));
    outlined copy of Result<_DataTable, Error>(v41, 0);
    swift_retain();
    Swift::String v32 = CMLTable.description()();
    if (v33)
    {
      uint64_t countAndFlagsBits = 0;
      swift_errorRelease(v33);
      swift_release();
      char v35 = 0;
    }
    else
    {
      uint64_t countAndFlagsBits = v32._countAndFlagsBits;
      char v35 = (char)v32._object;
      swift_release();
    }
    unint64_t v36 = v40;
    uint64_t v37 = v41;
    outlined consume of Result<_DataTable, Error>(v41, 0);
    objc_allocWithZone((Class)NSMutableAttributedString);
    id v38 = @nonobjc NSMutableAttributedString.init(string:attributes:)(countAndFlagsBits, v35, 0);
    v40[3] = type metadata accessor for NSMutableAttributedString();
    uint64_t result = outlined consume of Result<_DataTable, Error>(v37, 0);
    *unint64_t v36 = v38;
  }
  return result;
}

uint64_t MLDataTable.description.getter()
{
  uint64_t v1 = *(void *)v0;
  if (*(unsigned char *)(v0 + 8))
  {
    v7[0] = 0;
    v7[1] = 0xE000000000000000;
    v8[0] = v1;
    uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    _print_unlocked<A, B>(_:_:)(v8, v7, v2, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    return v7[0];
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(v1, 0);
    swift_retain();
    uint64_t countAndFlagsBits = CMLTable.description()()._countAndFlagsBits;
    if (v5)
    {
      swift_errorRelease(v5);
      swift_release();
      uint64_t v3 = 0;
    }
    else
    {
      uint64_t v3 = countAndFlagsBits;
      swift_release();
    }
    outlined consume of Result<_DataTable, Error>(v1, 0);
  }
  return v3;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLDataTable()
{
  return MLDataTable.description.getter();
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLDataTable()
{
  return MLDataTable.playgroundDescription.getter();
}

id @nonobjc NSMutableAttributedString.init(string:attributes:)(uint64_t a1, char a2, uint64_t a3)
{
  NSString v5 = String._bridgeToObjectiveC()();
  swift_bridgeObjectRelease(a2);
  if (a3)
  {
    type metadata accessor for NSAttributedStringKey(0);
    lazy protocol witness table accessor for type NSAttributedStringKey and conformance NSAttributedStringKey();
    v6.super.Class isa = Dictionary._bridgeToObjectiveC()().super.isa;
    swift_bridgeObjectRelease(a3);
  }
  else
  {
    v6.super.Class isa = 0;
  }
  id v7 = [v3 initWithString:v5 attributes:v6.super.isa];

  return v7;
}

uint64_t type metadata accessor for _DataTable()
{
  return objc_opt_self(_TtC8CreateML10_DataTable);
}

uint64_t sub_26BB97()
{
  return objectdestroyTm_6();
}

uint64_t partial apply for closure #1 in MLDataTable.subscript.getter(uint64_t *a1)
{
  return closure #1 in MLDataTable.subscript.getter(a1, *(void *)(v1 + 16), *(unsigned char *)(v1 + 24));
}

uint64_t sub_26BBB4()
{
  return objectdestroyTm_6();
}

uint64_t objectdestroyTm_6()
{
  outlined consume of Result<_DataTable, Error>(*(void *)(v0 + 16), *(_DWORD *)(v0 + 24));
  return swift_deallocObject(v0, 25, 7);
}

uint64_t partial apply for closure #2 in MLDataTable.subscript.getter(uint64_t *a1)
{
  return closure #2 in MLDataTable.subscript.getter(a1, *(void *)(v1 + 16), *(unsigned char *)(v1 + 24));
}

char specialized closure #1 in Sequence<>.contains(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a1 == a3 && a2 == a4) {
    return 1;
  }
  else {
    return _stringCompareWithSmolCheck(_:_:expecting:)(a1, a2, a3, a4, 0);
  }
}

uint64_t specialized closure #1 in LazyMapSequence<>.map<A>(_:)(uint64_t a1, uint64_t a2, void (*a3)(unsigned char *), uint64_t a4, uint64_t a5, void (*a6)(void *))
{
  v13[0] = a1;
  v13[1] = a2;
  a6(v13);
  a3(v9);
  uint64_t v7 = v11;
  LOBYTE(a3) = v12;
  swift_bridgeObjectRelease(v10);
  return outlined consume of Result<_DataTable, Error>(v7, (char)a3);
}

uint64_t specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)(uint64_t a1, unsigned __int8 a2, void *a3)
{
  char v40 = a3;
  uint64_t v4 = *(void *)(a1 + 16);
  if (!v4) {
    return swift_bridgeObjectRelease(a1);
  }
  uint64_t v36 = v3;
  uint64_t v38 = a1;
  NSString v5 = (void *)(a1 + 48);
  while (1)
  {
    uint64_t v34 = v4;
    uint64_t v6 = *(v5 - 2);
    uint64_t v7 = *(v5 - 1);
    char v35 = v5;
    uint64_t v33 = *v5;
    v31[0] = v6;
    v31[1] = v7;
    Swift::String v8 = (void *)*v40;
    swift_bridgeObjectRetain(v7);
    uint64_t v37 = v6;
    uint64_t v39 = v7;
    unint64_t v10 = specialized __RawDictionaryStorage.find<A>(_:)(v6, v7);
    BOOL v11 = (v9 & 1) == 0;
    BOOL v12 = __OFADD__(v8[2], v11);
    uint64_t v13 = v8[2] + v11;
    if (v12) {
      BUG();
    }
    char v14 = v9;
    if (v8[3] >= v13)
    {
      if ((a2 & 1) == 0)
      {
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, Double>);
        _NativeDictionary.copy()();
      }
    }
    else
    {
      specialized _NativeDictionary._copyOrMoveAndResize(capacity:moveElements:)(v13, a2);
      unint64_t v10 = specialized __RawDictionaryStorage.find<A>(_:)(v37, v39);
      if ((v14 & 1) != (v15 & 1))
      {
        KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
        BUG();
      }
    }
    if (v14) {
      break;
    }
    uint64_t v16 = (void *)*v40;
    v16[(v10 >> 6) + 8] |= 1 << v10;
    uint64_t v17 = v16[6];
    uint64_t v18 = 16 * v10;
    *(void *)(v17 + v18) = v37;
    *(void *)(v17 + v18 + 8) = v39;
    *(void *)(v16[7] + 8 * v10) = v33;
    uint64_t v19 = v16[2];
    BOOL v12 = __OFADD__(1, v19);
    uint64_t v20 = v19 + 1;
    if (v12) {
      BUG();
    }
    v16[2] = v20;
    NSString v5 = v35 + 3;
    a2 = 1;
    uint64_t v4 = v34 - 1;
    if (v34 == 1) {
      return swift_bridgeObjectRelease(v38);
    }
  }
  uint64_t v21 = swift_allocError(&type metadata for _MergeError, &protocol witness table for _MergeError, 0, 0);
  swift_willThrow(&type metadata for _MergeError, &protocol witness table for _MergeError, v22, v23, v24, v25);
  uint64_t v32 = v21;
  swift_errorRetain(v21);
  uint64_t v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
  if (swift_dynamicCast(&demangling cache variable for type metadata for Error, &v32, v26, &type metadata for _MergeError, 0))
  {
    uint64_t v29 = 0;
    unint64_t v30 = 0xE000000000000000;
    _StringGuts.grow(_:)(30);
    v28._char object = "Swift/NativeDictionary.swift" + 0x8000000000000000;
    v28._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
    String.append(_:)(v28);
    _print_unlocked<A, B>(_:_:)(v31, &v29, &type metadata for String, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    v28._uint64_t countAndFlagsBits = 39;
    v28._char object = (void *)0xE100000000000000;
    String.append(_:)(v28);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v29, v30, "Swift/NativeDictionary.swift", 28, 2, 783, 0);
    BUG();
  }
  swift_bridgeObjectRelease(v38);
  swift_bridgeObjectRelease(v39);
  return swift_errorRelease(v32);
}

uint64_t specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)(uint64_t *a1, int a2, void *a3)
{
  uint64_t v4 = v3;
  uint64_t v52 = a3;
  int v70 = a2;
  uint64_t v5 = *a1;
  uint64_t v49 = (void (*)(void *))a1[1];
  uint64_t v6 = a1[2];
  uint64_t v50 = (uint64_t (*)(long long *))a1[3];
  uint64_t v7 = a1[4];
  uint64_t v51 = (void (*)(long long *))a1[5];
  uint64_t v63 = a1[6];
  swift_retain(v5);
  uint64_t v60 = v6;
  swift_retain(v6);
  uint64_t v61 = v7;
  swift_retain(v7);
  swift_retain(v63);
  if (!CMLDictionary.size.getter())
  {
LABEL_18:
    swift_release_n(v63, 2);
    swift_release_n(v61, 2);
    swift_release_n(v60, 2);
    return swift_release_n(v5, 2);
  }
  uint64_t v8 = 0;
  uint64_t v62 = v5;
  while (1)
  {
    Swift::String v69 = (void *)CMLDictionary.keyAndValue(at:)(v8);
    uint64_t v66 = v4;
    if (v4)
    {
      swift_unexpectedError(v66, "CreateML/DictionaryType.swift", 29, 1, 75);
      BUG();
    }
    uint64_t v10 = v9;
    swift_retain(v5);
    uint64_t v54 = specialized RandomAccessCollection<>.index(after:)(v8);
    swift_release(v5);
    BOOL v11 = v69;
    v53[0] = v69;
    v53[1] = v10;
    v49(v53);
    swift_release(v10);
    swift_release(v11);
    LOBYTE(v68) = v48;
    long long v55 = v44;
    uint64_t v56 = v45;
    Swift::String v69 = v46;
    uint64_t v57 = v46;
    Swift::String v67 = v47;
    uint64_t v58 = v47;
    char v59 = v48;
    if (v50(&v55)) {
      break;
    }
    outlined consume of (MLDataValue, MLDataValue)?((void *)v44, *((void **)&v44 + 1), v45, v69, v67, (char)v68);
    uint64_t v5 = v62;
    uint64_t v12 = CMLDictionary.size.getter();
LABEL_6:
    uint64_t v8 = v54;
    uint64_t v4 = v66;
    if (v54 == v12) {
      goto LABEL_18;
    }
  }
  long long v55 = v44;
  uint64_t v64 = (void *)*((void *)&v44 + 1);
  uint64_t v56 = v45;
  uint64_t v57 = v69;
  uint64_t v13 = v67;
  uint64_t v58 = v67;
  char v59 = (char)v68;
  LODWORD(v68) = v68;
  v51(&v55);
  outlined consume of (MLDataValue, MLDataValue)?((void *)v44, v64, v45, v69, v13, (char)v68);
  if (v40 == 0xFF)
  {
    uint64_t v5 = v62;
    goto LABEL_18;
  }
  long long v55 = v39;
  LOBYTE(v56) = v40;
  uint64_t v64 = v41;
  char v68 = v42;
  char v71 = v43;
  char v14 = (void *)*v52;
  Swift::String v69 = (void *)*((void *)&v39 + 1);
  Swift::String v67 = (void *)v39;
  int v65 = v40;
  unint64_t v15 = specialized __RawDictionaryStorage.find<A>(_:)(v39, v40);
  char v17 = v16;
  BOOL v18 = (v16 & 1) == 0;
  BOOL v19 = __OFADD__(v14[2], v18);
  uint64_t v20 = v14[2] + v18;
  if (v19) {
    BUG();
  }
  if (v14[3] >= v20)
  {
    if ((v70 & 1) == 0)
    {
      LOBYTE(v70) = v16;
      unint64_t v30 = v15;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<MLDataValue, MLDataValue>);
      _NativeDictionary.copy()();
      unint64_t v15 = v30;
      char v17 = v70;
    }
  }
  else
  {
    specialized _NativeDictionary._copyOrMoveAndResize(capacity:moveElements:)(v20, v70);
    *(void *)&long long v21 = v67;
    *((void *)&v21 + 1) = v69;
    unint64_t v15 = specialized __RawDictionaryStorage.find<A>(_:)(v21, v65);
    if ((v17 & 1) != (v22 & 1))
    {
      KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for MLDataValue);
      BUG();
    }
  }
  if ((v17 & 1) == 0)
  {
    uint64_t v23 = (void *)*v52;
    v23[(v15 >> 6) + 8] |= 1 << v15;
    uint64_t v24 = v23[6];
    uint64_t v25 = 24 * v15;
    *(void *)(v24 + v25) = v67;
    *(void *)(v24 + v25 + 8) = v69;
    *(unsigned char *)(v24 + v25 + 16) = v40;
    uint64_t v26 = v23[7];
    *(void *)(v26 + v25) = v64;
    *(void *)(v26 + v25 + 8) = v68;
    *(unsigned char *)(v26 + v25 + 16) = v71;
    uint64_t v27 = v23[2];
    BOOL v19 = __OFADD__(1, v27);
    uint64_t v28 = v27 + 1;
    if (v19) {
      BUG();
    }
    v23[2] = v28;
    uint64_t v5 = v62;
    uint64_t v12 = CMLDictionary.size.getter();
    LOBYTE(v29) = 1;
    int v70 = v29;
    goto LABEL_6;
  }
  uint64_t v32 = swift_allocError(&type metadata for _MergeError, &protocol witness table for _MergeError, 0, 0);
  swift_willThrow();
  v53[0] = v32;
  uint64_t v66 = v32;
  swift_errorRetain(v32);
  uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
  if (swift_dynamicCast(&demangling cache variable for type metadata for Error, v53, v33, &type metadata for _MergeError, 0))
  {
    *(void *)&long long v44 = 0;
    *((void *)&v44 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(30);
    v38._char object = "Swift/NativeDictionary.swift" + 0x8000000000000000;
    v38._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
    String.append(_:)(v38);
    _print_unlocked<A, B>(_:_:)(&v55, &v44, &type metadata for MLDataValue, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    v38._uint64_t countAndFlagsBits = 39;
    v38._char object = (void *)0xE100000000000000;
    String.append(_:)(v38);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v44, *((void *)&v44 + 1), "Swift/NativeDictionary.swift", 28, 2, 783, 0);
    BUG();
  }
  uint64_t v34 = v63;
  swift_release(v63);
  uint64_t v35 = v61;
  swift_release(v61);
  uint64_t v36 = v60;
  swift_release(v60);
  uint64_t v37 = v62;
  swift_release(v62);
  outlined consume of MLDataValue(v64, v68, v71);
  outlined consume of MLDataValue(v67, v69, v65);
  swift_release(v34);
  swift_release(v35);
  swift_release(v36);
  swift_release(v37);
  return swift_errorRelease(v53[0]);
}

uint64_t specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)(uint64_t a1, uint64_t a2, uint64_t a3, int a4, void *a5)
{
  uint64_t v44 = v5;
  char v48 = a5;
  int v51 = a4;
  uint64_t v7 = a2;
  unint64_t v8 = *(void *)(a1 + 16);
  uint64_t v49 = a1;
  swift_bridgeObjectRetain(a1);
  if (v8)
  {
    uint64_t v45 = (unsigned __int8 *)(v49 + 48);
    uint64_t v42 = a3 - a2;
    unint64_t v9 = 0;
    uint64_t v43 = a3;
    uint64_t v47 = a2;
    while (1)
    {
      if (v9 >= v8) {
        BUG();
      }
      if (v42 == v9) {
        return swift_bridgeObjectRelease_n(v49, 2, v9, v10, v11);
      }
      if (a3 < v7) {
        BUG();
      }
      if ((uint64_t)(v9 + v7) >= a3) {
        BUG();
      }
      uint64_t v40 = v9 + v7;
      uint64_t v12 = (void *)*((void *)v45 - 2);
      uint64_t v13 = (void *)*((void *)v45 - 1);
      unsigned __int8 v52 = *v45;
      unint64_t v41 = v9;
      outlined copy of MLDataValue(v12, v13, v52);
      unint64_t v9 = v52;
      if (v52 == 0xFF) {
        return swift_bridgeObjectRelease_n(v49, 2, v9, v10, v11);
      }
      v37[0] = v12;
      v37[1] = v13;
      unsigned __int8 v38 = v52;
      char v14 = (void *)*v48;
      uint64_t v50 = v12;
      *(void *)&long long v15 = v12;
      uint64_t v46 = v13;
      *((void *)&v15 + 1) = v13;
      char v16 = v52;
      unint64_t v18 = specialized __RawDictionaryStorage.find<A>(_:)(v15, v52);
      *(void *)&long long v15 = (v17 & 1) == 0;
      BOOL v19 = __OFADD__(v14[2], (void)v15);
      uint64_t v20 = v14[2] + v15;
      if (v19) {
        BUG();
      }
      char v21 = v17;
      if (v14[3] < v20) {
        break;
      }
      uint64_t v7 = v47;
      if ((v51 & 1) == 0)
      {
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<MLDataValue, Int>);
        _NativeDictionary.copy()();
LABEL_11:
        uint64_t v7 = v47;
      }
      uint64_t v24 = v50;
      if (v21)
      {
        uint64_t v31 = swift_allocError(&type metadata for _MergeError, &protocol witness table for _MergeError, 0, 0);
        swift_willThrow();
        uint64_t v39 = v31;
        swift_errorRetain(v31);
        uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
        if (swift_dynamicCast(&demangling cache variable for type metadata for Error, &v39, v32, &type metadata for _MergeError, 0))
        {
          uint64_t v35 = 0;
          unint64_t v36 = 0xE000000000000000;
          _StringGuts.grow(_:)(30);
          v34._char object = "Swift/NativeDictionary.swift" + 0x8000000000000000;
          v34._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
          String.append(_:)(v34);
          _print_unlocked<A, B>(_:_:)(v37, &v35, &type metadata for MLDataValue, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
          v34._uint64_t countAndFlagsBits = 39;
          v34._char object = (void *)0xE100000000000000;
          String.append(_:)(v34);
          _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v35, v36, "Swift/NativeDictionary.swift", 28, 2, 783, 0);
          BUG();
        }
        uint64_t v33 = v49;
        swift_bridgeObjectRelease(v49);
        outlined consume of MLDataValue(v50, v46, v16);
        swift_bridgeObjectRelease(v33);
        return swift_errorRelease(v39);
      }
      uint64_t v25 = (void *)*v48;
      v25[(v18 >> 6) + 8] |= 1 << v18;
      uint64_t v26 = v25[6];
      uint64_t v27 = 24 * v18;
      *(void *)(v26 + v27) = v24;
      *(void *)(v26 + v27 + 8) = v46;
      *(unsigned char *)(v26 + v27 + 16) = v52;
      *(void *)(v25[7] + 8 * v18) = v40;
      uint64_t v28 = v25[2];
      BOOL v19 = __OFADD__(1, v28);
      uint64_t v10 = v28 + 1;
      if (v19) {
        BUG();
      }
      unint64_t v9 = v41 + 1;
      void v25[2] = v10;
      int v29 = v49;
      unint64_t v8 = *(void *)(v49 + 16);
      v45 += 24;
      LOBYTE(v29) = 1;
      int v51 = v29;
      a3 = v43;
      if (v9 == v8) {
        return swift_bridgeObjectRelease_n(v49, 2, v9, v10, v11);
      }
    }
    specialized _NativeDictionary._copyOrMoveAndResize(capacity:moveElements:)(v20, v51);
    *(void *)&long long v22 = v50;
    *((void *)&v22 + 1) = v46;
    unint64_t v18 = specialized __RawDictionaryStorage.find<A>(_:)(v22, v52);
    if ((v21 & 1) != (v23 & 1))
    {
      KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for MLDataValue);
      BUG();
    }
    goto LABEL_11;
  }
  return swift_bridgeObjectRelease_n(v49, 2, v9, v10, v11);
}

{
  uint64_t v5;
  uint64_t v6;
  unsigned __int8 v8;
  __m128i si128;
  uint64_t v10;
  const __m128i *v11;
  uint64_t v12;
  int v13;
  void *v14;
  uint64_t epi64;
  char v16;
  unint64_t v17;
  uint64_t v18;
  BOOL v19;
  BOOL v20;
  uint64_t v21;
  char v22;
  char v23;
  char v24;
  long long v25;
  void *v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  char v38;
  uint64_t v39;
  Swift::String v40;
  uint64_t v41;
  unint64_t v42;
  __m128i v43;
  char v44;
  uint64_t v45;
  uint64_t v46;
  unint64_t v47;
  const __m128i *v48;
  uint64_t v49;
  Swift::UInt v50;
  uint64_t v51;
  uint64_t v52;
  Swift::UInt v53[2];
  int v54;
  uint64_t v55;
  uint64_t v56;
  void *v57;
  int v58;
  char v59;

  uint64_t v57 = a5;
  uint64_t v49 = *(void *)(a1 + 16);
  if (!v49) {
    return swift_bridgeObjectRelease(a1);
  }
  uint64_t v6 = a3;
  if (a2 == a3) {
    return swift_bridgeObjectRelease(a1);
  }
  if (a2 > a3) {
    BUG();
  }
  uint64_t v58 = a4;
  unsigned __int8 v52 = v5;
  *(_OWORD *)long long v53 = *(_OWORD *)(a1 + 32);
  unint64_t v8 = *(unsigned char *)(a1 + 48);
  swift_bridgeObjectRetain(a1);
  si128 = _mm_load_si128((const __m128i *)v53);
  uint64_t v10 = a2;
  uint64_t v11 = (const __m128i *)(a1 + 72);
  uint64_t v12 = 1;
  uint64_t v56 = a1;
  long long v55 = v6;
  while (1)
  {
    if (v6 == v10) {
      BUG();
    }
    uint64_t v47 = v12;
    char v48 = v11;
    uint64_t v46 = v10;
    uint64_t v13 = v8;
    uint64_t v43 = si128;
    char v59 = v8 & 1;
    uint64_t v44 = v8 & 1;
    char v14 = (void *)*v57;
    *(__m128i *)long long v53 = si128;
    epi64 = _mm_extract_epi64(si128, 1);
    outlined copy of MLRecommender.Identifier(si128.i64[0], epi64, v13);
    uint64_t v54 = v13;
    uint64_t v50 = si128.i64[0];
    int v51 = epi64;
    char v17 = specialized __RawDictionaryStorage.find<A>(_:)(si128.u64[0], epi64, v13 & 1);
    BOOL v19 = (v16 & 1) == 0;
    uint64_t v20 = __OFADD__(v14[2], v19);
    char v21 = v14[2] + v19;
    if (v20) {
      BUG();
    }
    long long v22 = v16;
    if (v14[3] >= v21)
    {
      uint64_t v6 = v55;
      uint64_t v25 = *(_OWORD *)v53;
      char v23 = v59;
      if ((v58 & 1) == 0)
      {
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<MLRecommender.Identifier, Int>);
        _NativeDictionary.copy()();
        uint64_t v25 = *(_OWORD *)v53;
        uint64_t v6 = v55;
      }
    }
    else
    {
      specialized _NativeDictionary._copyOrMoveAndResize(capacity:moveElements:)(v21, v58);
      char v23 = v59;
      char v17 = specialized __RawDictionaryStorage.find<A>(_:)(v50, v51, v59);
      if ((v22 & 1) != (v24 & 1))
      {
        KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for MLRecommender.Identifier);
        BUG();
      }
      uint64_t v6 = v55;
      uint64_t v25 = *(_OWORD *)v53;
    }
    if (v22) {
      break;
    }
    uint64_t v26 = (void *)*v57;
    uint64_t v27 = 1 << v17;
    v26[(v17 >> 6) + 8] |= 1 << v17;
    uint64_t v28 = v26[6];
    int v29 = 24 * v17;
    *(_OWORD *)(v28 + v29) = v25;
    *(unsigned char *)(v28 + v29 + 16) = v23;
    uint64_t v10 = v46;
    *(void *)(v26[7] + 8 * v17) = v46;
    unint64_t v30 = v26[2];
    uint64_t v20 = __OFADD__(1, v30);
    uint64_t v31 = v30 + 1;
    if (v20) {
      BUG();
    }
    void v26[2] = v31;
    uint64_t v12 = v47;
    if (v49 == v47)
    {
      uint64_t v39 = v56;
      return swift_bridgeObjectRelease_n(v39, 2, v10, v12, v18);
    }
    if (v47 >= *(void *)(v56 + 16)) {
      BUG();
    }
    ++v10;
    uint64_t v12 = v47 + 1;
    unint64_t v8 = v48->i8[0];
    si128 = _mm_loadu_si128(v48 - 1);
    uint64_t v11 = (const __m128i *)((char *)v48 + 24);
    LOBYTE(v27) = 1;
    uint64_t v58 = v27;
    if (v6 == v10)
    {
      uint64_t v39 = v56;
      return swift_bridgeObjectRelease_n(v39, 2, v10, v12, v18);
    }
  }
  uint64_t v32 = swift_allocError(&type metadata for _MergeError, &protocol witness table for _MergeError, 0, 0);
  swift_willThrow(&type metadata for _MergeError, &protocol witness table for _MergeError, v33, v34, v35, v36);
  uint64_t v45 = v32;
  swift_errorRetain(v32);
  uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
  if (swift_dynamicCast(&demangling cache variable for type metadata for Error, &v45, v37, &type metadata for _MergeError, 0))
  {
    unint64_t v41 = 0;
    uint64_t v42 = 0xE000000000000000;
    _StringGuts.grow(_:)(30);
    v40._char object = "Swift/NativeDictionary.swift" + 0x8000000000000000;
    v40._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
    String.append(_:)(v40);
    _print_unlocked<A, B>(_:_:)(&v43, &v41, &type metadata for MLRecommender.Identifier, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    v40._uint64_t countAndFlagsBits = 39;
    v40._char object = (void *)0xE100000000000000;
    String.append(_:)(v40);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v41, v42, "Swift/NativeDictionary.swift", 28, 2, 783, 0);
    BUG();
  }
  unsigned __int8 v38 = v56;
  swift_bridgeObjectRelease(v56);
  outlined consume of MLRecommender.Identifier(v50, v51, v54);
  swift_bridgeObjectRelease(v38);
  return swift_errorRelease(v45);
}

uint64_t specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)(uint64_t a1, void (*a2)(unint64_t *), uint64_t a3, int a4, void *a5)
{
  uint64_t v6 = v5;
  uint64_t v61 = a5;
  int v62 = a4;
  unsigned __int8 v52 = a2;
  uint64_t v8 = a1;
  swift_retain_n(a1, 2);
  uint64_t v59 = a3;
  swift_retain();
  uint64_t v9 = CMLSequence.size.getter();
  uint64_t v10 = specialized RandomAccessCollection<>.distance(from:to:)(0, v9);
  swift_release();
  if (!v10)
  {
LABEL_18:
    swift_release_n(v59, 2);
    return swift_release_n(v8, 2);
  }
  uint64_t v11 = 0;
  uint64_t v60 = v8;
  while (1)
  {
    uint64_t v56 = v11;
    CMLSequence.value(at:)(v11);
    if (v6)
    {
      swift_unexpectedError(v6, "CreateML/SequenceType.swift", 27, 1, 76);
      BUG();
    }
    Swift::String v12 = CMLFeatureValue.stringValue()();
    uint64_t v58 = v13;
    if (v13)
    {
      swift_errorRelease(v58);
      swift_release();
      unint64_t v54 = 0;
      long long v55 = (char *)0xE000000000000000;
      _StringGuts.grow(_:)(37);
      swift_bridgeObjectRelease(v55);
      unint64_t v54 = 0xD000000000000022;
      long long v55 = "able.ColumnNames.swift" + 0x8000000000000000;
      uint64_t v45 = v56;
      v41._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
      char object = v41._object;
      String.append(_:)(v41);
      swift_bridgeObjectRelease(object);
      v43._uint64_t countAndFlagsBits = 46;
      v43._char object = (void *)0xE100000000000000;
      String.append(_:)(v43);
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v54, v55, "CreateML/MLDataTable.ColumnNames.swift", 38, 2, 17, 0);
      goto LABEL_26;
    }
    uint64_t countAndFlagsBits = v12._countAndFlagsBits;
    long long v15 = (char *)v12._object;
    swift_release();
    swift_retain();
    uint64_t v16 = CMLSequence.size.getter();
    uint64_t v17 = specialized RandomAccessCollection<>.distance(from:to:)(0, v16);
    swift_release();
    if (v56 >= v17) {
      BUG();
    }
    unint64_t v54 = countAndFlagsBits;
    long long v55 = v15;
    v52(&v54);
    swift_bridgeObjectRelease(v15);
    if (!v48)
    {
      uint64_t v8 = v60;
      goto LABEL_18;
    }
    uint64_t v18 = v47;
    uint64_t v53 = v49;
    unint64_t v54 = v47;
    long long v55 = v48;
    char v63 = v50;
    BOOL v19 = (void *)*v61;
    uint64_t v57 = v48;
    unint64_t v21 = specialized __RawDictionaryStorage.find<A>(_:)(v47, (uint64_t)v48);
    BOOL v22 = (v20 & 1) == 0;
    BOOL v23 = __OFADD__(v19[2], v22);
    uint64_t v24 = v19[2] + v22;
    if (v23) {
      BUG();
    }
    char v25 = v20;
    if (v19[3] >= v24)
    {
      if ((v62 & 1) == 0)
      {
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, MLUntypedColumn>);
        _NativeDictionary.copy()();
      }
    }
    else
    {
      specialized _NativeDictionary._copyOrMoveAndResize(capacity:moveElements:)(v24, v62);
      unint64_t v21 = specialized __RawDictionaryStorage.find<A>(_:)(v47, (uint64_t)v57);
      if ((v25 & 1) != (v26 & 1))
      {
        KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
        BUG();
      }
    }
    if (v25) {
      break;
    }
    uint64_t v27 = (void *)*v61;
    v27[(v21 >> 6) + 8] |= 1 << v21;
    uint64_t v28 = v27[6];
    uint64_t v29 = 16 * v21;
    *(void *)(v28 + v29) = v18;
    *(void *)(v28 + v29 + 8) = v57;
    uint64_t v30 = v27[7];
    *(void *)(v30 + v29) = v53;
    *(unsigned char *)(v30 + v29 + 8) = v63 & 1;
    uint64_t v31 = v27[2];
    BOOL v23 = __OFADD__(1, v31);
    uint64_t v32 = v31 + 1;
    if (v23) {
      BUG();
    }
    uint64_t v33 = v56 + 1;
    v27[2] = v32;
    uint64_t v8 = v60;
    swift_retain();
    uint64_t v34 = CMLSequence.size.getter();
    uint64_t v35 = specialized RandomAccessCollection<>.distance(from:to:)(0, v34);
    uint64_t v36 = swift_release();
    uint64_t v11 = v33;
    LOBYTE(v36) = 1;
    int v62 = v36;
    BOOL v37 = v33 == v35;
    uint64_t v6 = v58;
    if (v37) {
      goto LABEL_18;
    }
  }
  uint64_t v39 = swift_allocError(&type metadata for _MergeError, &protocol witness table for _MergeError, 0, 0);
  swift_willThrow();
  uint64_t v51 = v39;
  swift_errorRetain(v39);
  uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
  if (swift_dynamicCast(&demangling cache variable for type metadata for Error, &v51, v40, &type metadata for _MergeError, 0))
  {
    uint64_t v45 = 0;
    unint64_t v46 = 0xE000000000000000;
    _StringGuts.grow(_:)(30);
    v44._char object = "Swift/NativeDictionary.swift" + 0x8000000000000000;
    v44._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
    String.append(_:)(v44);
    _print_unlocked<A, B>(_:_:)(&v54, &v45, &type metadata for String, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    v44._uint64_t countAndFlagsBits = 39;
    v44._char object = (void *)0xE100000000000000;
    String.append(_:)(v44);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v45, v46, "Swift/NativeDictionary.swift", 28, 2, 783, 0);
LABEL_26:
    BUG();
  }
  swift_release();
  swift_release();
  outlined consume of Result<_DataTable, Error>(v53, v63);
  swift_release();
  swift_release();
  swift_bridgeObjectRelease(v57);
  return swift_errorRelease(v51);
}

uint64_t specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)(void *a1, uint64_t a2, uint64_t a3, char a4, void *a5)
{
  uint64_t v56 = a5;
  uint64_t v48 = a1[2];
  if (!v48 || a2 == a3) {
    return swift_bridgeObjectRelease((_BYTE)a1);
  }
  if (a2 > a3) {
    BUG();
  }
  uint64_t v51 = v5;
  uint64_t v55 = a1[4];
  uint64_t v9 = a1[5];
  uint64_t v57 = a2;
  swift_bridgeObjectRetain((_BYTE)a1);
  uint64_t v58 = v9;
  swift_bridgeObjectRetain(v9);
  uint64_t v50 = a3;
  uint64_t v49 = a2 - a3;
  if (a2 >= a3) {
LABEL_25:
  }
    BUG();
  uint64_t v10 = a1 + 7;
  uint64_t v11 = 1;
  unint64_t v54 = a1;
  while (1)
  {
    uint64_t v53 = v11;
    unsigned __int8 v12 = a4;
    unsigned __int8 v52 = v10;
    v46[0] = v55;
    v46[1] = v58;
    uint64_t v13 = (void *)*v56;
    unint64_t v16 = specialized __RawDictionaryStorage.find<A>(_:)(v55, v58);
    BOOL v17 = (v14 & 1) == 0;
    BOOL v18 = __OFADD__(v13[2], v17);
    uint64_t v19 = v13[2] + v17;
    if (v18) {
      BUG();
    }
    char v20 = v14;
    if (v13[3] >= v19)
    {
      uint64_t v22 = v57;
      BOOL v23 = v52;
      if ((v12 & 1) == 0)
      {
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, Int>);
        _NativeDictionary.copy()();
        BOOL v23 = v52;
        uint64_t v22 = v57;
      }
    }
    else
    {
      specialized _NativeDictionary._copyOrMoveAndResize(capacity:moveElements:)(v19, v12);
      unint64_t v16 = specialized __RawDictionaryStorage.find<A>(_:)(v55, v58);
      if ((v20 & 1) != (v21 & 1))
      {
        KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
        BUG();
      }
      uint64_t v22 = v57;
      BOOL v23 = v52;
    }
    unint64_t v24 = v53;
    if (v20) {
      break;
    }
    uint64_t v25 = v22 + v53 - 1;
    char v26 = (void *)*v56;
    v26[(v16 >> 6) + 8] |= 1 << v16;
    uint64_t v27 = v26[6];
    uint64_t v28 = 16 * v16;
    *(void *)(v27 + v28) = v55;
    *(void *)(v27 + v28 + 8) = v58;
    *(void *)(v26[7] + 8 * v16) = v25;
    uint64_t v29 = v26[2];
    BOOL v18 = __OFADD__(1, v29);
    uint64_t v30 = v29 + 1;
    if (v18) {
      BUG();
    }
    void v26[2] = v30;
    if (v48 == v24)
    {
      uint64_t v31 = v54;
      return swift_bridgeObjectRelease_n(v31, 2, v25, v30, v15);
    }
    uint64_t v31 = v54;
    if (v24 >= v54[2]) {
      BUG();
    }
    if (!(v24 + v49)) {
      return swift_bridgeObjectRelease_n(v31, 2, v25, v30, v15);
    }
    uint64_t v32 = v22 + v24;
    uint64_t v55 = *(v23 - 1);
    uint64_t v58 = *v23;
    uint64_t v33 = v22;
    swift_bridgeObjectRetain(v58);
    if (v32 >= v33)
    {
      uint64_t v11 = v24 + 1;
      uint64_t v10 = v23 + 2;
      a4 = 1;
      if (v32 < v50) {
        continue;
      }
    }
    goto LABEL_25;
  }
  uint64_t v34 = swift_allocError(&type metadata for _MergeError, &protocol witness table for _MergeError, 0, 0);
  swift_willThrow(&type metadata for _MergeError, &protocol witness table for _MergeError, v35, v36, v37, v38);
  uint64_t v47 = v34;
  swift_errorRetain(v34);
  uint64_t v39 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
  if (swift_dynamicCast(&demangling cache variable for type metadata for Error, &v47, v39, &type metadata for _MergeError, 0))
  {
    uint64_t v44 = 0;
    unint64_t v45 = 0xE000000000000000;
    _StringGuts.grow(_:)(30);
    v43._char object = "Swift/NativeDictionary.swift" + 0x8000000000000000;
    v43._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
    String.append(_:)(v43);
    _print_unlocked<A, B>(_:_:)(v46, &v44, &type metadata for String, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    v43._uint64_t countAndFlagsBits = 39;
    v43._char object = (void *)0xE100000000000000;
    String.append(_:)(v43);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v44, v45, "Swift/NativeDictionary.swift", 28, 2, 783, 0);
    BUG();
  }
  swift_bridgeObjectRelease(v58);
  swift_bridgeObjectRelease_n(v54, 2, v40, v41, v42);
  return swift_errorRelease(v47);
}

uint64_t _sSRsRi_zrlE17withMemoryRebound2to_qd_1_qd__m_qd_1_SRyqd__Gqd_0_YKXEtqd_0_YKs5ErrorRd_0_Ri_d__Ri_d_1_r1_lFSRyxGq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lys4Int8VsAD_pqd_1_Isgyrzr_SRys5UInt8VGqd_1_sAD_pAIRszAGRsd__sAD_pRsd_0_Ri_d_1_r_1_lIetMgyrzo_Tpq5yt_Tg507_sSRys4f5VGxs5E34_pIgyrzo_ACxsAD_pIegyrzr_lTRyt_TG5SRyAGGytsAD_pIgyrzo_Tf1ncn_n038_ss11_StringGutsV11withCStringyxxSPys4F27VGKXEKlFxSRyAEGKXEfU_yt_Tg5SPyAGGxsAD_pRi_zRi0_zlyytIsgyrzo_Tf1nnc_n(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t))
{
  if (!a1) {
    a1 = 0;
  }
  return a3(a1);
}

uint64_t specialized closure #1 in LazyMapSequence<>.map<A>(_:)(uint64_t *a1, void (*a2)(unsigned char *), uint64_t a3, uint64_t a4)
{
  return specialized closure #1 in LazyMapSequence<>.map<A>(_:)(*a1, a1[1], a2, a3, *(void *)a4, *(void (**)(void *))(a4 + 8));
}

uint64_t sub_26D896()
{
  swift_release(v0[3]);
  swift_release(v0[4]);
  swift_release(v0[6]);
  return swift_deallocObject(v0, 56, 7);
}

uint64_t partial apply for specialized closure #1 in LazyMapSequence<>.map<A>(_:)(uint64_t *a1)
{
  return specialized closure #1 in LazyMapSequence<>.map<A>(_:)(a1, *(void (**)(unsigned char *))(v1 + 16), *(void *)(v1 + 24), v1 + 32);
}

uint64_t outlined init with take of (key: String, value: MLDataValueConvertible)?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: String, value: MLDataValueConvertible)?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

unint64_t partial apply for closure #1 in CMLTable.columnType(name:)(uint64_t a1)
{
  return closure #1 in CMLTable.columnType(name:)(a1, v1);
}

uint64_t sub_26D923()
{
  swift_release(v0[4]);
  swift_bridgeObjectRelease(v0[5]);
  swift_release(v0[7]);
  return swift_deallocObject(v0, 64, 7);
}

uint64_t partial apply for closure #1 in MLDataTable.map<A>(_:)(uint64_t a1)
{
  return closure #1 in MLDataTable.map<A>(_:)(a1, *(void *)(v1 + 32), *(void *)(v1 + 40), *(void (**)(void *, uint64_t))(v1 + 48), *(void *)(v1 + 56), *(void *)(v1 + 16), *(void *)(v1 + 24));
}

uint64_t sub_26D980()
{
  swift_release(*(void *)(v0 + 40));
  return swift_deallocObject(v0, 48, 7);
}

uint64_t partial apply for closure #1 in MLDataTable.map<A>(_:)(long long *a1)
{
  return closure #1 in MLDataTable.map<A>(_:)(a1, *(void (**)(long long *, void, uint64_t))(v1 + 32), *(void *)(v1 + 40), *(void *)(v1 + 16));
}

uint64_t partial apply for closure #1 in CMLTable.fillMissing(columnNamed:with:)(uint64_t a1)
{
  return closure #1 in CMLTable.fillMissing(columnNamed:with:)(a1, *(void *)(v1 + 16), *(void *)(v1 + 24));
}

uint64_t partial apply for closure #1 in CMLTable.sorted(by:increasingOrder:)(uint64_t a1)
{
  return closure #1 in CMLTable.sorted(by:increasingOrder:)(a1, *(void *)(v1 + 16), *(_DWORD *)(v1 + 24));
}

uint64_t partial apply for closure #1 in CMLTable.stack(columnName:to:)(uint64_t a1)
{
  return closure #1 in CMLTable.stack(columnName:to:)(a1, v1[2], v1[3], v1[4]);
}

uint64_t partial apply for closure #1 in CMLTable.unstack(columnName:newColumnName:)(uint64_t a1)
{
  return closure #1 in CMLTable.unstack(columnName:newColumnName:)(a1, v1[2], v1[3], v1[4]);
}

uint64_t lazy protocol witness table accessor for type MLDataTableVisualization and conformance MLDataTableVisualization()
{
  uint64_t result = lazy protocol witness table cache variable for type MLDataTableVisualization and conformance MLDataTableVisualization;
  if (!lazy protocol witness table cache variable for type MLDataTableVisualization and conformance MLDataTableVisualization)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLDataTableVisualization, &type metadata for MLDataTableVisualization);
    lazy protocol witness table cache variable for type MLDataTableVisualization and conformance MLDataTableVisualization = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLDataTableVisualization and conformance MLDataTableVisualization;
  if (!lazy protocol witness table cache variable for type MLDataTableVisualization and conformance MLDataTableVisualization)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLDataTableVisualization, &type metadata for MLDataTableVisualization);
    lazy protocol witness table cache variable for type MLDataTableVisualization and conformance MLDataTableVisualization = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLDataTableVisualization and conformance MLDataTableVisualization;
  if (!lazy protocol witness table cache variable for type MLDataTableVisualization and conformance MLDataTableVisualization)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLDataTableVisualization, &type metadata for MLDataTableVisualization);
    lazy protocol witness table cache variable for type MLDataTableVisualization and conformance MLDataTableVisualization = result;
  }
  return result;
}

uint64_t type metadata accessor for NSMutableAttributedString()
{
  uint64_t result = lazy cache variable for type metadata for NSMutableAttributedString;
  if (!lazy cache variable for type metadata for NSMutableAttributedString)
  {
    uint64_t v1 = objc_opt_self(NSMutableAttributedString);
    uint64_t result = swift_getObjCClassMetadata(v1);
    lazy cache variable for type metadata for NSMutableAttributedString = result;
  }
  return result;
}

uint64_t base witness table accessor for Equatable in MLDataTable.JoinType()
{
  return lazy protocol witness table accessor for type MLDataTable.JoinType and conformance MLDataTable.JoinType();
}

uint64_t lazy protocol witness table accessor for type MLDataTable.JoinType and conformance MLDataTable.JoinType()
{
  uint64_t result = lazy protocol witness table cache variable for type MLDataTable.JoinType and conformance MLDataTable.JoinType;
  if (!lazy protocol witness table cache variable for type MLDataTable.JoinType and conformance MLDataTable.JoinType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLDataTable.JoinType, &type metadata for MLDataTable.JoinType);
    lazy protocol witness table cache variable for type MLDataTable.JoinType and conformance MLDataTable.JoinType = result;
  }
  return result;
}

uint64_t sub_26DA9B(uint64_t a1, Swift::String *a2)
{
  return key path getter for MLDataTable.subscript(_:) : MLDataTable(a1, a2);
}

uint64_t sub_26DAA5(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  return key path setter for MLDataTable.subscript(_:) : MLDataTable(a1, a2, a3);
}

uint64_t sub_26DAAF()
{
  return 0;
}

uint64_t sub_26DAC7(uint64_t a1, uint64_t *a2, uint64_t a3)
{
  return key path getter for MLDataTable.subscript<A>(_:) : <A>MLDataTableA(a1, a2, a3);
}

uint64_t sub_26DAD1(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  return key path setter for MLDataTable.subscript<A>(_:) : <A>MLDataTableA(a1, a2, a3);
}

uint64_t sub_26DADB()
{
  return 16;
}

void sub_26DAF5(_OWORD *a1, _OWORD *a2)
{
  *a2 = *a1;
}

uint64_t destroy for MLDataTable(uint64_t a1)
{
  return outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
}

ValueMetadata *type metadata accessor for MLDataTable()
{
  return &type metadata for MLDataTable;
}

ValueMetadata *type metadata accessor for MLDataTable.JoinType()
{
  return &type metadata for MLDataTable.JoinType;
}

void outlined consume of (MLDataValue, MLDataValue)?(void *a1, void *a2, char a3, void *a4, void *a5, char a6)
{
  if (a3 != -1)
  {
    outlined consume of MLDataValue(a1, a2, a3);
    outlined consume of MLDataValue(a4, a5, a6);
  }
}

uint64_t partial apply for closure #1 in CMLTable.init(joiningMultiple:and:columnNames:method:)(uint64_t a1)
{
  return closure #1 in CMLTable.init(joiningMultiple:and:columnNames:method:)(a1, v1[2], v1[3], v1[4]);
}

uint64_t outlined consume of Result<(), Error>(uint64_t a1, char a2)
{
  if (a2) {
    return swift_errorRelease(a1);
  }
  return result;
}

NSURL *partial apply for closure #1 in CMLTable.removeColumn(name:)(uint64_t a1)
{
  return closure #1 in CMLTable.removeColumn(name:)(a1, v1);
}

uint64_t outlined copy of MLRecommender.Identifier(uint64_t a1, uint64_t a2, char a3)
{
  if ((a3 & 1) == 0) {
    return swift_bridgeObjectRetain(a2);
  }
  return result;
}

uint64_t outlined init with copy of (String, JSONType)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, JSONType));
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t initializeWithCopy for MLDataTable(uint64_t a1, uint64_t a2)
{
  return initializeBufferWithCopyOfBuffer for MLDataTable.Rows(a1, a2);
}

unint64_t MLWordTagger.FeatureExtractorType.description.getter()
{
  unint64_t result = 0xD000000000000016;
  if (*v0)
  {
    if (*v0 == 1) {
      return 0xD000000000000027;
    }
    else {
      return 0xD000000000000046;
    }
  }
  return result;
}

BOOL static MLWordTagger.FeatureExtractorType.== infix(_:_:)(unsigned char *a1, unsigned char *a2)
{
  return *a1 == *a2;
}

void MLWordTagger.FeatureExtractorType.hash(into:)()
{
  Hasher._combine(_:)(*v0);
}

Swift::Int MLWordTagger.FeatureExtractorType.hashValue.getter()
{
  Swift::UInt v1 = *v0;
  Hasher.init(_seed:)(0);
  Hasher._combine(_:)(v1);
  return Hasher._finalize()();
}

BOOL protocol witness for static Equatable.== infix(_:_:) in conformance MLWordTagger.FeatureExtractorType(unsigned char *a1, unsigned char *a2)
{
  return static MLWordTagger.FeatureExtractorType.== infix(_:_:)(a1, a2);
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLWordTagger.FeatureExtractorType()
{
  return MLWordTagger.FeatureExtractorType.hashValue.getter();
}

void protocol witness for Hashable.hash(into:) in conformance MLWordTagger.FeatureExtractorType()
{
}

unint64_t MLWordTagger.FeatureExtractorType.debugDescription.getter()
{
  unint64_t result = 0xD000000000000016;
  if (*v0)
  {
    if (*v0 == 1) {
      return 0xD000000000000027;
    }
    else {
      return 0xD000000000000046;
    }
  }
  return result;
}

unint64_t *MLWordTagger.FeatureExtractorType.playgroundDescription.getter()
{
  unint64_t v2 = 0xD000000000000016;
  if (*v1)
  {
    if (*v1 == 1)
    {
      uint64_t v3 = "Unspecified Language" + 0x8000000000000000;
      unint64_t v2 = 0xD000000000000027;
    }
    else
    {
      uint64_t v3 = "Average Tokens per Sequence" + 0x8000000000000000;
      unint64_t v2 = 0xD000000000000046;
    }
  }
  else
  {
    uint64_t v3 = "ge Model Text Embedding" + 0x8000000000000000;
  }
  result[3] = (unint64_t)&type metadata for String;
  *unint64_t result = v2;
  result[1] = (unint64_t)v3;
  return result;
}

uint64_t base witness table accessor for Equatable in MLWordTagger.FeatureExtractorType()
{
  return lazy protocol witness table accessor for type MLWordTagger.FeatureExtractorType and conformance MLWordTagger.FeatureExtractorType();
}

uint64_t lazy protocol witness table accessor for type MLWordTagger.FeatureExtractorType and conformance MLWordTagger.FeatureExtractorType()
{
  uint64_t result = lazy protocol witness table cache variable for type MLWordTagger.FeatureExtractorType and conformance MLWordTagger.FeatureExtractorType;
  if (!lazy protocol witness table cache variable for type MLWordTagger.FeatureExtractorType and conformance MLWordTagger.FeatureExtractorType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLWordTagger.FeatureExtractorType, &type metadata for MLWordTagger.FeatureExtractorType);
    lazy protocol witness table cache variable for type MLWordTagger.FeatureExtractorType and conformance MLWordTagger.FeatureExtractorType = result;
  }
  return result;
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLWordTagger.FeatureExtractorType()
{
  return MLWordTagger.FeatureExtractorType.description.getter();
}

unint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLWordTagger.FeatureExtractorType()
{
  return MLWordTagger.FeatureExtractorType.debugDescription.getter();
}

unint64_t *protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLWordTagger.FeatureExtractorType()
{
  return MLWordTagger.FeatureExtractorType.playgroundDescription.getter();
}

ValueMetadata *type metadata accessor for MLWordTagger.FeatureExtractorType()
{
  return &type metadata for MLWordTagger.FeatureExtractorType;
}

uint64_t String.featureValue.getter(uint64_t a1, uint64_t a2)
{
  return CMLFeatureValue.__allocating_init(_:)(a1, a2);
}

uint64_t Int.dataValue.getter(uint64_t a1)
{
  *(void *)uint64_t result = a1;
  *(void *)(result + 8) = 0;
  *(unsigned char *)(result + 16) = 0;
  return result;
}

uint64_t String.dataValue.getter(uint64_t a1, uint64_t a2)
{
  *(void *)uint64_t v2 = a1;
  *(void *)(v2 + 8) = a2;
  *(unsigned char *)(v2 + 16) = 2;
  return swift_bridgeObjectRetain(a2);
}

uint64_t Bool.featureValue.getter(char a1)
{
  uint64_t v1 = specialized handling<A, B>(_:_:)(a1 & 1);
  if (!v1) {
    BUG();
  }
  uint64_t v2 = type metadata accessor for CMLFeatureValue();
  swift_allocObject(v2, 25, 7);
  return CMLFeatureValue.init(rawValue:ownsValue:)(v1, 1);
}

uint64_t Int.featureValue.getter(uint64_t a1)
{
  uint64_t v1 = specialized handling<A, B>(_:_:)(a1);
  if (!v1) {
    BUG();
  }
  uint64_t v2 = type metadata accessor for CMLFeatureValue();
  swift_allocObject(v2, 25, 7);
  return CMLFeatureValue.init(rawValue:ownsValue:)(v1, 1);
}

uint64_t MLDataValueConvertible.featureValue.getter(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(void *)(a1 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v3 + 16))(&v15, v2, a1);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureValueConvertible);
  if (swift_dynamicCast(&v20, &v15, a1, v7, 6))
  {
    outlined init with take of MLIdentifier(&v20, (uint64_t)&v16);
    uint64_t v8 = v18;
    uint64_t v9 = v19;
    __swift_project_boxed_opaque_existential_0Tm(&v16, v18);
    uint64_t v10 = (*(uint64_t (**)(uint64_t, uint64_t))(v9 + 24))(v8, v9);
    __swift_destroy_boxed_opaque_existential_1Tm(&v16);
  }
  else
  {
    long long v21 = 0;
    long long v20 = 0;
    uint64_t v22 = 0;
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v20, &demangling cache variable for type metadata for FeatureValueConvertible?);
    double v11 = (*(double (**)(uint64_t, uint64_t))(a2 + 32))(a1, a2);
    long long v12 = v16;
    long long v20 = v16;
    LOBYTE(v21) = v17;
    char v13 = v17;
    uint64_t v10 = MLDataValue.featureValue.getter(v11);
    outlined consume of MLDataValue((void *)v12, *((void **)&v12 + 1), v13);
  }
  return v10;
}

uint64_t Double.dataValue.getter(double a1)
{
  *(double *)uint64_t result = a1;
  *(void *)(result + 8) = 0;
  *(unsigned char *)(result + 16) = 1;
  return result;
}

uint64_t static MLDataValueConvertible.makeInstance(featureValue:)(uint64_t a1, uint64_t a2, uint64_t a3, double a4)
{
  uint64_t v30 = a3;
  uint64_t v6 = v4;
  uint64_t v7 = dynamic_cast_existential_1_conditional(v5, v5, (uint64_t)&protocol descriptor for FeatureValueConvertible);
  if (v7)
  {
    uint64_t v9 = v7;
    uint64_t v29 = v6;
    uint64_t v30 = a2;
    uint64_t v25 = *(void (**)(uint64_t, uint64_t, uint64_t))(v8 + 16);
    uint64_t v10 = v8;
    uint64_t v28 = &v20;
    uint64_t v26 = type metadata accessor for Optional(0, v7);
    uint64_t v27 = *(void *)(v26 - 8);
    int64_t v11 = *(void *)(v27 + 64);
    long long v12 = alloca(v11);
    char v13 = alloca(v11);
    swift_retain();
    v25(a1, v9, v10);
    if (__swift_getEnumTagSinglePayload((uint64_t)&v20, 1, v9) == 1)
    {
      (*(void (**)(long long *, uint64_t))(v27 + 8))(&v20, v26);
      long long v23 = 0;
      long long v22 = 0;
      uint64_t v24 = 0;
    }
    else
    {
      *((void *)&v23 + 1) = v9;
      uint64_t v24 = v10;
      uint64_t v15 = __swift_allocate_boxed_opaque_existential_1(&v22);
      (*(void (**)(void *, long long *, uint64_t))(*(void *)(v9 - 8) + 32))(v15, &v20, v9);
    }
    uint64_t v16 = v30;
    uint64_t v17 = v29;
    uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureValueConvertible?);
    unsigned __int8 v19 = swift_dynamicCast(v17, &v22, v18, v16, 6);
    return __swift_storeEnumTagSinglePayload(v17, v19 ^ 1u, 1, v16);
  }
  else
  {
    swift_retain();
    MLDataValue.init(_:)(a1, a4);
    long long v20 = v22;
    char v21 = v23;
    return (*(uint64_t (**)(long long *, uint64_t))(v30 + 16))(&v20, a2);
  }
}

uint64_t Double.init(from:)(uint64_t a1, double a2)
{
  return *(void *)&a2;
}

uint64_t String.init(from:)()
{
  uint64_t countAndFlagsBits = CMLFeatureValue.stringValue()()._countAndFlagsBits;
  swift_release();
  if (v1)
  {
    swift_errorRelease(v1);
    return 0;
  }
  return countAndFlagsBits;
}

uint64_t Double.featureValue.getter()
{
  uint64_t v0 = specialized handling<A, B>(_:_:)();
  if (!v0) {
    BUG();
  }
  uint64_t v1 = type metadata accessor for CMLFeatureValue();
  swift_allocObject(v1, 25, 7);
  return CMLFeatureValue.init(rawValue:ownsValue:)(v0, 1);
}

uint64_t MLDataValueConvertible.featureColumn.getter(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(void *)(a1 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v3 + 16))(&v13, v2, a1);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for CMLColumnConvertible);
  if (swift_dynamicCast(v17, &v13, a1, v7, 6))
  {
    outlined init with take of MLIdentifier(v17, (uint64_t)v14);
    uint64_t v8 = v15;
    uint64_t v9 = v16;
    __swift_project_boxed_opaque_existential_0Tm(v14, v15);
    uint64_t v10 = (*(uint64_t (**)(uint64_t, uint64_t))(v9 + 8))(v8, v9);
    __swift_destroy_boxed_opaque_existential_1Tm(v14);
  }
  else
  {
    memset(v17, 0, sizeof(v17));
    uint64_t v18 = 0;
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v17, &demangling cache variable for type metadata for CMLColumnConvertible?);
    type metadata accessor for CMLColumn();
    uint64_t v11 = MLDataValueConvertible.featureValue.getter(a1, a2);
    return CMLColumn.__allocating_init(repeating:count:)(v11, 1);
  }
  return v10;
}

void *Int.init(from:)(uint64_t a1)
{
  uint64_t result = *(void **)a1;
  char v2 = *(unsigned char *)(a1 + 16);
  if (v2)
  {
    outlined consume of MLDataValue(*(void **)a1, *(void **)(a1 + 8), v2);
    return 0;
  }
  return result;
}

unsigned char *protocol witness for static MLDataValueConvertible.dataValueType.getter in conformance Int()
{
  return static Bool.dataValueType.getter();
}

void *protocol witness for MLDataValueConvertible.init(from:) in conformance Int(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t result = Int.init(from:)(a1);
  *(void *)uint64_t v2 = result;
  *(unsigned char *)(v2 + 8) = v4 & 1;
  return result;
}

uint64_t protocol witness for MLDataValueConvertible.dataValue.getter in conformance Int()
{
  return Int.dataValue.getter(*v0);
}

uint64_t protocol witness for FeatureValueConvertible.init(from:) in conformance Int(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t result = Int.init(from:)(a1);
  *(void *)uint64_t v2 = result;
  *(unsigned char *)(v2 + 8) = v4 & 1;
  return result;
}

uint64_t protocol witness for FeatureValueConvertible.featureValue.getter in conformance Int()
{
  return Int.featureValue.getter(*v0);
}

unsigned char *static Bool.dataValueType.getter()
{
  *uint64_t result = 0;
  return result;
}

char Bool.init(from:)(uint64_t a1)
{
  uint64_t v2 = *(void **)a1;
  char v3 = *(unsigned char *)(a1 + 16);
  if (!v3) {
    return v2 != 0;
  }
  outlined consume of MLDataValue(v2, *(void **)(a1 + 8), v3);
  return 2;
}

uint64_t Bool.dataValue.getter(char a1)
{
  *(void *)uint64_t result = a1 & 1;
  *(void *)(result + 8) = 0;
  *(unsigned char *)(result + 16) = 0;
  return result;
}

BOOL Bool.init(from:)(uint64_t a1)
{
  uint64_t v1 = specialized handling<A, B>(_:_:)(*(void *)(a1 + 16));
  swift_release();
  return v1 != 0;
}

char protocol witness for MLDataValueConvertible.init(from:) in conformance Bool(uint64_t a1)
{
  uint64_t v2 = v1;
  char result = Bool.init(from:)(a1);
  char *v2 = result;
  return result;
}

unsigned char *protocol witness for MLDataValueConvertible.init() in conformance Bool()
{
  *char result = 0;
  return result;
}

uint64_t protocol witness for MLDataValueConvertible.dataValue.getter in conformance Bool()
{
  return Bool.dataValue.getter(*v0);
}

BOOL protocol witness for FeatureValueConvertible.init(from:) in conformance Bool(uint64_t a1)
{
  uint64_t v2 = v1;
  BOOL result = Bool.init(from:)(a1);
  BOOL *v2 = result;
  return result;
}

uint64_t protocol witness for FeatureValueConvertible.featureValue.getter in conformance Bool()
{
  return Bool.featureValue.getter(*v0);
}

void *Int64.init(from:)(uint64_t a1)
{
  BOOL result = *(void **)a1;
  char v2 = *(unsigned char *)(a1 + 16);
  if (v2)
  {
    outlined consume of MLDataValue(*(void **)a1, *(void **)(a1 + 8), v2);
    return 0;
  }
  return result;
}

uint64_t Int.init(from:)(uint64_t a1)
{
  uint64_t v1 = specialized handling<A, B>(_:_:)(*(void *)(a1 + 16));
  swift_release();
  return v1;
}

uint64_t Int64.featureValue.getter(uint64_t a1)
{
  uint64_t v1 = specialized handling<A, B>(_:_:)(a1);
  if (!v1) {
    BUG();
  }
  uint64_t v2 = type metadata accessor for CMLFeatureValue();
  swift_allocObject(v2, 25, 7);
  return CMLFeatureValue.init(rawValue:ownsValue:)(v1, 1);
}

void *protocol witness for MLDataValueConvertible.init(from:) in conformance Int64(uint64_t a1)
{
  uint64_t v2 = v1;
  BOOL result = Int64.init(from:)(a1);
  *(void *)uint64_t v2 = result;
  *(unsigned char *)(v2 + 8) = v4 & 1;
  return result;
}

uint64_t protocol witness for FeatureValueConvertible.featureValue.getter in conformance Int64()
{
  return Int64.featureValue.getter(*v0);
}

unsigned char *static Double.dataValueType.getter()
{
  *BOOL result = 1;
  return result;
}

void *Double.init(from:)(uint64_t a1)
{
  BOOL result = *(void **)a1;
  char v2 = *(unsigned char *)(a1 + 16);
  if (v2 != 1)
  {
    outlined consume of MLDataValue(*(void **)a1, *(void **)(a1 + 8), v2);
    return 0;
  }
  return result;
}

unsigned char *protocol witness for static MLDataValueConvertible.dataValueType.getter in conformance Double()
{
  return static Double.dataValueType.getter();
}

void *protocol witness for MLDataValueConvertible.init(from:) in conformance Double(uint64_t a1)
{
  uint64_t v2 = v1;
  BOOL result = Double.init(from:)(a1);
  *(void *)uint64_t v2 = result;
  *(unsigned char *)(v2 + 8) = v4 & 1;
  return result;
}

uint64_t protocol witness for MLDataValueConvertible.dataValue.getter in conformance Double()
{
  return Double.dataValue.getter(*v0);
}

uint64_t protocol witness for FeatureValueConvertible.init(from:) in conformance Double(uint64_t a1, double a2)
{
  uint64_t v3 = v2;
  uint64_t result = Double.init(from:)(a1, a2);
  *(void *)uint64_t v3 = result;
  *(unsigned char *)(v3 + 8) = v5 & 1;
  return result;
}

uint64_t protocol witness for FeatureValueConvertible.featureValue.getter in conformance Double()
{
  return Double.featureValue.getter();
}

unsigned char *static String.dataValueType.getter()
{
  *uint64_t result = 2;
  return result;
}

void *String.init(from:)(uint64_t a1)
{
  uint64_t result = *(void **)a1;
  char v2 = *(unsigned char *)(a1 + 16);
  if (v2 != 2)
  {
    outlined consume of MLDataValue(*(void **)a1, *(void **)(a1 + 8), v2);
    return 0;
  }
  return result;
}

unsigned char *protocol witness for static MLDataValueConvertible.dataValueType.getter in conformance String()
{
  return static String.dataValueType.getter();
}

void *protocol witness for MLDataValueConvertible.init(from:) in conformance String(uint64_t a1)
{
  char v2 = v1;
  uint64_t result = String.init(from:)(a1);
  void *v2 = result;
  v2[1] = v4;
  return result;
}

uint64_t protocol witness for MLDataValueConvertible.dataValue.getter in conformance String()
{
  return String.dataValue.getter(*v0, v0[1]);
}

uint64_t protocol witness for FeatureValueConvertible.init(from:) in conformance String()
{
  uint64_t v1 = v0;
  uint64_t result = String.init(from:)();
  *uint64_t v1 = result;
  v1[1] = v3;
  return result;
}

uint64_t protocol witness for FeatureValueConvertible.featureValue.getter in conformance String()
{
  return String.featureValue.getter(*v0, v0[1]);
}

uint64_t dispatch thunk of static MLDataValueConvertible.dataValueType.getter(uint64_t a1, uint64_t a2)
{
  return (*(uint64_t (**)(void))(a2 + 8))();
}

uint64_t dispatch thunk of MLDataValueConvertible.init(from:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return (*(uint64_t (**)(void))(a3 + 16))();
}

uint64_t dispatch thunk of MLDataValueConvertible.init()(uint64_t a1, uint64_t a2)
{
  return (*(uint64_t (**)(void))(a2 + 24))();
}

uint64_t dispatch thunk of MLDataValueConvertible.dataValue.getter(uint64_t a1, uint64_t a2)
{
  return (*(uint64_t (**)(void))(a2 + 32))();
}

uint64_t dynamic_cast_existential_1_conditional(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (!swift_conformsToProtocol2(a2, a3)) {
    return 0;
  }
  return a1;
}

unsigned char *static Int.dataValueType.getter()
{
  return static Bool.dataValueType.getter();
}

unsigned char *static Int64.dataValueType.getter()
{
  return static Bool.dataValueType.getter();
}

uint64_t Int64.dataValue.getter(uint64_t a1)
{
  return Int.dataValue.getter(a1);
}

uint64_t protocol witness for FeatureValueConvertible.init(from:) in conformance Int64(uint64_t a1)
{
  return protocol witness for FeatureValueConvertible.init(from:) in conformance Int(a1);
}

uint64_t protocol witness for MLDataValueConvertible.dataValue.getter in conformance Int64()
{
  return protocol witness for MLDataValueConvertible.dataValue.getter in conformance Int();
}

id MLObjectDetector.model.getter()
{
  return *(id *)(*(void *)v0 + 24);
}

uint64_t MLObjectDetector.modelParameters.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLObjectDetector(0);
  return outlined init with copy of MLObjectDetector.ModelParameters(v1 + *(int *)(v3 + 20), v2);
}

uint64_t type metadata accessor for MLObjectDetector(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLObjectDetector;
  if (!type metadata singleton initialization cache for MLObjectDetector) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLObjectDetector);
  }
  return result;
}

uint64_t outlined init with copy of MLObjectDetector.ModelParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLObjectDetector.ModelParameters(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

void *MLObjectDetector.trainingMetrics.getter(double a1)
{
  return _Model.makeDetectorMetrics(onTraining:)(1, a1);
}

void *MLObjectDetector.validationMetrics.getter(double a1)
{
  uint64_t v2 = v1;
  if (_Model.hasObjectDetectorValidationMetrics.getter(a1)) {
    return _Model.makeDetectorMetrics(onTraining:)(0, a1);
  }
  uint64_t v4 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t result = (void *)swift_allocError(&type metadata for MLCreateError, v4, 0, 0);
  *(void *)uint64_t v5 = 0xD000000000000035;
  *(void *)(v5 + 8) = " the given table." + 0x8000000000000000;
  *(_OWORD *)(v5 + 16) = 0;
  *(_OWORD *)(v5 + 32) = 0;
  *(unsigned char *)(v5 + 48) = 0;
  *(void *)uint64_t v2 = result;
  *(_OWORD *)(v2 + 8) = 0;
  *(void *)(v2 + 24) = 0;
  *(unsigned char *)(v2 + 32) = 1;
  return result;
}

uint64_t MLObjectDetector.init(trainingData:parameters:annotationType:)(void (*a1)(ValueMetadata **, uint64_t), uint64_t a2, __int16 *a3, __m128 a4)
{
  Swift::String v43 = v4;
  __int16 v50 = *a3;
  char v6 = *((unsigned char *)a3 + 2);
  static _ImageUtilities.getImageURLsAndObjectAnnotations(from:imageColumnName:labelColumnName:)(a1, 0, 0, 0, 0, a4);
  if (v5)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(a2, type metadata accessor for MLObjectDetector.ModelParameters);
    return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)a1, type metadata accessor for MLObjectDetector.DataSource);
  }
  char v49 = v6;
  unint64_t v46 = a1;
  uint64_t v44 = a2;
  uint64_t v8 = v38;
  char v9 = v39;
  static MLObjectDetector.validateInput(trainingData:imageColumn:annotationColumn:)((uint64_t)&v38, 0x7461506567616D69, 0xE900000000000068, 0x697461746F6E6E61, 0xEA00000000006E6FLL, *(double *)a4.i64);
  uint64_t v37 = type metadata accessor for MLObjectDetector(0);
  uint64_t v10 = (uint64_t)v43 + *(int *)(v37 + 20);
  uint64_t v47 = 0;
  uint64_t v11 = v44;
  uint64_t v45 = v10;
  outlined init with copy of MLObjectDetector.ModelParameters(v44, v10);
  LOWORD(v41) = v50;
  BYTE2(v41) = v49;
  uint64_t v48 = v8;
  uint64_t v38 = v8;
  char v39 = v9;
  uint64_t v12 = v11;
  uint64_t v13 = v47;
  uint64_t v14 = static MLObjectDetector.validateAndConvertParameters(_:annotationType:imageColumn:annotationColumn:table:)(v11, &v41, 0x7461506567616D69, 0xE900000000000068, 0x697461746F6E6E61, (int *)0xEA00000000006E6FLL, a4, &v38);
  if (v13)
  {
    uint64_t v47 = v13;
    outlined destroy of MLActivityClassifier.ModelParameters(v11, type metadata accessor for MLObjectDetector.ModelParameters);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v46, type metadata accessor for MLObjectDetector.DataSource);
    outlined consume of Result<_DataTable, Error>(v48, v9);
    return outlined destroy of MLActivityClassifier.ModelParameters(v45, type metadata accessor for MLObjectDetector.ModelParameters);
  }
  char v51 = v9;
  uint64_t v15 = v14;
  swift_retain();
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLObjectDetector.init(trainingData:parameters:annotationType:), v15);
  uint64_t v17 = v16;
  swift_release();
  uint64_t v47 = 0;
  uint64_t v45 = v15;
  *Swift::String v43 = v17;
  if (!AnalyticsReporter.init()())
  {
    uint64_t v38 = v48;
    char v39 = v51;
    int v18 = MLDataTable.size.getter();
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_objectDetector, (Swift::String)__PAIR128__((unint64_t)(" training session" + 0x8000000000000000), 0xD000000000000011), (float)v18);
    unsigned __int8 v19 = (int *)type metadata accessor for MLObjectDetector.ModelParameters(0);
    uint64_t v20 = v19[6];
    float v21 = 0.0;
    if (!*(unsigned char *)(v12 + v20 + 8)) {
      float v21 = (float)(int)*(void *)(v12 + v20);
    }
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_objectDetector, (Swift::String)__PAIR128__(0xEE00736E6F697461, 0x726574492078614DLL), v21);
    uint64_t v22 = v19[5];
    float v23 = 0.0;
    if (!*(unsigned char *)(v12 + v22 + 8)) {
      float v23 = (float)(int)*(void *)(v12 + v22);
    }
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_objectDetector, (Swift::String)__PAIR128__(0xEA0000000000657ALL, 0x6953206863746142), v23);
    Swift::Float v24 = (float)(int)*(void *)(v12 + v19[7]);
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_objectDetector, (Swift::String)__PAIR128__(0xEF68746469572065, 0x7A69532064697247), v24);
    Swift::Float v25 = (float)(int)*(void *)(v12 + v19[8]);
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_objectDetector, (Swift::String)__PAIR128__((unint64_t)("etrics not available." + 0x8000000000000000), 0xD000000000000010), v25);
    outlined init with copy of Any?(v12 + v19[10], (uint64_t)&v38);
    if (v40)
    {
      if (swift_dynamicCast(&v41, &v38, (char *)&type metadata for Any + 8, &type metadata for MLObjectDetector.ModelParameters.ModelAlgorithmType, 6))
      {
        uint64_t v26 = v41;
        char v27 = v42;
LABEL_16:
        uint64_t v38 = v26;
        char v39 = v27 & 1;
        uint64_t v28 = MLObjectDetector.ModelParameters.ModelAlgorithmType.dictionary.getter();
        char v29 = v28;
        uint64_t v30 = Dictionary.description.getter(v28, &type metadata for String, (char *)&type metadata for Any + 8, &protocol witness table for String);
        unint64_t v32 = v31;
        swift_bridgeObjectRelease(v29);
        AnalyticsReporter.reportParameterSettings(model:parameterName:parameterValue:)(CreateML_ModelType_objectDetector, (Swift::String)__PAIR128__(0xE90000000000006DLL, 0x687469726F676C41), (Swift::String)__PAIR128__(v32, v30));
        swift_bridgeObjectRelease(v32);
        outlined consume of Result<_DataTable, Error>(v48, v51);
        swift_release();
        uint64_t v12 = v44;
        goto LABEL_17;
      }
    }
    else
    {
      outlined destroy of Any?((uint64_t)&v38);
    }
    char v27 = 1;
    uint64_t v26 = 0;
    goto LABEL_16;
  }
  outlined consume of Result<_DataTable, Error>(v48, v51);
  swift_release();
LABEL_17:
  char v33 = v50;
  uint64_t v34 = (uint64_t)v46;
  char v35 = HIBYTE(v50);
  outlined destroy of MLActivityClassifier.ModelParameters(v12, type metadata accessor for MLObjectDetector.ModelParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v34, type metadata accessor for MLObjectDetector.DataSource);
  uint64_t result = *(int *)(v37 + 24);
  uint64_t v36 = v43;
  *((unsigned char *)v43 + result) = v33;
  *((unsigned char *)v36 + result + 1) = v35;
  *((unsigned char *)v36 + result + 2) = v49;
  return result;
}

uint64_t closure #1 in MLObjectDetector.init(trainingData:parameters:annotationType:)(uint64_t a1, uint64_t a2)
{
  *(void *)(v2 + 16) = a1;
  uint64_t v3 = type metadata accessor for _Model();
  swift_allocObject(v3, 48, 7);
  uint64_t v4 = dword_3AABDC;
  swift_retain();
  uint64_t v5 = (void *)swift_task_alloc(v4);
  *(void *)(v2 + 24) = v5;
  *uint64_t v5 = v2;
  v5[1] = closure #1 in MLRandomForestRegressor.init(checkpoint:);
  return _Model.init(type:parameters:modelOptions:)(17, a2, 0);
}

uint64_t partial apply for closure #1 in MLObjectDetector.init(trainingData:parameters:annotationType:)(uint64_t a1)
{
  uint64_t v3 = (void *)swift_task_alloc(dword_3AD75C);
  *(void *)(v2 + 16) = v3;
  void *v3 = v2;
  v3[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLObjectDetector.init(trainingData:parameters:annotationType:)(a1, v1);
}

uint64_t MLObjectDetector.init(trainingData:imageColumn:annotationColumn:annotationType:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, int *a5, char *a6, __m128 a7, uint64_t a8)
{
  uint64_t v45 = v8;
  uint64_t v12 = *(void *)a1;
  char v13 = *(unsigned char *)(a1 + 8);
  char v50 = *a6;
  __int16 v49 = *(_WORD *)(a6 + 1);
  uint64_t v48 = v12;
  uint64_t v38 = v12;
  char v51 = v13;
  char v39 = v13;
  uint64_t v46 = a4;
  uint64_t v47 = a5;
  static MLObjectDetector.validateInput(trainingData:imageColumn:annotationColumn:)((uint64_t)&v38, a2, a3, a4, (uint64_t)a5, *(double *)a7.i64);
  if (v9)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(a8, type metadata accessor for MLObjectDetector.ModelParameters);
    swift_bridgeObjectRelease(a3);
    swift_bridgeObjectRelease((_BYTE)v47);
    return outlined consume of Result<_DataTable, Error>(v48, v51);
  }
  uint64_t v42 = type metadata accessor for MLObjectDetector(0);
  uint64_t v41 = (uint64_t)v45 + *(int *)(v42 + 20);
  outlined init with copy of MLObjectDetector.ModelParameters(a8, v41);
  LOBYTE(v43) = v50;
  *(_WORD *)((char *)&v43 + 1) = v49;
  uint64_t v38 = v48;
  char v39 = v51;
  uint64_t v15 = static MLObjectDetector.validateAndConvertParameters(_:annotationType:imageColumn:annotationColumn:table:)(a8, &v43, a2, a3, v46, v47, a7, &v38);
  swift_bridgeObjectRelease(a3);
  swift_bridgeObjectRelease((_BYTE)v47);
  swift_retain();
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLObjectDetector.init(trainingData:imageColumn:annotationColumn:annotationType:parameters:), v15);
  uint64_t v17 = v16;
  swift_release();
  int v18 = v45;
  *uint64_t v45 = v17;
  unsigned __int8 v19 = v18;
  if (!AnalyticsReporter.init()())
  {
    uint64_t v46 = v15;
    uint64_t v47 = 0;
    uint64_t v20 = v48;
    uint64_t v38 = v48;
    char v21 = v51;
    char v39 = v51;
    int v22 = MLDataTable.size.getter();
    outlined consume of Result<_DataTable, Error>(v20, v21);
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_objectDetector, (Swift::String)__PAIR128__((unint64_t)(" training session" + 0x8000000000000000), 0xD000000000000011), (float)v22);
    float v23 = (int *)type metadata accessor for MLObjectDetector.ModelParameters(0);
    uint64_t v24 = v23[6];
    float v25 = 0.0;
    if (!*(unsigned char *)(a8 + v24 + 8)) {
      float v25 = (float)(int)*(void *)(a8 + v24);
    }
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_objectDetector, (Swift::String)__PAIR128__(0xEE00736E6F697461, 0x726574492078614DLL), v25);
    uint64_t v26 = v23[5];
    float v27 = 0.0;
    if (!*(unsigned char *)(a8 + v26 + 8)) {
      float v27 = (float)(int)*(void *)(a8 + v26);
    }
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_objectDetector, (Swift::String)__PAIR128__(0xEA0000000000657ALL, 0x6953206863746142), v27);
    Swift::Float v28 = (float)(int)*(void *)(a8 + v23[7]);
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_objectDetector, (Swift::String)__PAIR128__(0xEF68746469572065, 0x7A69532064697247), v28);
    Swift::Float v29 = (float)(int)*(void *)(a8 + v23[8]);
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_objectDetector, (Swift::String)__PAIR128__((unint64_t)("etrics not available." + 0x8000000000000000), 0xD000000000000010), v29);
    outlined init with copy of Any?(a8 + v23[10], (uint64_t)&v38);
    if (v40)
    {
      if (swift_dynamicCast(&v43, &v38, (char *)&type metadata for Any + 8, &type metadata for MLObjectDetector.ModelParameters.ModelAlgorithmType, 6))
      {
        uint64_t v30 = v43;
        char v31 = v44;
LABEL_14:
        uint64_t v38 = v30;
        char v39 = v31 & 1;
        uint64_t v32 = MLObjectDetector.ModelParameters.ModelAlgorithmType.dictionary.getter();
        char v33 = v32;
        uint64_t v34 = Dictionary.description.getter(v32, &type metadata for String, (char *)&type metadata for Any + 8, &protocol witness table for String);
        unint64_t v36 = v35;
        swift_bridgeObjectRelease(v33);
        AnalyticsReporter.reportParameterSettings(model:parameterName:parameterValue:)(CreateML_ModelType_objectDetector, (Swift::String)__PAIR128__(0xE90000000000006DLL, 0x687469726F676C41), (Swift::String)__PAIR128__(v36, v34));
        swift_release();
        swift_bridgeObjectRelease(v36);
        outlined destroy of MLActivityClassifier.ModelParameters(a8, type metadata accessor for MLObjectDetector.ModelParameters);
        unsigned __int8 v19 = v45;
        goto LABEL_15;
      }
    }
    else
    {
      outlined destroy of Any?((uint64_t)&v38);
    }
    char v31 = 1;
    uint64_t v30 = 0;
    goto LABEL_14;
  }
  outlined destroy of MLActivityClassifier.ModelParameters(a8, type metadata accessor for MLObjectDetector.ModelParameters);
  swift_release();
  outlined consume of Result<_DataTable, Error>(v48, v51);
LABEL_15:
  __int16 v37 = v49;
  uint64_t result = *(int *)(v42 + 24);
  *((unsigned char *)v19 + result) = v50;
  *(_WORD *)((char *)v19 + result + 1) = v37;
  return result;
}

uint64_t closure #1 in MLObjectDetector.init(trainingData:imageColumn:annotationColumn:annotationType:parameters:)(uint64_t a1, uint64_t a2)
{
  *(void *)(v2 + 16) = a1;
  uint64_t v3 = type metadata accessor for _Model();
  swift_allocObject(v3, 48, 7);
  uint64_t v4 = dword_3AABDC;
  swift_retain();
  uint64_t v5 = (void *)swift_task_alloc(v4);
  *(void *)(v2 + 24) = v5;
  *uint64_t v5 = v2;
  v5[1] = closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:);
  return _Model.init(type:parameters:modelOptions:)(17, a2, 0);
}

uint64_t partial apply for closure #1 in MLObjectDetector.init(trainingData:imageColumn:annotationColumn:annotationType:parameters:)(uint64_t a1)
{
  uint64_t v3 = (void *)swift_task_alloc(dword_3AD76C);
  *(void *)(v2 + 16) = v3;
  void *v3 = v2;
  v3[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLObjectDetector.init(trainingData:imageColumn:annotationColumn:annotationType:parameters:)(a1, v1);
}

void *MLObjectDetector.description.getter(double a1)
{
  return MLObjectDetector.debugDescription.getter(a1);
}

void *MLObjectDetector.debugDescription.getter(double a1)
{
  uint64_t v2 = *(void **)v1;
  v52._char object = (void *)ModelType.description.getter(*(_DWORD *)(*(void *)v1 + 32));
  uint64_t v55 = v3;
  type metadata accessor for MLObjectDetector(0);
  uint64_t v56 = v1;
  v52._uint64_t countAndFlagsBits = MLObjectDetector.ModelParameters.description.getter();
  char v51 = v4;
  uint64_t v57 = v2;
  _Model.makeDetectorMetrics(onTraining:)(1, a1);
  if (v36)
  {
    uint64_t v38 = 0;
    *(void *)&long long v39 = 0xE000000000000000;
    uint64_t v42 = v33;
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    _print_unlocked<A, B>(_:_:)(&v42, &v38, v5, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    outlined consume of Result<MLObjectDetector.Metrics, Error>(v33, v34, *((uint64_t *)&v34 + 1), v35, 1);
    v54._uint64_t countAndFlagsBits = v38;
    uint64_t v53 = (void *)v39;
  }
  else
  {
    outlined copy of Result<MLObjectDetector.Metrics, Error>(v33, v34, *((uint64_t *)&v34 + 1), v35, 0);
    swift_bridgeObjectRelease(v34);
    swift_bridgeObjectRelease(v33);
    uint64_t v38 = v33;
    long long v39 = v34;
    uint64_t v40 = v35;
    char v41 = 0;
    v54._uint64_t countAndFlagsBits = MLObjectDetectorMetrics.description.getter();
    uint64_t v53 = v6;
    outlined consume of Result<MLObjectDetector.Metrics, Error>(v33, v34, *((uint64_t *)&v34 + 1), v35, 0);
  }
  if (_Model.hasObjectDetectorValidationMetrics.getter(a1))
  {
    _Model.makeDetectorMetrics(onTraining:)(0, a1);
    uint64_t v7 = v38;
    uint64_t v8 = *((void *)&v39 + 1);
    uint64_t v9 = v39;
    uint64_t v10 = v40;
    char v11 = v41;
  }
  else
  {
    uint64_t v12 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v10 = 0;
    uint64_t v7 = swift_allocError(&type metadata for MLCreateError, v12, 0, 0);
    *(void *)uint64_t v13 = 0xD000000000000035;
    *(void *)(v13 + 8) = " the given table." + 0x8000000000000000;
    a1 = 0.0;
    *(_OWORD *)(v13 + 16) = 0;
    *(_OWORD *)(v13 + 32) = 0;
    *(unsigned char *)(v13 + 48) = 0;
    uint64_t v38 = v7;
    long long v39 = 0;
    uint64_t v40 = 0;
    char v41 = 1;
    char v11 = 1;
    uint64_t v8 = 0;
    uint64_t v9 = 0;
  }
  outlined consume of Result<MLObjectDetector.Metrics, Error>(v7, v9, v8, v10, v11);
  char v14 = _Model.hasObjectDetectorValidationMetrics.getter(a1);
  LOBYTE(v56) = v11;
  if ((v14 & 1) == 0)
  {
    uint64_t v18 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v57 = 0;
    uint64_t v15 = swift_allocError(&type metadata for MLCreateError, v18, 0, 0);
    *(void *)uint64_t v19 = 0xD000000000000035;
    *(void *)(v19 + 8) = " the given table." + 0x8000000000000000;
    *(_OWORD *)(v19 + 16) = 0;
    *(_OWORD *)(v19 + 32) = 0;
    *(unsigned char *)(v19 + 48) = 0;
    uint64_t v42 = v15;
    uint64_t v44 = 0;
    long long v43 = 0;
    char v45 = 1;
    uint64_t v16 = 0;
    uint64_t v17 = 0;
    goto LABEL_11;
  }
  _Model.makeDetectorMetrics(onTraining:)(0, a1);
  uint64_t v15 = v42;
  uint64_t v16 = *((void *)&v43 + 1);
  uint64_t v17 = v44;
  if (v45)
  {
    uint64_t v57 = (void *)v43;
LABEL_11:
    char object = 0;
    uint64_t v47 = (void *)0xE000000000000000;
    v37._uint64_t countAndFlagsBits = v15;
    uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    _print_unlocked<A, B>(_:_:)(&v37, &object, v20, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    outlined consume of Result<MLObjectDetector.Metrics, Error>(v15, (uint64_t)v57, v16, v17, 1);
    v54._char object = object;
    uint64_t v57 = v47;
    goto LABEL_13;
  }
  uint64_t v21 = v43;
  outlined copy of Result<MLObjectDetector.Metrics, Error>(v42, v43, *((uint64_t *)&v43 + 1), v44, 0);
  swift_bridgeObjectRelease(v21);
  swift_bridgeObjectRelease(v15);
  char object = (void *)v15;
  uint64_t v47 = (void *)v21;
  uint64_t v48 = v16;
  uint64_t v49 = v17;
  char v50 = 0;
  v54._char object = (void *)MLObjectDetectorMetrics.description.getter();
  uint64_t v57 = v22;
  outlined consume of Result<MLObjectDetector.Metrics, Error>(v15, v21, v16, v17, 0);
LABEL_13:
  char object = v52._object;
  uint64_t v47 = v55;
  swift_bridgeObjectRetain((_BYTE)v55);
  v23._uint64_t countAndFlagsBits = 0x656D617261500A0ALL;
  v23._char object = (void *)0xED00000A73726574;
  String.append(_:)(v23);
  char v24 = (char)v47;
  swift_bridgeObjectRetain((_BYTE)v47);
  v23._uint64_t countAndFlagsBits = v52._countAndFlagsBits;
  char v25 = (char)v51;
  v23._char object = v51;
  String.append(_:)(v23);
  swift_bridgeObjectRelease(v24);
  v37._uint64_t countAndFlagsBits = 0xD00000000000001ELL;
  v37._char object = "ActivityClassifier\n\nParameters\n" + 0x8000000000000000;
  v23._uint64_t countAndFlagsBits = v54._countAndFlagsBits;
  char v26 = (char)v53;
  v23._char object = v53;
  String.append(_:)(v23);
  char v27 = (char)v37._object;
  String.append(_:)(v37);
  swift_bridgeObjectRelease(v27);
  if (v56)
  {
    char v28 = (char)v57;
  }
  else
  {
    v37._uint64_t countAndFlagsBits = 0xD000000000000020;
    v37._char object = "\nPerformance on Training Data\n" + 0x8000000000000000;
    v29._uint64_t countAndFlagsBits = (uint64_t)v54._object;
    char v28 = (char)v57;
    v29._char object = v57;
    String.append(_:)(v29);
    char v30 = (char)v37._object;
    String.append(_:)(v37);
    swift_bridgeObjectRelease(v25);
    char v25 = v26;
    char v26 = v30;
  }
  char v31 = (char)v55;
  swift_bridgeObjectRelease(v25);
  swift_bridgeObjectRelease(v26);
  swift_bridgeObjectRelease(v28);
  swift_bridgeObjectRelease(v31);
  return object;
}

NSAttributedString MLObjectDetector.playgroundDescription.getter(double a1)
{
  uint64_t v2 = v1;
  uint64_t v3 = type metadata accessor for NSAttributedString();
  v4._uint64_t countAndFlagsBits = (uint64_t)MLObjectDetector.debugDescription.getter(a1);
  v4._char object = v5;
  result.super.Class isa = NSAttributedString.__allocating_init(string:)(v4).super.isa;
  v2[3].super.Class isa = (Class)v3;
  v2->super.Class isa = result.super.isa;
  return result;
}

void *protocol witness for CustomStringConvertible.description.getter in conformance MLObjectDetector(double a1)
{
  return MLObjectDetector.description.getter(a1);
}

void *protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLObjectDetector(double a1)
{
  return MLObjectDetector.debugDescription.getter(a1);
}

NSAttributedString protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLObjectDetector(double a1)
{
  return MLObjectDetector.playgroundDescription.getter(a1);
}

uint64_t outlined consume of Result<MLObjectDetector.Metrics, Error>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, char a5)
{
  if (a5) {
    return swift_errorRelease(a1);
  }
  swift_bridgeObjectRelease(a1);
  return swift_bridgeObjectRelease(a2);
}

uint64_t outlined copy of Result<MLObjectDetector.Metrics, Error>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, char a5)
{
  if (a5) {
    return swift_errorRetain(a1);
  }
  swift_bridgeObjectRetain(a1);
  return swift_bridgeObjectRetain(a2);
}

void *initializeBufferWithCopyOfBuffer for MLObjectDetector(void *a1, void *a2, uint64_t a3)
{
  int v3 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  uint64_t v4 = *a2;
  *a1 = *a2;
  if ((v3 & 0x20000) != 0)
  {
    uint64_t v5 = (void *)(v4 + ((v3 + 16) & ~v3));
    swift_retain();
    return v5;
  }
  uint64_t v5 = a1;
  uint64_t v6 = *(int *)(a3 + 20);
  uint64_t v7 = (char *)a1 + v6;
  uint64_t v8 = (char *)a2 + v6;
  uint64_t v9 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  swift_retain();
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v8, v9);
  switch(EnumCaseMultiPayload)
  {
    case 3:
      uint64_t v13 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v13 - 8) + 16))(v7, v8, v13);
      uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
      uint64_t v15 = *(int *)(v14 + 48);
      *(void *)&v7[v15] = *(void *)&v8[v15];
      uint64_t v16 = *(void *)&v8[v15 + 8];
      *(void *)&v7[v15 + 8] = v16;
      uint64_t v17 = *(int *)(v14 + 64);
      *(void *)&v7[v17] = *(void *)&v8[v17];
      uint64_t v18 = v9;
      uint64_t v19 = *(void *)&v8[v17 + 8];
      *(void *)&v7[v17 + 8] = v19;
      swift_bridgeObjectRetain(v16);
      swift_bridgeObjectRetain(v19);
      uint64_t v20 = 3;
      uint64_t v21 = v7;
      uint64_t v22 = v18;
LABEL_16:
      swift_storeEnumTagMultiPayload(v21, v22, v20);
      goto LABEL_17;
    case 2:
      uint64_t v23 = *(void *)v8;
      uint64_t v52 = v9;
      char v24 = v8[8];
      outlined copy of Result<_DataTable, Error>(*(void *)v8, v24);
      *(void *)uint64_t v7 = v23;
      void v7[8] = v24;
      *((void *)v7 + 2) = *((void *)v8 + 2);
      uint64_t v25 = *((void *)v8 + 3);
      *((void *)v7 + 3) = v25;
      *((void *)v7 + 4) = *((void *)v8 + 4);
      uint64_t v26 = *((void *)v8 + 5);
      *((void *)v7 + 5) = v26;
      swift_bridgeObjectRetain(v25);
      swift_bridgeObjectRetain(v26);
      uint64_t v20 = 2;
      uint64_t v21 = v7;
      uint64_t v22 = v52;
      goto LABEL_16;
    case 1:
      uint64_t v11 = type metadata accessor for MLObjectDetector.DataSource(0);
      unsigned int v51 = swift_getEnumCaseMultiPayload(v8, v11);
      switch(v51)
      {
        case 0u:
          uint64_t v12 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 16))(v7, v8, v12);
          break;
        case 1u:
          uint64_t v55 = v11;
          uint64_t v27 = type metadata accessor for URL(0);
          uint64_t v53 = v9;
          char v28 = *(void (**)(char *, char *, uint64_t))(*(void *)(v27 - 8) + 16);
          v28(v7, v8, v27);
          uint64_t v29 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL));
          uint64_t v30 = v27;
          uint64_t v11 = v55;
          v28(&v7[*(int *)(v29 + 48)], &v8[*(int *)(v29 + 48)], v30);
          uint64_t v9 = v53;
          break;
        case 2u:
          uint64_t v56 = v11;
          uint64_t v31 = *(void *)v8;
          char v54 = v8[8];
          outlined copy of Result<_DataTable, Error>(*(void *)v8, v54);
          *(void *)uint64_t v7 = v31;
          void v7[8] = v54;
          *((void *)v7 + 2) = *((void *)v8 + 2);
          uint64_t v32 = *((void *)v8 + 3);
          *((void *)v7 + 3) = v32;
          *((void *)v7 + 4) = *((void *)v8 + 4);
          uint64_t v33 = *((void *)v8 + 5);
          *((void *)v7 + 5) = v33;
          goto LABEL_14;
        case 3u:
          uint64_t v34 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v34 - 8) + 16))(v7, v8, v34);
          uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
          uint64_t v36 = *(int *)(v35 + 48);
          *(void *)&v7[v36] = *(void *)&v8[v36];
          uint64_t v32 = *(void *)&v8[v36 + 8];
          *(void *)&v7[v36 + 8] = v32;
          uint64_t v37 = *(int *)(v35 + 64);
          *(void *)&v7[v37] = *(void *)&v8[v37];
          uint64_t v56 = v11;
          uint64_t v33 = *(void *)&v8[v37 + 8];
          *(void *)&v7[v37 + 8] = v33;
LABEL_14:
          swift_bridgeObjectRetain(v32);
          char v38 = v33;
          uint64_t v11 = v56;
          swift_bridgeObjectRetain(v38);
          break;
      }
      swift_storeEnumTagMultiPayload(v7, v11, v51);
      uint64_t v20 = 1;
      uint64_t v21 = v7;
      uint64_t v22 = v9;
      goto LABEL_16;
  }
  memcpy(v7, v8, *(void *)(*(void *)(v9 - 8) + 64));
LABEL_17:
  long long v39 = (int *)type metadata accessor for MLObjectDetector.ModelParameters(0);
  uint64_t v40 = v39[5];
  v7[v40 + 8] = v8[v40 + 8];
  *(void *)&v7[v40] = *(void *)&v8[v40];
  uint64_t v41 = v39[6];
  *(void *)&v7[v41] = *(void *)&v8[v41];
  v7[v41 + 8] = v8[v41 + 8];
  *(void *)&v7[v39[7]] = *(void *)&v8[v39[7]];
  *(void *)&v7[v39[8]] = *(void *)&v8[v39[8]];
  v7[v39[9]] = v8[v39[9]];
  uint64_t v42 = v39[10];
  long long v43 = &v7[v42];
  uint64_t v44 = &v8[v42];
  uint64_t v45 = *(void *)&v8[v42 + 24];
  if (v45)
  {
    *((void *)v43 + 3) = v45;
    (**(void (***)(char *, char *))(v45 - 8))(v43, v44);
  }
  else
  {
    long long v46 = *(_OWORD *)v44;
    *((_OWORD *)v43 + 1) = *((_OWORD *)v44 + 1);
    *(_OWORD *)long long v43 = v46;
  }
  uint64_t v47 = *(int *)(a3 + 24);
  *((unsigned char *)v5 + v47 + 2) = *((unsigned char *)a2 + v47 + 2);
  *(_WORD *)((char *)v5 + v47) = *(_WORD *)((char *)a2 + v47);
  return v5;
}

uint64_t destroy for MLObjectDetector(uint64_t a1, uint64_t a2)
{
  swift_release();
  uint64_t v2 = a1 + *(int *)(a2 + 20);
  uint64_t v3 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v2, v3);
  switch(EnumCaseMultiPayload)
  {
    case 3:
LABEL_7:
      uint64_t v8 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v8 - 8) + 8))(v2, v8);
      uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
      swift_bridgeObjectRelease(*(void *)(v2 + *(int *)(v9 + 48) + 8));
      uint64_t v7 = *(void *)(v2 + *(int *)(v9 + 64) + 8);
      goto LABEL_8;
    case 2:
LABEL_6:
      outlined consume of Result<_DataTable, Error>(*(void *)v2, *(_DWORD *)(v2 + 8));
      swift_bridgeObjectRelease(*(void *)(v2 + 24));
      uint64_t v7 = *(void *)(v2 + 40);
LABEL_8:
      swift_bridgeObjectRelease(v7);
      break;
    case 1:
      uint64_t v5 = type metadata accessor for MLObjectDetector.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(v2, v5))
      {
        case 0u:
          uint64_t v6 = type metadata accessor for URL(0);
          (*(void (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8))(v2, v6);
          break;
        case 1u:
          uint64_t v11 = type metadata accessor for URL(0);
          uint64_t v12 = *(void (**)(uint64_t, uint64_t))(*(void *)(v11 - 8) + 8);
          v12(v2, v11);
          uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL));
          v12(v2 + *(int *)(v13 + 48), v11);
          break;
        case 2u:
          goto LABEL_6;
        case 3u:
          goto LABEL_7;
        default:
          goto LABEL_9;
      }
      break;
  }
LABEL_9:
  uint64_t result = *(int *)(type metadata accessor for MLObjectDetector.ModelParameters(0) + 40);
  if (*(void *)(v2 + result + 24)) {
    return __swift_destroy_boxed_opaque_existential_1Tm((void *)(result + v2));
  }
  return result;
}

void *initializeWithCopy for MLObjectDetector(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v4 = *(int *)(a3 + 20);
  uint64_t v5 = (char *)a1 + v4;
  uint64_t v6 = (char *)a2 + v4;
  uint64_t v7 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  swift_retain();
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v6, v7);
  switch(EnumCaseMultiPayload)
  {
    case 3:
      uint64_t v11 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 16))(v5, v6, v11);
      uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
      uint64_t v13 = *(int *)(v12 + 48);
      *(void *)&v5[v13] = *(void *)&v6[v13];
      uint64_t v14 = *(void *)&v6[v13 + 8];
      *(void *)&v5[v13 + 8] = v14;
      uint64_t v15 = *(int *)(v12 + 64);
      *(void *)&v5[v15] = *(void *)&v6[v15];
      uint64_t v16 = v7;
      uint64_t v17 = *(void *)&v6[v15 + 8];
      *(void *)&v5[v15 + 8] = v17;
      swift_bridgeObjectRetain(v14);
      swift_bridgeObjectRetain(v17);
      uint64_t v18 = 3;
      uint64_t v19 = v5;
      uint64_t v20 = v16;
      break;
    case 2:
      uint64_t v21 = *(void *)v6;
      uint64_t v50 = v7;
      char v22 = v6[8];
      outlined copy of Result<_DataTable, Error>(*(void *)v6, v22);
      *(void *)uint64_t v5 = v21;
      v5[8] = v22;
      *((void *)v5 + 2) = *((void *)v6 + 2);
      uint64_t v23 = *((void *)v6 + 3);
      *((void *)v5 + 3) = v23;
      *((void *)v5 + 4) = *((void *)v6 + 4);
      uint64_t v24 = *((void *)v6 + 5);
      *((void *)v5 + 5) = v24;
      swift_bridgeObjectRetain(v23);
      swift_bridgeObjectRetain(v24);
      uint64_t v18 = 2;
      uint64_t v19 = v5;
      uint64_t v20 = v50;
      break;
    case 1:
      uint64_t v9 = type metadata accessor for MLObjectDetector.DataSource(0);
      unsigned int v49 = swift_getEnumCaseMultiPayload(v6, v9);
      switch(v49)
      {
        case 0u:
          uint64_t v10 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 16))(v5, v6, v10);
          break;
        case 1u:
          uint64_t v53 = v9;
          uint64_t v25 = type metadata accessor for URL(0);
          uint64_t v51 = v7;
          uint64_t v26 = *(void (**)(char *, char *, uint64_t))(*(void *)(v25 - 8) + 16);
          v26(v5, v6, v25);
          uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL));
          uint64_t v28 = v25;
          uint64_t v9 = v53;
          v26(&v5[*(int *)(v27 + 48)], &v6[*(int *)(v27 + 48)], v28);
          uint64_t v7 = v51;
          break;
        case 2u:
          uint64_t v54 = v9;
          uint64_t v29 = *(void *)v6;
          char v52 = v6[8];
          outlined copy of Result<_DataTable, Error>(*(void *)v6, v52);
          *(void *)uint64_t v5 = v29;
          v5[8] = v52;
          *((void *)v5 + 2) = *((void *)v6 + 2);
          uint64_t v30 = *((void *)v6 + 3);
          *((void *)v5 + 3) = v30;
          *((void *)v5 + 4) = *((void *)v6 + 4);
          uint64_t v31 = *((void *)v6 + 5);
          *((void *)v5 + 5) = v31;
          goto LABEL_12;
        case 3u:
          uint64_t v32 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v32 - 8) + 16))(v5, v6, v32);
          uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
          uint64_t v34 = *(int *)(v33 + 48);
          *(void *)&v5[v34] = *(void *)&v6[v34];
          uint64_t v30 = *(void *)&v6[v34 + 8];
          *(void *)&v5[v34 + 8] = v30;
          uint64_t v35 = *(int *)(v33 + 64);
          *(void *)&v5[v35] = *(void *)&v6[v35];
          uint64_t v54 = v9;
          uint64_t v31 = *(void *)&v6[v35 + 8];
          *(void *)&v5[v35 + 8] = v31;
LABEL_12:
          swift_bridgeObjectRetain(v30);
          char v36 = v31;
          uint64_t v9 = v54;
          swift_bridgeObjectRetain(v36);
          break;
      }
      swift_storeEnumTagMultiPayload(v5, v9, v49);
      uint64_t v18 = 1;
      uint64_t v19 = v5;
      uint64_t v20 = v7;
      break;
    default:
      memcpy(v5, v6, *(void *)(*(void *)(v7 - 8) + 64));
      goto LABEL_15;
  }
  swift_storeEnumTagMultiPayload(v19, v20, v18);
LABEL_15:
  uint64_t v37 = (int *)type metadata accessor for MLObjectDetector.ModelParameters(0);
  uint64_t v38 = v37[5];
  v5[v38 + 8] = v6[v38 + 8];
  *(void *)&v5[v38] = *(void *)&v6[v38];
  uint64_t v39 = v37[6];
  *(void *)&v5[v39] = *(void *)&v6[v39];
  v5[v39 + 8] = v6[v39 + 8];
  *(void *)&v5[v37[7]] = *(void *)&v6[v37[7]];
  *(void *)&v5[v37[8]] = *(void *)&v6[v37[8]];
  v5[v37[9]] = v6[v37[9]];
  uint64_t v40 = v37[10];
  uint64_t v41 = &v5[v40];
  uint64_t v42 = &v6[v40];
  uint64_t v43 = *(void *)&v6[v40 + 24];
  if (v43)
  {
    *((void *)v41 + 3) = v43;
    (**(void (***)(char *, char *))(v43 - 8))(v41, v42);
  }
  else
  {
    long long v44 = *(_OWORD *)v42;
    *((_OWORD *)v41 + 1) = *((_OWORD *)v42 + 1);
    *(_OWORD *)uint64_t v41 = v44;
  }
  uint64_t v45 = *(int *)(a3 + 24);
  *((unsigned char *)a1 + v45 + 2) = *((unsigned char *)a2 + v45 + 2);
  *(_WORD *)((char *)a1 + v45) = *(_WORD *)((char *)a2 + v45);
  return a1;
}

void *assignWithCopy for MLObjectDetector(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  swift_retain();
  swift_release();
  uint64_t v50 = a3;
  uint64_t v5 = *(int *)(a3 + 20);
  uint64_t v6 = (char *)a1 + v5;
  uint64_t v7 = (char *)a2 + v5;
  if (a1 != a2)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v6, type metadata accessor for MLObjectDetector.ModelParameters.ValidationData);
    uint64_t v8 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v7, v8);
    switch(EnumCaseMultiPayload)
    {
      case 3:
        uint64_t v12 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 16))(v6, v7, v12);
        uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
        uint64_t v14 = *(int *)(v13 + 48);
        *(void *)&v6[v14] = *(void *)&v7[v14];
        uint64_t v15 = *(void *)&v7[v14 + 8];
        *(void *)&v6[v14 + 8] = v15;
        uint64_t v16 = *(int *)(v13 + 64);
        *(void *)&v6[v16] = *(void *)&v7[v16];
        uint64_t v17 = *(void *)&v7[v16 + 8];
        *(void *)&v6[v16 + 8] = v17;
        swift_bridgeObjectRetain(v15);
        swift_bridgeObjectRetain(v17);
        uint64_t v48 = 3;
        break;
      case 2:
        uint64_t v18 = *(void *)v7;
        uint64_t v52 = v8;
        char v19 = v7[8];
        outlined copy of Result<_DataTable, Error>(*(void *)v7, v19);
        *(void *)uint64_t v6 = v18;
        v6[8] = v19;
        *((void *)v6 + 2) = *((void *)v7 + 2);
        uint64_t v20 = *((void *)v7 + 3);
        *((void *)v6 + 3) = v20;
        *((void *)v6 + 4) = *((void *)v7 + 4);
        uint64_t v21 = *((void *)v7 + 5);
        *((void *)v6 + 5) = v21;
        swift_bridgeObjectRetain(v20);
        swift_bridgeObjectRetain(v21);
        uint64_t v22 = 2;
        uint64_t v23 = v6;
        uint64_t v24 = v52;
LABEL_16:
        swift_storeEnumTagMultiPayload(v23, v24, v22);
        goto LABEL_17;
      case 1:
        uint64_t v10 = type metadata accessor for MLObjectDetector.DataSource(0);
        unsigned int v51 = swift_getEnumCaseMultiPayload(v7, v10);
        switch(v51)
        {
          case 0u:
            uint64_t v11 = type metadata accessor for URL(0);
            (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 16))(v6, v7, v11);
            break;
          case 1u:
            uint64_t v55 = v10;
            uint64_t v25 = type metadata accessor for URL(0);
            uint64_t v53 = v8;
            uint64_t v26 = *(void (**)(char *, char *, uint64_t))(*(void *)(v25 - 8) + 16);
            v26(v6, v7, v25);
            uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL));
            uint64_t v28 = v25;
            uint64_t v10 = v55;
            v26(&v6[*(int *)(v27 + 48)], &v7[*(int *)(v27 + 48)], v28);
            uint64_t v8 = v53;
            break;
          case 2u:
            uint64_t v56 = v10;
            uint64_t v29 = *(void *)v7;
            uint64_t v54 = v8;
            char v30 = v7[8];
            outlined copy of Result<_DataTable, Error>(*(void *)v7, v30);
            *(void *)uint64_t v6 = v29;
            v6[8] = v30;
            uint64_t v8 = v54;
            *((void *)v6 + 2) = *((void *)v7 + 2);
            uint64_t v31 = *((void *)v7 + 3);
            *((void *)v6 + 3) = v31;
            *((void *)v6 + 4) = *((void *)v7 + 4);
            uint64_t v32 = *((void *)v7 + 5);
            *((void *)v6 + 5) = v32;
            goto LABEL_13;
          case 3u:
            uint64_t v33 = type metadata accessor for DataFrame(0);
            (*(void (**)(char *, char *, uint64_t))(*(void *)(v33 - 8) + 16))(v6, v7, v33);
            uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
            uint64_t v35 = *(int *)(v34 + 48);
            *(void *)&v6[v35] = *(void *)&v7[v35];
            uint64_t v31 = *(void *)&v7[v35 + 8];
            *(void *)&v6[v35 + 8] = v31;
            uint64_t v36 = *(int *)(v34 + 64);
            *(void *)&v6[v36] = *(void *)&v7[v36];
            uint64_t v56 = v10;
            uint64_t v32 = *(void *)&v7[v36 + 8];
            *(void *)&v6[v36 + 8] = v32;
LABEL_13:
            swift_bridgeObjectRetain(v31);
            char v37 = v32;
            uint64_t v10 = v56;
            swift_bridgeObjectRetain(v37);
            break;
        }
        swift_storeEnumTagMultiPayload(v6, v10, v51);
        uint64_t v48 = 1;
        break;
      default:
        memcpy(v6, v7, *(void *)(*(void *)(v8 - 8) + 64));
        goto LABEL_17;
    }
    uint64_t v22 = v48;
    uint64_t v23 = v6;
    uint64_t v24 = v8;
    goto LABEL_16;
  }
LABEL_17:
  uint64_t v38 = (int *)type metadata accessor for MLObjectDetector.ModelParameters(0);
  uint64_t v39 = v38[5];
  v6[v39 + 8] = v7[v39 + 8];
  *(void *)&v6[v39] = *(void *)&v7[v39];
  uint64_t v40 = v38[6];
  *(void *)&v6[v40] = *(void *)&v7[v40];
  v6[v40 + 8] = v7[v40 + 8];
  *(void *)&v6[v38[7]] = *(void *)&v7[v38[7]];
  *(void *)&v6[v38[8]] = *(void *)&v7[v38[8]];
  v6[v38[9]] = v7[v38[9]];
  uint64_t v41 = v38[10];
  uint64_t v42 = &v6[v41];
  uint64_t v43 = &v7[v41];
  uint64_t v44 = *(void *)&v7[v41 + 24];
  if (!*(void *)&v6[v41 + 24])
  {
    if (v44)
    {
      *((void *)v42 + 3) = v44;
      (**(void (***)(char *, char *))(v44 - 8))(v42, v43);
      goto LABEL_24;
    }
LABEL_23:
    long long v45 = *(_OWORD *)v43;
    *((_OWORD *)v42 + 1) = *((_OWORD *)v43 + 1);
    *(_OWORD *)uint64_t v42 = v45;
    goto LABEL_24;
  }
  if (!v44)
  {
    __swift_destroy_boxed_opaque_existential_1Tm(&v6[v41]);
    goto LABEL_23;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)&v6[v41], (uint64_t *)&v7[v41]);
LABEL_24:
  uint64_t v46 = *(int *)(v50 + 24);
  *((unsigned char *)a1 + v46) = *((unsigned char *)a2 + v46);
  *((unsigned char *)a1 + v46 + 1) = *((unsigned char *)a2 + v46 + 1);
  *((unsigned char *)a1 + v46 + 2) = *((unsigned char *)a2 + v46 + 2);
  return a1;
}

void *initializeWithTake for MLObjectDetector(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v5 = *(int *)(a3 + 20);
  uint64_t v6 = (char *)a1 + v5;
  uint64_t v7 = (char *)a2 + v5;
  uint64_t v8 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v7, v8);
  if (EnumCaseMultiPayload == 3)
  {
    uint64_t v15 = type metadata accessor for DataFrame(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 32))(v6, v7, v15);
    uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
    *(_OWORD *)&v6[*(int *)(v16 + 48)] = *(_OWORD *)&v7[*(int *)(v16 + 48)];
    *(_OWORD *)&v6[*(int *)(v16 + 64)] = *(_OWORD *)&v7[*(int *)(v16 + 64)];
    swift_storeEnumTagMultiPayload(v6, v8, 3);
  }
  else
  {
    if (EnumCaseMultiPayload == 1)
    {
      uint64_t v31 = type metadata accessor for MLObjectDetector.DataSource(0);
      int v10 = swift_getEnumCaseMultiPayload(v7, v31);
      if (v10 == 3)
      {
        uint64_t v17 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 32))(v6, v7, v17);
        uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
        *(_OWORD *)&v6[*(int *)(v18 + 48)] = *(_OWORD *)&v7[*(int *)(v18 + 48)];
        *(_OWORD *)&v6[*(int *)(v18 + 64)] = *(_OWORD *)&v7[*(int *)(v18 + 64)];
        uint64_t v27 = 3;
      }
      else
      {
        if (v10 != 1)
        {
          if (v10)
          {
            memcpy(v6, v7, *(void *)(*(void *)(v31 - 8) + 64));
            goto LABEL_14;
          }
          uint64_t v11 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 32))(v6, v7, v11);
          uint64_t v12 = v6;
          uint64_t v13 = v31;
          uint64_t v14 = 0;
LABEL_12:
          swift_storeEnumTagMultiPayload(v12, v13, v14);
LABEL_14:
          swift_storeEnumTagMultiPayload(v6, v8, 1);
          goto LABEL_15;
        }
        uint64_t v29 = type metadata accessor for URL(0);
        char v30 = *(void (**)(char *, char *, uint64_t))(*(void *)(v29 - 8) + 32);
        v30(v6, v7, v29);
        uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL));
        v30(&v6[*(int *)(v19 + 48)], &v7[*(int *)(v19 + 48)], v29);
        uint64_t v27 = 1;
      }
      uint64_t v14 = v27;
      uint64_t v12 = v6;
      uint64_t v13 = v31;
      goto LABEL_12;
    }
    memcpy(v6, v7, *(void *)(*(void *)(v8 - 8) + 64));
  }
LABEL_15:
  uint64_t v20 = (int *)type metadata accessor for MLObjectDetector.ModelParameters(0);
  uint64_t v21 = v20[5];
  v6[v21 + 8] = v7[v21 + 8];
  *(void *)&v6[v21] = *(void *)&v7[v21];
  uint64_t v22 = v20[6];
  *(void *)&v6[v22] = *(void *)&v7[v22];
  v6[v22 + 8] = v7[v22 + 8];
  *(void *)&v6[v20[7]] = *(void *)&v7[v20[7]];
  *(void *)&v6[v20[8]] = *(void *)&v7[v20[8]];
  v6[v20[9]] = v7[v20[9]];
  uint64_t v23 = v20[10];
  long long v24 = *(_OWORD *)&v7[v23 + 16];
  *(_OWORD *)&v6[v23] = *(_OWORD *)&v7[v23];
  *(_OWORD *)&v6[v23 + 16] = v24;
  uint64_t v25 = *(int *)(a3 + 24);
  *((unsigned char *)a1 + v25 + 2) = *((unsigned char *)a2 + v25 + 2);
  *(_WORD *)((char *)a1 + v25) = *(_WORD *)((char *)a2 + v25);
  return a1;
}

void *assignWithTake for MLObjectDetector(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  swift_release();
  uint64_t v32 = a3;
  uint64_t v5 = *(int *)(a3 + 20);
  uint64_t v6 = (char *)a1 + v5;
  uint64_t v7 = (char *)a2 + v5;
  if (a1 != a2)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v6, type metadata accessor for MLObjectDetector.ModelParameters.ValidationData);
    uint64_t v8 = type metadata accessor for MLObjectDetector.ModelParameters.ValidationData(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v7, v8);
    if (EnumCaseMultiPayload == 3)
    {
      uint64_t v16 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 32))(v6, v7, v16);
      uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
      *(_OWORD *)&v6[*(int *)(v17 + 48)] = *(_OWORD *)&v7[*(int *)(v17 + 48)];
      *(_OWORD *)&v6[*(int *)(v17 + 64)] = *(_OWORD *)&v7[*(int *)(v17 + 64)];
      swift_storeEnumTagMultiPayload(v6, v8, 3);
      goto LABEL_15;
    }
    if (EnumCaseMultiPayload != 1)
    {
      memcpy(v6, v7, *(void *)(*(void *)(v8 - 8) + 64));
      goto LABEL_15;
    }
    uint64_t v10 = type metadata accessor for MLObjectDetector.DataSource(0);
    int v11 = swift_getEnumCaseMultiPayload(v7, v10);
    if (v11 == 3)
    {
      uint64_t v18 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 32))(v6, v7, v18);
      uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
      *(_OWORD *)&v6[*(int *)(v19 + 48)] = *(_OWORD *)&v7[*(int *)(v19 + 48)];
      *(_OWORD *)&v6[*(int *)(v19 + 64)] = *(_OWORD *)&v7[*(int *)(v19 + 64)];
      uint64_t v15 = 3;
      uint64_t v13 = v6;
      uint64_t v14 = v10;
    }
    else if (v11 == 1)
    {
      uint64_t v34 = v10;
      uint64_t v20 = type metadata accessor for URL(0);
      uint64_t v33 = v8;
      uint64_t v21 = *(void (**)(char *, char *, uint64_t))(*(void *)(v20 - 8) + 32);
      v21(v6, v7, v20);
      uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL));
      v21(&v6[*(int *)(v22 + 48)], &v7[*(int *)(v22 + 48)], v20);
      uint64_t v8 = v33;
      uint64_t v15 = 1;
      uint64_t v13 = v6;
      uint64_t v14 = v34;
    }
    else
    {
      if (v11)
      {
        memcpy(v6, v7, *(void *)(*(void *)(v10 - 8) + 64));
        goto LABEL_14;
      }
      uint64_t v12 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(v6, v7, v12);
      uint64_t v13 = v6;
      uint64_t v14 = v10;
      uint64_t v15 = 0;
    }
    swift_storeEnumTagMultiPayload(v13, v14, v15);
LABEL_14:
    swift_storeEnumTagMultiPayload(v6, v8, 1);
  }
LABEL_15:
  uint64_t v23 = (int *)type metadata accessor for MLObjectDetector.ModelParameters(0);
  uint64_t v24 = v23[5];
  v6[v24 + 8] = v7[v24 + 8];
  *(void *)&v6[v24] = *(void *)&v7[v24];
  uint64_t v25 = v23[6];
  *(void *)&v6[v25] = *(void *)&v7[v25];
  v6[v25 + 8] = v7[v25 + 8];
  *(void *)&v6[v23[7]] = *(void *)&v7[v23[7]];
  *(void *)&v6[v23[8]] = *(void *)&v7[v23[8]];
  v6[v23[9]] = v7[v23[9]];
  uint64_t v26 = v23[10];
  uint64_t v27 = &v6[v26];
  if (*(void *)&v6[v26 + 24]) {
    __swift_destroy_boxed_opaque_existential_1Tm(&v6[v26]);
  }
  long long v28 = *(_OWORD *)&v7[v26];
  *((_OWORD *)v27 + 1) = *(_OWORD *)&v7[v26 + 16];
  *(_OWORD *)uint64_t v27 = v28;
  uint64_t v29 = *(int *)(v32 + 24);
  *((unsigned char *)a1 + v29) = *((unsigned char *)a2 + v29);
  *((unsigned char *)a1 + v29 + 1) = *((unsigned char *)a2 + v29 + 1);
  *((unsigned char *)a1 + v29 + 2) = *((unsigned char *)a2 + v29 + 2);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLObjectDetector(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_270B93);
}

uint64_t sub_270B93(void *a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t result = 0;
    if ((*a1 & 0xFFFFFFFF00000001) == 0) {
      return (*a1 >> 1) + 1;
    }
  }
  else
  {
    uint64_t v5 = type metadata accessor for MLObjectDetector.ModelParameters(0);
    return __swift_getEnumTagSinglePayload((uint64_t)a1 + *(int *)(a3 + 20), a2, v5);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLObjectDetector(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_270C0E);
}

uint64_t sub_270C0E(void *a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 0x7FFFFFFF)
  {
    *a1 = 2 * (a2 - 1);
  }
  else
  {
    uint64_t v5 = type metadata accessor for MLObjectDetector.ModelParameters(0);
    return __swift_storeEnumTagSinglePayload((uint64_t)a1 + *(int *)(a4 + 20), a2, a2, v5);
  }
  return result;
}

uint64_t type metadata completion function for MLObjectDetector(uint64_t a1)
{
  v3[0] = (char *)&value witness table for Builtin.NativeObject + 64;
  uint64_t result = type metadata accessor for MLObjectDetector.ModelParameters(319);
  if (v2 <= 0x3F)
  {
    v3[1] = *(void *)(result - 8) + 64;
    v3[2] = &unk_350958;
    swift_initStructMetadata(a1, 256, 3, v3, a1 + 16);
    return 0;
  }
  return result;
}

void MLLogisticRegressionClassifier.Model.export(internalMetadata:)()
{
  uint64_t v120 = v0;
  uint64_t v131 = type metadata accessor for FeatureType(0);
  uint64_t v130 = *(void *)(v131 - 8);
  int64_t v3 = *(void *)(v130 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v145 = v116;
  uint64_t v132 = type metadata accessor for LinearClassifierConfiguration.ClassLabels(0);
  uint64_t v122 = *(void *)(v132 - 8);
  int64_t v6 = *(void *)(v122 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v121 = v116;
  uint64_t v136 = type metadata accessor for ModelKind(0);
  uint64_t v129 = *(void *)(v136 - 8);
  int64_t v9 = *(void *)(v129 + 64);
  uint64_t v10 = alloca(v9);
  int v11 = alloca(v9);
  uint64_t v126 = v116;
  uint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v123 = v116;
  uint64_t v137 = type metadata accessor for LinearClassifierConfiguration(0);
  uint64_t v138 = *(void *)(v137 - 8);
  int64_t v14 = *(void *)(v138 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v139 = v116;
  int64_t v17 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Model?)
                              - 8)
                  + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v124 = v116;
  uint64_t v127 = type metadata accessor for Model(0);
  uint64_t v128 = *(void *)(v127 - 8);
  int64_t v20 = *(void *)(v128 + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  unint64_t v140 = v116;
  uint64_t v23 = alloca(v20);
  uint64_t v24 = alloca(v20);
  uint64_t v150 = v116;
  uint64_t v135 = type metadata accessor for URL.DirectoryHint(0);
  uint64_t v143 = *(void *)(v135 - 8);
  int64_t v25 = *(void *)(v143 + 64);
  uint64_t v26 = alloca(v25);
  uint64_t v27 = alloca(v25);
  uint64_t v144 = v116;
  uint64_t v149 = type metadata accessor for UUID(0);
  uint64_t v117 = *(void *)(v149 - 8);
  int64_t v28 = *(void *)(v117 + 64);
  uint64_t v29 = alloca(v28);
  char v30 = alloca(v28);
  uint64_t v118 = v116;
  uint64_t v141 = type metadata accessor for URL(0);
  uint64_t v142 = *(void *)(v141 - 8);
  int64_t v31 = *(void *)(v142 + 64);
  uint64_t v32 = alloca(v31);
  uint64_t v33 = alloca(v31);
  uint64_t v119 = v116;
  uint64_t v34 = alloca(v31);
  uint64_t v35 = alloca(v31);
  uint64_t v153 = v116;
  uint64_t v36 = alloca(v31);
  char v37 = alloca(v31);
  uint64_t v148 = v116;
  uint64_t v38 = alloca(v31);
  uint64_t v39 = alloca(v31);
  uint64_t v40 = v2[2];
  if (!v40)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000001CLL, "ressorModel.swift" + 0x8000000000000000, "CreateML/MLLogisticRegressionClassifier.Model+CoreML.swift", 58, 2, 10, 0);
    goto LABEL_16;
  }
  uint64_t v41 = specialized FeatureVectorizer.Transformer.exportEncoders()(v2[2], v2[3], v2[4]);
  if (v1) {
    return;
  }
  uint64_t v125 = v40;
  uint64_t v151 = v41;
  uint64_t v146 = v116;
  uint64_t v147 = v2;
  uint64_t v42 = objc_opt_self(NSFileManager);
  id v43 = [v42 defaultManager];
  id v44 = v43;
  NSFileManager.createTemporaryModelDirectory()();
  if (v45)
  {
    swift_bridgeObjectRelease(v151);

    return;
  }

  id v46 = [v42 defaultManager];
  id v47 = v46;
  NSFileManager.temporaryModelDirectory.getter();

  uint64_t v48 = v118;
  UUID.init()();
  uint64_t v49 = UUID.uuidString.getter();
  uint64_t v152 = 0;
  uint64_t v50 = v49;
  uint64_t v52 = v51;
  (*(void (**)(char *, uint64_t))(v117 + 8))(v48, v149);
  uint64_t v133 = v50;
  uint64_t v134 = v52;
  uint64_t v53 = v144;
  uint64_t v54 = v135;
  uint64_t v55 = v143;
  (*(void (**)(char *, void, uint64_t))(v143 + 104))(v144, enum case for URL.DirectoryHint.inferFromPath(_:), v135);
  uint64_t v56 = lazy protocol witness table accessor for type String and conformance String();
  uint64_t v57 = v153;
  URL.appending<A>(component:directoryHint:)(&v133, v53, &type metadata for String, v56);
  (*(void (**)(char *, uint64_t))(v55 + 8))(v53, v54);
  swift_bridgeObjectRelease(v134);
  uint64_t v58 = *(void (**)(char *, uint64_t))(v142 + 8);
  uint64_t v59 = v141;
  v58(v57, v141);
  uint64_t v60 = v146;
  uint64_t v61 = v148;
  URL.appendingPathExtension(_:)(0x6C65646F6D6C6D2ELL, 0xE800000000000000);
  v58(v61, v59);
  uint64_t v62 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  uint64_t v63 = v152;
  BaseLogisticRegressionClassifierModel.export(to:)(v60);
  if (v63)
  {
    v58(v146, v141);
    swift_bridgeObjectRelease(v151);
    return;
  }
  uint64_t v153 = (char *)v62;
  uint64_t v148 = (char *)v58;
  uint64_t v64 = v119;
  (*(void (**)(char *, char *, uint64_t))(v142 + 16))(v119, v146, v141);
  Model.init(contentsOf:)(v64);
  uint64_t v152 = 0;
  uint64_t v65 = (uint64_t)v124;
  specialized BidirectionalCollection.last.getter(v151);
  uint64_t v66 = v127;
  if (__swift_getEnumTagSinglePayload(v65, 1, v127) == 1) {
    BUG();
  }
  uint64_t v67 = v65;
  uint64_t v68 = Model.outputs.getter(v65, 1);
  uint64_t v142 = *(void *)(v128 + 8);
  ((void (*)(uint64_t, uint64_t))v142)(v67, v66);
  Model.inputs.setter(v68);
  Swift::String v69 = (char *)*v147;
  uint64_t v70 = v147[1];
  swift_bridgeObjectRetain(v70);
  Model.predictedFeatureName.setter(v69, v70);
  uint64_t v144 = v69;
  uint64_t v133 = (uint64_t)v69;
  uint64_t v134 = v70;
  uint64_t v143 = v70;
  swift_bridgeObjectRetain(v70);
  v71._uint64_t countAndFlagsBits = 0x6C696261626F7250;
  v71._char object = (void *)0xEB00000000797469;
  String.append(_:)(v71);
  Model.predictedProbabilitiesName.setter(v133, v134);
  uint64_t v72 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for String, &protocol witness table for String);
  Model.metadata.setter(v72);
  uint64_t v73 = (uint64_t)v123;
  Model.kind.getter();
  uint64_t v74 = v73;
  v71._uint64_t countAndFlagsBits = v73;
  uint64_t v75 = v136;
  uint64_t v76 = v129;
  LODWORD(v135) = (*(uint64_t (**)(uint64_t, uint64_t))(v129 + 88))(v71._countAndFlagsBits, v136);
  if (v135 != enum case for ModelKind.linearClassifier(_:))
  {
    (*(void (**)(uint64_t, uint64_t))(v76 + 8))(v74, v75);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000001DLL, "ssifier.Model+CoreML.swift" + 0x8000000000000000, "CreateML/MLLogisticRegressionClassifier.Model+CoreML.swift", 58, 2, 31, 0);
LABEL_16:
    BUG();
  }
  (*(void (**)(uint64_t, uint64_t))(v76 + 96))(v74, v75);
  (*(void (**)(char *, uint64_t, uint64_t))(v138 + 32))(v139, v74, v137);
  uint64_t v77 = *((int *)v153 + 7);
  uint64_t v78 = *(uint64_t *)((char *)v147 + v77);
  BOOL v79 = *((unsigned char *)v147 + v77 + 8) == 0;
  uint64_t v80 = v121;
  *(void *)uint64_t v121 = v78;
  unint64_t v81 = *(void (**)(char *, void, uint64_t))(v122 + 104);
  if (v79)
  {
    v81(v80, enum case for LinearClassifierConfiguration.ClassLabels.int(_:), v132);
    swift_bridgeObjectRetain(v78);
    LinearClassifierConfiguration.classLabels.setter(v80);
    uint64_t v92 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
    uint64_t v93 = *(void *)(type metadata accessor for FeatureDescription(0) - 8);
    uint64_t v149 = *(void *)(v93 + 72);
    uint64_t v94 = swift_allocObject(v92, ((*(unsigned __int8 *)(v93 + 80) + 32) & ~*(unsigned __int8 *)(v93 + 80)) + 2 * v149, *(unsigned __int8 *)(v93 + 80) | 7);
    *(void *)(v94 + 16) = 2;
    *(void *)(v94 + 24) = 4;
    uint64_t v153 = (char *)v94;
    uint64_t v95 = v143;
    swift_bridgeObjectRetain(v143);
    char v96 = v145;
    FeatureType.IntParameters.init(optional:)(0);
    (*(void (**)(char *, void, uint64_t))(v130 + 104))(v96, enum case for FeatureType.int(_:), v131);
    char v97 = v144;
    FeatureDescription.init(name:type:description:)(v144, v95, v96, 0, 0xE000000000000000);
    uint64_t v133 = (uint64_t)v97;
    uint64_t v134 = v95;
    swift_bridgeObjectRetain(v95);
    v98._uint64_t countAndFlagsBits = 0x6C696261626F7250;
    v98._char object = (void *)0xEB00000000797469;
    String.append(_:)(v98);
    uint64_t v89 = v133;
    uint64_t v90 = v134;
    uint64_t v91 = v145;
    static FeatureType.dictionaryWithIntKeys(optional:)(0);
  }
  else
  {
    v81(v80, enum case for LinearClassifierConfiguration.ClassLabels.string(_:), v132);
    swift_bridgeObjectRetain(v78);
    LinearClassifierConfiguration.classLabels.setter(v80);
    uint64_t v82 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
    uint64_t v83 = *(void *)(type metadata accessor for FeatureDescription(0) - 8);
    uint64_t v149 = *(void *)(v83 + 72);
    uint64_t v84 = swift_allocObject(v82, ((*(unsigned __int8 *)(v83 + 80) + 32) & ~*(unsigned __int8 *)(v83 + 80)) + 2 * v149, *(unsigned __int8 *)(v83 + 80) | 7);
    *(void *)(v84 + 16) = 2;
    *(void *)(v84 + 24) = 4;
    uint64_t v153 = (char *)v84;
    uint64_t v85 = v143;
    swift_bridgeObjectRetain(v143);
    uint64_t v86 = v145;
    FeatureType.StringParameters.init(optional:)(0);
    (*(void (**)(char *, void, uint64_t))(v130 + 104))(v86, enum case for FeatureType.string(_:), v131);
    uint64_t v87 = v144;
    FeatureDescription.init(name:type:description:)(v144, v85, v86, 0, 0xE000000000000000);
    uint64_t v133 = (uint64_t)v87;
    uint64_t v134 = v85;
    swift_bridgeObjectRetain(v85);
    v88._uint64_t countAndFlagsBits = 0x6C696261626F7250;
    v88._char object = (void *)0xEB00000000797469;
    String.append(_:)(v88);
    uint64_t v89 = v133;
    uint64_t v90 = v134;
    uint64_t v91 = v145;
    static FeatureType.dictionaryWithStringKeys(optional:)(0);
  }
  FeatureDescription.init(name:type:description:)(v89, v90, v91, 0, 0xE000000000000000);
  Model.outputs.setter(v153);
  char v99 = v126;
  (*(void (**)(char *, char *, uint64_t))(v138 + 16))(v126, v139, v137);
  uint64_t v153 = *(char **)(v129 + 104);
  ((void (*)(char *, void, uint64_t))v153)(v99, v135, v136);
  Model.kind.setter(v99);
  Model.init()();
  Model.specificationVersion.setter(1);
  uint64_t v100 = v125;
  swift_bridgeObjectRetain(v125);
  uint64_t v101 = v152;
  ML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay8CreateML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n(v100);
  uint64_t v152 = v101;
  swift_bridgeObjectRelease(v100);
  Model.inputs.setter(ML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n);
  uint64_t v103 = Model.outputs.getter(ML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n, v116);
  Model.outputs.setter(v103);
  uint64_t v104 = *v147;
  uint64_t v105 = v147[1];
  swift_bridgeObjectRetain(v105);
  Model.predictedFeatureName.setter(v104, v105);
  uint64_t v133 = v104;
  uint64_t v134 = v105;
  swift_bridgeObjectRetain(v105);
  v106._uint64_t countAndFlagsBits = 0x6C696261626F7250;
  v106._char object = (void *)0xEB00000000797469;
  String.append(_:)(v106);
  Model.predictedProbabilitiesName.setter(v133, v134);
  uint64_t v107 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Model>);
  uint64_t v108 = v128;
  uint64_t v109 = *(unsigned __int8 *)(v128 + 80);
  uint64_t v110 = ((int)v109 + 32) & ~*(unsigned __int8 *)(v128 + 80);
  uint64_t v111 = swift_allocObject(v107, v110 + *(void *)(v128 + 72), v109 | 7);
  *(void *)(v111 + 16) = 1;
  *(void *)(v111 + 24) = 2;
  v106._uint64_t countAndFlagsBits = v111 + v110;
  uint64_t v112 = v127;
  (*(void (**)(uint64_t, char *, uint64_t))(v108 + 16))(v106._countAndFlagsBits, v150, v127);
  uint64_t v133 = v151;
  specialized Array.append<A>(contentsOf:)(v111);
  uint64_t v113 = (uint64_t)v126;
  PipelineClassifierConfiguration.init(models:names:)(v133, _swiftEmptyArrayStorage);
  ((void (*)(uint64_t, void, uint64_t))v153)(v113, enum case for ModelKind.pipelineClassifier(_:), v136);
  v106._uint64_t countAndFlagsBits = v113;
  uint64_t v114 = v140;
  Model.kind.setter(v106._countAndFlagsBits);
  (*(void (**)(char *, uint64_t))(v138 + 8))(v139, v137);
  ((void (*)(char *, uint64_t))v142)(v150, v112);
  (*(void (**)(uint64_t, char *, uint64_t))(v108 + 32))(v120, v114, v112);
  uint64_t v115 = v146;
  $defer #1 () in MLLogisticRegressionClassifier.Model.export(internalMetadata:)();
  ((void (*)(char *, uint64_t))v148)(v115, v141);
}

NSURL *$defer #1 () in MLLogisticRegressionClassifier.Model.export(internalMetadata:)()
{
  uint64_t v0 = objc_opt_self(NSFileManager);
  id v1 = [v0 defaultManager];
  unint64_t v2 = (NSURL *)v1;
  URL._bridgeToObjectiveC()(v2);
  uint64_t v4 = v3;
  id v10 = 0;
  unsigned __int8 v5 = [(NSURL *)v2 removeItemAtURL:v3 error:&v10];

  id v6 = v10;
  if (v5) {
    return (NSURL *)v10;
  }
  id v8 = v10;
  uint64_t v9 = _convertNSErrorToError(_:)(v6);

  swift_willThrow();
  swift_errorRelease(v9);
  return __stack_chk_guard;
}

void *initializeBufferWithCopyOfBuffer for MLLinearRegressor.Regressor(void *a1, uint64_t *a2, uint64_t a3)
{
  int64_t v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v9 = *a2;
    void *v3 = *a2;
    int64_t v3 = (void *)(v9 + ((v4 + 16) & ~v4));
    swift_retain(v9);
  }
  else
  {
    *a1 = *a2;
    uint64_t v6 = a2[1];
    v3[1] = v6;
    uint64_t v7 = a2[2];
    v3[2] = v7;
    uint64_t v16 = v3 + 3;
    int64_t v17 = (long long *)(a2 + 3);
    uint64_t v8 = a2[6];
    swift_bridgeObjectRetain(v6);
    swift_bridgeObjectRetain(v7);
    if (v8)
    {
      v3[6] = v8;
      (**(void (***)(_OWORD *, long long *, uint64_t))(v8 - 8))(v16, v17, v8);
    }
    else
    {
      long long v10 = *v17;
      *(_OWORD *)(v3 + 5) = *(_OWORD *)(a2 + 5);
      *uint64_t v16 = v10;
    }
    *(_OWORD *)(v3 + 7) = *(_OWORD *)(a2 + 7);
    *(_OWORD *)(v3 + 9) = *(_OWORD *)(a2 + 9);
    v3[11] = a2[11];
    *((unsigned char *)v3 + 96) = *((unsigned char *)a2 + 96);
    uint64_t v11 = *(int *)(a3 + 28);
    uint64_t v12 = (char *)v3 + v11;
    uint64_t v13 = (uint64_t)a2 + v11;
    uint64_t v14 = type metadata accessor for BaseLinearRegressor(0);
    (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v14 - 8) + 16))(v12, v13, v14);
  }
  return v3;
}

uint64_t destroy for MLLinearRegressor.Regressor(void *a1, uint64_t a2)
{
  swift_bridgeObjectRelease(a1[1]);
  swift_bridgeObjectRelease(a1[2]);
  if (a1[6]) {
    __swift_destroy_boxed_opaque_existential_1Tm(a1 + 3);
  }
  unint64_t v2 = (char *)a1 + *(int *)(a2 + 28);
  uint64_t v3 = type metadata accessor for BaseLinearRegressor(0);
  return (*(uint64_t (**)(char *, uint64_t))(*(void *)(v3 - 8) + 8))(v2, v3);
}

uint64_t initializeWithCopy for MLLinearRegressor.Regressor(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v4 = *(void *)(a2 + 8);
  *(void *)(a1 + 8) = v4;
  uint64_t v5 = *(void *)(a2 + 16);
  *(void *)(a1 + 16) = v5;
  uint64_t v14 = (_OWORD *)(a1 + 24);
  uint64_t v6 = *(void *)(a2 + 48);
  swift_bridgeObjectRetain(v4);
  swift_bridgeObjectRetain(v5);
  if (v6)
  {
    *(void *)(a1 + 48) = v6;
    (**(void (***)(_OWORD *, uint64_t, uint64_t))(v6 - 8))(v14, a2 + 24, v6);
  }
  else
  {
    long long v7 = *(_OWORD *)(a2 + 24);
    *(_OWORD *)(a1 + 40) = *(_OWORD *)(a2 + 40);
    *uint64_t v14 = v7;
  }
  *(_OWORD *)(a1 + 56) = *(_OWORD *)(a2 + 56);
  *(_OWORD *)(a1 + 72) = *(_OWORD *)(a2 + 72);
  *(void *)(a1 + 88) = *(void *)(a2 + 88);
  *(unsigned char *)(a1 + 96) = *(unsigned char *)(a2 + 96);
  uint64_t v8 = *(int *)(a3 + 28);
  uint64_t v9 = a1 + v8;
  uint64_t v10 = v8 + a2;
  uint64_t v11 = type metadata accessor for BaseLinearRegressor(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v11 - 8) + 16))(v9, v10, v11);
  return a1;
}

uint64_t assignWithCopy for MLLinearRegressor.Regressor(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v5 = *(void *)(a2 + 8);
  uint64_t v6 = *(void *)(a1 + 8);
  *(void *)(a1 + 8) = v5;
  swift_bridgeObjectRetain(v5);
  swift_bridgeObjectRelease(v6);
  uint64_t v7 = *(void *)(a2 + 16);
  uint64_t v8 = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = v7;
  swift_bridgeObjectRetain(v7);
  swift_bridgeObjectRelease(v8);
  uint64_t v9 = *(void *)(a2 + 48);
  if (!*(void *)(a1 + 48))
  {
    if (v9)
    {
      *(void *)(a1 + 48) = v9;
      (**(void (***)(uint64_t, uint64_t))(v9 - 8))(a1 + 24, a2 + 24);
      goto LABEL_8;
    }
LABEL_7:
    long long v10 = *(_OWORD *)(a2 + 24);
    *(_OWORD *)(a1 + 40) = *(_OWORD *)(a2 + 40);
    *(_OWORD *)(a1 + 24) = v10;
    goto LABEL_8;
  }
  if (!v9)
  {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 24));
    goto LABEL_7;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)(a1 + 24), (uint64_t *)(a2 + 24));
LABEL_8:
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  *(void *)(a1 + 64) = *(void *)(a2 + 64);
  *(void *)(a1 + 72) = *(void *)(a2 + 72);
  *(void *)(a1 + 80) = *(void *)(a2 + 80);
  *(void *)(a1 + 88) = *(void *)(a2 + 88);
  *(unsigned char *)(a1 + 96) = *(unsigned char *)(a2 + 96);
  uint64_t v11 = *(int *)(a3 + 28);
  uint64_t v12 = a1 + v11;
  uint64_t v13 = v11 + a2;
  uint64_t v14 = type metadata accessor for BaseLinearRegressor(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v14 - 8) + 24))(v12, v13, v14);
  return a1;
}

uint64_t initializeWithTake for MLLinearRegressor.Regressor(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  qmemcpy((void *)(a1 + 24), (const void *)(a2 + 24), 0x49uLL);
  uint64_t v3 = *(int *)(a3 + 28);
  uint64_t v4 = type metadata accessor for BaseLinearRegressor(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a1 + v3, a2 + v3, v4);
  return a1;
}

uint64_t assignWithTake for MLLinearRegressor.Regressor(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v5 = *(void *)(a1 + 8);
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  swift_bridgeObjectRelease(v6);
  if (*(void *)(a1 + 48)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 24));
  }
  long long v7 = *(_OWORD *)(a2 + 24);
  *(_OWORD *)(a1 + 40) = *(_OWORD *)(a2 + 40);
  *(_OWORD *)(a1 + 24) = v7;
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  *(_OWORD *)(a1 + 64) = *(_OWORD *)(a2 + 64);
  *(_OWORD *)(a1 + 80) = *(_OWORD *)(a2 + 80);
  *(unsigned char *)(a1 + 96) = *(unsigned char *)(a2 + 96);
  uint64_t v8 = *(int *)(a3 + 28);
  uint64_t v9 = a1 + v8;
  uint64_t v10 = v8 + a2;
  uint64_t v11 = type metadata accessor for BaseLinearRegressor(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v11 - 8) + 40))(v9, v10, v11);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLinearRegressor.Regressor(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_271DE5);
}

uint64_t sub_271DE5(uint64_t a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t result = 0;
    if ((*(void *)(a1 + 8) & 0xFFFFFFFF00000001) == 0) {
      return (*(void *)(a1 + 8) >> 1) + 1;
    }
  }
  else
  {
    uint64_t v5 = type metadata accessor for BaseLinearRegressor(0);
    return __swift_getEnumTagSinglePayload(*(int *)(a3 + 28) + a1, a2, v5);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLLinearRegressor.Regressor(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_271E6D);
}

uint64_t sub_271E6D(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(a1 + 8) = 2 * (a2 - 1);
  }
  else
  {
    uint64_t v5 = type metadata accessor for BaseLinearRegressor(0);
    return __swift_storeEnumTagSinglePayload(*(int *)(a4 + 28) + a1, a2, a2, v5);
  }
  return result;
}

uint64_t type metadata accessor for MLLinearRegressor.Regressor(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLLinearRegressor.Regressor;
  if (!type metadata singleton initialization cache for MLLinearRegressor.Regressor) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLLinearRegressor.Regressor);
  }
  return result;
}

uint64_t type metadata completion function for MLLinearRegressor.Regressor(uint64_t a1)
{
  v3[0] = &unk_350990;
  v3[1] = (char *)&value witness table for Builtin.BridgeObject + 64;
  v3[2] = &unk_3509A8;
  uint64_t result = type metadata accessor for BaseLinearRegressor(319);
  if (v2 <= 0x3F)
  {
    v3[3] = *(void *)(result - 8) + 64;
    swift_initStructMetadata(a1, 256, 4, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t associated type witness table accessor for SupervisedTabularEstimator.Transformer : TabularTransformer in MLLinearRegressor.Regressor()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLLinearRegressor.Model and conformance MLLinearRegressor.Model, type metadata accessor for MLLinearRegressor.Model, (uint64_t)&protocol conformance descriptor for MLLinearRegressor.Model);
}

uint64_t MLLinearRegressor.Regressor.init(annotationColumnName:featureColumnNames:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v36 = a4;
  uint64_t v34 = a3;
  uint64_t v35 = a2;
  uint64_t v5 = v4;
  uint64_t v29 = type metadata accessor for BaseLinearRegressor(0);
  uint64_t v30 = *(void *)(v29 - 8);
  int64_t v6 = *(void *)(v30 + 64);
  long long v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  int64_t v31 = &v22;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearRegressor<Double>.Configuration);
  uint64_t v32 = *(void *)(v9 - 8);
  int64_t v10 = *(void *)(v32 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  uint64_t v33 = v5;
  *(void *)uint64_t v5 = a1;
  *((void *)v5 + 1) = v35;
  *((void *)v5 + 2) = v34;
  uint64_t v15 = (uint64_t)(v5 + 24);
  uint64_t v16 = v36;
  outlined init with copy of MLLinearRegressor.ModelParameters(v36, v15);
  outlined init with copy of MLLinearRegressor.ModelParameters(v16, (uint64_t)v23);
  uint64_t v17 = lazy protocol witness table accessor for type Double and conformance Double();
  LinearRegressor.Configuration.init()(&type metadata for Double, &protocol witness table for Double, v17);
  LinearRegressor.Configuration.maximumIterations.setter(v24, v9);
  LinearRegressor.Configuration.l1Penalty.setter(v9, v25);
  LinearRegressor.Configuration.l2Penalty.setter(v9, v26);
  LinearRegressor.Configuration.stepSize.setter(v9, v27);
  LinearRegressor.Configuration.convergenceThreshold.setter(v9, v28);
  outlined destroy of MLLinearRegressor.ModelParameters((uint64_t)v23);
  uint64_t v18 = v32;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v32 + 16))(&v22, &v22, v9);
  uint64_t v19 = v31;
  BaseLinearRegressor.init(configuration:)(&v22);
  outlined destroy of MLLinearRegressor.ModelParameters(v36);
  (*(void (**)(uint64_t *, uint64_t))(v18 + 8))(&v22, v9);
  uint64_t v20 = type metadata accessor for MLLinearRegressor.Regressor(0);
  return (*(uint64_t (**)(char *, uint64_t *, uint64_t))(v30 + 32))(&v33[*(int *)(v20 + 28)], v19, v29);
}

uint64_t MLLinearRegressor.Regressor.makeTransformer()()
{
  uint64_t v2 = v0;
  uint64_t v3 = *v1;
  uint64_t v4 = v1[1];
  type metadata accessor for MLLinearRegressor.Regressor(0);
  type metadata accessor for MLLinearRegressor.Model(0);
  swift_bridgeObjectRetain(v4);
  uint64_t result = BaseLinearRegressor.makeTransformer()(v4);
  *(void *)uint64_t v2 = v3;
  *(void *)(v2 + 8) = v4;
  *(_OWORD *)(v2 + 16) = 0;
  *(void *)(v2 + 32) = 0;
  return result;
}

uint64_t MLLinearRegressor.Regressor.update(_:with:eventHandler:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v66 = v4;
  int64_t v6 = v5;
  uint64_t v52 = a4;
  uint64_t v53 = a3;
  uint64_t v59 = type metadata accessor for BaseLinearRegressor(0);
  uint64_t v58 = *(void *)(v59 - 8);
  int64_t v7 = *(void *)(v58 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v51 = &v40;
  uint64_t v63 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearRegressor<Double>.Configuration);
  uint64_t v62 = *(void *)(v63 - 8);
  int64_t v10 = *(void *)(v62 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v54 = &v40;
  uint64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  uint64_t v55 = &v40;
  uint64_t v64 = type metadata accessor for AnyColumn(0);
  uint64_t v49 = *(void *)(v64 - 8);
  int64_t v15 = *(void *)(v49 + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v50 = &v40;
  uint64_t v61 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  uint64_t v60 = *(void *)(v61 - 8);
  int64_t v18 = *(void *)(v60 + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  ML16ColumnDescriptorVsAE_pTg5 = (void *)a1[2];
  uint64_t v57 = a1;
  uint64_t v65 = &v40;
  uint64_t v48 = v6;
  if (ML16ColumnDescriptorVsAE_pTg5)
  {
    uint64_t v22 = a1[3];
    uint64_t v23 = (char *)a1[4];
    uint64_t v24 = v66;
  }
  else
  {
    uint64_t v56 = &v40;
    uint64_t v35 = v6[2];
    uint64_t v36 = alloca(24);
    char v37 = alloca(32);
    uint64_t v42 = a2;
    swift_bridgeObjectRetain(v35);
    uint64_t v38 = v66;
    ML16ColumnDescriptorVsAE_pTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_8CreateML16ColumnDescriptorVsAE_pTg5((void (*)(void *, uint64_t *))partial apply for closure #1 in FeatureVectorizer.fitted(to:), (uint64_t)&v40, v35);
    uint64_t result = swift_bridgeObjectRelease(v35);
    if (v38) {
      return result;
    }
    uint64_t v22 = 0xD000000000000013;
    uint64_t v66 = 0;
    uint64_t v39 = v57;
    outlined consume of FeatureVectorizer<Double>.Transformer?(v57[2], v57[3], v57[4]);
    v39[2] = (uint64_t)ML16ColumnDescriptorVsAE_pTg5;
    v39[3] = 0xD000000000000013;
    uint64_t v23 = "raining samples." + 0x8000000000000000;
    v39[4] = (uint64_t)("raining samples." + 0x8000000000000000);
    uint64_t v24 = v66;
  }
  uint64_t result = specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(a2, 1u, (uint64_t)ML16ColumnDescriptorVsAE_pTg5, v22, (uint64_t)v23);
  if (!v24)
  {
    uint64_t v66 = 0;
    double v26 = v48;
    double v27 = v50;
    DataFrame.subscript.getter(*v48, v48[1]);
    uint64_t v28 = AnyColumn.convertedToDoubles()();
    (*(void (**)(uint64_t *, uint64_t))(v49 + 8))(v27, v64);
    uint64_t v64 = v28;
    if (!v28) {
      BUG();
    }
    outlined init with copy of MLLinearRegressor.ModelParameters((uint64_t)(v26 + 3), (uint64_t)v41);
    uint64_t v29 = lazy protocol witness table accessor for type Double and conformance Double();
    uint64_t v30 = v55;
    LinearRegressor.Configuration.init()(&type metadata for Double, &protocol witness table for Double, v29);
    uint64_t v31 = v63;
    LinearRegressor.Configuration.maximumIterations.setter(v43, v63);
    LinearRegressor.Configuration.l1Penalty.setter(v31, v44);
    LinearRegressor.Configuration.l2Penalty.setter(v31, v45);
    LinearRegressor.Configuration.stepSize.setter(v31, v46);
    LinearRegressor.Configuration.convergenceThreshold.setter(v31, v47);
    outlined destroy of MLLinearRegressor.ModelParameters((uint64_t)v41);
    uint64_t v32 = v54;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v62 + 16))(v54, v30, v31);
    uint64_t v33 = v51;
    BaseLinearRegressor.init(configuration:)(v32);
    uint64_t v34 = type metadata accessor for MLLinearRegressor.Model(0);
    BaseLinearRegressor.update(_:features:annotations:eventHandler:)((char *)v57 + *(int *)(v34 + 24), v65, v64, v53, v52);
    swift_release();
    (*(void (**)(uint64_t *, uint64_t))(v58 + 8))(v33, v59);
    (*(void (**)(uint64_t *, uint64_t))(v62 + 8))(v30, v63);
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v60 + 8))(v65, v61);
  }
  return result;
}

uint64_t MLLinearRegressor.Regressor.annotationColumnID.getter()
{
  uint64_t v1 = *v0;
  uint64_t v2 = v0[1];
  swift_bridgeObjectRetain(v2);
  return ColumnID.init(_:_:)(v1, v2, &type metadata for Double);
}

uint64_t MLLinearRegressor.Regressor.annotationColumnID.setter(uint64_t a1)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<Double>);
  uint64_t v3 = ColumnID.name.getter(v2);
  uint64_t v5 = v4;
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  uint64_t result = swift_bridgeObjectRelease(v1[1]);
  *uint64_t v1 = v3;
  v1[1] = v5;
  return result;
}

uint64_t MLLinearRegressor.Regressor.fitted(to:validateOn:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  *(void *)&long long v141 = v5;
  uint64_t v116 = a4;
  uint64_t v117 = a3;
  uint64_t v111 = a2;
  uint64_t v129 = a1;
  uint64_t v114 = v4;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                             - 8)
                 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v110 = v102;
  uint64_t v125 = type metadata accessor for DataFrame(0);
  uint64_t v126 = *(void *)(v125 - 8);
  int64_t v10 = *(void *)(v126 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v127 = v102;
  uint64_t v118 = type metadata accessor for BaseLinearRegressorModel(0);
  uint64_t v119 = *(void *)(v118 - 8);
  int64_t v13 = *(void *)(v119 + 64);
  uint64_t v14 = alloca(v13);
  int64_t v15 = alloca(v13);
  uint64_t v113 = v102;
  uint64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v120 = v102;
  int64_t v18 = alloca(v13);
  uint64_t v19 = alloca(v13);
  uint64_t v123 = v102;
  uint64_t v134 = type metadata accessor for BaseLinearRegressor(0);
  uint64_t v133 = *(void *)(v134 - 8);
  int64_t v20 = *(void *)(v133 + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v124 = v102;
  uint64_t v138 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearRegressor<Double>.Configuration);
  uint64_t v137 = *(void *)(v138 - 8);
  int64_t v23 = *(void *)(v137 + 64);
  uint64_t v24 = alloca(v23);
  double v25 = alloca(v23);
  uint64_t v112 = v102;
  double v26 = alloca(v23);
  double v27 = alloca(v23);
  uint64_t v139 = v102;
  uint64_t v122 = type metadata accessor for AnyColumn(0);
  uint64_t v130 = *(void *)(v122 - 8);
  int64_t v28 = *(void *)(v130 + 64);
  uint64_t v29 = alloca(v28);
  uint64_t v30 = alloca(v28);
  uint64_t v115 = v102;
  uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  uint64_t v32 = *(void *)(v31 - 8);
  int64_t v33 = *(void *)(v32 + 64);
  uint64_t v34 = alloca(v33);
  uint64_t v35 = alloca(v33);
  uint64_t v131 = v102;
  uint64_t v36 = alloca(v33);
  char v37 = alloca(v33);
  uint64_t v142 = v102;
  uint64_t v132 = v6;
  uint64_t v38 = v6[2];
  uint64_t v103 = v129;
  swift_bridgeObjectRetain(v38);
  uint64_t v39 = v141;
  ML16ColumnDescriptorVsAE_pTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_8CreateML16ColumnDescriptorVsAE_pTg5((void (*)(void *, uint64_t *))closure #1 in FeatureVectorizer.fitted(to:)partial apply, (uint64_t)v102, v38);
  *(void *)&long long v141 = v39;
  if (v39)
  {
    char v41 = v38;
    return swift_bridgeObjectRelease(v41);
  }
  uint64_t v140 = v32;
  uint64_t v135 = v31;
  uint64_t v42 = (uint64_t)ML16ColumnDescriptorVsAE_pTg5;
  swift_bridgeObjectRelease(v38);
  uint64_t v43 = v141;
  specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(v129, 1u, v42, 0xD000000000000013, (uint64_t)("raining samples." + 0x8000000000000000));
  *(void *)&long long v141 = v43;
  if (v43)
  {
    char v41 = v42;
    return swift_bridgeObjectRelease(v41);
  }
  uint64_t v121 = "raining samples." + 0x8000000000000000;
  uint64_t v136 = v42;
  double v45 = v115;
  DataFrame.subscript.getter(*v132, v132[1]);
  uint64_t v46 = AnyColumn.convertedToDoubles()();
  uint64_t v130 = *(void *)(v130 + 8);
  ((void (*)(unsigned char *, uint64_t))v130)(v45, v122);
  if (!v46)
  {
    swift_bridgeObjectRelease(v136);
    *(void *)&v104[0] = 0;
    *((void *)&v104[0] + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(52);
    v60._uint64_t countAndFlagsBits = 0xD000000000000031;
    v60._char object = "Expected a linear classifier." + 0x8000000000000000;
    String.append(_:)(v60);
    DataFrame.subscript.getter(*v132, v132[1]);
    uint64_t v61 = AnyColumn.wrappedElementType.getter();
    ((void (*)(unsigned char *, uint64_t))v130)(v45, v122);
    uint64_t v62 = _typeName(_:qualified:)(v61, 0);
    char v64 = (char)v63;
    v60._uint64_t countAndFlagsBits = v62;
    v60._char object = v63;
    String.append(_:)(v60);
    swift_bridgeObjectRelease(v64);
    v60._uint64_t countAndFlagsBits = 46;
    v60._char object = (void *)0xE100000000000000;
    String.append(_:)(v60);
    long long v141 = v104[0];
    v60._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v65 = swift_allocError(&type metadata for MLCreateError, v60._object, 0, 0);
    *(_OWORD *)uint64_t v66 = v141;
    *(_OWORD *)(v66 + 16) = 0;
    *(_OWORD *)(v66 + 32) = 0;
    *(unsigned char *)(v66 + 48) = 1;
    *(void *)&long long v141 = v65;
    swift_willThrow(&type metadata for MLCreateError, v60._object, v66, v67, v68, v69);
LABEL_13:
    uint64_t v58 = v142;
    uint64_t v59 = v135;
    return (*(uint64_t (**)(unsigned char *, uint64_t))(v140 + 8))(v58, v59);
  }
  uint64_t v128 = v46;
  outlined init with copy of MLLinearRegressor.ModelParameters((uint64_t)(v132 + 3), (uint64_t)v104);
  uint64_t v47 = lazy protocol witness table accessor for type Double and conformance Double();
  uint64_t v48 = v139;
  LinearRegressor.Configuration.init()(&type metadata for Double, &protocol witness table for Double, v47);
  uint64_t v49 = v138;
  LinearRegressor.Configuration.maximumIterations.setter(v105, v138);
  LinearRegressor.Configuration.l1Penalty.setter(v49, v106);
  LinearRegressor.Configuration.l2Penalty.setter(v49, v107);
  LinearRegressor.Configuration.stepSize.setter(v49, v108);
  LinearRegressor.Configuration.convergenceThreshold.setter(v49, v109);
  outlined destroy of MLLinearRegressor.ModelParameters((uint64_t)v104);
  uint64_t v50 = v112;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v137 + 16))(v112, v48, v49);
  uint64_t v51 = v124;
  BaseLinearRegressor.init(configuration:)(v50);
  uint64_t v52 = (uint64_t)v110;
  outlined init with copy of DataFrame?(v111, (uint64_t)v110);
  uint64_t v53 = v125;
  if (__swift_getEnumTagSinglePayload(v52, 1, v125) == 1)
  {
    outlined destroy of DataFrame?(v52);
    uint64_t v54 = v113;
    uint64_t v55 = v51;
    uint64_t v56 = v141;
    BaseLinearRegressor.fitted(features:annotations:eventHandler:)(v142, v128, v117, v116);
    *(void *)&long long v141 = v56;
    uint64_t v57 = v135;
    if (v56)
    {
      swift_release();
      swift_bridgeObjectRelease(v136);
      (*(void (**)(unsigned char *, uint64_t))(v133 + 8))(v55, v134);
      (*(void (**)(unsigned char *, uint64_t))(v137 + 8))(v139, v138);
      uint64_t v58 = v142;
      uint64_t v59 = v57;
      return (*(uint64_t (**)(unsigned char *, uint64_t))(v140 + 8))(v58, v59);
    }
    swift_release();
    (*(void (**)(unsigned char *, uint64_t))(v133 + 8))(v55, v134);
    (*(void (**)(unsigned char *, uint64_t))(v137 + 8))(v139, v138);
    (*(void (**)(unsigned char *, uint64_t))(v140 + 8))(v142, v57);
    uint64_t v75 = v54;
    uint64_t v76 = *(void (**)(unsigned char *, unsigned char *, uint64_t))(v119 + 32);
    uint64_t v77 = v123;
    goto LABEL_22;
  }
  uint64_t v70 = v52;
  uint64_t v71 = (uint64_t)v127;
  uint64_t v72 = v126;
  (*(void (**)(unsigned char *, uint64_t, uint64_t))(v126 + 32))(v127, v70, v53);
  char v73 = v136;
  uint64_t v74 = v141;
  specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(v71, 1u, v136, 0xD000000000000013, (uint64_t)v121);
  *(void *)&long long v141 = v74;
  if (v74)
  {
    swift_release();
    swift_bridgeObjectRelease(v73);
    (*(void (**)(uint64_t, uint64_t))(v72 + 8))(v71, v53);
    (*(void (**)(unsigned char *, uint64_t))(v133 + 8))(v124, v134);
    (*(void (**)(unsigned char *, uint64_t))(v137 + 8))(v139, v138);
    goto LABEL_13;
  }
  uint64_t v78 = v115;
  DataFrame.subscript.getter(*v132, v132[1]);
  uint64_t v79 = AnyColumn.convertedToDoubles()();
  uint64_t v80 = v122;
  ((void (*)(unsigned char *, uint64_t))v130)(v78, v122);
  if (!v79)
  {
    swift_release();
    swift_bridgeObjectRelease(v136);
    *(void *)&v104[0] = 0;
    *((void *)&v104[0] + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(52);
    v86._uint64_t countAndFlagsBits = 0xD000000000000031;
    v86._char object = "Expected a linear classifier." + 0x8000000000000000;
    String.append(_:)(v86);
    DataFrame.subscript.getter(*v132, v132[1]);
    uint64_t v87 = AnyColumn.wrappedElementType.getter();
    ((void (*)(unsigned char *, uint64_t))v130)(v78, v80);
    uint64_t v88 = _typeName(_:qualified:)(v87, 0);
    char v90 = (char)v89;
    v86._uint64_t countAndFlagsBits = v88;
    v86._char object = v89;
    String.append(_:)(v86);
    swift_bridgeObjectRelease(v90);
    v86._uint64_t countAndFlagsBits = 46;
    v86._char object = (void *)0xE100000000000000;
    String.append(_:)(v86);
    long long v141 = v104[0];
    v86._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v91 = swift_allocError(&type metadata for MLCreateError, v86._object, 0, 0);
    *(_OWORD *)uint64_t v92 = v141;
    *(_OWORD *)(v92 + 16) = 0;
    *(_OWORD *)(v92 + 32) = 0;
    *(unsigned char *)(v92 + 48) = 1;
    *(void *)&long long v141 = v91;
    swift_willThrow(&type metadata for MLCreateError, v86._object, v92, v93, v94, v95);
    uint64_t v83 = *(void (**)(unsigned char *, uint64_t))(v140 + 8);
    uint64_t v84 = v135;
    v83(v131, v135);
    (*(void (**)(unsigned char *, uint64_t))(v126 + 8))(v127, v125);
    uint64_t v85 = v124;
    goto LABEL_20;
  }
  unint64_t v81 = v124;
  uint64_t v82 = v141;
  BaseLinearRegressor.fitted(trainingFeatures:trainingAnnotations:validationFeatures:validationAnnotations:eventHandler:)(v142, v128, v131, v79, v117, v116);
  *(void *)&long long v141 = v82;
  if (v82)
  {
    swift_bridgeObjectRelease(v136);
    swift_release();
    swift_release();
    uint64_t v83 = *(void (**)(unsigned char *, uint64_t))(v140 + 8);
    uint64_t v84 = v135;
    v83(v131, v135);
    (*(void (**)(unsigned char *, uint64_t))(v126 + 8))(v127, v125);
    uint64_t v85 = v81;
LABEL_20:
    (*(void (**)(unsigned char *, uint64_t))(v133 + 8))(v85, v134);
    (*(void (**)(unsigned char *, uint64_t))(v137 + 8))(v139, v138);
    return ((uint64_t (*)(unsigned char *, uint64_t))v83)(v142, v84);
  }
  swift_release();
  swift_release();
  char v96 = *(void (**)(unsigned char *, uint64_t))(v140 + 8);
  uint64_t v97 = v135;
  v96(v131, v135);
  (*(void (**)(unsigned char *, uint64_t))(v126 + 8))(v127, v125);
  (*(void (**)(unsigned char *, uint64_t))(v133 + 8))(v81, v134);
  (*(void (**)(unsigned char *, uint64_t))(v137 + 8))(v139, v138);
  v96(v142, v97);
  uint64_t v76 = *(void (**)(unsigned char *, unsigned char *, uint64_t))(v119 + 32);
  uint64_t v77 = v123;
  uint64_t v75 = v120;
LABEL_22:
  uint64_t v98 = v118;
  v76(v77, v75, v118);
  uint64_t v129 = *v132;
  uint64_t v99 = v132[1];
  uint64_t v100 = type metadata accessor for MLLinearRegressor.Model(0);
  uint64_t v101 = v114;
  v76((unsigned char *)v114 + *(int *)(v100 + 24), v123, v98);
  void *v101 = v129;
  v101[1] = v99;
  v101[2] = v136;
  v101[3] = 0xD000000000000013;
  v101[4] = v121;
  return swift_bridgeObjectRetain(v99);
}

uint64_t MLLinearRegressor.Regressor.encode(_:to:)(uint64_t a1, uint64_t a2)
{
  uint64_t v16 = v2;
  uint64_t v3 = *(void *)(a1 + 32);
  uint64_t v15 = a1;
  long long v13 = *(_OWORD *)(a1 + 16);
  uint64_t v14 = v3;
  uint64_t v4 = *(void *)(a2 + 24);
  uint64_t v17 = *(void *)(a2 + 32);
  __swift_mutable_project_boxed_opaque_existential_1(a2, v4);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer?);
  uint64_t v6 = lazy protocol witness table accessor for type FeatureVectorizer<Double>.Transformer? and conformance <A> A?();
  uint64_t result = ((uint64_t (*)(long long *, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))dispatch thunk of EstimatorEncoder.encode<A>(_:))(&v13, v5, v6, v4, v17, v7);
  if (!v2)
  {
    uint64_t v9 = *(int *)(type metadata accessor for MLLinearRegressor.Model(0) + 24) + v15;
    uint64_t v17 = *(void *)(a2 + 24);
    uint64_t v16 = *(void *)(a2 + 32);
    __swift_mutable_project_boxed_opaque_existential_1(a2, v17);
    uint64_t v10 = type metadata accessor for BaseLinearRegressorModel(0);
    uint64_t v11 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type BaseLinearRegressorModel and conformance BaseLinearRegressorModel, (uint64_t (*)(uint64_t))&type metadata accessor for BaseLinearRegressorModel, (uint64_t)&protocol conformance descriptor for BaseLinearRegressorModel);
    return dispatch thunk of EstimatorEncoder.encode<A>(_:)(v9, v10, v11, v17, v16, v12, v13, *((void *)&v13 + 1), v14);
  }
  return result;
}

uint64_t MLLinearRegressor.Regressor.decode(from:)(uint64_t a1)
{
  uint64_t v28 = v2;
  uint64_t v21 = v1;
  uint64_t v19 = type metadata accessor for BaseLinearRegressorModel(0);
  uint64_t v22 = *(void *)(v19 - 8);
  int64_t v4 = *(void *)(v22 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  double v25 = v18;
  uint64_t v23 = *v3;
  uint64_t v7 = v3[1];
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
  uint64_t v9 = *(void *)(a1 + 24);
  uint64_t v29 = *(void *)(a1 + 32);
  uint64_t v20 = a1;
  uint64_t v27 = __swift_mutable_project_boxed_opaque_existential_1(a1, v9);
  uint64_t v10 = lazy protocol witness table accessor for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer(&lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer, (uint64_t)&protocol conformance descriptor for FeatureVectorizer<A>.Transformer);
  uint64_t v26 = v7;
  swift_bridgeObjectRetain(v7);
  uint64_t v11 = v28;
  dispatch thunk of EstimatorDecoder.decode<A>(_:)(v8, v8, v10, v9, v29);
  if (v11) {
    return swift_bridgeObjectRelease(v26);
  }
  uint64_t v28 = v18[0];
  uint64_t v24 = v18[1];
  uint64_t v29 = v18[2];
  uint64_t v12 = *(void *)(v20 + 24);
  uint64_t v27 = *(void *)(v20 + 32);
  __swift_mutable_project_boxed_opaque_existential_1(v20, v12);
  uint64_t v13 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type BaseLinearRegressorModel and conformance BaseLinearRegressorModel, (uint64_t (*)(uint64_t))&type metadata accessor for BaseLinearRegressorModel, (uint64_t)&protocol conformance descriptor for BaseLinearRegressorModel);
  uint64_t v14 = v19;
  dispatch thunk of EstimatorDecoder.decode<A>(_:)(v19, v19, v13, v12, v27);
  uint64_t v16 = v21;
  *(void *)uint64_t v21 = v23;
  *((void *)v16 + 1) = v26;
  *((void *)v16 + 2) = v28;
  *((void *)v16 + 3) = v24;
  *((void *)v16 + 4) = v29;
  uint64_t v17 = type metadata accessor for MLLinearRegressor.Model(0);
  return (*(uint64_t (**)(char *, void *, uint64_t))(v22 + 32))(&v16[*(int *)(v17 + 24)], v25, v14);
}

uint64_t protocol witness for SupervisedTabularEstimator.annotationColumnID.getter in conformance MLLinearRegressor.Regressor()
{
  return MLLinearRegressor.Regressor.annotationColumnID.getter();
}

uint64_t protocol witness for SupervisedTabularEstimator.annotationColumnID.setter in conformance MLLinearRegressor.Regressor(uint64_t a1)
{
  return MLLinearRegressor.Regressor.annotationColumnID.setter(a1);
}

void (*protocol witness for SupervisedTabularEstimator.annotationColumnID.modify in conformance MLLinearRegressor.Regressor(void *a1))(uint64_t a1, char a2)
{
  uint64_t v2 = malloc(0x28uLL);
  *a1 = v2;
  void *v2 = v1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<Double>);
  v2[1] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[2] = v4;
  size_t v5 = *(void *)(v4 + 64);
  v2[3] = malloc(v5);
  v2[4] = malloc(v5);
  MLLinearRegressor.Regressor.annotationColumnID.getter();
  return protocol witness for SupervisedTabularEstimator.annotationColumnID.modify in conformance MLLinearRegressor.Regressor;
}

void protocol witness for SupervisedTabularEstimator.annotationColumnID.modify in conformance MLLinearRegressor.Regressor(uint64_t a1, char a2)
{
  uint64_t v2 = *(void **)a1;
  uint64_t v3 = *(void **)(*(void *)a1 + 24);
  uint64_t v4 = *(void **)(*(void *)a1 + 32);
  if (a2)
  {
    uint64_t v5 = v2[2];
    uint64_t v6 = v2[1];
    (*(void (**)(void *, void *))(v5 + 16))(v3, v4);
    MLLinearRegressor.Regressor.annotationColumnID.setter((uint64_t)v3);
    (*(void (**)(void *, uint64_t))(v5 + 8))(v4, v6);
  }
  else
  {
    MLLinearRegressor.Regressor.annotationColumnID.setter(*(void *)(*(void *)a1 + 32));
  }
  free(v4);
  free(v3);
  free(v2);
}

uint64_t protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance MLLinearRegressor.Regressor(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  MLLinearRegressor.Regressor.fitted(to:validateOn:eventHandler:)(a2, a3, a4, a5);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(*(uint64_t (**)(void))(v5 + 8));
}

uint64_t protocol witness for SupervisedTabularEstimator.encode(_:to:) in conformance MLLinearRegressor.Regressor(uint64_t a1, uint64_t a2)
{
  return MLLinearRegressor.Regressor.encode(_:to:)(a1, a2);
}

uint64_t protocol witness for SupervisedTabularEstimator.decode(from:) in conformance MLLinearRegressor.Regressor(uint64_t a1)
{
  return MLLinearRegressor.Regressor.decode(from:)(a1);
}

uint64_t base witness table accessor for SupervisedTabularEstimator in MLLinearRegressor.Regressor()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLLinearRegressor.Regressor and conformance MLLinearRegressor.Regressor, type metadata accessor for MLLinearRegressor.Regressor, (uint64_t)&protocol conformance descriptor for MLLinearRegressor.Regressor);
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.makeTransformer() in conformance MLLinearRegressor.Regressor()
{
  return MLLinearRegressor.Regressor.makeTransformer()();
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.update(_:with:eventHandler:) in conformance MLLinearRegressor.Regressor(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  MLLinearRegressor.Regressor.update(_:with:eventHandler:)(a1, a2, a3, a4);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(*(uint64_t (**)(void))(v4 + 8));
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.encodeWithOptimizer(_:to:) in conformance MLLinearRegressor.Regressor(uint64_t a1, uint64_t a2)
{
  return protocol witness for SupervisedTabularEstimator.encode(_:to:) in conformance MLLinearRegressor.Regressor(a1, a2);
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.decodeWithOptimizer(from:) in conformance MLLinearRegressor.Regressor(uint64_t a1)
{
  return protocol witness for SupervisedTabularEstimator.decode(from:) in conformance MLLinearRegressor.Regressor(a1);
}

uint64_t outlined consume of FeatureVectorizer<Double>.Transformer?(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a1)
  {
    swift_bridgeObjectRelease(a1);
    return swift_bridgeObjectRelease(a3);
  }
  return result;
}

uint64_t instantiation function for generic protocol witness table for Adam<A>(uint64_t a1, uint64_t a2)
{
  uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for Adam<A>, a2);
  *(void *)(a1 + 8) = result;
  return result;
}

void static MLCreateError.checkoutDictionaryMissingOrInvalidValue(key:)(Swift::String a1)
{
  char object = a1._object;
  *(void *)&long long v6 = 0;
  uint64_t countAndFlagsBits = a1._countAndFlagsBits;
  uint64_t v4 = v1;
  *((void *)&v6 + 1) = 0xE000000000000000;
  _StringGuts.grow(_:)(58);
  v5._char object = " numeric but got " + 0x8000000000000000;
  v5._uint64_t countAndFlagsBits = 0xD000000000000038;
  String.append(_:)(v5);
  v5._uint64_t countAndFlagsBits = countAndFlagsBits;
  v5._char object = object;
  String.append(_:)(v5);
  *(_OWORD *)uint64_t v4 = v6;
  *(_OWORD *)(v4 + 16) = 0;
  *(_OWORD *)(v4 + 32) = 0;
  *(unsigned char *)(v4 + 48) = 2;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSD4KeysVySSSaySdG_G_SSs5NeverOTg5101_s8CreateML16_ModelCheckpointPAA14NeuralNetworks5Layer0C0RpzrlE4save2toy10Foundation3URLV_tKFS2SXEfU_Tf1cn_n(uint64_t a1)
{
  int64_t v1 = *(void *)(a1 + 16);
  if (v1)
  {
    uint64_t v2 = a1;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0);
    int64_t v3 = specialized _NativeDictionary.startIndex.getter(a1);
    if (v3 < 0 || v3 >= 1 << *(unsigned char *)(a1 + 32)) {
LABEL_22:
    }
      BUG();
    uint64_t v20 = a1 + 64;
    while (1)
    {
      int64_t v16 = v1;
      unint64_t v5 = (unint64_t)v3 >> 6;
      uint64_t v6 = *(void *)(v20 + 8 * ((unint64_t)v3 >> 6));
      uint64_t v7 = 1 << v3;
      if (!_bittest64(&v6, v3)) {
        BUG();
      }
      if (v4 != *(_DWORD *)(v2 + 36)) {
        BUG();
      }
      int v17 = v4;
      uint64_t v8 = *(void *)(v2 + 48);
      uint64_t v14 = *(void *)(v8 + 16 * v3);
      unint64_t v9 = _swiftEmptyArrayStorage[2];
      unint64_t v18 = _swiftEmptyArrayStorage[3];
      int64_t v19 = v9 + 1;
      uint64_t v13 = v3;
      uint64_t v15 = *(void *)(v8 + 16 * v3 + 8);
      swift_bridgeObjectRetain(v15);
      if (v18 >> 1 <= v9) {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v18 >= 2, v19, 1);
      }
      _swiftEmptyArrayStorage[2] = v19;
      uint64_t v10 = 2 * v9;
      _swiftEmptyArrayStorage[v10 + 4] = v14;
      _swiftEmptyArrayStorage[v10 + 5] = v15;
      uint64_t v2 = a1;
      char v11 = *(unsigned char *)(a1 + 32);
      if (v13 >= -(-1 << v11)) {
        BUG();
      }
      if ((v7 & *(void *)(v20 + 8 * v5)) == 0) {
        BUG();
      }
      if (v17 != *(_DWORD *)(a1 + 36)) {
        BUG();
      }
      int64_t v3 = _HashTable.occupiedBucket(after:)(v13, v20, ~(-1 << v11));
      int64_t v1 = v16 - 1;
      if (v16 == 1) {
        break;
      }
      if (v3 >= 0)
      {
        int v4 = *(_DWORD *)(a1 + 36);
        if (v3 < 1 << *(unsigned char *)(a1 + 32)) {
          continue;
        }
      }
      goto LABEL_22;
    }
  }
  return _swiftEmptyArrayStorage;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSD6ValuesVySSSaySdG_G_AHs5NeverOTg5107_s8CreateML16_ModelCheckpointPAA14NeuralNetworks5Layer0C0RpzrlE4save2toy10Foundation3URLV_tKFSaySdGAMXEfU0_Tf1cn_n(uint64_t a1)
{
  int64_t v1 = *(void *)(a1 + 16);
  if (!v1) {
    return _swiftEmptyArrayStorage;
  }
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0);
  uint64_t v20 = _swiftEmptyArrayStorage;
  uint64_t v2 = a1;
  int64_t v3 = specialized Dictionary.Values.startIndex.getter(a1);
  if (v3 < 0 || v3 >= 1 << *(unsigned char *)(a1 + 32)) {
LABEL_23:
  }
    BUG();
  uint64_t v5 = a1 + 64;
  uint64_t v17 = a1 + 64;
  while (1)
  {
    int64_t v15 = v1;
    unint64_t v6 = (unint64_t)v3 >> 6;
    uint64_t v7 = *(void *)(v5 + 8 * ((unint64_t)v3 >> 6));
    uint64_t v8 = 1 << v3;
    if (!_bittest64(&v7, v3)) {
      BUG();
    }
    if (v4 != *(_DWORD *)(v2 + 36)) {
      BUG();
    }
    int v16 = v4;
    unint64_t v14 = v20[2];
    unint64_t v18 = v20[3];
    int64_t v19 = v14 + 1;
    uint64_t v12 = v3;
    uint64_t v13 = *(void *)(*(void *)(v2 + 56) + 8 * v3);
    swift_bridgeObjectRetain(v13);
    unint64_t v9 = v20;
    if (v18 >> 1 <= v14)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v18 >= 2, v19, 1);
      unint64_t v9 = v20;
    }
    void v9[2] = v19;
    v9[v14 + 4] = v13;
    uint64_t v2 = a1;
    char v10 = *(unsigned char *)(a1 + 32);
    uint64_t v5 = a1 + 64;
    if (v12 >= -(-1 << v10)) {
      BUG();
    }
    if ((v8 & *(void *)(v17 + 8 * v6)) == 0) {
      BUG();
    }
    if (v16 != *(_DWORD *)(a1 + 36)) {
      BUG();
    }
    uint64_t v20 = v9;
    int64_t v3 = _HashTable.occupiedBucket(after:)(v12, v17, ~(-1 << v10));
    int64_t v1 = v15 - 1;
    if (v15 == 1) {
      return v9;
    }
    if (v3 >= 0)
    {
      int v4 = *(_DWORD *)(a1 + 36);
      if (v3 < 1 << *(unsigned char *)(a1 + 32)) {
        continue;
      }
    }
    goto LABEL_23;
  }
}

uint64_t specialized _ModelCheckpoint<>.save(to:)(uint64_t a1)
{
  return specialized _ModelCheckpoint<>.save(to:)(a1, (uint64_t (*)(void))MLHandActionClassifier.GraphCNN.getCheckpointStatesDictionary());
}

{
  return specialized _ModelCheckpoint<>.save(to:)(a1, (uint64_t (*)(void))MLActivityClassifier.Trainer.ModelContainer.getCheckpointStatesDictionary());
}

uint64_t specialized _ModelCheckpoint<>.save(to:)(uint64_t a1, uint64_t (*a2)(void))
{
  uint64_t v25 = (uint64_t)a2;
  uint64_t v22 = a1;
  uint64_t v3 = type metadata accessor for URL(0);
  uint64_t v4 = *(void *)(v3 - 8);
  int64_t v5 = *(void *)(v4 + 64);
  unint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v21 = v18;
  uint64_t result = a2();
  if (!v2)
  {
    uint64_t v24 = v3;
    uint64_t v23 = v4;
    uint64_t v9 = result;
    uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MLDataValueConvertible)>);
    uint64_t inited = (void *)swift_initStackObject(v10, v18);
    inited[2] = 2;
    inited[3] = 4;
    inited[4] = 1937335659;
    inited[5] = 0xE400000000000000;
    swift_bridgeObjectRetain(v9);
    ML16_ModelCheckpointPAA14NeuralNetworks5Layer0C0RpzrlE4save2toy10Foundation3URLV_tKFS2SXEfU_Tf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSD4KeysVySSSaySdG_G_SSs5NeverOTg5101_s8CreateML16_ModelCheckpointPAA14NeuralNetworks5Layer0C0RpzrlE4save2toy10Foundation3URLV_tKFS2SXEfU_Tf1cn_n(v9);
    uint64_t v25 = 0;
    swift_bridgeObjectRelease(v9);
    inited[9] = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
    inited[10] = lazy protocol witness table accessor for type [String] and conformance <A> [A](&lazy protocol witness table cache variable for type [String] and conformance <A> [A], &demangling cache variable for type metadata for [String]);
    inited[6] = ML16_ModelCheckpointPAA14NeuralNetworks5Layer0C0RpzrlE4save2toy10Foundation3URLV_tKFS2SXEfU_Tf1cn_n;
    inited[11] = 0x7365756C6176;
    inited[12] = 0xE600000000000000;
    uint64_t v13 = v25;
    ML16_ModelCheckpointPAA14NeuralNetworks5Layer0C0RpzrlE4save2toy10Foundation3URLV_tKFSaySdGAMXEfU0_Tf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSD6ValuesVySSSaySdG_G_AHs5NeverOTg5107_s8CreateML16_ModelCheckpointPAA14NeuralNetworks5Layer0C0RpzrlE4save2toy10Foundation3URLV_tKFSaySdGAMXEfU0_Tf1cn_n(v9);
    swift_bridgeObjectRelease(v9);
    inited[16] = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [[Double]]);
    inited[17] = lazy protocol witness table accessor for type [[Double]] and conformance <A> [A]();
    inited[13] = ML16_ModelCheckpointPAA14NeuralNetworks5Layer0C0RpzrlE4save2toy10Foundation3URLV_tKFSaySdGAMXEfU0_Tf1cn_n;
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLDataValueConvertible);
    uint64_t v16 = Dictionary.init(dictionaryLiteral:)(inited, &type metadata for String, v15, &protocol witness table for String);
    uint64_t result = MLDataTable.init(dictionary:)(v16);
    if (!v13)
    {
      uint64_t v25 = v19;
      char v26 = v20;
      uint64_t v17 = (uint64_t)v21;
      URL.appendingPathComponent(_:)(0x7461446C65646F6DLL, 0xE900000000000061);
      MLDataTable.write(to:)(v17);
      (*(void (**)(uint64_t, uint64_t))(v23 + 8))(v17, v24);
      return outlined consume of Result<_DataTable, Error>(v25, v26);
    }
  }
  return result;
}

uint64_t (*HandActionClassifierTrainingSessionDelegate.sourceTable.modify(uint64_t a1))()
{
  swift_beginAccess(OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable + v1, a1, 33, 0);
  return HandPoseClassifierTrainingSessionDelegate.sourceTable.modify;
}

uint64_t HandActionClassifierTrainingSessionDelegate.init(sessionParameters:)(uint64_t a1)
{
  uint64_t v2 = v1 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters;
  uint64_t v3 = type metadata accessor for MLHandActionClassifier.PersistentParameters(0);
  __swift_storeEnumTagSinglePayload(v2, 1, 1, v3);
  uint64_t v4 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable) = 0;
  *(unsigned char *)(v1 + v4 + 8) = -1;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTrainingRowCount) = 0;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceValidationRowCount) = 0;
  static MLHandActionClassifier.buildFeatureTable(features:labels:sessionIds:videoFiles:)((uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage);
  static MLHandActionClassifier.buildFeatureTable(features:labels:sessionIds:videoFiles:)((uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage);
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_model) = 0;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_classLabels) = 0;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_metricsAttributesDictionary) = _swiftEmptyDictionarySingleton;
  outlined init with take of MLClassifierMetrics(a1, v1 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  return v1;
}

uint64_t HandActionClassifierTrainingSessionDelegate.init(trainingData:modelParameters:sessionParameters:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v169 = v3;
  uint64_t v167 = a3;
  uint64_t v164 = a2;
  uint64_t v160 = a1;
  uint64_t v141 = type metadata accessor for MLHandActionClassifier.ModelParameters.ValidationData(0);
  int64_t v5 = *(void *)(*(void *)(v141 - 8) + 64);
  unint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v140 = v132;
  uint64_t v148 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v147 = *(void *)(v148 - 8);
  int64_t v8 = *(void *)(v147 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v149 = v132;
  uint64_t v136 = type metadata accessor for AnyColumn(0);
  uint64_t v135 = *(void *)(v136 - 8);
  int64_t v11 = *(void *)(v135 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v139 = v132;
  unint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  uint64_t v137 = v132;
  uint64_t v159 = type metadata accessor for DataFrame(0);
  uint64_t v153 = *(void *)(v159 - 8);
  int64_t v16 = *(void *)(v153 + 64);
  uint64_t v17 = alloca(v16);
  unint64_t v18 = alloca(v16);
  uint64_t v138 = v132;
  uint64_t v19 = alloca(v16);
  char v20 = alloca(v16);
  uint64_t v163 = v132;
  uint64_t v21 = (int *)type metadata accessor for MLHandActionClassifier.PersistentParameters(0);
  int64_t v22 = *(void *)(*((void *)v21 - 1) + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  v166 = v132;
  uint64_t v145 = type metadata accessor for MLHandActionClassifier.ModelParameters(0);
  int64_t v25 = *(void *)(*(void *)(v145 - 8) + 64);
  char v26 = alloca(v25);
  uint64_t v27 = alloca(v25);
  uint64_t v154 = (void *)type metadata accessor for MLHandActionClassifier.DataSource(0);
  int64_t v28 = *(void *)(*(v154 - 1) + 64);
  uint64_t v29 = alloca(v28);
  uint64_t v30 = alloca(v28);
  uint64_t v134 = v132;
  uint64_t v31 = alloca(v28);
  uint64_t v32 = alloca(v28);
  uint64_t v168 = (uint64_t *)v132;
  int64_t v33 = alloca(v28);
  uint64_t v34 = alloca(v28);
  uint64_t v155 = (int *)v132;
  int64_t v35 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  uint64_t v36 = alloca(v35);
  char v37 = alloca(v35);
  v161 = v132;
  uint64_t v157 = (void *)(v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters);
  __swift_storeEnumTagSinglePayload(v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters, 1, 1, (uint64_t)v21);
  uint64_t v38 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable;
  *(void *)(v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable) = 0;
  *(unsigned char *)(v4 + v38 + 8) = -1;
  *(void *)(v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTrainingRowCount) = 0;
  *(void *)(v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceValidationRowCount) = 0;
  uint64_t v146 = v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures;
  static MLHandActionClassifier.buildFeatureTable(features:labels:sessionIds:videoFiles:)((uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage);
  uint64_t v142 = v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures;
  static MLHandActionClassifier.buildFeatureTable(features:labels:sessionIds:videoFiles:)((uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage);
  *(void *)(v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_model) = 0;
  uint64_t v150 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_classLabels;
  *(void *)(v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_classLabels) = 0;
  uint64_t v165 = v4;
  *(void *)(v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_metricsAttributesDictionary) = _swiftEmptyDictionarySingleton;
  uint64_t v39 = (uint64_t)v155;
  outlined init with copy of MLTrainingSessionParameters(v160, (uint64_t)v155, type metadata accessor for MLHandActionClassifier.DataSource);
  outlined init with copy of MLTrainingSessionParameters(v164, (uint64_t)v132, type metadata accessor for MLHandActionClassifier.ModelParameters);
  uint64_t v156 = v21[6];
  uint64_t v162 = v21[7];
  uint64_t v158 = v21[8];
  uint64_t v40 = v21[9];
  char v41 = v166;
  *(void *)&v166[v40] = 0x403E000000000000;
  outlined init with take of MLClassifierMetrics(v39, (uint64_t)v41, type metadata accessor for MLHandActionClassifier.DataSource);
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v132, (uint64_t)&v41[v21[5]], type metadata accessor for MLHandActionClassifier.ModelParameters.ValidationData);
  uint64_t v42 = (int *)v145;
  *(void *)&v41[v156] = *(void *)&v132[*(int *)(v145 + 20)];
  *(void *)&v41[v158] = *(void *)&v132[v42[7]];
  *(void *)&v41[v162] = *(void *)&v132[v42[6]];
  *(void *)&v41[v21[10]] = *(void *)&v132[v42[8]];
  uint64_t v155 = *(int **)&v132[v42[10]];
  outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v132, type metadata accessor for MLHandActionClassifier.ModelParameters);
  __m128 v43 = (__m128)(unint64_t)v155;
  *(void *)&v41[v40] = v155;
  double v44 = v168;
  double v45 = v154;
  uint64_t v46 = (uint64_t)v161;
  outlined init with take of MLClassifierMetrics((uint64_t)v41, (uint64_t)v161, type metadata accessor for MLHandActionClassifier.PersistentParameters);
  uint64_t v155 = v21;
  __swift_storeEnumTagSinglePayload(v46, 0, 1, (uint64_t)v21);
  uint64_t v47 = (uint64_t)v157;
  swift_beginAccess(v157, &v151, 33, 0);
  uint64_t v48 = v46;
  uint64_t v49 = v160;
  outlined assign with take of MLHandActionClassifier.PersistentParameters?(v48, v47);
  swift_endAccess(&v151);
  outlined init with copy of MLTrainingSessionParameters(v49, (uint64_t)v44, type metadata accessor for MLHandActionClassifier.DataSource);
  if (swift_getEnumCaseMultiPayload(v44, v45) == 3)
  {
    uint64_t v50 = *v44;
    int v51 = *((_DWORD *)v44 + 2);
    uint64_t v159 = v44[2];
    uint64_t v162 = v44[3];
    uint64_t v163 = (unsigned char *)v44[4];
    uint64_t v158 = v44[5];
    v166 = (char *)v44[6];
    uint64_t v168 = (uint64_t *)v44[7];
    uint64_t v52 = v146;
    swift_beginAccess(v146, v133, 1, 0);
    v161 = *(unsigned char **)v52;
    *(void *)uint64_t v52 = v50;
    int v53 = *(_DWORD *)(v52 + 8);
    *(unsigned char *)(v52 + 8) = v51 & 1;
    uint64_t v156 = v50;
    uint64_t v54 = v50;
    int v55 = v51;
    outlined copy of Result<_DataTable, Error>(v54, v51);
    uint64_t v56 = v168;
    outlined consume of Result<_DataTable, Error>((uint64_t)v161, v53);
    swift_beginAccess(v52, &v151, 33, 0);
    uint64_t v57 = v169;
    static MLHandActionClassifier.reformatKeypointsDataTable(table:featureColumn:)((unsigned char *)v52, (uint64_t)v166, v56, *(double *)v43.i64);
    if (v57)
    {
      uint64_t v169 = v57;
      char v58 = 0;
      swift_endAccess(&v151);
      swift_bridgeObjectRelease((_BYTE)v56);
      swift_bridgeObjectRelease(v158);
      swift_bridgeObjectRelease(v162);
      outlined consume of Result<_DataTable, Error>(v156, v55);
LABEL_12:
      uint64_t v67 = v165;
      goto LABEL_13;
    }
    LODWORD(v161) = v55;
    swift_endAccess(&v151);
    swift_beginAccess(v52, &v151, 33, 0);
    char v74 = v162;
    uint64_t v75 = v56;
    char v76 = v158;
    static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(v52, v159, (void *)v162, v166, v75, (uint64_t)v163, (void *)v158);
    uint64_t v169 = 0;
    swift_endAccess(&v151);
    swift_bridgeObjectRelease((_BYTE)v168);
    swift_bridgeObjectRelease(v76);
    swift_bridgeObjectRelease(v74);
    swift_beginAccess(v52, &v151, 32, 0);
    v91._uint64_t countAndFlagsBits = 0x6C6562616CLL;
    v91._char object = (void *)0xE500000000000000;
    specialized MLDataTable.subscript.getter(v91, *(void *)v52, *(unsigned __int8 *)(v52 + 8), v92, v93);
    uint64_t v94 = v143;
    char v95 = v144;
    swift_endAccess(&v151);
    specialized MLDataColumn.dropDuplicates()(v94, v95);
    outlined consume of Result<_DataTable, Error>(v94, v95);
    char v96 = specialized Array<A>.init(_:)(v151, v152, *(double *)v43.i64);
    outlined consume of Result<_DataTable, Error>(v156, (char)v161);
    goto LABEL_21;
  }
  outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v44, type metadata accessor for MLHandActionClassifier.DataSource);
  uint64_t v59 = (uint64_t)v134;
  outlined init with copy of MLTrainingSessionParameters(v49, (uint64_t)v134, type metadata accessor for MLHandActionClassifier.DataSource);
  if (swift_getEnumCaseMultiPayload(v59, v45) == 5)
  {
    Swift::String v60 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
    uint64_t v61 = v60[12];
    uint64_t v156 = *(void *)(v59 + v61);
    uint64_t v168 = *(uint64_t **)(v59 + v61 + 8);
    uint64_t v62 = v60[16];
    uint64_t v158 = *(void *)(v59 + v62);
    uint64_t v162 = *(void *)(v59 + v62 + 8);
    uint64_t v63 = v60[20];
    v166 = *(char **)(v59 + v63);
    uint64_t v64 = *(void *)(v59 + v63 + 8);
    (*(void (**)(unsigned char *, uint64_t, uint64_t))(v153 + 32))(v163, v59, v159);
    uint64_t v65 = v137;
    v161 = (unsigned char *)v64;
    DataFrame.subscript.getter(v166, v64);
    uint64_t v66 = (void *)AnyColumn.wrappedElementType.getter();
    (*(void (**)(unsigned char *, uint64_t))(v135 + 8))(v65, v136);
    if (v66 == &type metadata for String)
    {
      uint64_t v78 = (uint64_t)v161;
      DataFrame.subscript.getter(v166, v161, &type metadata for String);
      uint64_t v79 = v139;
      uint64_t v80 = v169;
      Column<A>.parseAsJSONArrays()();
      uint64_t v68 = v78;
      if (v80)
      {
        swift_bridgeObjectRelease(v78);
        swift_bridgeObjectRelease(v162);
        swift_bridgeObjectRelease((_BYTE)v168);
        outlined destroy of MLHandActionClassifier.DataSource(v167, type metadata accessor for MLTrainingSessionParameters);
        outlined destroy of MLHandActionClassifier.DataSource(v164, type metadata accessor for MLHandActionClassifier.ModelParameters);
        outlined destroy of MLHandActionClassifier.DataSource(v160, type metadata accessor for MLHandActionClassifier.DataSource);
        (*(void (**)(unsigned char *, uint64_t))(v147 + 8))(v149, v148);
        goto LABEL_29;
      }
      uint64_t v169 = 0;
      (*(void (**)(unsigned char *, uint64_t))(v147 + 8))(v149, v148);
      swift_bridgeObjectRetain(v78);
      DataFrame.subscript.setter(v79, v166, v78);
      uint64_t v67 = v165;
    }
    else
    {
      uint64_t v67 = v165;
      uint64_t v68 = (uint64_t)v161;
    }
    uint64_t v69 = (uint64_t)v138;
    uint64_t v70 = v153;
    *(double *)v43.i64 = (*(double (**)(unsigned char *, unsigned char *, uint64_t))(v153 + 16))(v138, v163, v159);
    uint64_t v71 = v169;
    MLDataTable.init(_:convertArraysToShapedArrays:)(v69, 0, v43);
    if (v71)
    {
      swift_bridgeObjectRelease(v68);
      swift_bridgeObjectRelease(v162);
      swift_bridgeObjectRelease((_BYTE)v168);
      outlined destroy of MLHandActionClassifier.DataSource(v167, type metadata accessor for MLTrainingSessionParameters);
      outlined destroy of MLHandActionClassifier.DataSource(v164, type metadata accessor for MLHandActionClassifier.ModelParameters);
      outlined destroy of MLHandActionClassifier.DataSource(v160, type metadata accessor for MLHandActionClassifier.DataSource);
      (*(void (**)(unsigned char *, uint64_t))(v70 + 8))(v163, v159);
LABEL_30:
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v67 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
      outlined consume of MLDataTable?(*(void *)(v67 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable), *(_DWORD *)(v67 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable + 8));
      outlined consume of Result<_DataTable, Error>(*(void *)(v67 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures), *(_DWORD *)(v67 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures + 8));
      outlined consume of Result<_DataTable, Error>(*(void *)(v67 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures), *(_DWORD *)(v67 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures + 8));
      swift_release();
      swift_bridgeObjectRelease(*(void *)(v67
                                          + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_classLabels));
      swift_bridgeObjectRelease(*(void *)(v67
                                          + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_metricsAttributesDictionary));
      uint64_t v114 = type metadata accessor for HandActionClassifierTrainingSessionDelegate(0);
      swift_deallocPartialClassInstance(v67, v114, *(unsigned int *)(*(void *)v67 + 48), *(unsigned __int16 *)(*(void *)v67 + 52));
      return v67;
    }
    uint64_t v169 = 0;
    uint64_t v82 = v151;
    uint64_t v83 = (void *)v68;
    char v84 = v152;
    uint64_t v85 = v146;
    swift_beginAccess(v146, v133, 1, 0);
    uint64_t v86 = *(void *)v85;
    *(void *)uint64_t v85 = v82;
    int v87 = *(_DWORD *)(v85 + 8);
    *(unsigned char *)(v85 + 8) = v84;
    uint64_t v88 = v83;
    outlined consume of Result<_DataTable, Error>(v86, v87);
    swift_beginAccess(v85, &v151, 33, 0);
    uint64_t v89 = v166;
    uint64_t v90 = v169;
    static MLHandActionClassifier.reformatKeypointsDataTable(table:featureColumn:)((unsigned char *)v85, (uint64_t)v166, v88, *(double *)v43.i64);
    if (!v90)
    {
      swift_endAccess(&v151);
      swift_beginAccess(v85, &v151, 33, 0);
      uint64_t v112 = v89;
      char v113 = v162;
      static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(v85, v156, v168, v112, v88, v158, (void *)v162);
      uint64_t v169 = 0;
      swift_endAccess(&v151);
      swift_bridgeObjectRelease((_BYTE)v88);
      swift_bridgeObjectRelease(v113);
      swift_bridgeObjectRelease((_BYTE)v168);
      swift_beginAccess(v85, &v151, 32, 0);
      v126._uint64_t countAndFlagsBits = 0x6C6562616CLL;
      v126._char object = (void *)0xE500000000000000;
      specialized MLDataTable.subscript.getter(v126, *(void *)v85, *(unsigned __int8 *)(v85 + 8), v127, v128);
      uint64_t v129 = v143;
      char v130 = v144;
      swift_endAccess(&v151);
      specialized MLDataColumn.dropDuplicates()(v129, v130);
      outlined consume of Result<_DataTable, Error>(v129, v130);
      char v96 = specialized Array<A>.init(_:)(v151, v152, *(double *)v43.i64);
      (*(void (**)(unsigned char *, uint64_t))(v153 + 8))(v163, v159);
      goto LABEL_21;
    }
    swift_endAccess(&v151);
    swift_bridgeObjectRelease((_BYTE)v88);
    swift_bridgeObjectRelease(v162);
    swift_bridgeObjectRelease((_BYTE)v168);
    outlined destroy of MLHandActionClassifier.DataSource(v167, type metadata accessor for MLTrainingSessionParameters);
    outlined destroy of MLHandActionClassifier.DataSource(v164, type metadata accessor for MLHandActionClassifier.ModelParameters);
    outlined destroy of MLHandActionClassifier.DataSource(v160, type metadata accessor for MLHandActionClassifier.DataSource);
LABEL_29:
    (*(void (**)(unsigned char *, uint64_t))(v153 + 8))(v163, v159);
    uint64_t v67 = v165;
    goto LABEL_30;
  }
  outlined destroy of MLHandActionClassifier.DataSource(v59, type metadata accessor for MLHandActionClassifier.DataSource);
  uint64_t v72 = v169;
  char v73 = static _VideoUtilities.videoURLsPerClass(from:)(v49, v43);
  uint64_t v169 = v72;
  if (v72)
  {
    char v58 = 0;
    goto LABEL_12;
  }
  char v81 = (char)v73;
  char v96 = specialized _copyCollectionToContiguousArray<A>(_:)((uint64_t)v73);
  swift_bridgeObjectRelease(v81);
LABEL_21:
  uint64_t v67 = v165;
  uint64_t v97 = v150;
  uint64_t v98 = *(void *)(v165 + v150);
  *(void *)(v165 + v150) = v96;
  swift_bridgeObjectRelease(v98);
  uint64_t v99 = v157;
  uint64_t v100 = (uint64_t)v155;
  if (__swift_getEnumTagSinglePayload((uint64_t)v157, 1, (uint64_t)v155))
  {
LABEL_34:
    uint64_t v116 = v167;
    goto LABEL_35;
  }
  uint64_t v101 = (uint64_t)v99 + *(int *)(v100 + 20);
  uint64_t v102 = (uint64_t)v140;
  outlined init with copy of MLTrainingSessionParameters(v101, (uint64_t)v140, type metadata accessor for MLHandActionClassifier.ModelParameters.ValidationData);
  if (swift_getEnumCaseMultiPayload(v102, v141) != 1)
  {
    uint64_t v111 = type metadata accessor for MLHandActionClassifier.ModelParameters.ValidationData;
LABEL_33:
    outlined destroy of MLHandActionClassifier.DataSource(v102, v111);
    goto LABEL_34;
  }
  if (swift_getEnumCaseMultiPayload(v102, v154) != 3)
  {
    uint64_t v111 = type metadata accessor for MLHandActionClassifier.DataSource;
    goto LABEL_33;
  }
  uint64_t v103 = *(char **)v102;
  int v104 = *(_DWORD *)(v102 + 8);
  uint64_t v158 = *(void *)(v102 + 16);
  uint64_t v154 = *(void **)(v102 + 24);
  uint64_t v162 = *(void *)(v102 + 32);
  uint64_t v168 = *(uint64_t **)(v102 + 40);
  v161 = *(unsigned char **)(v102 + 48);
  uint64_t v157 = *(void **)(v102 + 56);
  uint64_t v105 = v142;
  swift_beginAccess(v142, &v151, 1, 0);
  uint64_t v155 = *(int **)v105;
  *(void *)uint64_t v105 = v103;
  int v106 = *(_DWORD *)(v105 + 8);
  *(unsigned char *)(v105 + 8) = v104 & 1;
  v166 = v103;
  uint64_t v107 = (uint64_t)v103;
  int v108 = v104;
  outlined copy of Result<_DataTable, Error>(v107, v104);
  outlined consume of Result<_DataTable, Error>((uint64_t)v155, v106);
  swift_beginAccess(v105, &v143, 33, 0);
  double v109 = v161;
  uint64_t v110 = v169;
  static MLHandActionClassifier.reformatKeypointsDataTable(table:featureColumn:)((unsigned char *)v105, (uint64_t)v161, v157, *(double *)v43.i64);
  if (v110)
  {
    swift_endAccess(&v143);
    swift_bridgeObjectRelease((_BYTE)v154);
    swift_bridgeObjectRelease((_BYTE)v168);
    swift_bridgeObjectRelease((_BYTE)v157);
    outlined consume of Result<_DataTable, Error>((uint64_t)v166, v108);
    outlined destroy of MLHandActionClassifier.DataSource(v167, type metadata accessor for MLTrainingSessionParameters);
    outlined destroy of MLHandActionClassifier.DataSource(v164, type metadata accessor for MLHandActionClassifier.ModelParameters);
    outlined destroy of MLHandActionClassifier.DataSource(v160, type metadata accessor for MLHandActionClassifier.DataSource);
    uint64_t v67 = v165;
    goto LABEL_30;
  }
  LODWORD(v169) = v108;
  swift_endAccess(&v143);
  swift_beginAccess(v105, &v143, 33, 0);
  char v131 = (char)v168;
  static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(v105, v158, v154, v109, v157, v162, v168);
  uint64_t v67 = v165;
  swift_endAccess(&v143);
  swift_bridgeObjectRelease((_BYTE)v154);
  swift_bridgeObjectRelease(v131);
  swift_bridgeObjectRelease((_BYTE)v157);
  outlined consume of Result<_DataTable, Error>((uint64_t)v166, v169);
  uint64_t v116 = v167;
  uint64_t v97 = v150;
LABEL_35:
  outlined init with copy of MLTrainingSessionParameters(v116, v67 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  uint64_t v117 = *(void *)(v67 + v97);
  if (v117)
  {
    uint64_t v169 = *(void *)(v164 + *(int *)(v145 + 28));
    uint64_t v118 = type metadata accessor for MLHandActionClassifier.GraphCNN(0);
    swift_allocObject(v118, *(unsigned int *)(v118 + 48), *(unsigned __int16 *)(v118 + 52));
    swift_bridgeObjectRetain(v117);
    uint64_t v119 = MLHandActionClassifier.GraphCNN.init(classLabels:export:numOfKeypoints:numOfKeypointsChannels:windowSize:)(v117, 0, 21, 3, v169);
    outlined destroy of MLHandActionClassifier.DataSource(v167, type metadata accessor for MLTrainingSessionParameters);
    outlined destroy of MLHandActionClassifier.DataSource(v164, type metadata accessor for MLHandActionClassifier.ModelParameters);
    outlined destroy of MLHandActionClassifier.DataSource(v160, type metadata accessor for MLHandActionClassifier.DataSource);
    *(void *)(v67 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_model) = v119;
    swift_release();
    return v67;
  }
  uint64_t v120 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v121 = swift_allocError(&type metadata for MLCreateError, v120, 0, 0);
  *(void *)uint64_t v122 = 0xD00000000000003DLL;
  *(void *)(v122 + 8) = "ng a feature checkpoint." + 0x8000000000000000;
  *(_OWORD *)(v122 + 16) = 0;
  *(_OWORD *)(v122 + 32) = 0;
  *(unsigned char *)(v122 + 48) = 0;
  uint64_t v169 = v121;
  swift_willThrow(&type metadata for MLCreateError, v120, v122, v123, v124, v125);
  char v58 = 1;
LABEL_13:
  uint64_t v77 = v164;
  outlined destroy of MLHandActionClassifier.DataSource(v167, type metadata accessor for MLTrainingSessionParameters);
  outlined destroy of MLHandActionClassifier.DataSource(v77, type metadata accessor for MLHandActionClassifier.ModelParameters);
  outlined destroy of MLHandActionClassifier.DataSource(v160, type metadata accessor for MLHandActionClassifier.DataSource);
  if (!v58) {
    goto LABEL_30;
  }
  swift_release();
  return v67;
}

char HandActionClassifierTrainingSessionDelegate.populateSourceTable(parameters:)(__m128 a1)
{
  type metadata accessor for MLHandActionClassifier.PersistentParameters(0);
  char result = MLHandActionClassifier.ModelParameters.ValidationData.extractAnnotations(trainingData:)(&v29, &v27, a1);
  if (!v1)
  {
    uint64_t v35 = v2;
    uint64_t v39 = v29;
    unsigned __int8 v4 = v30;
    uint64_t v5 = v27;
    char v6 = v30;
    int v40 = v28;
    uint64_t v31 = 0;
    if (v30 == 0xFF)
    {
      if (v28 != 0xFF)
      {
        int v41 = v30;
        uint64_t v15 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable;
        uint64_t v16 = v35;
        unsigned __int8 v17 = v28;
        swift_beginAccess(v35 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable, &v29, 1, 0);
        uint64_t v37 = *(void *)(v16 + v15);
        *(void *)(v16 + v15) = v5;
        int v38 = *(_DWORD *)(v16 + v15 + 8);
        *(unsigned char *)(v16 + v15 + 8) = v17;
        char v18 = v17 & 1;
        outlined copy of Result<_DataTable, Error>(v5, v18);
        outlined consume of MLDataTable?(v37, v38);
        *(void *)(v16 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTrainingRowCount) = 0;
LABEL_13:
        uint64_t v32 = v5;
        char v33 = v18 != 0;
        Swift::Int v26 = MLDataTable.size.getter();
        outlined consume of MLDataTable?(v39, v41);
        outlined consume of MLDataTable?(v5, v40);
LABEL_16:
        char result = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceValidationRowCount;
        *(void *)(v16 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceValidationRowCount) = v26;
        return result;
      }
      uint64_t v16 = v35;
      *(void *)(v35 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTrainingRowCount) = 0;
LABEL_15:
      outlined consume of MLDataTable?(v39, v6);
      Swift::Int v26 = 0;
      goto LABEL_16;
    }
    uint64_t v37 = v27;
    int v41 = v30;
    char v7 = v30 & 1;
    uint64_t v8 = v35 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable;
    unsigned __int8 v42 = v28;
    LOBYTE(v38) = v30 & 1;
    if (v28 == 0xFF)
    {
      char v19 = v7 != 0;
      swift_beginAccess(v35 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable, &v29, 1, 0);
      uint64_t v20 = *(void *)v8;
      uint64_t v21 = v39;
      *(void *)uint64_t v8 = v39;
      LODWORD(v36) = *(_DWORD *)(v8 + 8);
      *(unsigned char *)(v8 + 8) = v4;
      uint64_t v10 = v21;
      outlined copy of MLDataTable?(v21, v41);
      outlined copy of Result<_DataTable, Error>(v10, v19);
      outlined consume of MLDataTable?(v20, v36);
    }
    else
    {
      swift_beginAccess(v35 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable, &v27, 1, 0);
      uint64_t v36 = *(void *)v8;
      uint64_t v9 = v39;
      *(void *)uint64_t v8 = v39;
      LODWORD(v34) = *(_DWORD *)(v8 + 8);
      *(unsigned char *)(v8 + 8) = v7;
      uint64_t v10 = v9;
      outlined copy of Result<_DataTable, Error>(v9, v7 != 0);
      outlined copy of MLDataTable?(v9, v41);
      outlined copy of MLDataTable?(v37, v40);
      outlined consume of MLDataTable?(v36, (char)v34);
      int64_t v11 = HandActionClassifierTrainingSessionDelegate.sourceTable.modify((uint64_t)&v29);
      if (*(unsigned char *)(v12 + 8) != 0xFF)
      {
        LODWORD(v36) = v7 != 0;
        uint64_t v13 = v37;
        uint64_t v32 = v37;
        unsigned __int8 v14 = v42;
        uint64_t v34 = v11;
        char v33 = v42 & 1;
        MLDataTable.append(contentsOf:)((uint64_t)&v32);
        ((void (*)(uint64_t *, void))v34)(&v29, 0);
        outlined consume of MLDataTable?(v9, v41);
        outlined consume of MLDataTable?(v13, v40);
        outlined copy of Result<_DataTable, Error>(v9, v36);
        goto LABEL_11;
      }
      ((void (*)(uint64_t *, void))v11)(&v29, 0);
      outlined consume of MLDataTable?(v39, v41);
      outlined consume of MLDataTable?(v37, v40);
      uint64_t v10 = v39;
      outlined copy of Result<_DataTable, Error>(v39, v7 != 0);
    }
    unsigned __int8 v14 = v42;
LABEL_11:
    uint64_t v32 = v10;
    char v33 = (_BYTE)v38 != 0;
    uint64_t v22 = v10;
    Swift::Int v23 = MLDataTable.size.getter();
    char v24 = v41;
    outlined consume of MLDataTable?(v22, v41);
    uint64_t v25 = v35;
    *(void *)(v35 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTrainingRowCount) = v23;
    uint64_t v16 = v25;
    char v6 = v24;
    if (v14 != 0xFF)
    {
      char v18 = v14 & 1;
      uint64_t v5 = v37;
      goto LABEL_13;
    }
    goto LABEL_15;
  }
  return result;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> HandActionClassifierTrainingSessionDelegate.setUp()()
{
  uint64_t v12 = v0;
  int64_t v2 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  uint64_t v3 = alloca(v2);
  unsigned __int8 v4 = alloca(v2);
  uint64_t v5 = type metadata accessor for MLHandActionClassifier.PersistentParameters(0);
  int64_t v6 = *(void *)(*(void *)(v5 - 8) + 64);
  char v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v9 = v0 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v0 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters, v11, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v9, (uint64_t)&v10, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v10, 1, v5) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v10, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
    BUG();
  }
  outlined init with take of MLClassifierMetrics((uint64_t)&v10, (uint64_t)&v10, type metadata accessor for MLHandActionClassifier.PersistentParameters);
  HandActionClassifierTrainingSessionDelegate.populateSourceTable(parameters:)(v1);
  outlined destroy of MLHandActionClassifier.DataSource((uint64_t)&v10, type metadata accessor for MLHandActionClassifier.PersistentParameters);
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> HandActionClassifierTrainingSessionDelegate.resume(from:)(Swift::OpaquePointer from)
{
  uint64_t v166 = v1;
  uint64_t v181 = v2;
  uint64_t rawValue = (uint64_t)from._rawValue;
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for URL(0) - 8) + 64);
  int64_t v6 = alloca(v5);
  char v7 = alloca(v5);
  uint64_t v173 = &v128;
  uint64_t v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v171 = &v128;
  uint64_t v10 = alloca(v5);
  int64_t v11 = alloca(v5);
  v170 = &v128;
  uint64_t v12 = alloca(v5);
  uint64_t v13 = alloca(v5);
  uint64_t v167 = &v128;
  int64_t v14 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                              - 8)
                  + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v168 = &v128;
  unsigned __int8 v17 = alloca(v14);
  char v18 = alloca(v14);
  uint64_t v183 = (uint64_t)&v128;
  uint64_t v184 = type metadata accessor for MLCheckpoint(0);
  uint64_t v169 = *(void *)(v184 - 8);
  int64_t v19 = *(void *)(v169 + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  v182 = &v128;
  uint64_t v22 = alloca(v19);
  Swift::Int v23 = alloca(v19);
  uint64_t v176 = &v128;
  char v24 = alloca(v19);
  uint64_t v25 = alloca(v19);
  uint64_t v189 = &v128;
  Swift::Int v26 = alloca(v19);
  uint64_t v27 = alloca(v19);
  uint64_t v185 = &v128;
  int64_t v28 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  uint64_t v29 = alloca(v28);
  unsigned __int8 v30 = alloca(v28);
  uint64_t v31 = type metadata accessor for MLHandActionClassifier.PersistentParameters(0);
  int64_t v32 = *(void *)(*(void *)(v31 - 8) + 64);
  char v33 = alloca(v32);
  uint64_t v34 = alloca(v32);
  uint64_t v35 = v181 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v181 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters, v162, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v35, (uint64_t)&v128, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
  uint64_t v172 = v31;
  if (__swift_getEnumTagSinglePayload((uint64_t)&v128, 1, v31) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v128, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
    BUG();
  }
  outlined init with take of MLClassifierMetrics((uint64_t)&v128, (uint64_t)&v128, type metadata accessor for MLHandActionClassifier.PersistentParameters);
  uint64_t v36 = v183;
  specialized BidirectionalCollection.last.getter(rawValue);
  uint64_t v37 = v184;
  if (__swift_getEnumTagSinglePayload(v36, 1, v184) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v183, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v38 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v38, 0, 0);
    *(void *)uint64_t v39 = 0xD00000000000001DLL;
    *(void *)(v39 + 8) = "reated." + 0x8000000000000000;
    *(_OWORD *)(v39 + 16) = 0;
    *(_OWORD *)(v39 + 32) = 0;
    *(unsigned char *)(v39 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v38, v39, v40, v41, v42);
    __m128 v43 = &v128;
    goto LABEL_69;
  }
  v188 = &v128;
  unint64_t v44 = 0xEB0000000064657ALL;
  uint64_t v175 = 0x6974636172747865;
  uint64_t v45 = 0x696C616974696E69;
  uint64_t v46 = (uint64_t)v185;
  outlined init with take of MLClassifierMetrics(v183, (uint64_t)v185, type metadata accessor for MLCheckpoint);
  uint64_t v183 = *(int *)(v37 + 20);
  switch(*(unsigned char *)(v46 + v183))
  {
    case 0:
      goto LABEL_9;
    case 1:
      swift_bridgeObjectRelease(110);
      uint64_t v47 = (uint64_t)v189;
      outlined init with copy of MLTrainingSessionParameters((uint64_t)v185, (uint64_t)v189, type metadata accessor for MLCheckpoint);
      goto LABEL_10;
    case 2:
      uint64_t v45 = 0x676E696E69617274;
      unint64_t v44 = 0xE800000000000000;
      goto LABEL_9;
    case 3:
      uint64_t v45 = 0x697461756C617665;
      unint64_t v44 = 0xEA0000000000676ELL;
      goto LABEL_9;
    case 4:
      uint64_t v45 = 0x636E657265666E69;
      unint64_t v44 = 0xEB00000000676E69;
LABEL_9:
      char v48 = _stringCompareWithSmolCheck(_:_:expecting:)(v45, v44, 0x6974636172747865, 0xEA0000000000676ELL, 0);
      swift_bridgeObjectRelease(v44);
      uint64_t v47 = (uint64_t)v189;
      outlined init with copy of MLTrainingSessionParameters((uint64_t)v185, (uint64_t)v189, type metadata accessor for MLCheckpoint);
      if ((v48 & 1) == 0)
      {
        switch(*(unsigned char *)(v47 + *(int *)(v184 + 20)))
        {
          case 0:
            uint64_t v51 = 0x696C616974696E69;
            unint64_t v52 = 0xEB0000000064657ALL;
            goto LABEL_20;
          case 1:
            uint64_t v51 = 0x6974636172747865;
            goto LABEL_19;
          case 2:
            swift_bridgeObjectRelease(0);
            break;
          case 3:
            uint64_t v51 = 0x697461756C617665;
LABEL_19:
            unint64_t v52 = 0xEA0000000000676ELL;
LABEL_20:
            _stringCompareWithSmolCheck(_:_:expecting:)(v51, v52, 0x676E696E69617274, 0xE800000000000000, 0);
            swift_bridgeObjectRelease(v52);
            JUMPOUT(0x2755FBLL);
          case 4:
            JUMPOUT(0x27558ALL);
        }
      }
LABEL_10:
      outlined destroy of MLHandActionClassifier.DataSource(v47, type metadata accessor for MLCheckpoint);
      uint64_t v49 = (uint64_t)v188;
      uint64_t v50 = v166;
      HandActionClassifierTrainingSessionDelegate.populateSourceTable(parameters:)(v3);
      if (v50)
      {
        outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v185, type metadata accessor for MLCheckpoint);
        __m128 v43 = (uint64_t *)v49;
        goto LABEL_69;
      }
      uint64_t v53 = 0x676E696E69617274;
      uint64_t v54 = (uint64_t)v185;
      uint64_t v55 = *((unsigned __int8 *)v185 + v183);
      uint64_t v189 = 0;
      switch(v55)
      {
        case 0:
          unint64_t v56 = 0xEB0000000064657ALL;
          uint64_t v53 = 0x696C616974696E69;
          goto LABEL_26;
        case 1:
          swift_bridgeObjectRelease(110);
          goto LABEL_27;
        case 2:
          unint64_t v56 = 0xE800000000000000;
          goto LABEL_26;
        case 3:
          uint64_t v53 = 0x697461756C617665;
          unint64_t v56 = 0xEA0000000000676ELL;
          goto LABEL_26;
        case 4:
          uint64_t v53 = 0x636E657265666E69;
          unint64_t v56 = 0xEB00000000676E69;
LABEL_26:
          char v57 = _stringCompareWithSmolCheck(_:_:expecting:)(v53, v56, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v56);
          uint64_t v58 = (uint64_t)v176;
          if (v57)
          {
LABEL_27:
            uint64_t v59 = v167;
            URL.appendingPathComponent(_:)(0x676E696E69617274, 0xE800000000000000);
            char v186 = 1;
            LOBYTE(v145) = 1;
            uint64_t v146 = 44;
            unint64_t v147 = 0xE100000000000000;
            uint64_t v148 = 0;
            unint64_t v149 = 0xE000000000000000;
            uint64_t v150 = 92;
            unint64_t v151 = 0xE100000000000000;
            char v152 = 1;
            uint64_t v153 = 34;
            unint64_t v154 = 0xE100000000000000;
            char v155 = 1;
            uint64_t v156 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
            uint64_t v157 = 10;
            unint64_t v158 = 0xE100000000000000;
            long long v159 = 0;
            char v160 = 1;
            uint64_t v161 = 0;
            uint64_t v60 = (uint64_t)v189;
            MLDataTable.init(contentsOf:options:)(v59, &v145);
            if (v60)
            {
              uint64_t v61 = v54;
            }
            else
            {
              v182 = v177;
              LOBYTE(v184) = v178;
              uint64_t v72 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures;
              uint64_t v189 = 0;
              uint64_t v73 = v181;
              swift_beginAccess(v181 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures, v163, 1, 0);
              uint64_t v74 = *(void *)(v73 + v72);
              *(void *)(v73 + v72) = v182;
              int v75 = *(_DWORD *)(v73 + v72 + 8);
              *(unsigned char *)(v73 + v72 + 8) = v184;
              outlined consume of Result<_DataTable, Error>(v74, v75);
              char v76 = v170;
              URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEA00000000006E6FLL);
              LOBYTE(v128) = 1;
              uint64_t v129 = 44;
              char v130 = (uint64_t *)0xE100000000000000;
              uint64_t v131 = 0;
              char v187 = 1;
              unint64_t v132 = 0xE000000000000000;
              uint64_t v133 = 92;
              unint64_t v134 = 0xE100000000000000;
              char v135 = 1;
              uint64_t v136 = 34;
              unint64_t v137 = 0xE100000000000000;
              char v138 = 1;
              uint64_t v139 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
              uint64_t v140 = 10;
              unint64_t v141 = 0xE100000000000000;
              v3.i64[0] = 0;
              long long v142 = 0;
              char v143 = 1;
              uint64_t v144 = 0;
              uint64_t v77 = (uint64_t)v189;
              MLDataTable.init(contentsOf:options:)(v76, &v128);
              uint64_t v189 = (uint64_t *)v77;
              if (!v77)
              {
                uint64_t v78 = v179;
                LOBYTE(v184) = v180;
                uint64_t v79 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures;
                swift_beginAccess(v73 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures, v164, 1, 0);
                uint64_t v80 = *(void *)(v73 + v79);
                *(void *)(v73 + v79) = v78;
                int v81 = *(_DWORD *)(v73 + v79 + 8);
                *(unsigned char *)(v73 + v79 + 8) = v184;
                outlined consume of Result<_DataTable, Error>(v80, v81);
                uint64_t v82 = (uint64_t)v188;
                unint64_t v83 = 0xEA0000000000676ELL;
                switch(*(unsigned char *)(v54 + v183))
                {
                  case 0:
                    goto LABEL_49;
                  case 1:
                    goto LABEL_59;
                  case 2:
                    goto LABEL_56;
                  case 3:
                    goto LABEL_57;
                  case 4:
                    goto LABEL_58;
                }
              }
              uint64_t v61 = v54;
            }
            goto LABEL_29;
          }
          uint64_t v145 = rawValue;
          uint64_t v62 = *(void *)(rawValue + 16);
          char v63 = 1;
          if (!v62)
          {
            uint64_t v64 = 0;
            goto LABEL_46;
          }
          uint64_t v64 = v62 - 1;
          uint64_t v65 = v64 * *(void *)(v169 + 72)
              + ((*(unsigned __int8 *)(v169 + 80) + 32) & ~*(unsigned __int8 *)(v169 + 80))
              + rawValue;
          uint64_t rawValue = -*(void *)(v169 + 72);
          break;
      }
      break;
  }
  while (2)
  {
    uint64_t v66 = (uint64_t)v182;
    outlined init with copy of MLTrainingSessionParameters(v65, (uint64_t)v182, type metadata accessor for MLCheckpoint);
    switch(*(unsigned char *)(v66 + *(int *)(v184 + 20)))
    {
      case 0:
        JUMPOUT(0x275861);
      case 1:
        swift_bridgeObjectRelease(110);
        outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v182, type metadata accessor for MLCheckpoint);
        char v63 = 0;
        goto LABEL_46;
      case 2:
        uint64_t v67 = v65;
        unint64_t v68 = 0xE800000000000000;
        uint64_t v69 = 0x676E696E69617274;
        goto LABEL_37;
      case 3:
        uint64_t v67 = v65;
        unint64_t v68 = 0xEA0000000000676ELL;
        uint64_t v69 = 0x697461756C617665;
        goto LABEL_37;
      case 4:
        uint64_t v67 = v65;
        unint64_t v68 = 0xEB00000000676E69;
        uint64_t v69 = 0x636E657265666E69;
LABEL_37:
        char v70 = _stringCompareWithSmolCheck(_:_:expecting:)(v69, v68, 0x6974636172747865, 0xEA0000000000676ELL, 0);
        swift_bridgeObjectRelease(v68);
        outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v182, type metadata accessor for MLCheckpoint);
        if ((v70 & 1) == 0)
        {
          uint64_t v65 = rawValue + v67;
          BOOL v71 = v64-- != 0;
          uint64_t v58 = (uint64_t)v176;
          if (!v71)
          {
            uint64_t v64 = 0;
            char v63 = 1;
            goto LABEL_46;
          }
          continue;
        }
        char v63 = 0;
        uint64_t v58 = (uint64_t)v176;
LABEL_46:
        char v84 = alloca(24);
        uint64_t v85 = alloca(32);
        char v130 = &v145;
        uint64_t v86 = (uint64_t)v168;
        uint64_t v87 = (uint64_t)v189;
        _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))partial apply for specialized closure #1 in BidirectionalCollection.last(where:), (uint64_t)&v128, v64, v63, (uint64_t)v165);
        int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v86, 1, v184);
        uint64_t v189 = (uint64_t *)v87;
        if (EnumTagSinglePayload == 1)
        {
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v86, &demangling cache variable for type metadata for MLCheckpoint?);
          uint64_t v89 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures;
          uint64_t v90 = v181;
          swift_beginAccess(v181 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures, &v145, 0, 0);
          char v91 = *(unsigned char *)(v90 + v89 + 8);
          uint64_t v128 = *(void *)(v90 + v89);
          LOBYTE(v129) = v91;
          if (MLDataTable.size.getter())
          {
            uint64_t v82 = (uint64_t)v188;
            unint64_t v83 = 0xEA0000000000676ELL;
            switch(*((unsigned char *)v185 + v183))
            {
              case 0:
                goto LABEL_49;
              case 1:
                goto LABEL_59;
              case 2:
                goto LABEL_56;
              case 3:
                goto LABEL_57;
              case 4:
                goto LABEL_58;
            }
          }
          uint64_t v94 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          swift_allocError(&type metadata for MLCreateError, v94, 0, 0);
          *(void *)uint64_t v95 = 0xD000000000000028;
          uint64_t v99 = "erly initialized.";
LABEL_66:
          *(void *)(v95 + 8) = (unint64_t)v99 | 0x8000000000000000;
          *(_OWORD *)(v95 + 16) = 0;
          *(_OWORD *)(v95 + 32) = 0;
          *(unsigned char *)(v95 + 48) = 0;
          swift_willThrow(&type metadata for MLCreateError, v94, v95, v96, v97, v98);
          uint64_t v61 = (uint64_t)v185;
LABEL_29:
          outlined destroy of MLHandActionClassifier.DataSource(v61, type metadata accessor for MLCheckpoint);
          __m128 v43 = v188;
LABEL_69:
          outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v43, type metadata accessor for MLHandActionClassifier.PersistentParameters);
        }
        else
        {
          outlined init with take of MLClassifierMetrics(v86, v58, type metadata accessor for MLCheckpoint);
          uint64_t v92 = v171;
          URL.appendingPathComponent(_:)(0x676E696E69617274, 0xE800000000000000);
          char v186 = 1;
          LOBYTE(v145) = 1;
          uint64_t v146 = 44;
          unint64_t v147 = 0xE100000000000000;
          uint64_t v148 = 0;
          unint64_t v149 = 0xE000000000000000;
          uint64_t v150 = 92;
          unint64_t v151 = 0xE100000000000000;
          char v152 = 1;
          uint64_t v153 = 34;
          unint64_t v154 = 0xE100000000000000;
          char v155 = 1;
          uint64_t v156 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
          uint64_t v157 = 10;
          unint64_t v158 = 0xE100000000000000;
          long long v159 = 0;
          char v160 = 1;
          uint64_t v161 = 0;
          uint64_t v93 = (uint64_t)v189;
          MLDataTable.init(contentsOf:options:)(v92, &v145);
          if (!v93)
          {
            v182 = v177;
            LOBYTE(v184) = v178;
            uint64_t v189 = 0;
            uint64_t v100 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures;
            uint64_t v101 = v181;
            swift_beginAccess(v181 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures, v163, 1, 0);
            uint64_t v102 = *(void *)(v101 + v100);
            *(void *)(v101 + v100) = v182;
            int v103 = *(_DWORD *)(v101 + v100 + 8);
            *(unsigned char *)(v101 + v100 + 8) = v184;
            outlined consume of Result<_DataTable, Error>(v102, v103);
            int v104 = v173;
            URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEA00000000006E6FLL);
            LOBYTE(v128) = 1;
            uint64_t v129 = 44;
            char v130 = (uint64_t *)0xE100000000000000;
            uint64_t v131 = 0;
            char v187 = 1;
            unint64_t v132 = 0xE000000000000000;
            uint64_t v133 = 92;
            unint64_t v134 = 0xE100000000000000;
            char v135 = 1;
            uint64_t v136 = 34;
            unint64_t v137 = 0xE100000000000000;
            char v138 = 1;
            uint64_t v139 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
            uint64_t v140 = 10;
            unint64_t v141 = 0xE100000000000000;
            v3.i64[0] = 0;
            long long v142 = 0;
            char v143 = 1;
            uint64_t v144 = 0;
            uint64_t v105 = (uint64_t)v189;
            MLDataTable.init(contentsOf:options:)(v104, &v128);
            uint64_t v189 = (uint64_t *)v105;
            if (v105)
            {
              outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v176, type metadata accessor for MLCheckpoint);
              uint64_t v61 = (uint64_t)v185;
              goto LABEL_29;
            }
            outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v176, type metadata accessor for MLCheckpoint);
            uint64_t v106 = v179;
            char v107 = v180;
            uint64_t v108 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures;
            swift_beginAccess(v101 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures, v164, 1, 0);
            uint64_t v109 = *(void *)(v101 + v108);
            *(void *)(v101 + v108) = v106;
            int v110 = *(_DWORD *)(v101 + v108 + 8);
            *(unsigned char *)(v101 + v108 + 8) = v107;
            unint64_t v83 = 0xEA0000000000676ELL;
            outlined consume of Result<_DataTable, Error>(v109, v110);
            uint64_t v82 = (uint64_t)v188;
            switch(*((unsigned char *)v185 + v183))
            {
              case 0:
LABEL_49:
                uint64_t v175 = 0x696C616974696E69;
                unint64_t v83 = 0xEB0000000064657ALL;
                goto LABEL_59;
              case 1:
                goto LABEL_59;
              case 2:
LABEL_56:
                swift_bridgeObjectRelease(0);
                goto LABEL_60;
              case 3:
LABEL_57:
                uint64_t v175 = 0x697461756C617665;
                goto LABEL_59;
              case 4:
LABEL_58:
                uint64_t v175 = 0x636E657265666E69;
                unint64_t v83 = 0xEB00000000676E69;
LABEL_59:
                char v111 = _stringCompareWithSmolCheck(_:_:expecting:)(v175, v83, 0x676E696E69617274, 0xE800000000000000, 0);
                swift_bridgeObjectRelease(v83);
                if ((v111 & 1) == 0) {
                  goto LABEL_68;
                }
LABEL_60:
                uint64_t v112 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures;
                uint64_t v113 = v181;
                swift_beginAccess(OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures + v181, &v128, 0, 0);
                uint64_t v114 = *(void *)(v113 + v112);
                LODWORD(v112) = *(unsigned __int8 *)(v113 + v112 + 8);
                outlined copy of Result<_DataTable, Error>(v114, v112);
                v115._uint64_t countAndFlagsBits = 0x6C6562616CLL;
                v115._char object = (void *)0xE500000000000000;
                specialized MLDataTable.subscript.getter(v115, v114, v112, v116, v117);
                outlined consume of Result<_DataTable, Error>(v114, v112);
                uint64_t v118 = v179;
                LOBYTE(v112) = v180;
                specialized MLDataColumn.dropDuplicates()(v179, v180);
                outlined consume of Result<_DataTable, Error>(v118, v112);
                uint64_t v119 = specialized Array<A>.init(_:)((uint64_t)v177, v178, *(double *)v3.i64);
                uint64_t v120 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_classLabels;
                v115._uint64_t countAndFlagsBits = *(void *)(v113
                                                    + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_classLabels);
                *(void *)(v113 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_classLabels) = v119;
                swift_bridgeObjectRelease(v115._countAndFlagsBits);
                uint64_t v121 = *(void *)(v113 + v120);
                if (!v121)
                {
                  uint64_t v94 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
                  swift_allocError(&type metadata for MLCreateError, v94, 0, 0);
                  *(void *)uint64_t v95 = 0xD00000000000002ELL;
                  uint64_t v99 = "re not properly constructed.";
                  goto LABEL_66;
                }
                uint64_t v122 = *(uint64_t *)((char *)v188 + *(int *)(v172 + 32));
                uint64_t v123 = type metadata accessor for MLHandActionClassifier.GraphCNN(0);
                swift_allocObject(v123, *(unsigned int *)(v123 + 48), *(unsigned __int16 *)(v123 + 52));
                swift_bridgeObjectRetain(v121);
                uint64_t v124 = MLHandActionClassifier.GraphCNN.init(classLabels:export:numOfKeypoints:numOfKeypointsChannels:windowSize:)(v121, 0, 21, 3, v122);
                uint64_t v125 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_model;
                *(void *)(v113 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_model) = v124;
                swift_release();
                if (!*(void *)(v113 + v125))
                {
                  uint64_t v94 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
                  swift_allocError(&type metadata for MLCreateError, v94, 0, 0);
                  *(void *)uint64_t v95 = 0xD000000000000031;
                  uint64_t v99 = "ning checkpoints are supported.";
                  goto LABEL_66;
                }
                swift_retain();
                uint64_t v126 = (uint64_t)v185;
                uint64_t v127 = (uint64_t)v189;
                MLHandActionClassifier.GraphCNN.updateGraphCNN(from:)((uint64_t)v185, *(double *)v3.i64, v4);
                uint64_t v189 = (uint64_t *)v127;
                if (v127)
                {
                  swift_release();
                  uint64_t v61 = v126;
                  goto LABEL_29;
                }
                MLHandActionClassifier.GraphCNN.initDevice()();
                swift_release();
                uint64_t v82 = (uint64_t)v188;
LABEL_68:
                outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v185, type metadata accessor for MLCheckpoint);
                __m128 v43 = (uint64_t *)v82;
                break;
            }
            goto LABEL_69;
          }
          outlined destroy of MLHandActionClassifier.DataSource(v58, type metadata accessor for MLCheckpoint);
          outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v185, type metadata accessor for MLCheckpoint);
          outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v188, type metadata accessor for MLHandActionClassifier.PersistentParameters);
        }
        return;
    }
  }
}

Swift::Int_optional __swiftcall HandActionClassifierTrainingSessionDelegate.itemCount(phase:)(CreateML::MLPhase phase)
{
  switch(*(unsigned char *)phase)
  {
    case 0:
    case 3:
    case 4:
      char v2 = 1;
      Swift::Int v3 = 0;
      break;
    case 1:
      uint64_t v4 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable;
      int64_t v5 = (uint64_t *)(OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable + v1);
      Swift::Int v3 = 0;
      swift_beginAccess(OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable + v1, v9, 0, 0);
      char v6 = *(unsigned char *)(v1 + v4 + 8);
      if (v6 != -1)
      {
        uint64_t v10 = *v5;
        char v11 = v6 & 1;
        Swift::Int v3 = MLDataTable.size.getter();
      }
      char v2 = 0;
      break;
    case 2:
      uint64_t v7 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sessionParameters + v1;
      char v2 = 0;
      Swift::Int v3 = *(void *)(*(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 28) + v7);
      break;
  }
  v8.value = v3;
  v8.is_nil = v2;
  return v8;
}

Swift::tuple_Int_finished_Bool __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> HandActionClassifierTrainingSessionDelegate.extractFeatures(from:)(Swift::Int from)
{
  uint64_t v55 = v1;
  Swift::Int v46 = from;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  uint64_t v6 = type metadata accessor for MLHandActionClassifier.PersistentParameters(0);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  Swift::Int_optional v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v54 = &v38;
  uint64_t v10 = v2 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v2 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters, v39, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, (uint64_t)&v38, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
  uint64_t v49 = v6;
  if (__swift_getEnumTagSinglePayload((uint64_t)&v38, 1, v6) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v38, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
    BUG();
  }
  uint64_t v11 = (uint64_t)v54;
  outlined init with take of MLClassifierMetrics((uint64_t)&v38, (uint64_t)v54, type metadata accessor for MLHandActionClassifier.PersistentParameters);
  uint64_t v12 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable;
  swift_beginAccess(OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable + v2, v40, 0, 0);
  unsigned __int8 v13 = *(unsigned char *)(v2 + v12 + 8);
  if (v13 == 0xFF)
  {
    outlined destroy of MLHandActionClassifier.DataSource(v11, type metadata accessor for MLHandActionClassifier.PersistentParameters);
LABEL_11:
    v26.finished = 1;
    v26._0 = 1;
    return v26;
  }
  uint64_t v14 = *(void *)(v2 + v12);
  uint64_t v44 = v14;
  int v15 = v13;
  char v16 = v13 & 1;
  char v45 = v16;
  int v56 = v15;
  outlined copy of Result<_DataTable, Error>(v14, v15);
  MLDataTable.size.getter();
  if (v17 <= 0)
  {
    outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v54, type metadata accessor for MLHandActionClassifier.PersistentParameters);
    outlined consume of MLDataTable?(v14, v56);
    goto LABEL_11;
  }
  uint64_t v53 = v14;
  uint64_t v18 = *(void *)(v2 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTrainingRowCount);
  uint64_t v50 = v2;
  uint64_t v19 = *(void *)(v2 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceValidationRowCount);
  BOOL v24 = __OFADD__(v18, v19);
  uint64_t v20 = v18 + v19;
  if (v24) {
    BUG();
  }
  uint64_t v21 = v46;
  if (v20 <= v46)
  {
    outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v54, type metadata accessor for MLHandActionClassifier.PersistentParameters);
    outlined consume of MLDataTable?(v53, v56);
    v26.finished = 1;
    v26._0 = 0;
  }
  else
  {
    uint64_t v42 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceValidationRowCount;
    uint64_t v41 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTrainingRowCount;
    uint64_t v22 = v50 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sessionParameters;
    uint64_t v47 = v18;
    uint64_t v23 = *(void *)(*(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 20) + v22);
    BOOL v24 = __OFADD__(v21, v23);
    uint64_t v25 = v21 + v23;
    if (v47 <= v21)
    {
      if (v24) {
        BUG();
      }
    }
    else
    {
      uint64_t v20 = v47;
      if (v24) {
        BUG();
      }
    }
    if (v20 < v25) {
      uint64_t v25 = v20;
    }
    if (v25 < v21) {
      BUG();
    }
    uint64_t v51 = v53;
    char v52 = v16;
    uint64_t v43 = v25;
    MLDataTable.subscript.getter(v21, v25);
    uint64_t v27 = v44;
    char v28 = v45;
    type metadata accessor for MLHandActionClassifier.FeatureExtractor();
    uint64_t v48 = v27;
    uint64_t v51 = v27;
    char v52 = v28;
    uint64_t v29 = (uint64_t)v54;
    uint64_t v30 = v55;
    static MLHandActionClassifier.FeatureExtractor.extractFeatures(from:targetFrameRate:startingSessionId:)((uint64_t)&v51, v21, *(double *)((char *)v54 + *(int *)(v49 + 36)));
    uint64_t v31 = v21;
    if (v30)
    {
      outlined destroy of MLHandActionClassifier.DataSource(v29, type metadata accessor for MLHandActionClassifier.PersistentParameters);
      outlined consume of MLDataTable?(v53, v56);
      v26._0 = outlined consume of Result<_DataTable, Error>(v48, v28);
    }
    else
    {
      char v32 = v28;
      uint64_t v33 = v48;
      uint64_t v55 = 0;
      char v34 = v45;
      uint64_t v49 = v44;
      uint64_t v51 = v44;
      char v52 = v45 & 1;
      if (v47 <= v31) {
        uint64_t v35 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures;
      }
      else {
        uint64_t v35 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures;
      }
      swift_beginAccess(v50 + v35, &v44, 33, 0);
      MLDataTable.append(contentsOf:)((uint64_t)&v51);
      swift_endAccess(&v44);
      outlined consume of Result<_DataTable, Error>(v33, v32);
      outlined consume of MLDataTable?(v53, v56);
      outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v54, type metadata accessor for MLHandActionClassifier.PersistentParameters);
      outlined consume of Result<_DataTable, Error>(v49, v34);
      v26._0 = v43 - v46;
      if (__OFSUB__(v43, v46)) {
        BUG();
      }
      uint64_t v36 = *(void *)(v50 + v41);
      BOOL v24 = __OFADD__(*(void *)(v50 + v42), v36);
      uint64_t v37 = *(void *)(v50 + v42) + v36;
      if (v24) {
        BUG();
      }
      v26.finished = v43 == v37;
    }
  }
  return v26;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> HandActionClassifierTrainingSessionDelegate.transitionTo(phase:)(CreateML::MLPhase phase)
{
  uint64_t v4 = v2;
  uint64_t v53 = type metadata accessor for MLHandActionClassifier.ModelParameters(0);
  int64_t v5 = *(void *)(*(void *)(v53 - 8) + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v54 = &v46;
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v11 = type metadata accessor for MLHandActionClassifier.PersistentParameters(0);
  int64_t v12 = *(void *)(*(void *)(v11 - 8) + 64);
  unsigned __int8 v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  if (*(unsigned char *)phase != 2) {
    return;
  }
  uint64_t v59 = &v46;
  uint64_t v56 = v1;
  uint64_t v15 = v2 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters;
  uint64_t v16 = v11;
  swift_beginAccess(v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters, v47, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v15, (uint64_t)&v46, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
  uint64_t v55 = (int *)v16;
  if (__swift_getEnumTagSinglePayload((uint64_t)&v46, 1, v16) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v46, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
    BUG();
  }
  outlined init with take of MLClassifierMetrics((uint64_t)&v46, (uint64_t)v59, type metadata accessor for MLHandActionClassifier.PersistentParameters);
  uint64_t v17 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures;
  swift_beginAccess(v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures, v48, 0, 0);
  uint64_t v18 = *(void *)(v4 + v17);
  unsigned int v19 = *(unsigned __int8 *)(v4 + v17 + 8);
  outlined copy of Result<_DataTable, Error>(v18, *(unsigned char *)(v4 + v17 + 8));
  v20._uint64_t countAndFlagsBits = 0x6C6562616CLL;
  v20._char object = (void *)0xE500000000000000;
  specialized MLDataTable.subscript.getter(v20, v18, v19, v21, v22);
  outlined consume of Result<_DataTable, Error>(v18, v19);
  uint64_t v23 = v51;
  LOBYTE(v17) = v52;
  specialized MLDataColumn.dropDuplicates()(v51, v52);
  outlined consume of Result<_DataTable, Error>(v23, v17);
  BOOL v24 = specialized Array<A>.init(_:)(v49, v50, v3);
  uint64_t v25 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_classLabels;
  v20._uint64_t countAndFlagsBits = *(void *)(v4
                                     + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_classLabels);
  *(void *)(v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_classLabels) = v24;
  swift_bridgeObjectRelease(v20._countAndFlagsBits);
  uint64_t v26 = *(void *)(v4 + v25);
  if (!v26)
  {
    uint64_t v40 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v40, 0, 0);
    *(void *)uint64_t v41 = 0xD00000000000002ELL;
    char v45 = "re not properly constructed.";
LABEL_10:
    *(void *)(v41 + 8) = (unint64_t)v45 | 0x8000000000000000;
    *(_OWORD *)(v41 + 16) = 0;
    *(_OWORD *)(v41 + 32) = 0;
    *(unsigned char *)(v41 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v40, v41, v42, v43, v44);
    outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v59, type metadata accessor for MLHandActionClassifier.PersistentParameters);
    return;
  }
  uint64_t v27 = v55;
  uint64_t v28 = *(uint64_t *)((char *)v59 + v55[8]);
  uint64_t v29 = type metadata accessor for MLHandActionClassifier.GraphCNN(0);
  uint64_t v58 = swift_allocObject(v29, *(unsigned int *)(v29 + 48), *(unsigned __int16 *)(v29 + 52));
  swift_bridgeObjectRetain_n(v26, 2);
  uint64_t v57 = v28;
  uint64_t v30 = MLHandActionClassifier.GraphCNN.init(classLabels:export:numOfKeypoints:numOfKeypointsChannels:windowSize:)(v26, 0, 21, 3, v28);
  uint64_t v31 = v26;
  uint64_t v32 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_model;
  *(void *)(v4 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_model) = v30;
  swift_release();
  if (!*(void *)(v4 + v32))
  {
    swift_bridgeObjectRelease(v31);
    uint64_t v40 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v40, 0, 0);
    *(void *)uint64_t v41 = 0xD00000000000003CLL;
    char v45 = "ve training parameters";
    goto LABEL_10;
  }
  uint64_t v58 = v31;
  uint64_t v33 = (uint64_t)v59;
  uint64_t v34 = (uint64_t)v54;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v59 + v27[5], (uint64_t)v54, type metadata accessor for MLHandActionClassifier.ModelParameters.ValidationData);
  uint64_t v35 = *(void *)(v33 + v27[7]);
  uint64_t v36 = *(void *)(v33 + v27[10]);
  uint64_t v37 = *(void *)(v33 + v27[9]);
  uint64_t v38 = (int *)v53;
  *(void *)(v34 + *(int *)(v53 + 20)) = *(void *)(v33 + v27[6]);
  *(void *)(v34 + v38[6]) = v35;
  *(void *)(v34 + v38[7]) = v57;
  *(void *)(v34 + v38[8]) = v36;
  *(void *)(v34 + v38[10]) = v37;
  swift_retain();
  outlined destroy of MLHandActionClassifier.DataSource(v34, type metadata accessor for MLHandActionClassifier.ModelParameters);
  MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel()();
  if (!v39) {
    MLHandActionClassifier.GraphCNN.initDevice()();
  }
  outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v59, type metadata accessor for MLHandActionClassifier.PersistentParameters);
  swift_bridgeObjectRelease(v58);
  swift_release();
}

Swift::tuple_Int_metrics_OpaquePointer_finished_Bool __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> HandActionClassifierTrainingSessionDelegate.train(from:)(Swift::Int from)
{
  double v95 = v1;
  uint64_t v92 = type metadata accessor for Tensor(0);
  uint64_t v93 = *(void *)(v92 - 8);
  int64_t v4 = *(void *)(v93 + 64);
  int64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v94 = &v84;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?)
                             - 8)
                 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v100 = &v84;
  uint64_t v91 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
  uint64_t v90 = *(void *)(v91 - 8);
  int64_t v10 = *(void *)(v90 + 64);
  uint64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  uint64_t v101 = &v84;
  uint64_t v104 = type metadata accessor for MLHandActionClassifier.PersistentParameters(0);
  int64_t v13 = *(void *)(*(void *)(v104 - 8) + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v109 = &v84;
  int64_t v16 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  *(double *)&int v110 = COERCE_DOUBLE(type metadata accessor for MLHandActionClassifier.ModelParameters(0));
  int64_t v19 = *(void *)(*((void *)v110 - 1) + 64);
  Swift::String v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  uint64_t v103 = (uint64_t)&v84;
  uint64_t v22 = alloca(v19);
  uint64_t v23 = alloca(v19);
  uint64_t v102 = &v84;
  uint64_t v108 = v2;
  uint64_t v24 = v2 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sessionParameters;
  uint64_t v25 = type metadata accessor for MLTrainingSessionParameters(0);
  uint64_t v26 = *(int **)(*(int *)(v25 + 20) + v24);
  if (__OFADD__(v26, from)) {
    BUG();
  }
  Swift::Int v27 = *(void *)(v24 + *(int *)(v25 + 28));
  uint64_t v28 = v27 - from;
  if (__OFSUB__(v27, from)) {
    BUG();
  }
  double v105 = *(double *)&from;
  Swift::Int v89 = v27;
  Swift::Int v88 = (Swift::Int)v26 + from;
  if ((uint64_t)v26 < v28) {
    uint64_t v28 = (uint64_t)v26;
  }
  uint64_t v29 = v108;
  uint64_t v30 = v108 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v108 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters, v85, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v30, (uint64_t)&v84, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
  uint64_t v31 = v104;
  if (!__swift_getEnumTagSinglePayload((uint64_t)&v84, 1, v104))
  {
    uint64_t v96 = v28;
    uint64_t v28 = v31;
    uint64_t v38 = (uint64_t)v109;
    outlined init with copy of MLTrainingSessionParameters((uint64_t)&v84, (uint64_t)v109, type metadata accessor for MLHandActionClassifier.PersistentParameters);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v84, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
    uint64_t v39 = v103;
    outlined init with copy of MLTrainingSessionParameters(v38 + *(int *)(v28 + 20), v103, type metadata accessor for MLHandActionClassifier.ModelParameters.ValidationData);
    uint64_t v40 = *(void *)(v38 + *(int *)(v28 + 28));
    uint64_t v41 = *(void *)(v38 + *(int *)(v28 + 32));
    uint64_t v42 = *(void *)(v38 + *(int *)(v28 + 40));
    double v43 = *(double *)(v38 + *(int *)(v28 + 36));
    uint64_t v44 = v110;
    *(void *)(v39 + v110[5]) = *(void *)(v38 + *(int *)(v28 + 24));
    *(void *)(v39 + v44[6]) = v40;
    *(void *)(v39 + v44[7]) = v41;
    *(void *)(v39 + v44[8]) = v42;
    *(double *)(v39 + v44[10]) = v43;
    outlined destroy of MLHandActionClassifier.DataSource(v38, type metadata accessor for MLHandActionClassifier.PersistentParameters);
    uint64_t v31 = (uint64_t)v102;
    outlined init with take of MLClassifierMetrics(v39, (uint64_t)v102, type metadata accessor for MLHandActionClassifier.ModelParameters);
    if (!*(void *)(v29 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_model)
      || (uint64_t v45 = v29,
          (uint64_t v46 = *(void *)(v29 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_classLabels)) == 0))
    {
      swift_bridgeObjectRelease(_swiftEmptyDictionarySingleton);
      uint64_t v53 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v53, 0, 0);
      *(void *)uint64_t v54 = 0xD00000000000003CLL;
      *(void *)(v54 + 8) = "ve training parameters" + 0x8000000000000000;
      *(_OWORD *)(v54 + 16) = 0;
      *(_OWORD *)(v54 + 32) = 0;
      *(unsigned char *)(v54 + 48) = 0;
      swift_willThrow(&type metadata for MLCreateError, v53, v54, v55, v56, v57);
      Swift::Int v37 = outlined destroy of MLHandActionClassifier.DataSource(v31, type metadata accessor for MLHandActionClassifier.ModelParameters);
      goto LABEL_12;
    }
    uint64_t v47 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures;
    uint64_t v104 = *(void *)(v29 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_model);
    uint64_t v109 = (uint64_t *)v46;
    swift_beginAccess(v29 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures, v86, 0, 0);
    uint64_t v48 = *(void *)(v29 + v47);
    LODWORD(v103) = *(_DWORD *)(v29 + v47 + 8);
    uint64_t v97 = (int *)v48;
    char v98 = v103 & 1;
    uint64_t v31 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures;
    swift_beginAccess(v29 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures, v87, 0, 0);
    uint64_t v49 = *(void *)(v29 + v31);
    LODWORD(v31) = *(_DWORD *)(v45 + v31 + 8);
    uint64_t v106 = v49;
    char v107 = v31 & 1;
    swift_retain();
    char v50 = v109;
    swift_bridgeObjectRetain((_BYTE)v109);
    int v110 = (int *)v48;
    uint64_t v51 = v48;
    LOBYTE(v28) = v103;
    outlined copy of Result<_DataTable, Error>(v51, v103);
    outlined copy of Result<_DataTable, Error>(v49, v31);
    double v52 = v95;
    static MLHandActionClassifier.prepareDataset(classLabels:trainingFeatures:validationFeatures:parameters:)((uint64_t)v101, (uint64_t)v100, v50, (uint64_t)&v97, (uint64_t)&v106, (uint64_t)v102, v43);
    uint64_t v28 = v28;
    if (v52 != 0.0)
    {
      swift_bridgeObjectRelease((_BYTE)v109);
      swift_release();
      outlined consume of Result<_DataTable, Error>(v49, v31);
      outlined consume of Result<_DataTable, Error>((uint64_t)v110, v28);
      outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v102, type metadata accessor for MLHandActionClassifier.ModelParameters);
      Swift::Int v37 = swift_bridgeObjectRelease(_swiftEmptyDictionarySingleton);
      goto LABEL_12;
    }
    outlined consume of Result<_DataTable, Error>(v49, v31);
    outlined consume of Result<_DataTable, Error>((uint64_t)v110, v28);
    uint64_t v60 = v96;
    if (v96 < 0) {
      BUG();
    }
    uint64_t v61 = (uint64_t)v100;
    uint64_t v62 = (uint64_t)v101;
    if (v96)
    {
      uint64_t v63 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_metricsAttributesDictionary;
      uint64_t v64 = 0;
      do
      {
        if (v60 == v64) {
          BUG();
        }
        if (__OFADD__(v64, *(void *)&v105)) {
          BUG();
        }
        uint64_t v65 = MLHandActionClassifier.GraphCNN.iterateTraining(trainingData:validationData:epochCount:)(v62, v61, v64 + *(void *)&v105, v43);
        ++v64;
        uint64_t v66 = *(void *)(v108 + v63);
        *(void *)(v108 + v63) = v65;
        swift_bridgeObjectRelease(v66);
        uint64_t v60 = v96;
        uint64_t v61 = (uint64_t)v100;
        uint64_t v62 = (uint64_t)v101;
      }
      while (v96 != v64);
    }
    double v105 = *(double *)&OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_metricsAttributesDictionary;
    uint64_t v67 = *(void *)(v108
                    + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_metricsAttributesDictionary);
    swift_bridgeObjectRetain(v67);
    specialized Dictionary.subscript.getter(0x676E696E69617274, 0xED000073736F6C5FLL, v67);
    swift_bridgeObjectRelease(v67);
    if (v99)
    {
      if (swift_dynamicCast(&v106, &v97, (char *)&type metadata for Any + 8, &type metadata for Double, 6))
      {
        int v110 = (int *)v106;
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
        uint64_t v97 = (int *)_swiftEmptyDictionarySingleton;
        double v43 = *(double *)&v110;
        specialized _NativeDictionary.setValue(_:forKey:isUnique:)(0, isUniquelyReferenced_nonNull_native, *(double *)&v110);
        uint64_t v69 = v97;
        swift_bridgeObjectRelease(0);
        goto LABEL_24;
      }
    }
    else
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v97, &demangling cache variable for type metadata for Any?);
    }
    uint64_t v69 = (int *)_swiftEmptyDictionarySingleton;
LABEL_24:
    uint64_t v70 = *(void *)(v108 + *(void *)&v105);
    swift_bridgeObjectRetain(v70);
    specialized Dictionary.subscript.getter(0x69746164696C6176, 0xEF73736F6C5F6E6FLL, v70);
    swift_bridgeObjectRelease(v70);
    if (v99)
    {
      if (swift_dynamicCast(&v106, &v97, (char *)&type metadata for Any + 8, &type metadata for Double, 6))
      {
        int v110 = (int *)v106;
        char v71 = swift_isUniquelyReferenced_nonNull_native(v69);
        uint64_t v97 = v69;
        double v43 = *(double *)&v110;
        specialized _NativeDictionary.setValue(_:forKey:isUnique:)(4, v71, *(double *)&v110);
        int v110 = v97;
        swift_bridgeObjectRelease(0);
      }
      else
      {
        int v110 = v69;
      }
    }
    else
    {
      int v110 = v69;
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v97, &demangling cache variable for type metadata for Any?);
    }
    uint64_t v72 = *(void *)(v108 + *(void *)&v105);
    swift_bridgeObjectRetain(v72);
    specialized Dictionary.subscript.getter(0xD000000000000012, (uint64_t)("oseClassifier.swift" + 0x8000000000000000), v72);
    swift_bridgeObjectRelease(v72);
    if (v99)
    {
      uint64_t v73 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
      if (swift_dynamicCast(&v106, &v97, (char *)&type metadata for Any + 8, v73, 6))
      {
        uint64_t v103 = v106;
        uint64_t v74 = (uint64_t)v94;
        _MetricUtilities.ConfusionMatrixMeter.value(normalized:)(0, v43, v3);
        double v95 = static _MetricUtilities.top1Accuracy(confusionMatrix:classCount:)(v74, v109[2]);
        (*(void (**)(uint64_t, uint64_t))(v93 + 8))(v74, v92);
        uint64_t v75 = (uint64_t)v110;
        char v76 = swift_isUniquelyReferenced_nonNull_native(v110);
        uint64_t v97 = (int *)v75;
        double v43 = v95;
        specialized _NativeDictionary.setValue(_:forKey:isUnique:)(3, v76, v95);
        int v110 = v97;
        swift_release();
        swift_bridgeObjectRelease(0);
      }
    }
    else
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v97, &demangling cache variable for type metadata for Any?);
    }
    uint64_t v77 = *(void *)(v108 + *(void *)&v105);
    swift_bridgeObjectRetain(v77);
    specialized Dictionary.subscript.getter(0xD000000000000014, (uint64_t)("ve training confusion matrix" + 0x8000000000000000), v77);
    swift_bridgeObjectRelease(v77);
    if (v99)
    {
      uint64_t v78 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
      if (swift_dynamicCast(&v106, &v97, (char *)&type metadata for Any + 8, v78, 6))
      {
        uint64_t v108 = v106;
        uint64_t v79 = (uint64_t)v94;
        _MetricUtilities.ConfusionMatrixMeter.value(normalized:)(0, v43, v3);
        uint64_t v80 = v109[2];
        swift_bridgeObjectRelease((_BYTE)v109);
        double v105 = static _MetricUtilities.top1Accuracy(confusionMatrix:classCount:)(v79, v80);
        (*(void (**)(uint64_t, uint64_t))(v93 + 8))(v79, v92);
        uint64_t v81 = (uint64_t)v110;
        char v82 = swift_isUniquelyReferenced_nonNull_native(v110);
        uint64_t v97 = (int *)v81;
        specialized _NativeDictionary.setValue(_:forKey:isUnique:)(5, v82, v105);
        uint64_t v83 = (uint64_t)v97;
        swift_release();
        swift_bridgeObjectRelease(0);
LABEL_39:
        LOBYTE(v31) = v88 >= v89;
        uint64_t v28 = (uint64_t)specialized _dictionaryUpCast<A, B, C, D>(_:)(v83);
        swift_bridgeObjectRelease(v83);
        swift_release();
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v100, &demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);
        (*(void (**)(uint64_t *, uint64_t))(v90 + 8))(v101, v91);
        outlined destroy of MLHandActionClassifier.DataSource((uint64_t)v102, type metadata accessor for MLHandActionClassifier.ModelParameters);
        Swift::Int v37 = v96;
        goto LABEL_12;
      }
      swift_bridgeObjectRelease((_BYTE)v109);
    }
    else
    {
      swift_bridgeObjectRelease((_BYTE)v109);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v97, &demangling cache variable for type metadata for Any?);
    }
    uint64_t v83 = (uint64_t)v110;
    goto LABEL_39;
  }
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v84, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
  swift_bridgeObjectRelease(_swiftEmptyDictionarySingleton);
  uint64_t v32 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  swift_allocError(&type metadata for MLCreateError, v32, 0, 0);
  *(void *)uint64_t v33 = 0xD000000000000026;
  *(void *)(v33 + 8) = "Augmentation options" + 0x8000000000000000;
  *(_OWORD *)(v33 + 16) = 0;
  *(_OWORD *)(v33 + 32) = 0;
  *(unsigned char *)(v33 + 48) = 0;
  Swift::Int v37 = swift_willThrow(&type metadata for MLCreateError, v32, v33, v34, v35, v36);
LABEL_12:
  uint64_t v58 = (void *)v28;
  Swift::Bool v59 = v31;
  result.metrics._uint64_t rawValue = v58;
  result._0 = v37;
  result.finished = v59;
  return result;
}

uint64_t HandActionClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)(uint64_t a1, unsigned __int8 *a2)
{
  uint64_t v90 = v2;
  uint64_t v88 = a1;
  LODWORD(v4) = 0;
  uint64_t v5 = type metadata accessor for URL(0);
  int64_t v6 = *(void *)(*(void *)(v5 - 8) + 64);
  int64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v9 = alloca(v6);
  int64_t v10 = alloca(v6);
  uint64_t v11 = alloca(v6);
  int64_t v12 = alloca(v6);
  int64_t v13 = alloca(v6);
  uint64_t v14 = alloca(v6);
  int v15 = *a2;
  if (v15 == 2)
  {
    LOBYTE(v4) = 1;
    if (*(void *)(v3 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_model))
    {
      swift_retain();
      specialized _ModelCheckpoint<>.save(to:)(v88, (uint64_t (*)(void))MLHandActionClassifier.GraphCNN.getCheckpointStatesDictionary());
      swift_release();
    }
  }
  else if (v15 == 1)
  {
    uint64_t v87 = *(void *)(v5 - 8);
    uint64_t v72 = v33;
    uint64_t v86 = v5;
    uint64_t v73 = v33;
    uint64_t v74 = v33;
    uint64_t v16 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures;
    uint64_t v75 = (uint64_t *)(v3 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures);
    swift_beginAccess(v3 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures, v50, 1, 0);
    uint64_t v17 = *(void *)(v3 + v16);
    char v18 = *(unsigned char *)(v3 + v16 + 8);
    int64_t v4 = &v52;
    uint64_t v52 = v17;
    LOBYTE(v53) = v18;
    outlined copy of Result<_DataTable, Error>(v17, v18);
    URL.appendingPathComponent(_:)(0x676E696E69617274, 0xE800000000000000);
    int64_t v19 = v90;
    MLDataTable.write(to:)((uint64_t)v33);
    if (v19)
    {
      (*(void (**)(char *, uint64_t))(v87 + 8))(v33, v86);
      outlined consume of Result<_DataTable, Error>(v52, v53);
    }
    else
    {
      uint64_t v90 = *(void (**)(void, void))(v87 + 8);
      v90(v33, v86);
      outlined consume of Result<_DataTable, Error>(v52, v53);
      uint64_t v20 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures;
      uint64_t v87 = v3 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures;
      swift_beginAccess(v3 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures, v51, 1, 0);
      char v21 = *(unsigned char *)(v3 + v20 + 8);
      uint64_t v84 = *(void *)(v3 + v20);
      LOBYTE(v85) = v21;
      outlined copy of Result<_DataTable, Error>(v84, v21);
      uint64_t v22 = (uint64_t)v72;
      URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEA00000000006E6FLL);
      MLDataTable.write(to:)(v22);
      v90(v22, v86);
      outlined consume of Result<_DataTable, Error>(v84, v85);
      int64_t v4 = (uint64_t *)v73;
      uint64_t v90 = 0;
      URL.appendingPathComponent(_:)(0x676E696E69617274, 0xE800000000000000);
      LOBYTE(v52) = 1;
      *(_DWORD *)((char *)&v52 + 1) = *(_DWORD *)v76;
      HIDWORD(v52) = *(_DWORD *)&v76[3];
      uint64_t v53 = 44;
      unint64_t v54 = 0xE100000000000000;
      uint64_t v55 = 0;
      char v91 = 1;
      unint64_t v56 = 0xE000000000000000;
      uint64_t v57 = 92;
      unint64_t v58 = 0xE100000000000000;
      char v59 = 1;
      *(_DWORD *)uint64_t v60 = *(_DWORD *)v77;
      *(_DWORD *)&v60[3] = *(_DWORD *)&v77[3];
      uint64_t v61 = 34;
      unint64_t v62 = 0xE100000000000000;
      char v63 = 1;
      *(_DWORD *)&v64[3] = *(_DWORD *)&v78[3];
      *(_DWORD *)uint64_t v64 = *(_DWORD *)v78;
      uint64_t v65 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
      uint64_t v66 = 10;
      unint64_t v67 = 0xE100000000000000;
      long long v68 = 0;
      char v69 = 1;
      *(_DWORD *)uint64_t v70 = *(_DWORD *)v79;
      *(_DWORD *)&v70[3] = *(_DWORD *)&v79[3];
      uint64_t v71 = 0;
      uint64_t v24 = v90;
      MLDataTable.init(contentsOf:options:)(v4, &v52);
      if (!v24)
      {
        char v25 = v81;
        uint64_t v26 = v75;
        uint64_t v27 = *v75;
        *uint64_t v75 = v80;
        int v28 = *((_DWORD *)v26 + 2);
        *((unsigned char *)v26 + 8) = v25;
        outlined consume of Result<_DataTable, Error>(v27, v28);
        int64_t v4 = (uint64_t *)v74;
        URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEA00000000006E6FLL);
        v33[0] = 1;
        uint64_t v34 = 44;
        unint64_t v35 = 0xE100000000000000;
        uint64_t v36 = 0;
        char v89 = 1;
        unint64_t v37 = 0xE000000000000000;
        uint64_t v38 = 92;
        unint64_t v39 = 0xE100000000000000;
        char v40 = 1;
        uint64_t v41 = 34;
        unint64_t v42 = 0xE100000000000000;
        char v43 = 1;
        uint64_t v44 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
        uint64_t v45 = 10;
        unint64_t v46 = 0xE100000000000000;
        long long v47 = 0;
        char v48 = 1;
        uint64_t v49 = 0;
        MLDataTable.init(contentsOf:options:)(v4, v33);
        char v29 = v83;
        uint64_t v30 = v87;
        uint64_t v31 = *(void *)v87;
        *(void *)uint64_t v87 = v82;
        int v32 = *(_DWORD *)(v30 + 8);
        *(unsigned char *)(v30 + 8) = v29;
        outlined consume of Result<_DataTable, Error>(v31, v32);
        LOBYTE(v4) = 1;
      }
    }
  }
  return v4;
}

uint64_t HandActionClassifierTrainingSessionDelegate.save(to:)(uint64_t a1)
{
  uint64_t v19 = v1;
  uint64_t v20 = a1;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v6 = type metadata accessor for MLHandActionClassifier.PersistentParameters(0);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters + v2;
  swift_beginAccess(v10, v18, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, (uint64_t)&v17, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v17, 1, v6) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v17, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
    uint64_t v11 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v11, 0, 0);
    *(void *)uint64_t v12 = 0xD000000000000030;
    *(void *)(v12 + 8) = "Feature Extractor" + 0x8000000000000000;
    *(_OWORD *)(v12 + 16) = 0;
    *(_OWORD *)(v12 + 32) = 0;
    *(unsigned char *)(v12 + 48) = 2;
    return swift_willThrow(&type metadata for MLCreateError, v11, v12, v13, v14, v15);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)&v17, (uint64_t)&v17, type metadata accessor for MLHandActionClassifier.PersistentParameters);
    MLHandActionClassifier.PersistentParameters.save(toSessionDirectory:)(v20);
    return outlined destroy of MLHandActionClassifier.DataSource((uint64_t)&v17, type metadata accessor for MLHandActionClassifier.PersistentParameters);
  }
}

NSURL *HandActionClassifierTrainingSessionDelegate.restore(from:phase:)(uint64_t a1)
{
  unint64_t v39 = (uint64_t *)v1;
  uint64_t v37 = v2;
  uint64_t v32 = a1;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v34 = v30;
  uint64_t v6 = alloca(v3);
  int64_t v7 = alloca(v3);
  unint64_t v35 = v30;
  int64_t v8 = alloca(v3);
  uint64_t v9 = alloca(v3);
  uint64_t v38 = v30;
  uint64_t v10 = type metadata accessor for URL(0);
  uint64_t v11 = *(void *)(v10 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v33 = type metadata accessor for MLHandActionClassifier.PersistentParameters(0);
  int64_t v15 = *(void *)(*(void *)(v33 - 8) + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v36 = v30;
  char v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v11 + 16))(v30, v32, v10);
  uint64_t v20 = (uint64_t)v39;
  Swift::tuple_Int_metrics_OpaquePointer_finished_Bool result = MLHandActionClassifier.PersistentParameters.init(sessionDirectory:)(v30);
  if (!v20)
  {
    unint64_t v39 = v30;
    uint64_t v22 = v37 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters;
    swift_beginAccess(v37 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters, v30, 0, 0);
    uint64_t v23 = (uint64_t)v38;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v22, (uint64_t)v38, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
    uint64_t v24 = v23;
    uint64_t v25 = v33;
    if (__swift_getEnumTagSinglePayload(v24, 1, v33) == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v38, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
      uint64_t v26 = (uint64_t)v35;
      outlined init with take of MLClassifierMetrics((uint64_t)v39, (uint64_t)v35, type metadata accessor for MLHandActionClassifier.PersistentParameters);
      __swift_storeEnumTagSinglePayload(v26, 0, 1, v25);
      uint64_t v27 = (uint64_t)v34;
      outlined init with take of DataFrame?(v26, (uint64_t)v34, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
      swift_beginAccess(v22, v31, 33, 0);
      outlined assign with take of MLHandActionClassifier.PersistentParameters?(v27, v22);
      return (NSURL *)swift_endAccess(v31);
    }
    else
    {
      uint64_t v28 = (uint64_t)v36;
      outlined init with take of MLClassifierMetrics((uint64_t)v38, (uint64_t)v36, type metadata accessor for MLHandActionClassifier.PersistentParameters);
      uint64_t v29 = (uint64_t)v39;
      HandActionClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)((uint64_t)v39, v28);
      outlined destroy of MLHandActionClassifier.DataSource(v28, type metadata accessor for MLHandActionClassifier.PersistentParameters);
      return (NSURL *)outlined destroy of MLHandActionClassifier.DataSource(v29, type metadata accessor for MLHandActionClassifier.PersistentParameters);
    }
  }
  return result;
}

uint64_t HandActionClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v185 = v2;
  v166._char object = (void *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
  int64_t v4 = *(void *)(*((void *)v166._object - 1) + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v165 = (void (*)(void, void))&v165;
  uint64_t v180 = type metadata accessor for MLHandActionClassifier.DataSource(0);
  int64_t v7 = *(void *)(*(void *)(v180 - 8) + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  v167._uint64_t countAndFlagsBits = (uint64_t)&v165;
  uint64_t v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  uint64_t v168 = &v165;
  int64_t v12 = alloca(v7);
  uint64_t v13 = alloca(v7);
  uint64_t v169 = &v165;
  uint64_t v14 = alloca(v7);
  int64_t v15 = alloca(v7);
  v170 = &v165;
  uint64_t v181 = (void *)type metadata accessor for DataFrame(0);
  uint64_t v182 = *(v181 - 1);
  int64_t v16 = *(void *)(v182 + 64);
  uint64_t v17 = alloca(v16);
  char v18 = alloca(v16);
  Swift::String v174 = &v165;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v176 = &v165;
  char v21 = alloca(v16);
  uint64_t v22 = alloca(v16);
  v177 = &v165;
  uint64_t v23 = alloca(v16);
  uint64_t v24 = alloca(v16);
  uint64_t v184 = &v165;
  int64_t v25 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                              - 8)
                  + 64);
  uint64_t v26 = alloca(v25);
  uint64_t v27 = alloca(v25);
  uint64_t v175 = &v165;
  uint64_t v28 = alloca(v25);
  uint64_t v29 = alloca(v25);
  uint64_t v30 = alloca(v25);
  uint64_t v31 = alloca(v25);
  char v186 = &v165;
  uint64_t v32 = alloca(v25);
  uint64_t v33 = alloca(v25);
  uint64_t v34 = (int *)type metadata accessor for MLHandActionClassifier.PersistentParameters(0);
  uint64_t v35 = v34[6];
  uint64_t v36 = *(void *)(a2 + v35);
  if (*(void *)(a1 + v35) != v36)
  {
    uint64_t v178 = *(void *)(a1 + v35);
    uint64_t v47 = lazy protocol witness table accessor for type Int and conformance Int();
    uint64_t v185 = (void (*)(void, void, void))BinaryInteger.description.getter(&type metadata for Int, v47);
    char v186 = (void *)v48;
    uint64_t v178 = v36;
    uint64_t v49 = BinaryInteger.description.getter(&type metadata for Int, v47);
    uint64_t v51 = v50;
    uint64_t v52 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v52, 0, 0);
    *(void *)uint64_t v53 = 0x6953206863746142;
    *(void *)(v53 + 8) = 0xEA0000000000657ALL;
    *(void *)(v53 + 16) = v185;
    *(void *)(v53 + 24) = v186;
    *(void *)(v53 + 32) = v49;
    *(void *)(v53 + 40) = v51;
LABEL_14:
    *(unsigned char *)(v53 + 48) = 3;
    return swift_willThrow(&type metadata for MLCreateError, v52, v53, v54, v55, v56);
  }
  uint64_t v37 = v34[7];
  uint64_t v38 = *(void *)(a2 + v37);
  if (*(void *)(a1 + v37) != v38)
  {
    uint64_t v178 = *(void *)(a1 + v37);
    uint64_t v57 = lazy protocol witness table accessor for type Int and conformance Int();
    uint64_t v185 = (void (*)(void, void, void))BinaryInteger.description.getter(&type metadata for Int, v57);
    char v186 = (void *)v58;
    uint64_t v178 = v38;
    uint64_t v59 = BinaryInteger.description.getter(&type metadata for Int, v57);
    uint64_t v61 = v60;
    uint64_t v52 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v52, 0, 0);
    *(void *)uint64_t v53 = 0xD000000000000012;
    unint64_t v62 = "metricsAttributesDictionary";
LABEL_13:
    *(void *)(v53 + 8) = (unint64_t)v62 | 0x8000000000000000;
    *(void *)(v53 + 16) = v185;
    *(void *)(v53 + 24) = v186;
    *(void *)(v53 + 32) = v59;
    *(void *)(v53 + 40) = v61;
    goto LABEL_14;
  }
  uint64_t v39 = v34[8];
  uint64_t v40 = *(void *)(a2 + v39);
  if (*(void *)(a1 + v39) != v40)
  {
    uint64_t v178 = *(void *)(a1 + v39);
    uint64_t v63 = lazy protocol witness table accessor for type Int and conformance Int();
    uint64_t v185 = (void (*)(void, void, void))BinaryInteger.description.getter(&type metadata for Int, v63);
    char v186 = (void *)v64;
    uint64_t v178 = v40;
    uint64_t v59 = BinaryInteger.description.getter(&type metadata for Int, v63);
    uint64_t v61 = v65;
    uint64_t v52 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v52, 0, 0);
    *(void *)uint64_t v53 = 0xD000000000000016;
    unint64_t v62 = "Number of Labels";
    goto LABEL_13;
  }
  uint64_t v41 = v34[9];
  double v42 = *(double *)(a1 + v41);
  if (v42 != *(double *)(a2 + v41))
  {
    uint64_t v185 = *(void (**)(void, void, void))(a2 + v41);
    uint64_t v66 = Double.description.getter(v42);
    uint64_t v68 = v67;
    uint64_t v69 = Double.description.getter(*(double *)&v185);
    uint64_t v71 = v70;
    uint64_t v52 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v52, 0, 0);
    *(void *)uint64_t v53 = 0xD000000000000011;
    unint64_t v54 = "lassification algorithm." + 0x8000000000000000;
    *(void *)(v53 + 8) = "lassification algorithm." + 0x8000000000000000;
    *(void *)(v53 + 16) = v66;
    *(void *)(v53 + 24) = v68;
    *(void *)(v53 + 32) = v69;
    *(void *)(v53 + 40) = v71;
    *(unsigned char *)(v53 + 48) = 3;
    return swift_willThrow(&type metadata for MLCreateError, v52, v53, v54, v55, v56);
  }
  uint64_t v43 = v34[10];
  uint64_t v44 = *(void *)(a2 + v43);
  if (*(void *)(a1 + v43) != v44)
  {
    uint64_t v178 = *(void *)(a1 + v43);
    uint64_t v72 = lazy protocol witness table accessor for type Int and conformance Int();
    uint64_t v185 = (void (*)(void, void, void))BinaryInteger.description.getter(&type metadata for Int, v72);
    char v186 = (void *)v73;
    uint64_t v178 = v44;
    uint64_t v59 = BinaryInteger.description.getter(&type metadata for Int, v72);
    uint64_t v61 = v74;
    uint64_t v52 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v52, 0, 0);
    *(void *)uint64_t v53 = 0xD000000000000014;
    unint64_t v62 = "Maximum Iterations";
    goto LABEL_13;
  }
  uint64_t v171 = a2;
  uint64_t v45 = v185;
  uint64_t result = MLHandActionClassifier.DataSource.gatherAnnotatedFileNames()();
  if (!v45)
  {
    uint64_t v183 = &v165;
    MLHandActionClassifier.DataSource.gatherAnnotatedFileNames()();
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v183, (uint64_t)&v165, &demangling cache variable for type metadata for DataFrame?);
    if (__swift_getEnumTagSinglePayload((uint64_t)&v165, 1, (uint64_t)v181) == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v165, &demangling cache variable for type metadata for DataFrame?);
    }
    else
    {
      uint64_t v76 = (uint64_t)v184;
      uint64_t v77 = (uint64_t)v181;
      uint64_t v185 = *(void (**)(void, void, void))(v182 + 32);
      v185(v184, &v165, v181);
      if (DataFrame.shape.getter(v76) <= 0)
      {
        (*(void (**)(void *, uint64_t))(v182 + 8))(v184, v77);
        uint64_t v81 = (uint64_t)v183;
        uint64_t v75 = v180;
LABEL_24:
        uint64_t v185 = 0;
        uint64_t v82 = (uint64_t)v170;
        outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v170, type metadata accessor for MLHandActionClassifier.DataSource);
        if (swift_getEnumCaseMultiPayload(v82, v75) == 3)
        {
          uint64_t v184 = *(void **)v82;
          LOBYTE(v180) = *(unsigned char *)(v82 + 8);
          v166._uint64_t countAndFlagsBits = *(void *)(v82 + 16);
          uint64_t v175 = *(void **)(v82 + 24);
          v167._char object = *(void **)(v82 + 32);
          v177 = *(void **)(v82 + 40);
          swift_bridgeObjectRelease(*(void *)(v82 + 56));
          uint64_t v82 = (uint64_t)v169;
          outlined init with copy of MLTrainingSessionParameters(v171, (uint64_t)v169, type metadata accessor for MLHandActionClassifier.DataSource);
          if (swift_getEnumCaseMultiPayload(v82, v75) == 3)
          {
            uint64_t v181 = *(void **)v82;
            LODWORD(v182) = *(_DWORD *)(v82 + 8);
            v167._uint64_t countAndFlagsBits = *(void *)(v82 + 16);
            v170 = *(void **)(v82 + 24);
            uint64_t v168 = *(void **)(v82 + 32);
            Swift::String v174 = *(void **)(v82 + 40);
            swift_bridgeObjectRelease(*(void *)(v82 + 56));
            uint64_t v83 = (uint64_t)v184;
            uint64_t v172 = (uint64_t)v184;
            int v84 = v180;
            LOBYTE(v180) = v180 & 1;
            char v173 = v180;
            outlined copy of Result<_DataTable, Error>((uint64_t)v184, v84);
            v85._uint64_t countAndFlagsBits = (uint64_t)v167._object;
            char v86 = (char)v177;
            v85._char object = v177;
            MLDataTable.subscript.getter(v85);
            swift_bridgeObjectRelease(v86);
            LODWORD(v176) = v84;
            outlined consume of Result<_DataTable, Error>(v83, v84);
            uint64_t v172 = v178;
            char v173 = v179;
            uint64_t v169 = Array<A>.init(_:)((uint64_t)&v172, v42);
            uint64_t v87 = (uint64_t)v181;
            uint64_t v172 = (uint64_t)v181;
            LOBYTE(v83) = v182;
            LOBYTE(v177) = v182 & 1;
            char v173 = v182 & 1;
            outlined copy of Result<_DataTable, Error>((uint64_t)v181, v182);
            v85._uint64_t countAndFlagsBits = (uint64_t)v168;
            char v88 = (char)v174;
            v85._char object = v174;
            MLDataTable.subscript.getter(v85);
            swift_bridgeObjectRelease(v88);
            outlined consume of Result<_DataTable, Error>(v87, v83);
            uint64_t v172 = v178;
            char v173 = v179;
            char v89 = Array<A>.init(_:)((uint64_t)&v172, v42);
            LOBYTE(v87) = (_BYTE)v89;
            LOBYTE(v83) = (_BYTE)v169;
            char v90 = specialized static Array<A>.== infix(_:_:)((uint64_t)v169, (uint64_t)v89);
            swift_bridgeObjectRelease(v83);
            swift_bridgeObjectRelease(v87);
            if (v90)
            {
              uint64_t v91 = (uint64_t)v184;
              uint64_t v172 = (uint64_t)v184;
              char v173 = v180;
              char v92 = (char)v176;
              outlined copy of Result<_DataTable, Error>((uint64_t)v184, (char)v176);
              v93._uint64_t countAndFlagsBits = v166._countAndFlagsBits;
              char v94 = (char)v175;
              v93._char object = v175;
              MLDataTable.subscript.getter(v93);
              swift_bridgeObjectRelease(v94);
              outlined consume of Result<_DataTable, Error>(v91, v92);
              uint64_t v172 = v178;
              char v173 = v179;
              uint64_t v180 = (uint64_t)Array<A>.init(_:)((uint64_t)&v172, v42);
              uint64_t v95 = (uint64_t)v181;
              uint64_t v172 = (uint64_t)v181;
              char v173 = (char)v177;
              char v96 = v182;
              outlined copy of Result<_DataTable, Error>((uint64_t)v181, v182);
              v93._uint64_t countAndFlagsBits = v167._countAndFlagsBits;
              LOBYTE(v91) = (_BYTE)v170;
              v93._char object = v170;
              MLDataTable.subscript.getter(v93);
              LOBYTE(v93._countAndFlagsBits) = v91;
              char v97 = v96;
              swift_bridgeObjectRelease(v93._countAndFlagsBits);
              outlined consume of Result<_DataTable, Error>(v95, v96);
              uint64_t v172 = v178;
              char v173 = v179;
              char v98 = Array<A>.init(_:)((uint64_t)&v172, v42);
              char v99 = (char)v98;
              LOBYTE(v95) = v180;
              char v100 = specialized static Array<A>.== infix(_:_:)(v180, (uint64_t)v98);
              swift_bridgeObjectRelease(v95);
              swift_bridgeObjectRelease(v99);
              if (v100)
              {
                outlined consume of Result<_DataTable, Error>((uint64_t)v181, v97);
                outlined consume of Result<_DataTable, Error>((uint64_t)v184, (char)v176);
LABEL_51:
                outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v186, &demangling cache variable for type metadata for DataFrame?);
                return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v183, &demangling cache variable for type metadata for DataFrame?);
              }
              uint64_t v148 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
              swift_allocError(&type metadata for MLCreateError, v148, 0, 0);
              *(void *)uint64_t v149 = 1;
              *(_OWORD *)(v149 + 8) = 0;
              *(_OWORD *)(v149 + 24) = 0;
              *(void *)(v149 + 40) = 0;
              *(unsigned char *)(v149 + 48) = 4;
              swift_willThrow(&type metadata for MLCreateError, v148, v149, v150, v151, v152);
              uint64_t v137 = (uint64_t)v181;
              char v136 = v97;
            }
            else
            {
              swift_bridgeObjectRelease((_BYTE)v170);
              swift_bridgeObjectRelease((_BYTE)v175);
              uint64_t v131 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
              swift_allocError(&type metadata for MLCreateError, v131, 0, 0);
              *(void *)uint64_t v132 = 1;
              *(_OWORD *)(v132 + 8) = 0;
              *(_OWORD *)(v132 + 24) = 0;
              *(void *)(v132 + 40) = 0;
              *(unsigned char *)(v132 + 48) = 4;
              swift_willThrow(&type metadata for MLCreateError, v131, v132, v133, v134, v135);
              char v136 = v182;
              uint64_t v137 = (uint64_t)v181;
            }
            outlined consume of Result<_DataTable, Error>(v137, v136);
            outlined consume of Result<_DataTable, Error>((uint64_t)v184, (char)v176);
            goto LABEL_47;
          }
          outlined consume of Result<_DataTable, Error>((uint64_t)v184, v180);
          swift_bridgeObjectRelease((_BYTE)v177);
          swift_bridgeObjectRelease((_BYTE)v175);
        }
        outlined destroy of MLHandActionClassifier.DataSource(v82, type metadata accessor for MLHandActionClassifier.DataSource);
        uint64_t v101 = a1;
        uint64_t v102 = (uint64_t)v168;
        outlined init with copy of MLTrainingSessionParameters(v101, (uint64_t)v168, type metadata accessor for MLHandActionClassifier.DataSource);
        if (swift_getEnumCaseMultiPayload(v102, v75) == 5)
        {
          uint64_t v103 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          uint64_t v104 = v103[12];
          uint64_t v169 = *(void **)(v102 + v104);
          uint64_t v184 = *(void **)(v102 + v104 + 8);
          uint64_t v105 = v103[16];
          v170 = *(void **)(v102 + v105);
          uint64_t v180 = *(void *)(v102 + v105 + 8);
          swift_bridgeObjectRelease(*(void *)(v102 + v103[20] + 8));
          uint64_t v106 = v102;
          uint64_t v107 = (uint64_t)v181;
          uint64_t v168 = *(void **)(v182 + 32);
          ((void (*)(void *, uint64_t, void *))v168)(v176, v106, v181);
          uint64_t v108 = v75;
          uint64_t countAndFlagsBits = v167._countAndFlagsBits;
          outlined init with copy of MLTrainingSessionParameters(v171, v167._countAndFlagsBits, type metadata accessor for MLHandActionClassifier.DataSource);
          if (swift_getEnumCaseMultiPayload(countAndFlagsBits, v108) == 5)
          {
            uint64_t v110 = v103[12];
            v167._char object = *(void **)(countAndFlagsBits + v110);
            uint64_t v171 = *(void *)(countAndFlagsBits + v110 + 8);
            uint64_t v111 = v103[16];
            uint64_t v175 = *(void **)(countAndFlagsBits + v111);
            v177 = *(void **)(countAndFlagsBits + v111 + 8);
            swift_bridgeObjectRelease(*(void *)(countAndFlagsBits + v103[20] + 8));
            ((void (*)(void *, uint64_t, uint64_t))v168)(v174, countAndFlagsBits, v107);
            uint64_t v112 = v165;
            char v113 = v180;
            DataFrame.subscript.getter(v170, v180);
            swift_bridgeObjectRelease(v113);
            char v114 = (char)v177;
            DataFrame.subscript.getter(v175, v177);
            swift_bridgeObjectRelease(v114);
            char v115 = specialized Sequence.allSatisfy(_:)(v112);
            outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v112, &demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
            uint64_t v116 = v176;
            if (v115)
            {
              char v117 = (char)v184;
              DataFrame.subscript.getter(v169, v184);
              swift_bridgeObjectRelease(v117);
              char v118 = v171;
              DataFrame.subscript.getter(v167._object, v171);
              swift_bridgeObjectRelease(v118);
              char v119 = specialized Sequence.allSatisfy(_:)(v112);
              outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v112, &demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
              uint64_t v120 = (uint64_t)v186;
              if ((v119 & 1) == 0)
              {
                uint64_t v121 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
                swift_allocError(&type metadata for MLCreateError, v121, 0, 0);
                *(void *)uint64_t v122 = 1;
                *(_OWORD *)(v122 + 8) = 0;
                *(_OWORD *)(v122 + 24) = 0;
                *(void *)(v122 + 40) = 0;
                *(unsigned char *)(v122 + 48) = 4;
                swift_willThrow(&type metadata for MLCreateError, v121, v122, v123, v124, v125);
              }
              uint64_t v126 = *(void (**)(void *, void *))(v182 + 8);
              uint64_t v127 = (uint64_t)v181;
              v126(v174, v181);
              v126(v176, (void *)v127);
              uint64_t v128 = v120;
              goto LABEL_48;
            }
            swift_bridgeObjectRelease(v171);
            swift_bridgeObjectRelease((_BYTE)v184);
            uint64_t v138 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            swift_allocError(&type metadata for MLCreateError, v138, 0, 0);
            *(void *)uint64_t v139 = 1;
            *(_OWORD *)(v139 + 8) = 0;
            *(_OWORD *)(v139 + 24) = 0;
            *(void *)(v139 + 40) = 0;
            *(unsigned char *)(v139 + 48) = 4;
            swift_willThrow(&type metadata for MLCreateError, v138, v139, v140, v141, v142);
            char v143 = *(void (**)(void *, void *))(v182 + 8);
            uint64_t v144 = (uint64_t)v181;
            v143(v174, v181);
            uint64_t v145 = (uint64_t)v116;
            goto LABEL_43;
          }
          swift_bridgeObjectRelease(v180);
          swift_bridgeObjectRelease((_BYTE)v184);
          (*(void (**)(void *, uint64_t))(v182 + 8))(v176, v107);
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v186, &demangling cache variable for type metadata for DataFrame?);
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v183, &demangling cache variable for type metadata for DataFrame?);
          uint64_t v129 = countAndFlagsBits;
        }
        else
        {
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v186, &demangling cache variable for type metadata for DataFrame?);
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v81, &demangling cache variable for type metadata for DataFrame?);
          uint64_t v129 = v102;
        }
        return outlined destroy of MLHandActionClassifier.DataSource(v129, type metadata accessor for MLHandActionClassifier.DataSource);
      }
      uint64_t v78 = (uint64_t)v175;
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v186, (uint64_t)v175, &demangling cache variable for type metadata for DataFrame?);
      int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v78, 1, v77);
      uint64_t v80 = v77;
      uint64_t v75 = v180;
      if (EnumTagSinglePayload == 1)
      {
        (*(void (**)(void *, uint64_t))(v182 + 8))(v184, v80);
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v78, &demangling cache variable for type metadata for DataFrame?);
        goto LABEL_22;
      }
      char v130 = v177;
      v185(v177, v78, v80);
      if (DataFrame.shape.getter(v130) > 0)
      {
        uint64_t v153 = HandActionClassifierTrainingSessionDelegate.pathsByLabel(for:)();
        unint64_t v154 = v177;
        char v155 = HandActionClassifierTrainingSessionDelegate.pathsByLabel(for:)();
        char v156 = (char)v155;
        uint64_t v185 = 0;
        char v157 = specialized static Dictionary<>.== infix(_:_:)((uint64_t)v153, (uint64_t)v155);
        swift_bridgeObjectRelease((_BYTE)v153);
        swift_bridgeObjectRelease(v156);
        if (v157)
        {
          unint64_t v158 = *(void (**)(void *, void *))(v182 + 8);
          uint64_t v159 = (uint64_t)v181;
          v158(v154, v181);
          v158(v184, (void *)v159);
          goto LABEL_51;
        }
        uint64_t v160 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v160, 0, 0);
        *(void *)uint64_t v161 = 1;
        *(_OWORD *)(v161 + 8) = 0;
        *(_OWORD *)(v161 + 24) = 0;
        *(void *)(v161 + 40) = 0;
        *(unsigned char *)(v161 + 48) = 4;
        swift_willThrow(&type metadata for MLCreateError, v160, v161, v162, v163, v164);
        char v143 = *(void (**)(void *, void *))(v182 + 8);
        uint64_t v144 = (uint64_t)v181;
        v143(v154, v181);
        uint64_t v145 = (uint64_t)v184;
LABEL_43:
        v143((void *)v145, (void *)v144);
LABEL_47:
        uint64_t v128 = (uint64_t)v186;
LABEL_48:
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v128, &demangling cache variable for type metadata for DataFrame?);
        return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v183, &demangling cache variable for type metadata for DataFrame?);
      }
      uint64_t v146 = *(void (**)(void *, void *))(v182 + 8);
      uint64_t v147 = (uint64_t)v181;
      v146(v177, v181);
      v146(v184, (void *)v147);
    }
    uint64_t v75 = v180;
LABEL_22:
    uint64_t v81 = (uint64_t)v183;
    goto LABEL_24;
  }
  return result;
}

void *HandActionClassifierTrainingSessionDelegate.pathsByLabel(for:)()
{
  uint64_t v73 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v78 = *(void **)(v73 - 8);
  int64_t v0 = v78[8];
  uint64_t v1 = alloca(v0);
  uint64_t v2 = alloca(v0);
  uint64_t v74 = &v64;
  uint64_t v85 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>);
  int64_t v3 = *(void *)(*(void *)(v85 - 8) + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v87 = &v64;
  uint64_t v86 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>.Iterator);
  int64_t v6 = *(void *)(*(void *)(v86 - 8) + 64);
  int64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v80 = &v64;
  uint64_t v76 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<String>);
  uint64_t v77 = *(void *)(v76 - 8);
  int64_t v9 = *(void *)(v77 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  int64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  ColumnID.init(_:_:)(0x7461506F65646976, 0xE900000000000068, &type metadata for String);
  ColumnID.init(_:_:)(0x6C6562616CLL, 0xE500000000000000, &type metadata for String);
  uint64_t v83 = &v64;
  if (!specialized DataFrame.containsColumn<A>(_:)() || !specialized DataFrame.containsColumn<A>(_:)())
  {
    uint64_t v57 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
    uint64_t v58 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, v57, &protocol witness table for String);
    uint64_t v59 = *(void (**)(uint64_t *, uint64_t))(v77 + 8);
    uint64_t v60 = v76;
    v59(&v64, v76);
    v59(v83, v60);
    return (void *)v58;
  }
  uint64_t v14 = (uint64_t)v87;
  DataFrame.subscript.getter(v83, &type metadata for String);
  uint64_t v85 = v14 + *(int *)(v85 + 52);
  uint64_t v71 = &v64;
  DataFrame.subscript.getter(&v64, &type metadata for String);
  int64_t v15 = (void (*)(uint64_t *, uint64_t, uint64_t))v78[4];
  int64_t v16 = v74;
  uint64_t v17 = v73;
  v15(v74, v14, v73);
  uint64_t v87 = (uint64_t *)lazy protocol witness table accessor for type Column<String> and conformance Column<A>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, (uint64_t)&protocol conformance descriptor for Column<A>);
  char v18 = v80;
  dispatch thunk of Sequence.makeIterator()(v17, v87);
  v15(v16, v85, v17);
  uint64_t v19 = v86;
  uint64_t v68 = (char *)v18 + *(int *)(v86 + 52);
  dispatch thunk of Sequence.makeIterator()(v17, v87);
  uint64_t v75 = *(int *)(v19 + 56);
  *((unsigned char *)v18 + v75) = 0;
  uint64_t v69 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<Column<String>>);
  uint64_t v20 = (uint64_t *)((char *)v18 + *(int *)(v69 + 36));
  uint64_t v21 = (uint64_t)v18;
  uint64_t v22 = lazy protocol witness table accessor for type Column<String> and conformance Column<A>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v81 = _swiftEmptyDictionarySingleton;
  uint64_t v82 = 0;
  uint64_t v70 = v20;
  uint64_t v86 = v22;
  while (1)
  {
    uint64_t v87 = (uint64_t *)*v20;
    uint64_t v23 = v20;
    uint64_t v24 = v73;
    dispatch thunk of Collection.endIndex.getter(v73, v22);
    if (v87 == (uint64_t *)v72[0]) {
      break;
    }
    int64_t v25 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v72, v23, v24, v86);
    uint64_t v67 = *v26;
    uint64_t v85 = v26[1];
    swift_bridgeObjectRetain(v85);
    v25(v72, 0);
    uint64_t v27 = v74;
    unint64_t v84 = v78[2];
    ((void (*)(uint64_t *, uint64_t, uint64_t))v84)(v74, v21, v24);
    dispatch thunk of Collection.formIndex(after:)(v23, v24, v86);
    uint64_t v65 = (void (*)(uint64_t *, uint64_t))v78[1];
    v65(v27, v24);
    uint64_t v28 = *(int *)(v69 + 36);
    uint64_t v29 = v27;
    uint64_t v30 = v68;
    uint64_t v87 = *(uint64_t **)&v68[v28];
    dispatch thunk of Collection.endIndex.getter(v24, v86);
    if (v87 == (uint64_t *)v72[0])
    {
      swift_bridgeObjectRelease(v85);
      uint64_t v21 = (uint64_t)v80;
      break;
    }
    uint64_t v31 = &v30[v28];
    uint64_t v66 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v72, v31, v24, v86);
    uint64_t v79 = *v32;
    uint64_t v87 = (uint64_t *)v32[1];
    swift_bridgeObjectRetain((_BYTE)v87);
    v66(v72, 0);
    ((void (*)(uint64_t *, char *, uint64_t))v84)(v29, v30, v24);
    dispatch thunk of Collection.formIndex(after:)(v31, v24, v86);
    v65(v29, v24);
    char v33 = v85;
    if (v85)
    {
      uint64_t v34 = (uint64_t)v87;
      if (v87)
      {
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v82, 0);
        uint64_t v35 = v81;
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v81);
        v72[0] = v35;
        unint64_t v84 = specialized __RawDictionaryStorage.find<A>(_:)(v79, v34);
        BOOL v38 = (v37 & 1) == 0;
        BOOL v39 = __OFADD__(v35[2], v38);
        Swift::Int v40 = v35[2] + v38;
        if (v39) {
          BUG();
        }
        char v41 = v37;
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [String]>);
        Swift::Bool v42 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v40);
        uint64_t v43 = (void *)v72[0];
        unint64_t v44 = v84;
        if (v42)
        {
          unint64_t v44 = specialized __RawDictionaryStorage.find<A>(_:)(v79, (uint64_t)v87);
          if ((v41 & 1) != (v45 & 1))
          {
            KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
            BUG();
          }
        }
        swift_bridgeObjectRelease(0);
        if (v41)
        {
          char v46 = (char)v43;
        }
        else
        {
          v43[(v44 >> 6) + 8] |= 1 << v44;
          uint64_t v47 = v43[6];
          uint64_t v48 = 16 * v44;
          *(void *)(v47 + v48) = v79;
          char v49 = (char)v87;
          *(void *)(v47 + v48 + 8) = v87;
          *(void *)(v43[7] + 8 * v44) = _swiftEmptyArrayStorage;
          uint64_t v50 = v43[2];
          swift_bridgeObjectRetain((_BYTE)v43);
          BOOL v39 = __OFADD__(1, v50);
          uint64_t v51 = v50 + 1;
          if (v39) {
            BUG();
          }
          v43[2] = v51;
          char v46 = v49;
        }
        swift_bridgeObjectRetain(v46);
        uint64_t v52 = v43[7];
        swift_bridgeObjectRelease((_BYTE)v43);
        uint64_t v53 = *(void **)(v52 + 8 * v44);
        char v54 = swift_isUniquelyReferenced_nonNull_native(v53);
        *(void *)(v52 + 8 * v44) = v53;
        uint64_t v81 = v43;
        unint64_t v84 = v44;
        if (!v54)
        {
          uint64_t v53 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v53[2] + 1, 1, (uint64_t)v53);
          *(void *)(v52 + 8 * v44) = v53;
        }
        unint64_t v55 = v53[2];
        if (v53[3] >> 1 <= v55)
        {
          uint64_t v53 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v53[3] >= 2uLL, v55 + 1, 1, (uint64_t)v53);
          *(void *)(v52 + 8 * v84) = v53;
        }
        void v53[2] = v55 + 1;
        uint64_t v56 = 2 * v55;
        v53[v56 + 4] = v67;
        v53[v56 + 5] = v85;
        swift_bridgeObjectRelease((_BYTE)v87);
        uint64_t v82 = specialized thunk for @callee_guaranteed () -> (@owned [Double]);
        goto LABEL_22;
      }
    }
    else
    {
      char v33 = (char)v87;
    }
    swift_bridgeObjectRelease(v33);
LABEL_22:
    uint64_t v21 = (uint64_t)v80;
    uint64_t v20 = v70;
    uint64_t v22 = v86;
    if (*((unsigned char *)v80 + v75) == 1) {
      goto LABEL_27;
    }
  }
  *(unsigned char *)(v21 + v75) = 1;
LABEL_27:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v21, &demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>.Iterator);
  uint64_t v61 = *(void (**)(uint64_t *, uint64_t))(v77 + 8);
  uint64_t v62 = v76;
  v61(v71, v76);
  v61(v83, v62);
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v82, 0);
  return v81;
}

BOOL specialized DataFrame.containsColumn<A>(_:)()
{
  uint64_t v19 = type metadata accessor for AnyColumn(0);
  uint64_t v0 = *(void *)(v19 - 8);
  int64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = alloca(v1);
  int64_t v3 = alloca(v1);
  uint64_t v20 = &v18;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<String>);
  v5._uint64_t countAndFlagsBits = ColumnID.name.getter(v4);
  char object = v5._object;
  Swift::String v7 = v5;
  Swift::Int_optional v8 = DataFrame.indexOfColumn(_:)(v5);
  Swift::Int value = v8.value;
  Swift::Bool is_nil = v8.is_nil;
  swift_bridgeObjectRelease((_BYTE)object);
  BOOL result = 0;
  if (!is_nil)
  {
    uint64_t v12 = DataFrame.columns.getter(object, v7._object);
    if (value < 0) {
      BUG();
    }
    char v13 = v12;
    if ((unint64_t)value >= *(void *)(v12 + 16)) {
      BUG();
    }
    uint64_t v14 = v20;
    uint64_t v15 = ((*(unsigned __int8 *)(v0 + 80) + 32) & ~*(unsigned __int8 *)(v0 + 80)) + v12 + *(void *)(v0 + 72) * value;
    uint64_t v16 = v19;
    (*(void (**)(uint64_t *, uint64_t, uint64_t))(v0 + 16))(v20, v15, v19);
    swift_bridgeObjectRelease(v13);
    uint64_t v17 = (void *)AnyColumn.wrappedElementType.getter();
    (*(void (**)(uint64_t *, uint64_t))(v0 + 8))(v14, v16);
    return v17 == &type metadata for String;
  }
  return result;
}

uint64_t HandActionClassifierTrainingSessionDelegate.deinit()
{
  outlined destroy of MLHandActionClassifier.DataSource(v0 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
  outlined consume of MLDataTable?(*(void *)(v0 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable), *(_DWORD *)(v0 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_sourceTable + 8));
  outlined consume of Result<_DataTable, Error>(*(void *)(v0 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures), *(_DWORD *)(v0 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_trainingFeatures + 8));
  outlined consume of Result<_DataTable, Error>(*(void *)(v0 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures), *(_DWORD *)(v0 + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_validationFeatures + 8));
  swift_release();
  swift_bridgeObjectRelease(*(void *)(v0
                                      + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_classLabels));
  swift_bridgeObjectRelease(*(void *)(v0
                                      + OBJC_IVAR____TtC8CreateML43HandActionClassifierTrainingSessionDelegate_metricsAttributesDictionary));
  return v0;
}

uint64_t HandActionClassifierTrainingSessionDelegate.__deallocating_deinit()
{
  HandActionClassifierTrainingSessionDelegate.deinit();
  return swift_deallocClassInstance(v0, *(unsigned int *)(*(void *)v0 + 48), *(unsigned __int16 *)(*(void *)v0 + 52));
}

uint64_t ObjC metadata update function for HandActionClassifierTrainingSessionDelegate()
{
  return type metadata accessor for HandActionClassifierTrainingSessionDelegate(0);
}

uint64_t type metadata accessor for HandActionClassifierTrainingSessionDelegate(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for HandActionClassifierTrainingSessionDelegate;
  if (!type metadata singleton initialization cache for HandActionClassifierTrainingSessionDelegate) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for HandActionClassifierTrainingSessionDelegate);
  }
  return result;
}

uint64_t type metadata completion function for HandActionClassifierTrainingSessionDelegate(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLTrainingSessionParameters(319);
  if (v2 <= 0x3F)
  {
    v4[0] = *(void *)(result - 8) + 64;
    uint64_t result = type metadata accessor for MLHandActionClassifier.PersistentParameters?(319);
    if (v3 <= 0x3F)
    {
      v4[1] = *(void *)(result - 8) + 64;
      v4[2] = "\t";
      v4[3] = (char *)&value witness table for Builtin.Int64 + 64;
      _OWORD v4[4] = (char *)&value witness table for Builtin.Int64 + 64;
      v4[5] = &unk_350AD8;
      v4[6] = &unk_350AD8;
      v4[7] = &unk_350AF0;
      void v4[8] = &unk_350AF0;
      v4[9] = (char *)&value witness table for Builtin.BridgeObject + 64;
      uint64_t result = swift_updateClassMetadata2(a1, 256, 10, v4, a1 + 80);
      if (!result) {
        return 0;
      }
    }
  }
  return result;
}

uint64_t type metadata accessor for MLHandActionClassifier.PersistentParameters?(uint64_t a1)
{
  uint64_t result = lazy cache variable for type metadata for MLHandActionClassifier.PersistentParameters?;
  if (!lazy cache variable for type metadata for MLHandActionClassifier.PersistentParameters?)
  {
    uint64_t v2 = type metadata accessor for MLHandActionClassifier.PersistentParameters(255);
    uint64_t result = type metadata accessor for Optional(a1, v2);
    if (!v3) {
      lazy cache variable for type metadata for MLHandActionClassifier.PersistentParameters? = result;
    }
  }
  return result;
}

void protocol witness for TrainingSessionDelegate.setUp() in conformance HandActionClassifierTrainingSessionDelegate()
{
}

void protocol witness for TrainingSessionDelegate.resume(from:) in conformance HandActionClassifierTrainingSessionDelegate(Swift::OpaquePointer a1)
{
}

unint64_t protocol witness for TrainingSessionDelegate.itemCount(phase:) in conformance HandActionClassifierTrainingSessionDelegate(CreateML::MLPhase a1)
{
  return (unint64_t)HandActionClassifierTrainingSessionDelegate.itemCount(phase:)(a1);
}

void protocol witness for TrainingSessionDelegate.transitionTo(phase:) in conformance HandActionClassifierTrainingSessionDelegate(CreateML::MLPhase a1)
{
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance HandActionClassifierTrainingSessionDelegate(Swift::Int a1)
{
  *(Swift::tuple_Int_finished_Bool *)&long long v2 = HandActionClassifierTrainingSessionDelegate.extractFeatures(from:)(a1);
  if (v4)
  {
    uint64_t v5 = v1;
  }
  else
  {
    unsigned int v3 = BYTE8(v2);
    uint64_t v5 = v1;
    *((void *)&v2 + 1) = v2;
  }
  return protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(*(uint64_t (**)(uint64_t, void))(v1 + 8), v5, *((uint64_t *)&v2 + 1), v3);
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance HandActionClassifierTrainingSessionDelegate(Swift::Int a1)
{
  Swift::tuple_Int_metrics_OpaquePointer_finished_Bool v9 = HandActionClassifierTrainingSessionDelegate.train(from:)(a1);
  if (v4)
  {
    uint64_t v5 = *(uint64_t (**)(uint64_t, uint64_t, void))(v1 + 8);
    uint64_t v6 = v1;
  }
  else
  {
    uint64_t rawValue = v9.metrics._rawValue;
    uint64_t v5 = *(uint64_t (**)(uint64_t, uint64_t, void))(v1 + 8);
    BOOL finished = v9.finished;
    uint64_t v6 = v1;
    v9.metrics._uint64_t rawValue = (void *)v9._0;
    *(void *)&v9.BOOL finished = rawValue;
  }
  return protocol witness for TrainingSessionDelegate.train(from:) in conformance HandPoseClassifierTrainingSessionDelegate(v5, v6, (uint64_t)v9.metrics._rawValue, *(uint64_t *)&v9.finished, finished);
}

uint64_t protocol witness for TrainingSessionDelegate.saveCheckpoint(to:phase:iteration:) in conformance HandActionClassifierTrainingSessionDelegate(uint64_t a1, unsigned __int8 *a2)
{
  return HandActionClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)(a1, a2);
}

uint64_t protocol witness for TrainingSessionCodable.save(to:) in conformance HandActionClassifierTrainingSessionDelegate(uint64_t a1)
{
  return HandActionClassifierTrainingSessionDelegate.save(to:)(a1);
}

NSURL *protocol witness for TrainingSessionCodable.restore(from:phase:) in conformance HandActionClassifierTrainingSessionDelegate(uint64_t a1)
{
  return HandActionClassifierTrainingSessionDelegate.restore(from:phase:)(a1);
}

uint64_t outlined assign with take of MLHandActionClassifier.PersistentParameters?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandActionClassifier.PersistentParameters?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 40))(a2, a1, v2);
  return a2;
}

uint64_t lazy protocol witness table accessor for type [[Double]] and conformance <A> [A]()
{
  uint64_t result = lazy protocol witness table cache variable for type [[Double]] and conformance <A> [A];
  if (!lazy protocol witness table cache variable for type [[Double]] and conformance <A> [A])
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [[Double]]);
    lazy protocol witness table accessor for type [String] and conformance <A> [A](&lazy protocol witness table cache variable for type [Double] and conformance <A> [A], &demangling cache variable for type metadata for [Double]);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for <A> [A], v1);
    lazy protocol witness table cache variable for type [[Double]] and conformance <A> [A] = result;
  }
  return result;
}

uint64_t specialized Dictionary.Values.startIndex.getter(uint64_t a1)
{
  return specialized Dictionary.Values.startIndex.getter(a1);
}

{
  char v1;
  uint64_t result;
  unint64_t v3;
  uint64_t v4;
  unint64_t v5;
  uint64_t v6;

  uint64_t v1 = *(unsigned char *)(a1 + 32);
  uint64_t result = 1 << v1;
  unsigned int v3 = *(void *)(a1 + 64);
  if (v3)
  {
    uint64_t v4 = 0;
LABEL_3:
    _BitScanForward64(&v5, v3);
    return v4 + v5;
  }
  if ((v1 & 0x3Fu) >= 7)
  {
    unsigned int v3 = *(void *)(a1 + 72);
    if (v3)
    {
      uint64_t v4 = 64;
      goto LABEL_3;
    }
    uint64_t v4 = 64;
    uint64_t v6 = 10;
    while (v6 - 8 < (unint64_t)(result + 63) >> 6)
    {
      unsigned int v3 = *(void *)(a1 + 8 * v6);
      v4 += 64;
      ++v6;
      if (v3) {
        goto LABEL_3;
      }
    }
  }
  return result;
}

uint64_t specialized _NativeDictionary.startIndex.getter(uint64_t a1)
{
  return specialized _NativeDictionary.startIndex.getter(a1);
}

{
  char v1;
  uint64_t result;
  unint64_t v3;
  uint64_t v4;
  unint64_t v5;
  unsigned __int8 v6;
  uint64_t v7;

  uint64_t v1 = *(unsigned char *)(a1 + 32);
  uint64_t result = 1 << v1;
  unsigned int v3 = *(void *)(a1 + 64);
  if (v3)
  {
    uint64_t v4 = 0;
LABEL_3:
    _BitScanForward64(&v5, v3);
    return v4 + v5;
  }
  uint64_t v6 = v1 & 0x3F;
  if (v6 >= 7u)
  {
    unsigned int v3 = *(void *)(a1 + 72);
    if (v3)
    {
      uint64_t v4 = 64;
      goto LABEL_3;
    }
    if (v6 >= 8u)
    {
      unsigned int v3 = *(void *)(a1 + 80);
      uint64_t v4 = 128;
      if (v3) {
        goto LABEL_3;
      }
      unsigned int v3 = *(void *)(a1 + 88);
      uint64_t v4 = 192;
      if (v3) {
        goto LABEL_3;
      }
      Swift::String v7 = 12;
      while (v7 - 8 < (unint64_t)(result + 63) >> 6)
      {
        unsigned int v3 = *(void *)(a1 + 8 * v7);
        v4 += 64;
        ++v7;
        if (v3) {
          goto LABEL_3;
        }
      }
    }
  }
  return result;
}

uint64_t outlined destroy of MLHandActionClassifier.DataSource(uint64_t a1, uint64_t (*a2)(void))
{
  uint64_t v2 = a2(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

unsigned char *assignWithCopy for MLLogisticRegressionClassifier.ModelParameters.ValidationData(unsigned char *__dst, unsigned char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)__dst);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v7 = type metadata accessor for DataFrame(0);
      (*(void (**)(unsigned char *, unsigned char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v5 = *(void *)__src;
      char v6 = __src[8];
      outlined copy of Result<_DataTable, Error>(*(void *)__src, v6);
      *(void *)__dst = v5;
      __dst[8] = v6;
      swift_storeEnumTagMultiPayload(__dst, a3, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLLogisticRegressionClassifier.ModelParameters.ValidationData;
  if (!type metadata singleton initialization cache for MLLogisticRegressionClassifier.ModelParameters.ValidationData) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
  }
  return result;
}

void *assignWithTake for MLLogisticRegressionClassifier.ModelParameters.ValidationData(void *__dst, void *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)__dst);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 2)
    {
      uint64_t v4 = type metadata accessor for DataFrame(0);
      (*(void (**)(void *, void *, uint64_t))(*(void *)(v4 - 8) + 32))(__dst, __src, v4);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLLogisticRegressionClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  v5[0] = &unk_350B38;
  v5[1] = &unk_350B50;
  uint64_t result = type metadata accessor for DataFrame(319);
  if (v4 <= 0x3F)
  {
    v5[2] = *(void *)(result - 8) + 64;
    swift_initEnumMetadataMultiPayload(a1, 256, 3, v5, v2, v3);
    return 0;
  }
  return result;
}

uint64_t MLLogisticRegressionClassifier.ModelParameters.ValidationData.asTable()(__m128 a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = type metadata accessor for DataFrame(0);
  uint64_t v27 = *(void *)(v4 - 8);
  int64_t v5 = *(void *)(v27 + 64);
  char v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v29 = &v25;
  Swift::Int_optional v8 = alloca(v5);
  Swift::tuple_Int_metrics_OpaquePointer_finished_Bool v9 = alloca(v5);
  uint64_t v28 = &v25;
  uint64_t v10 = type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData(0);
  int64_t v11 = *(void *)(*(void *)(v10 - 8) + 64);
  uint64_t v12 = alloca(v11);
  char v13 = alloca(v11);
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v2, (uint64_t)&v25);
  uint64_t result = swift_getEnumCaseMultiPayload(&v25, v10);
  switch((int)result)
  {
    case 0:
      *(void *)uint64_t v3 = 0;
      *(unsigned char *)(v3 + 8) = -1;
      break;
    case 1:
      uint64_t result = v25;
      char v15 = v26;
      goto LABEL_7;
    case 2:
      uint64_t v16 = v28;
      uint64_t v17 = v27;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v27 + 32))(v28, &v25, v4);
      uint64_t v18 = (uint64_t)v29;
      *(double *)a1.i64 = (*(double (**)(uint64_t *, uint64_t *, uint64_t))(v17 + 16))(v29, v16, v4);
      MLDataTable.init(_:convertArraysToShapedArrays:)(v18, 1, a1);
      (*(void (**)(uint64_t *, uint64_t))(v17 + 8))(v16, v4);
      uint64_t result = v30;
      char v15 = v31;
LABEL_7:
      *(void *)uint64_t v3 = result;
      *(unsigned char *)(v3 + 8) = v15;
      break;
    case 3:
      uint64_t v19 = v3;
      uint64_t empty = tc_v1_sframe_create_empty(0);
      if (!empty) {
        BUG();
      }
      uint64_t v21 = empty;
      uint64_t v22 = type metadata accessor for CMLTable();
      uint64_t v23 = swift_allocObject(v22, 24, 7);
      *(void *)(v23 + 16) = v21;
      uint64_t v24 = type metadata accessor for _DataTable();
      swift_allocObject(v24, 40, 7);
      uint64_t result = _DataTable.init(impl:)(v23);
      *(void *)uint64_t v19 = result;
      *(unsigned char *)(v19 + 8) = 0;
      break;
  }
  return result;
}

uint64_t MLLogisticRegressionClassifier.ModelParameters.ValidationData.generateDataFrames(trainingData:)(uint64_t a1, uint64_t a2, void (*a3)(uint64_t *, uint64_t, uint64_t))
{
  uint64_t v55 = v3;
  uint64_t v57 = a3;
  uint64_t v56 = (uint64_t *)a2;
  uint64_t v54 = a1;
  uint64_t v5 = type metadata accessor for DataFrame(0);
  uint64_t v58 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v58 + 64);
  uint64_t v7 = alloca(v6);
  Swift::Int_optional v8 = alloca(v6);
  uint64_t v50 = &v44;
  uint64_t v46 = type metadata accessor for DataFrame.Slice(0);
  uint64_t v51 = *(void *)(v46 - 8);
  int64_t v9 = *(void *)(v51 + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v48 = &v44;
  uint64_t v12 = alloca(v9);
  char v13 = alloca(v9);
  uint64_t v53 = &v44;
  uint64_t v14 = alloca(v9);
  char v15 = alloca(v9);
  uint64_t v52 = &v44;
  int64_t v16 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame.Slice?)
                              - 8)
                  + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v47 = &v44;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  char v49 = &v44;
  uint64_t v21 = type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData(0);
  int64_t v22 = *(void *)(*(void *)(v21 - 8) + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(v4, (uint64_t)&v44);
  switch(swift_getEnumCaseMultiPayload(&v44, v21))
  {
    case 0u:
      uint64_t v58 = v5;
      uint64_t v25 = (uint64_t)v49;
      uint64_t v26 = (uint64_t)v52;
      DataFrame.randomSplit(strategy:)((uint64_t)v49, (uint64_t)v52, (uint64_t)&v44);
      uint64_t v27 = v53;
      uint64_t v28 = v46;
      uint64_t v57 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 16);
      v57(v53, v26, v46);
      DataFrame.init(_:)(v27);
      uint64_t v29 = (uint64_t)v47;
      outlined init with copy of DataFrame.Slice?(v25, (uint64_t)v47);
      if (__swift_getEnumTagSinglePayload(v29, 1, v28) == 1)
      {
        __swift_storeEnumTagSinglePayload((uint64_t)v56, 1, 1, v58);
        uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v51 + 8);
      }
      else
      {
        Swift::Int v40 = v53;
        uint64_t v41 = v51;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 32))(v53, v29, v28);
        Swift::Bool v42 = v48;
        v57(v48, (uint64_t)v40, v28);
        uint64_t v43 = (uint64_t)v56;
        DataFrame.init(_:)(v42);
        uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v41 + 8);
        v30(v53, v28);
        __swift_storeEnumTagSinglePayload(v43, 0, 1, v58);
      }
      v30(v52, v28);
      return outlined destroy of DataFrame.Slice?((uint64_t)v49);
    case 1u:
      uint64_t v35 = v44;
      char v36 = v45;
      (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
      uint64_t v44 = v35;
      char v45 = v36;
      uint64_t v37 = (uint64_t)v56;
      DataFrame.init(_:)((uint64_t)&v44);
      uint64_t v33 = v37;
      goto LABEL_10;
    case 2u:
      char v31 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v58 + 32);
      v31(v50, &v44, v5);
      if (DataFrameProtocol.isEmpty.getter(v5, &protocol witness table for DataFrame))
      {
        uint64_t v32 = v58;
        (*(void (**)(uint64_t *, uint64_t))(v58 + 8))(v50, v5);
        (*(void (**)(uint64_t, void, uint64_t))(v32 + 16))(v54, v57, v5);
LABEL_7:
        uint64_t v33 = (uint64_t)v56;
        uint64_t v34 = 1;
      }
      else
      {
        (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
        uint64_t v38 = (uint64_t)v56;
        v31(v56, v50, v5);
        uint64_t v33 = v38;
LABEL_10:
        uint64_t v34 = 0;
      }
      return __swift_storeEnumTagSinglePayload(v33, v34, 1, v5);
    case 3u:
      (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
      goto LABEL_7;
  }
}

void MLBoostedTreeClassifier.predictions(from:)(uint64_t a1)
{
  uint64_t v3 = v2;
  uint64_t v14 = v1;
  uint64_t v5 = type metadata accessor for DataFrame(0);
  uint64_t v13 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v13 + 64);
  uint64_t v7 = alloca(v6);
  Swift::Int_optional v8 = alloca(v6);
  char v15 = &v12;
  uint64_t v9 = type metadata accessor for MLBoostedTreeClassifier(0);
  DataFrame.validateContainsColumns(_:context:)(*(Swift::OpaquePointer *)((char *)v3 + *(int *)(v9 + 28)), (Swift::String)__PAIR128__(0xE700000000000000, 0x65727574616546));
  if (!v10)
  {
    AnyTreeClassifierModel.applied(to:eventHandler:)(a1, 0, 0);
    int64_t v11 = v15;
    DataFrame.subscript.getter(*v3, v3[1]);
    (*(void (**)(uint64_t *, uint64_t))(v13 + 8))(v11, v5);
  }
}

uint64_t type metadata accessor for MLBoostedTreeClassifier(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLBoostedTreeClassifier;
  if (!type metadata singleton initialization cache for MLBoostedTreeClassifier) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLBoostedTreeClassifier);
  }
  return result;
}

uint64_t MLBoostedTreeClassifier.predictions(from:)(uint64_t a1, __m128 a2)
{
  uint64_t v15 = v3;
  uint64_t v16 = v2;
  uint64_t v17 = type metadata accessor for DataFrame(0);
  uint64_t v18 = *(void *)(v17 - 8);
  int64_t v4 = *(void *)(v18 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  int64_t v7 = *(void *)(*(void *)(type metadata accessor for AnyColumn(0) - 8) + 64);
  Swift::Int_optional v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  char v10 = *(unsigned char *)(a1 + 8);
  uint64_t v13 = *(void *)a1;
  char v14 = v10;
  outlined copy of Result<_DataTable, Error>(v13, v10);
  DataFrame.init(_:)((uint64_t)&v13);
  uint64_t v11 = v15;
  MLBoostedTreeClassifier.predictions(from:)((uint64_t)&v13);
  if (v11) {
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v18 + 8))(&v13, v17);
  }
  *(double *)a2.i64 = (*(double (**)(uint64_t *, uint64_t))(v18 + 8))(&v13, v17);
  return MLUntypedColumn.init(_:convertArraysToShapedArrays:)((uint64_t)&v13, 1, a2);
}

uint64_t MLBoostedTreeClassifier.evaluation(on:)(uint64_t a1)
{
  int64_t v4 = v1;
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for AnyClassificationMetrics(0) - 8) + 64);
  int64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v8 = type metadata accessor for MLBoostedTreeClassifier(0);
  uint64_t v9 = *(int *)(v8 + 28);
  uint64_t v28 = v2;
  v10._uint64_t rawValue = *(void **)(v2 + v9);
  uint64_t v27 = a1;
  DataFrame.validateContainsColumns(_:context:)(v10, (Swift::String)__PAIR128__(0xE700000000000000, 0x65727574616546));
  if (v11) {
    goto LABEL_6;
  }
  uint64_t v29 = &v25;
  uint64_t v30 = v4;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t inited = (void *)swift_initStackObject(v12, v26);
  inited[2] = 1;
  inited[3] = 2;
  uint64_t v14 = *(int *)(v8 + 24);
  uint64_t v15 = *(void *)(v28 + v14 + 8);
  inited[4] = *(void *)(v28 + v14);
  inited[5] = v15;
  swift_bridgeObjectRetain(v15);
  uint64_t v16 = v27;
  DataFrame.validateContainsColumns(_:context:)((Swift::OpaquePointer)inited, (Swift::String)__PAIR128__(0xE500000000000000, 0x6C6562614CLL));
  if (v11)
  {
    swift_setDeallocating(inited);
    specialized _ContiguousArrayStorage.__deallocating_deinit();
    int64_t v4 = v30;
LABEL_6:
    void *v4 = v11;
    uint64_t v18 = type metadata accessor for MLClassifierMetrics.Contents(0);
    uint64_t v19 = 2;
    uint64_t v20 = v4;
    uint64_t v21 = v18;
    return swift_storeEnumTagMultiPayload(v20, v21, v19);
  }
  swift_setDeallocating(inited);
  specialized _ContiguousArrayStorage.__deallocating_deinit();
  uint64_t v17 = v29;
  AnyTreeClassifierModel.computeMetrics(on:)(v16);
  uint64_t v23 = (uint64_t)v17;
  uint64_t v24 = (uint64_t)v30;
  outlined init with take of MLClassifierMetrics(v23, (uint64_t)v30, type metadata accessor for AnyClassificationMetrics);
  uint64_t v20 = (void *)v24;
  uint64_t v21 = type metadata accessor for MLClassifierMetrics.Contents(0);
  uint64_t v19 = 0;
  return swift_storeEnumTagMultiPayload(v20, v21, v19);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  int64_t v4;
  void *v5;
  void *v6;
  char v7;
  uint64_t v9;
  char v10;
  uint64_t v11;

  uint64_t v11 = v1;
  uint64_t v2 = type metadata accessor for DataFrame(0);
  uint64_t v3 = *(void *)(v2 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  int64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  int64_t v7 = *(unsigned char *)(a1 + 8);
  uint64_t v9 = *(void *)a1;
  Swift::OpaquePointer v10 = v7;
  outlined copy of Result<_DataTable, Error>(v9, v7);
  DataFrame.init(_:)((uint64_t)&v9);
  MLBoostedTreeClassifier.evaluation(on:)((uint64_t)&v9);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v3 + 8))(&v9, v2);
}

uint64_t MLBoostedTreeClassifier.write(to:metadata:)(uint64_t a1, uint64_t *a2)
{
  uint64_t v63 = v2;
  uint64_t v62 = v3;
  uint64_t v61 = a1;
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for AnyTreeClassifierModel(0) - 8) + 64);
  int64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  char v45 = &v40;
  uint64_t v54 = type metadata accessor for Model(0);
  uint64_t v53 = *(void *)(v54 - 8);
  int64_t v7 = *(void *)(v53 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  Swift::Bool v42 = &v40;
  uint64_t v10 = type metadata accessor for URL(0);
  uint64_t v11 = *(void *)(v10 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v47 = *a2;
  uint64_t v43 = a2[1];
  unint64_t v48 = a2[2];
  char v49 = (char *)a2[3];
  uint64_t v50 = a2[4];
  uint64_t v51 = a2[5];
  uint64_t v46 = a2[6];
  unint64_t v52 = a2[7];
  uint64_t v15 = a2[8];
  uint64_t v16 = v63;
  uint64_t result = static _ValidationUtilities.validateWriteLocation(atURL:defaultName:fileExtension:)(v61, 0xD000000000000015, (unint64_t)("ierTrainingSessionDelegate" + 0x8000000000000000), 0x6C65646F6D6C6DLL, (void *)0xE700000000000000);
  if (!v16)
  {
    uint64_t v63 = 0;
    uint64_t v56 = &v40;
    uint64_t v57 = v10;
    uint64_t v55 = v11;
    outlined init with copy of MLTrainingSessionParameters(v62, (uint64_t)v45, type metadata accessor for AnyTreeClassifierModel);
    uint64_t v18 = v43;
    uint64_t v44 = v15;
    if (v43)
    {
      uint64_t v19 = v47;
      uint64_t v61 = v43;
      uint64_t v20 = v48;
      unint64_t v21 = v48;
      uint64_t v22 = (uint64_t)v49;
      uint64_t v60 = v49;
      uint64_t v23 = v50;
      uint64_t v24 = v50;
      uint64_t v25 = v51;
      uint64_t v58 = v51;
      uint64_t v26 = v46;
      uint64_t v27 = v46;
      uint64_t v28 = v52;
      unint64_t v59 = v52;
      uint64_t v62 = v15;
      uint64_t v29 = v47;
    }
    else
    {
      uint64_t v30 = NSFullUserName();
      char v31 = v30;
      uint64_t v29 = static String._unconditionallyBridgeFromObjectiveC(_:)(v31);
      uint64_t v61 = v32;

      uint64_t v60 = "RandomForestRegressor" + 0x8000000000000000;
      unint64_t v21 = 0xD000000000000033;
      unint64_t v59 = 0xE100000000000000;
      uint64_t v27 = 49;
      uint64_t v24 = 0;
      uint64_t v58 = 0;
      uint64_t v62 = 0;
      uint64_t v26 = v46;
      uint64_t v19 = v47;
      uint64_t v20 = v48;
      uint64_t v22 = (uint64_t)v49;
      uint64_t v23 = v50;
      uint64_t v25 = v51;
      uint64_t v28 = v52;
    }
    v41[0] = v29;
    v41[1] = v61;
    v41[2] = v21;
    v41[3] = v60;
    v41[4] = v24;
    v41[5] = v58;
    v41[6] = v27;
    v41[7] = v59;
    char v41[8] = v62;
    outlined copy of MLModelMetadata?(v19, v18, v20, v22, v23, v25, v26, v28, v44);
    uint64_t v33 = v42;
    uint64_t v34 = (uint64_t)v45;
    uint64_t v35 = v63;
    specialized CoreMLExportable.export(metadata:)((uint64_t)v41);
    if (v35)
    {
      uint64_t v63 = v35;
      swift_bridgeObjectRelease(v59);
      swift_bridgeObjectRelease((_BYTE)v60);
      swift_bridgeObjectRelease(v61);
      swift_bridgeObjectRelease(v58);
      swift_bridgeObjectRelease(v62);
      outlined destroy of MLActivityClassifier.ModelParameters(v34, type metadata accessor for AnyTreeClassifierModel);
      uint64_t v36 = v55;
      uint64_t v37 = v57;
      BOOL v39 = v56;
    }
    else
    {
      swift_bridgeObjectRelease(v59);
      swift_bridgeObjectRelease((_BYTE)v60);
      swift_bridgeObjectRelease(v61);
      swift_bridgeObjectRelease(v58);
      swift_bridgeObjectRelease(v62);
      outlined destroy of MLActivityClassifier.ModelParameters(v34, type metadata accessor for AnyTreeClassifierModel);
      uint64_t v38 = v56;
      Model.write(to:)(v56);
      uint64_t v63 = 0;
      uint64_t v36 = v55;
      (*(void (**)(uint64_t *, uint64_t))(v53 + 8))(v33, v54);
      BOOL v39 = v38;
      uint64_t v37 = v57;
    }
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v36 + 8))(v39, v37);
  }
  return result;
}

uint64_t MLBoostedTreeClassifier.write(toFile:metadata:)(uint64_t a1, uint64_t a2, long long *a3)
{
  uint64_t v23 = v3;
  uint64_t v25 = a2;
  uint64_t v24 = a1;
  uint64_t v26 = type metadata accessor for URL.DirectoryHint(0);
  uint64_t v27 = *(void *)(v26 - 8);
  int64_t v5 = *(void *)(v27 + 64);
  int64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v11 = type metadata accessor for URL(0);
  uint64_t v29 = *(void *)(v11 - 8);
  int64_t v12 = *(void *)(v29 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v28 = *((void *)a3 + 8);
  long long v19 = *a3;
  long long v20 = a3[1];
  long long v21 = a3[2];
  long long v22 = a3[3];
  uint64_t v30 = v11;
  __swift_storeEnumTagSinglePayload((uint64_t)v17, 1, 1, v11);
  (*(void (**)(_OWORD *, void, uint64_t))(v27 + 104))(v17, enum case for URL.DirectoryHint.inferFromPath(_:), v26);
  uint64_t v15 = v25;
  swift_bridgeObjectRetain(v25);
  URL.init(filePath:directoryHint:relativeTo:)(v24, v15, v17, v17);
  v17[0] = v19;
  v17[1] = v20;
  long long v17[2] = v21;
  v17[3] = v22;
  uint64_t v18 = v28;
  MLBoostedTreeClassifier.write(to:metadata:)((uint64_t)v17, (uint64_t *)v17);
  return (*(uint64_t (**)(_OWORD *, uint64_t))(v29 + 8))(v17, v30);
}

id MLBoostedTreeClassifier.model.getter()
{
  uint64_t v1 = type metadata accessor for MLBoostedTreeClassifier(0);
  return *(id *)(v0 + *(int *)(v1 + 20));
}

unint64_t MLBoostedTreeClassifier.description.getter()
{
  return MLBoostedTreeClassifier.debugDescription.getter();
}

unint64_t MLBoostedTreeClassifier.debugDescription.getter()
{
  uint64_t v1 = v0;
  v25._char object = (void *)type metadata accessor for MLClassifierMetrics.Contents(0);
  int64_t v2 = *(void *)(*((void *)v25._object - 1) + 64);
  uint64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  uint64_t v5 = type metadata accessor for MLBoostedTreeClassifier(0);
  v25._uint64_t countAndFlagsBits = MLBoostedTreeClassifier.ModelParameters.description.getter();
  int64_t v7 = v6;
  v22._uint64_t countAndFlagsBits = MLClassifierMetrics.description.getter();
  v22._char object = v8;
  uint64_t v9 = *(int *)(v5 + 40);
  uint64_t v10 = v7;
  outlined init with copy of MLTrainingSessionParameters(v1 + v9, (uint64_t)&v20, type metadata accessor for MLClassifierMetrics.Contents);
  LODWORD(v7) = swift_getEnumCaseMultiPayload(&v20, v25._object);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v20, type metadata accessor for MLClassifierMetrics.Contents);
  v25._char object = (void *)MLClassifierMetrics.description.getter();
  int64_t v12 = v11;
  unint64_t v23 = 0xD000000000000022;
  uint64_t v24 = "BoostedTreeClassifier" + 0x8000000000000000;
  v13._uint64_t countAndFlagsBits = v25._countAndFlagsBits;
  v25._uint64_t countAndFlagsBits = (uint64_t)v10;
  v13._char object = v10;
  String.append(_:)(v13);
  v21._uint64_t countAndFlagsBits = 0xD00000000000001ELL;
  v21._char object = "ActivityClassifier\n\nParameters\n" + 0x8000000000000000;
  char object = (char)v22._object;
  String.append(_:)(v22);
  char v15 = (char)v21._object;
  String.append(_:)(v21);
  swift_bridgeObjectRelease(v15);
  if (v7 > 1)
  {
    char v18 = object;
  }
  else
  {
    v21._uint64_t countAndFlagsBits = 0xD000000000000020;
    v21._char object = "\nPerformance on Training Data\n" + 0x8000000000000000;
    v16._uint64_t countAndFlagsBits = (uint64_t)v25._object;
    v16._char object = v12;
    String.append(_:)(v16);
    char v17 = (char)v21._object;
    String.append(_:)(v21);
    swift_bridgeObjectRelease(object);
    char v18 = (char)v12;
    LOBYTE(v12) = v17;
  }
  swift_bridgeObjectRelease(v18);
  swift_bridgeObjectRelease((_BYTE)v12);
  swift_bridgeObjectRelease(v25._countAndFlagsBits);
  return v23;
}

NSAttributedString MLBoostedTreeClassifier.playgroundDescription.getter()
{
  uint64_t v1 = v0;
  uint64_t v2 = type metadata accessor for NSAttributedString();
  v3._uint64_t countAndFlagsBits = MLBoostedTreeClassifier.debugDescription.getter();
  v3._char object = v4;
  result.super.Class isa = NSAttributedString.__allocating_init(string:)(v3).super.isa;
  v1[3].super.Class isa = (Class)v2;
  v1->super.Class isa = result.super.isa;
  return result;
}

void key path setter for MLBoostedTreeClassifier.model : MLBoostedTreeClassifier(id *a1)
{
  id v1 = *a1;
  MLBoostedTreeClassifier.model.setter((uint64_t)v1);
}

void MLBoostedTreeClassifier.model.setter(uint64_t a1)
{
  uint64_t v2 = *(int *)(type metadata accessor for MLBoostedTreeClassifier(0) + 20);

  *(void *)(v1 + v2) = a1;
}

void (*MLBoostedTreeClassifier.model.modify(uint64_t a1))(uint64_t a1, char a2)
{
  *(void *)(a1 + 8) = v1;
  uint64_t v3 = *(int *)(type metadata accessor for MLBoostedTreeClassifier(0) + 20);
  *(_DWORD *)(a1 + 16) = v3;
  int64_t v4 = *(void **)(v1 + v3);
  *(void *)a1 = v4;
  v4;
  return MLActivityClassifier.model.modify;
}

uint64_t MLBoostedTreeClassifier.targetColumn.getter()
{
  uint64_t v1 = *(int *)(type metadata accessor for MLBoostedTreeClassifier(0) + 24);
  uint64_t v2 = *(void *)(v0 + v1);
  swift_bridgeObjectRetain(*(void *)(v0 + v1 + 8));
  return v2;
}

uint64_t MLBoostedTreeClassifier.targetColumn.setter(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(int *)(type metadata accessor for MLBoostedTreeClassifier(0) + 24);
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v2 + v3 + 8));
  *(void *)(v2 + v3) = a1;
  *(void *)(v2 + v3 + 8) = a2;
  return result;
}

void (*MLBoostedTreeClassifier.targetColumn.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLBoostedTreeClassifier.featureColumns.getter()
{
  uint64_t v1 = type metadata accessor for MLBoostedTreeClassifier(0);
  return swift_bridgeObjectRetain(*(void *)(v0 + *(int *)(v1 + 28)));
}

uint64_t MLBoostedTreeClassifier.featureColumns.setter(uint64_t a1)
{
  uint64_t v2 = *(int *)(type metadata accessor for MLBoostedTreeClassifier(0) + 28);
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v1 + v2));
  *(void *)(v1 + v2) = a1;
  return result;
}

void (*MLBoostedTreeClassifier.featureColumns.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLBoostedTreeClassifier.modelParameters.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLBoostedTreeClassifier(0);
  return outlined init with copy of MLBoostedTreeClassifier.ModelParameters(v1 + *(int *)(v3 + 32), v2);
}

uint64_t MLBoostedTreeClassifier.trainingMetrics.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLBoostedTreeClassifier(0);
  return outlined init with copy of MLTrainingSessionParameters(v1 + *(int *)(v3 + 36), v2, type metadata accessor for MLClassifierMetrics);
}

uint64_t MLBoostedTreeClassifier.validationMetrics.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLBoostedTreeClassifier(0);
  return outlined init with copy of MLTrainingSessionParameters(v1 + *(int *)(v3 + 40), v2, type metadata accessor for MLClassifierMetrics);
}

uint64_t static MLBoostedTreeClassifier._defaultSessionParameters.getter()
{
  uint64_t v1 = v0;
  if (one-time initialization token for _defaultSessionParameters != -1) {
    swift_once(&one-time initialization token for _defaultSessionParameters, one-time initialization function for _defaultSessionParameters);
  }
  uint64_t v2 = type metadata accessor for MLTrainingSessionParameters(0);
  uint64_t v3 = __swift_project_value_buffer(v2, (uint64_t)static MLBoostedTreeClassifier._defaultSessionParameters);
  return outlined init with copy of MLTrainingSessionParameters(v3, v1, type metadata accessor for MLTrainingSessionParameters);
}

uint64_t MLBoostedTreeClassifier.init(_:targetColumn:featureColumns:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v6[7] = a6;
  v6[6] = a5;
  v6[5] = a4;
  void v6[4] = a3;
  v6[3] = a2;
  v6[2] = a1;
  return swift_task_switch(MLBoostedTreeClassifier.init(_:targetColumn:featureColumns:parameters:), 0, 0);
}

uint64_t MLBoostedTreeClassifier.init(_:targetColumn:featureColumns:parameters:)()
{
  uint64_t v14 = *(void *)(v0 + 48);
  long long v13 = *(_OWORD *)(v0 + 32);
  uint64_t v1 = *(void *)(v0 + 16);
  uint64_t v2 = (int *)type metadata accessor for MLBoostedTreeClassifier(0);
  *(void *)(v0 + 64) = v2;
  *(_DWORD *)(v0 + 96) = v2[9];
  MLClassifierMetrics.init()();
  uint64_t v3 = v2[10];
  *(_DWORD *)(v0 + 100) = v3;
  uint64_t v4 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v5 = swift_allocError(&type metadata for MLCreateError, v4, 0, 0);
  *(void *)uint64_t v6 = 0xD0000000000000C0;
  *(void *)(v6 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v6 + 16) = 0;
  *(_OWORD *)(v6 + 32) = 0;
  *(unsigned char *)(v6 + 48) = 0;
  *(void *)(v1 + v3) = v5;
  uint64_t v7 = type metadata accessor for MLClassifierMetrics.Contents(0);
  swift_storeEnumTagMultiPayload(v1 + v3, v7, 2);
  uint64_t v8 = v2[7];
  *(_DWORD *)(v0 + 104) = v8;
  *(void *)(v1 + v8) = v14;
  uint64_t v9 = v2[6];
  *(_DWORD *)(v0 + 108) = v9;
  *(_OWORD *)(v1 + v9) = v13;
  uint64_t v10 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                          + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v11 = (void *)swift_task_alloc(dword_3AE24C);
  *(void *)(v0 + 72) = v11;
  *uint64_t v11 = v0;
  v11[1] = MLBoostedTreeClassifier.init(_:targetColumn:featureColumns:parameters:);
  return v10();
}

{
  uint64_t v0;
  uint64_t v1;
  const void *v2;
  uint64_t v3;
  uint64_t v4;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(const void **)(v0 + 56);
  uint64_t v3 = *(void *)(v0 + 16);
  uint64_t v4 = *(void *)(v0 + 24);
  *(void *)(v3 + *(int *)(v1 + 20)) = *(void *)(v0 + 88);
  outlined init with take of MLClassifierMetrics(v4, v3, type metadata accessor for AnyTreeClassifierModel);
  qmemcpy((void *)(v3 + *(int *)(v1 + 32)), v2, 0x70uLL);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;

  uint64_t v7 = *(int *)(v0 + 108);
  uint64_t v6 = *(int *)(v0 + 104);
  uint64_t v1 = *(void *)(v0 + 16);
  uint64_t v2 = *(void *)(v0 + 24);
  uint64_t v3 = v1 + *(int *)(v0 + 100);
  uint64_t v4 = v1 + *(int *)(v0 + 96);
  outlined destroy of MLBoostedTreeClassifier.ModelParameters(*(void *)(v0 + 56));
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for AnyTreeClassifierModel);
  swift_bridgeObjectRelease(*(void *)(v1 + v7 + 8));
  swift_bridgeObjectRelease(*(void *)(v1 + v6));
  outlined destroy of MLActivityClassifier.ModelParameters(v4, type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLClassifierMetrics);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLBoostedTreeClassifier.init(_:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  uint64_t v5 = *(void *)(*v2 + 72);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 80) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = MLBoostedTreeClassifier.init(_:targetColumn:featureColumns:parameters:);
  }
  else
  {
    *(void *)(v4 + 88) = a1;
    uint64_t v6 = MLBoostedTreeClassifier.init(_:targetColumn:featureColumns:parameters:);
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t MLBoostedTreeClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(void (*a1)(uint64_t *, uint64_t, uint64_t), uint64_t a2, char *a3, void (*a4)(_OWORD *, void *, uint64_t), uint64_t a5)
{
  uint64_t v206 = a4;
  _ = a3;
  uint64_t v7 = v5;
  v210._uint64_t countAndFlagsBits = a2;
  uint64_t v205 = (char *)v6;
  uint64_t v216 = a5;
  v211 = a1;
  int64_t v8 = *(void *)(*(void *)(type metadata accessor for AnyClassificationMetrics(0) - 8) + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  v188 = v162;
  uint64_t v11 = alloca(v8);
  int64_t v12 = alloca(v8);
  uint64_t v184 = v162;
  int64_t v13 = *(void *)(*(void *)(type metadata accessor for MLClassifierMetrics(0) - 8) + 64);
  uint64_t v14 = alloca(v13);
  char v15 = alloca(v13);
  uint64_t v189 = v162;
  Swift::String v16 = alloca(v13);
  char v17 = alloca(v13);
  uint64_t v185 = v162;
  uint64_t v182 = *(void *)(type metadata accessor for AnyTreeClassifierModel(0) - 8);
  int64_t v18 = *(void *)(v182 + 64);
  long long v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v180 = v162;
  int64_t v181 = v18;
  Swift::String v21 = alloca(v18);
  Swift::String v22 = alloca(v18);
  v208 = v162;
  int64_t v23 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                              - 8)
                  + 64);
  uint64_t v24 = alloca(v23);
  Swift::String v25 = alloca(v23);
  v177 = v162;
  int64_t v26 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?)
                              - 8)
                  + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  v199 = v162;
  uint64_t v193 = type metadata accessor for AnyColumn(0);
  int64_t v29 = *(void *)(*(void *)(v193 - 8) + 64);
  uint64_t v30 = alloca(v29);
  char v31 = alloca(v29);
  v197 = v162;
  uint64_t v32 = alloca(v29);
  uint64_t v33 = alloca(v29);
  unint64_t v203 = v162;
  uint64_t v34 = alloca(v29);
  uint64_t v35 = alloca(v29);
  uint64_t v202 = (uint64_t)v162;
  int64_t v36 = *(void *)(*(void *)(type metadata accessor for AnyTreeClassifier(0) - 8) + 64);
  uint64_t v37 = alloca(v36);
  uint64_t v38 = alloca(v36);
  v207 = v162;
  uint64_t v218 = type metadata accessor for DataFrame(0);
  uint64_t v201 = *(void *)(v218 - 8);
  int64_t v39 = *(void *)(v201 + 64);
  uint64_t v40 = alloca(v39);
  uint64_t v41 = alloca(v39);
  char v187 = v162;
  Swift::Bool v42 = alloca(v39);
  uint64_t v43 = alloca(v39);
  uint64_t v200 = (void (*)(uint64_t *, uint64_t, uint64_t))v162;
  uint64_t v44 = alloca(v39);
  char v45 = alloca(v39);
  v196 = v162;
  uint64_t v46 = alloca(v39);
  uint64_t v47 = alloca(v39);
  v210._char object = v162;
  v220 = (void *)type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
  int64_t v48 = *(void *)(*(v220 - 1) + 64);
  char v49 = alloca(v48);
  uint64_t v50 = alloca(v48);
  v219 = v162;
  uint64_t v209 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
  int64_t v51 = *(void *)(*(void *)(v209 - 8) + 64);
  unint64_t v52 = alloca(v51);
  uint64_t v53 = alloca(v51);
  char v186 = v162;
  uint64_t v54 = alloca(v51);
  uint64_t v55 = alloca(v51);
  uint64_t v183 = v162;
  uint64_t v56 = alloca(v51);
  uint64_t v57 = alloca(v51);
  unsigned int v192 = v162;
  uint64_t v58 = alloca(v51);
  unint64_t v59 = alloca(v51);
  char v179 = v162;
  uint64_t v60 = alloca(v51);
  uint64_t v61 = alloca(v51);
  uint64_t v176 = v162;
  uint64_t v62 = alloca(v51);
  uint64_t v63 = alloca(v51);
  v217 = v162;
  uint64_t v213 = type metadata accessor for BoostedTreeConfiguration(0);
  uint64_t v215 = *(void *)(v213 - 8);
  int64_t v64 = *(void *)(v215 + 64);
  uint64_t v65 = alloca(v64);
  uint64_t v66 = alloca(v64);
  uint64_t v178 = v162;
  uint64_t v67 = alloca(v64);
  uint64_t v68 = alloca(v64);
  uint64_t v69 = type metadata accessor for MLBoostedTreeClassifier(0);
  uint64_t v190 = (uint64_t)v7 + *(int *)(v69 + 36);
  MLClassifierMetrics.init()();
  uint64_t v194 = v69;
  uint64_t v70 = *(int *)(v69 + 40);
  uint64_t v71 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v72 = swift_allocError(&type metadata for MLCreateError, v71, 0, 0);
  *(void *)uint64_t v73 = 0xD0000000000000C0;
  *(void *)(v73 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v73 + 16) = 0;
  *(_OWORD *)(v73 + 32) = 0;
  *(unsigned char *)(v73 + 48) = 0;
  uint64_t v195 = v7;
  *(uint64_t *)((char *)v7 + v70) = v72;
  uint64_t v74 = type metadata accessor for MLClassifierMetrics.Contents(0);
  uint64_t v191 = (uint64_t)v7 + v70;
  uint64_t v198 = v74;
  swift_storeEnumTagMultiPayload((char *)v7 + v70, v74, 2);
  uint64_t v75 = v216;
  outlined init with copy of MLBoostedTreeClassifier.ModelParameters(v216, (uint64_t)v162);
  BoostedTreeConfiguration.init()();
  BoostedTreeConfiguration.maximumDepth.setter(v163);
  BoostedTreeConfiguration.maximumIterations.setter(v164);
  BoostedTreeConfiguration.minimumLossReduction.setter(v165);
  BoostedTreeConfiguration.minimumChildWeight.setter(v166);
  BoostedTreeConfiguration.randomSeed.setter(v167);
  BoostedTreeConfiguration.learningRate.setter(v168);
  BoostedTreeConfiguration.earlyStoppingIterationCount.setter(v169, v170);
  BoostedTreeConfiguration.rowSubsample.setter(v171);
  double v76 = v172;
  v214 = v162;
  BoostedTreeConfiguration.columnSubsample.setter(v172);
  outlined destroy of MLBoostedTreeClassifier.ModelParameters((uint64_t)v162);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v75, (uint64_t)&v174, &demangling cache variable for type metadata for Any?);
  if (!v175) {
    BUG();
  }
  uint64_t v77 = v217;
  uint64_t v78 = (char *)v217 + *(int *)(v209 + 48);
  outlined init with take of Any(&v174, v162);
  swift_dynamicCast(v219, v162, (char *)&type metadata for Any + 8, v220, 7);
  uint64_t v79 = v211;
  uint64_t v80 = (uint64_t)v205;
  MLBoostedTreeClassifier.ModelParameters.ValidationData.generateDataFrames(trainingData:)((uint64_t)v77, (uint64_t)v78, v211);
  if (v80)
  {
    swift_bridgeObjectRelease((_BYTE)_);
    swift_bridgeObjectRelease((_BYTE)v206);
    outlined destroy of MLBoostedTreeClassifier.ModelParameters(v216);
    (*(void (**)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))(v201 + 8))(v79, v218);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v219, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
    (*(void (**)(_OWORD *, uint64_t))(v215 + 8))(v214, v213);
LABEL_5:
    outlined destroy of MLActivityClassifier.ModelParameters(v190, type metadata accessor for MLClassifierMetrics);
    return outlined destroy of MLActivityClassifier.ModelParameters(v191, type metadata accessor for MLClassifierMetrics);
  }
  uint64_t v205 = v78;
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v219, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
  char v81 = (char)v206;
  uint64_t v82 = static _FeatureUtilities.selectFeaturesFromTrainingData(trainingData:targetColumn:featureColumns:)((uint64_t)v77, v210._countAndFlagsBits, _, (uint64_t)v206);
  v219 = 0;
  uint64_t v83 = v218;
  v204 = v82;
  swift_bridgeObjectRelease(v81);
  uint64_t v85 = v176;
  uint64_t v86 = (uint64_t)v176 + *(int *)(v209 + 48);
  uint64_t v87 = v201;
  uint64_t v206 = *(void (**)(_OWORD *, void *, uint64_t))(v201 + 16);
  v206(v176, v217, v83);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v205, v86, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload(v86, 1, v83) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v86, &demangling cache variable for type metadata for DataFrame?);
    v220 = *(void **)(v87 + 8);
    ((void (*)(_OWORD *, uint64_t))v220)(v85, v83);
  }
  else
  {
    (*(void (**)(void *, uint64_t, uint64_t))(v87 + 32))(v210._object, v86, v83);
    v220 = *(void **)(v87 + 8);
    ((void (*)(_OWORD *, uint64_t))v220)(v85, v83);
    uint64_t v97 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
    uint64_t inited = (void *)swift_initStackObject(v97, v173);
    inited[2] = 1;
    inited[3] = 2;
    inited[4] = v210._countAndFlagsBits;
    char v99 = _;
    inited[5] = _;
    swift_bridgeObjectRetain((_BYTE)v99);
    DataFrame.validateContainsColumns(_:context:)((Swift::OpaquePointer)inited, (Swift::String)__PAIR128__(0xEE00726569666973, 0x73616C4365657254));
    if (v100)
    {
      swift_setDeallocating(inited);
      specialized _ContiguousArrayStorage.__deallocating_deinit();
      swift_bridgeObjectRelease((_BYTE)v99);
      swift_bridgeObjectRelease((_BYTE)v204);
      outlined destroy of MLBoostedTreeClassifier.ModelParameters(v216);
      uint64_t v101 = v218;
      uint64_t v102 = (void (*)(void *, uint64_t))v220;
      ((void (*)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))v220)(v211, v218);
      v102(v210._object, v101);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v217, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      (*(void (**)(_OWORD *, uint64_t))(v215 + 8))(v214, v213);
      goto LABEL_5;
    }
    swift_setDeallocating(inited);
    specialized _ContiguousArrayStorage.__deallocating_deinit();
    uint64_t v111 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any.Type>);
    uint64_t v112 = (void *)swift_allocObject(v111, 48, 7);
    v112[2] = 2;
    v112[3] = 4;
    v112[4] = &type metadata for String;
    v112[5] = &type metadata for Int;
    v113._uint64_t countAndFlagsBits = v210._countAndFlagsBits;
    v113._char object = v99;
    char object = v210._object;
    DataFrame.validateColumnTypes(_:_:context:)(v113, (Swift::OpaquePointer)v112, (Swift::String)__PAIR128__(0xEE00726569666973, 0x73616C4365657254));
    v219 = (_OWORD *)v115;
    if (v115)
    {
      swift_bridgeObjectRelease((_BYTE)v99);
      swift_bridgeObjectRelease((_BYTE)v204);
      swift_bridgeObjectRelease((_BYTE)v112);
      outlined destroy of MLBoostedTreeClassifier.ModelParameters(v216);
      uint64_t v116 = v218;
      char v117 = (void (*)(void *, uint64_t))v220;
      ((void (*)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))v220)(v211, v218);
      v117(object, v116);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v217, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      (*(void (**)(_OWORD *, uint64_t))(v215 + 8))(v214, v213);
      goto LABEL_5;
    }
    ((void (*)(void *, uint64_t))v220)(object, v218);
    swift_bridgeObjectRelease((_BYTE)v112);
  }
  char v88 = v179;
  char v89 = (char *)v179 + *(int *)(v209 + 48);
  char v90 = v217;
  v206(v179, v217, v218);
  uint64_t v91 = (uint64_t)v205;
  v210._char object = v89;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v205, (uint64_t)v89, &demangling cache variable for type metadata for DataFrame?);
  DataFrame.subscript.getter(v210._countAndFlagsBits, _);
  uint64_t v92 = v218;
  ((void (*)(_OWORD *, uint64_t))v220)(v88, v218);
  Swift::String v93 = v90;
  char v94 = v192;
  uint64_t v95 = (uint64_t)v192 + *(int *)(v209 + 48);
  v206(v192, v93, v92);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v91, v95, &demangling cache variable for type metadata for DataFrame?);
  uint64_t v96 = (uint64_t)v177;
  outlined init with take of DataFrame?(v95, (uint64_t)v177);
  if (__swift_getEnumTagSinglePayload(v96, 1, v92) == 1)
  {
    ((void (*)(_OWORD *, uint64_t))v220)(v94, v92);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v96, &demangling cache variable for type metadata for DataFrame?);
    __swift_storeEnumTagSinglePayload((uint64_t)v199, 1, 1, v193);
  }
  else
  {
    uint64_t v103 = (uint64_t)v199;
    DataFrame.subscript.getter(v210._countAndFlagsBits, _);
    uint64_t v104 = v96;
    uint64_t v105 = (void (*)(_OWORD *, uint64_t))v220;
    ((void (*)(uint64_t, uint64_t))v220)(v104, v92);
    __swift_storeEnumTagSinglePayload(v103, 0, 1, v193);
    v105(v192, v92);
  }
  uint64_t v106 = (uint64_t)_;
  uint64_t v107 = (uint64_t)v178;
  (*(void (**)(_OWORD *, _OWORD *, uint64_t))(v215 + 16))(v178, v214, v213);
  swift_bridgeObjectRetain(v106);
  uint64_t v108 = (uint64_t)v204;
  swift_bridgeObjectRetain((_BYTE)v204);
  uint64_t v109 = (uint64_t)v219;
  AnyTreeClassifier.init(trainingLabelsColumn:validationLabelsColumn:annotationColumnName:featureColumnNames:configuration:)(v202, (uint64_t)v199, v210._countAndFlagsBits, v106, v108, v107);
  if (v109)
  {
    swift_bridgeObjectRelease(v106);
    swift_bridgeObjectRelease(v108);
    outlined destroy of MLBoostedTreeClassifier.ModelParameters(v216);
    ((void (*)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))v220)(v211, v218);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v217, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    (*(void (**)(_OWORD *, uint64_t))(v215 + 8))(v214, v213);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v210._object, &demangling cache variable for type metadata for DataFrame?);
    goto LABEL_5;
  }
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v210._object, &demangling cache variable for type metadata for DataFrame?);
  uint64_t v110 = (uint64_t)v208;
  AnyTreeClassifier.fitted(to:validateOn:eventHandler:)(v217, (uint64_t)v205, 0, 0, v76);
  v219 = 0;
  uint64_t v118 = v110;
  if (!AnalyticsReporter.init()())
  {
    char v119 = v183;
    uint64_t v120 = (uint64_t)v183 + *(int *)(v209 + 48);
    uint64_t v121 = v218;
    v206(v183, v217, v218);
    uint64_t v122 = (uint64_t)v205;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v205, v120, &demangling cache variable for type metadata for DataFrame?);
    Swift::Int v123 = DataFrame.shape.getter(v122);
    uint64_t v124 = v119;
    uint64_t v118 = (uint64_t)v208;
    ((void (*)(_OWORD *, uint64_t))v220)(v124, v121);
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_boostedTreeClassifier, (Swift::String)__PAIR128__((unint64_t)("vectorized_features" + 0x8000000000000000), 0xD000000000000015), v123);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v120, &demangling cache variable for type metadata for DataFrame?);
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_boostedTreeClassifier, (Swift::String)__PAIR128__((unint64_t)("Number of Annotations" + 0x8000000000000000), 0xD000000000000010), *(void *)(*((void *)v207 + 3) + 16));
  }
  uint64_t v125 = v194;
  uint64_t v126 = *(int *)(v194 + 24);
  uint64_t v127 = v195;
  *(uint64_t *)((char *)v195 + v126) = v210._countAndFlagsBits;
  v210._uint64_t countAndFlagsBits = v126;
  *(uint64_t *)((char *)v127 + v126 + 8) = (uint64_t)_;
  _ = (char *)v127 + *(int *)(v125 + 32);
  outlined init with copy of MLBoostedTreeClassifier.ModelParameters(v216, (uint64_t)_);
  v210._char object = (void *)*(int *)(v125 + 28);
  *(uint64_t *)((char *)v127 + (unint64_t)v210._object) = (uint64_t)v204;
  uint64_t v128 = (uint64_t)v180;
  outlined init with copy of MLTrainingSessionParameters(v118, (uint64_t)v180, type metadata accessor for AnyTreeClassifierModel);
  uint64_t v129 = *(unsigned __int8 *)(v182 + 80);
  uint64_t v130 = ~*(unsigned __int8 *)(v182 + 80) & (v129 + 16);
  uint64_t v131 = swift_allocObject(&unk_39C7E8, v130 + v181, v129 | 7);
  outlined init with take of MLClassifierMetrics(v128, v131 + v130, type metadata accessor for AnyTreeClassifierModel);
  uint64_t v132 = (uint64_t)v219;
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLBoostedTreeClassifier.init(trainingData:targetColumn:featureColumns:parameters:), v131);
  if (v132)
  {
    v219 = (_OWORD *)v132;
    swift_release();
    outlined destroy of MLBoostedTreeClassifier.ModelParameters(v216);
    ((void (*)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))v220)(v211, v218);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v208, type metadata accessor for AnyTreeClassifierModel);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v207, type metadata accessor for AnyTreeClassifier);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v217, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    (*(void (**)(_OWORD *, uint64_t))(v215 + 8))(v214, v213);
LABEL_24:
    uint64_t v135 = (uint64_t)_;
    char v136 = (char *)v210._object;
    swift_bridgeObjectRelease(*(uint64_t *)((char *)v127 + v210._countAndFlagsBits + 8));
    swift_bridgeObjectRelease(*(void *)&v136[(void)v127]);
    outlined destroy of MLBoostedTreeClassifier.ModelParameters(v135);
    goto LABEL_5;
  }
  uint64_t v134 = v133;
  swift_release();
  uint64_t v202 = *(int *)(v194 + 20);
  *(uint64_t *)((char *)v127 + v202) = v134;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v208, (uint64_t)v127, type metadata accessor for AnyTreeClassifierModel);
  AnyTreeClassifierModel.applied(to:eventHandler:)((uint64_t)v217, 0, 0);
  v219 = 0;
  uint64_t v137 = *v127;
  uint64_t v138 = v127[1];
  DataFrame.subscript.getter(*v127, v138);
  uint64_t v139 = (uint64_t)v197;
  uint64_t v140 = v217;
  DataFrame.subscript.getter(v137, v138);
  uint64_t v141 = v184;
  AnyClassificationMetrics.init(_:_:)((uint64_t)v203, v139);
  uint64_t v142 = v218;
  ((void (*)(_OWORD *, uint64_t))v220)(v196, v218);
  uint64_t v143 = (uint64_t)v141;
  uint64_t v144 = (uint64_t)v185;
  outlined init with take of MLClassifierMetrics(v143, (uint64_t)v185, type metadata accessor for AnyClassificationMetrics);
  swift_storeEnumTagMultiPayload(v144, v198, 0);
  outlined assign with take of MLClassifierMetrics(v144, v190);
  uint64_t v145 = v186;
  uint64_t v146 = (uint64_t)v186 + *(int *)(v209 + 48);
  v206(v186, v140, v142);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v205, v146, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload(v146, 1, v142) == 1)
  {
    outlined destroy of MLBoostedTreeClassifier.ModelParameters(v216);
    uint64_t v147 = (uint64_t (*)(_OWORD *, uint64_t))v220;
    ((void (*)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))v220)(v211, v142);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v208, type metadata accessor for AnyTreeClassifierModel);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v207, type metadata accessor for AnyTreeClassifier);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v217, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    (*(void (**)(_OWORD *, uint64_t))(v215 + 8))(v214, v213);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v146, &demangling cache variable for type metadata for DataFrame?);
    return v147(v145, v142);
  }
  else
  {
    uint64_t v148 = (uint64_t)v200;
    (*(void (**)(_OWORD *, uint64_t, uint64_t))(v201 + 32))(v200, v146, v142);
    ((void (*)(_OWORD *, uint64_t))v220)(v145, v142);
    uint64_t v149 = v187;
    uint64_t v127 = v195;
    uint64_t v150 = (uint64_t)v219;
    AnyTreeClassifierModel.applied(to:eventHandler:)(v148, 0, 0);
    v219 = (_OWORD *)v150;
    uint64_t v151 = v214;
    if (v150)
    {
      outlined destroy of MLBoostedTreeClassifier.ModelParameters(v216);
      uint64_t v152 = v218;
      uint64_t v153 = (void (*)(_OWORD *, uint64_t))v220;
      ((void (*)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))v220)(v211, v218);
      v153(v200, v152);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v208, type metadata accessor for AnyTreeClassifierModel);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v207, type metadata accessor for AnyTreeClassifier);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v217, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      (*(void (**)(_OWORD *, uint64_t))(v215 + 8))(v151, v213);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v127, type metadata accessor for AnyTreeClassifierModel);

      goto LABEL_24;
    }
    uint64_t v209 = *v127;
    uint64_t v154 = v127[1];
    DataFrame.subscript.getter(v209, v154);
    uint64_t v155 = (uint64_t)v197;
    char v156 = v200;
    DataFrame.subscript.getter(v209, v154);
    uint64_t v157 = (uint64_t)v188;
    AnyClassificationMetrics.init(_:_:)((uint64_t)v203, v155);
    unint64_t v158 = v149;
    uint64_t v159 = v218;
    uint64_t v160 = (void (*)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))v220;
    ((void (*)(_OWORD *, uint64_t))v220)(v158, v218);
    outlined destroy of MLBoostedTreeClassifier.ModelParameters(v216);
    v160(v211, v159);
    v160(v156, v159);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v208, type metadata accessor for AnyTreeClassifierModel);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v207, type metadata accessor for AnyTreeClassifier);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v217, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    (*(void (**)(_OWORD *, uint64_t))(v215 + 8))(v214, v213);
    uint64_t v161 = (uint64_t)v189;
    outlined init with take of MLClassifierMetrics(v157, (uint64_t)v189, type metadata accessor for AnyClassificationMetrics);
    swift_storeEnumTagMultiPayload(v161, v198, 0);
    return outlined assign with take of MLClassifierMetrics(v161, v191);
  }
}

uint64_t closure #1 in MLBoostedTreeClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
  uint64_t v2 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                         + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v3 = (void *)swift_task_alloc(dword_3AE24C);
  *(void *)(v1 + 24) = v3;
  void *v3 = v1;
  v3[1] = closure #1 in MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:);
  return v2();
}

uint64_t MLBoostedTreeClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t *a1, uint64_t a2, char *a3, void (*a4)(_OWORD *, void *, uint64_t), uint64_t a5)
{
  int64_t v13 = a4;
  uint64_t v14 = a3;
  uint64_t v15 = a2;
  int64_t v6 = *(void *)(*(void *)(type metadata accessor for DataFrame(0) - 8) + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  char v9 = *((unsigned char *)a1 + 8);
  uint64_t v11 = *a1;
  char v12 = v9;
  DataFrame.init(_:)((uint64_t)&v11);
  outlined init with copy of MLBoostedTreeClassifier.ModelParameters(a5, (uint64_t)&v11);
  MLBoostedTreeClassifier.init(trainingData:targetColumn:featureColumns:parameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v11, v15, v14, v13, (uint64_t)&v11);
  return outlined destroy of MLBoostedTreeClassifier.ModelParameters(a5);
}

uint64_t MLBoostedTreeClassifier.init(checkpoint:)(uint64_t a1)
{
  uint64_t v71 = v2;
  uint64_t v88 = a1;
  uint64_t v3 = v1;
  uint64_t v84 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
  int64_t v4 = *(void *)(*(void *)(v84 - 8) + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  char v81 = v70;
  uint64_t v7 = alloca(v4);
  int64_t v8 = alloca(v4);
  uint64_t v80 = v70;
  int64_t v9 = *(void *)(*(void *)(type metadata accessor for BoostedTreeConfiguration(0) - 8) + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  char v89 = v70;
  uint64_t v90 = type metadata accessor for AnyTreeClassifier(0);
  int64_t v12 = *(void *)(*(void *)(v90 - 8) + 64);
  int64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v78 = v70;
  uint64_t v15 = alloca(v12);
  Swift::String v16 = alloca(v12);
  uint64_t v72 = v70;
  uint64_t v77 = *(void *)(type metadata accessor for AnyTreeClassifierModel(0) - 8);
  int64_t v17 = *(void *)(v77 + 64);
  int64_t v18 = alloca(v17);
  long long v19 = alloca(v17);
  uint64_t v82 = v70;
  uint64_t v20 = alloca(v17);
  Swift::String v21 = alloca(v17);
  double v76 = v70;
  Swift::String v22 = alloca(v17);
  int64_t v23 = alloca(v17);
  int64_t v75 = v17;
  uint64_t v24 = alloca(v17);
  Swift::String v25 = alloca(v17);
  uint64_t v83 = v70;
  uint64_t v26 = type metadata accessor for MLBoostedTreeClassifier(0);
  uint64_t v85 = v3 + *(int *)(v26 + 36);
  MLClassifierMetrics.init()();
  uint64_t v87 = (int *)v26;
  uint64_t v27 = *(int *)(v26 + 40);
  uint64_t v74 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v28 = swift_allocError(&type metadata for MLCreateError, v74, 0, 0);
  *(void *)uint64_t v29 = 0xD0000000000000C0;
  *(void *)(v29 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v29 + 16) = 0;
  *(_OWORD *)(v29 + 32) = 0;
  *(unsigned char *)(v29 + 48) = 0;
  uint64_t v79 = v3;
  *(void *)(v3 + v27) = v28;
  uint64_t v30 = type metadata accessor for MLClassifierMetrics.Contents(0);
  uint64_t v86 = v27 + v3;
  swift_storeEnumTagMultiPayload(v27 + v3, v30, 2);
  uint64_t v31 = *(unsigned __int8 *)(v88 + *(int *)(type metadata accessor for MLCheckpoint(0) + 20));
  uint64_t v73 = v70;
  switch(v31)
  {
    case 0:
      uint64_t v32 = 0x696C616974696E69;
      uint64_t v33 = (uint64_t)v89;
      uint64_t v34 = v90;
      unint64_t v35 = 0xEB0000000064657ALL;
      goto LABEL_9;
    case 1:
      uint64_t v32 = 0x6974636172747865;
      goto LABEL_6;
    case 2:
      swift_bridgeObjectRelease(0);
      uint64_t v33 = (uint64_t)v89;
      uint64_t v34 = v90;
      goto LABEL_10;
    case 3:
      uint64_t v32 = 0x697461756C617665;
LABEL_6:
      unint64_t v35 = 0xEA0000000000676ELL;
      break;
    case 4:
      unint64_t v35 = 0xEB00000000676E69;
      uint64_t v32 = 0x636E657265666E69;
      break;
    case 5:
      JUMPOUT(0x27CA0CLL);
  }
  uint64_t v33 = (uint64_t)v89;
  uint64_t v34 = v90;
LABEL_9:
  char v36 = _stringCompareWithSmolCheck(_:_:expecting:)(v32, v35, 0x676E696E69617274, 0xE800000000000000, 0);
  swift_bridgeObjectRelease(v35);
  if ((v36 & 1) == 0)
  {
    uint64_t v44 = v74;
    swift_allocError(&type metadata for MLCreateError, v74, 0, 0);
    *(void *)uint64_t v45 = 0xD000000000000042;
    *(void *)(v45 + 8) = "ifier\n\nParameters\n" + 0x8000000000000000;
    *(_OWORD *)(v45 + 16) = 0;
    *(_OWORD *)(v45 + 32) = 0;
    *(unsigned char *)(v45 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v44, v45, v46, v47, v48);
    char v49 = type metadata accessor for MLCheckpoint;
    uint64_t v50 = v88;
LABEL_16:
    outlined destroy of MLActivityClassifier.ModelParameters(v50, v49);
    uint64_t v60 = v86;
    outlined destroy of MLActivityClassifier.ModelParameters(v85, type metadata accessor for MLClassifierMetrics);
    return outlined destroy of MLActivityClassifier.ModelParameters(v60, type metadata accessor for MLClassifierMetrics);
  }
LABEL_10:
  uint64_t v37 = specialized _setUpCast<A, B>(_:)((uint64_t)&_swiftEmptySetSingleton);
  BoostedTreeConfiguration.init()();
  uint64_t v38 = (uint64_t)v72;
  AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)((uint64_t)v37, 0, 0xE000000000000000, (uint64_t)_swiftEmptyArrayStorage, v33);
  uint64_t v39 = lazy protocol witness table accessor for type AnyTreeClassifier and conformance AnyTreeClassifier();
  uint64_t v40 = v73;
  char v89 = (void *)v39;
  uint64_t v41 = v71;
  UpdatableSupervisedTabularEstimator.readWithOptimizer(from:)(v88, v34, v39);
  outlined destroy of MLActivityClassifier.ModelParameters(v38, type metadata accessor for AnyTreeClassifier);
  if (v41)
  {
    Swift::Bool v42 = specialized _setUpCast<A, B>(_:)((uint64_t)&_swiftEmptySetSingleton);
    BoostedTreeConfiguration.init()();
    uint64_t v43 = (uint64_t)v78;
    AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)((uint64_t)v42, 0, 0xE000000000000000, (uint64_t)_swiftEmptyArrayStorage, v33);
    UpdatableSupervisedTabularEstimator.readWithOptimizer(from:)(v88, v90, v89);
    outlined destroy of MLActivityClassifier.ModelParameters(v43, type metadata accessor for AnyTreeClassifier);
    swift_errorRelease(v41);
    uint64_t v51 = (uint64_t)v82;
  }
  else
  {
    uint64_t v51 = (uint64_t)v40;
  }
  uint64_t v90 = 0;
  uint64_t v52 = (uint64_t)v83;
  outlined init with take of MLClassifierMetrics(v51, (uint64_t)v83, type metadata accessor for AnyTreeClassifierModel);
  uint64_t v53 = (uint64_t)v76;
  outlined init with copy of MLTrainingSessionParameters(v52, (uint64_t)v76, type metadata accessor for AnyTreeClassifierModel);
  uint64_t v54 = *(unsigned __int8 *)(v77 + 80);
  uint64_t v55 = ~*(unsigned __int8 *)(v77 + 80) & (v54 + 16);
  uint64_t v56 = swift_allocObject(&unk_39C810, v55 + v75, v54 | 7);
  outlined init with take of MLClassifierMetrics(v53, v56 + v55, type metadata accessor for AnyTreeClassifierModel);
  uint64_t v57 = v90;
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLBoostedTreeClassifier.init(checkpoint:), v56);
  uint64_t v59 = v58;
  swift_release();
  if (v57)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(v88, type metadata accessor for MLCheckpoint);
    char v49 = type metadata accessor for AnyTreeClassifierModel;
    uint64_t v50 = v52;
    goto LABEL_16;
  }
  uint64_t v62 = v79;
  *(void *)(v79 + v87[5]) = v59;
  outlined init with copy of MLTrainingSessionParameters(v52, v62, type metadata accessor for AnyTreeClassifierModel);
  uint64_t v63 = (uint64_t)v80;
  *uint64_t v80 = 0;
  *(_WORD *)(v63 + 16) = 256;
  swift_storeEnumTagMultiPayload(v63, v84, 0);
  uint64_t v64 = v87[8];
  *(_OWORD *)(v62 + v64 + 16) = 0;
  *(_OWORD *)(v62 + v64) = 0;
  *(void *)(v62 + v64 + 32) = 6;
  __m128 v65 = _mm_loadh_ps((const double *)&qword_346D50);
  *(void *)(v62 + v64 + 40) = 10;
  *(__m128 *)(v62 + v64 + 48) = v65;
  *(void *)(v62 + v64 + 64) = 42;
  *(void *)(v62 + v64 + 72) = 0x3FD3333333333333;
  *(void *)(v62 + v64 + 80) = 0;
  uint64_t v90 = v62 + v64;
  *(unsigned char *)(v62 + v64 + 88) = 1;
  *(_OWORD *)(v62 + v64 + 96) = xmmword_34E1F0;
  uint64_t v66 = (uint64_t)v81;
  outlined init with copy of MLTrainingSessionParameters(v63, (uint64_t)v81, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
  v70[3] = v84;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v70);
  outlined init with take of MLClassifierMetrics(v66, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
  outlined assign with take of Any?((uint64_t)v70, v90);
  outlined destroy of MLActivityClassifier.ModelParameters(v63, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
  uint64_t v68 = v87;
  uint64_t v69 = v87[6];
  *(void *)(v62 + v69) = 0;
  *(void *)(v62 + v69 + 8) = 0xE000000000000000;
  outlined destroy of MLActivityClassifier.ModelParameters(v88, type metadata accessor for MLCheckpoint);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v83, type metadata accessor for AnyTreeClassifierModel);
  uint64_t result = v68[7];
  *(void *)(v62 + result) = _swiftEmptyArrayStorage;
  return result;
}

void *static MLBoostedTreeClassifier.train(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, uint64_t a3, void (*a4)(void, void), uint64_t a5, uint64_t a6)
{
  uint64_t v21 = a6;
  uint64_t v22 = a5;
  int64_t v23 = a4;
  uint64_t v24 = a3;
  uint64_t v25 = a2;
  uint64_t v7 = type metadata accessor for DataFrame(0);
  uint64_t v8 = *(void *)(v7 - 8);
  int64_t v9 = *(void *)(v8 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  char v12 = *(unsigned char *)(a1 + 8);
  uint64_t v19 = *(void *)a1;
  char v20 = v12;
  outlined copy of Result<_DataTable, Error>(v19, v12);
  DataFrame.init(_:)((uint64_t)&v19);
  int64_t v13 = static MLBoostedTreeClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v19, v25, v24, v23, v22, v21);
  uint64_t v14 = v7;
  if (v6) {
    return (void *)(*(uint64_t (**)(uint64_t *, uint64_t))(v8 + 8))(&v19, v7);
  }
  uint64_t v16 = (uint64_t)v13;
  (*(void (**)(uint64_t *, uint64_t))(v8 + 8))(&v19, v14);
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLBoostedTreeClassifier>);
  int64_t v18 = (void *)swift_allocObject(v17, *(unsigned int *)(v17 + 48), *(unsigned __int16 *)(v17 + 52));
  return specialized MLJob.init(_:)(v18, v16);
}

long long *static MLBoostedTreeClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, uint64_t a3, void (*a4)(void, void), uint64_t a5, uint64_t a6)
{
  uint64_t v16 = a6;
  uint64_t v17 = a5;
  int64_t v18 = a4;
  uint64_t v19 = a3;
  uint64_t v7 = type metadata accessor for DataFrame(0);
  uint64_t v20 = *(void *)(v7 - 8);
  int64_t v8 = *(void *)(v20 + 64);
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  char v11 = *(unsigned char *)(a1 + 8);
  uint64_t v14 = *(void *)a1;
  char v15 = v11;
  outlined copy of Result<_DataTable, Error>(v14, v11);
  DataFrame.init(_:)((uint64_t)&v14);
  char v12 = static MLBoostedTreeClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v14, a2, v19, v18, v17, v16);
  (*(void (**)(uint64_t *, uint64_t))(v20 + 8))(&v14, v7);
  return v12;
}

void *static MLBoostedTreeClassifier.resume(_:)(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLBoostedTreeClassifier>);
  uint64_t v2 = (void *)swift_allocObject(v1, *(unsigned int *)(v1 + 48), *(unsigned __int16 *)(v1 + 52));
  swift_retain();
  return specialized MLJob.init(_:)(v2, a1);
}

long long *static MLBoostedTreeClassifier.train(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(void (*a1)(uint64_t *, uint64_t, uint64_t), uint64_t a2, uint64_t a3, void (*a4)(void, void), uint64_t a5, uint64_t a6)
{
  uint64_t result = static MLBoostedTreeClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(a1, a2, a3, a4, a5, a6);
  if (!v6)
  {
    uint64_t v8 = (uint64_t)result;
    uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLBoostedTreeClassifier>);
    uint64_t v10 = (void *)swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
    return (long long *)specialized MLJob.init(_:)(v10, v8);
  }
  return result;
}

long long *static MLBoostedTreeClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(void (*a1)(uint64_t *, uint64_t, uint64_t), uint64_t a2, uint64_t a3, void (*a4)(void, void), uint64_t a5, uint64_t a6)
{
  uint64_t v72 = v6;
  uint64_t v68 = a6;
  __m128 v65 = a4;
  uint64_t v66 = a3;
  uint64_t v59 = a2;
  uint64_t v73 = a1;
  int64_t v8 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v63 = &v44;
  char v11 = alloca(v8);
  char v12 = alloca(v8);
  uint64_t v60 = &v44;
  int64_t v13 = *(void *)(*(void *)(type metadata accessor for BoostedTreeConfiguration(0) - 8) + 64);
  uint64_t v14 = alloca(v13);
  char v15 = alloca(v13);
  uint64_t v61 = &v44;
  uint64_t v74 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
  int64_t v16 = *(void *)(*(void *)(v74 - 8) + 64);
  uint64_t v17 = alloca(v16);
  int64_t v18 = alloca(v16);
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
  int64_t v20 = *(void *)(*(void *)(v19 - 8) + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v70 = &v44;
  int64_t v23 = alloca(v20);
  uint64_t v24 = alloca(v20);
  int64_t v75 = &v44;
  uint64_t v25 = alloca(v20);
  uint64_t v26 = alloca(v20);
  uint64_t v71 = &v44;
  uint64_t v62 = a5;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a5, (uint64_t)&v57, &demangling cache variable for type metadata for Any?);
  if (!v58) {
    BUG();
  }
  uint64_t v67 = v19;
  uint64_t v27 = *(int *)(v19 + 48);
  uint64_t v28 = (uint64_t)v71;
  uint64_t v29 = (uint64_t)v71 + v27;
  uint64_t v30 = &v45;
  outlined init with take of Any(&v57, &v45);
  swift_dynamicCast(&v44, &v45, (char *)&type metadata for Any + 8, v74, 7);
  uint64_t v31 = v72;
  MLBoostedTreeClassifier.ModelParameters.ValidationData.generateDataFrames(trainingData:)(v28, v29, v73);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v44, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
  if (!v31)
  {
    uint64_t v32 = (void (*)(uint64_t *, uint64_t, uint64_t))((char *)v75 + *(int *)(v67 + 48));
    uint64_t v33 = type metadata accessor for DataFrame(0);
    uint64_t v69 = *(void *)(v33 - 8);
    uint64_t v72 = *(void (**)(void, void, void))(v69 + 16);
    uint64_t v64 = 0;
    uint64_t v34 = (uint64_t)v71;
    v72(v75, v71, v33);
    uint64_t v73 = v32;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v29, (uint64_t)v32, &demangling cache variable for type metadata for DataFrame?);
    uint64_t v30 = (long long *)((char *)v70 + *(int *)(v67 + 48));
    uint64_t v74 = v33;
    v72(v70, v34, v33);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v29, (uint64_t)v30, &demangling cache variable for type metadata for DataFrame?);
    outlined init with copy of MLBoostedTreeClassifier.ModelParameters(v62, (uint64_t)&v45);
    swift_bridgeObjectRetain((_BYTE)v65);
    swift_bridgeObjectRetain(v66);
    uint64_t v35 = (uint64_t)v61;
    BoostedTreeConfiguration.init()();
    BoostedTreeConfiguration.maximumDepth.setter(v47);
    BoostedTreeConfiguration.maximumIterations.setter(v48);
    BoostedTreeConfiguration.minimumLossReduction.setter(v49);
    BoostedTreeConfiguration.minimumChildWeight.setter(v50);
    BoostedTreeConfiguration.randomSeed.setter(v51);
    BoostedTreeConfiguration.learningRate.setter(v52);
    BoostedTreeConfiguration.earlyStoppingIterationCount.setter(v53, v54);
    BoostedTreeConfiguration.rowSubsample.setter(v55);
    BoostedTreeConfiguration.columnSubsample.setter(v56);
    outlined destroy of MLBoostedTreeClassifier.ModelParameters((uint64_t)&v45);
    uint64_t v36 = (uint64_t)v60;
    outlined init with copy of MLTrainingSessionParameters(v68, (uint64_t)v60, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v37 = type metadata accessor for TreeClassifierTrainingSessionDelegate(0);
    swift_allocObject(v37, *(unsigned int *)(v37 + 48), *(unsigned __int16 *)(v37 + 52));
    uint64_t v38 = v64;
    uint64_t v39 = TreeClassifierTrainingSessionDelegate.init(trainingData:validationData:targetColumn:featureColumns:configuration:sessionParameters:)((uint64_t)v75, (uint64_t)v30, v59, v66, v65, v35, v36);
    if (v38)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v71, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      (*(void (**)(uint64_t *, uint64_t))(v69 + 8))(v70, v74);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v73, &demangling cache variable for type metadata for DataFrame?);
    }
    else
    {
      uint64_t v40 = (uint64_t)v39;
      (*(void (**)(uint64_t *, uint64_t))(v69 + 8))(v70, v74);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v73, &demangling cache variable for type metadata for DataFrame?);
      uint64_t v46 = v37;
      uint64_t v47 = &protocol witness table for TreeClassifierTrainingSessionDelegate;
      *(void *)&long long v45 = v40;
      uint64_t v41 = (uint64_t)v63;
      outlined init with copy of MLTrainingSessionParameters(v68, (uint64_t)v63, type metadata accessor for MLTrainingSessionParameters);
      uint64_t v42 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>);
      swift_allocObject(v42, *(unsigned int *)(v42 + 48), *(unsigned __int16 *)(v42 + 52));
      int64_t v75 = (uint64_t *)v40;
      swift_retain();
      uint64_t v30 = (long long *)specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)&v45, v41, 5);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v71, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      swift_release();
    }
  }
  return v30;
}

uint64_t static MLBoostedTreeClassifier.restoreTrainingSession(sessionParameters:)(uint64_t a1)
{
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  uint64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  char v12 = v11;
  uint64_t v5 = alloca(v2);
  uint64_t v6 = alloca(v2);
  outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v11, type metadata accessor for MLTrainingSessionParameters);
  uint64_t v7 = type metadata accessor for TreeClassifierTrainingSessionDelegate(0);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  uint64_t result = TreeClassifierTrainingSessionDelegate.init(sessionParameters:)((uint64_t)v11);
  if (!v1)
  {
    v11[3] = v7;
    _OWORD v11[4] = &protocol witness table for TreeClassifierTrainingSessionDelegate;
    v11[0] = result;
    uint64_t v9 = (uint64_t)v12;
    outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v12, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLBoostedTreeClassifier>);
    swift_allocObject(v10, *(unsigned int *)(v10 + 48), *(unsigned __int16 *)(v10 + 52));
    return specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)v11, v9, 5);
  }
  return result;
}

uint64_t closure #1 in closure #1 in static MLBoostedTreeClassifier.resume(_:)(uint64_t a1, char a2, uint64_t a3, void (*a4)(uint64_t *), uint64_t a5)
{
  uint64_t v22 = a5;
  int64_t v23 = a4;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLBoostedTreeClassifier, Error>);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TaskPriority?)
                              - 8)
                  + 64);
  char v11 = alloca(v10);
  char v12 = alloca(v10);
  if (a2)
  {
    uint64_t v19 = a1;
    swift_storeEnumTagMultiPayload(&v19, v6, 1);
    swift_errorRetain(a1);
    v23(&v19);
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v19, &demangling cache variable for type metadata for Result<MLBoostedTreeClassifier, Error>);
  }
  else
  {
    outlined init with copy of TabularRegressionTask(direct field offset for MLTrainingSession.delegate + a3, (uint64_t)v20);
    uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingSessionDelegate);
    uint64_t v14 = type metadata accessor for TreeClassifierTrainingSessionDelegate(0);
    swift_dynamicCast(&v21, v20, v13, v14, 7);
    uint64_t v15 = v21;
    uint64_t v16 = type metadata accessor for TaskPriority(0);
    __swift_storeEnumTagSinglePayload((uint64_t)&v19, 1, 1, v16);
    uint64_t v17 = swift_allocObject(&unk_39C848, 56, 7);
    *(_OWORD *)(v17 + 16) = 0;
    *(void *)(v17 + 32) = v15;
    *(void *)(v17 + 40) = v23;
    *(void *)(v17 + 48) = v22;
    swift_retain();
    _sScTss5NeverORs_rlE8priority9operationScTyxABGScPSg_xyYaYAcntcfCyt_Tgm5((uint64_t)&v19, (uint64_t)&async function pointer to partial apply for closure #1 in static MLBoostedTreeClassifier.handleResult(_:session:fulfill:), v17);
    return swift_release();
  }
}

uint64_t closure #1 in static MLBoostedTreeClassifier.handleResult(_:session:fulfill:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  void v6[4] = a6;
  v6[3] = a5;
  v6[2] = a4;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLBoostedTreeClassifier, Error>);
  v6[5] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(closure #1 in static MLBoostedTreeClassifier.handleResult(_:session:fulfill:), 0, 0);
}

uint64_t closure #1 in static MLBoostedTreeClassifier.handleResult(_:session:fulfill:)()
{
  uint64_t v1 = (char *)&async function pointer to specialized Result<>.init(catching:)
     + async function pointer to specialized Result<>.init(catching:);
  uint64_t v2 = dword_3AE644;
  swift_retain();
  uint64_t v3 = (void *)swift_task_alloc(v2);
  v0[6] = v3;
  void *v3 = v0;
  v3[1] = closure #1 in static MLBoostedTreeClassifier.handleResult(_:session:fulfill:);
  return ((uint64_t (*)(void, void))v1)(v0[5], v0[2]);
}

{
  uint64_t v0;

  swift_task_dealloc(*(void *)(*(void *)v0 + 48));
  return swift_task_switch(closure #1 in static MLBoostedTreeClassifier.handleResult(_:session:fulfill:), 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;

  uint64_t v1 = *(void *)(v0 + 40);
  (*(void (**)(uint64_t))(v0 + 24))(v1);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, &demangling cache variable for type metadata for Result<MLBoostedTreeClassifier, Error>);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLBoostedTreeClassifier.init(delegate:)(uint64_t a1, uint64_t a2)
{
  v2[43] = a2;
  v2[42] = a1;
  uint64_t v3 = type metadata accessor for AnyClassificationMetrics(0);
  v2[44] = v3;
  unint64_t v4 = (*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[45] = swift_task_alloc(v4);
  v2[46] = swift_task_alloc(v4);
  unint64_t v5 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyClassificationMetrics?)
                              - 8)
                  + 64)
      + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[47] = swift_task_alloc(v5);
  v2[48] = swift_task_alloc(v5);
  uint64_t v6 = type metadata accessor for MLClassifierMetrics(0);
  v2[49] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifierModel?);
  v2[50] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for MLBoostedTreeClassifier(0);
  v2[51] = v8;
  v2[52] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  v2[53] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for BoostedTreeConfiguration(0);
  v2[54] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v2[55] = v11;
  v2[56] = swift_task_alloc((*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  v2[57] = swift_task_alloc((*(void *)(*(void *)(v12 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v13 = type metadata accessor for PersistentParametersForTreeBasedMethods(0);
  v2[58] = v13;
  v2[59] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLBoostedTreeClassifier.init(delegate:), 0, 0);
}

uint64_t MLBoostedTreeClassifier.init(delegate:)()
{
  uint64_t v1 = v0[58];
  uint64_t v2 = v0[57];
  uint64_t v3 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters + v0[43];
  swift_beginAccess(v3, v0 + 30, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v3, v2, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1) {
    BUG();
  }
  uint64_t v4 = v0[59];
  unint64_t v5 = (int *)v0[58];
  uint64_t v6 = v0[56];
  uint64_t v19 = v0[55];
  uint64_t v16 = v0[54];
  uint64_t v17 = v0[53];
  uint64_t v7 = v0[43];
  uint64_t v15 = v0[50];
  outlined init with take of MLClassifierMetrics(v0[57], v4, type metadata accessor for PersistentParametersForTreeBasedMethods);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v19 + 16))(v6, v4 + v5[8], v16);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v4 + v5[5], v17, &demangling cache variable for type metadata for DataFrame?);
  MLBoostedTreeClassifier.ModelParameters.init(configuration:validation:)(v6, v17);
  uint64_t v8 = v5[6];
  uint64_t v18 = *(void *)(v4 + v8);
  uint64_t v20 = *(void *)(v4 + v8 + 8);
  uint64_t v9 = *(void *)(v4 + v5[7]);
  uint64_t v10 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model + v7;
  swift_beginAccess(v10, v0 + 33, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, v15, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  uint64_t v11 = type metadata accessor for AnyTreeClassifierModel(0);
  if (__swift_getEnumTagSinglePayload(v15, 1, v11) == 1) {
    BUG();
  }
  outlined init with copy of MLBoostedTreeClassifier.ModelParameters((uint64_t)(v0 + 2), (uint64_t)(v0 + 16));
  uint64_t v12 = dword_3ADCFC;
  swift_bridgeObjectRetain(v20);
  swift_bridgeObjectRetain(v9);
  uint64_t v13 = (void *)swift_task_alloc(v12);
  v0[60] = v13;
  *uint64_t v13 = v0;
  v13[1] = MLBoostedTreeClassifier.init(delegate:);
  return MLBoostedTreeClassifier.init(_:targetColumn:featureColumns:parameters:)(v0[52], v0[50], v18, v20, v9, (uint64_t)(v0 + 16));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 480);
  *(void *)(*(void *)v1 + 488) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLBoostedTreeClassifier.init(delegate:);
  }
  else {
    uint64_t v3 = MLBoostedTreeClassifier.init(delegate:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;

  uint64_t v1 = *(void *)(v0 + 384);
  uint64_t v2 = *(void *)(v0 + 352);
  uint64_t v3 = *(void *)(v0 + 344);
  outlined init with take of MLClassifierMetrics(*(void *)(v0 + 416), *(void *)(v0 + 336), type metadata accessor for MLBoostedTreeClassifier);
  uint64_t v4 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingMetrics + v3;
  swift_beginAccess(v4, v0 + 288, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v4, v1, &demangling cache variable for type metadata for AnyClassificationMetrics?);
  if (__swift_getEnumTagSinglePayload(v1, 1, v2) == 1) {
    BUG();
  }
  unint64_t v5 = *(void *)(v0 + 472);
  uint64_t v22 = *(void *)(v0 + 408);
  uint64_t v6 = *(void *)(v0 + 392);
  uint64_t v7 = *(void *)(v0 + 384);
  uint64_t v29 = *(void *)(v0 + 376);
  uint64_t v26 = *(void *)(v0 + 352);
  uint64_t v24 = *(void *)(v0 + 336);
  uint64_t v8 = *(void *)(v0 + 344);
  outlined destroy of MLBoostedTreeClassifier.ModelParameters(v0 + 16);
  outlined destroy of MLActivityClassifier.ModelParameters(v5, type metadata accessor for PersistentParametersForTreeBasedMethods);
  outlined init with take of MLClassifierMetrics(v7, v6, type metadata accessor for AnyClassificationMetrics);
  uint64_t v9 = type metadata accessor for MLClassifierMetrics.Contents(0);
  swift_storeEnumTagMultiPayload(v6, v9, 0);
  outlined assign with take of MLClassifierMetrics(v6, v24 + *(int *)(v22 + 36));
  uint64_t v10 = v8 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics;
  swift_beginAccess(v8 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics, v0 + 312, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, v29, &demangling cache variable for type metadata for AnyClassificationMetrics?);
  swift_release();
  if (__swift_getEnumTagSinglePayload(v29, 1, v26) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 376), &demangling cache variable for type metadata for AnyClassificationMetrics?);
  }
  else
  {
    uint64_t v30 = *(void *)(v0 + 408);
    uint64_t v11 = *(void *)(v0 + 368);
    uint64_t v12 = *(void *)(v0 + 336);
    uint64_t v27 = v9;
    uint64_t v13 = *(void *)(v0 + 360);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 376), v11, type metadata accessor for AnyClassificationMetrics);
    outlined init with take of MLClassifierMetrics(v11, v13, type metadata accessor for AnyClassificationMetrics);
    uint64_t v14 = v12 + *(int *)(v30 + 40);
    outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLClassifierMetrics);
    outlined init with take of MLClassifierMetrics(v13, v14, type metadata accessor for AnyClassificationMetrics);
    swift_storeEnumTagMultiPayload(v14, v27, 0);
  }
  uint64_t v15 = *(void *)(v0 + 456);
  uint64_t v16 = *(void *)(v0 + 448);
  uint64_t v17 = *(void *)(v0 + 424);
  uint64_t v18 = *(void *)(v0 + 416);
  uint64_t v20 = *(void *)(v0 + 400);
  uint64_t v25 = *(void *)(v0 + 392);
  int64_t v23 = *(void *)(v0 + 384);
  uint64_t v21 = *(void *)(v0 + 376);
  uint64_t v28 = *(void *)(v0 + 360);
  uint64_t v31 = *(void *)(v0 + 368);
  swift_task_dealloc(*(void *)(v0 + 472));
  swift_task_dealloc(v15);
  swift_task_dealloc(v16);
  swift_task_dealloc(v17);
  swift_task_dealloc(v18);
  swift_task_dealloc(v20);
  swift_task_dealloc(v25);
  swift_task_dealloc(v23);
  swift_task_dealloc(v21);
  swift_task_dealloc(v31);
  swift_task_dealloc(v28);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;

  uint64_t v1 = *(void *)(v0 + 472);
  uint64_t v2 = *(void *)(v0 + 456);
  uint64_t v3 = *(void *)(v0 + 448);
  uint64_t v12 = *(void *)(v0 + 424);
  uint64_t v11 = *(void *)(v0 + 416);
  uint64_t v10 = *(void *)(v0 + 400);
  uint64_t v9 = *(void *)(v0 + 392);
  uint64_t v8 = *(void *)(v0 + 384);
  uint64_t v7 = *(void *)(v0 + 376);
  uint64_t v6 = *(void *)(v0 + 368);
  unint64_t v5 = *(void *)(v0 + 360);
  swift_release();
  outlined destroy of MLBoostedTreeClassifier.ModelParameters(v0 + 16);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for PersistentParametersForTreeBasedMethods);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  swift_task_dealloc(v5);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLBoostedTreeClassifier()
{
  return MLBoostedTreeClassifier.description.getter();
}

unint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLBoostedTreeClassifier()
{
  return MLBoostedTreeClassifier.debugDescription.getter();
}

NSAttributedString protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLBoostedTreeClassifier()
{
  return MLBoostedTreeClassifier.playgroundDescription.getter();
}

uint64_t protocol witness for TabularClassificationTask.validationMetrics.getter in conformance MLBoostedTreeClassifier()
{
  return MLBoostedTreeClassifier.validationMetrics.getter();
}

uint64_t outlined init with copy of MLBoostedTreeClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  (*(void (**)(uint64_t, uint64_t))(*((void *)&type metadata for MLBoostedTreeClassifier.ModelParameters - 1)
                                           + 16))(a2, a1);
  return a2;
}

uint64_t outlined destroy of MLBoostedTreeClassifier.ModelParameters(uint64_t a1)
{
  return a1;
}

uint64_t sub_27DD8F()
{
  return objectdestroyTm_3();
}

uint64_t partial apply for closure #1 in MLBoostedTreeClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  type metadata accessor for AnyTreeClassifierModel(0);
  uint64_t v2 = (void *)swift_task_alloc(dword_3ADC04);
  *(void *)(v1 + 16) = v2;
  void *v2 = v1;
  v2[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLBoostedTreeClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(a1);
}

uint64_t sub_27DE1D()
{
  return objectdestroyTm_3();
}

uint64_t partial apply for closure #1 in MLBoostedTreeClassifier.init(checkpoint:)(uint64_t a1)
{
  type metadata accessor for AnyTreeClassifierModel(0);
  uint64_t v2 = (void *)swift_task_alloc(dword_3ADC14);
  *(void *)(v1 + 16) = v2;
  void *v2 = v1;
  v2[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLRandomForestClassifier.init(checkpoint:)(a1);
}

id sub_27DEB5()
{
  uint64_t v1 = v0;
  id result = MLBoostedTreeClassifier.model.getter();
  *uint64_t v1 = result;
  return result;
}

void sub_27DECF(id *a1)
{
}

void *initializeBufferWithCopyOfBuffer for MLBoostedTreeClassifier(void *a1, void *a2, int *a3)
{
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v4 & 0x20000) == 0)
  {
    *a1 = *a2;
    uint64_t v5 = a2[1];
    a1[1] = v5;
    uint64_t v6 = a2[2];
    swift_bridgeObjectRetain(v5);
    if (v6)
    {
      a1[2] = v6;
      a1[3] = a2[3];
      uint64_t v7 = a2[4];
      a1[4] = v7;
      swift_bridgeObjectRetain(v6);
      swift_bridgeObjectRetain(v7);
    }
    else
    {
      a1[4] = a2[4];
      *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
    }
    uint64_t v10 = type metadata accessor for AnyTreeClassifierModel(0);
    uint64_t v11 = *(int *)(v10 + 24);
    uint64_t v12 = type metadata accessor for BaseTreeClassifierModel(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 16))((char *)a1 + v11, (char *)a2 + v11, v12);
    uint64_t v13 = *(int *)(v10 + 28);
    uint64_t v14 = *(void *)((char *)a2 + v13);
    char v15 = *((unsigned char *)a2 + v13 + 8);
    *(void *)((char *)a1 + v13) = v14;
    *((unsigned char *)a1 + v13 + 8) = v15;
    uint64_t v16 = a3[5];
    uint64_t v17 = *(void **)((char *)a2 + v16);
    *(void *)((char *)a1 + v16) = v17;
    uint64_t v18 = a3[6];
    *(void *)((char *)a1 + v18) = *(void *)((char *)a2 + v18);
    uint64_t v19 = a1;
    uint64_t v20 = *(void *)((char *)a2 + v18 + 8);
    *(void *)((char *)v19 + v18 + 8) = v20;
    uint64_t v21 = a3[7];
    uint64_t v70 = *(void *)((char *)a2 + v21);
    *(void *)((char *)v19 + v21) = v70;
    uint64_t v22 = a3[8];
    uint64_t v63 = v19;
    int64_t v23 = (char *)v19 + v22;
    uint64_t v24 = (char *)a2 + v22;
    uint64_t v25 = *(void *)((char *)a2 + v22 + 24);
    swift_bridgeObjectRetain(v14);
    v17;
    swift_bridgeObjectRetain(v20);
    swift_bridgeObjectRetain(v70);
    if (v25)
    {
      *((void *)v23 + 3) = v25;
      (**(void (***)(char *, char *, uint64_t))(v25 - 8))(v23, v24, v25);
    }
    else
    {
      long long v26 = *(_OWORD *)v24;
      *((_OWORD *)v23 + 1) = *((_OWORD *)v24 + 1);
      *(_OWORD *)int64_t v23 = v26;
    }
    *((_OWORD *)v23 + 2) = *((_OWORD *)v24 + 2);
    *((_OWORD *)v23 + 3) = *((_OWORD *)v24 + 3);
    *((_OWORD *)v23 + 4) = *((_OWORD *)v24 + 4);
    *((void *)v23 + 10) = *((void *)v24 + 10);
    v23[88] = v24[88];
    *((_OWORD *)v23 + 6) = *((_OWORD *)v24 + 6);
    uint64_t v27 = a3;
    uint64_t v28 = a3[9];
    uint64_t v9 = v63;
    uint64_t v29 = (void *)((char *)v63 + v28);
    uint64_t v30 = (char *)a2 + v28;
    uint64_t v71 = type metadata accessor for MLClassifierMetrics.Contents(0);
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v30, v71);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v37 = v29;
      uint64_t v38 = *(void *)v30;
      swift_errorRetain(*(void *)v30);
      *uint64_t v37 = v38;
      uint64_t v29 = v37;
      unsigned int EnumCaseMultiPayload = 2;
    }
    else if (EnumCaseMultiPayload == 1)
    {
      *uint64_t v29 = *(void *)v30;
      uint64_t v64 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v32 = *(int *)(v64 + 20);
      uint64_t v62 = (char *)v29 + v32;
      uint64_t v33 = type metadata accessor for DataFrame(0);
      uint64_t v72 = (char *)v29;
      uint64_t v34 = *(void (**)(char *, char *, uint64_t))(*(void *)(v33 - 8) + 16);
      uint64_t v35 = &v30[v32];
      uint64_t v9 = v63;
      v34(v62, v35, v33);
      uint64_t v36 = v33;
      uint64_t v27 = a3;
      v34(&v72[*(int *)(v64 + 24)], &v30[*(int *)(v64 + 24)], v36);
      uint64_t v29 = v72;
    }
    else
    {
      uint64_t v73 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      int v39 = swift_getEnumCaseMultiPayload(v30, v73);
      BOOL v65 = v39 == 1;
      uint64_t v40 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      if (v39 == 1) {
        uint64_t v40 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(v40);
      (*(void (**)(void *, char *, uint64_t))(*(void *)(v41 - 8) + 16))(v29, v30, v41);
      swift_storeEnumTagMultiPayload(v29, v73, v65);
    }
    swift_storeEnumTagMultiPayload(v29, v71, EnumCaseMultiPayload);
    uint64_t v42 = v27[10];
    uint64_t v43 = (void *)((char *)v9 + v42);
    uint64_t v44 = (void *)((char *)a2 + v42);
    int v45 = swift_getEnumCaseMultiPayload((char *)a2 + v42, v71);
    if (v45 == 2)
    {
      uint64_t v50 = *v44;
      swift_errorRetain(v50);
      *uint64_t v43 = v50;
      uint64_t v61 = 2;
    }
    else
    {
      if (v45 != 1)
      {
        uint64_t v54 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
        int v55 = swift_getEnumCaseMultiPayload(v44, v54);
        double v56 = v44;
        BOOL v57 = v55 == 1;
        uint64_t v58 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
        if (v55 == 1) {
          uint64_t v58 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
        }
        uint64_t v59 = __swift_instantiateConcreteTypeFromMangledName(v58);
        (*(void (**)(void *, void *, uint64_t))(*(void *)(v59 - 8) + 16))(v43, v56, v59);
        swift_storeEnumTagMultiPayload(v43, v54, v57);
        double v52 = v43;
        uint64_t v53 = v71;
        uint64_t v51 = 0;
        goto LABEL_24;
      }
      *uint64_t v43 = *v44;
      uint64_t v69 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v46 = *(int *)(v69 + 20);
      uint64_t v67 = (char *)v43 + v46;
      uint64_t v47 = type metadata accessor for DataFrame(0);
      uint64_t v48 = *(void (**)(char *, char *, uint64_t))(*(void *)(v47 - 8) + 16);
      double v49 = (char *)v44 + v46;
      uint64_t v9 = v63;
      v48(v67, v49, v47);
      v48((char *)v43 + *(int *)(v69 + 24), (char *)v44 + *(int *)(v69 + 24), v47);
      uint64_t v61 = 1;
    }
    uint64_t v51 = v61;
    double v52 = v43;
    uint64_t v53 = v71;
LABEL_24:
    swift_storeEnumTagMultiPayload(v52, v53, v51);
    return v9;
  }
  uint64_t v8 = *a2;
  *a1 = *a2;
  uint64_t v9 = (void *)(v8 + ((v4 + 16) & ~v4));
  swift_retain();
  return v9;
}

void *initializeWithCopy for MLBoostedTreeClassifier(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v4 = a2[1];
  a1[1] = v4;
  uint64_t v5 = a2[2];
  swift_bridgeObjectRetain(v4);
  if (v5)
  {
    a1[2] = v5;
    a1[3] = a2[3];
    uint64_t v6 = a2[4];
    a1[4] = v6;
    swift_bridgeObjectRetain(v5);
    swift_bridgeObjectRetain(v6);
  }
  else
  {
    a1[4] = a2[4];
    *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
  }
  uint64_t v7 = type metadata accessor for AnyTreeClassifierModel(0);
  uint64_t v8 = *(int *)(v7 + 24);
  uint64_t v9 = type metadata accessor for BaseTreeClassifierModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))((char *)a1 + v8, (char *)a2 + v8, v9);
  uint64_t v10 = *(int *)(v7 + 28);
  uint64_t v11 = *(void *)((char *)a2 + v10);
  char v12 = *((unsigned char *)a2 + v10 + 8);
  *(void *)((char *)a1 + v10) = v11;
  *((unsigned char *)a1 + v10 + 8) = v12;
  uint64_t v13 = a3[5];
  uint64_t v14 = *(void **)((char *)a2 + v13);
  *(void *)((char *)a1 + v13) = v14;
  uint64_t v15 = a3[6];
  *(void *)((char *)a1 + v15) = *(void *)((char *)a2 + v15);
  uint64_t v16 = a1;
  uint64_t v17 = *(void *)((char *)a2 + v15 + 8);
  *(void *)((char *)v16 + v15 + 8) = v17;
  uint64_t v18 = a3[7];
  uint64_t v56 = *(void *)((char *)a2 + v18);
  *(void *)((char *)v16 + v18) = v56;
  uint64_t v19 = a3[8];
  uint64_t v53 = v16;
  uint64_t v20 = (char *)v16 + v19;
  uint64_t v21 = (char *)a2 + v19;
  uint64_t v22 = *(void *)((char *)a2 + v19 + 24);
  swift_bridgeObjectRetain(v11);
  v14;
  swift_bridgeObjectRetain(v17);
  swift_bridgeObjectRetain(v56);
  if (v22)
  {
    *((void *)v20 + 3) = v22;
    (**(void (***)(char *, char *, uint64_t))(v22 - 8))(v20, v21, v22);
  }
  else
  {
    long long v23 = *(_OWORD *)v21;
    *((_OWORD *)v20 + 1) = *((_OWORD *)v21 + 1);
    *(_OWORD *)uint64_t v20 = v23;
  }
  *((_OWORD *)v20 + 2) = *((_OWORD *)v21 + 2);
  *((_OWORD *)v20 + 3) = *((_OWORD *)v21 + 3);
  *((_OWORD *)v20 + 4) = *((_OWORD *)v21 + 4);
  *((void *)v20 + 10) = *((void *)v21 + 10);
  v20[88] = v21[88];
  *((_OWORD *)v20 + 6) = *((_OWORD *)v21 + 6);
  uint64_t v24 = a3[9];
  uint64_t v25 = (char *)v53 + v24;
  long long v26 = (char *)a2 + v24;
  uint64_t v57 = type metadata accessor for MLClassifierMetrics.Contents(0);
  unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v26, v57);
  if (EnumCaseMultiPayload == 2)
  {
    uint64_t v32 = *(void *)v26;
    swift_errorRetain(*(void *)v26);
    *(void *)uint64_t v25 = v32;
  }
  else if (EnumCaseMultiPayload == 1)
  {
    *(void *)uint64_t v25 = *(void *)v26;
    uint64_t v54 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v28 = *(int *)(v54 + 20);
    double v52 = &v25[v28];
    uint64_t v29 = type metadata accessor for DataFrame(0);
    uint64_t v30 = &v26[v28];
    uint64_t v31 = *(void (**)(char *, char *, uint64_t))(*(void *)(v29 - 8) + 16);
    v31(v52, v30, v29);
    v31(&v25[*(int *)(v54 + 24)], &v26[*(int *)(v54 + 24)], v29);
  }
  else
  {
    uint64_t v55 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v33 = swift_getEnumCaseMultiPayload(v26, v55);
    BOOL v34 = v33 == 1;
    uint64_t v35 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v33 == 1) {
      uint64_t v35 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v36 = __swift_instantiateConcreteTypeFromMangledName(v35);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v36 - 8) + 16))(v25, v26, v36);
    swift_storeEnumTagMultiPayload(v25, v55, v34);
  }
  swift_storeEnumTagMultiPayload(v25, v57, EnumCaseMultiPayload);
  uint64_t v37 = a3[10];
  uint64_t v38 = (char *)v53 + v37;
  int v39 = (char *)a2 + v37;
  unsigned int v40 = swift_getEnumCaseMultiPayload((char *)a2 + v37, v57);
  if (v40 == 2)
  {
    uint64_t v45 = *(void *)v39;
    swift_errorRetain(v45);
    *(void *)uint64_t v38 = v45;
  }
  else if (v40 == 1)
  {
    *(void *)uint64_t v38 = *(void *)v39;
    uint64_t v59 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v41 = *(int *)(v59 + 20);
    uint64_t v61 = &v38[v41];
    uint64_t v42 = type metadata accessor for DataFrame(0);
    uint64_t v43 = &v39[v41];
    uint64_t v44 = *(void (**)(char *, char *, uint64_t))(*(void *)(v42 - 8) + 16);
    v44(v61, v43, v42);
    v44(&v38[*(int *)(v59 + 24)], &v39[*(int *)(v59 + 24)], v42);
  }
  else
  {
    uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v47 = swift_getEnumCaseMultiPayload(v39, v46);
    uint64_t v62 = v39;
    BOOL v48 = v47 == 1;
    double v49 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v47 == 1) {
      double v49 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v50 = __swift_instantiateConcreteTypeFromMangledName(v49);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v50 - 8) + 16))(v38, v62, v50);
    swift_storeEnumTagMultiPayload(v38, v46, v48);
  }
  swift_storeEnumTagMultiPayload(v38, v57, v40);
  return v53;
}

void *assignWithCopy for MLBoostedTreeClassifier(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v5 = a2[1];
  uint64_t v6 = a1[1];
  a1[1] = v5;
  swift_bridgeObjectRetain(v5);
  swift_bridgeObjectRelease(v6);
  uint64_t v7 = a1 + 2;
  uint64_t v8 = a2 + 2;
  uint64_t v9 = a1[2];
  uint64_t v10 = a2[2];
  if (v9)
  {
    if (v10)
    {
      a1[2] = v10;
      swift_bridgeObjectRetain(v10);
      swift_bridgeObjectRelease(v9);
      a1[3] = a2[3];
      uint64_t v11 = a2[4];
      uint64_t v12 = a1[4];
      a1[4] = v11;
      swift_bridgeObjectRetain(v11);
      swift_bridgeObjectRelease(v12);
    }
    else
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)(a1 + 2), &demangling cache variable for type metadata for FeatureVectorizer<Float>.Transformer);
      *uint64_t v7 = *v8;
      a1[4] = a2[4];
    }
  }
  else if (v10)
  {
    a1[2] = v10;
    a1[3] = a2[3];
    uint64_t v13 = a2[4];
    a1[4] = v13;
    swift_bridgeObjectRetain(v10);
    swift_bridgeObjectRetain(v13);
  }
  else
  {
    a1[4] = a2[4];
    *uint64_t v7 = *v8;
  }
  uint64_t v14 = type metadata accessor for AnyTreeClassifierModel(0);
  uint64_t v15 = *(int *)(v14 + 24);
  uint64_t v16 = type metadata accessor for BaseTreeClassifierModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 24))((char *)a1 + v15, (char *)a2 + v15, v16);
  uint64_t v17 = *(int *)(v14 + 28);
  uint64_t v18 = *(void *)((char *)a2 + v17);
  char v19 = *((unsigned char *)a2 + v17 + 8);
  uint64_t v20 = *(void *)((char *)a1 + v17);
  *(void *)((char *)a1 + v17) = v18;
  *((unsigned char *)a1 + v17 + 8) = v19;
  swift_bridgeObjectRetain(v18);
  swift_bridgeObjectRelease(v20);
  uint64_t v21 = a3[5];
  uint64_t v22 = *(void **)((char *)a2 + v21);
  long long v23 = *(void **)((char *)a1 + v21);
  *(void *)((char *)a1 + v21) = v22;
  v22;

  uint64_t v24 = a3[6];
  *(void *)((char *)a1 + v24) = *(void *)((char *)a2 + v24);
  uint64_t v25 = *(void *)((char *)a2 + v24 + 8);
  uint64_t v26 = *(void *)((char *)a1 + v24 + 8);
  *(void *)((char *)a1 + v24 + 8) = v25;
  swift_bridgeObjectRetain(v25);
  swift_bridgeObjectRelease(v26);
  uint64_t v27 = a3[7];
  uint64_t v28 = *(void *)((char *)a2 + v27);
  uint64_t v29 = *(void *)((char *)a1 + v27);
  *(void *)((char *)a1 + v27) = v28;
  swift_bridgeObjectRetain(v28);
  swift_bridgeObjectRelease(v29);
  uint64_t v30 = a3[8];
  uint64_t v31 = (char *)a1 + v30;
  uint64_t v32 = (char *)a2 + v30;
  uint64_t v33 = *(void *)((char *)a2 + v30 + 24);
  if (*(void *)((char *)a1 + v30 + 24))
  {
    BOOL v34 = (void *)((char *)a1 + v30);
    if (v33)
    {
      __swift_assign_boxed_opaque_existential_0(v34, (void *)((char *)a2 + v30));
      goto LABEL_15;
    }
    __swift_destroy_boxed_opaque_existential_1Tm(v34);
  }
  else if (v33)
  {
    *((void *)v31 + 3) = v33;
    (**(void (***)(char *, char *))(v33 - 8))(v31, v32);
    goto LABEL_15;
  }
  long long v35 = *(_OWORD *)v32;
  *((_OWORD *)v31 + 1) = *((_OWORD *)v32 + 1);
  *(_OWORD *)uint64_t v31 = v35;
LABEL_15:
  *((void *)v31 + 4) = *((void *)v32 + 4);
  *((void *)v31 + 5) = *((void *)v32 + 5);
  *((void *)v31 + 6) = *((void *)v32 + 6);
  *((void *)v31 + 7) = *((void *)v32 + 7);
  *((void *)v31 + 8) = *((void *)v32 + 8);
  *((void *)v31 + 9) = *((void *)v32 + 9);
  *((void *)v31 + 10) = *((void *)v32 + 10);
  v31[88] = v32[88];
  *((void *)v31 + 12) = *((void *)v32 + 12);
  *((void *)v31 + 13) = *((void *)v32 + 13);
  if (a1 != a2)
  {
    uint64_t v36 = a3[9];
    uint64_t v37 = (void *)((char *)a1 + v36);
    uint64_t v38 = (void *)((char *)a2 + v36);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v37, type metadata accessor for MLClassifierMetrics.Contents);
    uint64_t v39 = type metadata accessor for MLClassifierMetrics.Contents(0);
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v38, v39);
    unsigned int v74 = EnumCaseMultiPayload;
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v43 = *v38;
      swift_errorRetain(v43);
      uint64_t v44 = 2;
      *uint64_t v37 = v43;
    }
    else
    {
      if (EnumCaseMultiPayload == 1)
      {
        *uint64_t v37 = *v38;
        uint64_t v64 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
        uint64_t v66 = v39;
        uint64_t v41 = *(int *)(v64 + 20);
        uint64_t v62 = (char *)v37 + v41;
        uint64_t v63 = type metadata accessor for DataFrame(0);
        uint64_t v71 = *(void (**)(char *, char *, uint64_t))(*(void *)(v63 - 8) + 16);
        uint64_t v42 = (char *)v38 + v41;
        uint64_t v39 = v66;
        v71(v62, v42, v63);
        v71((char *)v37 + *(int *)(v64 + 24), (char *)v38 + *(int *)(v64 + 24), v63);
      }
      else
      {
        uint64_t v67 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
        int v45 = swift_getEnumCaseMultiPayload(v38, v67);
        BOOL v72 = v45 == 1;
        uint64_t v46 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
        if (v45 == 1) {
          uint64_t v46 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
        }
        uint64_t v47 = __swift_instantiateConcreteTypeFromMangledName(v46);
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v47 - 8) + 16))(v37, v38, v47);
        swift_storeEnumTagMultiPayload(v37, v67, v72);
      }
      uint64_t v44 = v74;
    }
    swift_storeEnumTagMultiPayload(v37, v39, v44);
    uint64_t v48 = a3[10];
    double v49 = (void *)((char *)a1 + v48);
    uint64_t v50 = (void *)((char *)a2 + v48);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)a1 + v48, type metadata accessor for MLClassifierMetrics.Contents);
    unsigned int v51 = swift_getEnumCaseMultiPayload(v50, v39);
    if (v51 == 2)
    {
      uint64_t v56 = *v50;
      swift_errorRetain(v56);
      *double v49 = v56;
    }
    else
    {
      unsigned int v70 = v51;
      if (v51 == 1)
      {
        *double v49 = *v50;
        uint64_t v73 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
        uint64_t v52 = *(int *)(v73 + 20);
        BOOL v65 = (char *)v49 + v52;
        uint64_t v68 = v39;
        uint64_t v53 = type metadata accessor for DataFrame(0);
        int64_t v75 = *(void (**)(char *, char *, uint64_t))(*(void *)(v53 - 8) + 16);
        uint64_t v54 = (char *)v50 + v52;
        unsigned int v51 = 1;
        v75(v65, v54, v53);
        uint64_t v55 = v53;
        uint64_t v39 = v68;
        v75((char *)v49 + *(int *)(v73 + 24), (char *)v50 + *(int *)(v73 + 24), v55);
      }
      else
      {
        uint64_t v76 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
        int v57 = swift_getEnumCaseMultiPayload(v50, v76);
        BOOL v58 = v57 == 1;
        uint64_t v59 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
        if (v57 == 1) {
          uint64_t v59 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
        }
        uint64_t v60 = __swift_instantiateConcreteTypeFromMangledName(v59);
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v60 - 8) + 16))(v49, v50, v60);
        swift_storeEnumTagMultiPayload(v49, v76, v58);
        unsigned int v51 = v70;
      }
    }
    swift_storeEnumTagMultiPayload(v49, v39, v51);
  }
  return a1;
}

uint64_t initializeWithTake for MLBoostedTreeClassifier(uint64_t a1, uint64_t a2, int *a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = *(_OWORD *)(a2 + 16);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v5 = type metadata accessor for AnyTreeClassifierModel(0);
  uint64_t v6 = *(int *)(v5 + 24);
  uint64_t v7 = type metadata accessor for BaseTreeClassifierModel(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v7 - 8) + 32))(a1 + v6, a2 + v6, v7);
  uint64_t v8 = *(int *)(v5 + 28);
  *(unsigned char *)(a1 + v8 + 8) = *(unsigned char *)(a2 + v8 + 8);
  *(void *)(a1 + v8) = *(void *)(a2 + v8);
  *(void *)(a1 + a3[5]) = *(void *)(a2 + a3[5]);
  *(_OWORD *)(a1 + a3[6]) = *(_OWORD *)(a2 + a3[6]);
  *(void *)(a1 + a3[7]) = *(void *)(a2 + a3[7]);
  qmemcpy((void *)(a1 + a3[8]), (const void *)(a2 + a3[8]), 0x70uLL);
  uint64_t v47 = a3;
  uint64_t v9 = a3[9];
  uint64_t v10 = (char *)(v9 + a1);
  uint64_t v11 = (char *)(a2 + v9);
  uint64_t v12 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v11, v12);
  if (EnumCaseMultiPayload == 1)
  {
    *(void *)uint64_t v10 = *(void *)v11;
    uint64_t v45 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v21 = *(int *)(v45 + 20);
    uint64_t v46 = &v10[v21];
    uint64_t v51 = v12;
    uint64_t v22 = type metadata accessor for DataFrame(0);
    long long v23 = &v11[v21];
    uint64_t v24 = *(void (**)(char *, char *, uint64_t))(*(void *)(v22 - 8) + 32);
    v24(v46, v23, v22);
    uint64_t v25 = v22;
    uint64_t v12 = v51;
    v24(&v10[*(int *)(v45 + 24)], &v11[*(int *)(v45 + 24)], v25);
    uint64_t v20 = 1;
    uint64_t v18 = v10;
    uint64_t v19 = v51;
LABEL_7:
    swift_storeEnumTagMultiPayload(v18, v19, v20);
    goto LABEL_9;
  }
  if (!EnumCaseMultiPayload)
  {
    uint64_t v50 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v14 = swift_getEnumCaseMultiPayload(v11, v50);
    BOOL v15 = v14 == 1;
    uint64_t v16 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v14 == 1) {
      uint64_t v16 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(v16);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 32))(v10, v11, v17);
    swift_storeEnumTagMultiPayload(v10, v50, v15);
    uint64_t v18 = v10;
    uint64_t v19 = v12;
    uint64_t v20 = 0;
    goto LABEL_7;
  }
  memcpy(v10, v11, *(void *)(*(void *)(v12 - 8) + 64));
LABEL_9:
  uint64_t v26 = v47[10];
  uint64_t v27 = (char *)(a1 + v26);
  uint64_t v28 = (char *)(v26 + a2);
  int v29 = swift_getEnumCaseMultiPayload(v28, v12);
  if (v29 == 1)
  {
    *(void *)uint64_t v27 = *(void *)v28;
    uint64_t v39 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v52 = v12;
    uint64_t v40 = *(int *)(v39 + 20);
    uint64_t v48 = &v27[v40];
    uint64_t v41 = type metadata accessor for DataFrame(0);
    uint64_t v42 = &v28[v40];
    uint64_t v43 = *(void (**)(char *, char *, uint64_t))(*(void *)(v41 - 8) + 32);
    v43(v48, v42, v41);
    v43(&v27[*(int *)(v39 + 24)], &v28[*(int *)(v39 + 24)], v41);
    uint64_t v38 = 1;
    uint64_t v36 = v27;
    uint64_t v37 = v52;
  }
  else
  {
    if (v29)
    {
      memcpy(v27, v28, *(void *)(*(void *)(v12 - 8) + 64));
      return a1;
    }
    uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v31 = swift_getEnumCaseMultiPayload(v28, v30);
    uint64_t v32 = v12;
    BOOL v33 = v31 == 1;
    BOOL v34 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v31 == 1) {
      BOOL v34 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(v34);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v35 - 8) + 32))(v27, v28, v35);
    swift_storeEnumTagMultiPayload(v27, v30, v33);
    uint64_t v36 = v27;
    uint64_t v37 = v32;
    uint64_t v38 = 0;
  }
  swift_storeEnumTagMultiPayload(v36, v37, v38);
  return a1;
}

void *assignWithTake for MLBoostedTreeClassifier(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v5 = a1[1];
  a1[1] = a2[1];
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = a1 + 2;
  uint64_t v7 = a2 + 2;
  uint64_t v8 = a1[2];
  if (v8)
  {
    uint64_t v9 = a2[2];
    if (v9)
    {
      a1[2] = v9;
      swift_bridgeObjectRelease(v8);
      a1[3] = a2[3];
      uint64_t v10 = a1[4];
      a1[4] = a2[4];
      swift_bridgeObjectRelease(v10);
    }
    else
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)(a1 + 2), &demangling cache variable for type metadata for FeatureVectorizer<Float>.Transformer);
      _OWORD *v6 = *v7;
      a1[4] = a2[4];
    }
  }
  else
  {
    a1[4] = a2[4];
    _OWORD *v6 = *v7;
  }
  uint64_t v11 = type metadata accessor for AnyTreeClassifierModel(0);
  uint64_t v12 = *(int *)(v11 + 24);
  uint64_t v13 = type metadata accessor for BaseTreeClassifierModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v13 - 8) + 40))((char *)a1 + v12, (char *)a2 + v12, v13);
  uint64_t v14 = *(int *)(v11 + 28);
  char v15 = *((unsigned char *)a2 + v14 + 8);
  uint64_t v16 = *(void *)((char *)a1 + v14);
  *(void *)((char *)a1 + v14) = *(void *)((char *)a2 + v14);
  *((unsigned char *)a1 + v14 + 8) = v15;
  swift_bridgeObjectRelease(v16);
  uint64_t v17 = a3[5];
  uint64_t v18 = *(void **)((char *)a1 + v17);
  *(void *)((char *)a1 + v17) = *(void *)((char *)a2 + v17);

  uint64_t v19 = a3[6];
  *(void *)((char *)a1 + v19) = *(void *)((char *)a2 + v19);
  uint64_t v20 = *(void *)((char *)a1 + v19 + 8);
  *(void *)((char *)a1 + v19 + 8) = *(void *)((char *)a2 + v19 + 8);
  swift_bridgeObjectRelease(v20);
  uint64_t v21 = a3[7];
  uint64_t v22 = *(void *)((char *)a1 + v21);
  *(void *)((char *)a1 + v21) = *(void *)((char *)a2 + v21);
  swift_bridgeObjectRelease(v22);
  uint64_t v23 = a3[8];
  uint64_t v24 = (char *)a1 + v23;
  uint64_t v25 = (char *)a2 + v23;
  if (*(void *)((char *)a1 + v23 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)((char *)a1 + v23));
  }
  long long v26 = *(_OWORD *)v25;
  *((_OWORD *)v24 + 1) = *((_OWORD *)v25 + 1);
  *(_OWORD *)uint64_t v24 = v26;
  *((_OWORD *)v24 + 2) = *((_OWORD *)v25 + 2);
  *((_OWORD *)v24 + 3) = *((_OWORD *)v25 + 3);
  *((void *)v24 + 8) = *((void *)v25 + 8);
  *((void *)v24 + 9) = *((void *)v25 + 9);
  *((void *)v24 + 10) = *((void *)v25 + 10);
  v24[88] = v25[88];
  *((_OWORD *)v24 + 6) = *((_OWORD *)v25 + 6);
  if (a1 == a2) {
    return a1;
  }
  uint64_t v27 = a3[9];
  uint64_t v28 = (char *)a1 + v27;
  int v29 = (char *)a2 + v27;
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v28, type metadata accessor for MLClassifierMetrics.Contents);
  uint64_t v64 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v29, v64);
  if (EnumCaseMultiPayload == 1)
  {
    *(void *)uint64_t v28 = *(void *)v29;
    uint64_t v66 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v39 = *(int *)(v66 + 20);
    uint64_t v60 = &v28[v39];
    uint64_t v61 = type metadata accessor for DataFrame(0);
    uint64_t v40 = &v29[v39];
    uint64_t v41 = *(void (**)(char *, char *, uint64_t))(*(void *)(v61 - 8) + 32);
    v41(v60, v40, v61);
    v41(&v28[*(int *)(v66 + 24)], &v29[*(int *)(v66 + 24)], v61);
    uint64_t v38 = 1;
    uint64_t v35 = v28;
    uint64_t v36 = v64;
    uint64_t v37 = v64;
  }
  else
  {
    if (EnumCaseMultiPayload)
    {
      uint64_t v42 = v29;
      uint64_t v36 = v64;
      memcpy(v28, v42, *(void *)(*(void *)(v64 - 8) + 64));
      goto LABEL_17;
    }
    uint64_t v65 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v31 = swift_getEnumCaseMultiPayload(v29, v65);
    BOOL v32 = v31 == 1;
    BOOL v33 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v31 == 1) {
      BOOL v33 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(v33);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v34 - 8) + 32))(v28, v29, v34);
    swift_storeEnumTagMultiPayload(v28, v65, v32);
    uint64_t v35 = v28;
    uint64_t v36 = v64;
    uint64_t v37 = v64;
    uint64_t v38 = 0;
  }
  swift_storeEnumTagMultiPayload(v35, v37, v38);
LABEL_17:
  uint64_t v43 = a3[10];
  uint64_t v44 = (char *)a1 + v43;
  uint64_t v45 = (char *)a2 + v43;
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)a1 + v43, type metadata accessor for MLClassifierMetrics.Contents);
  int v46 = swift_getEnumCaseMultiPayload(v45, v36);
  if (v46 == 1)
  {
    *(void *)uint64_t v44 = *(void *)v45;
    uint64_t v63 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v55 = *(int *)(v63 + 20);
    uint64_t v67 = &v44[v55];
    uint64_t v56 = type metadata accessor for DataFrame(0);
    int v57 = &v45[v55];
    BOOL v58 = *(void (**)(char *, char *, uint64_t))(*(void *)(v56 - 8) + 32);
    v58(v67, v57, v56);
    v58(&v44[*(int *)(v63 + 24)], &v45[*(int *)(v63 + 24)], v56);
    uint64_t v54 = 1;
    uint64_t v52 = v44;
    uint64_t v53 = v64;
  }
  else
  {
    if (v46)
    {
      memcpy(v44, v45, *(void *)(*(void *)(v36 - 8) + 64));
      return a1;
    }
    uint64_t v47 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v48 = swift_getEnumCaseMultiPayload(v45, v47);
    BOOL v49 = v48 == 1;
    uint64_t v50 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v48 == 1) {
      uint64_t v50 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v51 = __swift_instantiateConcreteTypeFromMangledName(v50);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v51 - 8) + 32))(v44, v45, v51);
    swift_storeEnumTagMultiPayload(v44, v47, v49);
    uint64_t v52 = v44;
    uint64_t v53 = v64;
    uint64_t v54 = 0;
  }
  swift_storeEnumTagMultiPayload(v52, v53, v54);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLBoostedTreeClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_27F29F);
}

uint64_t sub_27F29F(uint64_t a1, unsigned int a2, uint64_t a3)
{
  uint64_t v4 = a1;
  uint64_t v5 = type metadata accessor for AnyTreeClassifierModel(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(v4, a2, v5);
  }
  if (a2 != 0x7FFFFFFF)
  {
    uint64_t v5 = type metadata accessor for MLClassifierMetrics(0);
    uint64_t v4 = *(int *)(a3 + 36) + a1;
    return __swift_getEnumTagSinglePayload(v4, a2, v5);
  }
  uint64_t result = 0;
  if ((*(void *)(a1 + *(int *)(a3 + 20)) & 0xFFFFFFFF00000001) == 0) {
    return (*(void *)(a1 + *(int *)(a3 + 20)) >> 1) + 1;
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLBoostedTreeClassifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_27F32C);
}

uint64_t sub_27F32C(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = a1;
  uint64_t v7 = type metadata accessor for AnyTreeClassifierModel(0);
  if (*(_DWORD *)(*(void *)(v7 - 8) + 84) != a3)
  {
    if (a3 == 0x7FFFFFFF)
    {
      uint64_t result = *(int *)(a4 + 20);
      *(void *)(a1 + result) = 2 * (a2 - 1);
      return result;
    }
    uint64_t v7 = type metadata accessor for MLClassifierMetrics(0);
    uint64_t v6 = *(int *)(a4 + 36) + a1;
  }
  return __swift_storeEnumTagSinglePayload(v6, a2, a2, v7);
}

uint64_t type metadata completion function for MLBoostedTreeClassifier(uint64_t a1)
{
  uint64_t result = type metadata accessor for AnyTreeClassifierModel(319);
  if (v2 <= 0x3F)
  {
    v4[0] = *(void *)(result - 8) + 64;
    v4[1] = (char *)&value witness table for Builtin.UnknownObject + 64;
    v4[2] = &unk_350C48;
    v4[3] = (char *)&value witness table for Builtin.BridgeObject + 64;
    _OWORD v4[4] = &unk_350C60;
    uint64_t result = type metadata accessor for MLClassifierMetrics.Contents(319);
    if (v3 <= 0x3F)
    {
      uint64_t v5 = *(void *)(result - 8) + 64;
      uint64_t v6 = v5;
      swift_initStructMetadata(a1, 256, 7, v4, a1 + 16);
      return 0;
    }
  }
  return result;
}

uint64_t sub_27F451()
{
  swift_unknownObjectRelease(v0[2]);
  swift_release(v0[4]);
  swift_release(v0[6]);
  return swift_deallocObject(v0, 56, 7);
}

uint64_t partial apply for closure #1 in static MLBoostedTreeClassifier.handleResult(_:session:fulfill:)(uint64_t a1)
{
  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v5 = v1[6];
  uint64_t v6 = (void *)swift_task_alloc(dword_3ADCE4);
  *(void *)(v2 + 16) = v6;
  void *v6 = v2;
  v6[1] = partial apply for specialized closure #1 in blockAwait<A>(_:);
  return closure #1 in static MLBoostedTreeClassifier.handleResult(_:session:fulfill:)(a1, v3, v4, v8, v9, v5);
}

char *specialized _ArrayProtocol.filter(_:)(uint64_t a1, void *a2)
{
  uint64_t v47 = v2;
  uint64_t v3 = a2;
  uint64_t v4 = a1;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v8 = &v36;
  uint64_t v53 = type metadata accessor for URL(0);
  uint64_t v9 = *(void *)(v53 - 8);
  int64_t v10 = *(void *)(v9 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  int v46 = (char *)&v36;
  uint64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  uint64_t v38 = &v36;
  char v15 = alloca(v10);
  uint64_t v16 = alloca(v10);
  uint64_t v51 = (char *)&v36;
  uint64_t v52 = (char *)_swiftEmptyArrayStorage;
  uint64_t v42 = *(void *)(a1 + 16);
  if (v42)
  {
    unint64_t v17 = 0;
    uint64_t v45 = a2;
    uint64_t v50 = a1;
    uint64_t v43 = &v36;
    uint64_t v48 = v9;
    while (1)
    {
      if (v17 >= *(void *)(v4 + 16)) {
        BUG();
      }
      uint64_t v40 = (*(unsigned __int8 *)(v9 + 80) + 32) & ~*(unsigned __int8 *)(v9 + 80);
      uint64_t v18 = *(void (**)(void, unint64_t, uint64_t))(v9 + 16);
      uint64_t v44 = *(void *)(v9 + 72);
      unint64_t v39 = v17;
      uint64_t v19 = v4 + v40 + v17 * v44;
      uint64_t v20 = v53;
      uint64_t v36 = v18;
      v18(v8, v19, v53);
      __swift_storeEnumTagSinglePayload((uint64_t)v8, 0, 1, v20);
      if (__swift_getEnumTagSinglePayload((uint64_t)v8, 1, v20) == 1) {
        break;
      }
      uint64_t v41 = *(void (**)(char *, void, uint64_t))(v9 + 32);
      v41(v51, v8, v53);
      if (v3[2])
      {
        uint64_t v21 = v3[5];
        uint64_t v22 = lazy protocol witness table accessor for type URL and conformance URL(&lazy protocol witness table cache variable for type URL and conformance URL, (uint64_t)&protocol conformance descriptor for URL);
        uint64_t v23 = dispatch thunk of Hashable._rawHashValue(seed:)(v21, v53, v22);
        uint64_t v3 = v45;
        uint64_t v37 = ~(-1 << *((unsigned char *)v45 + 32));
        for (unint64_t i = v37 & v23; ; unint64_t i = v37 & (i + 1))
        {
          uint64_t v25 = v3[(i >> 6) + 7];
          if (!_bittest64(&v25, i)) {
            break;
          }
          long long v26 = v38;
          uint64_t v27 = v53;
          v36(v38, v3[6] + v44 * i, v53);
          uint64_t v28 = lazy protocol witness table accessor for type URL and conformance URL(&lazy protocol witness table cache variable for type URL and conformance URL, (uint64_t)&protocol conformance descriptor for URL);
          LOBYTE(v49) = dispatch thunk of static Equatable.== infix(_:_:)(v26, v51, v27, v28);
          (*(void (**)(void (**)(void, void, void), uint64_t))(v48 + 8))(v26, v27);
          if (v49)
          {
            int v29 = (void (*)(char *, char *, uint64_t))v41;
            v41(v46, v51, v27);
            uint64_t v30 = v52;
            if (!swift_isUniquelyReferenced_nonNull_native(v52))
            {
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v30 + 2) + 1, 1);
              uint64_t v30 = v52;
            }
            uint64_t v4 = v50;
            unint64_t v31 = *((void *)v30 + 2);
            unint64_t v32 = *((void *)v30 + 3);
            unint64_t v33 = v31 + 1;
            if (v32 >> 1 <= v31)
            {
              unint64_t v49 = v31 + 1;
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v32 >= 2, v31 + 1, 1);
              unint64_t v33 = v49;
              uint64_t v30 = v52;
            }
            *((void *)v30 + 2) = v33;
            v29(&v30[v40 + v44 * v31], v46, v53);
            uint64_t v52 = v30;
            uint64_t v3 = v45;
            uint64_t v9 = v48;
            goto LABEL_11;
          }
        }
      }
      uint64_t v9 = v48;
      (*(void (**)(char *, uint64_t))(v48 + 8))(v51, v53);
      uint64_t v4 = v50;
LABEL_11:
      unint64_t v17 = v39 + 1;
      uint64_t v8 = v43;
      if (v39 + 1 == v42) {
        goto LABEL_18;
      }
    }
    char v34 = v50;
  }
  else
  {
LABEL_18:
    __swift_storeEnumTagSinglePayload((uint64_t)v8, 1, 1, v53);
    char v34 = v4;
  }
  swift_bridgeObjectRelease(v34);
  outlined destroy of URL?((uint64_t)v8);
  swift_bridgeObjectRelease((_BYTE)v3);
  return v52;
}

char static _ImageUtilities.getImageURLsAndObjectAnnotations(from:imageColumnName:labelColumnName:)(void (*a1)(ValueMetadata **, uint64_t), uint64_t a2, void *a3, uint64_t a4, void *a5, __m128 a6)
{
  uint64_t v295 = v7;
  v285._char object = a5;
  v285._uint64_t countAndFlagsBits = a4;
  uint64_t named = a3;
  v283._uint64_t countAndFlagsBits = a2;
  v290 = (void (*)(ValueMetadata **, uint64_t))a1;
  v282 = v6;
  v289._uint64_t countAndFlagsBits = type metadata accessor for DataFrame(0);
  v286 = *(char **)(v289._countAndFlagsBits - 8);
  int64_t v8 = *((void *)v286 + 8);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  v278 = &v241;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  v284 = &v241;
  uint64_t v13 = alloca(v8);
  uint64_t v14 = alloca(v8);
  v291._char object = &v241;
  uint64_t v15 = type metadata accessor for MLObjectDetector.DataSource(0);
  int64_t v16 = *(void *)(*(void *)(v15 - 8) + 64);
  unint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  v291._uint64_t countAndFlagsBits = type metadata accessor for URL(0);
  v287._uint64_t countAndFlagsBits = *(void *)(v291._countAndFlagsBits - 8);
  int64_t v19 = *(void *)(v287._countAndFlagsBits + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  v253 = &v241;
  uint64_t v22 = alloca(v19);
  uint64_t v23 = alloca(v19);
  v273 = &v241;
  uint64_t v24 = alloca(v19);
  uint64_t v25 = alloca(v19);
  v283._char object = &v241;
  long long v26 = alloca(v19);
  uint64_t v27 = alloca(v19);
  uint64_t v28 = alloca(v19);
  int v29 = alloca(v19);
  uint64_t v30 = alloca(v19);
  unint64_t v31 = alloca(v19);
  v289._char object = &v241;
  unint64_t v32 = alloca(v19);
  unint64_t v33 = alloca(v19);
  v294 = (ValueMetadata *)&v241;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v290, (uint64_t)&v241, type metadata accessor for MLObjectDetector.DataSource);
  switch(swift_getEnumCaseMultiPayload(&v241, v15))
  {
    case 0u:
      v291._char object = *(void **)(v287._countAndFlagsBits + 32);
      uint64_t countAndFlagsBits = v291._countAndFlagsBits;
      ((void (*)(ValueMetadata **, ValueMetadata **, uint64_t, unint64_t))v291._object)(&v241, &v241, v291._countAndFlagsBits, 0xE000000000000000);
      URL.resolvingSymlinksInPath()();
      URL.resolvingSymlinksInPath()();
      uint64_t v35 = *(void (**)(void, void))(v287._countAndFlagsBits + 8);
      v275 = &v241;
      v290 = (void (*)(ValueMetadata **, uint64_t))v35;
      v35(&v241, countAndFlagsBits);
      char object = v289._object;
      v279 = &v241;
      ((void (*)(void *, ValueMetadata **, uint64_t))v291._object)(v289._object, &v241, countAndFlagsBits);
      uint64_t v37 = countAndFlagsBits;
      goto LABEL_4;
    case 1u:
      uint64_t v38 = &v242[*(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL))
                         + 48)
                - 8];
      unint64_t v39 = *(void (**)(ValueMetadata **, char *, uint64_t))(v287._countAndFlagsBits + 32);
      v275 = &v241;
      uint64_t v40 = v291._countAndFlagsBits;
      uint64_t v41 = v39;
      v291._char object = v39;
      v39(&v241, (char *)&v241, v291._countAndFlagsBits);
      v41(&v241, v38, v40);
      URL.resolvingSymlinksInPath()();
      URL.resolvingSymlinksInPath()();
      uint64_t v42 = *(void (**)(ValueMetadata **, uint64_t))(v287._countAndFlagsBits + 8);
      v279 = &v241;
      v42(&v241, v40);
      v290 = v42;
      v42(v275, v40);
      char object = v289._object;
      ((void (*)(void *, void *, uint64_t))v291._object)(v289._object, v283._object, v40);
      uint64_t v37 = v40;
LABEL_4:
      uint64_t v43 = v294;
      uint64_t v44 = v295;
      uint64_t v45 = static _FileUtilities.getReadableJsonFilesInDirectory(at:)((uint64_t)object);
      int v46 = object;
      uint64_t v47 = v44;
      if (v44)
      {
        uint64_t v48 = (uint64_t (*)(void *, uint64_t))v290;
        v290((ValueMetadata **)v46, v37);
        unint64_t v49 = v43;
        return v48(v49, v37);
      }
      char v82 = v45;
      uint64_t v83 = *(ValueMetadata **)(v45 + 16);
      if ((unint64_t)v83 >= 2)
      {
        *(void *)&long long v254 = 0;
        *((void *)&v254 + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(58);
        v84._uint64_t countAndFlagsBits = 0xD000000000000037;
        v84._char object = "with object annotations." + 0x8000000000000000;
        String.append(_:)(v84);
        swift_bridgeObjectRelease(v82);
        v280 = v83;
        uint64_t v85 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
        char v87 = (char)v86;
        v84._uint64_t countAndFlagsBits = v85;
        v84._char object = v86;
        String.append(_:)(v84);
        swift_bridgeObjectRelease(v87);
        v84._uint64_t countAndFlagsBits = 46;
        v84._char object = (void *)0xE100000000000000;
        String.append(_:)(v84);
        Swift::String v287 = (Swift::String)v254;
        uint64_t v88 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v88, 0, 0);
        *(Swift::String *)uint64_t v89 = v287;
        *(_OWORD *)(v89 + 16) = 0;
        *(_OWORD *)(v89 + 32) = 0;
        *(unsigned char *)(v89 + 48) = 0;
LABEL_26:
        swift_willThrow(&type metadata for MLCreateError, v88, v89, v90, v91, v92);
        uint64_t v118 = v291._countAndFlagsBits;
        char v119 = (uint64_t (*)(ValueMetadata *, uint64_t))v290;
        v290((ValueMetadata **)v289._object, v291._countAndFlagsBits);
        return v119(v294, v118);
      }
      if (!v83)
      {
        swift_bridgeObjectRelease(v45);
        uint64_t v88 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v88, 0, 0);
        *(void *)uint64_t v89 = 0xD000000000000058;
        *(void *)(v89 + 8) = " specified data source." + 0x8000000000000000;
        *(_OWORD *)(v89 + 16) = 0;
        *(_OWORD *)(v89 + 32) = 0;
        *(unsigned char *)(v89 + 48) = 0;
        goto LABEL_26;
      }
      uint64_t v111 = (char *)((*(unsigned __int8 *)(v287._countAndFlagsBits + 80) + 32) & ~*(unsigned __int8 *)(v287._countAndFlagsBits + 80));
      uint64_t v112 = v273;
      v291._char object = *(void **)(v287._countAndFlagsBits + 16);
      ((void (*)(ValueMetadata **, char *, uint64_t))v291._object)(v273, &v111[v45], v291._countAndFlagsBits);
      swift_bridgeObjectRelease(v82);
      LOBYTE(v254) = 1;
      *(_DWORD *)((char *)&v254 + 1) = *(_DWORD *)v249;
      DWORD1(v254) = *(_DWORD *)&v249[3];
      *((void *)&v254 + 1) = 44;
      unint64_t v255 = 0xE100000000000000;
      uint64_t v256 = 0;
      char v288 = 1;
      unint64_t v257 = 0xE000000000000000;
      uint64_t v258 = 92;
      unint64_t v259 = 0xE100000000000000;
      char v260 = 1;
      *(_DWORD *)v261 = *(_DWORD *)v250;
      *(_DWORD *)&v261[3] = *(_DWORD *)&v250[3];
      uint64_t v262 = 34;
      unint64_t v263 = 0xE100000000000000;
      char v264 = 1;
      *(_DWORD *)&v265[3] = *(_DWORD *)&v251[3];
      *(_DWORD *)v265 = *(_DWORD *)v251;
      v266 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
      uint64_t v267 = 10;
      unint64_t v268 = 0xE100000000000000;
      long long v269 = 0;
      char v270 = 1;
      *(_DWORD *)v271 = *(_DWORD *)v252;
      *(_DWORD *)&v271[3] = *(_DWORD *)&v252[3];
      uint64_t v272 = 0;
      MLDataTable.init(contentsOf:options:)(v112, &v254);
      v283._char object = v111;
      if (!named)
      {
        *(void *)&long long v254 = v292;
        BYTE8(v254) = v293;
        LOBYTE(v280) = 2;
        outlined copy of Result<_DataTable, Error>(v292, v293);
        uint64_t v126 = specialized static _ImageUtilities.findColumnWithNonDefaultName(from:directoryURL:columnType:defaultName:validateContentFunc:)((uint64_t)&v254, (uint64_t)v294, (unsigned __int8 *)&v280, 0x6C69666567616D69, (void *)0xED0000656D616E65, (uint64_t (*)(unint64_t *))closure #1 in Sequence<>.contains(_:)specialized partial apply, (uint64_t (*)(Swift::String *, uint64_t, void, uint64_t *, void, uint64_t))specialized closure #1 in static _ImageUtilities.findColumnWithNonDefaultName(from:directoryURL:columnType:defaultName:validateContentFunc:));
        uint64_t v138 = v137;
        uint64_t v295 = 0;
        v289._uint64_t countAndFlagsBits = v126;
        outlined consume of Result<_DataTable, Error>(v254, SBYTE8(v254));
        MLDataTable.willMutate()();
        v139._uint64_t countAndFlagsBits = v289._countAndFlagsBits;
        v139._char object = v138;
        v140._uint64_t countAndFlagsBits = 0x6C69666567616D69;
        v140._char object = (void *)0xED0000656D616E65;
        MLDataTable.renameImpl(named:to:)(v139, v140);
        if (!(_BYTE)v293)
        {
          uint64_t v141 = v292;
          outlined copy of Result<_DataTable, Error>(v292, 0);
          _DataTable.columnNamesDidChange()();
          outlined consume of Result<_DataTable, Error>(v141, 0);
        }
        swift_bridgeObjectRelease((_BYTE)v138);
        goto LABEL_53;
      }
      uint64_t v120 = v283._countAndFlagsBits;
      if ((v283._countAndFlagsBits != 0x6C69666567616D69 || named != (void *)0xED0000656D616E65)
        && (_stringCompareWithSmolCheck(_:_:expecting:)(v283._countAndFlagsBits, named, 0x6C69666567616D69, 0xED0000656D616E65, 0) & 1) == 0)
      {
        uint64_t v295 = 0;
        MLDataTable.willMutate()();
        v121._uint64_t countAndFlagsBits = v120;
        v121._char object = named;
        v122._uint64_t countAndFlagsBits = 0x6C69666567616D69;
        v122._char object = (void *)0xED0000656D616E65;
        MLDataTable.renameImpl(named:to:)(v121, v122);
        if (!(_BYTE)v293)
        {
          uint64_t v123 = v292;
          outlined copy of Result<_DataTable, Error>(v292, 0);
          _DataTable.columnNamesDidChange()();
          outlined consume of Result<_DataTable, Error>(v123, 0);
        }
LABEL_53:
        uint64_t v47 = v295;
      }
      uint64_t v142 = v285._object;
      if (v285._object)
      {
        uint64_t v295 = v47;
        if ((v285._countAndFlagsBits != 0x697461746F6E6E61 || v285._object != (void *)0xEA00000000006E6FLL)
          && (_stringCompareWithSmolCheck(_:_:expecting:)(v285._countAndFlagsBits, v285._object, 0x697461746F6E6E61, 0xEA00000000006E6FLL, 0) & 1) == 0)
        {
          MLDataTable.willMutate()();
          v143._uint64_t countAndFlagsBits = v285._countAndFlagsBits;
          v143._char object = v142;
          v144._uint64_t countAndFlagsBits = 0x697461746F6E6E61;
          v144._char object = (void *)0xEA00000000006E6FLL;
          MLDataTable.renameImpl(named:to:)(v143, v144);
          if (!(_BYTE)v293)
          {
            uint64_t v145 = v292;
            outlined copy of Result<_DataTable, Error>(v292, 0);
            _DataTable.columnNamesDidChange()();
            outlined consume of Result<_DataTable, Error>(v145, 0);
          }
        }
      }
      else
      {
        *(void *)&long long v254 = v292;
        BYTE8(v254) = v293;
        LOBYTE(v280) = 3;
        outlined copy of Result<_DataTable, Error>(v292, v293);
        uint64_t v146 = v294;
        uint64_t v147 = specialized static _ImageUtilities.findColumnWithNonDefaultName(from:directoryURL:columnType:defaultName:validateContentFunc:)((uint64_t)&v254, (uint64_t)v294, (unsigned __int8 *)&v280, 0x697461746F6E6E61, (void *)0xEA00000000006E6FLL, (uint64_t (*)(unint64_t *))closure #1 in Sequence<>.contains(_:)specialized partial apply, (uint64_t (*)(Swift::String *, uint64_t, void, uint64_t *, void, uint64_t))specialized closure #1 in static _ImageUtilities.findColumnWithNonDefaultName(from:directoryURL:columnType:defaultName:validateContentFunc:));
        if (v47)
        {
          outlined consume of Result<_DataTable, Error>(v254, SBYTE8(v254));
LABEL_68:
          uint64_t v165 = v291._countAndFlagsBits;
          double v166 = (void (*)(ValueMetadata *, uint64_t))v290;
          v290((ValueMetadata **)v289._object, v291._countAndFlagsBits);
          uint64_t v167 = v146;
          goto LABEL_69;
        }
        uint64_t v149 = v147;
        uint64_t v150 = v148;
        uint64_t v295 = 0;
        outlined consume of Result<_DataTable, Error>(v254, SBYTE8(v254));
        MLDataTable.willMutate()();
        v151._uint64_t countAndFlagsBits = v149;
        v151._char object = v150;
        v152._uint64_t countAndFlagsBits = 0x697461746F6E6E61;
        v152._char object = (void *)0xEA00000000006E6FLL;
        MLDataTable.renameImpl(named:to:)(v151, v152);
        if (!(_BYTE)v293)
        {
          uint64_t v153 = v292;
          outlined copy of Result<_DataTable, Error>(v292, 0);
          _DataTable.columnNamesDidChange()();
          outlined consume of Result<_DataTable, Error>(v153, 0);
        }
        swift_bridgeObjectRelease((_BYTE)v150);
      }
      uint64_t v154 = v292;
      int v155 = v293;
      v278 = (ValueMetadata **)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
      uint64_t inited = swift_initStackObject(v278, v247);
      *(void *)(inited + 16) = 1;
      *(void *)(inited + 24) = 2;
      strcpy((char *)(inited + 32), "imagefilename");
      *(_WORD *)(inited + 46) = -4864;
      *(void *)&long long v254 = v154;
      LOBYTE(v284) = v155 & 1;
      BYTE8(v254) = v155 & 1;
      v286 = (char *)v154;
      LODWORD(v289._countAndFlagsBits) = v155;
      outlined copy of Result<_DataTable, Error>(v154, v155);
      uint64_t v157 = v295;
      static _ValidationUtilities.validateTableFormat(table:context:columns:)((uint64_t)&v254, 0x6C69466567616D49, (void *)0xED0000656D614E65, inited);
      if (v157)
      {
        uint64_t v295 = v157;
        swift_bridgeObjectRelease(inited);
        outlined consume of Result<_DataTable, Error>((uint64_t)v286, v289._countAndFlagsBits);
        uint64_t v161 = v291._countAndFlagsBits;
        uint64_t v162 = (void (*)(ValueMetadata *, uint64_t))v290;
        v290((ValueMetadata **)v289._object, v291._countAndFlagsBits);
        v162(v294, v161);
        return outlined consume of Result<_DataTable, Error>(v292, v293);
      }
      uint64_t v158 = (uint64_t)v286;
      *(void *)&long long v254 = v286;
      BYTE8(v254) = (_BYTE)v284;
      uint64_t v159 = (void *)swift_initStackObject(v278, v248);
      v159[2] = 1;
      v159[3] = 2;
      v159[4] = 0x697461746F6E6E61;
      v159[5] = 0xEA00000000006E6FLL;
      static _ValidationUtilities.validateTableFormat(table:context:columns:)((uint64_t)&v254, 0x697461746F6E6E41, (void *)0xEA00000000006E6FLL, (uint64_t)v159);
      uint64_t v160 = v158;
      uint64_t v295 = 0;
      swift_setDeallocating(v159);
      specialized _ContiguousArrayStorage.__deallocating_deinit();
      outlined consume of Result<_DataTable, Error>(v158, v289._countAndFlagsBits);
      swift_setDeallocating(inited);
      specialized _ContiguousArrayStorage.__deallocating_deinit();
      uint64_t v146 = v294;
      uint64_t v163 = v295;
      uint64_t v164 = static _ImageUtilities.getImageURLs(at:)(v294);
      if (v163) {
        goto LABEL_68;
      }
      v285._char object = v164;
      uint64_t v295 = 0;
      *(void *)&long long v254 = v160;
      BYTE8(v254) = (_BYTE)v284;
      v168._uint64_t countAndFlagsBits = 0x6C69666567616D69;
      v168._char object = (void *)0xED0000656D616E65;
      MLDataTable.subscript.getter(v168);
      uint64_t v169 = v280;
      if ((_BYTE)v281)
      {
        outlined consume of Result<_DataTable, Error>((uint64_t)v280, 1);
        char v296 = 6;
        uint64_t v170 = 0;
        v276 = 0;
        v283._uint64_t countAndFlagsBits = 0;
      }
      else
      {
        swift_retain();
        uint64_t v170 = 0;
        _UntypedColumn.valueAtIndex(index:)(0, 0.0);
        outlined consume of Result<_DataTable, Error>((uint64_t)v169, 0);
        outlined consume of Result<_DataTable, Error>((uint64_t)v169, 0);
        unint64_t v171 = *((void *)&v254 + 1);
        unsigned long long v173 = v254;
        v283._uint64_t countAndFlagsBits = v173 >> 64;
        uint64_t v172 = v173;
        v276 = (void *)v254;
        if ((_BYTE)v255 == 2)
        {
          swift_bridgeObjectRetain(BYTE8(v254));
          char v296 = 2;
          uint64_t v170 = v172;
          goto LABEL_76;
        }
        char v296 = v255;
      }
      unint64_t v171 = 0xE000000000000000;
LABEL_76:
      *(void *)&long long v254 = v170;
      *((void *)&v254 + 1) = v171;
      v280 = (ValueMetadata *)(&stru_20 + 15);
      unint64_t v281 = 0xE100000000000000;
      uint64_t named = (void *)lazy protocol witness table accessor for type String and conformance String();
      uint64_t v174 = StringProtocol.components<A>(separatedBy:)(&v280, &type metadata for String, &type metadata for String, named, named);
      swift_bridgeObjectRelease(v171);
      v285._uint64_t countAndFlagsBits = *(void *)(v174 + 16);
      swift_bridgeObjectRelease(v174);
      uint64_t v175 = v285._object;
      int64_t v176 = *((void *)v285._object + 2);
      if (v176)
      {
        *(void *)&long long v254 = _swiftEmptyArrayStorage;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v176, 0);
        v289._uint64_t countAndFlagsBits = *(void *)(v287._countAndFlagsBits + 72);
        v287._uint64_t countAndFlagsBits = (uint64_t)v283._object + (unint64_t)v175;
        v177 = (char *)v283._object + (unint64_t)v175;
        v273 = (ValueMetadata **)v176;
        uint64_t v178 = (char *)v176;
        char v179 = v279;
        uint64_t v180 = v275;
        int64_t v181 = (void (*)(ValueMetadata **, char *, uint64_t))v291._object;
        do
        {
          v283._char object = v178;
          v286 = v177;
          uint64_t v182 = v291._countAndFlagsBits;
          v181(v180, v177, v291._countAndFlagsBits);
          URL.resolvingSymlinksInPath()();
          v284 = (ValueMetadata **)URL.path.getter(v180);
          v278 = v183;
          uint64_t v184 = v179;
          uint64_t v185 = v290;
          v290(v184, v182);
          v185(v180, v182);
          uint64_t v186 = v254;
          if (!swift_isUniquelyReferenced_nonNull_native(v254))
          {
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(v186 + 16) + 1, 1);
            uint64_t v186 = v254;
          }
          unint64_t v187 = *(void *)(v186 + 16);
          unint64_t v188 = v187 + 1;
          char v179 = v279;
          if (*(void *)(v186 + 24) >> 1 <= v187)
          {
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(*(void *)(v186 + 24) >= 2uLL, v187 + 1, 1);
            unint64_t v188 = v187 + 1;
            char v179 = v279;
            uint64_t v186 = v254;
          }
          *(void *)(v186 + 16) = v188;
          uint64_t v189 = 16 * v187;
          *(void *)(v186 + v189 + 32) = v284;
          *(void *)(v186 + v189 + 40) = v278;
          v177 = &v286[v289._countAndFlagsBits];
          uint64_t v178 = (char *)v283._object - 1;
          int64_t v181 = (void (*)(ValueMetadata **, char *, uint64_t))v291._object;
        }
        while (v283._object != (char *)&dword_0 + 1);
        v284 = (ValueMetadata **)v186;
        v277 = _swiftEmptyArrayStorage;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, (int64_t)v273, 0);
        uint64_t v190 = (void (*)(ValueMetadata **, uint64_t, uint64_t))v291._object;
        uint64_t v191 = v291._countAndFlagsBits;
        uint64_t v192 = v287._countAndFlagsBits;
        do
        {
          uint64_t v193 = v253;
          v287._uint64_t countAndFlagsBits = v192;
          v190(v253, v192, v191);
          *(void *)&long long v194 = URL.path.getter(v193);
          char v195 = BYTE8(v194);
          long long v254 = v194;
          v280 = (ValueMetadata *)(&stru_20 + 15);
          unint64_t v281 = 0xE100000000000000;
          uint64_t v196 = StringProtocol.components<A>(separatedBy:)(&v280, &type metadata for String, &type metadata for String, named, named);
          swift_bridgeObjectRelease(v195);
          unint64_t v197 = *(void *)(v196 + 16);
          uint64_t v198 = 2 * v197 + 1;
          BOOL v199 = v197 < v285._countAndFlagsBits;
          unint64_t v200 = v197 - v285._countAndFlagsBits;
          unint64_t v201 = 0;
          if (!v199) {
            unint64_t v201 = v200;
          }
          *(void *)&long long v254 = v196;
          *((void *)&v254 + 1) = v196 + 32;
          unint64_t v255 = v201;
          uint64_t v256 = v198;
          uint64_t v202 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ArraySlice<String>);
          uint64_t v203 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type ArraySlice<String> and conformance ArraySlice<A>, &demangling cache variable for type metadata for ArraySlice<String>, (uint64_t)&protocol conformance descriptor for ArraySlice<A>);
          uint64_t v204 = v202;
          uint64_t v191 = v291._countAndFlagsBits;
          v286 = (char *)BidirectionalCollection<>.joined(separator:)(47, 0xE100000000000000, v204, v203);
          v283._char object = v205;
          swift_bridgeObjectRelease(v196);
          v290(v253, v191);
          uint64_t v206 = v277;
          if (!swift_isUniquelyReferenced_nonNull_native(v277))
          {
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v206[2] + 1, 1);
            uint64_t v206 = v277;
          }
          unint64_t v207 = v206[2];
          if (v206[3] >> 1 <= v207)
          {
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v206[3] >= 2uLL, v207 + 1, 1);
            uint64_t v206 = v277;
          }
          v206[2] = v207 + 1;
          uint64_t v208 = 2 * v207;
          v206[v208 + 4] = v286;
          v206[v208 + 5] = v283._object;
          uint64_t v192 = v289._countAndFlagsBits + v287._countAndFlagsBits;
          BOOL v209 = v273 == (ValueMetadata **)((char *)&dword_0 + 1);
          v273 = (ValueMetadata **)((char *)v273 - 1);
          uint64_t v190 = (void (*)(ValueMetadata **, uint64_t, uint64_t))v291._object;
        }
        while (!v209);
        swift_bridgeObjectRelease(v285._object);
      }
      else
      {
        swift_bridgeObjectRelease(v285._object);
        uint64_t v206 = _swiftEmptyArrayStorage;
        v284 = (ValueMetadata **)_swiftEmptyArrayStorage;
      }
      uint64_t v210 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MLUntypedColumn)>);
      uint64_t v211 = swift_initStackObject(v210, v242);
      v287._uint64_t countAndFlagsBits = (uint64_t)&v241;
      *(void *)(v211 + 16) = 2;
      *(void *)(v211 + 24) = 4;
      *(void *)(v211 + 32) = 0x7461506567616D69;
      *(void *)(v211 + 40) = 0xE900000000000068;
      *(void *)&long long v254 = v284;
      v212 = alloca(24);
      uint64_t v213 = alloca(32);
      v243 = &v254;
      uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
      char v216 = v215;
      swift_bridgeObjectRelease(v254);
      v287._uint64_t countAndFlagsBits = (uint64_t)&v241;
      *(void *)(v211 + 48) = ML14_UntypedColumnC_s5Error_pTgm5;
      *(unsigned char *)(v211 + 56) = v216 & 1;
      strcpy((char *)(v211 + 64), "imagefilename");
      *(_WORD *)(v211 + 78) = -4864;
      *(void *)&long long v254 = v206;
      v217 = alloca(24);
      uint64_t v218 = alloca(32);
      v243 = &v254;
      uint64_t v219 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
      char v221 = v220;
      swift_bridgeObjectRelease(v254);
      *(void *)(v211 + 80) = v219;
      *(unsigned char *)(v211 + 88) = v221 & 1;
      uint64_t v222 = Dictionary.init(dictionaryLiteral:)(v211, &type metadata for String, &type metadata for MLUntypedColumn, &protocol witness table for String);
      uint64_t v223 = v295;
      specialized MLDataTable.init<A>(uniqueKeysWithValues:)(v222);
      if (!v223)
      {
        uint64_t v295 = 0;
        uint64_t v224 = v254;
        char v225 = BYTE8(v254);
        LODWORD(v291._object) = BYTE8(v254);
        uint64_t v226 = v292;
        char v227 = v293;
        *(void *)&long long v254 = 0x72656E6E69;
        *((void *)&v254 + 1) = 0xE500000000000000;
        outlined copy of Result<_DataTable, Error>(v292, v293);
        outlined copy of Result<_DataTable, Error>(v224, v225);
        v287._uint64_t countAndFlagsBits = specialized binaryDo<A, B, C>(_:_:_:)(v226, v227, v224, v225, (uint64_t)&outlined read-only object #0 of static _ImageUtilities.getImageURLsAndObjectAnnotations(from:imageColumnName:labelColumnName:), (uint64_t *)&v254);
        char v229 = v228;
        v289._uint64_t countAndFlagsBits = v224;
        uint64_t v230 = v224;
        char v231 = (char)v291._object;
        outlined consume of Result<_DataTable, Error>(v230, (char)v291._object);
        outlined consume of Result<_DataTable, Error>(v226, v227);
        outlined consume of Result<_DataTable, Error>(v226, v227);
        uint64_t v292 = v287._countAndFlagsBits;
        LOBYTE(v293) = v229 & 1;
        *(void *)&long long v254 = v287._countAndFlagsBits;
        BYTE8(v254) = v229 & 1;
        if (MLDataTable.size.getter())
        {
          outlined consume of Result<_DataTable, Error>(v289._countAndFlagsBits, v231);
          outlined consume of MLDataValue(v276, (void *)v283._countAndFlagsBits, v296);
          uint64_t v232 = v291._countAndFlagsBits;
          v233 = (void (*)(ValueMetadata *, uint64_t))v290;
          v290((ValueMetadata **)v289._object, v291._countAndFlagsBits);
          v233(v294, v232);
          char result = v292;
          char v234 = v293;
          v235 = v282;
          void *v282 = v292;
          *((unsigned char *)v235 + 8) = v234;
          return result;
        }
        uint64_t v236 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v236, 0, 0);
        *(void *)uint64_t v237 = 0xD000000000000026;
        *(void *)(v237 + 8) = "llowing error state: " + 0x8000000000000000;
        *(_OWORD *)(v237 + 16) = 0;
        *(_OWORD *)(v237 + 32) = 0;
        *(unsigned char *)(v237 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v236, v237, v238, v239, v240);
        outlined consume of Result<_DataTable, Error>(v289._countAndFlagsBits, v231);
      }
      outlined consume of MLDataValue(v276, (void *)v283._countAndFlagsBits, v296);
      uint64_t v165 = v291._countAndFlagsBits;
      double v166 = (void (*)(ValueMetadata *, uint64_t))v290;
      v290((ValueMetadata **)v289._object, v291._countAndFlagsBits);
      uint64_t v167 = v294;
LABEL_69:
      v166(v167, v165);
      uint64_t v61 = v292;
      char v62 = v293;
      return outlined consume of Result<_DataTable, Error>(v61, v62);
    case 2u:
      uint64_t v51 = v241;
      uint64_t v52 = v244;
      char v53 = v246;
      if (v242[0])
      {
        v294 = v241;
        swift_errorRetain(v241);
        swift_bridgeObjectRelease(v53);
        swift_bridgeObjectRelease((_BYTE)v52);
        *(void *)&long long v254 = 0;
        *((void *)&v254 + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(87);
        v54._uint64_t countAndFlagsBits = 0xD000000000000055;
        v54._char object = " required columns." + 0x8000000000000000;
        String.append(_:)(v54);
        uint64_t v55 = v294;
        v280 = v294;
        uint64_t v56 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
        _print_unlocked<A, B>(_:_:)(&v280, &v254, v56, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
        Swift::String v287 = (Swift::String)v254;
        v54._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v54._object, 0, 0);
        *(Swift::String *)uint64_t v57 = v287;
        *(_OWORD *)(v57 + 16) = 0;
        *(_OWORD *)(v57 + 32) = 0;
        *(unsigned char *)(v57 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v54._object, v57, v58, v59, v60);
        outlined consume of Result<_DataTable, Error>((uint64_t)v55, 1);
        uint64_t v61 = (uint64_t)v55;
        char v62 = 1;
        return outlined consume of Result<_DataTable, Error>(v61, v62);
      }
      v287._uint64_t countAndFlagsBits = v246;
      Swift::String v93 = v243;
      v291._uint64_t countAndFlagsBits = v245;
      outlined copy of Result<_DataTable, Error>((uint64_t)v241, 0);
      _DataTable.columnNames.getter(v51);
      outlined consume of Result<_DataTable, Error>((uint64_t)v51, 0);
      v291._char object = v93;
      *(void *)&long long v254 = v93;
      v290 = (void (*)(ValueMetadata **, uint64_t))v52;
      *((void *)&v254 + 1) = v52;
      char v94 = alloca(24);
      uint64_t v95 = alloca(32);
      v243 = &v254;
      uint64_t v96 = v295;
      LOBYTE(v93) = specialized Sequence.contains(where:)((uint64_t (*)(unint64_t *))partial apply for specialized closure #1 in Sequence<>.contains(_:), (uint64_t)&v241, (uint64_t)v280);
      uint64_t v295 = v96;
      swift_release();
      if ((v93 & 1) == 0) {
        goto LABEL_23;
      }
      outlined copy of Result<_DataTable, Error>((uint64_t)v51, 0);
      _DataTable.columnNames.getter(v51);
      outlined consume of Result<_DataTable, Error>((uint64_t)v51, 0);
      *(void *)&long long v254 = v291._countAndFlagsBits;
      *((void *)&v254 + 1) = v287._countAndFlagsBits;
      uint64_t v97 = alloca(24);
      char v98 = alloca(32);
      v243 = &v254;
      uint64_t v99 = v295;
      char v100 = specialized Sequence.contains(where:)((uint64_t (*)(unint64_t *))closure #1 in Sequence<>.contains(_:)specialized partial apply, (uint64_t)&v241, (uint64_t)v280);
      uint64_t v295 = v99;
      swift_release();
      if ((v100 & 1) == 0)
      {
LABEL_23:
        swift_bridgeObjectRelease(v287._countAndFlagsBits);
        swift_bridgeObjectRelease((_BYTE)v290);
        uint64_t v113 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v113, 0, 0);
        *(void *)uint64_t v114 = 0xD000000000000022;
        *(void *)(v114 + 8) = "aining checkpoint." + 0x8000000000000000;
        *(_OWORD *)(v114 + 16) = 0;
        *(_OWORD *)(v114 + 32) = 0;
        *(unsigned char *)(v114 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v113, v114, v115, v116, v117);
        uint64_t v61 = (uint64_t)v51;
        char v62 = 0;
        return outlined consume of Result<_DataTable, Error>(v61, v62);
      }
      v294 = v51;
      *(void *)&long long v254 = v51;
      BYTE8(v254) = 0;
      uint64_t v101 = v291._object;
      uint64_t v102 = v290;
      if (v291._object == (void *)0x6C69666567616D69
        && v290 == (void (*)(ValueMetadata **, uint64_t))0xED0000656D616E65)
      {
        LODWORD(v289._object) = 0;
        uint64_t v103 = v294;
        outlined copy of Result<_DataTable, Error>((uint64_t)v294, 0);
        swift_bridgeObjectRelease(101);
        v291._char object = v103;
        uint64_t v104 = v282;
        uint64_t v105 = v291._countAndFlagsBits;
      }
      else
      {
        char v124 = _stringCompareWithSmolCheck(_:_:expecting:)(v291._object, v290, 0x6C69666567616D69, 0xED0000656D616E65, 0);
        uint64_t v125 = v294;
        outlined copy of Result<_DataTable, Error>((uint64_t)v294, 0);
        if (v124)
        {
          swift_bridgeObjectRelease((_BYTE)v102);
          LODWORD(v289._object) = 0;
          v291._char object = v125;
          uint64_t v105 = v291._countAndFlagsBits;
        }
        else
        {
          MLDataTable.willMutate()();
          v127._uint64_t countAndFlagsBits = 0x7461506567616D69;
          v127._char object = (void *)0xE900000000000068;
          v128._uint64_t countAndFlagsBits = (uint64_t)v101;
          v128._char object = v102;
          MLDataTable.renameImpl(named:to:)(v128, v127);
          uint64_t v129 = v254;
          uint64_t v105 = v291._countAndFlagsBits;
          v291._char object = (void *)v254;
          if (BYTE8(v254))
          {
            uint64_t v130 = swift_bridgeObjectRelease((_BYTE)v102);
            LOBYTE(v130) = 1;
            LODWORD(v289._object) = v130;
          }
          else
          {
            LODWORD(v289._object) = 0;
            outlined copy of Result<_DataTable, Error>(v254, 0);
            _DataTable.columnNamesDidChange()();
            outlined consume of Result<_DataTable, Error>(v129, 0);
            swift_bridgeObjectRelease((_BYTE)v102);
          }
        }
        uint64_t v104 = v282;
      }
      if (v105 == 0x697461746F6E6E61 && v287._countAndFlagsBits == 0xEA00000000006E6FLL)
      {
        outlined consume of Result<_DataTable, Error>((uint64_t)v294, 0);
        char v131 = 111;
LABEL_45:
        swift_bridgeObjectRelease(v131);
        uint64_t v134 = v291._object;
        char result = (char)v289._object;
        goto LABEL_49;
      }
      uint64_t v132 = v105;
      uint64_t v133 = (void *)v287._countAndFlagsBits;
      if (_stringCompareWithSmolCheck(_:_:expecting:)(v132, v287._countAndFlagsBits, 0x697461746F6E6E61, 0xEA00000000006E6FLL, 0))
      {
        outlined consume of Result<_DataTable, Error>((uint64_t)v294, 0);
        char v131 = (char)v133;
        goto LABEL_45;
      }
      MLDataTable.willMutate()();
      v135._uint64_t countAndFlagsBits = v291._countAndFlagsBits;
      v135._char object = v133;
      v136._uint64_t countAndFlagsBits = 0x697461746F6E6E61;
      v136._char object = (void *)0xEA00000000006E6FLL;
      MLDataTable.renameImpl(named:to:)(v135, v136);
      uint64_t v134 = (void *)v254;
      if (BYTE8(v254))
      {
        outlined consume of Result<_DataTable, Error>((uint64_t)v294, 0);
        swift_bridgeObjectRelease((_BYTE)v133);
        char result = 1;
      }
      else
      {
        outlined copy of Result<_DataTable, Error>(v254, 0);
        _DataTable.columnNamesDidChange()();
        outlined consume of Result<_DataTable, Error>((uint64_t)v134, 0);
        outlined consume of Result<_DataTable, Error>((uint64_t)v294, 0);
        swift_bridgeObjectRelease((_BYTE)v133);
        char result = 0;
      }
LABEL_49:
      void *v104 = v134;
      *((unsigned char *)v104 + 8) = result;
      return result;
    case 3u:
      uint64_t v63 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, annotationColumn: String));
      uint64_t v64 = *(int *)(v63 + 48);
      uint64_t v65 = *(void *)&v242[v64 - 8];
      uint64_t v66 = *(void **)&v242[v64];
      uint64_t v67 = *(int *)(v63 + 64);
      v287._uint64_t countAndFlagsBits = *(void *)&v242[v67 - 8];
      v294 = *(ValueMetadata **)&v242[v67];
      (*((void (**)(void *, ValueMetadata **, uint64_t))v286 + 4))(v291._object, &v241, v289._countAndFlagsBits);
      v68._uint64_t countAndFlagsBits = v65;
      v68._char object = v66;
      Swift::Int_optional v69 = DataFrame.indexOfColumn(_:)(v68);
      Swift::Int value = v69.value;
      Swift::Bool is_nil = v69.is_nil;
      swift_bridgeObjectRelease((_BYTE)v66);
      if (is_nil)
      {
        swift_bridgeObjectRelease((_BYTE)v294);
        goto LABEL_20;
      }
      v72._uint64_t countAndFlagsBits = v287._countAndFlagsBits;
      char v73 = (char)v294;
      v72._char object = v294;
      Swift::Int_optional v74 = DataFrame.indexOfColumn(_:)(v72);
      Swift::Int v75 = v74.value;
      Swift::Bool v76 = v74.is_nil;
      swift_bridgeObjectRelease(v73);
      if (v76)
      {
LABEL_20:
        uint64_t v106 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v106, 0, 0);
        *(void *)uint64_t v107 = 0xD000000000000022;
        *(void *)(v107 + 8) = "aining checkpoint." + 0x8000000000000000;
        *(_OWORD *)(v107 + 16) = 0;
        *(_OWORD *)(v107 + 32) = 0;
        *(unsigned char *)(v107 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v106, v107, v108, v109, v110);
        return (*((uint64_t (**)(void *, uint64_t))v286 + 1))(v291._object, v289._countAndFlagsBits);
      }
      v294 = (ValueMetadata *)*((void *)v286 + 2);
      uint64_t v77 = v284;
      ((void (*)(ValueMetadata **, void *, uint64_t))v294)(v284, v291._object, v289._countAndFlagsBits);
      uint64_t v78 = (void (*)(long long *, void))DataFrame.subscript.modify(&v254, value);
      AnyColumn.name.setter(0x7461506567616D69, 0xE900000000000068);
      v78(&v254, 0);
      uint64_t v79 = (void (*)(long long *, void))DataFrame.subscript.modify(&v254, v75);
      AnyColumn.name.setter(0x697461746F6E6E61, 0xEA00000000006E6FLL);
      uint64_t v80 = v77;
      uint64_t v37 = v289._countAndFlagsBits;
      v79(&v254, 0);
      uint64_t v81 = (uint64_t)v278;
      *(double *)a6.i64 = ((double (*)(ValueMetadata **, ValueMetadata **, uint64_t))v294)(v278, v80, v37);
      MLDataTable.init(_:convertArraysToShapedArrays:)(v81, 0, a6);
      uint64_t v48 = (uint64_t (*)(void *, uint64_t))*((void *)v286 + 1);
      v48(v80, v37);
      unint64_t v49 = v291._object;
      return v48(v49, v37);
  }
}

uint64_t static _ImageUtilities.validateOneImageURL(from:)()
{
  URL._bridgeToObjectiveC()(v0);
  CFURLRef v2 = v1;
  unsigned int v3 = 0;
  uint64_t v4 = CGImageSourceCreateWithURL(v1, 0);

  if (v4)
  {
    unsigned int v3 = 0;
    CFDictionaryRef v5 = CGImageSourceCopyPropertiesAtIndex(v4, 0, 0);

    if (v5)
    {

      LOBYTE(v3) = 1;
    }
  }
  return v3;
}

void *static _ImageUtilities.validateImageURLs(from:)(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for URL(0);
  uint64_t v2 = *(void *)(v1 - 8);
  int64_t v3 = *(void *)(v2 + 64);
  uint64_t v4 = alloca(v3);
  CFDictionaryRef v5 = alloca(v3);
  uint64_t v48 = &v38;
  uint64_t v6 = alloca(v3);
  uint64_t v7 = alloca(v3);
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  uint64_t v11 = &v38;
  uint64_t v12 = *(void *)(a1 + 16);
  uint64_t v49 = a1;
  if (v12)
  {
    uint64_t v42 = v12;
    uint64_t v44 = (*(unsigned __int8 *)(v2 + 80) + 32) & ~*(unsigned __int8 *)(v2 + 80);
    uint64_t v13 = v44 + a1;
    uint64_t v45 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v2 + 16);
    uint64_t v47 = *(void *)(v2 + 72);
    swift_bridgeObjectRetain(a1);
    char v53 = _swiftEmptyArrayStorage;
    uint64_t v43 = "es or has incorrect format." + 0x8000000000000000;
    uint64_t v46 = v1;
    uint64_t v40 = v2;
    uint64_t v52 = &v38;
    uint64_t v41 = &v38;
    while (1)
    {
      v45(v11, v13, v1);
      __swift_storeEnumTagSinglePayload((uint64_t)v11, 0, 1, v1);
      if (__swift_getEnumTagSinglePayload((uint64_t)v11, 1, v1) == 1) {
        break;
      }
      uint64_t v38 = v13;
      uint64_t v14 = *(uint64_t (**)(uint64_t *, uint64_t *, uint64_t))(v2 + 32);
      uint64_t v15 = (NSURL *)v14(v52, v11, v1);
      URL._bridgeToObjectiveC()(v15);
      CFURLRef v17 = v16;
      uint64_t v18 = CGImageSourceCreateWithURL(v16, 0);

      if (v18 && (CFDictionaryRef v19 = CGImageSourceCopyPropertiesAtIndex(v18, 0, 0), v18, v19))
      {

        uint64_t v1 = v46;
        v45(v48, (uint64_t)v52, v46);
        uint64_t v20 = v53;
        if (!swift_isUniquelyReferenced_nonNull_native(v53)) {
          uint64_t v20 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v20[2] + 1, 1, (uint64_t)v20);
        }
        unint64_t v21 = v20[2];
        if (v20[3] >> 1 <= v21) {
          uint64_t v20 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v20[3] >= 2uLL, v21 + 1, 1, (uint64_t)v20);
        }
        void v20[2] = v21 + 1;
        char v53 = v20;
        uint64_t v22 = v47;
        v14((void *)((char *)v20 + v44 + v47 * v21), v48, v1);
        uint64_t v23 = v52;
      }
      else
      {
        unint64_t v50 = 0;
        unint64_t v51 = 0xE000000000000000;
        _StringGuts.grow(_:)(30);
        unint64_t v24 = v51;
        swift_bridgeObjectRelease(v51);
        unint64_t v50 = 0xD00000000000001BLL;
        unint64_t v51 = (unint64_t)v43;
        uint64_t v23 = v52;
        v25._uint64_t countAndFlagsBits = URL.path.getter(v24);
        char object = (char)v25._object;
        String.append(_:)(v25);
        swift_bridgeObjectRelease(object);
        v27._uint64_t countAndFlagsBits = 46;
        v27._char object = (void *)0xE100000000000000;
        String.append(_:)(v27);
        unint64_t v28 = v50;
        unint64_t v39 = v50;
        unint64_t v29 = v51;
        unsigned __int8 v54 = static os_log_type_t.info.getter();
        uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
        unint64_t v31 = (void *)swift_allocObject(v30, 64, 7);
        void v31[2] = 1;
        v31[3] = 2;
        v31[7] = &type metadata for String;
        v31[4] = v28;
        v31[5] = v29;
        swift_bridgeObjectRetain(v29);
        print(_:separator:terminator:)(v31, 32, 0xE100000000000000, 10, 0xE100000000000000);
        swift_bridgeObjectRelease((_BYTE)v31);
        type metadata accessor for OS_os_log();
        unint64_t v32 = (void *)static OS_os_log.default.getter(0);
        uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
        char v34 = (void *)swift_allocObject(v33, 72, 7);
        v34[2] = 1;
        v34[3] = 2;
        v34[7] = &type metadata for String;
        v34[8] = lazy protocol witness table accessor for type String and conformance String();
        v34[4] = v39;
        v34[5] = v29;
        swift_bridgeObjectRetain(v29);
        os_log(_:dso:log:type:_:)("%@\n", 3, 2, &dword_0, v32, v54, v34);
        swift_bridgeObjectRelease(v29);

        swift_bridgeObjectRelease((_BYTE)v34);
        uint64_t v1 = v46;
        uint64_t v22 = v47;
      }
      uint64_t v2 = v40;
      (*(void (**)(uint64_t *, uint64_t))(v40 + 8))(v23, v1);
      uint64_t v13 = v22 + v38;
      BOOL v35 = v42-- == 1;
      uint64_t v11 = v41;
      if (v35) {
        goto LABEL_15;
      }
    }
  }
  else
  {
    swift_bridgeObjectRetain(a1);
    char v53 = _swiftEmptyArrayStorage;
LABEL_15:
    __swift_storeEnumTagSinglePayload((uint64_t)v11, 1, 1, v1);
  }
  uint64_t v36 = v53;
  swift_bridgeObjectRelease(v49);
  return v36;
}

uint64_t static _ImageUtilities.getImageURLsAndLabels(from:)(uint64_t a1)
{
  uint64_t v128 = v1;
  uint64_t v132 = type metadata accessor for UTType(0);
  *(void *)&long long v124 = *(void *)(v132 - 8);
  int64_t v2 = *(void *)(v124 + 64);
  int64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v126 = v122;
  CFDictionaryRef v5 = alloca(v2);
  uint64_t v6 = alloca(v2);
  Swift::String v127 = v122;
  int64_t v131 = type metadata accessor for URL(0);
  uint64_t v129 = *(void **)(v131 - 8);
  int64_t v7 = v129[8];
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v130 = (char *)v122;
  int64_t v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  uint64_t v12 = v122;
  uint64_t v13 = type metadata accessor for MLImageClassifier.DataSource(0);
  int64_t v14 = *(void *)(*(void *)(v13 - 8) + 64);
  uint64_t v15 = alloca(v14);
  CFURLRef v16 = alloca(v14);
  outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v122, type metadata accessor for MLImageClassifier.DataSource);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v122, v13);
  if (EnumCaseMultiPayload)
  {
    if (EnumCaseMultiPayload != 1) {
      return v122[0];
    }
    uint64_t v18 = (uint64_t)v130;
    CFDictionaryRef v19 = v130;
    int64_t v20 = v131;
    unint64_t v21 = v129;
    ((void (*)(char *, void *, int64_t))v129[4])(v130, v122, v131);
    uint64_t v22 = (uint64_t)v126;
    static UTType.image.getter(v19);
    uint64_t v23 = v128;
    uint64_t v24 = static _FileUtilities.collectFilesLabeledByFileName(at:type:)(v18, v22);
    uint64_t v128 = v23;
    if (v23)
    {
      (*(void (**)(uint64_t, uint64_t))(v124 + 8))(v22, v132);
      Swift::String v25 = (void *)v18;
      int64_t v26 = v20;
      return ((uint64_t (*)(void *, int64_t))v21[1])(v25, v26);
    }
    uint64_t v133 = (void *)v24;
    uint64_t v31 = v22;
    uint64_t v12 = (void *)v18;
  }
  else
  {
    int64_t v27 = v131;
    unint64_t v21 = v129;
    ((void (*)(void *, void *, int64_t))v129[4])(v122, v122, v131);
    uint64_t v28 = (uint64_t)v127;
    static UTType.image.getter(v122);
    uint64_t v29 = v128;
    uint64_t v30 = static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)((uint64_t)v122, v28);
    uint64_t v128 = v29;
    uint64_t v31 = v28;
    if (v29)
    {
      (*(void (**)(uint64_t, uint64_t))(v124 + 8))(v28, v132);
      Swift::String v25 = v122;
      int64_t v26 = v27;
      return ((uint64_t (*)(void *, int64_t))v21[1])(v25, v26);
    }
    uint64_t v133 = v30;
  }
  (*(void (**)(uint64_t, uint64_t))(v124 + 8))(v31, v132);
  ((void (*)(void *, int64_t))v21[1])(v12, v131);
  uint64_t v33 = (uint64_t)v133;
  specialized _NativeDictionary.makeIterator()((uint64_t)v133);
  uint64_t v130 = (char *)v122[1];
  uint64_t v125 = v122[2];
  uint64_t v34 = v122[4];
  unint64_t v35 = v122[5];
  Swift::String v127 = (void *)((unint64_t)(v122[3] + 64) >> 6);
  swift_bridgeObjectRetain_n(v33, 2);
  uint64_t v36 = _swiftEmptyArrayStorage;
  while (1)
  {
    if (v35)
    {
      _BitScanForward64(&v37, v35);
      uint64_t v126 = (void *)((v35 - 1) & v35);
      uint64_t v132 = v34;
      unint64_t v38 = v37 | (v34 << 6);
      goto LABEL_30;
    }
    uint64_t v39 = v34 + 1;
    if (__OFADD__(1, v34)) {
      BUG();
    }
    if (v39 >= (uint64_t)v127) {
      goto LABEL_49;
    }
    unint64_t v40 = *(void *)(v125 + 8 * v39);
    if (!v40) {
      break;
    }
    uint64_t v41 = v34 + 1;
LABEL_29:
    _BitScanForward64(&v43, v40);
    uint64_t v126 = (void *)(v40 & (v40 - 1));
    uint64_t v132 = v41;
    unint64_t v38 = v43 + (v41 << 6);
LABEL_30:
    uint64_t v44 = *((void *)v130 + 7);
    uint64_t v45 = *(void *)(v44 + 8 * v38);
    uint64_t v46 = *(void *)(v45 + 16);
    int64_t v47 = v36[2];
    int64_t v48 = v46 + v47;
    if (__OFADD__(v46, v47)) {
      BUG();
    }
    *(void *)&long long v124 = *(void *)(v44 + 8 * v38);
    swift_bridgeObjectRetain(v45);
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v36);
    if (!isUniquelyReferenced_nonNull_native || v36[3] >> 1 < v48)
    {
      if (v47 > v48) {
        int64_t v48 = v47;
      }
      uint64_t v36 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(isUniquelyReferenced_nonNull_native, v48, 1, (uint64_t)v36);
    }
    uint64_t v34 = v132;
    char v50 = v124;
    if (*(void *)(v124 + 16))
    {
      uint64_t v51 = v36[2];
      if ((v36[3] >> 1) - v51 < v46) {
        BUG();
      }
      uint64_t v52 = (*((unsigned __int8 *)v129 + 80) + 32) & ~*((unsigned __int8 *)v129 + 80);
      uint64_t v53 = v129[9];
      unsigned __int8 v54 = (char *)v36 + v53 * v51 + v52;
      unint64_t v55 = v124 + v52;
      uint64_t v56 = v46 * v53;
      if (v55 < (unint64_t)&v54[v56] && (unint64_t)v54 < v55 + v56)
      {
        _fatalErrorMessage(_:_:file:line:flags:)("Fatal error", 11, 2, "UnsafeMutablePointer.initialize overlapping range", 49, 2, "Swift/UnsafePointer.swift", 25, 2, 1092, 1);
        BUG();
      }
      swift_arrayInitWithCopy(v54, v55, v46, v131);
      char v50 = v124;
      if (v46)
      {
        BOOL v57 = __OFADD__(v36[2], v46);
        uint64_t v58 = v36[2] + v46;
        if (v57) {
          BUG();
        }
        v36[2] = v58;
      }
    }
    else if (v46)
    {
      BUG();
    }
    swift_bridgeObjectRelease(v50);
    unint64_t v35 = (unint64_t)v126;
  }
  uint64_t v42 = v34 + 2;
  if (v34 + 2 >= (uint64_t)v127) {
    goto LABEL_49;
  }
  unint64_t v40 = *(void *)(v125 + 8 * v39 + 8);
  if (v40) {
    goto LABEL_28;
  }
  uint64_t v42 = v34 + 3;
  if (v34 + 3 >= (uint64_t)v127) {
    goto LABEL_49;
  }
  unint64_t v40 = *(void *)(v125 + 8 * v39 + 16);
  if (v40) {
    goto LABEL_28;
  }
  uint64_t v42 = v34 + 4;
  if (v34 + 4 >= (uint64_t)v127) {
    goto LABEL_49;
  }
  unint64_t v40 = *(void *)(v125 + 8 * v39 + 24);
  if (v40) {
    goto LABEL_28;
  }
  uint64_t v42 = v34 + 5;
  if (v34 + 5 >= (uint64_t)v127) {
    goto LABEL_49;
  }
  unint64_t v40 = *(void *)(v125 + 8 * v39 + 32);
  if (v40) {
    goto LABEL_28;
  }
  uint64_t v42 = v34 + 6;
  if (v34 + 6 >= (uint64_t)v127) {
    goto LABEL_49;
  }
  unint64_t v40 = *(void *)(v125 + 8 * v39 + 40);
  if (v40)
  {
LABEL_28:
    uint64_t v41 = v42;
    goto LABEL_29;
  }
  uint64_t v59 = v34 + 7;
  while (v59 < (uint64_t)v127)
  {
    unint64_t v40 = *(void *)(v125 + 8 * v59++);
    if (v40)
    {
      uint64_t v41 = v59 - 1;
      goto LABEL_29;
    }
  }
LABEL_49:
  uint64_t v60 = (uint64_t)v133;
  swift_bridgeObjectRelease((_BYTE)v133);
  swift_release();
  uint64_t v61 = static _ImageUtilities.validateImageURLs(from:)((uint64_t)v36);
  swift_bridgeObjectRelease((_BYTE)v36);
  uint64_t v62 = specialized Set.init<A>(_:)((uint64_t)v61);
  uint64_t v63 = 1 << *(unsigned char *)(v60 + 32);
  uint64_t v64 = ~(-1 << v63);
  if (v63 >= 64) {
    uint64_t v64 = -1;
  }
  unint64_t v65 = *(void *)(v60 + 64) & v64;
  uint64_t v126 = (void *)v62;
  uint64_t v130 = (char *)((unint64_t)(v63 + 63) >> 6);
  uint64_t v129 = _swiftEmptyDictionarySingleton;
  uint64_t v66 = 0;
  while (2)
  {
    if (v65)
    {
      _BitScanForward64(&v67, v65);
      uint64_t v132 = (v65 - 1) & v65;
      *(void *)&long long v124 = v66;
      unint64_t v68 = v67 | (v66 << 6);
LABEL_65:
      uint64_t v73 = v133[6];
      uint64_t v74 = *(void *)(v73 + 16 * v68);
      uint64_t v75 = *(void *)(v73 + 16 * v68 + 8);
      uint64_t v76 = *(void *)(v133[7] + 8 * v68);
      uint64_t v77 = v126;
      swift_bridgeObjectRetain((_BYTE)v126);
      swift_bridgeObjectRetain(v75);
      swift_bridgeObjectRetain(v76);
      uint64_t v78 = v128;
      uint64_t v79 = specialized _ArrayProtocol.filter(_:)(v76, v77);
      uint64_t v128 = v78;
      uint64_t v80 = v129;
      char v81 = swift_isUniquelyReferenced_nonNull_native(v129);
      *(void *)&long long v123 = v80;
      specialized _NativeDictionary.setValue(_:forKey:isUnique:)((uint64_t)v79, v74, v75, v81);
      uint64_t v129 = (void *)v123;
      swift_bridgeObjectRelease(v75);
      swift_bridgeObjectRelease(0);
      uint64_t v66 = v124;
      unint64_t v65 = v132;
      continue;
    }
    break;
  }
  BOOL v57 = __OFADD__(1, v66);
  uint64_t v69 = v66 + 1;
  if (v57) {
    BUG();
  }
  if (v69 >= (uint64_t)v130) {
    goto LABEL_71;
  }
  unint64_t v70 = v133[v69 + 8];
  if (v70)
  {
LABEL_64:
    _BitScanForward64(&v72, v70);
    uint64_t v132 = v70 & (v70 - 1);
    *(void *)&long long v124 = v69;
    unint64_t v68 = v72 + (v69 << 6);
    goto LABEL_65;
  }
  uint64_t v71 = v69 + 1;
  if (v69 + 1 >= (uint64_t)v130) {
    goto LABEL_71;
  }
  unint64_t v70 = v133[v69 + 9];
  if (v70) {
    goto LABEL_63;
  }
  uint64_t v71 = v69 + 2;
  if (v69 + 2 >= (uint64_t)v130) {
    goto LABEL_71;
  }
  unint64_t v70 = v133[v69 + 10];
  if (v70) {
    goto LABEL_63;
  }
  uint64_t v71 = v69 + 3;
  if (v69 + 3 >= (uint64_t)v130) {
    goto LABEL_71;
  }
  unint64_t v70 = v133[v69 + 11];
  if (v70)
  {
LABEL_63:
    uint64_t v69 = v71;
    goto LABEL_64;
  }
  v69 += 3;
  while (1)
  {
    BOOL v57 = __OFADD__(1, v69++);
    if (v57) {
      BUG();
    }
    if (v69 >= (uint64_t)v130) {
      break;
    }
    unint64_t v70 = v133[v69 + 8];
    if (v70) {
      goto LABEL_64;
    }
  }
LABEL_71:
  swift_bridgeObjectRelease((_BYTE)v126);
  swift_release();
  uint64_t v82 = (uint64_t)v129;
  swift_bridgeObjectRetain((_BYTE)v129);
  uint64_t v83 = v128;
  Swift::String v84 = specialized _NativeDictionary.filter(_:)(v82);
  uint64_t v128 = v83;
  swift_bridgeObjectRelease(v82);
  uint64_t v85 = 1 << *((unsigned char *)v84 + 32);
  uint64_t v86 = ~(-1 << v85);
  if (v85 >= 64) {
    uint64_t v86 = -1;
  }
  unint64_t v87 = v84[8] & v86;
  int64_t v131 = (unint64_t)(v85 + 63) >> 6;
  uint64_t v133 = v84;
  swift_retain();
  uint64_t v88 = 0;
  uint64_t v130 = "are not properly constructed." + 0x8000000000000000;
  while (2)
  {
    if (v87)
    {
      _BitScanForward64(&v89, v87);
      uint64_t v132 = (v87 - 1) & v87;
      *(void *)&long long v124 = v88;
      unint64_t v90 = v89 | (v88 << 6);
      uint64_t v91 = (uint64_t)v133;
LABEL_89:
      uint64_t v96 = *(void *)(v91 + 48);
      uint64_t v97 = 16 * v90;
      uint64_t v98 = *(void *)(v96 + v97);
      uint64_t v99 = *(void **)(v96 + v97 + 8);
      *(void *)&long long v123 = 0;
      *((void *)&v123 + 1) = 0xE000000000000000;
      swift_bridgeObjectRetain((_BYTE)v99);
      _StringGuts.grow(_:)(29);
      swift_bridgeObjectRelease(BYTE8(v123));
      *(void *)&long long v123 = 0xD000000000000019;
      *((void *)&v123 + 1) = v130;
      v100._uint64_t countAndFlagsBits = v98;
      v100._char object = v99;
      String.append(_:)(v100);
      swift_bridgeObjectRelease((_BYTE)v99);
      v100._uint64_t countAndFlagsBits = 11815;
      v100._char object = (void *)0xE200000000000000;
      String.append(_:)(v100);
      unint64_t v102 = *((void *)&v123 + 1);
      unint64_t v101 = v123;
      LOBYTE(v126) = static os_log_type_t.error.getter(11815, 0xE200000000000000);
      uint64_t v103 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
      uint64_t v104 = swift_allocObject(v103, 64, 7);
      *(void *)(v104 + 16) = 1;
      *(void *)(v104 + 24) = 2;
      *(void *)(v104 + 56) = &type metadata for String;
      *(_OWORD *)(v104 + 32) = __PAIR128__(v102, v101);
      swift_bridgeObjectRetain(v102);
      print(_:separator:terminator:)(v104, 32, 0xE100000000000000, 10, 0xE100000000000000);
      swift_bridgeObjectRelease(v104);
      type metadata accessor for OS_os_log();
      uint64_t v105 = (void *)static OS_os_log.default.getter(0);
      uint64_t v106 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
      uint64_t v107 = swift_allocObject(v106, 72, 7);
      *(void *)(v107 + 16) = 1;
      *(void *)(v107 + 24) = 2;
      *(void *)(v107 + 56) = &type metadata for String;
      *(void *)(v107 + 64) = lazy protocol witness table accessor for type String and conformance String();
      *(_OWORD *)(v107 + 32) = __PAIR128__(v102, v101);
      swift_bridgeObjectRetain(v102);
      os_log(_:dso:log:type:_:)("%@\n", 3, 2, &dword_0, v105, v126, v107);
      swift_bridgeObjectRelease(v102);

      swift_bridgeObjectRelease(v107);
      uint64_t v88 = v124;
      unint64_t v87 = v132;
      continue;
    }
    break;
  }
  BOOL v57 = __OFADD__(1, v88);
  int64_t v92 = v88 + 1;
  uint64_t v91 = (uint64_t)v133;
  if (v57) {
    BUG();
  }
  if (v92 < v131)
  {
    unint64_t i = v133[v92 + 8];
    if (i)
    {
      int64_t v94 = v92;
    }
    else
    {
      int64_t v94 = v92 + 1;
      if (v92 + 1 >= v131) {
        goto LABEL_96;
      }
      unint64_t i = v133[v92 + 9];
      if (!i)
      {
        int64_t v94 = v92 + 2;
        if (v92 + 2 >= v131) {
          goto LABEL_96;
        }
        unint64_t i = v133[v92 + 10];
        if (!i)
        {
          int64_t v94 = v92 + 3;
          if (v92 + 3 >= v131) {
            goto LABEL_96;
          }
          unint64_t i = v133[v92 + 11];
          if (!i)
          {
            int64_t v94 = v92 + 4;
            if (v92 + 4 >= v131) {
              goto LABEL_96;
            }
            unint64_t i = v133[v92 + 12];
            if (!i)
            {
              int64_t v94 = v92 + 5;
              if (v92 + 5 >= v131) {
                goto LABEL_96;
              }
              for (unint64_t i = v133[v92 + 13]; !i; unint64_t i = v133[v94 + 8])
              {
                BOOL v57 = __OFADD__(1, v94++);
                if (v57) {
                  BUG();
                }
                if (v94 >= v131) {
                  goto LABEL_96;
                }
              }
            }
          }
        }
      }
    }
    _BitScanForward64(&v95, i);
    uint64_t v132 = i & (i - 1);
    unint64_t v90 = v95 + (v94 << 6);
    *(void *)&long long v124 = v94;
    goto LABEL_89;
  }
LABEL_96:
  swift_release();
  if (*(void *)(v91 + 16))
  {
    swift_bridgeObjectRelease((_BYTE)v129);
    *(void *)&long long v123 = 0;
    uint64_t v108 = (void *)0xE000000000000000;
    *((void *)&v123 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(69);
    v109._char object = "eature data sources." + 0x8000000000000000;
    v109._uint64_t countAndFlagsBits = 0xD000000000000017;
    String.append(_:)(v109);
    uint64_t v110 = specialized Collection.first.getter(v91);
    if (v111) {
      uint64_t v108 = v111;
    }
    else {
      uint64_t v110 = 0;
    }
    v112._uint64_t countAndFlagsBits = v110;
    v112._char object = v108;
    String.append(_:)(v112);
    swift_bridgeObjectRelease((_BYTE)v108);
    v112._char object = "Missing data for label " + 0x8000000000000000;
    v112._uint64_t countAndFlagsBits = 0xD000000000000029;
    String.append(_:)(v112);
    uint64_t v113 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [URL]);
    uint64_t v114 = Dictionary.Keys.description.getter(v91, &type metadata for String, v113, &protocol witness table for String);
    char v116 = (char)v115;
    v112._uint64_t countAndFlagsBits = v114;
    v112._char object = v115;
    String.append(_:)(v112);
    swift_bridgeObjectRelease(v116);
    v112._uint64_t countAndFlagsBits = 46;
    v112._char object = (void *)0xE100000000000000;
    String.append(_:)(v112);
    long long v124 = v123;
    v112._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v117 = swift_allocError(&type metadata for MLCreateError, v112._object, 0, 0);
    *(_OWORD *)uint64_t v118 = v124;
    *(_OWORD *)(v118 + 16) = 0;
    *(_OWORD *)(v118 + 32) = 0;
    *(unsigned char *)(v118 + 48) = 0;
    uint64_t v128 = v117;
    swift_willThrow(&type metadata for MLCreateError, v112._object, v118, v119, v120, v121);
    return swift_release();
  }
  else
  {
    swift_release();
    return (uint64_t)v129;
  }
}

uint64_t static _ImageUtilities.generateImageTable(_:)(uint64_t a1)
{
  uint64_t v46 = v1;
  swift_bridgeObjectRetain(a1);
  int64_t v48 = specialized _copyCollectionToContiguousArray<A>(_:)(a1);
  specialized MutableCollection<>.sort(by:)(&v48);
  if (v2)
  {
    swift_release();
    BUG();
  }
  swift_bridgeObjectRelease(a1);
  uint64_t v44 = v48[2];
  if (!v44)
  {
    swift_release();
    uint64_t v4 = _swiftEmptyArrayStorage;
    unsigned __int8 v54 = _swiftEmptyArrayStorage;
    goto LABEL_47;
  }
  uint64_t v52 = a1;
  uint64_t v51 = 0;
  int64_t v47 = v48;
  uint64_t v45 = v48 + 4;
  uint64_t v3 = 0;
  uint64_t v4 = _swiftEmptyArrayStorage;
  unsigned __int8 v54 = _swiftEmptyArrayStorage;
  do
  {
    char v50 = v4;
    uint64_t v43 = v3;
    uint64_t v5 = v45[2 * v3];
    uint64_t v6 = v45[2 * v3 + 1];
    uint64_t v7 = *(void *)(v52 + 16);
    swift_bridgeObjectRetain(v6);
    int64_t v8 = _swiftEmptyArrayStorage;
    if (v7)
    {
      swift_bridgeObjectRetain(v6);
      unint64_t v9 = specialized __RawDictionaryStorage.find<A>(_:)(v5, v6);
      int64_t v8 = _swiftEmptyArrayStorage;
      if (v10)
      {
        int64_t v8 = *(void **)(*(void *)(v52 + 56) + 8 * v9);
        swift_bridgeObjectRetain((_BYTE)v8);
      }
      swift_bridgeObjectRelease(v6);
    }
    uint64_t v11 = v51;
    ML15_VideoUtilitiesV08generateC5TableyAA06MLDataF0VSDySSSay10Foundation3URLVGGKFZSSAIcfu0_33_43697e1f61f7e10b647d882195ad8775AISSTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay10Foundation3URLVG_SSs5NeverOTg5148_s8CreateML15_VideoUtilitiesV08generateC5TableyAA06MLDataF0VSDySSSay10Foundation3URLVGGKFZSSAIcfu0_33_43697e1f61f7e10b647d882195ad8775AISSTf3nnnpk_nTf1cn_n((uint64_t)v8);
    uint64_t v51 = v11;
    swift_bridgeObjectRelease((_BYTE)v8);
    uint64_t v49 = ML15_VideoUtilitiesV08generateC5TableyAA06MLDataF0VSDySSSay10Foundation3URLVGGKFZSSAIcfu0_33_43697e1f61f7e10b647d882195ad8775AISSTf3nnnpk_nTf1cn_n;
    uint64_t v13 = ML15_VideoUtilitiesV08generateC5TableyAA06MLDataF0VSDySSSay10Foundation3URLVGGKFZSSAIcfu0_33_43697e1f61f7e10b647d882195ad8775AISSTf3nnnpk_nTf1cn_n[2];
    if (!v13)
    {
      swift_bridgeObjectRelease(v6);
      int64_t v14 = _swiftEmptyArrayStorage;
LABEL_15:
      CFURLRef v17 = v54;
      goto LABEL_16;
    }
    int64_t v14 = (void *)static Array._allocateBufferUninitialized(minimumCapacity:)(v13);
    void v14[2] = v13;
    v14[4] = v5;
    v14[5] = v6;
    if (v13 == 1) {
      goto LABEL_15;
    }
    v14[6] = v5;
    uint64_t v53 = v14;
    v14[7] = v6;
    if (v13 != 2)
    {
      uint64_t v15 = v13 - 2;
      CFURLRef v16 = v53 + 9;
      do
      {
        *(v16 - 1) = v5;
        *CFURLRef v16 = v6;
        swift_bridgeObjectRetain(v6);
        v16 += 2;
        --v15;
      }
      while (v15);
    }
    swift_bridgeObjectRetain(v6);
    CFURLRef v17 = v54;
    int64_t v14 = v53;
LABEL_16:
    uint64_t v18 = v14[2];
    int64_t v19 = v17[2];
    int64_t v20 = v18 + v19;
    if (__OFADD__(v18, v19)) {
      BUG();
    }
    uint64_t v53 = v14;
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v17);
    if (!isUniquelyReferenced_nonNull_native || v17[3] >> 1 < v20)
    {
      if (v19 > v20) {
        int64_t v20 = v19;
      }
      CFURLRef v17 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(isUniquelyReferenced_nonNull_native, v20, 1, (uint64_t)v17);
    }
    uint64_t v4 = v50;
    char v22 = (char)v53;
    if (v53[2])
    {
      uint64_t v23 = v17[2];
      if ((v17[3] >> 1) - v23 < v18) {
        BUG();
      }
      unint64_t v24 = (unint64_t)&v17[2 * v23 + 4];
      if ((unint64_t)(v53 + 4) < v24 + 16 * v18 && v24 < (unint64_t)&v53[2 * v18 + 4])
      {
LABEL_56:
        _fatalErrorMessage(_:_:file:line:flags:)("Fatal error", 11, 2, "UnsafeMutablePointer.initialize overlapping range", 49, 2, "Swift/UnsafePointer.swift", 25, 2, 1092, 1);
        BUG();
      }
      swift_arrayInitWithCopy(v24, v53 + 4, v18, &type metadata for String);
      char v22 = (char)v53;
      if (v18)
      {
        BOOL v25 = __OFADD__(v17[2], v18);
        uint64_t v26 = v17[2] + v18;
        if (v25) {
          BUG();
        }
        long long v17[2] = v26;
      }
    }
    else if (v18)
    {
      BUG();
    }
    unsigned __int8 v54 = v17;
    swift_bridgeObjectRelease(v22);
    uint64_t v27 = v49[2];
    int64_t v28 = v4[2];
    int64_t v29 = v27 + v28;
    if (__OFADD__(v27, v28)) {
      BUG();
    }
    char v30 = swift_isUniquelyReferenced_nonNull_native(v4);
    if (!v30 || v4[3] >> 1 < v29)
    {
      if (v28 > v29) {
        int64_t v29 = v28;
      }
      uint64_t v4 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v30, v29, 1, (uint64_t)v4);
    }
    char v31 = (char)v49;
    if (v49[2])
    {
      uint64_t v32 = v4[2];
      if ((v4[3] >> 1) - v32 < v27) {
        BUG();
      }
      unint64_t v33 = (unint64_t)&v4[2 * v32 + 4];
      if ((unint64_t)(v49 + 4) < v33 + 16 * v27 && v33 < (unint64_t)&v49[2 * v27 + 4]) {
        goto LABEL_56;
      }
      swift_arrayInitWithCopy(v33, v49 + 4, v27, &type metadata for String);
      if (v27)
      {
        BOOL v25 = __OFADD__(v4[2], v27);
        uint64_t v34 = v4[2] + v27;
        if (v25) {
          BUG();
        }
        v4[2] = v34;
      }
    }
    else if (v27)
    {
      BUG();
    }
    uint64_t v3 = v43 + 1;
    swift_bridgeObjectRelease(v31);
  }
  while (v43 + 1 != v44);
  swift_release();
LABEL_47:
  uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MLDataValueConvertible)>);
  uint64_t inited = (void *)swift_initStackObject(v35, v42);
  inited[2] = 2;
  inited[3] = 4;
  inited[4] = 0x6C6562616CLL;
  inited[5] = 0xE500000000000000;
  uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  inited[9] = v37;
  uint64_t v38 = lazy protocol witness table accessor for type [String] and conformance <A> [A]();
  inited[10] = v38;
  inited[6] = v54;
  inited[11] = 0x7461506567616D69;
  inited[12] = 0xE900000000000068;
  inited[16] = v37;
  inited[17] = v38;
  inited[13] = v4;
  uint64_t v39 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLDataValueConvertible);
  uint64_t v40 = Dictionary.init(dictionaryLiteral:)(inited, &type metadata for String, v39, &protocol witness table for String);
  return MLDataTable.init(dictionary:)(v40);
}

uint64_t static _ImageUtilities.getImageURLsAndAnnotations(from:)(long long *a1, __m128 a2)
{
  *(void *)&long long v164 = v3;
  unsigned long long v173 = a1;
  Swift::String v151 = v2;
  uint64_t v172 = (void *)type metadata accessor for DataFrame(0);
  uint64_t v160 = *(v172 - 1);
  int64_t v4 = *(void *)(v160 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v153 = &v132;
  uint64_t v7 = alloca(v4);
  int64_t v8 = alloca(v4);
  uint64_t v161 = &v132;
  unint64_t v9 = (void *)type metadata accessor for UTType(0);
  char v10 = (long long *)*(v9 - 1);
  int64_t v11 = *((void *)v10 + 8);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  v168._char object = &v132;
  int64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  uint64_t v163 = &v132;
  unint64_t v169 = type metadata accessor for URL(0);
  unint64_t v171 = *(void **)(v169 - 8);
  int64_t v16 = v171[8];
  CFURLRef v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v162 = &v132;
  int64_t v19 = alloca(v16);
  int64_t v20 = alloca(v16);
  Swift::String v152 = &v132;
  unint64_t v21 = alloca(v16);
  char v22 = alloca(v16);
  double v166 = &v132;
  uint64_t v23 = alloca(v16);
  unint64_t v24 = alloca(v16);
  uint64_t v165 = &v132;
  BOOL v25 = alloca(v16);
  uint64_t v26 = alloca(v16);
  v168._uint64_t countAndFlagsBits = (uint64_t)&v132;
  uint64_t v27 = alloca(v16);
  int64_t v28 = alloca(v16);
  uint64_t v167 = &v132;
  uint64_t v29 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
  int64_t v30 = *(void *)(*(void *)(v29 - 8) + 64);
  char v31 = alloca(v30);
  uint64_t v32 = alloca(v30);
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v173, (uint64_t)&v132, type metadata accessor for MLHandPoseClassifier.DataSource);
  switch(swift_getEnumCaseMultiPayload(&v132, v29))
  {
    case 0u:
      unint64_t v33 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
      uint64_t v34 = (char *)&v132 + v33[12];
      uint64_t v35 = v33[16];
      v168._uint64_t countAndFlagsBits = *(void *)((char *)&v132 + v35);
      unsigned long long v173 = *(long long **)((char *)&v132 + v35 + 8);
      uint64_t v36 = v33[20];
      uint64_t v167 = *(long long **)((char *)&v132 + v36);
      uint64_t v172 = *(void **)((char *)&v132 + v36 + 8);
      uint64_t v37 = (void (*)(long long *, long long *, unint64_t))v171[4];
      uint64_t v38 = v169;
      v37(v165, &v132, v169);
      uint64_t v39 = (uint64_t)v166;
      v37(v166, (long long *)v34, v38);
      uint64_t v40 = v152;
      uint64_t v41 = v171;
      ((void (*)(long long *, uint64_t, uint64_t))v171[2])(v152, v39, v38);
      LOBYTE(v132) = 1;
      *(_DWORD *)((char *)&v132 + 1) = *(_DWORD *)v154;
      DWORD1(v132) = *(_DWORD *)&v154[3];
      *((void *)&v132 + 1) = 44;
      uint64_t v133 = (long long *)0xE100000000000000;
      uint64_t v134 = 0;
      char v170 = 1;
      unint64_t v135 = 0xE000000000000000;
      uint64_t v136 = 92;
      unint64_t v137 = 0xE100000000000000;
      char v138 = 1;
      *(_DWORD *)Swift::String v139 = *(_DWORD *)v155;
      *(_DWORD *)&v139[3] = *(_DWORD *)&v155[3];
      uint64_t v140 = 34;
      unint64_t v141 = 0xE100000000000000;
      char v142 = 1;
      *(_DWORD *)&v143[3] = *(_DWORD *)&v156[3];
      *(_DWORD *)Swift::String v143 = *(_DWORD *)v156;
      Swift::String v144 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
      uint64_t v145 = 10;
      unint64_t v146 = 0xE100000000000000;
      long long v147 = 0;
      char v148 = 1;
      *(_DWORD *)uint64_t v149 = *(_DWORD *)v157;
      *(_DWORD *)&v149[3] = *(_DWORD *)&v157[3];
      uint64_t v150 = 0;
      uint64_t v42 = v164;
      MLDataTable.init(contentsOf:options:)(v40, &v132);
      if (v42)
      {
        uint64_t v43 = (void (*)(long long *, uint64_t))v41[1];
        v43(v166, v38);
        swift_bridgeObjectRelease((_BYTE)v172);
        swift_bridgeObjectRelease((_BYTE)v173);
        return ((uint64_t (*)(long long *, uint64_t))v43)(v165, v38);
      }
      *(void *)&long long v164 = 0;
      uint64_t v174 = v158;
      LOBYTE(v175) = v159;
      v82._uint64_t countAndFlagsBits = v168._countAndFlagsBits;
      uint64_t v83 = v173;
      v82._char object = v173;
      MLDataTable.subscript.getter(v82);
      char object = (void *)v132;
      char v85 = BYTE8(v132);
      if (BYTE8(v132)
        || (outlined copy of Result<_DataTable, Error>(v132, 0),
            v168._char object = object,
            _UntypedColumn.type.getter(),
            char object = v168._object,
            outlined consume of Result<_DataTable, Error>((uint64_t)v168._object, 0),
            (_BYTE)v158 != 2))
      {
        outlined consume of Result<_DataTable, Error>((uint64_t)object, v85);
        swift_bridgeObjectRelease((_BYTE)v172);
        *(void *)&long long v132 = 0;
        *((void *)&v132 + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(26);
        swift_bridgeObjectRelease(BYTE8(v132));
        *(void *)&long long v132 = 0x206E6D756C6F43;
        *((void *)&v132 + 1) = 0xE700000000000000;
        v121._uint64_t countAndFlagsBits = v168._countAndFlagsBits;
        v121._char object = v83;
        String.append(_:)(v121);
        swift_bridgeObjectRelease((_BYTE)v83);
        v121._uint64_t countAndFlagsBits = 0xD000000000000011;
        String.append(_:)(v121);
        long long v164 = v132;
        v121._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v121._object, 0, 0);
        *(_OWORD *)uint64_t v122 = v164;
        *(_OWORD *)(v122 + 16) = 0;
        *(_OWORD *)(v122 + 32) = 0;
        *(unsigned char *)(v122 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v121._object, v122, v123, v124, v125);
        uint64_t v115 = (void (*)(long long *, uint64_t))v171[1];
        uint64_t v116 = (uint64_t)v166;
        uint64_t v114 = v169;
        goto LABEL_32;
      }
      outlined copy of Result<_DataTable, Error>((uint64_t)object, 0);
      _UntypedColumn.valueAtIndex(index:)(0, 0.0);
      unint64_t v86 = *((void *)&v132 + 1);
      uint64_t v87 = v132;
      if ((_BYTE)v133 != 2)
      {
        outlined consume of MLDataValue((void *)v132, *((void **)&v132 + 1), (char)v133);
        uint64_t v87 = 0;
        unint64_t v86 = 0xE000000000000000;
      }
      outlined consume of Result<_DataTable, Error>((uint64_t)v168._object, 0);
      *(void *)&long long v132 = v87;
      *((void *)&v132 + 1) = v86;
      uint64_t v88 = String.init<A>(_:)(&v132, &type metadata for String, &protocol witness table for String, &protocol witness table for String);
      char v90 = v89;
      URL.init(fileURLWithPath:)(v88, v89);
      swift_bridgeObjectRelease(v90);
      uint64_t v91 = objc_opt_self(NSFileManager);
      id v92 = [v91 defaultManager];
      id v93 = v92;
      URL.path.getter(v92);
      char v95 = v94;
      NSString v96 = String._bridgeToObjectiveC()();
      swift_bridgeObjectRelease(v95);
      unsigned __int8 v97 = [v93 fileExistsAtPath:v96];

      if (!v97)
      {
        uint64_t v98 = v168._object;
        outlined copy of Result<_DataTable, Error>((uint64_t)v168._object, 0);
        uint64_t v99 = specialized Array<A>.init(_:)((uint64_t)v98, 0, 0.0);
        Swift::String v100 = alloca(24);
        unint64_t v101 = alloca(32);
        uint64_t v133 = v165;
        uint64_t v102 = v164;
        uint64_t v103 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_SSs5NeverOTg5((void (*)(void *))partial apply for closure #1 in static _VideoUtilities.getVideoURLsAndAnnotations(from:), (uint64_t)&v132, (uint64_t)v99);
        *(void *)&long long v164 = v102;
        swift_bridgeObjectRelease((_BYTE)v99);
        uint64_t v163 = &v132;
        *(void *)&long long v132 = v103;
        uint64_t v104 = alloca(24);
        uint64_t v105 = alloca(24);
        uint64_t v133 = &v132;
        uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
        char v108 = v107;
        swift_bridgeObjectRelease(v132);
        uint64_t v109 = (uint64_t)v173;
        swift_bridgeObjectRetain((_BYTE)v173);
        MLDataTable.willMutate()();
        *(void *)&long long v132 = ML14_UntypedColumnC_s5Error_pTgm5;
        BYTE8(v132) = v108 & 1;
        MLDataTable.setColumnImpl(newColumn:named:)((uint64_t)&v132, v168._countAndFlagsBits, v109);
        swift_bridgeObjectRelease(v109);
        outlined consume of Result<_DataTable, Error>(ML14_UntypedColumnC_s5Error_pTgm5, v108);
        if (!(_BYTE)v175)
        {
          uint64_t v110 = v174;
          outlined copy of Result<_DataTable, Error>(v174, 0);
          _DataTable.columnNamesDidChange()();
          outlined consume of Result<_DataTable, Error>(v110, 0);
        }
      }
      char v111 = (char)v172;
      char v112 = (char)v173;
      uint64_t v113 = v164;
      static _ImageUtilities.renameImageTableColumns(table:imageColumn:labelColumn:)((uint64_t)&v174, v168._countAndFlagsBits, v173, (uint64_t)v167, v172, 0.0);
      uint64_t v114 = v169;
      if (v113)
      {
        swift_bridgeObjectRelease(v112);
        swift_bridgeObjectRelease(v111);
        outlined consume of Result<_DataTable, Error>((uint64_t)v168._object, 0);
        uint64_t v115 = (void (*)(long long *, uint64_t))v171[1];
        v115(v162, v114);
        uint64_t v116 = (uint64_t)v166;
LABEL_32:
        v115((long long *)v116, v114);
        v115(v165, v114);
        return outlined consume of Result<_DataTable, Error>(v174, v175);
      }
      swift_bridgeObjectRelease(v112);
      swift_bridgeObjectRelease(v111);
      outlined consume of Result<_DataTable, Error>((uint64_t)v168._object, 0);
      int64_t v131 = (void (*)(long long *, uint64_t))v171[1];
      v131(v162, v114);
      v131(v166, v114);
      v131(v165, v114);
LABEL_15:
      uint64_t result = v174;
      char v72 = v175;
      uint64_t v73 = v151;
      *Swift::String v151 = v174;
      *((unsigned char *)v73 + 8) = v72;
      return result;
    case 1u:
      uint64_t v172 = v9;
      unsigned long long v173 = v10;
      uint64_t countAndFlagsBits = v168._countAndFlagsBits;
      uint64_t v46 = v169;
      int64_t v47 = v171;
      ((void (*)(uint64_t, long long *, unint64_t))v171[4])(v168._countAndFlagsBits, &v132, v169);
      int64_t v48 = v168._object;
      static UTType.image.getter();
      uint64_t v49 = v164;
      char v50 = static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)(countAndFlagsBits, (uint64_t)v48);
      if (v49)
      {
        (*((void (**)(void *, void *))v173 + 1))(v168._object, v172);
        uint64_t v51 = v168._countAndFlagsBits;
        return ((uint64_t (*)(uint64_t, uint64_t))v47[1])(v51, v46);
      }
      uint64_t v117 = (uint64_t)v50;
      (*((void (**)(void *, void *))v173 + 1))(v168._object, v172);
      static _ImageUtilities.generateImageTable(_:)(v117);
      swift_bridgeObjectRelease(v117);
      uint64_t v126 = v132;
      char v127 = BYTE8(v132);
      uint64_t v174 = v132;
      LOBYTE(v175) = BYTE8(v132) & 1;
      BYTE8(v132) &= 1u;
      outlined copy of Result<_DataTable, Error>(v132, v127);
      static _ImageUtilities.validateImageInput(trainingData:imageColumn:labelColumn:)((uint64_t)&v132, 0x7461506567616D69, 0xE900000000000068, 0x6C6562616CLL, 0xE500000000000000, *(double *)a2.i64);
      outlined consume of Result<_DataTable, Error>(v126, v127);
      uint64_t v130 = v168._countAndFlagsBits;
      goto LABEL_34;
    case 2u:
      uint64_t v172 = v9;
      unsigned long long v173 = v10;
      uint64_t v52 = (uint64_t)v167;
      uint64_t v46 = v169;
      int64_t v47 = v171;
      ((void (*)(long long *, long long *, unint64_t))v171[4])(v167, &v132, v169);
      uint64_t v53 = (uint64_t)v163;
      static UTType.image.getter();
      uint64_t v54 = v164;
      uint64_t v55 = static _FileUtilities.collectFilesLabeledByFileName(at:type:)(v52, v53);
      if (v54)
      {
        (*((void (**)(long long *, void *))v173 + 1))(v163, v172);
        uint64_t v51 = (uint64_t)v167;
        return ((uint64_t (*)(uint64_t, uint64_t))v47[1])(v51, v46);
      }
      uint64_t v118 = v55;
      (*((void (**)(long long *, void *))v173 + 1))(v163, v172);
      static _ImageUtilities.generateImageTable(_:)(v118);
      swift_bridgeObjectRelease(v118);
      uint64_t v128 = v132;
      char v129 = BYTE8(v132);
      uint64_t v174 = v132;
      LOBYTE(v175) = BYTE8(v132) & 1;
      BYTE8(v132) &= 1u;
      outlined copy of Result<_DataTable, Error>(v132, v129);
      static _ImageUtilities.validateImageInput(trainingData:imageColumn:labelColumn:)((uint64_t)&v132, 0x7461506567616D69, 0xE900000000000068, 0x6C6562616CLL, 0xE500000000000000, *(double *)a2.i64);
      outlined consume of Result<_DataTable, Error>(v128, v129);
      uint64_t v130 = (uint64_t)v167;
LABEL_34:
      ((void (*)(uint64_t, unint64_t))v171[1])(v130, v169);
      goto LABEL_15;
    case 3u:
      char v56 = (char)v134;
      char v57 = v136;
      char v58 = v138;
      outlined consume of Result<_DataTable, Error>(v132, SBYTE8(v132));
      swift_bridgeObjectRelease(v58);
      swift_bridgeObjectRelease(v57);
      swift_bridgeObjectRelease(v56);
      goto LABEL_13;
    case 4u:
      char v59 = BYTE8(v132);
      unsigned long long v173 = v133;
      uint64_t v60 = v134;
      unint64_t v169 = v135;
      uint64_t v61 = (long long *)v136;
      uint64_t v174 = v132;
      LOBYTE(v175) = BYTE8(v132) & 1;
      unint64_t v171 = (void *)v132;
      outlined copy of Result<_DataTable, Error>(v132, SBYTE8(v132));
      uint64_t v62 = (uint64_t)v173;
      unsigned long long v173 = v61;
      uint64_t v63 = v164;
      static _ImageUtilities.renameImageTableColumns(table:imageColumn:labelColumn:)((uint64_t)&v174, v62, v60, v169, v61, *(double *)a2.i64);
      if (!v63)
      {
        swift_bridgeObjectRelease((_BYTE)v60);
        swift_bridgeObjectRelease((_BYTE)v173);
        outlined consume of Result<_DataTable, Error>((uint64_t)v171, v59);
        goto LABEL_15;
      }
      swift_bridgeObjectRelease((_BYTE)v60);
      swift_bridgeObjectRelease((_BYTE)v173);
      outlined consume of Result<_DataTable, Error>((uint64_t)v171, v59);
      return outlined consume of Result<_DataTable, Error>(v174, v175);
    case 5u:
      uint64_t v64 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      swift_bridgeObjectRelease(*(void *)((char *)&v132 + v64[12] + 8));
      swift_bridgeObjectRelease(*(void *)((char *)&v132 + v64[16] + 8));
      swift_bridgeObjectRelease(*(void *)((char *)&v132 + v64[20] + 8));
      (*(void (**)(long long *, void *))(v160 + 8))(&v132, v172);
LABEL_13:
      uint64_t empty = tc_v1_sframe_create_empty(0);
      if (!empty) {
        BUG();
      }
      uint64_t v66 = empty;
      uint64_t v67 = type metadata accessor for CMLTable();
      uint64_t v68 = swift_allocObject(v67, 24, 7);
      *(void *)(v68 + 16) = v66;
      uint64_t v69 = type metadata accessor for _DataTable();
      swift_allocObject(v69, 40, 7);
      uint64_t v174 = _DataTable.init(impl:)(v68);
      LOBYTE(v175) = 0;
      os_log_type_t v70 = static os_log_type_t.info.getter();
      v71._uint64_t countAndFlagsBits = 0xD0000000000000A7;
      v71._char object = "Skipped invalid image file " + 0x8000000000000000;
      log(_:type:)(v71, v70);
      goto LABEL_15;
    case 6u:
      uint64_t v74 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
      uint64_t v75 = *(int *)(v74 + 48);
      unint64_t v169 = *(void *)((char *)&v132 + v75);
      unint64_t v171 = *(void **)((char *)&v132 + v75 + 8);
      uint64_t v76 = *(int *)(v74 + 64);
      double v166 = *(long long **)((char *)&v132 + v76);
      unsigned long long v173 = *(long long **)((char *)&v132 + v76 + 8);
      uint64_t v77 = v161;
      uint64_t v78 = v172;
      uint64_t v79 = v160;
      (*(void (**)(long long *, long long *, void *))(v160 + 32))(v161, &v132, v172);
      uint64_t v80 = (uint64_t)v153;
      *(double *)a2.i64 = (*(double (**)(long long *, long long *, void *))(v79 + 16))(v153, v77, v78);
      uint64_t v81 = v164;
      MLDataTable.init(_:convertArraysToShapedArrays:)(v80, 0, a2);
      if (v81)
      {
        (*(void (**)(long long *, void *))(v79 + 8))(v161, v172);
        swift_bridgeObjectRelease((_BYTE)v173);
        return swift_bridgeObjectRelease((_BYTE)v171);
      }
      uint64_t v174 = v132;
      LOBYTE(v175) = BYTE8(v132);
      char v119 = (char)v171;
      char v120 = (char)v173;
      static _ImageUtilities.renameImageTableColumns(table:imageColumn:labelColumn:)((uint64_t)&v174, v169, v171, (uint64_t)v166, v173, *(double *)a2.i64);
      (*(void (**)(long long *, void *))(v79 + 8))(v161, v172);
      swift_bridgeObjectRelease(v119);
      swift_bridgeObjectRelease(v120);
      goto LABEL_15;
  }
}

uint64_t static _ImageUtilities.validateImageInput(trainingData:imageColumn:labelColumn:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, double a6)
{
  uint64_t v20 = v6;
  uint64_t v25 = a5;
  uint64_t v26 = a4;
  uint64_t v24 = a3;
  uint64_t v7 = *(void *)a1;
  char v8 = *(unsigned char *)(a1 + 8);
  uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t inited = (void *)swift_initStackObject(v28, v17);
  inited[2] = 1;
  inited[3] = 2;
  uint64_t v21 = a2;
  inited[4] = a2;
  char v10 = v24;
  inited[5] = v24;
  uint64_t v27 = v7;
  uint64_t v22 = v7;
  char v31 = v8;
  char v23 = v8;
  swift_bridgeObjectRetain(v10);
  uint64_t v11 = v20;
  static _ValidationUtilities.validateTableFormat(table:context:columns:)((uint64_t)&v22, 0x7461506567616D69, (void *)0xE900000000000068, (uint64_t)inited);
  if (v11)
  {
    swift_setDeallocating(inited);
  }
  else
  {
    uint64_t v22 = v27;
    char v23 = v31;
    uint64_t v13 = (void *)swift_initStackObject(v28, v18);
    v13[2] = 1;
    void v13[3] = 2;
    v13[4] = v26;
    char v14 = v25;
    v13[5] = v25;
    swift_bridgeObjectRetain(v14);
    static _ValidationUtilities.validateTableFormat(table:context:columns:)((uint64_t)&v22, 0x6C6562616CLL, (void *)0xE500000000000000, (uint64_t)v13);
    swift_setDeallocating(v13);
    specialized _ContiguousArrayStorage.__deallocating_deinit();
    swift_setDeallocating(inited);
    specialized _ContiguousArrayStorage.__deallocating_deinit();
    uint64_t v22 = v27;
    char v23 = v31;
    uint64_t v15 = (void *)swift_initStackObject(v28, v19);
    v15[2] = 1;
    v15[3] = 2;
    v15[4] = v21;
    char v16 = v24;
    v15[5] = v24;
    char v29 = 2;
    char v30 = 2;
    swift_bridgeObjectRetain(v16);
    static _ValidationUtilities.validateTableTypes(table:featureColumns:featureType:labelColumn:labelType:)(&v22, (unint64_t)v15, &v29, v26, v25, &v30, a6);
    swift_setDeallocating(v15);
  }
  return specialized _ContiguousArrayStorage.__deallocating_deinit();
}

uint64_t static _ImageUtilities.renameImageTableColumns(table:imageColumn:labelColumn:)(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, void *a5, double a6)
{
  v24._char object = a5;
  named._uint64_t countAndFlagsBits = a4;
  uint64_t v8 = *(void *)a1;
  uint64_t v25 = (uint64_t *)a1;
  char v9 = *(unsigned char *)(a1 + 8);
  uint64_t v21 = v8;
  char v22 = v9;
  outlined copy of Result<_DataTable, Error>(v8, v9);
  v24._uint64_t countAndFlagsBits = a2;
  named._char object = a3;
  uint64_t v10 = (uint64_t)a3;
  uint64_t countAndFlagsBits = named._countAndFlagsBits;
  static _ImageUtilities.validateImageInput(trainingData:imageColumn:labelColumn:)((uint64_t)&v21, a2, v10, named._countAndFlagsBits, (uint64_t)v24._object, a6);
  uint64_t result = outlined consume of Result<_DataTable, Error>(v8, v9);
  if (!v6)
  {
    uint64_t v13 = countAndFlagsBits;
    char v14 = v25;
    MLDataTable.willMutate()();
    v15._uint64_t countAndFlagsBits = 0x7461506567616D69;
    v15._char object = (void *)0xE900000000000068;
    v16._uint64_t countAndFlagsBits = v24._countAndFlagsBits;
    v16._char object = named._object;
    MLDataTable.renameImpl(named:to:)(v16, v15);
    if (!*((unsigned char *)v14 + 8))
    {
      uint64_t v17 = *v14;
      outlined copy of Result<_DataTable, Error>(*v14, 0);
      _DataTable.columnNamesDidChange()();
      outlined consume of Result<_DataTable, Error>(v17, 0);
    }
    MLDataTable.willMutate()();
    v18._uint64_t countAndFlagsBits = 0x6C6562616CLL;
    v18._char object = (void *)0xE500000000000000;
    v19._uint64_t countAndFlagsBits = v13;
    v19._char object = v24._object;
    uint64_t result = MLDataTable.renameImpl(named:to:)(v19, v18);
    if (!*((unsigned char *)v14 + 8))
    {
      uint64_t v20 = *v25;
      outlined copy of Result<_DataTable, Error>(*v25, 0);
      _DataTable.columnNamesDidChange()();
      return outlined consume of Result<_DataTable, Error>(v20, 0);
    }
  }
  return result;
}

uint64_t specialized StringProtocol.appending<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v6[0] = a1;
  v6[1] = a2;
  uint64_t v7 = a3;
  uint64_t v8 = a4;
  swift_bridgeObjectRetain(a4);
  uint64_t v7 = String.init<A>(_:)(&v7, &type metadata for String, &protocol witness table for String, &protocol witness table for String);
  uint64_t v8 = v4;
  String.append<A>(contentsOf:)(v6, &type metadata for String, &protocol witness table for String);
  return v7;
}

char static _ImageUtilities.validateAnnotationContent(from:directoryURL:)(uint64_t a1, double a2)
{
  char result = 0;
  if (*(unsigned char *)(a1 + 16) != 3) {
    return result;
  }
  uint64_t v3 = *(void **)a1;
  uint64_t v4 = *(void **)(a1 + 8);
  swift_retain();
  uint64_t v5 = CMLSequence.value(at:)(0);
  MLDataValue.init(_:)(v5, a2);
  outlined consume of MLDataValue(v3, v4, 3);
  if (v34 == 4)
  {
    if (v32[2])
    {
      swift_bridgeObjectRetain((_BYTE)v32);
      *(void *)&long long v6 = 0x6C6562616CLL;
      *((void *)&v6 + 1) = 0xE500000000000000;
      specialized __RawDictionaryStorage.find<A>(_:)(v6, 2);
      char v8 = v7;
      outlined consume of MLDataValue(v32, v33, 4);
      if (v8)
      {
        if (v32[2])
        {
          swift_bridgeObjectRetain((_BYTE)v32);
          *(void *)&long long v9 = 0x616E6964726F6F63;
          *((void *)&v9 + 1) = 0xEB00000000736574;
          specialized __RawDictionaryStorage.find<A>(_:)(v9, 2);
          char v11 = v10;
          outlined consume of MLDataValue(v32, v33, 4);
          if (v11)
          {
            if (v32[2])
            {
              swift_bridgeObjectRetain((_BYTE)v32);
              *(void *)&long long v12 = 0x6C6562616CLL;
              *((void *)&v12 + 1) = 0xE500000000000000;
              unint64_t v13 = specialized __RawDictionaryStorage.find<A>(_:)(v12, 2);
              if (v14)
              {
                uint64_t v15 = v32[7];
                uint64_t v16 = 24 * v13;
                uint64_t v17 = *(void **)(v15 + v16);
                Swift::String v18 = *(void **)(v15 + v16 + 8);
                uint64_t v19 = *(unsigned __int8 *)(v15 + v16 + 16);
                outlined copy of MLDataValue(v17, v18, *(unsigned char *)(v15 + v16 + 16));
                outlined consume of MLDataValue(v32, v33, 4);
                switch(v19)
                {
                  case 0:
                  case 1:
                  case 6:
                    goto LABEL_19;
                  case 2:
                    outlined consume of MLDataValue(v17, v18, 2);
                    if (!v32[2]) {
                      goto LABEL_19;
                    }
                    *(void *)&long long v20 = 0x616E6964726F6F63;
                    *((void *)&v20 + 1) = 0xEB00000000736574;
                    unint64_t v21 = specialized __RawDictionaryStorage.find<A>(_:)(v20, 2);
                    if ((v22 & 1) == 0) {
                      goto LABEL_19;
                    }
                    uint64_t v23 = v32[7];
                    uint64_t v24 = 24 * v21;
                    uint64_t v25 = *(void **)(v23 + v24);
                    uint64_t v26 = *(void **)(v23 + v24 + 8);
                    uint64_t v27 = *(unsigned __int8 *)(v23 + v24 + 16);
                    outlined copy of MLDataValue(v25, v26, *(unsigned char *)(v23 + v24 + 16));
                    outlined consume of MLDataValue(v32, v33, 4);
                    switch(v27)
                    {
                      case 0:
                      case 1:
                      case 6:
                        return 0;
                      case 2:
                        char v31 = 2;
                        goto LABEL_27;
                      case 3:
                        char v31 = 3;
                        goto LABEL_27;
                      case 4:
                        outlined consume of MLDataValue(v25, v26, 4);
                        return 1;
                      case 5:
                        char v31 = 5;
LABEL_27:
                        char v28 = v31;
                        char v29 = v25;
                        char v30 = v26;
                        break;
                    }
                    break;
                  case 3:
                    outlined consume of MLDataValue(v17, v18, 3);
                    goto LABEL_19;
                  case 4:
                    outlined consume of MLDataValue(v17, v18, 4);
                    char v29 = v32;
                    char v30 = v33;
                    char v28 = 4;
                    break;
                  case 5:
                    outlined consume of MLDataValue(v17, v18, 5);
                    goto LABEL_19;
                }
              }
              else
              {
                outlined consume of MLDataValue(v32, v33, 4);
                char v29 = v32;
                char v30 = v33;
                char v28 = 4;
              }
              goto LABEL_21;
            }
          }
        }
      }
    }
LABEL_19:
    char v28 = 4;
  }
  else
  {
    char v28 = v34;
  }
  char v29 = v32;
  char v30 = v33;
LABEL_21:
  outlined consume of MLDataValue(v29, v30, v28);
  return 0;
}

uint64_t specialized static _ImageUtilities.findColumnWithNonDefaultName(from:directoryURL:columnType:defaultName:validateContentFunc:)(uint64_t a1, uint64_t a2, unsigned __int8 *a3, uint64_t a4, void *a5, uint64_t (*a6)(unint64_t *), uint64_t (*a7)(Swift::String *, uint64_t, void, uint64_t *, void, uint64_t))
{
  uint64_t v67 = a6;
  v64._uint64_t countAndFlagsBits = v7;
  uint64_t v65 = a4;
  uint64_t v57 = a2;
  uint64_t v9 = *(void *)a1;
  unsigned __int8 v10 = *(unsigned char *)(a1 + 8);
  unsigned __int8 v68 = *a3;
  v66._uint64_t countAndFlagsBits = v9;
  LOBYTE(v66._object) = v10;
  if (MLDataTable.size.getter() <= 0)
  {
    uint64_t v15 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v15, 0, 0);
    *(void *)uint64_t v16 = 0xD00000000000003BLL;
    *(void *)(v16 + 8) = "No readable image files in " + 0x8000000000000000;
    *(_OWORD *)(v16 + 16) = 0;
    *(_OWORD *)(v16 + 32) = 0;
    *(unsigned char *)(v16 + 48) = 1;
    return swift_willThrow(&type metadata for MLCreateError, v15, v16, v17, v18, v19);
  }
  uint64_t v60 = a5;
  unsigned __int8 v69 = v10;
  uint64_t v63 = v9;
  if (v10)
  {
    outlined copy of Result<_DataTable, Error>(v9, 1);
    uint64_t v11 = tc_v1_flex_list_create(0);
    if (!v11) {
      BUG();
    }
    uint64_t v12 = v11;
    uint64_t v13 = type metadata accessor for CMLSequence();
    uint64_t v14 = swift_allocObject(v13, 25, 7);
    *(void *)(v14 + 16) = v12;
    *(unsigned char *)(v14 + 24) = 1;
    outlined consume of Result<_DataTable, Error>(v9, 1);
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(v9, 0);
    _DataTable.columnNames.getter(v9);
    outlined consume of Result<_DataTable, Error>(v9, 0);
    uint64_t v14 = v62;
  }
  v66._uint64_t countAndFlagsBits = v65;
  char v21 = (char)v60;
  v66._char object = v60;
  char v22 = alloca(24);
  uint64_t v23 = alloca(32);
  char object = &v66;
  uint64_t countAndFlagsBits = (uint64_t (*)(unint64_t *))v64._countAndFlagsBits;
  char v25 = specialized Sequence.contains(where:)(v67, (uint64_t)v55, v14);
  uint64_t v67 = countAndFlagsBits;
  swift_release();
  if (v25)
  {
    swift_bridgeObjectRetain(v21);
    return v65;
  }
  uint64_t v62 = 0;
  uint64_t v26 = v63;
  v66._uint64_t countAndFlagsBits = v63;
  unsigned __int8 v27 = v69;
  LOBYTE(v66._object) = v69;
  double v28 = (double)(int)MLDataTable.size.getter() * 0.2;
  if ((~*(void *)&v28 & 0x7FF0000000000000) == 0) {
    BUG();
  }
  if (v28 <= -9.223372036854778e18) {
    BUG();
  }
  if (v28 >= 9.223372036854776e18) {
    BUG();
  }
  uint64_t v29 = (int)v28;
  v66._uint64_t countAndFlagsBits = v26;
  LOBYTE(v66._object) = v27;
  Swift::Int v30 = MLDataTable.size.getter();
  if (v30 >= 10)
  {
    if ((int)v28 < 0xBuLL) {
      uint64_t v29 = 10;
    }
    uint64_t v61 = v29;
  }
  else
  {
    if (v30 > v29) {
      uint64_t v29 = v30;
    }
    uint64_t v61 = v29;
    BOOL v31 = v29 <= 0;
    uint64_t v32 = v65;
    if (v31)
    {
LABEL_34:
      v66._uint64_t countAndFlagsBits = 0;
      v66._char object = (void *)0xE000000000000000;
      _StringGuts.grow(_:)(166);
      v51._uint64_t countAndFlagsBits = 0xD000000000000098;
      v51._char object = "Annotations file is empty." + 0x8000000000000000;
      String.append(_:)(v51);
      v51._uint64_t countAndFlagsBits = v32;
      v51._char object = v60;
      String.append(_:)(v51);
      v51._uint64_t countAndFlagsBits = 0x2E316567616D693ALL;
      v51._char object = (void *)0xEC0000002E67706ALL;
      String.append(_:)(v51);
      Swift::String v64 = v66;
      uint64_t v15 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v15, 0, 0);
      *(Swift::String *)uint64_t v16 = v64;
      *(_OWORD *)(v16 + 16) = 0;
      *(_OWORD *)(v16 + 32) = 0;
      *(unsigned char *)(v16 + 48) = 1;
      return swift_willThrow(&type metadata for MLCreateError, v15, v16, v17, v18, v19);
    }
  }
  uint64_t v33 = 0;
  while (1)
  {
    uint64_t v58 = v33;
    if (v27)
    {
      outlined copy of Result<_DataTable, Error>(v26, 1);
      uint64_t v34 = tc_v1_flex_list_create(0);
      if (!v34) {
        BUG();
      }
      uint64_t v35 = v34;
      outlined consume of Result<_DataTable, Error>(v26, 1);
      uint64_t v36 = type metadata accessor for CMLSequence();
      uint64_t v37 = swift_allocObject(v36, 25, 7);
      *(void *)(v37 + 16) = v35;
      *(unsigned char *)(v37 + 24) = 1;
      uint64_t v59 = v37;
    }
    else
    {
      outlined copy of Result<_DataTable, Error>(v26, 0);
      _DataTable.columnNames.getter(v26);
      outlined consume of Result<_DataTable, Error>(v26, 0);
      uint64_t v37 = v59;
    }
    swift_retain_n(v37);
    uint64_t v38 = CMLSequence.size.getter();
    uint64_t v39 = specialized RandomAccessCollection<>.distance(from:to:)(0, v38);
    swift_release();
    uint64_t v40 = v67;
    if (v39) {
      break;
    }
LABEL_33:
    uint64_t v67 = v40;
    swift_release_n(v37);
    uint64_t v33 = v58 + 1;
    uint64_t v62 = v58 + 1;
    uint64_t v32 = v65;
    uint64_t v26 = v63;
    unsigned __int8 v27 = v69;
    if (v58 + 1 >= v61) {
      goto LABEL_34;
    }
  }
  uint64_t v41 = 0;
  v64._uint64_t countAndFlagsBits = v37;
  while (1)
  {
    uint64_t v67 = v41;
    CMLSequence.value(at:)((uint64_t)v41);
    if (v40)
    {
      swift_unexpectedError(v40, "CreateML/SequenceType.swift", 27, 1, 76);
      BUG();
    }
    Swift::String v42 = CMLFeatureValue.stringValue()();
    char object = (Swift::String *)v42._object;
    uint64_t v40 = v43;
    if (v43)
    {
      swift_errorRelease(v43);
      swift_release();
      v66._uint64_t countAndFlagsBits = 0;
      v66._char object = (void *)0xE000000000000000;
      _StringGuts.grow(_:)(37);
      swift_bridgeObjectRelease(v66._object);
      v66._uint64_t countAndFlagsBits = 0xD000000000000022;
      v66._char object = "able.ColumnNames.swift" + 0x8000000000000000;
      v55[1] = v67;
      v52._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
      char v53 = (char)v52._object;
      String.append(_:)(v52);
      swift_bridgeObjectRelease(v53);
      v54._uint64_t countAndFlagsBits = 46;
      v54._char object = (void *)0xE100000000000000;
      String.append(_:)(v54);
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v66._countAndFlagsBits, v66._object, "CreateML/MLDataTable.ColumnNames.swift", 38, 2, 17, 0);
      BUG();
    }
    uint64_t v44 = v42._countAndFlagsBits;
    swift_release();
    swift_retain();
    uint64_t v45 = CMLSequence.size.getter();
    uint64_t v46 = specialized RandomAccessCollection<>.distance(from:to:)(0, v45);
    swift_release();
    int64_t v47 = v67;
    if ((uint64_t)v67 >= v46) {
      BUG();
    }
    v66._uint64_t countAndFlagsBits = v44;
    char v48 = (char)object;
    v66._char object = object;
    if (a7(&v66, v63, v69, &v62, v68, v57)) {
      break;
    }
    swift_bridgeObjectRelease(v48);
    uint64_t v37 = v64._countAndFlagsBits;
    swift_retain();
    uint64_t v49 = CMLSequence.size.getter();
    uint64_t v41 = (uint64_t (*)(unint64_t *))((char *)v47 + 1);
    uint64_t v50 = specialized RandomAccessCollection<>.distance(from:to:)(0, v49);
    swift_release();
    if (v41 == (uint64_t (*)(unint64_t *))v50) {
      goto LABEL_33;
    }
  }
  swift_release_n(v64._countAndFlagsBits);
  return v44;
}

uint64_t specialized closure #1 in static _ImageUtilities.findColumnWithNonDefaultName(from:directoryURL:columnType:defaultName:validateContentFunc:)(uint64_t *a1, void *a2, int a3, uint64_t *a4, int a5, uint64_t a6, double a7)
{
  uint64_t v57 = v7;
  uint64_t v50 = a6;
  int v52 = a5;
  uint64_t v55 = type metadata accessor for URL(0);
  uint64_t v56 = *(void *)(v55 - 8);
  int64_t v10 = *(void *)(v56 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  Swift::String v54 = v41;
  uint64_t v51 = *a1;
  uint64_t v58 = a1[1];
  uint64_t v45 = a4;
  uint64_t v13 = *a4;
  uint64_t v44 = a2;
  int64_t v47 = a2;
  int v53 = a3;
  LOBYTE(v48) = a3 & 1;
  MLDataTable.Rows.subscript.getter(v13);
  uint64_t v14 = v42;
  uint64_t v15 = v43;
  if (!*(void *)(v42 + 16))
  {
    swift_release();
    swift_bridgeObjectRelease(v14);
    swift_release();
LABEL_8:
    char v22 = v54;
    uint64_t v23 = v55;
    uint64_t v24 = v56;
    (*(void (**)(void *, uint64_t, uint64_t))(v56 + 16))(v54, v50, v55);
    goto LABEL_9;
  }
  uint64_t v16 = v58;
  swift_bridgeObjectRetain(v58);
  unint64_t v17 = specialized __RawDictionaryStorage.find<A>(_:)(v51, v16);
  if ((v18 & 1) == 0)
  {
    swift_release();
    swift_bridgeObjectRelease(v14);
    swift_release();
    swift_bridgeObjectRelease(v58);
    goto LABEL_8;
  }
  uint64_t v19 = *(void *)(*(void *)(v14 + 56) + 8 * v17);
  swift_bridgeObjectRelease(v58);
  swift_retain_n(v15);
  uint64_t v20 = v57;
  uint64_t v46 = CMLSequence.value(at:)(v19);
  uint64_t v57 = v20;
  if (v20) {
    goto LABEL_23;
  }
  swift_release();
  MLDataValue.init(_:)(v46, a7);
  swift_bridgeObjectRelease(v14);
  swift_release();
  swift_release_n(v15);
  char v21 = v49;
  switch(v49)
  {
    case 0:
    case 1:
    case 6:
      break;
    case 2:
      outlined consume of MLDataValue(v47, v48, 2);
      break;
    case 3:
      outlined consume of MLDataValue(v47, v48, 3);
      break;
    case 4:
      outlined consume of MLDataValue(v47, v48, 4);
      break;
    case 5:
      outlined consume of MLDataValue(v47, v48, 5);
      break;
  }
  uint64_t v23 = v55;
  uint64_t v24 = v56;
  uint64_t v27 = v58;
  (*(void (**)(void *, uint64_t, uint64_t))(v56 + 16))(v54, v50, v55);
  if (v21 == (_BYTE)v52)
  {
    uint64_t v28 = *v45;
    int64_t v47 = v44;
    LOBYTE(v48) = v53 & 1;
    MLDataTable.Rows.subscript.getter(v28);
    uint64_t v58 = v41[1];
    uint64_t v29 = v42;
    uint64_t v30 = v43;
    if (*(void *)(v42 + 16))
    {
      swift_bridgeObjectRetain(v27);
      unint64_t v31 = specialized __RawDictionaryStorage.find<A>(_:)(v51, v27);
      if (v32)
      {
        uint64_t v33 = *(void *)(*(void *)(v29 + 56) + 8 * v31);
        swift_bridgeObjectRelease(v27);
        swift_retain_n(v30);
        uint64_t v34 = v57;
        uint64_t v35 = CMLSequence.value(at:)(v33);
        uint64_t v57 = v34;
        if (!v34)
        {
          uint64_t v36 = v35;
          swift_release();
          MLDataValue.init(_:)(v36, a7);
          swift_bridgeObjectRelease(v29);
          swift_release();
          swift_release_n(v30);
          uint64_t v37 = v47;
          uint64_t v38 = v48;
          char v39 = v49;
          LOBYTE(v40) = static _ImageUtilities.validateAnnotationContent(from:directoryURL:)((uint64_t)&v47, a7);
          unsigned int v25 = v40;
          outlined consume of MLDataValue(v37, v38, v39);
          (*(void (**)(void *, uint64_t))(v56 + 8))(v54, v55);
          return v25;
        }
LABEL_23:
        swift_release();
        swift_unexpectedError(v57, "CreateML/MLDataTable.Row.swift", 30, 1, 85);
        BUG();
      }
      swift_release();
      swift_bridgeObjectRelease(v29);
      swift_release();
      swift_bridgeObjectRelease(v27);
    }
    else
    {
      swift_release();
      swift_bridgeObjectRelease(v29);
      swift_release();
    }
    BUG();
  }
  char v22 = v54;
LABEL_9:
  (*(void (**)(void *, uint64_t))(v24 + 8))(v22, v23);
  return 0;
}

uint64_t specialized closure #1 in static _ImageUtilities.findColumnWithNonDefaultName(from:directoryURL:columnType:defaultName:validateContentFunc:)(uint64_t *a1, void *a2, int a3, uint64_t *a4, int a5, void *a6, double a7)
{
  uint64_t v68 = v7;
  unsigned __int8 v69 = a6;
  int v64 = a5;
  uint64_t v70 = type metadata accessor for URL(0);
  uint64_t v72 = *(void *)(v70 - 8);
  int64_t v10 = *(void *)(v72 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v62 = &v54;
  uint64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  Swift::String v71 = &v54;
  uint64_t v66 = *a1;
  uint64_t v67 = (void *)a1[1];
  uint64_t v61 = a4;
  uint64_t v15 = *a4;
  uint64_t v60 = a2;
  uint64_t v57 = a2;
  int v65 = a3;
  LOBYTE(v58) = a3 & 1;
  MLDataTable.Rows.subscript.getter(v15);
  uint64_t v16 = v55;
  uint64_t v17 = v56;
  if (!*(void *)(v55 + 16))
  {
    swift_release();
    swift_bridgeObjectRelease(v16);
    swift_release();
LABEL_8:
    uint64_t v26 = v71;
    uint64_t v27 = v70;
    uint64_t v28 = v72;
    (*(void (**)(void **, void *, uint64_t))(v72 + 16))(v71, v69, v70);
    goto LABEL_9;
  }
  uint64_t v63 = v54;
  uint64_t v18 = (uint64_t)v67;
  swift_bridgeObjectRetain((_BYTE)v67);
  unint64_t v19 = specialized __RawDictionaryStorage.find<A>(_:)(v66, v18);
  if ((v20 & 1) == 0)
  {
    swift_release();
    swift_bridgeObjectRelease(v16);
    swift_release();
    swift_bridgeObjectRelease((_BYTE)v67);
    goto LABEL_8;
  }
  uint64_t v21 = *(void *)(*(void *)(v16 + 56) + 8 * v19);
  swift_bridgeObjectRelease((_BYTE)v67);
  swift_retain_n(v17);
  uint64_t v22 = v68;
  uint64_t v23 = CMLSequence.value(at:)(v21);
  uint64_t v68 = v22;
  if (v22) {
    goto LABEL_25;
  }
  uint64_t v24 = v23;
  swift_release();
  MLDataValue.init(_:)(v24, a7);
  swift_bridgeObjectRelease(v16);
  swift_release();
  swift_release_n(v17);
  char v25 = v59;
  switch(v59)
  {
    case 0:
    case 1:
    case 6:
      break;
    case 2:
      outlined consume of MLDataValue(v57, v58, 2);
      break;
    case 3:
      outlined consume of MLDataValue(v57, v58, 3);
      break;
    case 4:
      outlined consume of MLDataValue(v57, v58, 4);
      break;
    case 5:
      outlined consume of MLDataValue(v57, v58, 5);
      break;
  }
  uint64_t v27 = v70;
  uint64_t v26 = v71;
  uint64_t v28 = v72;
  (*(void (**)(void **, void *, uint64_t))(v72 + 16))(v71, v69, v70);
  if (v25 != (_BYTE)v64)
  {
LABEL_9:
    (*(void (**)(void **, uint64_t))(v28 + 8))(v26, v27);
    return 0;
  }
  uint64_t v31 = *v61;
  uint64_t v57 = v60;
  LOBYTE(v58) = v65 & 1;
  MLDataTable.Rows.subscript.getter(v31);
  unsigned __int8 v69 = v54;
  uint64_t v32 = v55;
  uint64_t v33 = v56;
  if (!*(void *)(v55 + 16))
  {
    swift_release();
    swift_bridgeObjectRelease(v32);
    swift_release();
    goto LABEL_24;
  }
  uint64_t v34 = (uint64_t)v67;
  swift_bridgeObjectRetain((_BYTE)v67);
  unint64_t v35 = specialized __RawDictionaryStorage.find<A>(_:)(v66, v34);
  if ((v36 & 1) == 0)
  {
    swift_release();
    swift_bridgeObjectRelease(v32);
    swift_release();
    swift_bridgeObjectRelease(v34);
LABEL_24:
    BUG();
  }
  uint64_t v37 = *(void *)(*(void *)(v32 + 56) + 8 * v35);
  swift_bridgeObjectRelease(v34);
  swift_retain_n(v33);
  uint64_t v38 = v68;
  uint64_t v39 = CMLSequence.value(at:)(v37);
  uint64_t v68 = v38;
  if (v38)
  {
LABEL_25:
    swift_release();
    swift_unexpectedError(v68, "CreateML/MLDataTable.Row.swift", 30, 1, 85);
    BUG();
  }
  uint64_t v40 = v39;
  swift_release();
  MLDataValue.init(_:)(v40, a7);
  swift_bridgeObjectRelease(v32);
  swift_release();
  swift_release_n(v33);
  uint64_t v41 = v57;
  uint64_t v42 = v58;
  if (v59 == 2)
  {
    uint64_t v43 = v58;
    uint64_t v67 = v58;
    swift_bridgeObjectRetain((_BYTE)v58);
    uint64_t v44 = v62;
    URL.appendingPathComponent(_:)(v41, v42);
    outlined consume of MLDataValue(v41, v43, 2);
    uint64_t v45 = URL.path.getter(v41);
    unsigned __int8 v69 = v41;
    uint64_t v46 = v45;
    uint64_t v48 = v47;
    uint64_t v72 = *(void *)(v72 + 8);
    uint64_t v49 = v70;
    ((void (*)(void **, uint64_t))v72)(v44, v70);
    uint64_t v66 = specialized StringProtocol.appending<A>(_:)(v46, v48, 0, 0xE000000000000000);
    uint64_t v51 = v50;
    swift_bridgeObjectRelease(v48);
    URL.init(fileURLWithPath:)(v66, v51);
    swift_bridgeObjectRelease(v51);
    unsigned int v29 = static _ImageUtilities.validateOneImageURL(from:)(v44);
    int v52 = v44;
    int v53 = (void (*)(void **, uint64_t))v72;
    ((void (*)(void **, uint64_t))v72)(v52, v49);
    outlined consume of MLDataValue(v69, v67, 2);
  }
  else
  {
    outlined consume of MLDataValue(v57, v58, v59);
    int v53 = *(void (**)(void **, uint64_t))(v72 + 8);
    unsigned int v29 = 0;
    uint64_t v49 = v70;
  }
  v53(v71, v49);
  return v29;
}

ValueMetadata *static _ImageUtilities.getImageURLs(at:)(ValueMetadata *a1)
{
  *(void *)&long long v76 = v1;
  uint64_t v73 = type metadata accessor for URL(0);
  uint64_t v74 = *(void *)(v73 - 8);
  int64_t v2 = *(void *)(v74 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v72 = &v64;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  long long v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  unsigned __int8 v69 = &v64;
  uint64_t v8 = type metadata accessor for UTType(0);
  uint64_t v9 = *(void *)(v8 - 8);
  int64_t v10 = *(void *)(v9 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  Swift::String v71 = &v64;
  uint64_t v13 = (uint64_t)a1;
  uint64_t v14 = v76;
  uint64_t v15 = (ValueMetadata *)static _FileUtilities.getReadableSubdirectoriesOfDirectory(at:)();
  if (!v14)
  {
    uint64_t v17 = v15;
    uint64_t v18 = (uint64_t)v71;
    *(void *)&long long v76 = v8;
    uint64_t v75 = 0;
    Kind = (uint64_t *)v15[1].Kind;
    if (Kind)
    {
      uint64_t v20 = (*(unsigned __int8 *)(v74 + 80) + 32) & ~*(unsigned __int8 *)(v74 + 80);
      uint64_t v70 = v15;
      uint64_t v67 = v20;
      uint64_t v21 = (char *)v15 + v20;
      uint64_t v66 = *(void (**)(uint64_t *, char *, uint64_t))(v74 + 16);
      uint64_t v68 = *(void *)(v74 + 72);
      *(void *)&long long v76 = _swiftEmptyArrayStorage;
      uint64_t v22 = v73;
      uint64_t v23 = v72;
      while (1)
      {
        Swift::String v71 = Kind;
        uint64_t v24 = (uint64_t)v69;
        int v65 = v21;
        v66(v69, v21, v22);
        __swift_storeEnumTagSinglePayload(v24, 0, 1, v22);
        if (__swift_getEnumTagSinglePayload(v24, 1, v22) == 1) {
          goto LABEL_23;
        }
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v74 + 32))(v23, v24, v22);
        char v25 = objc_opt_self(NSFileManager);
        id v26 = [v25 defaultManager];
        uint64_t v27 = (NSURL *)v26;
        URL._bridgeToObjectiveC()(v27);
        unsigned int v29 = v28;
        *(void *)&long long v77 = 0;
        uint64_t v30 = v27;
        id v31 = [(NSURL *)v27 contentsOfDirectoryAtURL:v28 includingPropertiesForKeys:0 options:4 error:&v77];
        id v32 = v31;
        uint64_t v33 = v30;
        uint64_t v34 = v22;

        unint64_t v35 = (void *)v77;
        if (!v32) {
          break;
        }
        uint64_t v36 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v32, v22);
        v35;

        uint64_t v37 = *(void *)(v36 + 16);
        int64_t v38 = *(void *)(v76 + 16);
        int64_t v39 = v37 + v38;
        if (__OFADD__(v37, v38)) {
          BUG();
        }
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v76);
        uint64_t v41 = (void *)v76;
        if (!isUniquelyReferenced_nonNull_native || *(void *)(v76 + 24) >> 1 < v39)
        {
          if (v38 > v39) {
            int64_t v39 = v38;
          }
          uint64_t v41 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(isUniquelyReferenced_nonNull_native, v39, 1, v76);
        }
        uint64_t v22 = v73;
        BOOL v42 = *(void *)(v36 + 16) == 0;
        *(void *)&long long v76 = v41;
        if (v42)
        {
          if (v37) {
            BUG();
          }
        }
        else
        {
          uint64_t v43 = v41[2];
          if ((v41[3] >> 1) - v43 < v37) {
            BUG();
          }
          uint64_t v44 = (char *)v41 + v68 * v43 + v67;
          uint64_t v45 = v67 + v36;
          if (v67 + v36 < (unint64_t)&v44[v68 * v37] && (unint64_t)v44 < v45 + v68 * v37)
          {
            _fatalErrorMessage(_:_:file:line:flags:)("Fatal error", 11, 2, "UnsafeMutablePointer.initialize overlapping range", 49, 2, "Swift/UnsafePointer.swift", 25, 2, 1092, 1);
            BUG();
          }
          swift_arrayInitWithCopy(v44, v45, v37, v73);
          if (v37)
          {
            BOOL v46 = __OFADD__(*(void *)(v76 + 16), v37);
            uint64_t v47 = *(void *)(v76 + 16) + v37;
            if (v46) {
              BUG();
            }
            *(void *)(v76 + 16) = v47;
          }
        }
        swift_bridgeObjectRelease(v36);
        uint64_t v23 = v72;
        (*(void (**)(uint64_t *, uint64_t))(v74 + 8))(v72, v22);
        uint64_t v21 = &v65[v68];
        Kind = (uint64_t *)((char *)v71 - 1);
        if (v71 == (uint64_t *)((char *)&dword_0 + 1))
        {
          __swift_storeEnumTagSinglePayload((uint64_t)v69, 1, 1, v22);
LABEL_23:
          swift_bridgeObjectRelease((_BYTE)v70);
          return (ValueMetadata *)v76;
        }
      }
      id v50 = (id)v77;
      _convertNSErrorToError(_:)(v35);

      swift_willThrow(v50, "contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:", v51, v52, v53, v54);
      (*(void (**)(uint64_t *, uint64_t))(v74 + 8))(v72, v34);
      swift_bridgeObjectRelease(v76);
      a1 = v70;
      swift_bridgeObjectRelease((_BYTE)v70);
    }
    else
    {
      swift_bridgeObjectRelease((_BYTE)v15);
      static UTType.image.getter(v17);
      uint64_t v48 = v75;
      uint64_t v49 = static _FileUtilities.readableFiles(at:type:)(v13, v18);
      uint64_t v75 = v48;
      a1 = (ValueMetadata *)v18;
      if (v48)
      {
        (*(void (**)(uint64_t, void))(v9 + 8))(v18, v76);
      }
      else
      {
        uint64_t v55 = (ValueMetadata *)v49;
        (*(void (**)(ValueMetadata *, void))(v9 + 8))(a1, v76);
        a1 = v55;
        if (!v55[1].Kind)
        {
          swift_bridgeObjectRelease((_BYTE)v55);
          *(void *)&long long v77 = 0;
          *((void *)&v77 + 1) = 0xE000000000000000;
          _StringGuts.grow(_:)(29);
          uint64_t v56 = *((void *)&v77 + 1);
          swift_bridgeObjectRelease(BYTE8(v77));
          *(void *)&long long v77 = 0xD00000000000001BLL;
          *((void *)&v77 + 1) = " specified data source" + 0x8000000000000000;
          v57._uint64_t countAndFlagsBits = URL.path.getter(v56);
          char object = (char)v57._object;
          String.append(_:)(v57);
          swift_bridgeObjectRelease(object);
          long long v76 = v77;
          a1 = &type metadata for MLCreateError;
          uint64_t v59 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          swift_allocError(&type metadata for MLCreateError, v59, 0, 0);
          *(_OWORD *)uint64_t v60 = v76;
          *(_OWORD *)(v60 + 16) = 0;
          *(_OWORD *)(v60 + 32) = 0;
          *(unsigned char *)(v60 + 48) = 0;
          swift_willThrow(&type metadata for MLCreateError, v59, v60, v61, v62, v63);
        }
      }
    }
  }
  return a1;
}

uint64_t *static _ImageUtilities.getDataSourceSynopsisForHandPoseClassifier(from:)(long long *a1, __m128 a2)
{
  unint64_t v141 = (void *)v2;
  uint64_t v120 = type metadata accessor for URL(0);
  uint64_t v139 = *(void *)(v120 - 8);
  int64_t v3 = *(void *)(v139 + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  uint64_t v136 = &v111;
  long long v6 = alloca(v3);
  uint64_t v7 = alloca(v3);
  unint64_t v137 = &v111;
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DiscontiguousColumnSlice<Int>)
                             - 8)
                 + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  unint64_t v135 = &v111;
  uint64_t v115 = type metadata accessor for DataFrame.Slice(0);
  unint64_t v116 = *(void *)(v115 - 8);
  int64_t v11 = *(void *)(v116 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v117 = &v111;
  char v138 = (uint64_t *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v118 = *(v138 - 1);
  int64_t v14 = *(void *)(v118 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  char v119 = &v111;
  int64_t v17 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>)
                              - 8)
                  + 64);
  uint64_t v18 = alloca(v17);
  unint64_t v19 = alloca(v17);
  Swift::String v121 = &v111;
  uint64_t v122 = type metadata accessor for DataFrame(0);
  uint64_t v123 = *(uint64_t **)(v122 - 8);
  int64_t v20 = v123[8];
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v140 = &v111;
  uint64_t v23 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
  int64_t v24 = *(void *)(*(void *)(v23 - 8) + 64);
  char v25 = alloca(v24);
  id v26 = alloca(v24);
  uint64_t v27 = &v111;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)a1, (uint64_t)&v111, type metadata accessor for MLHandPoseClassifier.DataSource);
  if (swift_getEnumCaseMultiPayload(&v111, v23) != 3)
  {
    uint64_t v35 = (uint64_t)v141;
    static _ImageUtilities.getImageURLsAndAnnotations(from:)(a1, a2);
    uint64_t v128 = v35;
    if (v35)
    {
      swift_bridgeObjectRelease_n(_swiftEmptyDictionarySingleton, 2, v36, v37, v38);
      return (uint64_t *)outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)&v111);
    }
    else
    {
      uint64_t v67 = v131;
      unsigned int v68 = v132;
      outlined copy of Result<_DataTable, Error>((uint64_t)v131, v132);
      v69._uint64_t countAndFlagsBits = 0x6C6562616CLL;
      v69._char object = (void *)0xE500000000000000;
      specialized MLDataTable.subscript.getter(v69, (uint64_t)v67, v68, v70, v71);
      outlined consume of Result<_DataTable, Error>((uint64_t)v67, v68);
      uint64_t v72 = (uint64_t)v129;
      LODWORD(v141) = v130;
      specialized MLDataColumn.dropDuplicates()((uint64_t)v129, v130);
      outlined consume of Result<_DataTable, Error>(v72, (char)v141);
      uint64_t v73 = specialized Array<A>.init(_:)((uint64_t)v131, v132, *(double *)a2.i64);
      outlined copy of Result<_DataTable, Error>((uint64_t)v67, v68);
      v69._uint64_t countAndFlagsBits = 0x7461506567616D69;
      v69._char object = (void *)0xE900000000000068;
      specialized MLDataTable.subscript.getter(v69, (uint64_t)v67, v68, v74, v75);
      Swift::String v121 = v67;
      LODWORD(v140) = v68;
      outlined consume of Result<_DataTable, Error>((uint64_t)v67, v68);
      long long v76 = specialized Array<A>.init(_:)((uint64_t)v131, v132, *(double *)a2.i64);
      uint64_t v77 = (uint64_t)v76;
      int64_t v78 = v76[2];
      uint64_t v123 = &v111;
      uint64_t v113 = (uint64_t)v73;
      if (v78)
      {
        int64_t v131 = _swiftEmptyArrayStorage;
        char v138 = (uint64_t *)v78;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v78, 0);
        uint64_t v79 = v131;
        unint64_t v135 = (uint64_t *)v77;
        uint64_t v80 = (void *)(v77 + 40);
        do
        {
          unint64_t v141 = v80;
          uint64_t v81 = *(v80 - 1);
          uint64_t v82 = *v80;
          swift_bridgeObjectRetain(*v80);
          URL.init(fileURLWithPath:)(v81, v82);
          swift_bridgeObjectRelease(v82);
          int64_t v131 = v79;
          unint64_t v83 = v79[2];
          if ((unint64_t)v79[3] >> 1 <= v83)
          {
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)((unint64_t)v79[3] >= 2, v83 + 1, 1);
            uint64_t v79 = v131;
          }
          v79[2] = v83 + 1;
          (*(void (**)(char *, uint64_t *, uint64_t))(v139 + 32))((char *)v79+ ((*(unsigned __int8 *)(v139 + 80) + 32) & ~*(unsigned __int8 *)(v139 + 80))+ *(void *)(v139 + 72) * v83, v137, v120);
          uint64_t v80 = v141 + 2;
          char v138 = (uint64_t *)((char *)v138 - 1);
        }
        while (v138);
        uint64_t v114 = v79;
        swift_bridgeObjectRelease((_BYTE)v135);
        uint64_t v27 = v123;
        uint64_t v73 = (void *)v113;
      }
      else
      {
        swift_bridgeObjectRelease((_BYTE)v76);
        uint64_t v114 = _swiftEmptyArrayStorage;
      }
      uint64_t v84 = v73[2];
      LODWORD(v122) = v140;
      uint64_t v111 = v84;
      if (v84)
      {
        char v112 = v73 + 4;
        char v85 = _swiftEmptyDictionarySingleton;
        unint64_t v86 = 0;
        char v138 = _swiftEmptyDictionarySingleton;
        do
        {
          if (v86 >= v73[2]) {
            BUG();
          }
          uint64_t v115 = (uint64_t)v85;
          unint64_t v116 = v86;
          unint64_t v135 = (uint64_t *)v112[2 * v86];
          uint64_t v87 = v112[2 * v86 + 1];
          uint64_t v88 = (uint64_t)v121;
          int64_t v131 = v121;
          char v89 = v122;
          LOBYTE(v132) = v122;
          outlined copy of Result<_DataTable, Error>((uint64_t)v121, v122);
          swift_bridgeObjectRetain(v87);
          v90._uint64_t countAndFlagsBits = 0x6C6562616CLL;
          v90._char object = (void *)0xE500000000000000;
          MLDataTable.subscript.getter(v90);
          outlined consume of Result<_DataTable, Error>(v88, v89);
          uint64_t v91 = v124;
          LODWORD(v141) = v125;
          uint64_t v126 = v124;
          unsigned __int8 v127 = v125;
          uint64_t v133 = &type metadata for String;
          uint64_t v134 = &protocol witness table for String;
          int64_t v131 = v135;
          uint64_t v140 = (uint64_t *)v87;
          unint64_t v132 = v87;
          swift_bridgeObjectRetain(v87);
          static MLUntypedColumn.== infix(_:_:)((uint64_t)&v126, &v131);
          outlined consume of Result<_DataTable, Error>(v91, (char)v141);
          __swift_destroy_boxed_opaque_existential_1Tm(&v131);
          unint64_t v141 = v129;
          LOBYTE(v87) = v130;
          uint64_t v124 = v88;
          unsigned __int8 v125 = v89;
          uint64_t v126 = (uint64_t)v129;
          unsigned __int8 v127 = v130;
          outlined copy of Result<_DataTable, Error>(v88, v89);
          MLDataTable.subscript.getter((uint64_t)&v126);
          outlined consume of Result<_DataTable, Error>((uint64_t)v141, v87);
          outlined consume of Result<_DataTable, Error>(v88, v89);
          id v92 = v131;
          unsigned int v93 = v132;
          swift_bridgeObjectRetain((_BYTE)v140);
          Swift::Int v94 = MLDataTable.size.getter();
          char v95 = v138;
          char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v138);
          int64_t v131 = v95;
          LOBYTE(v95) = (_BYTE)v140;
          specialized _NativeDictionary.setValue(_:forKey:isUnique:)(v94, (uint64_t)v135, (uint64_t)v140, isUniquelyReferenced_nonNull_native);
          char v138 = v131;
          swift_bridgeObjectRelease((_BYTE)v95);
          swift_bridgeObjectRelease(0);
          outlined copy of Result<_DataTable, Error>((uint64_t)v92, v93);
          v90._uint64_t countAndFlagsBits = 0x7461506567616D69;
          v90._char object = (void *)0xE900000000000068;
          specialized MLDataTable.subscript.getter(v90, (uint64_t)v92, v93, v97, v98);
          uint64_t v117 = v92;
          LODWORD(v118) = v93;
          outlined consume of Result<_DataTable, Error>((uint64_t)v92, v93);
          uint64_t v99 = (uint64_t)v129;
          LOBYTE(v95) = v130;
          specialized MLDataColumn.dropDuplicates()((uint64_t)v129, v130);
          outlined consume of Result<_DataTable, Error>(v99, (char)v95);
          Swift::String v100 = specialized Array<A>.init(_:)((uint64_t)v131, v132, *(double *)a2.i64);
          unint64_t v101 = v100;
          int64_t v102 = v100[2];
          if (v102)
          {
            int64_t v131 = _swiftEmptyArrayStorage;
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v102, 0);
            uint64_t v103 = v131;
            char v119 = v101;
            uint64_t v104 = v101 + 5;
            do
            {
              unint64_t v141 = (void *)v102;
              unint64_t v137 = (uint64_t *)*(v104 - 1);
              uint64_t v105 = *v104;
              swift_bridgeObjectRetain(*v104);
              URL.init(fileURLWithPath:)(v137, v105);
              swift_bridgeObjectRelease(v105);
              int64_t v131 = v103;
              unint64_t v106 = v103[2];
              if ((unint64_t)v103[3] >> 1 <= v106)
              {
                specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)((unint64_t)v103[3] >= 2, v106 + 1, 1);
                uint64_t v103 = v131;
              }
              v103[2] = v106 + 1;
              (*(void (**)(char *, uint64_t *, uint64_t))(v139 + 32))((char *)v103+ ((*(unsigned __int8 *)(v139 + 80) + 32) & ~*(unsigned __int8 *)(v139 + 80))+ *(void *)(v139 + 72) * v106, v136, v120);
              v104 += 2;
              int64_t v102 = (int64_t)v141 - 1;
            }
            while (v141 != (void *)((char *)&dword_0 + 1));
            swift_bridgeObjectRelease((_BYTE)v119);
          }
          else
          {
            swift_bridgeObjectRelease((_BYTE)v100);
            uint64_t v103 = _swiftEmptyArrayStorage;
          }
          unint64_t v107 = v116 + 1;
          char v108 = (uint64_t *)v115;
          char v109 = swift_isUniquelyReferenced_nonNull_native(v115);
          int64_t v131 = v108;
          LOBYTE(v108) = (_BYTE)v140;
          specialized _NativeDictionary.setValue(_:forKey:isUnique:)((uint64_t)v103, (uint64_t)v135, (uint64_t)v140, v109);
          char v85 = v131;
          swift_bridgeObjectRelease((_BYTE)v108);
          swift_bridgeObjectRelease(0);
          outlined consume of Result<_DataTable, Error>((uint64_t)v117, v118);
          unint64_t v86 = v107;
          BOOL v110 = v107 == v111;
          uint64_t v27 = v123;
          uint64_t v73 = (void *)v113;
        }
        while (!v110);
        swift_bridgeObjectRelease(v113);
      }
      else
      {
        swift_bridgeObjectRelease((_BYTE)v73);
      }
      outlined consume of Result<_DataTable, Error>((uint64_t)v121, v122);
      outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v27);
      return v114;
    }
  }
  unint64_t v137 = v114;
  char v28 = v116;
  char v29 = v118;
  outlined consume of Result<_DataTable, Error>(v111, (char)v112);
  swift_bridgeObjectRelease(v29);
  swift_bridgeObjectRelease(v28);
  swift_bridgeObjectRelease((_BYTE)v137);
  uint64_t v30 = (uint64_t)v141;
  MLHandPoseClassifier.DataSource.extractKeypoints()(a2);
  uint64_t v128 = v30;
  if (v30) {
    return (uint64_t *)swift_bridgeObjectRelease_n(_swiftEmptyDictionarySingleton, 2, v31, v32, v33);
  }
  int64_t v39 = v119;
  DataFrame.subscript.getter(0x6C6562616CLL, 0xE500000000000000, &type metadata for String);
  int64_t v131 = 0;
  unint64_t v132 = 0xE000000000000000;
  uint64_t v40 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v41 = v138;
  OptionalColumnProtocol.filled(with:)(&v131, v138, v40);
  (*(void (**)(uint64_t *, uint64_t *))(v118 + 8))(v39, v41);
  uint64_t v42 = specialized Set.init<A>(_:)();
  uint64_t v43 = 1 << *(unsigned char *)(v42 + 32);
  uint64_t v44 = ~(-1 << v43);
  if (v43 >= 64) {
    uint64_t v44 = -1;
  }
  uint64_t v139 = v42;
  unint64_t v45 = *(void *)(v42 + 56) & v44;
  uint64_t v136 = (uint64_t *)((unint64_t)(v43 + 63) >> 6);
  BOOL v46 = _swiftEmptyDictionarySingleton;
  uint64_t v47 = 0;
  uint64_t v48 = (uint64_t)v117;
  while (1)
  {
    char v138 = v46;
    if (v45)
    {
      _BitScanForward64(&v49, v45);
      unint64_t v137 = (uint64_t *)((v45 - 1) & v45);
      unint64_t v141 = (void *)v47;
      unint64_t v50 = v49 | (v47 << 6);
      goto LABEL_22;
    }
    BOOL v51 = __OFADD__(1, v47);
    uint64_t v52 = v47 + 1;
    if (v51) {
      BUG();
    }
    if (v52 >= (uint64_t)v136)
    {
      uint64_t v54 = (uint64_t)v140;
      goto LABEL_35;
    }
    unint64_t v53 = *(void *)(v139 + 8 * v52 + 56);
    uint64_t v54 = (uint64_t)v140;
    if (!v53) {
      break;
    }
LABEL_21:
    _BitScanForward64(&v56, v53);
    unint64_t v137 = (uint64_t *)(v53 & (v53 - 1));
    unint64_t v141 = (void *)v52;
    unint64_t v50 = v56 + (v52 << 6);
LABEL_22:
    uint64_t v57 = *(void *)(v139 + 48);
    uint64_t v58 = 16 * v50;
    uint64_t v120 = *(void *)(v57 + v58);
    uint64_t v59 = *(void *)(v57 + v58 + 8);
    uint64_t v60 = alloca(32);
    uint64_t v61 = alloca(32);
    uint64_t v113 = v120;
    uint64_t v114 = (uint64_t *)v59;
    swift_bridgeObjectRetain(v59);
    uint64_t v62 = v128;
    DataFrame.filter<A>(on:_:_:)(0x6C6562616CLL, 0xE500000000000000, &type metadata for String, partial apply for closure #7 in MLActivityClassifier.DataSource.gatherDataFromAnnotations(directoryURL:annotationFileName:labelColumn:fileColumn:startTimeColumn:endTimeColumn:featureColumns:timeStampColumn:), &v111, &type metadata for String);
    uint64_t v128 = v62;
    DataFrame.Slice.subscript.getter(0x5F6E6F6973736573, 0xEA00000000006469, &type metadata for Int);
    uint64_t v63 = specialized Set.init<A>(_:)();
    uint64_t v64 = *(void *)(v63 + 16);
    swift_bridgeObjectRelease(v63);
    int v65 = v138;
    char v66 = swift_isUniquelyReferenced_nonNull_native(v138);
    int64_t v131 = v65;
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)(v64, v120, v59, v66);
    BOOL v46 = v131;
    swift_bridgeObjectRelease(v59);
    swift_bridgeObjectRelease(0);
    (*(void (**)(uint64_t, uint64_t))(v116 + 8))(v48, v115);
    uint64_t v47 = (uint64_t)v141;
    unint64_t v45 = (unint64_t)v137;
  }
  uint64_t v55 = v52 + 1;
  if (v52 + 1 >= (uint64_t)v136) {
    goto LABEL_35;
  }
  unint64_t v53 = *(void *)(v139 + 8 * v52 + 64);
  if (v53) {
    goto LABEL_20;
  }
  uint64_t v55 = v52 + 2;
  if (v52 + 2 >= (uint64_t)v136) {
    goto LABEL_35;
  }
  unint64_t v53 = *(void *)(v139 + 8 * v52 + 72);
  if (v53) {
    goto LABEL_20;
  }
  uint64_t v55 = v52 + 3;
  if (v52 + 3 >= (uint64_t)v136) {
    goto LABEL_35;
  }
  unint64_t v53 = *(void *)(v139 + 8 * v52 + 80);
  if (v53)
  {
LABEL_20:
    uint64_t v52 = v55;
    goto LABEL_21;
  }
  v52 += 3;
  while (1)
  {
    BOOL v51 = __OFADD__(1, v52++);
    if (v51) {
      BUG();
    }
    if (v52 >= (uint64_t)v136) {
      break;
    }
    unint64_t v53 = *(void *)(v139 + 8 * v52 + 56);
    if (v53) {
      goto LABEL_21;
    }
  }
LABEL_35:
  swift_release();
  ((void (*)(uint64_t, uint64_t))v123[1])(v54, v122);
  return _swiftEmptyArrayStorage;
}

uint64_t lazy protocol witness table accessor for type URL and conformance URL(uint64_t *a1, uint64_t a2)
{
  uint64_t result = *a1;
  if (!*a1)
  {
    uint64_t v3 = type metadata accessor for URL(255);
    uint64_t result = swift_getWitnessTable(a2, v3);
    *a1 = result;
  }
  return result;
}

uint64_t outlined destroy of MLHandPoseClassifier.DataSource(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

void *static PearsonSimilarity.buildItemStatistics(ratings:count:)(void *a1, uint64_t a2)
{
  uint64_t v40 = a2;
  uint64_t v2 = specialized Array.init(repeating:count:)(0, 0, a2, 0.0, 0.0);
  uint64_t v36 = a1[3];
  uint64_t v37 = a1[4];
  uint64_t v38 = a1[5];
  outlined retain of [Int](&v36);
  outlined retain of [Int](&v37);
  outlined retain of ContiguousArray<Double>(&v38);
  specialized SparseMatrix.IndexedSequence.Iterator.init(base:)((uint64_t)a1);
  specialized SparseMatrix.IndexedSequence.Iterator.next()(a1, 0, v3, v4, v5, v6);
  if ((v9 & 1) == 0)
  {
    uint64_t v10 = v7;
    double v11 = v8;
    do
    {
      if (v10 < 0) {
        BUG();
      }
      if ((unint64_t)v10 >= v2[2]) {
        BUG();
      }
      uint64_t v12 = 4 * v10;
      uint64_t v13 = v2[v12 + 5];
      BOOL v14 = __OFADD__(1, v13);
      int v15 = v13 + 1;
      if (v14) {
        BUG();
      }
      double v39 = *(double *)&v2[v12 + 6];
      uint64_t v16 = v2;
      if (!swift_isUniquelyReferenced_nonNull_native(v2))
      {
        uint64_t v16 = v2;
        uint64_t v2 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v2);
      }
      double v20 = v11 - v39;
      double v21 = (v11 - v39) / (double)v15 + *(double *)&v2[v12 + 6];
      *(double *)&v2[v12 + 6] = v21;
      *(double *)&v2[v12 + 7] = (v11 - v21) * v20 + *(double *)&v2[v12 + 7];
      uint64_t v22 = v2[v12 + 5];
      BOOL v14 = __OFADD__(1, v22);
      uint64_t v23 = v22 + 1;
      if (v14) {
        BUG();
      }
      int64_t v24 = &v2[v12 + 4];
      v24[1] = v23;
      uint64_t v25 = *v24 + 1;
      if (__OFADD__(1, *v24)) {
        BUG();
      }
      uint64_t *v24 = v25;
      specialized SparseMatrix.IndexedSequence.Iterator.next()(v16, 0, v17, v25, v18, v19);
      uint64_t v10 = v26;
      double v11 = v27;
    }
    while ((v28 & 1) == 0);
  }
  swift_release();
  swift_bridgeObjectRelease(v35);
  swift_bridgeObjectRelease(v34);
  uint64_t v29 = v40;
  if (v40 < 0) {
    BUG();
  }
  if (v40)
  {
    if ((unint64_t)(v40 - 1) >= v2[2]) {
      BUG();
    }
    if (!swift_isUniquelyReferenced_nonNull_native(v2)) {
      uint64_t v2 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v2);
    }
    uint64_t v30 = (double *)(v2 + 7);
    do
    {
      uint64_t v31 = *((void *)v30 - 2);
      uint64_t v32 = v31 - 1;
      if (__OFSUB__(v31, 1)) {
        BUG();
      }
      if (v32 < 2) {
        LODWORD(v32) = 1;
      }
      *uint64_t v30 = (double)(int)v31 / (double)(int)v32 * *v30;
      v30 += 4;
      --v29;
    }
    while (v29);
  }
  return v2;
}

void static PearsonSimilarityPredictor.updatePrediction(_:itemScore:neighborScore:)(double *a1, __m128d a2, double a3)
{
  a2.f64[0] = a2.f64[0] * a3;
  __m128d v3 = _mm_or_pd(_mm_and_pd((__m128d)xmmword_3474C0, a2), (__m128d)xmmword_34EAE0);
  v3.f64[0] = v3.f64[0] + a2.f64[0];
  *a1 = _mm_round_sd(a2, v3, 11).f64[0] + *a1;
}

double static PearsonSimilarityPredictor.finalizePrediction(_:userRatingCount:)(uint64_t a1, double a2)
{
  if (a1 > 0) {
    return a2 / (double)(int)a1;
  }
  else {
    return 0.0;
  }
}

double protocol witness for static ItemSimilarityPredictor.interactionScoreRange.getter in conformance PearsonSimilarityPredictor()
{
  return -1.0;
}

void protocol witness for static ItemSimilarityPredictor.updatePrediction(_:itemScore:neighborScore:) in conformance PearsonSimilarityPredictor(double *a1, __m128d a2, double a3)
{
}

double protocol witness for static ItemSimilarityPredictor.finalizePrediction(_:userRatingCount:) in conformance PearsonSimilarityPredictor(uint64_t a1, double a2)
{
  return static PearsonSimilarityPredictor.finalizePrediction(_:userRatingCount:)(a1, a2);
}

ValueMetadata *type metadata accessor for PearsonSimilarity()
{
  return &type metadata for PearsonSimilarity;
}

uint64_t getEnumTagSinglePayload for PearsonSimilarity.ItemScore(uint64_t a1, int a2)
{
  uint64_t result = 0;
  if (a2)
  {
    if (*(unsigned char *)(a1 + 24)) {
      return (*(_DWORD *)a1 + 1);
    }
  }
  return result;
}

void storeEnumTagSinglePayload for PearsonSimilarity.ItemScore(uint64_t a1, int a2, int a3)
{
  if (!a2)
  {
    if (!a3) {
      return;
    }
    char v3 = 0;
    goto LABEL_6;
  }
  *(_OWORD *)(a1 + 8) = 0;
  *(void *)a1 = (a2 - 1);
  char v3 = 1;
  if (a3) {
LABEL_6:
  }
    *(unsigned char *)(a1 + 24) = v3;
}

ValueMetadata *type metadata accessor for PearsonSimilarity.ItemScore()
{
  return &type metadata for PearsonSimilarity.ItemScore;
}

ValueMetadata *type metadata accessor for PearsonSimilarityPredictor()
{
  return &type metadata for PearsonSimilarityPredictor;
}

uint64_t *initializeBufferWithCopyOfBuffer for MLImageClassifier.PersistentParameters(uint64_t *a1, uint64_t *a2, int *a3)
{
  int v3 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  uint64_t v4 = *a2;
  *a1 = *a2;
  if ((v3 & 0x20000) != 0)
  {
    uint64_t v6 = (uint64_t *)(v4 + ((v3 + 16) & ~v3));
    swift_retain();
  }
  else
  {
    uint64_t v6 = a1;
    uint64_t v7 = a3[5];
    double v8 = (uint64_t *)((char *)a1 + v7);
    char v9 = (uint64_t *)((char *)a2 + v7);
    char v10 = v4;
    uint64_t v11 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
    swift_bridgeObjectRetain(v10);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v9, v11);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v14 = *v9;
      uint64_t *v8 = *v9;
      swift_bridgeObjectRetain(v14);
      swift_storeEnumTagMultiPayload(v8, v11, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v26 = type metadata accessor for MLImageClassifier.DataSource(0);
      unsigned int v27 = swift_getEnumCaseMultiPayload(v9, v26);
      if (v27 == 2)
      {
        uint64_t v15 = *v9;
        uint64_t *v8 = *v9;
        swift_bridgeObjectRetain(v15);
      }
      else
      {
        uint64_t v13 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v13 - 8) + 16))(v8, v9, v13);
      }
      swift_storeEnumTagMultiPayload(v8, v26, v27);
      swift_storeEnumTagMultiPayload(v8, v11, 1);
    }
    else
    {
      memcpy(v8, v9, *(void *)(*(void *)(v11 - 8) + 64));
    }
    uint64_t v16 = a3[6];
    uint64_t v17 = (char *)v6 + v16;
    uint64_t v18 = (char *)a2 + v16;
    uint64_t v19 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
    if (swift_getEnumCaseMultiPayload(v18, v19) == 1)
    {
      uint64_t v20 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v20 - 8) + 16))(v17, v18, v20);
      uint64_t v21 = *(int *)(type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0) + 20);
      *(void *)&v17[v21] = *(void *)&v18[v21];
      uint64_t v22 = *(void *)&v18[v21 + 8];
      *(void *)&v17[v21 + 8] = v22;
      swift_bridgeObjectRetain(v22);
      swift_storeEnumTagMultiPayload(v17, v19, 1);
    }
    else
    {
      memcpy(v17, v18, *(void *)(*(void *)(v19 - 8) + 64));
    }
    uint64_t v23 = a3[7];
    uint64_t v24 = *(uint64_t *)((char *)a2 + v23);
    if (v24 != 2) {
      swift_bridgeObjectRetain(*(uint64_t *)((char *)a2 + v23));
    }
    *(uint64_t *)((char *)v6 + v23) = v24;
    *(uint64_t *)((char *)v6 + a3[8]) = *(uint64_t *)((char *)a2 + a3[8]);
    *(uint64_t *)((char *)v6 + a3[9]) = *(uint64_t *)((char *)a2 + a3[9]);
  }
  return v6;
}

uint64_t destroy for MLImageClassifier.PersistentParameters(void *a1, int *a2)
{
  swift_bridgeObjectRelease(*a1);
  uint64_t v2 = (void *)((char *)a1 + a2[5]);
  uint64_t v3 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v2, v3);
  if (EnumCaseMultiPayload == 2) {
    goto LABEL_6;
  }
  if (EnumCaseMultiPayload != 1) {
    goto LABEL_7;
  }
  uint64_t v5 = type metadata accessor for MLImageClassifier.DataSource(0);
  unsigned int v6 = swift_getEnumCaseMultiPayload(v2, v5);
  if (v6 == 2)
  {
LABEL_6:
    swift_bridgeObjectRelease(*v2);
  }
  else if (v6 <= 1)
  {
    uint64_t v7 = type metadata accessor for URL(0);
    (*(void (**)(void *, uint64_t))(*(void *)(v7 - 8) + 8))(v2, v7);
  }
LABEL_7:
  double v8 = (char *)a1 + a2[6];
  uint64_t v9 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  if (swift_getEnumCaseMultiPayload(v8, v9) == 1)
  {
    uint64_t v10 = type metadata accessor for URL(0);
    (*(void (**)(char *, uint64_t))(*(void *)(v10 - 8) + 8))(v8, v10);
    uint64_t v11 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
    swift_bridgeObjectRelease(*(void *)&v8[*(int *)(v11 + 20) + 8]);
  }
  uint64_t result = a2[7];
  uint64_t v13 = *(void *)((char *)a1 + result);
  if (v13 != 2) {
    return swift_bridgeObjectRelease(v13);
  }
  return result;
}

uint64_t *initializeWithCopy for MLImageClassifier.PersistentParameters(uint64_t *a1, uint64_t *a2, int *a3)
{
  uint64_t v4 = *a2;
  *a1 = *a2;
  uint64_t v5 = a3[5];
  unsigned int v6 = (uint64_t *)((char *)a1 + v5);
  uint64_t v7 = (uint64_t *)((char *)a2 + v5);
  char v8 = v4;
  uint64_t v9 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  swift_bridgeObjectRetain(v8);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v7, v9);
  if (EnumCaseMultiPayload == 2)
  {
    uint64_t v12 = *v7;
    uint64_t *v6 = *v7;
    swift_bridgeObjectRetain(v12);
    swift_storeEnumTagMultiPayload(v6, v9, 2);
  }
  else if (EnumCaseMultiPayload == 1)
  {
    uint64_t v24 = type metadata accessor for MLImageClassifier.DataSource(0);
    unsigned int v25 = swift_getEnumCaseMultiPayload(v7, v24);
    if (v25 == 2)
    {
      uint64_t v13 = *v7;
      uint64_t *v6 = *v7;
      swift_bridgeObjectRetain(v13);
    }
    else
    {
      uint64_t v11 = type metadata accessor for URL(0);
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v11 - 8) + 16))(v6, v7, v11);
    }
    swift_storeEnumTagMultiPayload(v6, v24, v25);
    swift_storeEnumTagMultiPayload(v6, v9, 1);
  }
  else
  {
    memcpy(v6, v7, *(void *)(*(void *)(v9 - 8) + 64));
  }
  uint64_t v14 = a3[6];
  uint64_t v15 = (char *)a1 + v14;
  uint64_t v16 = (char *)a2 + v14;
  uint64_t v17 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  if (swift_getEnumCaseMultiPayload(v16, v17) == 1)
  {
    uint64_t v18 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 16))(v15, v16, v18);
    uint64_t v19 = *(int *)(type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0) + 20);
    *(void *)&v15[v19] = *(void *)&v16[v19];
    uint64_t v20 = *(void *)&v16[v19 + 8];
    *(void *)&v15[v19 + 8] = v20;
    swift_bridgeObjectRetain(v20);
    swift_storeEnumTagMultiPayload(v15, v17, 1);
  }
  else
  {
    memcpy(v15, v16, *(void *)(*(void *)(v17 - 8) + 64));
  }
  uint64_t v21 = a3[7];
  uint64_t v22 = *(uint64_t *)((char *)a2 + v21);
  if (v22 != 2) {
    swift_bridgeObjectRetain(*(uint64_t *)((char *)a2 + v21));
  }
  *(uint64_t *)((char *)a1 + v21) = v22;
  *(uint64_t *)((char *)a1 + a3[8]) = *(uint64_t *)((char *)a2 + a3[8]);
  *(uint64_t *)((char *)a1 + a3[9]) = *(uint64_t *)((char *)a2 + a3[9]);
  return a1;
}

uint64_t *assignWithCopy for MLImageClassifier.PersistentParameters(uint64_t *a1, uint64_t *a2, int *a3)
{
  uint64_t v5 = *a2;
  uint64_t v6 = *a1;
  *a1 = *a2;
  swift_bridgeObjectRetain(v5);
  swift_bridgeObjectRelease(v6);
  uint64_t v29 = a3;
  if (a1 != a2)
  {
    uint64_t v7 = a3[5];
    char v8 = (uint64_t *)((char *)a1 + v7);
    uint64_t v9 = (uint64_t *)((char *)a2 + v7);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v8, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
    uint64_t v10 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v9, v10);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v13 = *v9;
      uint64_t *v8 = *v9;
      swift_bridgeObjectRetain(v13);
      swift_storeEnumTagMultiPayload(v8, v10, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v27 = type metadata accessor for MLImageClassifier.DataSource(0);
      unsigned int v28 = swift_getEnumCaseMultiPayload(v9, v27);
      if (v28 == 2)
      {
        uint64_t v14 = *v9;
        uint64_t *v8 = *v9;
        swift_bridgeObjectRetain(v14);
      }
      else
      {
        uint64_t v12 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v12 - 8) + 16))(v8, v9, v12);
      }
      swift_storeEnumTagMultiPayload(v8, v27, v28);
      swift_storeEnumTagMultiPayload(v8, v10, 1);
    }
    else
    {
      memcpy(v8, v9, *(void *)(*(void *)(v10 - 8) + 64));
    }
    uint64_t v15 = v29[6];
    uint64_t v16 = (char *)a1 + v15;
    uint64_t v17 = (char *)a2 + v15;
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v16, type metadata accessor for MLImageClassifier.FeatureExtractorType);
    uint64_t v18 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
    if (swift_getEnumCaseMultiPayload(v17, v18) == 1)
    {
      uint64_t v19 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16))(v16, v17, v19);
      uint64_t v20 = *(int *)(type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0) + 20);
      *(void *)&v16[v20] = *(void *)&v17[v20];
      uint64_t v21 = *(void *)&v17[v20 + 8];
      *(void *)&v16[v20 + 8] = v21;
      swift_bridgeObjectRetain(v21);
      swift_storeEnumTagMultiPayload(v16, v18, 1);
    }
    else
    {
      memcpy(v16, v17, *(void *)(*(void *)(v18 - 8) + 64));
    }
    a3 = v29;
  }
  uint64_t v22 = a3[7];
  uint64_t v23 = (uint64_t *)((char *)a1 + v22);
  uint64_t v24 = *(uint64_t *)((char *)a1 + v22);
  uint64_t v25 = *(uint64_t *)((char *)a2 + v22);
  if (v24 == 2)
  {
    if (v25 == 2)
    {
      *uint64_t v23 = 2;
    }
    else
    {
      *uint64_t v23 = v25;
      swift_bridgeObjectRetain(v25);
    }
  }
  else if (v25 == 2)
  {
    outlined destroy of MLImageClassifier.ModelParameters.ClassifierType((uint64_t)a1 + v22);
    *uint64_t v23 = *(uint64_t *)((char *)a2 + v22);
  }
  else
  {
    *uint64_t v23 = v25;
    swift_bridgeObjectRetain(v25);
    swift_bridgeObjectRelease(v24);
  }
  *(uint64_t *)((char *)a1 + v29[8]) = *(uint64_t *)((char *)a2 + v29[8]);
  *(uint64_t *)((char *)a1 + v29[9]) = *(uint64_t *)((char *)a2 + v29[9]);
  return a1;
}

uint64_t outlined destroy of MLImageClassifier.ModelParameters.ClassifierType(uint64_t a1)
{
  (*(void (**)(uint64_t))(*((void *)&type metadata for MLImageClassifier.ModelParameters.ClassifierType - 1)
                                  + 8))(a1);
  return a1;
}

void *initializeWithTake for MLImageClassifier.PersistentParameters(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v5 = a3[5];
  uint64_t v6 = (char *)a1 + v5;
  uint64_t v7 = (char *)a2 + v5;
  uint64_t v8 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  if (swift_getEnumCaseMultiPayload(v7, v8) != 1)
  {
    memcpy(v6, v7, *(void *)(*(void *)(v8 - 8) + 64));
    goto LABEL_10;
  }
  uint64_t v23 = v8;
  uint64_t v9 = type metadata accessor for MLImageClassifier.DataSource(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v7, v9);
  if (EnumCaseMultiPayload == 1)
  {
    uint64_t v15 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 32))(v6, v7, v15);
    uint64_t v14 = 1;
    uint64_t v12 = v6;
    uint64_t v13 = v9;
  }
  else
  {
    if (EnumCaseMultiPayload)
    {
      memcpy(v6, v7, *(void *)(*(void *)(v9 - 8) + 64));
      goto LABEL_9;
    }
    uint64_t v11 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 32))(v6, v7, v11);
    uint64_t v12 = v6;
    uint64_t v13 = v9;
    uint64_t v14 = 0;
  }
  swift_storeEnumTagMultiPayload(v12, v13, v14);
LABEL_9:
  swift_storeEnumTagMultiPayload(v6, v23, 1);
LABEL_10:
  uint64_t v16 = a3[6];
  uint64_t v17 = (char *)a1 + v16;
  uint64_t v18 = (char *)a2 + v16;
  uint64_t v19 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  if (swift_getEnumCaseMultiPayload(v18, v19) == 1)
  {
    uint64_t v20 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v20 - 8) + 32))(v17, v18, v20);
    uint64_t v21 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
    *(_OWORD *)&v17[*(int *)(v21 + 20)] = *(_OWORD *)&v18[*(int *)(v21 + 20)];
    swift_storeEnumTagMultiPayload(v17, v19, 1);
  }
  else
  {
    memcpy(v17, v18, *(void *)(*(void *)(v19 - 8) + 64));
  }
  *(void *)((char *)a1 + a3[7]) = *(void *)((char *)a2 + a3[7]);
  *(void *)((char *)a1 + a3[8]) = *(void *)((char *)a2 + a3[8]);
  *(void *)((char *)a1 + a3[9]) = *(void *)((char *)a2 + a3[9]);
  return a1;
}

uint64_t *assignWithTake for MLImageClassifier.PersistentParameters(uint64_t *a1, uint64_t *a2, int *a3)
{
  uint64_t v6 = *a1;
  *a1 = *a2;
  swift_bridgeObjectRelease(v6);
  if (a1 == a2) {
    goto LABEL_15;
  }
  uint64_t v29 = a3;
  uint64_t v7 = a3[5];
  uint64_t v8 = (char *)a1 + v7;
  uint64_t v9 = (char *)a2 + v7;
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v8, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  uint64_t v10 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  if (swift_getEnumCaseMultiPayload(v9, v10) == 1)
  {
    uint64_t v28 = type metadata accessor for MLImageClassifier.DataSource(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v9, v28);
    if (EnumCaseMultiPayload == 1)
    {
      uint64_t v16 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 32))(v8, v9, v16);
      uint64_t v15 = 1;
      uint64_t v13 = v8;
      uint64_t v14 = v28;
    }
    else
    {
      if (EnumCaseMultiPayload)
      {
        memcpy(v8, v9, *(void *)(*(void *)(v28 - 8) + 64));
        goto LABEL_10;
      }
      uint64_t v12 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(v8, v9, v12);
      uint64_t v13 = v8;
      uint64_t v14 = v28;
      uint64_t v15 = 0;
    }
    swift_storeEnumTagMultiPayload(v13, v14, v15);
LABEL_10:
    swift_storeEnumTagMultiPayload(v8, v10, 1);
    goto LABEL_11;
  }
  memcpy(v8, v9, *(void *)(*(void *)(v10 - 8) + 64));
LABEL_11:
  uint64_t v17 = v29[6];
  uint64_t v18 = (char *)a1 + v17;
  uint64_t v19 = (char *)a2 + v17;
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v18, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v20 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  if (swift_getEnumCaseMultiPayload(v19, v20) == 1)
  {
    uint64_t v21 = type metadata accessor for URL(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v21 - 8) + 32))(v18, v19, v21);
    uint64_t v22 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
    *(_OWORD *)&v18[*(int *)(v22 + 20)] = *(_OWORD *)&v19[*(int *)(v22 + 20)];
    swift_storeEnumTagMultiPayload(v18, v20, 1);
  }
  else
  {
    memcpy(v18, v19, *(void *)(*(void *)(v20 - 8) + 64));
  }
  a3 = v29;
LABEL_15:
  uint64_t v23 = a3[7];
  uint64_t v24 = (uint64_t *)((char *)a1 + v23);
  uint64_t v25 = *(uint64_t *)((char *)a1 + v23);
  uint64_t v26 = *(uint64_t *)((char *)a2 + v23);
  if (v25 != 2)
  {
    if (v26 != 2)
    {
      void *v24 = v26;
      swift_bridgeObjectRelease(v25);
      goto LABEL_22;
    }
    outlined destroy of MLImageClassifier.ModelParameters.ClassifierType((uint64_t)a1 + v23);
    uint64_t v26 = *(uint64_t *)((char *)a2 + v23);
    goto LABEL_20;
  }
  if (v26 != 2)
  {
LABEL_20:
    void *v24 = v26;
    goto LABEL_22;
  }
  void *v24 = 2;
LABEL_22:
  *(uint64_t *)((char *)a1 + a3[8]) = *(uint64_t *)((char *)a2 + a3[8]);
  *(uint64_t *)((char *)a1 + a3[9]) = *(uint64_t *)((char *)a2 + a3[9]);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLImageClassifier.PersistentParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_286912);
}

uint64_t sub_286912(void *a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t result = 0;
    if ((*a1 & 0xFFFFFFFF00000001) == 0) {
      return (*a1 >> 1) + 1;
    }
  }
  else
  {
    uint64_t v5 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
    if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2)
    {
      uint64_t v6 = *(int *)(a3 + 20);
    }
    else
    {
      uint64_t v5 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
      uint64_t v6 = *(int *)(a3 + 24);
    }
    return __swift_getEnumTagSinglePayload((uint64_t)a1 + v6, a2, v5);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLImageClassifier.PersistentParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_2869AF);
}

void sub_2869AF(void *a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 0x7FFFFFFF)
  {
    *a1 = 2 * (a2 - 1);
  }
  else
  {
    uint64_t v6 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
    if (*(_DWORD *)(*(void *)(v6 - 8) + 84) == a3)
    {
      uint64_t v7 = *(int *)(a4 + 20);
    }
    else
    {
      uint64_t v6 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
      uint64_t v7 = *(int *)(a4 + 24);
    }
    __swift_storeEnumTagSinglePayload((uint64_t)a1 + v7, a2, a2, v6);
  }
}

uint64_t type metadata accessor for MLImageClassifier.PersistentParameters(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLImageClassifier.PersistentParameters;
  if (!type metadata singleton initialization cache for MLImageClassifier.PersistentParameters) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLImageClassifier.PersistentParameters);
  }
  return result;
}

uint64_t type metadata completion function for MLImageClassifier.PersistentParameters(uint64_t a1)
{
  v4[0] = (char *)&value witness table for Builtin.BridgeObject + 64;
  uint64_t result = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(319);
  if (v2 <= 0x3F)
  {
    v4[1] = *(void *)(result - 8) + 64;
    uint64_t result = type metadata accessor for MLImageClassifier.FeatureExtractorType(319);
    if (v3 <= 0x3F)
    {
      v4[2] = *(void *)(result - 8) + 64;
      v4[3] = "\b";
      _OWORD v4[4] = (char *)&value witness table for Builtin.Int64 + 64;
      void v4[5] = (char *)&value witness table for Builtin.Int64 + 64;
      swift_initStructMetadata(a1, 256, 6, v4, a1 + 16);
      return 0;
    }
  }
  return result;
}

uint64_t MLImageClassifier.PersistentParameters.init(trainingData:modelParameters:)(uint64_t a1, void *a2)
{
  unint64_t v3 = v2;
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0) - 8)
                 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v7 = (int *)type metadata accessor for MLImageClassifier.PersistentParameters(0);
  uint64_t v17 = v7[7];
  *(void *)((char *)v3 + v17) = 2;
  void *v3 = a1;
  outlined init with copy of Any?((uint64_t)(a2 + 2), (uint64_t)&v15);
  if (!v16) {
    BUG();
  }
  uint64_t v8 = (char *)v3 + v7[5];
  outlined init with take of Any(&v15, v14);
  uint64_t v9 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  swift_dynamicCast(v8, v14, (char *)&type metadata for Any + 8, v9, 7);
  MLImageClassifier.ModelParameters.algorithm.getter(v8);
  uint64_t v10 = *(void *)((char *)v14
                  + *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType))
                           + 48));
  outlined init with take of MLClassifierMetrics((uint64_t)v14, (uint64_t)v3 + v7[6], type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v11 = v17;
  outlined consume of MLImageClassifier.ModelParameters.ClassifierType?(*(void *)((char *)v3 + v17));
  *(void *)((char *)v3 + v11) = v10;
  *(void *)((char *)v3 + v7[8]) = *a2;
  uint64_t v12 = a2[1];
  outlined destroy of MLImageClassifier.ModelParameters((uint64_t)a2);
  uint64_t result = v7[9];
  *(void *)((char *)v3 + result) = v12;
  return result;
}

NSURL *MLImageClassifier.PersistentParameters.init(sessionDirectory:)(uint64_t a1)
{
  uint64_t v118 = v2;
  unint64_t v3 = v1;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.ModelParameters.ValidationData?)
                             - 8)
                 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  unint64_t v101 = &v99;
  uint64_t v106 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  int64_t v7 = *(void *)(*(void *)(v106 - 8) + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v103 = &v99;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.FeatureExtractorType?)
                              - 8)
                  + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  char v112 = &v99;
  uint64_t v100 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  int64_t v13 = *(void *)(*(void *)(v100 - 8) + 64);
  uint64_t v14 = alloca(v13);
  long long v15 = alloca(v13);
  uint64_t v113 = &v99;
  uint64_t v117 = type metadata accessor for URL(0);
  uint64_t v107 = *(void *)(v117 - 8);
  int64_t v16 = *(void *)(v107 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  int64_t v102 = &v99;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v111 = &v99;
  uint64_t v21 = alloca(v16);
  uint64_t v22 = alloca(v16);
  uint64_t v23 = type metadata accessor for MLImageClassifier.PersistentParameters(0);
  uint64_t v24 = *(int *)(v23 + 28);
  uint64_t v114 = v3;
  uint64_t v105 = v24;
  *(uint64_t **)((char *)v3 + v24) = (void *)(&dword_0 + 2);
  uint64_t v122 = a1;
  URL.appendingPathComponent(_:)(0xD000000000000010, "ObjectDetectorMetrics." + 0x8000000000000000);
  uint64_t v25 = v118;
  uint64_t v26 = Data.init(contentsOf:options:)(&v99, 0);
  if (!v25)
  {
    unint64_t v30 = v27;
    uint64_t v108 = v23;
    uint64_t v110 = 0;
    uint64_t v31 = v117;
    uint64_t v32 = v26;
    uint64_t v118 = *(void (**)(void, void))(v107 + 8);
    v118(&v99, v117);
    uint64_t v33 = objc_opt_self(NSPropertyListSerialization);
    uint64_t v120 = v32;
    Class isa = Data._bridgeToObjectiveC()().super.isa;
    unint64_t v119 = v30;
    v124[0] = 0;
    id v35 = [v33 propertyListWithData:isa options:0 format:0 error:v124];
    id v36 = v35;

    id v37 = v124[0];
    uint64_t v38 = v31;
    if (!v36)
    {
      uint64_t v48 = v37;
      _convertNSErrorToError(_:)(v37);

      swift_willThrow(v48, "propertyListWithData:options:format:error:", v49, v50, v51, v52);
      outlined consume of Data._Representation(v120, v119);
      v118(v122, v31);
      goto LABEL_26;
    }
    _bridgeAnyObjectToAny(_:)(v36);
    swift_unknownObjectRelease(v36);
    outlined init with copy of Any((uint64_t)v126, (uint64_t)v124);
    uint64_t v39 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any]);
    if (!swift_dynamicCast(&v123, v124, (char *)&type metadata for Any + 8, v39, 6))
    {
      uint64_t v53 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v53, 0, 0);
      *(void *)uint64_t v54 = 0xD000000000000037;
      *(void *)(v54 + 8) = "parameters.plist" + 0x8000000000000000;
      *(_OWORD *)(v54 + 16) = 0;
      *(_OWORD *)(v54 + 32) = 0;
      *(unsigned char *)(v54 + 48) = 0;
      swift_willThrow(&type metadata for MLCreateError, v53, v54, v55, v56, v57);
      outlined consume of Data._Representation(v120, v119);
      uint64_t v58 = v122;
      uint64_t v59 = v38;
LABEL_25:
      v118(v58, v59);
      __swift_destroy_boxed_opaque_existential_1Tm(v126);
      goto LABEL_26;
    }
    uint64_t v115 = (char *)&type metadata for Any + 8;
    uint64_t v109 = v39;
    uint64_t v40 = v123;
    specialized Dictionary.subscript.getter(0x73656C6966, 0xE500000000000000, v123);
    if (v125)
    {
      uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : [String]]);
      if (!swift_dynamicCast(&v123, v124, v115, v41, 6))
      {
        char v61 = v40;
        uint64_t v43 = v38;
LABEL_22:
        swift_bridgeObjectRelease(v61);
        goto LABEL_23;
      }
      uint64_t v121 = v123;
      specialized Dictionary.subscript.getter(0xD000000000000014, (uint64_t)("Empty training input." + 0x8000000000000000), v40);
      if (v125)
      {
        if (swift_dynamicCast(&v123, v124, v115, &type metadata for Int, 6))
        {
          uint64_t v42 = v123;
          specialized Dictionary.subscript.getter(0x726574695F78616DLL, 0xEE00736E6F697461, v40);
          if (v125)
          {
            uint64_t v116 = v40;
            uint64_t v43 = v38;
            if (!swift_dynamicCast(&v123, v124, v115, &type metadata for Int, 6))
            {
              swift_bridgeObjectRelease(v121);
              swift_bridgeObjectRelease(v116);
LABEL_32:
              uint64_t v46 = v122;
              goto LABEL_24;
            }
            uint64_t v104 = v123;
            char v44 = v116;
            specialized Dictionary.subscript.getter(0xD000000000000011, (uint64_t)("logistic_regressor" + 0x8000000000000000), v116);
            if (v125)
            {
              char v45 = swift_dynamicCast(&v123, v124, v115, v109, 6);
              uint64_t v46 = v122;
              if (!v45)
              {
                swift_bridgeObjectRelease(v121);
                swift_bridgeObjectRelease(v116);
                goto LABEL_24;
              }
              uint64_t v47 = (uint64_t)v112;
              MLImageClassifier.FeatureExtractorType.init(dictionary:)(v123);
              if (__swift_getEnumTagSinglePayload(v47, 1, v100) == 1)
              {
                swift_bridgeObjectRelease(v121);
                swift_bridgeObjectRelease(v116);
                _s11TabularData9AnyColumnVSgWOhTm_1(v47, &demangling cache variable for type metadata for MLImageClassifier.FeatureExtractorType?);
LABEL_24:
                uint64_t v64 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
                swift_allocError(&type metadata for MLCreateError, v64, 0, 0);
                *(void *)uint64_t v65 = 0xD000000000000034;
                *(void *)(v65 + 8) = "ad training parameters." + 0x8000000000000000;
                *(_OWORD *)(v65 + 16) = 0;
                *(_OWORD *)(v65 + 32) = 0;
                *(unsigned char *)(v65 + 48) = 0;
                swift_willThrow(&type metadata for MLCreateError, v64, v65, v66, v67, v68);
                outlined consume of Data._Representation(v120, v119);
                uint64_t v58 = v46;
                uint64_t v59 = v43;
                goto LABEL_25;
              }
              uint64_t v72 = (uint64_t)v113;
              outlined init with take of MLClassifierMetrics(v47, (uint64_t)v113, type metadata accessor for MLImageClassifier.FeatureExtractorType);
              char v73 = v121;
              uint64_t v74 = v110;
              char v112 = specialized _NativeDictionary.mapValues<A>(_:)(v121);
              uint64_t v110 = v74;
              swift_bridgeObjectRelease(v73);
              uint64_t v75 = v114;
              *uint64_t v114 = v112;
              uint64_t v76 = v108;
              *(uint64_t **)((char *)v75 + *(int *)(v108 + 32)) = (uint64_t *)v104;
              char v112 = (uint64_t *)((char *)v75 + *(int *)(v76 + 24));
              outlined init with copy of MLTrainingSessionParameters(v72, (uint64_t)v112, type metadata accessor for MLImageClassifier.FeatureExtractorType);
              *(uint64_t **)((char *)v75 + *(int *)(v76 + 36)) = (uint64_t *)v42;
              specialized Dictionary.subscript.getter(0x6966697373616C63, 0xEF657079745F7265, v116);
              if (v125)
              {
                if (swift_dynamicCast(&v123, v124, v115, v109, 6))
                {
                  MLImageClassifier.ModelParameters.ClassifierType.init(dictionary:)(v123);
                  uint64_t v77 = (uint64_t *)v124[0];
                  if (v124[0] != (char *)&dword_0 + 2)
                  {
LABEL_41:
                    int64_t v78 = v114;
                    uint64_t v79 = v105;
                    outlined consume of MLImageClassifier.ModelParameters.ClassifierType?(*(uint64_t *)((char *)v114 + v105));
                    *(uint64_t **)((char *)v78 + v79) = v77;
                    URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEE00617461446E6FLL);
                    char v80 = v116;
                    specialized Dictionary.subscript.getter(0x69746164696C6176, 0xEA00000000006E6FLL, v116);
                    swift_bridgeObjectRelease(v80);
                    if (v125)
                    {
                      char v81 = swift_dynamicCast(&v123, v124, v115, v109, 6);
                      uint64_t v82 = v118;
                      if (v81)
                      {
                        uint64_t v83 = v123;
                        uint64_t v84 = (uint64_t)v102;
                        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v107 + 16))(v102, v111, v117);
                        uint64_t v85 = v83;
                        uint64_t v86 = (uint64_t)v101;
                        MLImageClassifier.ModelParameters.ValidationData.init(dictionary:tableFile:)(v85, v84);
                        if (__swift_getEnumTagSinglePayload(v86, 1, v106) != 1)
                        {
                          outlined consume of Data._Representation(v120, v119);
                          uint64_t v96 = v117;
                          v82(v122, v117);
                          v82(v111, v96);
                          outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v113, type metadata accessor for MLImageClassifier.FeatureExtractorType);
                          __swift_destroy_boxed_opaque_existential_1Tm(v126);
                          uint64_t v97 = v86;
                          uint64_t v98 = (uint64_t)v103;
                          outlined init with take of MLClassifierMetrics(v97, (uint64_t)v103, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
                          outlined init with take of MLClassifierMetrics(v98, (uint64_t)v114 + *(int *)(v108 + 20), type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
                          return __stack_chk_guard;
                        }
                        _s11TabularData9AnyColumnVSgWOhTm_1(v86, &demangling cache variable for type metadata for MLImageClassifier.ModelParameters.ValidationData?);
                        uint64_t v87 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
                        swift_allocError(&type metadata for MLCreateError, v87, 0, 0);
                        *(void *)uint64_t v88 = 0xD000000000000037;
                        *(void *)(v88 + 8) = "ion Classification algorithm." + 0x8000000000000000;
                        *(_OWORD *)(v88 + 16) = 0;
                        *(_OWORD *)(v88 + 32) = 0;
                        *(unsigned char *)(v88 + 48) = 0;
                        swift_willThrow(&type metadata for MLCreateError, v87, v88, v89, v90, v91);
                        outlined consume of Data._Representation(v120, v119);
                        uint64_t v92 = v117;
                        v82(v122, v117);
                        v82(v111, v92);
                        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v113, type metadata accessor for MLImageClassifier.FeatureExtractorType);
                        __swift_destroy_boxed_opaque_existential_1Tm(v126);
                        swift_bridgeObjectRelease(*v114);
                        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v112, type metadata accessor for MLImageClassifier.FeatureExtractorType);
                        goto LABEL_26;
                      }
                      outlined consume of Data._Representation(v120, v119);
                      uint64_t v93 = v122;
                    }
                    else
                    {
                      outlined consume of Data._Representation(v120, v119);
                      _s11TabularData9AnyColumnVSgWOhTm_1((uint64_t)v124, &demangling cache variable for type metadata for Any?);
                      uint64_t v93 = v122;
                      uint64_t v82 = v118;
                    }
                    uint64_t v94 = (uint64_t)v113;
                    uint64_t v95 = v117;
                    v82(v93, v117);
                    v82(v111, v95);
                    outlined destroy of MLActivityClassifier.ModelParameters(v94, type metadata accessor for MLImageClassifier.FeatureExtractorType);
                    __swift_destroy_boxed_opaque_existential_1Tm(v126);
                    swift_storeEnumTagMultiPayload((char *)v114 + *(int *)(v108 + 20), v106, 3);
                    return __stack_chk_guard;
                  }
                }
              }
              else
              {
                _s11TabularData9AnyColumnVSgWOhTm_1((uint64_t)v124, &demangling cache variable for type metadata for Any?);
              }
              uint64_t v77 = 0;
              goto LABEL_41;
            }
            swift_bridgeObjectRelease(v121);
            char v71 = v44;
          }
          else
          {
            char v70 = v40;
            uint64_t v43 = v38;
            swift_bridgeObjectRelease(v121);
            char v71 = v70;
          }
          swift_bridgeObjectRelease(v71);
          _s11TabularData9AnyColumnVSgWOhTm_1((uint64_t)v124, &demangling cache variable for type metadata for Any?);
          goto LABEL_32;
        }
        char v63 = v40;
        uint64_t v43 = v38;
        swift_bridgeObjectRelease(v121);
        char v61 = v63;
        goto LABEL_22;
      }
      char v62 = v40;
      uint64_t v43 = v38;
      swift_bridgeObjectRelease(v121);
      char v60 = v62;
    }
    else
    {
      char v60 = v40;
      uint64_t v43 = v38;
    }
    swift_bridgeObjectRelease(v60);
    _s11TabularData9AnyColumnVSgWOhTm_1((uint64_t)v124, &demangling cache variable for type metadata for Any?);
LABEL_23:
    uint64_t v46 = v122;
    goto LABEL_24;
  }
  uint64_t v28 = *(void (**)(void, void))(v107 + 8);
  uint64_t v29 = v117;
  v28(v122, v117);
  v28(&v99, v29);
LABEL_26:
  outlined consume of MLImageClassifier.ModelParameters.ClassifierType?(*(uint64_t *)((char *)v114 + v105));
  return __stack_chk_guard;
}

uint64_t MLImageClassifier.FeatureExtractorType.init(dictionary:)(uint64_t a1)
{
  uint64_t v3 = v1;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  char v60 = &v47;
  uint64_t v53 = type metadata accessor for URL(0);
  uint64_t v7 = *(void *)(v53 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  uint64_t v54 = &v47;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v49 = &v47;
  uint64_t v61 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  int64_t v13 = *(void *)(*(void *)(v61 - 8) + 64);
  uint64_t v14 = alloca(v13);
  long long v15 = alloca(v13);
  uint64_t v48 = &v47;
  int64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v18 = alloca(v13);
  uint64_t v19 = alloca(v13);
  if (!*(void *)(a1 + 16)) {
    goto LABEL_26;
  }
  unint64_t v20 = specialized __RawDictionaryStorage.find<A>(_:)(1684957547, 0xE400000000000000);
  if ((v21 & 1) == 0) {
    goto LABEL_26;
  }
  uint64_t v55 = &v47;
  uint64_t v50 = &v47;
  outlined init with copy of Any(*(void *)(a1 + 56) + 32 * v20, (uint64_t)v51);
  if (swift_dynamicCast(&v57, v51, (char *)&type metadata for Any + 8, &type metadata for String, 6))
  {
    uint64_t v56 = (char *)&type metadata for Any + 8;
    uint64_t v59 = v3;
    uint64_t v22 = v57;
    uint64_t v23 = v58;
    if (v57 == 0x697270656E656373 && v58 == 0xEA0000000000746ELL)
    {
      char v24 = 110;
LABEL_10:
      swift_bridgeObjectRelease(v24);
      uint64_t v3 = v59;
      unint64_t v27 = v56;
      uint64_t v28 = v55;
      specialized Dictionary.subscript.getter(0x6E6F697369766572, 0xE800000000000000, a1);
      swift_bridgeObjectRelease(a1);
      if (v52)
      {
        char v29 = swift_dynamicCast(&v57, v51, v27, &type metadata for Int, 6);
        if (v29) {
          uint64_t v30 = v57;
        }
        else {
          uint64_t v30 = 0;
        }
        uint64_t v26 = v61;
        char v31 = v29 ^ 1;
      }
      else
      {
        _s11TabularData9AnyColumnVSgWOhTm_1((uint64_t)v51, &demangling cache variable for type metadata for Any?);
        char v31 = 1;
        uint64_t v30 = 0;
        uint64_t v26 = v61;
      }
      *uint64_t v28 = v30;
      *((unsigned char *)v28 + 8) = v31;
      swift_storeEnumTagMultiPayload(v28, v26, 0);
      goto LABEL_20;
    }
    if (_stringCompareWithSmolCheck(_:_:expecting:)(0x697270656E656373, 0xEA0000000000746ELL, v57, v58, 0))
    {
      char v24 = v23;
      goto LABEL_10;
    }
    if (v22 == 0x6D6F74737563 && v23 == 0xE600000000000000)
    {
      swift_bridgeObjectRelease(0);
      uint64_t v3 = v59;
      uint64_t v32 = (uint64_t)v60;
    }
    else
    {
      char v35 = _stringCompareWithSmolCheck(_:_:expecting:)(0x6D6F74737563, 0xE600000000000000, v22, v23, 0);
      swift_bridgeObjectRelease(v23);
      BOOL v36 = (v35 & 1) == 0;
      uint64_t v3 = v59;
      uint64_t v32 = (uint64_t)v60;
      if (v36) {
        goto LABEL_26;
      }
    }
    specialized Dictionary.subscript.getter(0x61705F6C65646F6DLL, 0xEA00000000006874, a1);
    if (!v52)
    {
      swift_bridgeObjectRelease(a1);
      _s11TabularData9AnyColumnVSgWOhTm_1((uint64_t)v51, &demangling cache variable for type metadata for Any?);
      goto LABEL_27;
    }
    if (swift_dynamicCast(&v57, v51, v56, &type metadata for String, 6))
    {
      char v37 = v58;
      URL.init(string:)(v57, v58);
      swift_bridgeObjectRelease(v37);
      unsigned int v25 = 1;
      uint64_t v38 = v32;
      uint64_t v39 = v53;
      if (__swift_getEnumTagSinglePayload(v38, 1, v53) != 1)
      {
        uint64_t v41 = v49;
        uint64_t v42 = (uint64_t)v60;
        char v60 = *(uint64_t **)(v7 + 32);
        ((void (*)(uint64_t *, uint64_t, uint64_t))v60)(v49, v42, v39);
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v7 + 16))(v54, v41, v39);
        specialized Dictionary.subscript.getter(0x74757074756FLL, 0xE600000000000000, a1);
        swift_bridgeObjectRelease(a1);
        (*(void (**)(uint64_t *, uint64_t))(v7 + 8))(v41, v39);
        if (v52)
        {
          char v43 = swift_dynamicCast(&v57, v51, v56, &type metadata for String, 6);
          uint64_t v26 = v61;
          if (v43)
          {
            uint64_t v44 = v57;
            uint64_t v45 = v58;
          }
          else
          {
            uint64_t v44 = 0;
            uint64_t v45 = 0;
          }
        }
        else
        {
          _s11TabularData9AnyColumnVSgWOhTm_1((uint64_t)v51, &demangling cache variable for type metadata for Any?);
          uint64_t v44 = 0;
          uint64_t v45 = 0;
          uint64_t v26 = v61;
        }
        uint64_t v46 = *(int *)(type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0) + 20);
        uint64_t v28 = v48;
        ((void (*)(uint64_t *, uint64_t *, uint64_t))v60)(v48, v54, v53);
        *(uint64_t *)((char *)v28 + v46) = v44;
        *(uint64_t *)((char *)v28 + v46 + 8) = v45;
        swift_storeEnumTagMultiPayload(v28, v26, 1);
        uint64_t v3 = v59;
LABEL_20:
        uint64_t v33 = (uint64_t)v28;
        uint64_t v34 = (uint64_t)v50;
        outlined init with take of MLClassifierMetrics(v33, (uint64_t)v50, type metadata accessor for MLImageClassifier.FeatureExtractorType);
        outlined init with take of MLClassifierMetrics(v34, v3, type metadata accessor for MLImageClassifier.FeatureExtractorType);
        unsigned int v25 = 0;
        return __swift_storeEnumTagSinglePayload(v3, v25, 1, v26);
      }
      swift_bridgeObjectRelease(a1);
      _s11TabularData9AnyColumnVSgWOhTm_1((uint64_t)v60, &demangling cache variable for type metadata for URL?);
LABEL_28:
      uint64_t v26 = v61;
      return __swift_storeEnumTagSinglePayload(v3, v25, 1, v26);
    }
LABEL_26:
    swift_bridgeObjectRelease(a1);
LABEL_27:
    unsigned int v25 = 1;
    goto LABEL_28;
  }
  swift_bridgeObjectRelease(a1);
  unsigned int v25 = 1;
  uint64_t v26 = v61;
  return __swift_storeEnumTagSinglePayload(v3, v25, 1, v26);
}

uint64_t MLImageClassifier.ModelParameters.ClassifierType.init(dictionary:)(uint64_t a1)
{
  uint64_t v3 = v1;
  if (!*(void *)(a1 + 16)) {
    goto LABEL_16;
  }
  unint64_t v4 = specialized __RawDictionaryStorage.find<A>(_:)(1684957547, 0xE400000000000000);
  if ((v5 & 1) == 0) {
    goto LABEL_16;
  }
  outlined init with copy of Any(*(void *)(a1 + 56) + 32 * v4, (uint64_t)v13);
  if (!swift_dynamicCast(&v15, v13, (char *)&type metadata for Any + 8, &type metadata for String, 6))goto LABEL_16; {
  uint64_t v6 = v15;
  }
  if (v15 == 0xD000000000000011)
  {
    uint64_t v7 = "multilayerPerceptron" + 0x8000000000000000;
    if (v16 == "multilayerPerceptron" + 0x8000000000000000) {
      goto LABEL_8;
    }
  }
  uint64_t v17 = v16;
  if ((_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000011, "multilayerPerceptron" + 0x8000000000000000, v15, v16, 0) & 1) == 0)
  {
    {
      goto LABEL_13;
    }
    uint64_t v9 = v6;
    char v10 = (char)v17;
    swift_bridgeObjectRelease(v10);
    if (v11)
    {
LABEL_13:
      specialized Dictionary.subscript.getter(0x7A6953726579616CLL, 0xEA00000000007365, a1);
      swift_bridgeObjectRelease(a1);
      if (v14)
      {
        uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int]);
        if (swift_dynamicCast(&v15, v13, (char *)&type metadata for Any + 8, v12, 6))
        {
          uint64_t result = v15;
          goto LABEL_18;
        }
      }
      else
      {
        _s11TabularData9AnyColumnVSgWOhTm_1((uint64_t)v13, &demangling cache variable for type metadata for Any?);
      }
LABEL_17:
      uint64_t result = 2;
      goto LABEL_18;
    }
LABEL_16:
    swift_bridgeObjectRelease(a1);
    goto LABEL_17;
  }
  LOBYTE(v7) = (_BYTE)v17;
LABEL_8:
  swift_bridgeObjectRelease((_BYTE)v7);
  swift_bridgeObjectRelease(a1);
  uint64_t result = 0;
LABEL_18:
  uint64_t *v3 = result;
  return result;
}

uint64_t MLImageClassifier.ModelParameters.ValidationData.init(dictionary:tableFile:)(uint64_t a1, uint64_t a2)
{
  uint64_t v54 = a2;
  uint64_t v4 = v2;
  uint64_t v5 = type metadata accessor for URL(0);
  uint64_t v6 = *(void *)(v5 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v41 = &v40;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.DataSource?)
                              - 8)
                  + 64);
  char v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v40 = (uint64_t)&v40;
  uint64_t v13 = type metadata accessor for MLImageClassifier.DataSource(0);
  int64_t v14 = *(void *)(*(void *)(v13 - 8) + 64);
  uint64_t v15 = alloca(v14);
  int64_t v16 = alloca(v14);
  uint64_t v42 = &v40;
  uint64_t v55 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  int64_t v17 = *(void *)(*(void *)(v55 - 8) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v50 = &v40;
  if (!*(void *)(a1 + 16)) {
    goto LABEL_10;
  }
  unint64_t v20 = specialized __RawDictionaryStorage.find<A>(_:)(1684957547, 0xE400000000000000);
  if ((v21 & 1) == 0) {
    goto LABEL_10;
  }
  uint64_t v53 = v4;
  outlined init with copy of Any(*(void *)(a1 + 56) + 32 * v20, (uint64_t)&v44);
  uint64_t v51 = (uint64_t)&type metadata for Any + 8;
  if (!swift_dynamicCast(&v48, &v44, (char *)&type metadata for Any + 8, &type metadata for String, 6))
  {
    uint64_t v4 = v53;
    goto LABEL_10;
  }
  uint64_t v52 = v6;
  uint64_t v22 = v48;
  uint64_t v23 = v49;
  if ((v48 != 1701736302 || v49 != 0xE400000000000000)
    && (_stringCompareWithSmolCheck(_:_:expecting:)(1701736302, 0xE400000000000000, v48, v49, 0) & 1) == 0)
  {
    if (v22 == 0x756F735F61746164 && v23 == 0xEB00000000656372)
    {
      char v29 = 114;
LABEL_18:
      swift_bridgeObjectRelease(v29);
      uint64_t v6 = v52;
      specialized Dictionary.subscript.getter(1635017060, 0xE400000000000000, a1);
      swift_bridgeObjectRelease(a1);
      if (v47)
      {
        uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any]);
        if (swift_dynamicCast(&v48, &v44, v51, v30, 6))
        {
          uint64_t v51 = v48;
          uint64_t v31 = (uint64_t)v41;
          (*(void (**)(uint64_t *, uint64_t, uint64_t))(v6 + 16))(v41, v54, v5);
          uint64_t v32 = v40;
          MLImageClassifier.DataSource.init(dictionary:tableFile:)(v51, v31);
          (*(void (**)(uint64_t, uint64_t))(v6 + 8))(v54, v5);
          uint64_t v33 = v32;
          unsigned int v24 = 1;
          if (__swift_getEnumTagSinglePayload(v33, 1, v13) != 1)
          {
            uint64_t v37 = v33;
            uint64_t v38 = (uint64_t)v42;
            outlined init with take of MLClassifierMetrics(v37, (uint64_t)v42, type metadata accessor for MLImageClassifier.DataSource);
            uint64_t v39 = v38;
            uint64_t v26 = (uint64_t)v50;
            outlined init with take of MLClassifierMetrics(v39, (uint64_t)v50, type metadata accessor for MLImageClassifier.DataSource);
            uint64_t v25 = v55;
            goto LABEL_8;
          }
          _s11TabularData9AnyColumnVSgWOhTm_1(v33, &demangling cache variable for type metadata for MLImageClassifier.DataSource?);
          uint64_t v27 = 1;
          uint64_t v4 = v53;
LABEL_11:
          uint64_t v25 = v55;
          return __swift_storeEnumTagSinglePayload(v4, v27, 1, v25);
        }
      }
      else
      {
        _s11TabularData9AnyColumnVSgWOhTm_1((uint64_t)&v44, &demangling cache variable for type metadata for Any?);
      }
      uint64_t v4 = v53;
      goto LABEL_24;
    }
    uint64_t v43 = v22;
    if (_stringCompareWithSmolCheck(_:_:expecting:)(0x756F735F61746164, 0xEB00000000656372, v22, v23, 0))
    {
      char v29 = v23;
      goto LABEL_18;
    }
    if (v43 == 0x74696C7073 && v23 == 0xE500000000000000)
    {
      swift_bridgeObjectRelease(0);
      uint64_t v4 = v53;
      uint64_t v6 = v52;
      goto LABEL_30;
    }
    char v34 = _stringCompareWithSmolCheck(_:_:expecting:)(0x74696C7073, 0xE500000000000000, v43, v23, 0);
    swift_bridgeObjectRelease(v23);
    uint64_t v4 = v53;
    uint64_t v6 = v52;
    if (v34)
    {
LABEL_30:
      specialized Dictionary.subscript.getter(1635017060, 0xE400000000000000, a1);
      swift_bridgeObjectRelease(a1);
      if (v47)
      {
        uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any]);
        if (swift_dynamicCast(&v48, &v44, v51, v35, 6))
        {
          MLSplitStrategy.init(dictionary:)(v48);
          (*(void (**)(uint64_t, uint64_t))(v6 + 8))(v54, v5);
          uint64_t v25 = v55;
          if (!v46)
          {
            __int16 v36 = v45;
            uint64_t v26 = (uint64_t)v50;
            *(_OWORD *)uint64_t v50 = v44;
            *(unsigned char *)(v26 + 16) = v36;
            *(unsigned char *)(v26 + 17) = HIBYTE(v36) & 1;
            unsigned int v24 = 0;
            goto LABEL_8;
          }
LABEL_25:
          uint64_t v27 = 1;
          return __swift_storeEnumTagSinglePayload(v4, v27, 1, v25);
        }
      }
      else
      {
        _s11TabularData9AnyColumnVSgWOhTm_1((uint64_t)&v44, &demangling cache variable for type metadata for Any?);
      }
LABEL_24:
      uint64_t v25 = v55;
      (*(void (**)(uint64_t, uint64_t))(v6 + 8))(v54, v5);
      goto LABEL_25;
    }
LABEL_10:
    (*(void (**)(uint64_t, uint64_t))(v6 + 8))(v54, v5);
    swift_bridgeObjectRelease(a1);
    uint64_t v27 = 1;
    goto LABEL_11;
  }
  (*(void (**)(uint64_t, uint64_t))(v52 + 8))(v54, v5);
  swift_bridgeObjectRelease(a1);
  swift_bridgeObjectRelease(v23);
  unsigned int v24 = 3;
  uint64_t v25 = v55;
  uint64_t v26 = (uint64_t)v50;
LABEL_8:
  swift_storeEnumTagMultiPayload(v26, v25, v24);
  uint64_t v4 = v53;
  outlined init with take of MLClassifierMetrics(v26, v53, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  uint64_t v27 = 0;
  return __swift_storeEnumTagSinglePayload(v4, v27, 1, v25);
}

NSURL *MLImageClassifier.PersistentParameters.save(toSessionDirectory:)(uint64_t a1)
{
  uint64_t v37 = a1;
  uint64_t v42 = type metadata accessor for URL(0);
  uint64_t v41 = *(void *)(v42 - 8);
  int64_t v3 = *(void *)(v41 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  __int16 v36 = &v35;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
  uint64_t inited = swift_initStackObject(v6, v45);
  *(void *)(inited + 16) = 5;
  *(void *)(inited + 24) = 10;
  *(void *)(inited + 32) = 0x73656C6966;
  *(void *)(inited + 40) = 0xE500000000000000;
  uint64_t v8 = *v2;
  uint64_t v40 = v2;
  uint64_t v9 = specialized _NativeDictionary.mapValues<A>(_:)(v8);
  uint64_t v38 = v1;
  *(void *)(inited + 72) = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : [String]]);
  *(void *)(inited + 48) = v9;
  *(void *)(inited + 80) = 0x69746164696C6176;
  *(void *)(inited + 88) = 0xEA00000000006E6FLL;
  uint64_t v35 = type metadata accessor for MLImageClassifier.PersistentParameters(0);
  uint64_t v10 = MLImageClassifier.ModelParameters.ValidationData.dictionary.getter();
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any]);
  *(void *)(inited + 120) = v11;
  *(void *)(inited + 96) = v10;
  *(void *)(inited + 128) = 0xD000000000000011;
  *(void *)(inited + 136) = "logistic_regressor" + 0x8000000000000000;
  uint64_t v12 = (int *)v35;
  uint64_t v13 = MLImageClassifier.FeatureExtractorType.dictionary.getter();
  uint64_t v39 = (void *)v11;
  *(void *)(inited + 168) = v11;
  *(void *)(inited + 144) = v13;
  strcpy((char *)(inited + 176), "max_iterations");
  *(unsigned char *)(inited + 191) = -18;
  int64_t v14 = v40;
  uint64_t v15 = *(uint64_t *)((char *)v40 + v12[8]);
  *(void *)(inited + 216) = &type metadata for Int;
  *(void *)(inited + 192) = v15;
  *(void *)(inited + 224) = 0xD000000000000014;
  *(void *)(inited + 232) = "Empty training input." + 0x8000000000000000;
  uint64_t v16 = *(uint64_t *)((char *)v14 + v12[9]);
  int64_t v17 = v14;
  *(void *)(inited + 264) = &type metadata for Int;
  *(void *)(inited + 240) = v16;
  uint64_t v18 = Dictionary.init(dictionaryLiteral:)(inited, &type metadata for String, (char *)&type metadata for Any + 8, &protocol witness table for String);
  uint64_t v43 = v18;
  if (*(uint64_t *)((char *)v17 + v12[7]) != 2)
  {
    v44[0] = *(id *)((char *)v17 + v12[7]);
    uint64_t v19 = MLImageClassifier.ModelParameters.ClassifierType.dictionary.getter();
    v44[3] = v39;
    v44[0] = v19;
    specialized Dictionary.subscript.setter((uint64_t)v44, 0x6966697373616C63, 0xEF657079745F7265);
    LOBYTE(v18) = v43;
  }
  unint64_t v20 = objc_opt_self(NSPropertyListSerialization);
  Class isa = Dictionary._bridgeToObjectiveC()().super.isa;
  swift_bridgeObjectRelease(v18);
  v44[0] = 0;
  id v22 = [v20 dataWithPropertyList:isa format:200 options:0 error:v44];
  id v23 = v22;

  id v24 = v44[0];
  if (v23)
  {
    uint64_t v25 = static Data._unconditionallyBridgeFromObjectiveC(_:)(v23);
    unint64_t v27 = v26;

    uint64_t v28 = v36;
    URL.appendingPathComponent(_:)(0xD000000000000010, "ObjectDetectorMetrics." + 0x8000000000000000);
    Data.write(to:options:)(v28, 0, v25, v27);
    (*(void (**)(uint64_t *, uint64_t))(v41 + 8))(v28, v42);
    outlined consume of Data._Representation(v25, v27);
  }
  else
  {
    char v29 = v24;
    _convertNSErrorToError(_:)(v24);

    swift_willThrow(v29, "dataWithPropertyList:format:options:error:", v30, v31, v32, v33);
  }
  return __stack_chk_guard;
}

uint64_t MLImageClassifier.ModelParameters.ValidationData.dictionary.getter()
{
  uint64_t v1 = type metadata accessor for MLSoundClassifier.DataSource(0);
  int64_t v2 = *(void *)(*(void *)(v1 - 8) + 64);
  int64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  *(void *)&long long v41 = &v32;
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for MLImageClassifier.DataSource(0) - 8) + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v8 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  int64_t v9 = *(void *)(*(void *)(v8 - 8) + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  outlined init with copy of MLTrainingSessionParameters(v0, (uint64_t)&v32, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  switch(swift_getEnumCaseMultiPayload(&v32, v8))
  {
    case 0u:
      char v12 = v33;
      char v13 = v34;
      uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
      long long v41 = v32;
      uint64_t inited = (void *)swift_initStackObject(v14, &v32);
      inited[2] = 2;
      inited[3] = 4;
      inited[4] = 1684957547;
      inited[5] = 0xE400000000000000;
      inited[9] = &type metadata for String;
      inited[6] = 0x74696C7073;
      inited[7] = 0xE500000000000000;
      inited[10] = 1635017060;
      inited[11] = 0xE400000000000000;
      long long v38 = v41;
      char v39 = v12;
      char v40 = v13;
      uint64_t v16 = MLSplitStrategy.dictionary.getter();
      inited[15] = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any]);
      inited[12] = v16;
      int64_t v17 = (char *)&type metadata for Any + 8;
      uint64_t v18 = inited;
      goto LABEL_5;
    case 1u:
      outlined init with take of MLClassifierMetrics((uint64_t)&v32, (uint64_t)&v32, type metadata accessor for MLImageClassifier.DataSource);
      uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
      char v29 = (void *)swift_initStackObject(v28, v36);
      v29[2] = 2;
      v29[3] = 4;
      v29[4] = 1684957547;
      v29[5] = 0xE400000000000000;
      v29[9] = &type metadata for String;
      v29[6] = 0x756F735F61746164;
      v29[7] = 0xEB00000000656372;
      v29[10] = 1635017060;
      v29[11] = 0xE400000000000000;
      uint64_t v30 = MLImageClassifier.DataSource.dictionary.getter();
      v29[15] = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any]);
      v29[12] = v30;
      uint64_t v23 = Dictionary.init(dictionaryLiteral:)(v29, &type metadata for String, (char *)&type metadata for Any + 8, &protocol witness table for String);
      uint64_t v25 = &v32;
      id v24 = type metadata accessor for MLImageClassifier.DataSource;
      goto LABEL_7;
    case 2u:
      uint64_t v19 = (long long *)v41;
      *(void *)long long v41 = v32;
      swift_storeEnumTagMultiPayload(v19, v1, 2);
      uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
      char v21 = (void *)swift_initStackObject(v20, v35);
      Swift::Int v21[2] = 2;
      v21[3] = 4;
      v21[4] = 1684957547;
      v21[5] = 0xE400000000000000;
      v21[9] = &type metadata for String;
      uint64_t v21[6] = 0x756F735F61746164;
      v21[7] = 0xEB00000000656372;
      v21[10] = 1635017060;
      v21[11] = 0xE400000000000000;
      uint64_t v22 = MLSoundClassifier.DataSource.dictionary.getter();
      v21[15] = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any]);
      v21[12] = v22;
      uint64_t v23 = Dictionary.init(dictionaryLiteral:)(v21, &type metadata for String, (char *)&type metadata for Any + 8, &protocol witness table for String);
      id v24 = type metadata accessor for MLSoundClassifier.DataSource;
      uint64_t v25 = v19;
LABEL_7:
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v25, v24);
      break;
    case 3u:
      uint64_t v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
      unint64_t v27 = (void *)swift_initStackObject(v26, v37);
      v27[2] = 1;
      v27[3] = 2;
      v27[4] = 1684957547;
      v27[5] = 0xE400000000000000;
      v27[9] = &type metadata for String;
      v27[6] = 1701736302;
      v27[7] = 0xE400000000000000;
      int64_t v17 = (char *)&type metadata for Any + 8;
      uint64_t v18 = v27;
LABEL_5:
      uint64_t v23 = Dictionary.init(dictionaryLiteral:)(v18, &type metadata for String, v17, &protocol witness table for String);
      break;
  }
  return v23;
}

void *MLImageClassifier.FeatureExtractorType.dictionary.getter()
{
  uint64_t v20 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
  int64_t v1 = *(void *)(*(void *)(v20 - 8) + 64);
  int64_t v2 = alloca(v1);
  int64_t v3 = alloca(v1);
  uint64_t v4 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  int64_t v5 = *(void *)(*(void *)(v4 - 8) + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  char v21 = _swiftEmptyDictionarySingleton;
  outlined init with copy of MLTrainingSessionParameters(v0, (uint64_t)&v16, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  if (swift_getEnumCaseMultiPayload(&v16, v4) == 1)
  {
    outlined init with take of MLClassifierMetrics((uint64_t)&v16, (uint64_t)&v16, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
    uint64_t v19 = &type metadata for String;
    uint64_t v17 = 0x6D6F74737563;
    unint64_t v18 = 0xE600000000000000;
    specialized Dictionary.subscript.setter((uint64_t)&v17, 1684957547, 0xE400000000000000);
    uint64_t v8 = type metadata accessor for URL(0);
    uint64_t v19 = (void *)v8;
    int64_t v9 = __swift_allocate_boxed_opaque_existential_1(&v17);
    (*(void (**)(void *, uint64_t *, uint64_t))(*(void *)(v8 - 8) + 16))(v9, &v16, v8);
    specialized Dictionary.subscript.setter((uint64_t)&v17, 0x61705F6C65646F6DLL, 0xEA00000000006874);
    uint64_t v10 = *(int *)(v20 + 20);
    unint64_t v11 = *(uint64_t *)((char *)&v16 + v10 + 8);
    if (v11)
    {
      uint64_t v12 = *(uint64_t *)((char *)&v16 + v10);
      uint64_t v19 = &type metadata for String;
      uint64_t v17 = v12;
      unint64_t v18 = v11;
      swift_bridgeObjectRetain(v11);
      specialized Dictionary.subscript.setter((uint64_t)&v17, 0x74757074756FLL, 0xE600000000000000);
    }
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v16, type metadata accessor for MLImageClassifier.CustomFeatureExtractor);
  }
  else
  {
    uint64_t v13 = v16;
    char v14 = v17;
    uint64_t v19 = &type metadata for String;
    uint64_t v17 = 0x697270656E656373;
    unint64_t v18 = 0xEA0000000000746ELL;
    specialized Dictionary.subscript.setter((uint64_t)&v17, 1684957547, 0xE400000000000000);
    if (!v14)
    {
      uint64_t v19 = &type metadata for Int;
      uint64_t v17 = v13;
      specialized Dictionary.subscript.setter((uint64_t)&v17, 0x6E6F697369766572, 0xE800000000000000);
    }
  }
  return v21;
}

void *MLImageClassifier.ModelParameters.ClassifierType.dictionary.getter()
{
  unint64_t v1 = *v0;
  uint64_t v8 = _swiftEmptyDictionarySingleton;
  int64_t v7 = &type metadata for String;
  if (v1)
  {
    unint64_t v5 = 0xD000000000000014;
    swift_bridgeObjectRetain(v1);
    specialized Dictionary.subscript.setter((uint64_t)&v5, 1684957547, 0xE400000000000000);
    int64_t v7 = (void *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int]);
    unint64_t v5 = v1;
    uint64_t v2 = 0x7A6953726579616CLL;
    uint64_t v3 = 0xEA00000000007365;
  }
  else
  {
    unint64_t v5 = 0xD000000000000011;
    uint64_t v6 = "multilayerPerceptron" + 0x8000000000000000;
    uint64_t v2 = 1684957547;
    uint64_t v3 = 0xE400000000000000;
  }
  specialized Dictionary.subscript.setter((uint64_t)&v5, v2, v3);
  return v8;
}

uint64_t MLImageClassifier.DataSource.dictionary.getter()
{
  uint64_t v1 = v0;
  uint64_t v27 = type metadata accessor for URL(0);
  uint64_t v2 = *(void *)(v27 - 8);
  int64_t v3 = *(void *)(v2 + 64);
  uint64_t v4 = alloca(v3);
  unint64_t v5 = alloca(v3);
  uint64_t v6 = type metadata accessor for MLImageClassifier.DataSource(0);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  uint64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  outlined init with copy of MLTrainingSessionParameters(v1, (uint64_t)&v23, type metadata accessor for MLImageClassifier.DataSource);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v23, v6);
  if (EnumCaseMultiPayload)
  {
    if (EnumCaseMultiPayload != 1)
    {
      uint64_t v18 = v23;
      uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
      uint64_t inited = swift_initStackObject(v19, v24);
      *(void *)(inited + 16) = 2;
      *(void *)(inited + 24) = 4;
      *(void *)(inited + 32) = 1684957547;
      *(void *)(inited + 40) = 0xE400000000000000;
      *(void *)(inited + 72) = &type metadata for String;
      strcpy((char *)(inited + 48), "files_by_label");
      *(unsigned char *)(inited + 63) = -18;
      *(void *)(inited + 80) = 0x73656C6966;
      *(void *)(inited + 88) = 0xE500000000000000;
      char v21 = specialized _NativeDictionary.mapValues<A>(_:)(v18);
      swift_bridgeObjectRelease(v18);
      *(void *)(inited + 120) = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : [String]]);
      *(void *)(inited + 96) = v21;
      return Dictionary.init(dictionaryLiteral:)(inited, &type metadata for String, (char *)&type metadata for Any + 8, &protocol witness table for String);
    }
    uint64_t v11 = v27;
    uint64_t v28 = v2;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v2 + 32))(&v23, &v23, v27);
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
    uint64_t v13 = (void *)swift_initStackObject(v12, v25);
    v13[2] = 2;
    void v13[3] = 4;
    v13[4] = 1684957547;
    v13[5] = 0xE400000000000000;
    v13[9] = &type metadata for String;
    v13[6] = 0x5F64656C6562616CLL;
    char v14 = (char *)0xED000073656C6966;
  }
  else
  {
    uint64_t v11 = v27;
    uint64_t v28 = v2;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v2 + 32))(&v23, &v23, v27);
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
    uint64_t v13 = (void *)swift_initStackObject(v12, v26);
    v13[2] = 2;
    void v13[3] = 4;
    v13[4] = 1684957547;
    v13[5] = 0xE400000000000000;
    v13[9] = &type metadata for String;
    v13[6] = 0xD000000000000013;
    char v14 = "session_id_column" + 0x8000000000000000;
  }
  void v13[7] = v14;
  v13[10] = 1752457584;
  v13[11] = 0xE400000000000000;
  uint64_t v15 = URL.path.getter(v12);
  v13[15] = &type metadata for String;
  v13[12] = v15;
  v13[13] = v16;
  uint64_t v17 = Dictionary.init(dictionaryLiteral:)(v13, &type metadata for String, (char *)&type metadata for Any + 8, &protocol witness table for String);
  (*(void (**)(uint64_t *, uint64_t))(v28 + 8))(&v23, v11);
  return v17;
}

uint64_t MLImageClassifier.DataSource.init(dictionary:tableFile:)(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = a2;
  uint64_t v5 = v2;
  uint64_t v6 = type metadata accessor for MLImageClassifier.DataSource(0);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  uint64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  uint64_t v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  if (!*(void *)(a1 + 16)
    || (uint64_t v37 = &v36,
        unint64_t v12 = specialized __RawDictionaryStorage.find<A>(_:)(1684957547, 0xE400000000000000),
        (v13 & 1) == 0))
  {
    swift_bridgeObjectRelease(a1);
LABEL_33:
    uint64_t v32 = type metadata accessor for URL(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v32 - 8) + 8))(v3, v32);
LABEL_34:
    uint64_t v31 = 1;
    return __swift_storeEnumTagSinglePayload(v5, v31, 1, v6);
  }
  char v40 = &v36;
  uint64_t v44 = a2;
  outlined init with copy of Any(*(void *)(a1 + 56) + 32 * v12, (uint64_t)v38);
  if (!swift_dynamicCast(&v41, v38, (char *)&type metadata for Any + 8, &type metadata for String, 6))
  {
    swift_bridgeObjectRelease(a1);
LABEL_32:
    uint64_t v3 = v44;
    goto LABEL_33;
  }
  uint64_t v43 = v5;
  uint64_t v14 = v41;
  uint64_t v15 = v42;
  if (v41 == 0xD000000000000013 && v42 == "session_id_column" + 0x8000000000000000)
  {
    unsigned __int8 v16 = "session_id_column";
    goto LABEL_11;
  }
  if ((_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000013, "session_id_column" + 0x8000000000000000, v41, v42, 0) & 1) == 0)
  {
    if (v14 == 0x5F64656C6562616CLL && v15 == (char *)0xED000073656C6966)
    {
      char v21 = 102;
    }
    else
    {
      if ((_stringCompareWithSmolCheck(_:_:expecting:)(0x5F64656C6562616CLL, 0xED000073656C6966, v14, v15, 0) & 1) == 0)
      {
        if (v14 == 0x79625F73656C6966 && v15 == (char *)0xEE006C6562616C5FLL)
        {
          swift_bridgeObjectRelease(95);
          uint64_t v5 = v43;
        }
        else
        {
          char v24 = _stringCompareWithSmolCheck(_:_:expecting:)(0x79625F73656C6966, 0xEE006C6562616C5FLL, v14, v15, 0);
          swift_bridgeObjectRelease((_BYTE)v15);
          uint64_t v5 = v43;
          if ((v24 & 1) == 0)
          {
            uint64_t v34 = type metadata accessor for URL(0);
            (*(void (**)(uint64_t, uint64_t))(*(void *)(v34 - 8) + 8))(v44, v34);
            swift_bridgeObjectRelease(a1);
            goto LABEL_34;
          }
        }
        specialized Dictionary.subscript.getter(0x73656C6966, 0xE500000000000000, a1);
        swift_bridgeObjectRelease(a1);
        if (!v39) {
          goto LABEL_31;
        }
        uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : [String]]);
        if (!swift_dynamicCast(&v41, v38, (char *)&type metadata for Any + 8, v25, 6)) {
          goto LABEL_32;
        }
        char v26 = v41;
        uint64_t v27 = specialized _NativeDictionary.mapValues<A>(_:)(v41);
        swift_bridgeObjectRelease(v26);
        uint64_t v28 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v28 - 8) + 8))(v44, v28);
        uint64_t v18 = v40;
        *char v40 = (uint64_t)v27;
        uint64_t v5 = v43;
        int v35 = 2;
        goto LABEL_29;
      }
      char v21 = (char)v15;
    }
    swift_bridgeObjectRelease(v21);
    specialized Dictionary.subscript.getter(1752457584, 0xE400000000000000, a1);
    swift_bridgeObjectRelease(a1);
    uint64_t v5 = v43;
    if (!v39) {
      goto LABEL_31;
    }
    if (!swift_dynamicCast(&v41, v38, (char *)&type metadata for Any + 8, &type metadata for String, 6))goto LABEL_32; {
    char v22 = (char)v42;
    }
    uint64_t v18 = v40;
    URL.init(fileURLWithPath:)(v41, v42);
    swift_bridgeObjectRelease(v22);
    uint64_t v23 = type metadata accessor for URL(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v23 - 8) + 8))(v44, v23);
    int v35 = 1;
LABEL_29:
    unsigned int v19 = v35;
    goto LABEL_30;
  }
  unsigned __int8 v16 = v15;
LABEL_11:
  swift_bridgeObjectRelease(v16);
  specialized Dictionary.subscript.getter(1752457584, 0xE400000000000000, a1);
  swift_bridgeObjectRelease(a1);
  uint64_t v5 = v43;
  if (!v39)
  {
LABEL_31:
    _s11TabularData9AnyColumnVSgWOhTm_1((uint64_t)v38, &demangling cache variable for type metadata for Any?);
    goto LABEL_32;
  }
  if (!swift_dynamicCast(&v41, v38, (char *)&type metadata for Any + 8, &type metadata for String, 6))goto LABEL_32; {
  char v17 = (char)v42;
  }
  uint64_t v18 = v40;
  URL.init(fileURLWithPath:)(v41, v42);
  swift_bridgeObjectRelease(v17);
  unsigned int v19 = 0;
  uint64_t v20 = type metadata accessor for URL(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v20 - 8) + 8))(v44, v20);
LABEL_30:
  swift_storeEnumTagMultiPayload(v18, v6, v19);
  uint64_t v29 = (uint64_t)v18;
  uint64_t v30 = (uint64_t)v37;
  outlined init with take of MLClassifierMetrics(v29, (uint64_t)v37, type metadata accessor for MLImageClassifier.DataSource);
  outlined init with take of MLClassifierMetrics(v30, v5, type metadata accessor for MLImageClassifier.DataSource);
  uint64_t v31 = 0;
  return __swift_storeEnumTagSinglePayload(v5, v31, 1, v6);
}

uint64_t outlined consume of MLImageClassifier.ModelParameters.ClassifierType?(uint64_t a1)
{
  if (a1 != 2) {
    return swift_bridgeObjectRelease(a1);
  }
  return result;
}

uint64_t outlined destroy of MLImageClassifier.ModelParameters(uint64_t a1)
{
  return a1;
}

uint64_t *initializeBufferWithCopyOfBuffer for MLSupportVectorClassifier.Model(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v16 = *a2;
    uint64_t *v3 = *a2;
    uint64_t v3 = (uint64_t *)(v16 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    *a1 = *a2;
    uint64_t v5 = a2[1];
    v3[1] = v5;
    uint64_t v6 = a2[2];
    v3[2] = v6;
    v3[3] = a2[3];
    uint64_t v7 = a2[4];
    void v3[4] = v7;
    uint64_t v8 = *(int *)(a3 + 24);
    int64_t v9 = (char *)v3 + v8;
    uint64_t v10 = (char *)a2 + v8;
    swift_bridgeObjectRetain(v5);
    swift_bridgeObjectRetain(v6);
    swift_bridgeObjectRetain(v7);
    uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
    if (swift_getEnumCaseMultiPayload(v10, v11) == 1)
    {
      uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 16))(v9, v10, v12);
      uint64_t v13 = 1;
      uint64_t v14 = v9;
      uint64_t v15 = v11;
    }
    else
    {
      uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 16))(v9, v10, v17);
      uint64_t v14 = v9;
      uint64_t v15 = v11;
      uint64_t v13 = 0;
    }
    swift_storeEnumTagMultiPayload(v14, v15, v13);
  }
  return v3;
}

uint64_t destroy for MLSupportVectorClassifier.Model(void *a1, uint64_t a2)
{
  swift_bridgeObjectRelease(a1[1]);
  swift_bridgeObjectRelease(a1[2]);
  swift_bridgeObjectRelease(a1[4]);
  uint64_t v2 = (char *)a1 + *(int *)(a2 + 24);
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
  int v4 = &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>;
  if (swift_getEnumCaseMultiPayload(v2, v3) == 1) {
    int v4 = &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>;
  }
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(v4);
  return (*(uint64_t (**)(char *, uint64_t))(*(void *)(v5 - 8) + 8))(v2, v5);
}

void *initializeWithCopy for MLSupportVectorClassifier.Model(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v4 = a2[1];
  a1[1] = v4;
  uint64_t v5 = a2[2];
  a1[2] = v5;
  a1[3] = a2[3];
  uint64_t v6 = a2[4];
  a1[4] = v6;
  uint64_t v7 = *(int *)(a3 + 24);
  uint64_t v8 = (char *)a1 + v7;
  int64_t v9 = (char *)a2 + v7;
  swift_bridgeObjectRetain(v4);
  swift_bridgeObjectRetain(v5);
  swift_bridgeObjectRetain(v6);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v9, v10);
  BOOL v12 = EnumCaseMultiPayload == 1;
  uint64_t v13 = &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>;
  if (EnumCaseMultiPayload == 1) {
    uint64_t v13 = &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>;
  }
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(v13);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 16))(v8, v9, v14);
  swift_storeEnumTagMultiPayload(v8, v10, v12);
  return a1;
}

void *assignWithCopy for MLSupportVectorClassifier.Model(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v5 = a2[1];
  uint64_t v6 = a1[1];
  a1[1] = v5;
  swift_bridgeObjectRetain(v5);
  swift_bridgeObjectRelease(v6);
  uint64_t v7 = a2[2];
  uint64_t v8 = a1[2];
  a1[2] = v7;
  swift_bridgeObjectRetain(v7);
  swift_bridgeObjectRelease(v8);
  a1[3] = a2[3];
  uint64_t v9 = a2[4];
  uint64_t v10 = a1[4];
  a1[4] = v9;
  swift_bridgeObjectRetain(v9);
  swift_bridgeObjectRelease(v10);
  if (a1 != a2)
  {
    uint64_t v11 = *(int *)(a3 + 24);
    BOOL v12 = (char *)a2 + v11;
    uint64_t v13 = (uint64_t)a1 + v11;
    outlined destroy of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(v13);
    uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v12, v14);
    BOOL v16 = EnumCaseMultiPayload == 1;
    uint64_t v17 = &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>;
    if (EnumCaseMultiPayload == 1) {
      uint64_t v17 = &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>;
    }
    uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(v17);
    (*(void (**)(uint64_t, char *, uint64_t))(*(void *)(v18 - 8) + 16))(v13, v12, v18);
    swift_storeEnumTagMultiPayload(v13, v14, v16);
  }
  return a1;
}

uint64_t outlined destroy of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t initializeWithTake for MLSupportVectorClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = *(_OWORD *)(a2 + 16);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v4 = *(int *)(a3 + 24);
  uint64_t v5 = a1 + v4;
  uint64_t v6 = v4 + a2;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v6, v7);
  BOOL v9 = EnumCaseMultiPayload == 1;
  uint64_t v10 = &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>;
  if (EnumCaseMultiPayload == 1) {
    uint64_t v10 = &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>;
  }
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(v10);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v11 - 8) + 32))(v5, v6, v11);
  swift_storeEnumTagMultiPayload(v5, v7, v9);
  return a1;
}

void *assignWithTake for MLSupportVectorClassifier.Model(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v5 = a1[1];
  a1[1] = a2[1];
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = a1[2];
  a1[2] = a2[2];
  swift_bridgeObjectRelease(v6);
  a1[3] = a2[3];
  uint64_t v7 = a1[4];
  a1[4] = a2[4];
  swift_bridgeObjectRelease(v7);
  if (a1 != a2)
  {
    uint64_t v8 = *(int *)(a3 + 24);
    BOOL v9 = (char *)a2 + v8;
    uint64_t v10 = (uint64_t)a1 + v8;
    outlined destroy of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(v10);
    uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v9, v11);
    BOOL v13 = EnumCaseMultiPayload == 1;
    uint64_t v14 = &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>;
    if (EnumCaseMultiPayload == 1) {
      uint64_t v14 = &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>;
    }
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(v14);
    (*(void (**)(uint64_t, char *, uint64_t))(*(void *)(v15 - 8) + 32))(v10, v9, v15);
    swift_storeEnumTagMultiPayload(v10, v11, v13);
  }
  return a1;
}

uint64_t getEnumTagSinglePayload for MLSupportVectorClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_28995E);
}

uint64_t sub_28995E(uint64_t a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t result = 0;
    if ((*(void *)(a1 + 8) & 0xFFFFFFFF00000001) == 0) {
      return (*(void *)(a1 + 8) >> 1) + 1;
    }
  }
  else
  {
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
    return __swift_getEnumTagSinglePayload(*(int *)(a3 + 24) + a1, a2, v5);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLSupportVectorClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_2899EB);
}

uint64_t sub_2899EB(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(a1 + 8) = 2 * (a2 - 1);
  }
  else
  {
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
    return __swift_storeEnumTagSinglePayload(*(int *)(a4 + 24) + a1, a2, a2, v5);
  }
  return result;
}

uint64_t type metadata accessor for MLSupportVectorClassifier.Model(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLSupportVectorClassifier.Model;
  if (!type metadata singleton initialization cache for MLSupportVectorClassifier.Model) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLSupportVectorClassifier.Model);
  }
  return result;
}

uint64_t type metadata completion function for MLSupportVectorClassifier.Model(uint64_t a1)
{
  v3[0] = &unk_350D18;
  v3[1] = &unk_350D30;
  uint64_t result = type metadata accessor for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(319);
  if (v2 <= 0x3F)
  {
    v3[2] = *(void *)(result - 8) + 64;
    swift_initStructMetadata(a1, 256, 3, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t type metadata accessor for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(uint64_t a1)
{
  uint64_t result = lazy cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>;
  if (!lazy cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>)
  {
    uint64_t v2 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>);
    uint64_t result = type metadata accessor for Either(a1, v2, v3, v4);
    if (!v5) {
      lazy cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>> = result;
    }
  }
  return result;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d129ML25MLSupportVectorClassifierV5ModelV7applied2to12eventHandler11TabularData0L5FrameVAK_y0A12MLComponents5EventVYbcSgtYaKFSSSgAL26fG56VySSGcfu_32f90808cfe034de74f1d450820ef1a2faAsPTf3nnnpk_nTf1cn_n(uint64_t a1)
{
  int64_t v1 = *(void *)(a1 + 16);
  if (v1)
  {
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0);
    uint64_t v2 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>)
                   - 8);
    uint64_t v3 = ((*(unsigned __int8 *)(v2 + 80) + 32) & ~*(unsigned __int8 *)(v2 + 80)) + a1;
    uint64_t v10 = *(void *)(v2 + 72);
    do
    {
      uint64_t KeyPath = swift_getKeyPath(&unk_350DA8);
      swift_getAtKeyPath(v3, KeyPath);
      swift_release();
      int64_t v9 = v1;
      if (!swift_isUniquelyReferenced_nonNull_native(_swiftEmptyArrayStorage)) {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, _swiftEmptyArrayStorage[2] + 1, 1);
      }
      unint64_t v5 = _swiftEmptyArrayStorage[2];
      unint64_t v6 = v5 + 1;
      if (_swiftEmptyArrayStorage[3] >> 1 <= v5)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v5 + 1, 1);
        unint64_t v6 = v5 + 1;
      }
      _swiftEmptyArrayStorage[2] = v6;
      *(_OWORD *)&_swiftEmptyArrayStorage[2 * v5 + 4] = v8;
      v3 += v10;
      int64_t v1 = v9 - 1;
    }
    while (v9 != 1);
  }
  return _swiftEmptyArrayStorage;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d129ML25MLSupportVectorClassifierV5ModelV7applied2to12eventHandler11TabularData0L5FrameVAK_y0A12MLComponents5EventVYbcSgtYaKFSiSgAL26fG57VySiGcfu0_32be6a1569bf578dffa8811060c9259ebeAsPTf3nnnpk_nTf1cn_n(uint64_t a1)
{
  int64_t v1 = *(void *)(a1 + 16);
  if (v1)
  {
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0);
    uint64_t v2 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<Int>)
                   - 8);
    uint64_t v3 = ((*(unsigned __int8 *)(v2 + 80) + 32) & ~*(unsigned __int8 *)(v2 + 80)) + a1;
    uint64_t v10 = *(void *)(v2 + 72);
    do
    {
      uint64_t KeyPath = swift_getKeyPath(&unk_350DE0);
      swift_getAtKeyPath(v3, KeyPath);
      swift_release();
      int64_t v9 = v1;
      if (!swift_isUniquelyReferenced_nonNull_native(_swiftEmptyArrayStorage)) {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, _swiftEmptyArrayStorage[2] + 1, 1);
      }
      unint64_t v5 = _swiftEmptyArrayStorage[2];
      unint64_t v6 = v5 + 1;
      if (_swiftEmptyArrayStorage[3] >> 1 <= v5)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v5 + 1, 1);
        unint64_t v6 = v5 + 1;
      }
      _swiftEmptyArrayStorage[2] = v6;
      uint64_t v7 = 2 * v5;
      _swiftEmptyArrayStorage[v7 + 4] = v11;
      LOBYTE(_swiftEmptyArrayStorage[v7 + 5]) = v12 & 1;
      v3 += v10;
      int64_t v1 = v9 - 1;
    }
    while (v9 != 1);
  }
  return _swiftEmptyArrayStorage;
}

uint64_t specialized FeatureVectorizer.Transformer.exportEncoders()(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return specialized FeatureVectorizer.Transformer.exportEncoders()(a1, a2, a3);
}

{
  uint64_t v3;
  uint64_t v5;
  int64_t v6;
  void *v7;
  void *v8;
  void *v9;
  void *v10;
  int64_t v11;
  void *v12;
  void *v13;
  void *v14;
  void *v15;
  int64_t v16;
  void *v17;
  void *v18;
  void *v19;
  void *v20;
  void *v21;
  void *v22;
  int64_t v23;
  void *v24;
  void *v25;
  int64_t v26;
  void *v27;
  void *v28;
  int64_t v29;
  void *v30;
  void *v31;
  int64_t v32;
  void *v33;
  void *v34;
  void *v35;
  void *v36;
  void *v37;
  void *v38;
  void *v39;
  void *v40;
  void *v41;
  void *v42;
  void *ML16ColumnDescriptorVG_SSs5NeverOTg503_s8d131ML17FeatureVectorizerV11TransformerV10vectorized_13includingBias0A12MLComponents11DenseMatrixVyxG11TabularData0M5FrameV_SbtKFSSAA16fG54Vcfu_33_44daf68368b8b9c6f03dca699c8750fcAPSSTf3nnnpk_nTf1cn_n;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;
  char v47;
  uint64_t v48;
  Swift::String v49;
  uint64_t v50;
  void *v51;
  char v52;
  BOOL v53;
  char v54;
  uint64_t v55;
  char *v56;
  uint64_t v57;
  void *v58;
  uint64_t v59;
  char v60;
  void *v61;
  void *v62;
  void *v63;
  void *v64;
  char isUniquelyReferenced_nonNull_native;
  unint64_t v66;
  uint64_t v67;
  char *v68;
  char *v69;
  Swift::String v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  Swift::String v76;
  uint64_t v77;
  void *v78;
  char v79;
  uint64_t v80;
  uint64_t v81;
  unint64_t v82;
  uint64_t v83;
  Swift::Int v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  unint64_t v88;
  uint64_t v89;
  uint64_t v90;
  uint64_t v91;
  uint64_t v92;
  uint64_t v93;
  char v94;
  uint64_t v95;
  uint64_t v96;
  Swift::String v97;
  uint64_t v98;
  uint64_t v99;
  uint64_t v100;
  Swift::String v101;
  uint64_t v102;
  uint64_t v103;
  void *v104;
  char v105;
  uint64_t v106;
  unint64_t v107;
  Swift::Int v108;
  uint64_t v109;
  uint64_t v110;
  uint64_t v111;
  unint64_t v112;
  uint64_t v113;
  uint64_t v114;
  uint64_t v115;
  uint64_t v116;
  uint64_t v117;
  char v118;
  uint64_t v119;
  void *v120;
  void *v121;
  void *v122;
  char v123;
  unint64_t v124;
  uint64_t v125;
  uint64_t v126;
  uint64_t v127;
  uint64_t v128;
  uint64_t v129;
  uint64_t v130;
  uint64_t v131;
  char *v132;
  void *v133;
  char v134;
  unint64_t v135;
  uint64_t v136;
  uint64_t v137;
  int v138;
  uint64_t v139;
  char v140;
  uint64_t v141;
  uint64_t v142;
  uint64_t *v143;
  uint64_t *v144;
  uint64_t v145;
  uint64_t v146;
  char *v147;
  uint64_t v148;
  uint64_t v149;
  uint64_t v150;
  void *v151;
  char v152;
  unint64_t v153;
  uint64_t v154;
  uint64_t v155;
  int v156;
  uint64_t v157;
  char v158;
  uint64_t v159;
  uint64_t v160;
  uint64_t *v161;
  uint64_t *v162;
  uint64_t v163;
  uint64_t v164;
  void *v165;
  unint64_t v166;
  uint64_t v167;
  int v168;
  char *v169;
  uint64_t v170;
  void *v171;
  void *v172;
  void *v173;
  char *v174;
  uint64_t v175;
  uint64_t v176;
  char *v177;
  uint64_t v178;
  void *v179;
  char v180;
  char *v181;
  char *v182;
  uint64_t v183;
  uint64_t v184;
  uint64_t v185;
  uint64_t v186;
  uint64_t v187;
  uint64_t v188;
  uint64_t v189;
  uint64_t v190;
  char v192;
  uint64_t v193;
  uint64_t v194;
  char *v195;
  char *v196;
  char *v197;
  char *v198;
  uint64_t v199;
  uint64_t v200;
  uint64_t v201;
  char *v202;
  uint64_t v203;
  uint64_t v204;
  uint64_t v205;
  uint64_t v206;
  char *v207;
  char *v208;
  char *v209;
  char *v210;
  char *v211;
  char *v212;
  uint64_t v213;
  uint64_t v214;
  void *v215;
  char *v216;
  uint64_t v217;
  unint64_t v218;
  uint64_t v219;
  uint64_t v220;
  unint64_t v221;
  uint64_t v222;
  char *v223;
  uint64_t v224;
  uint64_t v225;
  uint64_t v226;
  char *v227;
  uint64_t v228;
  void *v229;
  uint64_t v230;
  char *v231;
  uint64_t v232;
  uint64_t v233;
  uint64_t v234;
  uint64_t v235;
  uint64_t v236;
  uint64_t v237;
  uint64_t v238;
  uint64_t v239;
  Swift::String v240;

  char v220 = a2;
  unint64_t v5 = a1;
  unint64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureDescription?)
                             - 8)
                 + 64);
  uint64_t v7 = alloca(v6);
  long long v8 = alloca(v6);
  char v195 = &v192;
  int64_t v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  uint64_t v196 = &v192;
  uint64_t v205 = type metadata accessor for FeatureVectorizerConfiguration.Input(0);
  uint64_t v206 = *(void *)(v205 - 8);
  uint64_t v11 = *(void *)(v206 + 64);
  char v12 = alloca(v11);
  BOOL v13 = alloca(v11);
  unint64_t v207 = &v192;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  char v227 = &v192;
  uint64_t v230 = type metadata accessor for FeatureDescription(0);
  uint64_t v232 = *(void *)(v230 - 8);
  BOOL v16 = *(void *)(v232 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v208 = &v192;
  unsigned int v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v210 = &v192;
  char v21 = alloca(v16);
  char v22 = alloca(v16);
  BOOL v209 = &v192;
  v214 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType(0);
  uint64_t v213 = *(void *)(v214 - 8);
  uint64_t v23 = *(void *)(v213 + 64);
  char v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  unint64_t v197 = &v192;
  char v26 = *(void *)(*(void *)(type metadata accessor for FeatureType(0) - 8) + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  uint64_t v198 = &v192;
  unint64_t v201 = type metadata accessor for ModelKind(0);
  unint64_t v200 = *(void *)(v201 - 8);
  uint64_t v29 = *(void *)(v200 + 64);
  uint64_t v30 = alloca(v29);
  uint64_t v31 = alloca(v29);
  uint64_t v202 = &v192;
  v233 = type metadata accessor for Model(0);
  v235 = *(void *)(v233 - 8);
  uint64_t v32 = *(void *)(v235 + 64);
  char v33 = alloca(v32);
  uint64_t v34 = alloca(v32);
  uint64_t v211 = &v192;
  int v35 = alloca(v32);
  uint64_t v36 = alloca(v32);
  uint64_t v223 = &v192;
  uint64_t v37 = alloca(v32);
  long long v38 = alloca(v32);
  v212 = &v192;
  uint64_t v39 = alloca(v32);
  char v40 = alloca(v32);
  char v216 = &v192;
  uint64_t v41 = alloca(v32);
  uint64_t v42 = alloca(v32);
  Model.init()();
  char v231 = &v192;
  Model.specificationVersion.setter(1);
  swift_bridgeObjectRetain(a1);
  ML16ColumnDescriptorVG_SSs5NeverOTg503_s8d131ML17FeatureVectorizerV11TransformerV10vectorized_13includingBias0A12MLComponents11DenseMatrixVyxG11TabularData0M5FrameV_SbtKFSSAA16fG54Vcfu_33_44daf68368b8b9c6f03dca699c8750fcAPSSTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay8CreateML16ColumnDescriptorVG_SSs5NeverOTg503_s8d131ML17FeatureVectorizerV11TransformerV10vectorized_13includingBias0A12MLComponents11DenseMatrixVyxG11TabularData0M5FrameV_SbtKFSSAA16fG54Vcfu_33_44daf68368b8b9c6f03dca699c8750fcAPSSTf3nnnpk_nTf1cn_n(a1);
  BOOL v199 = v3;
  swift_bridgeObjectRelease(a1);
  uint64_t v44 = specialized Set.init<A>(_:)((uint64_t)ML16ColumnDescriptorVG_SSs5NeverOTg503_s8d131ML17FeatureVectorizerV11TransformerV10vectorized_13includingBias0A12MLComponents11DenseMatrixVyxG11TabularData0M5FrameV_SbtKFSSAA16fG54Vcfu_33_44daf68368b8b9c6f03dca699c8750fcAPSSTf3nnnpk_nTf1cn_n);
  uint64_t v226 = v44;
  swift_bridgeObjectRetain(v44);
  __int16 v45 = a3;
  swift_bridgeObjectRetain(a3);
  char v46 = v220;
  uint64_t v47 = specialized Set.contains(_:)(v220, v45, v44);
  char v221 = v45;
  uint64_t v219 = a1;
  if (v47)
  {
    v240._uint64_t countAndFlagsBits = v44;
    swift_bridgeObjectRelease(v221);
    uint64_t v48 = 1;
    while (1)
    {
      v217 = v220;
      uint64_t v218 = v221;
      swift_bridgeObjectRetain(v221);
      v49._uint64_t countAndFlagsBits = 95;
      v49._char object = (void *)0xE100000000000000;
      String.append(_:)(v49);
      uint64_t v224 = v48;
      uint64_t v50 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
      uint64_t v52 = (char)v51;
      v49._uint64_t countAndFlagsBits = v50;
      v49._char object = v51;
      String.append(_:)(v49);
      swift_bridgeObjectRelease(v52);
      uint64_t v53 = __OFADD__(1, v48++);
      if (v53) {
        BUG();
      }
      char v46 = v217;
      __int16 v45 = v218;
      swift_bridgeObjectRetain(v218);
      uint64_t v54 = specialized Set.contains(_:)(v46, v45, v240._countAndFlagsBits);
      swift_bridgeObjectRelease(v45);
      if ((v54 & 1) == 0) {
        break;
      }
      swift_bridgeObjectRelease(v45);
    }
    unint64_t v5 = v219;
    LOBYTE(v44) = v240._countAndFlagsBits;
  }
  swift_bridgeObjectRelease(v44);
  swift_bridgeObjectRetain(v45);
  uint64_t v204 = v46;
  uint64_t v203 = v45;
  specialized Set._Variant.insert(_:)(&v217, v46, v45);
  swift_bridgeObjectRelease(v218);
  long long v194 = *(void *)(v5 + 16);
  if (v194)
  {
    swift_bridgeObjectRetain(v5);
    char v234 = 0;
    uint64_t v55 = 0;
    char v215 = _swiftEmptyArrayStorage;
    char v229 = _swiftEmptyArrayStorage;
    uint64_t v56 = v209;
    while (2)
    {
      uint64_t v193 = v55;
      uint64_t v57 = 32 * v55;
      v240._uint64_t countAndFlagsBits = *(void *)(v5 + 32 * v55 + 32);
      uint64_t v58 = *(void **)(v5 + 32 * v55 + 40);
      uint64_t v59 = *(void *)(v5 + 32 * v55 + 48);
      char v60 = *(unsigned char *)(v5 + v57 + 56);
      uint64_t v61 = v58;
      swift_bridgeObjectRetain((_BYTE)v58);
      outlined copy of ColumnDescriptor.ColumnTypeDescriptor(v59, v60);
      ColumnDescriptor.featureDescription.getter(v240._countAndFlagsBits, (uint64_t)v61, v59, v60);
      uint64_t v238 = v59;
      switch(v60)
      {
        case 0:
        case 1:
        case 2:
        case 3:
          FeatureVectorizerConfiguration.Input.init(name:size:)(v240._countAndFlagsBits, v61, v59);
          outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v59, v60);
          if (__OFADD__(v59, v234)) {
            BUG();
          }
          v234 += v59;
          (*(void (**)(char *, char *, uint64_t))(v232 + 16))(v208, v56, v230);
          v240._uint64_t countAndFlagsBits = Model.inputs.modify(&v217);
          char v63 = v62;
          uint64_t v64 = (void *)*v62;
          char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(*v62);
          *char v63 = v64;
          if (!isUniquelyReferenced_nonNull_native)
          {
            uint64_t v64 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v64[2] + 1, 1, (uint64_t)v64);
            *char v63 = v64;
          }
          uint64_t v66 = v64[2];
          if (v64[3] >> 1 <= v66)
          {
            uint64_t v64 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v64[3] >= 2uLL, v66 + 1, 1, (uint64_t)v64);
            *char v63 = v64;
          }
          v64[2] = v66 + 1;
          uint64_t v67 = v232;
          uint64_t v68 = (char *)v64
              + ((*(unsigned __int8 *)(v232 + 80) + 32) & ~*(unsigned __int8 *)(v232 + 80))
              + *(void *)(v232 + 72) * v66;
          Swift::String v69 = v208;
          goto LABEL_16;
        case 4:
          v217 = 0x5F6465646F636E65;
          uint64_t v218 = 0xE800000000000000;
          swift_bridgeObjectRetain((_BYTE)v61);
          outlined copy of ColumnDescriptor.ColumnTypeDescriptor(v59, 4);
          v70._uint64_t countAndFlagsBits = v240._countAndFlagsBits;
          v70._char object = v61;
          String.append(_:)(v70);
          char v225 = (uint64_t)v61;
          swift_bridgeObjectRelease((_BYTE)v61);
          char v71 = v217;
          uint64_t v72 = v218;
          char v73 = v226;
          swift_bridgeObjectRetain(v226);
          swift_bridgeObjectRetain(v72);
          char v228 = v71;
          LOBYTE(v71) = specialized Set.contains(_:)(v71, v72, v73);
          swift_bridgeObjectRelease(v72);
          if ((v71 & 1) == 0)
          {
            swift_bridgeObjectRelease(v73);
            uint64_t v125 = v238;
            uint64_t v126 = v228;
            goto LABEL_55;
          }
          uint64_t v237 = v73;
          uint64_t v74 = 1;
          uint64_t v75 = v228;
          uint64_t v239 = v72;
          while (2)
          {
            v217 = v75;
            uint64_t v218 = v72;
            swift_bridgeObjectRetain(v72);
            v76._uint64_t countAndFlagsBits = 95;
            v76._char object = (void *)0xE100000000000000;
            String.append(_:)(v76);
            uint64_t v224 = v74;
            uint64_t v77 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
            uint64_t v79 = (char)v78;
            v76._uint64_t countAndFlagsBits = v77;
            v76._char object = v78;
            String.append(_:)(v76);
            swift_bridgeObjectRelease(v79);
            uint64_t v53 = __OFADD__(1, v74);
            char v80 = v74 + 1;
            if (v53) {
              BUG();
            }
            uint64_t v222 = v80;
            char v81 = v217;
            uint64_t v82 = v218;
            uint64_t v83 = v237;
            if (*(void *)(v237 + 16))
            {
              Hasher.init(_seed:)(*(void *)(v237 + 40));
              swift_bridgeObjectRetain(v82);
              uint64_t v236 = v82;
              String.hash(into:)(&v217, v81);
              uint64_t v84 = Hasher._finalize()();
              LOBYTE(v86) = *(unsigned char *)(v83 + 32);
              uint64_t v87 = ~(-1 << v86);
              uint64_t v88 = v87 & v84;
              uint64_t v89 = *(void *)(v83 + 8 * ((v87 & (unint64_t)v84) >> 6) + 56);
              if (_bittest64(&v89, v88))
              {
                uint64_t v90 = *(void *)(v83 + 48);
                uint64_t v91 = *(void *)(v90 + 16 * v88);
                uint64_t v92 = *(void *)(v90 + 16 * v88 + 8);
                uint64_t v93 = v236;
                if (v91 != v81) {
                  goto LABEL_24;
                }
LABEL_23:
                if (v92 == v93)
                {
LABEL_28:
                  swift_bridgeObjectRelease_n(v93, 2, v85, v86, v93);
                  uint64_t v72 = v239;
                  uint64_t v75 = v228;
                  uint64_t v74 = v222;
                  continue;
                }
                while (1)
                {
LABEL_24:
                  uint64_t v94 = _stringCompareWithSmolCheck(_:_:expecting:)(v91, v92, v81, v93, 0);
                  uint64_t v93 = v236;
                  if (v94) {
                    goto LABEL_28;
                  }
                  uint64_t v85 = v81;
                  uint64_t v88 = v87 & (v88 + 1);
                  uint64_t v86 = v237;
                  uint64_t v95 = *(void *)(v237 + 8 * (v88 >> 6) + 56);
                  if (!_bittest64(&v95, v88)) {
                    break;
                  }
                  uint64_t v91 = *(void *)(v90 + 16 * v88);
                  uint64_t v92 = *(void *)(v90 + 16 * v88 + 8);
                  if (v91 == v81) {
                    goto LABEL_23;
                  }
                }
                uint64_t v126 = v81;
                uint64_t v72 = v236;
                swift_bridgeObjectRelease(v239);
                swift_bridgeObjectRelease(v237);
                swift_bridgeObjectRelease(v72);
              }
              else
              {
                swift_bridgeObjectRelease(v239);
                swift_bridgeObjectRelease(v83);
                uint64_t v72 = v236;
                swift_bridgeObjectRelease(v236);
                uint64_t v126 = v81;
              }
            }
            else
            {
              swift_bridgeObjectRelease(v239);
              swift_bridgeObjectRelease(v83);
              uint64_t v126 = v81;
              uint64_t v72 = v82;
            }
            break;
          }
          uint64_t v125 = v238;
LABEL_55:
          swift_bridgeObjectRetain(v72);
          specialized Set._Variant.insert(_:)(&v217, v126, v72);
          swift_bridgeObjectRelease(v218);
          char v129 = *(void *)(v125 + 16);
          swift_bridgeObjectRetain(v72);
          FeatureVectorizerConfiguration.Input.init(name:size:)(v126, v72, v129);
          unsigned __int8 v130 = v126;
          int64_t v131 = v129 + v234;
          if (__OFADD__(v129, v234)) {
            BUG();
          }
          unint64_t v132 = v216;
          specialized FeatureVectorizer.Transformer.makeOneHotEncoder(inputName:outputName:categories:)(v240._countAndFlagsBits, v225, v130, v72, v125);
          outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v125, 4);
          swift_bridgeObjectRelease(v72);
          (*(void (**)(char *, char *, uint64_t))(v235 + 16))(v212, v132, v233);
          uint64_t v133 = v229;
          uint64_t v134 = swift_isUniquelyReferenced_nonNull_native(v229);
          char v234 = v131;
          if (!v134) {
            uint64_t v133 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v133[2] + 1, 1, (uint64_t)v133);
          }
          unint64_t v135 = v133[2];
          uint64_t v136 = v233;
          unint64_t v137 = v235;
          if (v133[3] >> 1 <= v135)
          {
            unint64_t v171 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v133[3] >= 2uLL, v135 + 1, 1, (uint64_t)v133);
            unint64_t v137 = v235;
            uint64_t v136 = v233;
            uint64_t v133 = v171;
          }
          v133[2] = v135 + 1;
          char v138 = *(unsigned __int8 *)(v137 + 80);
          char v229 = v133;
          (*(void (**)(char *, char *, uint64_t))(v137 + 32))((char *)v133 + ((v138 + 32) & ~v138) + *(void *)(v137 + 72) * v135, v212, v136);
          uint64_t v139 = Model.outputs.getter();
          uint64_t v140 = v139;
          unint64_t v141 = (uint64_t)v196;
          specialized Collection.first.getter(v139);
          swift_bridgeObjectRelease(v140);
          char v142 = v230;
          if (__swift_getEnumTagSinglePayload(v141, 1, v230) == 1) {
            BUG();
          }
          v240._uint64_t countAndFlagsBits = Model.inputs.modify(&v217);
          Swift::String v144 = v143;
          specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
          uint64_t v145 = *(void *)(*v144 + 16);
          specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v145);
          unint64_t v146 = *v144;
          *(void *)(v146 + 16) = v145 + 1;
          (*(void (**)(uint64_t, uint64_t, uint64_t))(v232 + 32))(v146+ ((*(unsigned __int8 *)(v232 + 80) + 32) & ~*(unsigned __int8 *)(v232 + 80))+ *(void *)(v232 + 72) * v145, v141, v142);
          ((void (*)(uint64_t *, void))v240._countAndFlagsBits)(&v217, 0);
          swift_bridgeObjectRelease(v225);
          outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v238, 4);
          long long v147 = v216;
          goto LABEL_71;
        case 5:
          v217 = 0x5F6465646F636E65;
          uint64_t v218 = 0xE800000000000000;
          swift_bridgeObjectRetain((_BYTE)v61);
          uint64_t v96 = v59;
          outlined copy of ColumnDescriptor.ColumnTypeDescriptor(v59, 5);
          v97._uint64_t countAndFlagsBits = v240._countAndFlagsBits;
          v97._char object = v61;
          String.append(_:)(v97);
          char v225 = (uint64_t)v61;
          swift_bridgeObjectRelease((_BYTE)v61);
          uint64_t v98 = v217;
          uint64_t v99 = v218;
          uint64_t v100 = v226;
          swift_bridgeObjectRetain(v226);
          swift_bridgeObjectRetain(v99);
          char v228 = v98;
          LOBYTE(v98) = specialized Set.contains(_:)(v98, v99, v100);
          swift_bridgeObjectRelease(v99);
          if ((v98 & 1) == 0)
          {
            swift_bridgeObjectRelease(v100);
            unsigned __int8 v127 = v96;
            uint64_t v128 = v228;
            goto LABEL_64;
          }
          uint64_t v222 = 1;
          uint64_t v239 = v99;
          uint64_t v237 = v100;
          while (2)
          {
            v217 = v228;
            uint64_t v218 = v99;
            swift_bridgeObjectRetain(v99);
            v101._uint64_t countAndFlagsBits = 95;
            v101._char object = (void *)0xE100000000000000;
            String.append(_:)(v101);
            int64_t v102 = v222;
            uint64_t v224 = v222;
            uint64_t v103 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
            uint64_t v105 = (char)v104;
            v101._uint64_t countAndFlagsBits = v103;
            v101._char object = v104;
            String.append(_:)(v101);
            swift_bridgeObjectRelease(v105);
            uint64_t v222 = v102 + 1;
            if (__OFADD__(1, v102)) {
              BUG();
            }
            uint64_t v106 = v217;
            uint64_t v107 = v218;
            if (*(void *)(v100 + 16))
            {
              Hasher.init(_seed:)(*(void *)(v100 + 40));
              swift_bridgeObjectRetain(v107);
              uint64_t v236 = v107;
              String.hash(into:)(&v217, v106);
              uint64_t v108 = Hasher._finalize()();
              LOBYTE(v110) = *(unsigned char *)(v100 + 32);
              uint64_t v111 = ~(-1 << v110);
              char v112 = v111 & v108;
              uint64_t v113 = *(void *)(v100 + 8 * ((v111 & (unint64_t)v108) >> 6) + 56);
              if (_bittest64(&v113, v112))
              {
                uint64_t v114 = *(void *)(v100 + 48);
                uint64_t v115 = *(void *)(v114 + 16 * v112);
                uint64_t v116 = *(void *)(v114 + 16 * v112 + 8);
                uint64_t v117 = v236;
                if (v115 != v106) {
                  goto LABEL_36;
                }
LABEL_35:
                if (v116 == v117)
                {
LABEL_40:
                  swift_bridgeObjectRelease_n(v117, 2, v109, v110, v117);
                  uint64_t v99 = v239;
                  uint64_t v100 = v237;
                  continue;
                }
                while (1)
                {
LABEL_36:
                  uint64_t v118 = _stringCompareWithSmolCheck(_:_:expecting:)(v115, v116, v106, v117, 0);
                  uint64_t v117 = v236;
                  if (v118) {
                    goto LABEL_40;
                  }
                  uint64_t v109 = v106;
                  char v112 = v111 & (v112 + 1);
                  uint64_t v110 = v237;
                  unint64_t v119 = *(void *)(v237 + 8 * (v112 >> 6) + 56);
                  if (!_bittest64(&v119, v112)) {
                    break;
                  }
                  uint64_t v115 = *(void *)(v114 + 16 * v112);
                  uint64_t v116 = *(void *)(v114 + 16 * v112 + 8);
                  if (v115 == v106) {
                    goto LABEL_35;
                  }
                }
                uint64_t v128 = v106;
                uint64_t v99 = v236;
                swift_bridgeObjectRelease(v239);
                swift_bridgeObjectRelease(v237);
                swift_bridgeObjectRelease(v99);
              }
              else
              {
                swift_bridgeObjectRelease(v239);
                swift_bridgeObjectRelease(v100);
                uint64_t v99 = v236;
                swift_bridgeObjectRelease(v236);
                uint64_t v128 = v106;
              }
            }
            else
            {
              swift_bridgeObjectRelease(v239);
              swift_bridgeObjectRelease(v100);
              uint64_t v128 = v106;
              uint64_t v99 = v107;
            }
            break;
          }
          unsigned __int8 v127 = v238;
LABEL_64:
          swift_bridgeObjectRetain(v99);
          specialized Set._Variant.insert(_:)(&v217, v128, v99);
          swift_bridgeObjectRelease(v218);
          uint64_t v236 = *(void *)(v127 + 16);
          char v148 = v236;
          swift_bridgeObjectRetain(v99);
          FeatureVectorizerConfiguration.Input.init(name:size:)(v128, v99, v148);
          uint64_t v149 = v127;
          uint64_t v150 = v236 + v234;
          if (__OFADD__(v236, v234)) {
            BUG();
          }
          specialized FeatureVectorizer.Transformer.makeDictionaryVectorizer(inputName:outputName:descriptors:)(v240._countAndFlagsBits, v225, v128, v99, v149);
          outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v149, 5);
          swift_bridgeObjectRelease(v99);
          (*(void (**)(char *, char *, uint64_t))(v235 + 16))(v211, v223, v233);
          Swift::String v151 = v229;
          Swift::String v152 = swift_isUniquelyReferenced_nonNull_native(v229);
          char v234 = v150;
          if (!v152) {
            Swift::String v151 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v151[2] + 1, 1, (uint64_t)v151);
          }
          uint64_t v153 = v151[2];
          uint64_t v154 = v233;
          int v155 = v235;
          if (v151[3] >> 1 <= v153)
          {
            uint64_t v172 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v151[3] >= 2uLL, v153 + 1, 1, (uint64_t)v151);
            int v155 = v235;
            uint64_t v154 = v233;
            Swift::String v151 = v172;
          }
          v151[2] = v153 + 1;
          char v156 = *(unsigned __int8 *)(v155 + 80);
          char v229 = v151;
          (*(void (**)(char *, char *, uint64_t))(v155 + 32))((char *)v151 + ((v156 + 32) & ~v156) + *(void *)(v155 + 72) * v153, v211, v154);
          uint64_t v157 = Model.outputs.getter();
          uint64_t v158 = v157;
          char v159 = (uint64_t)v195;
          specialized Collection.first.getter(v157);
          swift_bridgeObjectRelease(v158);
          uint64_t v160 = v230;
          if (__swift_getEnumTagSinglePayload(v159, 1, v230) == 1) {
            BUG();
          }
          v240._uint64_t countAndFlagsBits = Model.inputs.modify(&v217);
          uint64_t v162 = v161;
          specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
          uint64_t v163 = *(void *)(*v162 + 16);
          specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v163);
          long long v164 = *v162;
          *(void *)(v164 + 16) = v163 + 1;
          (*(void (**)(uint64_t, uint64_t, uint64_t))(v232 + 32))(v164+ ((*(unsigned __int8 *)(v232 + 80) + 32) & ~*(unsigned __int8 *)(v232 + 80))+ *(void *)(v232 + 72) * v163, v159, v160);
          ((void (*)(uint64_t *, void))v240._countAndFlagsBits)(&v217, 0);
          swift_bridgeObjectRelease(v225);
          outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v238, 5);
          long long v147 = v223;
LABEL_71:
          (*(void (**)(char *, uint64_t))(v235 + 8))(v147, v233);
LABEL_72:
          (*(void (**)(char *, char *, uint64_t))(v206 + 16))(v207, v227, v205);
          uint64_t v165 = v215;
          if (!swift_isUniquelyReferenced_nonNull_native(v215)) {
            uint64_t v165 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v165[2] + 1, 1, (uint64_t)v165);
          }
          double v166 = v165[2];
          if (v165[3] >> 1 <= v166) {
            uint64_t v165 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v165[3] >= 2uLL, v166 + 1, 1, (uint64_t)v165);
          }
          uint64_t v55 = v193 + 1;
          v165[2] = v166 + 1;
          uint64_t v167 = v206;
          Swift::String v168 = *(unsigned __int8 *)(v206 + 80);
          char v215 = v165;
          unint64_t v169 = (char *)v165 + ((v168 + 32) & ~v168) + *(void *)(v206 + 72) * v166;
          char v170 = v205;
          (*(void (**)(char *, char *, uint64_t))(v206 + 32))(v169, v207, v205);
          (*(void (**)(char *, uint64_t))(v167 + 8))(v227, v170);
          uint64_t v56 = v209;
          (*(void (**)(char *, uint64_t))(v232 + 8))(v209, v230);
          unint64_t v5 = v219;
          if (v55 != v194) {
            continue;
          }
          swift_bridgeObjectRelease(v219);
          unsigned long long v173 = v215;
          break;
        case 6:
          FeatureVectorizerConfiguration.Input.init(name:size:)(v240._countAndFlagsBits, v61, 1);
          outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v59, 6);
          if (__OFADD__(1, v234)) {
            BUG();
          }
          ++v234;
          (*(void (**)(char *, char *, uint64_t))(v232 + 16))(v210, v56, v230);
          v240._uint64_t countAndFlagsBits = Model.inputs.modify(&v217);
          uint64_t v121 = v120;
          uint64_t v122 = (void *)*v120;
          uint64_t v123 = swift_isUniquelyReferenced_nonNull_native(*v120);
          uint64_t *v121 = v122;
          if (!v123)
          {
            uint64_t v122 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v122[2] + 1, 1, (uint64_t)v122);
            uint64_t *v121 = v122;
          }
          uint64_t v124 = v122[2];
          if (v122[3] >> 1 <= v124)
          {
            uint64_t v122 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v122[3] >= 2uLL, v124 + 1, 1, (uint64_t)v122);
            uint64_t *v121 = v122;
          }
          v122[2] = v124 + 1;
          uint64_t v67 = v232;
          uint64_t v68 = (char *)v122
              + ((*(unsigned __int8 *)(v232 + 80) + 32) & ~*(unsigned __int8 *)(v232 + 80))
              + *(void *)(v232 + 72) * v124;
          Swift::String v69 = v210;
LABEL_16:
          (*(void (**)(char *, char *, uint64_t))(v67 + 32))(v68, v69, v230);
          ((void (*)(uint64_t *, void))v240._countAndFlagsBits)(&v217, 0);
          goto LABEL_72;
      }
      break;
    }
  }
  else
  {
    unsigned long long v173 = _swiftEmptyArrayStorage;
    char v234 = 0;
    char v229 = _swiftEmptyArrayStorage;
  }
  swift_bridgeObjectRelease(v226);
  uint64_t v174 = v202;
  FeatureVectorizerConfiguration.init(inputs:)(v173);
  (*(void (**)(char *, void, uint64_t))(v200 + 104))(v174, enum case for ModelKind.featureVectorizer(_:), v201);
  Model.kind.setter(v174);
  int v175 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  int64_t v176 = swift_allocObject(v175, ((*(unsigned __int8 *)(v232 + 80) + 32) & ~*(unsigned __int8 *)(v232 + 80)) + *(void *)(v232 + 72), *(unsigned __int8 *)(v232 + 80) | 7);
  v240._uint64_t countAndFlagsBits = v176;
  *(void *)(v176 + 16) = 1;
  *(void *)(v176 + 24) = 2;
  v177 = v197;
  (*(void (**)(char *, void, uint64_t))(v213 + 104))(v197, enum case for FeatureType.ShapedArrayParameters.DataType.double(_:), v214);
  uint64_t v178 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  char v179 = (void *)swift_allocObject(v178, 40, 7);
  uint64_t v180 = (char)v179;
  v179[2] = 1;
  v179[3] = 2;
  v179[4] = v234;
  int64_t v181 = v198;
  static FeatureType.shapedArray(dataType:shape:optional:)(v177, v179, 0);
  swift_bridgeObjectRelease(v180);
  (*(void (**)(char *, uint64_t))(v213 + 8))(v177, v214);
  FeatureDescription.init(name:type:description:)(v204, v203, v181, 0, 0xE000000000000000);
  uint64_t v182 = v231;
  Model.outputs.setter(v240._countAndFlagsBits);
  uint64_t v183 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Model>);
  uint64_t v184 = *(unsigned __int8 *)(v235 + 80);
  uint64_t v185 = ((int)v184 + 32) & ~*(unsigned __int8 *)(v235 + 80);
  uint64_t v186 = swift_allocObject(v183, v185 + *(void *)(v235 + 72), v184 | 7);
  *(void *)(v186 + 16) = 1;
  *(void *)(v186 + 24) = 2;
  unint64_t v187 = v186 + v185;
  unint64_t v188 = v233;
  uint64_t v189 = v235;
  (*(void (**)(uint64_t, char *, uint64_t))(v235 + 16))(v187, v182, v233);
  v217 = (uint64_t)v229;
  specialized Array.append<A>(contentsOf:)(v186);
  uint64_t v190 = v217;
  (*(void (**)(char *, uint64_t))(v189 + 8))(v231, v188);
  return v190;
}

uint64_t specialized FeatureVectorizer.Transformer.makeOneHotEncoder(inputName:outputName:categories:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v30 = a4;
  uint64_t v31 = a3;
  uint64_t v33 = a2;
  uint64_t v34 = a1;
  uint64_t v7 = v5;
  uint64_t v35 = type metadata accessor for FeatureType(0);
  uint64_t v36 = *(void *)(v35 - 8);
  int64_t v8 = *(void *)(v36 + 64);
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v32 = v28;
  uint64_t v41 = type metadata accessor for OneHotEncoderConfiguration.UnknownBehavior(0);
  uint64_t v37 = *(void *)(v41 - 8);
  int64_t v11 = *(void *)(v37 + 64);
  char v12 = alloca(v11);
  BOOL v13 = alloca(v11);
  uint64_t v39 = type metadata accessor for ModelKind(0);
  uint64_t v40 = *(void *)(v39 - 8);
  int64_t v14 = *(void *)(v40 + 64);
  uint64_t v15 = alloca(v14);
  BOOL v16 = alloca(v14);
  Model.init()();
  uint64_t v38 = v7;
  Model.specificationVersion.setter(1);
  uint64_t v29 = a5;
  swift_bridgeObjectRetain(a5);
  specialized MutableCollection<>.sort(by:)(&v29);
  uint64_t v17 = v29;
  (*(void (**)(unsigned char *, void, uint64_t))(v37 + 104))(v28, enum case for OneHotEncoderConfiguration.UnknownBehavior.error(_:), v41);
  OneHotEncoderConfiguration.init(orderedCategories:sparseOutput:unknownBehavior:)(v17, 1, v28);
  (*(void (**)(unsigned char *, void, uint64_t))(v40 + 104))(v28, enum case for ModelKind.oneHotEncoder(_:), v39);
  Model.kind.setter(v28);
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  uint64_t v39 = v18;
  uint64_t v19 = *(void *)(type metadata accessor for FeatureDescription(0) - 8);
  uint64_t v20 = *(unsigned __int8 *)(v19 + 80);
  uint64_t v21 = ((int)v20 + 32) & ~*(unsigned __int8 *)(v19 + 80);
  uint64_t v40 = v21 + *(void *)(v19 + 72);
  v20 |= 7uLL;
  uint64_t v22 = swift_allocObject(v18, v40, v20);
  *(void *)(v22 + 16) = 1;
  *(void *)(v22 + 24) = 2;
  uint64_t v41 = v22 + v21;
  uint64_t v23 = v33;
  swift_bridgeObjectRetain(v33);
  char v24 = v32;
  FeatureType.StringParameters.init(optional:)(0);
  (*(void (**)(unsigned char *, void, uint64_t))(v36 + 104))(v24, enum case for FeatureType.string(_:), v35);
  FeatureDescription.init(name:type:description:)(v34, v23, v24, 0, 0xE000000000000000);
  Model.inputs.setter(v22);
  uint64_t v25 = swift_allocObject(v39, v40, v20);
  *(void *)(v25 + 16) = 1;
  *(void *)(v25 + 24) = 2;
  uint64_t v26 = v30;
  swift_bridgeObjectRetain(v30);
  static FeatureType.dictionaryWithIntKeys(optional:)(0);
  FeatureDescription.init(name:type:description:)(v31, v26, v24, 0, 0xE000000000000000);
  return Model.outputs.setter(v25);
}

uint64_t specialized FeatureVectorizer.Transformer.makeDictionaryVectorizer(inputName:outputName:descriptors:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v31 = a4;
  uint64_t v30 = a3;
  uint64_t v33 = a2;
  uint64_t v32 = a1;
  uint64_t v7 = v5;
  int64_t v8 = *(void *)(*(void *)(type metadata accessor for FeatureType(0) - 8) + 64);
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v34 = v28;
  uint64_t v37 = type metadata accessor for ModelKind(0);
  uint64_t v38 = *(void *)(v37 - 8);
  int64_t v11 = *(void *)(v38 + 64);
  char v12 = alloca(v11);
  BOOL v13 = alloca(v11);
  Model.init()();
  uint64_t v36 = v7;
  Model.specificationVersion.setter(1);
  ML16ColumnDescriptorVG_SSs5NeverOTg503_s8d131ML17FeatureVectorizerV11TransformerV10vectorized_13includingBias0A12MLComponents11DenseMatrixVyxG11TabularData0M5FrameV_SbtKFSSAA16fG54Vcfu_33_44daf68368b8b9c6f03dca699c8750fcAPSSTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay8CreateML16ColumnDescriptorVG_SSs5NeverOTg503_s8d131ML17FeatureVectorizerV11TransformerV10vectorized_13includingBias0A12MLComponents11DenseMatrixVyxG11TabularData0M5FrameV_SbtKFSSAA16fG54Vcfu_33_44daf68368b8b9c6f03dca699c8750fcAPSSTf3nnnpk_nTf1cn_n(a5);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  uint64_t v15 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [String] and conformance [A], &demangling cache variable for type metadata for [String], (uint64_t)&protocol conformance descriptor for [A]);
  DictionaryVectorizerConfiguration.init<A>(keys:)(&ML16ColumnDescriptorVG_SSs5NeverOTg503_s8d131ML17FeatureVectorizerV11TransformerV10vectorized_13includingBias0A12MLComponents11DenseMatrixVyxG11TabularData0M5FrameV_SbtKFSSAA16fG54Vcfu_33_44daf68368b8b9c6f03dca699c8750fcAPSSTf3nnnpk_nTf1cn_n, v14, v15);
  (*(void (**)(unsigned char *, void, uint64_t))(v38 + 104))(v28, enum case for ModelKind.dictionaryVectorizer(_:), v37);
  Model.kind.setter(v28);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  uint64_t v37 = v16;
  uint64_t v17 = *(void *)(type metadata accessor for FeatureDescription(0) - 8);
  uint64_t v18 = *(unsigned __int8 *)(v17 + 80);
  uint64_t v19 = ((int)v18 + 32) & ~*(unsigned __int8 *)(v17 + 80);
  uint64_t v38 = v19 + *(void *)(v17 + 72);
  v18 |= 7uLL;
  uint64_t v20 = swift_allocObject(v16, v38, v18);
  *(void *)(v20 + 16) = 1;
  *(void *)(v20 + 24) = 2;
  uint64_t v35 = v20 + v19;
  uint64_t v21 = v33;
  swift_bridgeObjectRetain(v33);
  uint64_t v22 = v34;
  static FeatureType.dictionaryWithStringKeys(optional:)(0);
  uint64_t v23 = v21;
  char v24 = v22;
  FeatureDescription.init(name:type:description:)(v32, v23, v22, 0, 0xE000000000000000);
  Model.inputs.setter(v20);
  uint64_t v25 = swift_allocObject(v37, v38, v18);
  *(void *)(v25 + 16) = 1;
  *(void *)(v25 + 24) = 2;
  uint64_t v26 = v31;
  swift_bridgeObjectRetain(v31);
  static FeatureType.dictionaryWithIntKeys(optional:)(0);
  FeatureDescription.init(name:type:description:)(v30, v26, v24, 0, 0xE000000000000000);
  return Model.outputs.setter(v25);
}

uint64_t MLSupportVectorClassifier.Model.exportAsCoreMLModel()()
{
  v1[2] = v0;
  uint64_t v2 = type metadata accessor for Model(0);
  v1[3] = v2;
  uint64_t v3 = *(void *)(v2 - 8);
  v1[4] = v3;
  v1[5] = swift_task_alloc((*(void *)(v3 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLSupportVectorClassifier.Model.exportAsCoreMLModel(), 0, 0);
}

{
  uint64_t v0;
  void *v1;
  NSString *v2;
  NSString *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void *v10;
  uint64_t v12[4];
  long long v13;
  uint64_t v14;
  unint64_t v15;
  uint64_t v16;
  uint64_t v17;
  void *v18;
  uint64_t v19;

  uint64_t v19 = v0 | 0x1000000000000000;
  uint64_t v18 = v1;
  uint64_t v17 = v1[2];
  uint64_t v2 = NSFullUserName();
  uint64_t v3 = v2;
  uint64_t v4 = static String._unconditionallyBridgeFromObjectiveC(_:)(v3);
  unint64_t v6 = v5;

  v12[0] = v4;
  v12[1] = v6;
  _OWORD v12[2] = 0xD000000000000033;
  v12[3] = (uint64_t)("RandomForestRegressor" + 0x8000000000000000);
  BOOL v13 = 0;
  uint64_t v14 = 49;
  uint64_t v15 = 0xE100000000000000;
  uint64_t v16 = 0;
  MLSupportVectorClassifier.Model.export(metadata:)(v12);
  swift_bridgeObjectRelease(v6);
  swift_bridgeObjectRelease(("RandomForestRegressor" + 0x8000000000000000));
  swift_bridgeObjectRelease_n(0, 2, v7, v8, v9);
  swift_bridgeObjectRelease(0);
  type metadata accessor for MLModel();
  uint64_t v10 = (void *)swift_task_alloc(dword_3A701C);
  v1[6] = v10;
  *uint64_t v10 = v1;
  v10[1] = MLSupportVectorClassifier.Model.exportAsCoreMLModel();
  return static MLModel.compile(_:)(v1[5]);
}

{
  uint64_t v0;
  uint64_t v1;

  int64_t v1 = *(void *)(v0 + 40);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 32) + 8))(v1, *(void *)(v0 + 24));
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))(*(void *)(v0 + 64));
}

{
  uint64_t v0;

  (*(void (**)(void, void))(*(void *)(v0 + 32) + 8))(*(void *)(v0 + 40), *(void *)(v0 + 24));
  swift_task_dealloc(*(void *)(v0 + 40));
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLSupportVectorClassifier.Model.exportAsCoreMLModel()(uint64_t a1)
{
  uint64_t v5 = *(void *)(*v2 + 48);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 56) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    unint64_t v6 = MLSupportVectorClassifier.Model.exportAsCoreMLModel();
  }
  else
  {
    *(void *)(v4 + 64) = a1;
    unint64_t v6 = MLSupportVectorClassifier.Model.exportAsCoreMLModel();
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t MLSupportVectorClassifier.Model.computeMetrics(on:)(uint64_t a1, uint64_t a2)
{
  void v3[4] = v2;
  v3[3] = a2;
  v3[2] = a1;
  unint64_t v4 = (*(void *)(*(void *)(type metadata accessor for AnyColumn(0) - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  void v3[5] = swift_task_alloc(v4);
  v3[6] = swift_task_alloc(v4);
  uint64_t v5 = type metadata accessor for DataFrame(0);
  v3[7] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  void v3[8] = v6;
  uint64_t v7 = swift_task_alloc((*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  v3[9] = v7;
  int64_t v8 = (void *)swift_task_alloc(dword_3ADEAC);
  v3[10] = v8;
  void *v8 = v3;
  v8[1] = MLSupportVectorClassifier.Model.computeMetrics(on:);
  return MLSupportVectorClassifier.Model.applied(to:eventHandler:)(v7, a2, 0, 0);
}

uint64_t MLSupportVectorClassifier.Model.computeMetrics(on:)()
{
  uint64_t v2 = *(void *)(*(void *)v1 + 80);
  *(void *)(*(void *)v1 + 88) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLSupportVectorClassifier.Model.computeMetrics(on:);
  }
  else {
    uint64_t v3 = MLSupportVectorClassifier.Model.computeMetrics(on:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;

  int64_t v8 = *(void *)(v0 + 72);
  uint64_t v6 = *(void *)(v0 + 64);
  uint64_t v7 = *(void *)(v0 + 56);
  int64_t v9 = *(void *)(v0 + 48);
  uint64_t v1 = *(void *)(v0 + 40);
  uint64_t v2 = *(void **)(v0 + 32);
  uint64_t v3 = *v2;
  unint64_t v4 = v2[1];
  DataFrame.subscript.getter(*v2, v4);
  DataFrame.subscript.getter(v3, v4);
  AnyClassificationMetrics.init(_:_:)(v9, v1);
  (*(void (**)(uint64_t, uint64_t))(v6 + 8))(v8, v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;

  uint64_t v1 = *(void *)(v0 + 40);
  uint64_t v2 = *(void *)(v0 + 48);
  swift_task_dealloc(*(void *)(v0 + 72));
  swift_task_dealloc(v2);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLSupportVectorClassifier.Model.predictions(from:)(uint64_t a1, uint64_t a2)
{
  v3[3] = v2;
  v3[2] = a1;
  uint64_t v4 = type metadata accessor for DataFrame(0);
  void v3[4] = v4;
  uint64_t v5 = *(void *)(v4 - 8);
  void v3[5] = v5;
  uint64_t v6 = swift_task_alloc((*(void *)(v5 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  v3[6] = v6;
  uint64_t v7 = (void *)swift_task_alloc(dword_3ADEAC);
  v3[7] = v7;
  *uint64_t v7 = v3;
  v7[1] = MLSupportVectorClassifier.Model.predictions(from:);
  return MLSupportVectorClassifier.Model.applied(to:eventHandler:)(v6, a2, 0, 0);
}

uint64_t MLSupportVectorClassifier.Model.predictions(from:)()
{
  uint64_t v2 = *(void *)(*(void *)v1 + 56);
  *(void *)(*(void *)v1 + 64) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = closure #1 in closure #1 in closure #1 in closure #1 in static MLStyleTransfer.resume(_:);
  }
  else {
    uint64_t v3 = MLSupportVectorClassifier.Model.predictions(from:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v1 = *(void *)(v0 + 48);
  uint64_t v2 = *(void *)(v0 + 40);
  uint64_t v3 = *(void *)(v0 + 32);
  DataFrame.subscript.getter(**(void **)(v0 + 24), *(void *)(*(void *)(v0 + 24) + 8));
  (*(void (**)(uint64_t, uint64_t))(v2 + 8))(v1, v3);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLSupportVectorClassifier.Model.export(metadata:)(uint64_t *a1)
{
  uint64_t v48 = v2;
  uint64_t v3 = v1;
  uint64_t v36 = type metadata accessor for Model(0);
  uint64_t v4 = *(void *)(v36 - 8);
  int64_t v5 = *(void *)(v4 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v37 = v35;
  uint64_t v39 = *a1;
  uint64_t v40 = a1[1];
  uint64_t v43 = a1[2];
  uint64_t v44 = a1[3];
  uint64_t v50 = (void (*)(void, void))a1[4];
  unint64_t v38 = a1[5];
  uint64_t v41 = a1[6];
  uint64_t v42 = a1[7];
  uint64_t v49 = a1[8];
  uint64_t v8 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for String, &protocol witness table for String);
  uint64_t v46 = v3;
  uint64_t v9 = v48;
  MLSupportVectorClassifier.Model.export(userInfo:)();
  if (v9) {
    return swift_bridgeObjectRelease(v8);
  }
  uint64_t v45 = 0;
  uint64_t v47 = v8;
  uint64_t v48 = v4;
  uint64_t v11 = v44;
  swift_bridgeObjectRetain(v44);
  uint64_t v12 = v46;
  Model.modelDescription.setter(v43, v11);
  uint64_t v13 = v42;
  swift_bridgeObjectRetain(v42);
  Model.versionString.setter(v41, v13);
  uint64_t v14 = v40;
  swift_bridgeObjectRetain(v40);
  Model.author.setter(v39, v14);
  uint64_t v15 = v50;
  if (!v38) {
    uint64_t v15 = 0;
  }
  unint64_t v16 = 0xE000000000000000;
  if (v38) {
    unint64_t v16 = v38;
  }
  swift_bridgeObjectRetain(v38);
  Model.license.setter(v15, v16);
  char v17 = v49;
  if (v49)
  {
    uint64_t v18 = v49;
  }
  else
  {
    uint64_t v18 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for String, &protocol witness table for String);
    char v17 = 0;
  }
  swift_bridgeObjectRetain(v17);
  Model.metadata.setter(v18);
  uint64_t v19 = v47;
  swift_bridgeObjectRetain(v47);
  uint64_t v20 = v12;
  uint64_t v21 = (void (*)(unsigned char *, void))Model.metadata.modify(v35);
  uint64_t v22 = v45;
  specialized Dictionary._Variant.merge<A>(_:uniquingKeysWith:)(v19, (uint64_t)specialized thunk for @escaping @callee_guaranteed (@in_guaranteed A, @in_guaranteed B) -> (@out A, @out B), 0, v23);
  uint64_t v49 = v22;
  v21(v35, 0);
  Swift::String v24 = getOSVersion()();
  uint64_t countAndFlagsBits = v24._countAndFlagsBits;
  char object = v24._object;
  uint64_t v50 = (void (*)(void, void))Model.metadata.modify(v35);
  specialized Dictionary._Variant.setValue(_:forKey:)(countAndFlagsBits, (uint64_t)object, 0xD00000000000001ALL, (uint64_t)("Recommender Model" + 0x8000000000000000));
  v50(v35, 0);
  uint64_t v27 = v37;
  uint64_t v28 = v36;
  uint64_t v29 = v48;
  (*(void (**)(unsigned char *, uint64_t, uint64_t))(v48 + 16))(v37, v20, v36);
  uint64_t v30 = Model.nestedModels.getter();
  (*(void (**)(unsigned char *, uint64_t))(v29 + 8))(v27, v28);
  ML17MLImageClassifierV5f41V6export8metadata20featureExtractorType20dE92ADVAA0K8MetadataV_AC07FeatureiJ0OtKFSiAJcfu_32b63bdf5f6c975d31a36a8f37561ba444AJSiTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay20MLModelSpecification5ModelVG_Sis5NeverOTg5032_s8CreateML17MLImageClassifierV5f41V6export8metadata20featureExtractorType20dE92ADVAA0K8MetadataV_AC07FeatureiJ0OtKFSiAJcfu_32b63bdf5f6c975d31a36a8f37561ba444AJSiTf3nnnpk_nTf1cn_n(v30);
  swift_bridgeObjectRelease(v30);
  swift_bridgeObjectRelease(v47);
  uint64_t v32 = specialized Sequence<>.max()((uint64_t)ML17MLImageClassifierV5f41V6export8metadata20featureExtractorType20dE92ADVAA0K8MetadataV_AC07FeatureiJ0OtKFSiAJcfu_32b63bdf5f6c975d31a36a8f37561ba444AJSiTf3nnnpk_nTf1cn_n);
  LOBYTE(v27) = v33;
  swift_bridgeObjectRelease((_BYTE)ML17MLImageClassifierV5f41V6export8metadata20featureExtractorType20dE92ADVAA0K8MetadataV_AC07FeatureiJ0OtKFSiAJcfu_32b63bdf5f6c975d31a36a8f37561ba444AJSiTf3nnnpk_nTf1cn_n);
  uint64_t v34 = 1;
  if ((v27 & 1) == 0) {
    uint64_t v34 = v32;
  }
  return Model.specificationVersion.setter(v34);
}

uint64_t specialized Transformer.applied<A>(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  void v4[5] = v3;
  _OWORD v4[4] = a3;
  v4[3] = a2;
  v4[2] = a1;
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>);
  v4[6] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v4[7] = v6;
  void v4[8] = swift_task_alloc((*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for Event(0, a2, v7);
  v4[9] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v4[10] = v9;
  v4[11] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  void v4[12] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v4[13] = v11;
  v4[14] = swift_task_alloc((*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  v4[15] = v12;
  uint64_t v13 = *(void *)(v12 - 8);
  v4[16] = v13;
  v4[17] = swift_task_alloc((*(void *)(v13 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>?);
  v4[18] = swift_task_alloc((*(void *)(*(void *)(v14 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized Transformer.applied<A>(to:eventHandler:), 0, 0);
}

{
  uint64_t v3;
  void *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;

  void v4[5] = v3;
  _OWORD v4[4] = a3;
  v4[3] = a2;
  v4[2] = a1;
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>);
  v4[6] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v4[7] = v6;
  void v4[8] = swift_task_alloc((*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for Event(0, a2, v7);
  v4[9] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v4[10] = v9;
  v4[11] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<Int>);
  void v4[12] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v4[13] = v11;
  v4[14] = swift_task_alloc((*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  v4[15] = v12;
  uint64_t v13 = *(void *)(v12 - 8);
  v4[16] = v13;
  v4[17] = swift_task_alloc((*(void *)(v13 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>?);
  v4[18] = swift_task_alloc((*(void *)(*(void *)(v14 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized Transformer.applied<A>(to:eventHandler:), 0, 0);
}

{
  uint64_t v3;
  void *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;

  void v4[5] = v3;
  _OWORD v4[4] = a3;
  v4[3] = a2;
  v4[2] = a1;
  uint64_t v5 = type metadata accessor for MLSoundClassifier.Model(0);
  v4[6] = v5;
  v4[7] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for Event(0, a2, v6);
  void v4[8] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  v4[9] = v8;
  v4[10] = swift_task_alloc((*(void *)(v8 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v4[11] = v9;
  uint64_t v10 = *(void *)(v9 - 8);
  void v4[12] = v10;
  v4[13] = swift_task_alloc((*(void *)(v10 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v4[14] = v11;
  uint64_t v12 = *(void *)(v11 - 8);
  v4[15] = v12;
  v4[16] = swift_task_alloc((*(void *)(v12 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  v4[17] = v13;
  v4[18] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  v4[19] = v14;
  uint64_t v15 = *(void *)(v14 - 8);
  v4[20] = v15;
  v4[21] = swift_task_alloc((*(void *)(v15 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  v4[22] = v16;
  char v17 = *(void *)(v16 - 8);
  v4[23] = v17;
  v4[24] = swift_task_alloc((*(void *)(v17 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>?);
  v4[25] = swift_task_alloc((*(void *)(*(void *)(v18 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized Transformer.applied<A>(to:eventHandler:), 0, 0);
}

uint64_t specialized Transformer.applied<A>(to:eventHandler:)()
{
  int64_t v1 = *(void *)(*(void *)(v0 + 16) + 16);
  *(void *)(v0 + 152) = v1;
  uint64_t v2 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0, (uint64_t)_swiftEmptyArrayStorage);
  if (v1)
  {
    uint64_t v3 = *(void *)(v0 + 128);
    int v4 = *(_DWORD *)(v3 + 80);
    *(_DWORD *)(v0 + 208) = v4;
    uint64_t v5 = *(void (**)(uint64_t, uint64_t, uint64_t))(v3 + 16);
    *(void *)(v0 + 160) = *(void *)(v3 + 72);
    *(void *)(v0 + 168) = v5;
    *(void *)(v0 + 184) = v2;
    *(void *)(v0 + 176) = 0;
    uint64_t v6 = *(void *)(v0 + 144);
    uint64_t v7 = *(void *)(v0 + 16);
    uint64_t v8 = *(void *)(v0 + 120);
    uint64_t v9 = v7 + ((v4 + 32) & ~v4);
    swift_bridgeObjectRetain(v7);
    v5(v6, v9, v8);
    __swift_storeEnumTagSinglePayload(v6, 0, 1, v8);
    if (__swift_getEnumTagSinglePayload(v6, 1, v8) != 1)
    {
      (*(void (**)(void, void, void))(*(void *)(v0 + 128) + 32))(*(void *)(v0 + 136), *(void *)(v0 + 144), *(void *)(v0 + 120));
      static Task<>.checkCancellation()();
      uint64_t v16 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type LinearSupportVectorClassifierModel<Double, String> and conformance LinearSupportVectorClassifierModel<A, B>, &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>, (uint64_t)&protocol conformance descriptor for LinearSupportVectorClassifierModel<A, B>);
      char v17 = (void *)swift_task_alloc(async function pointer to dispatch thunk of Transformer.applied(to:eventHandler:)[1]);
      *(void *)(v0 + 192) = v17;
      *char v17 = v0;
      v17[1] = specialized Transformer.applied<A>(to:eventHandler:);
      return dispatch thunk of Transformer.applied(to:eventHandler:)(*(void *)(v0 + 112), *(void *)(v0 + 136), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void *)(v0 + 48), v16);
    }
  }
  else
  {
    uint64_t v10 = *(void *)(v0 + 144);
    uint64_t v11 = *(void *)(v0 + 120);
    swift_bridgeObjectRetain(*(void *)(v0 + 16));
    __swift_storeEnumTagSinglePayload(v10, 1, 1, v11);
  }
  uint64_t v12 = *(void *)(v0 + 144);
  uint64_t v13 = *(void *)(v0 + 136);
  uint64_t v14 = *(void *)(v0 + 112);
  uint64_t v15 = *(void *)(v0 + 88);
  uint64_t v19 = *(void *)(v0 + 64);
  swift_bridgeObjectRelease(*(void *)(v0 + 16));
  swift_task_dealloc(v12);
  swift_task_dealloc(v13);
  swift_task_dealloc(v14);
  swift_task_dealloc(v15);
  swift_task_dealloc(v19);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t (*v4)();

  uint64_t v3 = *(void *)(*v1 + 192);
  uint64_t v2 = *v1;
  *(void *)(*v1 + 200) = v0;
  swift_task_dealloc(v3);
  if (v0)
  {
    swift_bridgeObjectRelease(*(void *)(v2 + 184));
    int v4 = specialized Transformer.applied<A>(to:eventHandler:);
  }
  else
  {
    int v4 = specialized Transformer.applied<A>(to:eventHandler:);
  }
  return swift_task_switch(v4, 0, 0);
}

{
  uint64_t v0;
  void *v1;
  unint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  char *v7;
  void *v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t (*v28)(void *);
  void *v29;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  void (*v38)(uint64_t);
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  void *v45;
  void *v46;

  int64_t v1 = *(void **)(v0 + 184);
  uint64_t v2 = v1[2];
  if (v1[3] >> 1 <= v2) {
    int64_t v1 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v1[3] >= 2uLL, v2 + 1, 1, *(void *)(v0 + 184));
  }
  uint64_t v3 = *(void *)(v0 + 112);
  int v4 = *(void *)(v0 + 96);
  uint64_t v5 = *(void *)(v0 + 104);
  uint64_t v6 = *(void *)(v0 + 24);
  v1[2] = v2 + 1;
  uint64_t v7 = (char *)v1 + ((*(unsigned __int8 *)(v5 + 80) + 32) & ~*(unsigned __int8 *)(v5 + 80)) + *(void *)(v5 + 72) * v2;
  uint64_t v8 = v1;
  (*(void (**)(char *, uint64_t, uint64_t))(v5 + 32))(v7, v3, v4);
  uint64_t v45 = v8;
  if (v6)
  {
    uint64_t v37 = *(void *)(v0 + 152);
    uint64_t v9 = *(void *)(v0 + 88);
    uint64_t v42 = *(void *)(v0 + 80);
    uint64_t v36 = *(void *)(v0 + 72);
    uint64_t v10 = *(void *)(v0 + 64);
    uint64_t v11 = *(void *)(v0 + 48);
    unint64_t v38 = *(void (**)(uint64_t))(v0 + 24);
    uint64_t v12 = *(void *)(v0 + 32);
    (*(void (**)(uint64_t, void, uint64_t))(*(void *)(v0 + 56) + 16))(v10, *(void *)(v0 + 40), v11);
    swift_retain();
    uint64_t v39 = String.init<A>(describing:)(v10, v11);
    uint64_t v40 = v13;
    uint64_t v41 = v45[2];
    uint64_t v14 = type metadata accessor for MetricsKey(0);
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    uint64_t v16 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, (uint64_t (*)(uint64_t))&type metadata accessor for MetricsKey, (uint64_t)&protocol conformance descriptor for MetricsKey);
    char v17 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, v14, v15, v16);
    Event.init(origin:itemCount:totalItemCount:metrics:)(v39, v40, v41, v37, 0, v17);
    v38(v9);
    _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v38, v12);
    (*(void (**)(uint64_t, uint64_t))(v42 + 8))(v9, v36);
  }
  uint64_t v18 = *(void *)(v0 + 176) + 1;
  uint64_t v19 = *(void *)(v0 + 152);
  (*(void (**)(void, void))(*(void *)(v0 + 128) + 8))(*(void *)(v0 + 136), *(void *)(v0 + 120));
  if (v18 == v19)
  {
    __swift_storeEnumTagSinglePayload(*(void *)(v0 + 144), 1, 1, *(void *)(v0 + 120));
LABEL_8:
    Swift::String v24 = *(void *)(v0 + 144);
    uint64_t v25 = *(void *)(v0 + 136);
    uint64_t v26 = *(void *)(v0 + 112);
    uint64_t v27 = *(void *)(v0 + 88);
    uint64_t v43 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(*(void *)(v0 + 16));
    swift_task_dealloc(v24);
    swift_task_dealloc(v25);
    swift_task_dealloc(v26);
    swift_task_dealloc(v27);
    swift_task_dealloc(v43);
    uint64_t v28 = *(uint64_t (**)(void *))(v0 + 8);
    uint64_t v29 = v45;
    return v28(v29);
  }
  uint64_t v20 = *(void *)(v0 + 200);
  uint64_t v21 = *(void *)(v0 + 176) + 1;
  *(void *)(v0 + 184) = v45;
  *(void *)(v0 + 176) = v21;
  uint64_t v22 = *(void *)(v0 + 120);
  uint64_t v23 = *(void *)(v0 + 144);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v0 + 168))(v23, *(void *)(v0 + 16)+ ((*(unsigned __int8 *)(v0 + 208) + 32) & ~*(unsigned __int8 *)(v0 + 208))+ *(void *)(v0 + 160) * v21, v22);
  __swift_storeEnumTagSinglePayload(v23, 0, 1, v22);
  if (__swift_getEnumTagSinglePayload(v23, 1, v22) == 1) {
    goto LABEL_8;
  }
  (*(void (**)(void, void, void))(*(void *)(v0 + 128) + 32))(*(void *)(v0 + 136), *(void *)(v0 + 144), *(void *)(v0 + 120));
  static Task<>.checkCancellation()();
  if (v20)
  {
    (*(void (**)(void, void))(*(void *)(v0 + 128) + 8))(*(void *)(v0 + 136), *(void *)(v0 + 120));
    swift_bridgeObjectRelease((_BYTE)v45);
    uint64_t v31 = *(void *)(v0 + 144);
    uint64_t v32 = *(void *)(v0 + 136);
    char v33 = *(void *)(v0 + 112);
    uint64_t v44 = *(void *)(v0 + 88);
    uint64_t v46 = *(void **)(v0 + 64);
    swift_bridgeObjectRelease(*(void *)(v0 + 16));
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v44);
    uint64_t v29 = v46;
    swift_task_dealloc(v46);
    uint64_t v28 = *(uint64_t (**)(void *))(v0 + 8);
    return v28(v29);
  }
  uint64_t v34 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type LinearSupportVectorClassifierModel<Double, String> and conformance LinearSupportVectorClassifierModel<A, B>, &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>, (uint64_t)&protocol conformance descriptor for LinearSupportVectorClassifierModel<A, B>);
  uint64_t v35 = (void *)swift_task_alloc(async function pointer to dispatch thunk of Transformer.applied(to:eventHandler:)[1]);
  *(void *)(v0 + 192) = v35;
  *uint64_t v35 = v0;
  v35[1] = specialized Transformer.applied<A>(to:eventHandler:);
  return dispatch thunk of Transformer.applied(to:eventHandler:)(*(void *)(v0 + 112), *(void *)(v0 + 136), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void *)(v0 + 48), v34);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;

  (*(void (**)(void, void))(*(void *)(v0 + 128) + 8))(*(void *)(v0 + 136), *(void *)(v0 + 120));
  int64_t v1 = *(void *)(v0 + 144);
  uint64_t v2 = *(void *)(v0 + 136);
  uint64_t v3 = *(void *)(v0 + 112);
  int v4 = *(void *)(v0 + 88);
  uint64_t v6 = *(void *)(v0 + 64);
  swift_bridgeObjectRelease(*(void *)(v0 + 16));
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  int64_t v1;
  void *v2;
  uint64_t v3;
  int v4;
  void (*v5)(uint64_t, uint64_t, uint64_t);
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  void *v17;
  uint64_t v19;

  int64_t v1 = *(void *)(*(void *)(v0 + 16) + 16);
  *(void *)(v0 + 152) = v1;
  uint64_t v2 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0, (uint64_t)_swiftEmptyArrayStorage);
  if (v1)
  {
    uint64_t v3 = *(void *)(v0 + 128);
    int v4 = *(_DWORD *)(v3 + 80);
    *(_DWORD *)(v0 + 208) = v4;
    uint64_t v5 = *(void (**)(uint64_t, uint64_t, uint64_t))(v3 + 16);
    *(void *)(v0 + 160) = *(void *)(v3 + 72);
    *(void *)(v0 + 168) = v5;
    *(void *)(v0 + 184) = v2;
    *(void *)(v0 + 176) = 0;
    uint64_t v6 = *(void *)(v0 + 144);
    uint64_t v7 = *(void *)(v0 + 16);
    uint64_t v8 = *(void *)(v0 + 120);
    uint64_t v9 = v7 + ((v4 + 32) & ~v4);
    swift_bridgeObjectRetain(v7);
    v5(v6, v9, v8);
    __swift_storeEnumTagSinglePayload(v6, 0, 1, v8);
    if (__swift_getEnumTagSinglePayload(v6, 1, v8) != 1)
    {
      (*(void (**)(void, void, void))(*(void *)(v0 + 128) + 32))(*(void *)(v0 + 136), *(void *)(v0 + 144), *(void *)(v0 + 120));
      static Task<>.checkCancellation()();
      uint64_t v16 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type LinearSupportVectorClassifierModel<Double, Int> and conformance LinearSupportVectorClassifierModel<A, B>, &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>, (uint64_t)&protocol conformance descriptor for LinearSupportVectorClassifierModel<A, B>);
      char v17 = (void *)swift_task_alloc(async function pointer to dispatch thunk of Transformer.applied(to:eventHandler:)[1]);
      *(void *)(v0 + 192) = v17;
      *char v17 = v0;
      v17[1] = specialized Transformer.applied<A>(to:eventHandler:);
      return dispatch thunk of Transformer.applied(to:eventHandler:)(*(void *)(v0 + 112), *(void *)(v0 + 136), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void *)(v0 + 48), v16);
    }
  }
  else
  {
    uint64_t v10 = *(void *)(v0 + 144);
    uint64_t v11 = *(void *)(v0 + 120);
    swift_bridgeObjectRetain(*(void *)(v0 + 16));
    __swift_storeEnumTagSinglePayload(v10, 1, 1, v11);
  }
  uint64_t v12 = *(void *)(v0 + 144);
  uint64_t v13 = *(void *)(v0 + 136);
  uint64_t v14 = *(void *)(v0 + 112);
  uint64_t v15 = *(void *)(v0 + 88);
  uint64_t v19 = *(void *)(v0 + 64);
  swift_bridgeObjectRelease(*(void *)(v0 + 16));
  swift_task_dealloc(v12);
  swift_task_dealloc(v13);
  swift_task_dealloc(v14);
  swift_task_dealloc(v15);
  swift_task_dealloc(v19);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t (*v4)();

  uint64_t v3 = *(void *)(*v1 + 192);
  uint64_t v2 = *v1;
  *(void *)(*v1 + 200) = v0;
  swift_task_dealloc(v3);
  if (v0)
  {
    swift_bridgeObjectRelease(*(void *)(v2 + 184));
    int v4 = specialized Transformer.applied<A>(to:eventHandler:);
  }
  else
  {
    int v4 = specialized Transformer.applied<A>(to:eventHandler:);
  }
  return swift_task_switch(v4, 0, 0);
}

{
  uint64_t v0;
  void *v1;
  unint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  char *v7;
  void *v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t (*v28)(void *);
  void *v29;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  void *v35;
  uint64_t v36;
  uint64_t v37;
  void (*v38)(uint64_t);
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  void *v45;
  void *v46;

  int64_t v1 = *(void **)(v0 + 184);
  uint64_t v2 = v1[2];
  if (v1[3] >> 1 <= v2) {
    int64_t v1 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v1[3] >= 2uLL, v2 + 1, 1, *(void *)(v0 + 184));
  }
  uint64_t v3 = *(void *)(v0 + 112);
  int v4 = *(void *)(v0 + 96);
  uint64_t v5 = *(void *)(v0 + 104);
  uint64_t v6 = *(void *)(v0 + 24);
  v1[2] = v2 + 1;
  uint64_t v7 = (char *)v1 + ((*(unsigned __int8 *)(v5 + 80) + 32) & ~*(unsigned __int8 *)(v5 + 80)) + *(void *)(v5 + 72) * v2;
  uint64_t v8 = v1;
  (*(void (**)(char *, uint64_t, uint64_t))(v5 + 32))(v7, v3, v4);
  uint64_t v45 = v8;
  if (v6)
  {
    uint64_t v37 = *(void *)(v0 + 152);
    uint64_t v9 = *(void *)(v0 + 88);
    uint64_t v42 = *(void *)(v0 + 80);
    uint64_t v36 = *(void *)(v0 + 72);
    uint64_t v10 = *(void *)(v0 + 64);
    uint64_t v11 = *(void *)(v0 + 48);
    unint64_t v38 = *(void (**)(uint64_t))(v0 + 24);
    uint64_t v12 = *(void *)(v0 + 32);
    (*(void (**)(uint64_t, void, uint64_t))(*(void *)(v0 + 56) + 16))(v10, *(void *)(v0 + 40), v11);
    swift_retain();
    uint64_t v39 = String.init<A>(describing:)(v10, v11);
    uint64_t v40 = v13;
    uint64_t v41 = v45[2];
    uint64_t v14 = type metadata accessor for MetricsKey(0);
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    uint64_t v16 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, (uint64_t (*)(uint64_t))&type metadata accessor for MetricsKey, (uint64_t)&protocol conformance descriptor for MetricsKey);
    char v17 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, v14, v15, v16);
    Event.init(origin:itemCount:totalItemCount:metrics:)(v39, v40, v41, v37, 0, v17);
    v38(v9);
    _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v38, v12);
    (*(void (**)(uint64_t, uint64_t))(v42 + 8))(v9, v36);
  }
  uint64_t v18 = *(void *)(v0 + 176) + 1;
  uint64_t v19 = *(void *)(v0 + 152);
  (*(void (**)(void, void))(*(void *)(v0 + 128) + 8))(*(void *)(v0 + 136), *(void *)(v0 + 120));
  if (v18 == v19)
  {
    __swift_storeEnumTagSinglePayload(*(void *)(v0 + 144), 1, 1, *(void *)(v0 + 120));
LABEL_8:
    Swift::String v24 = *(void *)(v0 + 144);
    uint64_t v25 = *(void *)(v0 + 136);
    uint64_t v26 = *(void *)(v0 + 112);
    uint64_t v27 = *(void *)(v0 + 88);
    uint64_t v43 = *(void *)(v0 + 64);
    swift_bridgeObjectRelease(*(void *)(v0 + 16));
    swift_task_dealloc(v24);
    swift_task_dealloc(v25);
    swift_task_dealloc(v26);
    swift_task_dealloc(v27);
    swift_task_dealloc(v43);
    uint64_t v28 = *(uint64_t (**)(void *))(v0 + 8);
    uint64_t v29 = v45;
    return v28(v29);
  }
  uint64_t v20 = *(void *)(v0 + 200);
  uint64_t v21 = *(void *)(v0 + 176) + 1;
  *(void *)(v0 + 184) = v45;
  *(void *)(v0 + 176) = v21;
  uint64_t v22 = *(void *)(v0 + 120);
  uint64_t v23 = *(void *)(v0 + 144);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v0 + 168))(v23, *(void *)(v0 + 16)+ ((*(unsigned __int8 *)(v0 + 208) + 32) & ~*(unsigned __int8 *)(v0 + 208))+ *(void *)(v0 + 160) * v21, v22);
  __swift_storeEnumTagSinglePayload(v23, 0, 1, v22);
  if (__swift_getEnumTagSinglePayload(v23, 1, v22) == 1) {
    goto LABEL_8;
  }
  (*(void (**)(void, void, void))(*(void *)(v0 + 128) + 32))(*(void *)(v0 + 136), *(void *)(v0 + 144), *(void *)(v0 + 120));
  static Task<>.checkCancellation()();
  if (v20)
  {
    (*(void (**)(void, void))(*(void *)(v0 + 128) + 8))(*(void *)(v0 + 136), *(void *)(v0 + 120));
    swift_bridgeObjectRelease((_BYTE)v45);
    uint64_t v31 = *(void *)(v0 + 144);
    uint64_t v32 = *(void *)(v0 + 136);
    char v33 = *(void *)(v0 + 112);
    uint64_t v44 = *(void *)(v0 + 88);
    uint64_t v46 = *(void **)(v0 + 64);
    swift_bridgeObjectRelease(*(void *)(v0 + 16));
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v33);
    swift_task_dealloc(v44);
    uint64_t v29 = v46;
    swift_task_dealloc(v46);
    uint64_t v28 = *(uint64_t (**)(void *))(v0 + 8);
    return v28(v29);
  }
  uint64_t v34 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type LinearSupportVectorClassifierModel<Double, Int> and conformance LinearSupportVectorClassifierModel<A, B>, &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>, (uint64_t)&protocol conformance descriptor for LinearSupportVectorClassifierModel<A, B>);
  uint64_t v35 = (void *)swift_task_alloc(async function pointer to dispatch thunk of Transformer.applied(to:eventHandler:)[1]);
  *(void *)(v0 + 192) = v35;
  *uint64_t v35 = v0;
  v35[1] = specialized Transformer.applied<A>(to:eventHandler:);
  return dispatch thunk of Transformer.applied(to:eventHandler:)(*(void *)(v0 + 112), *(void *)(v0 + 136), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void *)(v0 + 48), v34);
}

{
  uint64_t v0;
  int64_t v1;
  void *v2;
  uint64_t v3;
  int v4;
  void (*v5)(uint64_t, uint64_t, uint64_t);
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v17;
  uint64_t v18;
  int EnumCaseMultiPayload;
  uint64_t v20;
  void *v21;
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;

  int64_t v1 = *(void *)(*(void *)(v0 + 16) + 16);
  *(void *)(v0 + 208) = v1;
  uint64_t v2 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0, (uint64_t)_swiftEmptyArrayStorage);
  if (!v1)
  {
    uint64_t v10 = *(void *)(v0 + 200);
    uint64_t v11 = *(void *)(v0 + 176);
    swift_bridgeObjectRetain(*(void *)(v0 + 16));
    __swift_storeEnumTagSinglePayload(v10, 1, 1, v11);
    goto LABEL_5;
  }
  uint64_t v3 = *(void *)(v0 + 184);
  int v4 = *(_DWORD *)(v3 + 80);
  *(_DWORD *)(v0 + 280) = v4;
  uint64_t v5 = *(void (**)(uint64_t, uint64_t, uint64_t))(v3 + 16);
  *(void *)(v0 + 216) = *(void *)(v3 + 72);
  *(void *)(v0 + 224) = v5;
  *(void *)(v0 + 240) = v2;
  *(void *)(v0 + 232) = 0;
  uint64_t v6 = *(void *)(v0 + 200);
  uint64_t v7 = *(void *)(v0 + 16);
  uint64_t v8 = *(void *)(v0 + 176);
  uint64_t v9 = v7 + ((v4 + 32) & ~v4);
  swift_bridgeObjectRetain(v7);
  v5(v6, v9, v8);
  __swift_storeEnumTagSinglePayload(v6, 0, 1, v8);
  if (__swift_getEnumTagSinglePayload(v6, 1, v8) == 1)
  {
LABEL_5:
    uint64_t v12 = *(void *)(v0 + 200);
    uint64_t v13 = *(void *)(v0 + 192);
    uint64_t v14 = *(void *)(v0 + 168);
    uint64_t v15 = *(void *)(v0 + 144);
    uint64_t v26 = *(void *)(v0 + 128);
    uint64_t v25 = *(void *)(v0 + 104);
    Swift::String v24 = *(void *)(v0 + 80);
    uint64_t v23 = *(void *)(v0 + 56);
    swift_bridgeObjectRelease(*(void *)(v0 + 16));
    swift_task_dealloc(v12);
    swift_task_dealloc(v13);
    swift_task_dealloc(v14);
    swift_task_dealloc(v15);
    swift_task_dealloc(v26);
    swift_task_dealloc(v25);
    swift_task_dealloc(v24);
    swift_task_dealloc(v23);
    return (*(uint64_t (**)(void))(v0 + 8))();
  }
  (*(void (**)(void, void, void))(*(void *)(v0 + 184) + 32))(*(void *)(v0 + 192), *(void *)(v0 + 200), *(void *)(v0 + 176));
  static Task<>.checkCancellation()();
  char v17 = *(void *)(v0 + 144);
  uint64_t v18 = *(void *)(v0 + 136);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 40) + *(int *)(*(void *)(v0 + 48) + 20), v17, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v17, v18);
  uint64_t v20 = *(void *)(v0 + 144);
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 96) + 32))(*(void *)(v0 + 104), v20, *(void *)(v0 + 88));
    uint64_t v21 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 264) = v21;
    *uint64_t v21 = v0;
    v21[1] = specialized Transformer.applied<A>(to:eventHandler:);
    return FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 168), *(void *)(v0 + 192), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void *)(v0 + 88));
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 120) + 32))(*(void *)(v0 + 128), v20, *(void *)(v0 + 112));
    uint64_t v22 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 248) = v22;
    *uint64_t v22 = v0;
    v22[1] = specialized Transformer.applied<A>(to:eventHandler:);
    return LogisticRegressionClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 168), *(void *)(v0 + 192), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void *)(v0 + 112));
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 248);
  *(void *)(*(void *)v1 + 256) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized Transformer.applied<A>(to:eventHandler:);
  }
  else {
    uint64_t v3 = specialized Transformer.applied<A>(to:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 264);
  *(void *)(*(void *)v1 + 272) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized Transformer.applied<A>(to:eventHandler:);
  }
  else {
    uint64_t v3 = specialized Transformer.applied<A>(to:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  void *v1;
  unint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  char *v7;
  void *v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t (*v27)(void *);
  void *v28;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  int EnumCaseMultiPayload;
  uint64_t v36;
  void *v37;
  void *v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  void (*v52)(uint64_t);
  uint64_t v53;
  uint64_t v54;
  void *v55;
  void *v56;

  (*(void (**)(void, void))(*(void *)(v0 + 120) + 8))(*(void *)(v0 + 128), *(void *)(v0 + 112));
  int64_t v1 = *(void **)(v0 + 240);
  uint64_t v43 = *(void *)(v0 + 256);
  uint64_t v2 = v1[2];
  if (v1[3] >> 1 <= v2) {
    int64_t v1 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v1[3] >= 2uLL, v2 + 1, 1, (uint64_t)v1);
  }
  uint64_t v3 = *(void *)(v0 + 168);
  int v4 = *(void *)(v0 + 152);
  uint64_t v5 = *(void *)(v0 + 160);
  uint64_t v6 = *(void *)(v0 + 24);
  v1[2] = v2 + 1;
  uint64_t v7 = (char *)v1 + ((*(unsigned __int8 *)(v5 + 80) + 32) & ~*(unsigned __int8 *)(v5 + 80)) + *(void *)(v5 + 72) * v2;
  uint64_t v8 = v1;
  (*(void (**)(char *, uint64_t, uint64_t))(v5 + 32))(v7, v3, v4);
  uint64_t v55 = v8;
  if (v6)
  {
    uint64_t v39 = *(void *)(v0 + 208);
    uint64_t v9 = *(void *)(v0 + 80);
    uint64_t v46 = *(void *)(v0 + 72);
    uint64_t v49 = *(void *)(v0 + 64);
    uint64_t v10 = *(void *)(v0 + 56);
    uint64_t v11 = *(void *)(v0 + 48);
    uint64_t v52 = *(void (**)(uint64_t))(v0 + 24);
    uint64_t v12 = *(void *)(v0 + 32);
    outlined init with copy of MLSoundClassifier.Model(*(void *)(v0 + 40), v10);
    swift_retain();
    uint64_t v40 = String.init<A>(describing:)(v10, v11);
    uint64_t v41 = v13;
    uint64_t v42 = v55[2];
    uint64_t v14 = type metadata accessor for MetricsKey(0);
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    uint64_t v16 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, (uint64_t (*)(uint64_t))&type metadata accessor for MetricsKey, (uint64_t)&protocol conformance descriptor for MetricsKey);
    char v17 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, v14, v15, v16);
    Event.init(origin:itemCount:totalItemCount:metrics:)(v40, v41, v42, v39, 0, v17);
    v52(v9);
    _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v52, v12);
    (*(void (**)(uint64_t, uint64_t))(v46 + 8))(v9, v49);
  }
  uint64_t v18 = *(void *)(v0 + 232) + 1;
  uint64_t v19 = *(void *)(v0 + 208);
  (*(void (**)(void, void))(*(void *)(v0 + 184) + 8))(*(void *)(v0 + 192), *(void *)(v0 + 176));
  if (v18 == v19)
  {
    __swift_storeEnumTagSinglePayload(*(void *)(v0 + 200), 1, 1, *(void *)(v0 + 176));
LABEL_8:
    uint64_t v23 = *(void *)(v0 + 200);
    Swift::String v24 = *(void *)(v0 + 192);
    uint64_t v25 = *(void *)(v0 + 168);
    uint64_t v26 = *(void *)(v0 + 144);
    uint64_t v53 = *(void *)(v0 + 128);
    uint64_t v50 = *(void *)(v0 + 104);
    uint64_t v47 = *(void *)(v0 + 80);
    uint64_t v44 = *(void *)(v0 + 56);
    swift_bridgeObjectRelease(*(void *)(v0 + 16));
    swift_task_dealloc(v23);
    swift_task_dealloc(v24);
    swift_task_dealloc(v25);
    swift_task_dealloc(v26);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    swift_task_dealloc(v47);
    swift_task_dealloc(v44);
    uint64_t v27 = *(uint64_t (**)(void *))(v0 + 8);
    uint64_t v28 = v55;
    return v27(v28);
  }
  uint64_t v20 = *(void *)(v0 + 232) + 1;
  *(void *)(v0 + 240) = v55;
  *(void *)(v0 + 232) = v20;
  uint64_t v21 = *(void *)(v0 + 176);
  uint64_t v22 = *(void *)(v0 + 200);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v0 + 224))(v22, *(void *)(v0 + 16)+ ((*(unsigned __int8 *)(v0 + 280) + 32) & ~*(unsigned __int8 *)(v0 + 280))+ *(void *)(v0 + 216) * v20, v21);
  __swift_storeEnumTagSinglePayload(v22, 0, 1, v21);
  if (__swift_getEnumTagSinglePayload(v22, 1, v21) == 1) {
    goto LABEL_8;
  }
  (*(void (**)(void, void, void))(*(void *)(v0 + 184) + 32))(*(void *)(v0 + 192), *(void *)(v0 + 200), *(void *)(v0 + 176));
  static Task<>.checkCancellation()();
  if (v43)
  {
    (*(void (**)(void, void))(*(void *)(v0 + 184) + 8))(*(void *)(v0 + 192), *(void *)(v0 + 176));
    swift_bridgeObjectRelease((_BYTE)v55);
    uint64_t v30 = *(void *)(v0 + 200);
    uint64_t v31 = *(void *)(v0 + 192);
    uint64_t v32 = *(void *)(v0 + 168);
    uint64_t v54 = *(void *)(v0 + 144);
    uint64_t v51 = *(void *)(v0 + 128);
    uint64_t v48 = *(void *)(v0 + 104);
    uint64_t v45 = *(void *)(v0 + 80);
    uint64_t v56 = *(void **)(v0 + 56);
    swift_bridgeObjectRelease(*(void *)(v0 + 16));
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v54);
    swift_task_dealloc(v51);
    swift_task_dealloc(v48);
    swift_task_dealloc(v45);
    uint64_t v28 = v56;
    swift_task_dealloc(v56);
    uint64_t v27 = *(uint64_t (**)(void *))(v0 + 8);
    return v27(v28);
  }
  char v33 = *(void *)(v0 + 144);
  uint64_t v34 = *(void *)(v0 + 136);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 40) + *(int *)(*(void *)(v0 + 48) + 20), v33, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v33, v34);
  uint64_t v36 = *(void *)(v0 + 144);
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 96) + 32))(*(void *)(v0 + 104), v36, *(void *)(v0 + 88));
    uint64_t v37 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 264) = v37;
    *uint64_t v37 = v0;
    v37[1] = specialized Transformer.applied<A>(to:eventHandler:);
    return FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 168), *(void *)(v0 + 192), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void *)(v0 + 88));
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 120) + 32))(*(void *)(v0 + 128), v36, *(void *)(v0 + 112));
    unint64_t v38 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 248) = v38;
    *unint64_t v38 = v0;
    v38[1] = specialized Transformer.applied<A>(to:eventHandler:);
    return LogisticRegressionClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 168), *(void *)(v0 + 192), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void *)(v0 + 112));
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  int64_t v1 = *(void *)(v0 + 240);
  uint64_t v2 = *(void *)(v0 + 192);
  uint64_t v3 = *(void *)(v0 + 184);
  int v4 = *(void *)(v0 + 176);
  (*(void (**)(void, void))(*(void *)(v0 + 120) + 8))(*(void *)(v0 + 128), *(void *)(v0 + 112));
  swift_bridgeObjectRelease(v1);
  (*(void (**)(uint64_t, uint64_t))(v3 + 8))(v2, v4);
  uint64_t v5 = *(void *)(v0 + 200);
  uint64_t v6 = *(void *)(v0 + 192);
  uint64_t v7 = *(void *)(v0 + 168);
  uint64_t v8 = *(void *)(v0 + 144);
  uint64_t v13 = *(void *)(v0 + 128);
  uint64_t v12 = *(void *)(v0 + 104);
  uint64_t v11 = *(void *)(v0 + 80);
  uint64_t v10 = *(void *)(v0 + 56);
  swift_bridgeObjectRelease(*(void *)(v0 + 16));
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  void *v1;
  unint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  char *v7;
  void *v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t (*v27)(void *);
  void *v28;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  int EnumCaseMultiPayload;
  uint64_t v36;
  void *v37;
  void *v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  void (*v52)(uint64_t);
  uint64_t v53;
  uint64_t v54;
  void *v55;
  void *v56;

  (*(void (**)(void, void))(*(void *)(v0 + 96) + 8))(*(void *)(v0 + 104), *(void *)(v0 + 88));
  int64_t v1 = *(void **)(v0 + 240);
  uint64_t v43 = *(void *)(v0 + 272);
  uint64_t v2 = v1[2];
  if (v1[3] >> 1 <= v2) {
    int64_t v1 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v1[3] >= 2uLL, v2 + 1, 1, (uint64_t)v1);
  }
  uint64_t v3 = *(void *)(v0 + 168);
  int v4 = *(void *)(v0 + 152);
  uint64_t v5 = *(void *)(v0 + 160);
  uint64_t v6 = *(void *)(v0 + 24);
  v1[2] = v2 + 1;
  uint64_t v7 = (char *)v1 + ((*(unsigned __int8 *)(v5 + 80) + 32) & ~*(unsigned __int8 *)(v5 + 80)) + *(void *)(v5 + 72) * v2;
  uint64_t v8 = v1;
  (*(void (**)(char *, uint64_t, uint64_t))(v5 + 32))(v7, v3, v4);
  uint64_t v55 = v8;
  if (v6)
  {
    uint64_t v39 = *(void *)(v0 + 208);
    uint64_t v9 = *(void *)(v0 + 80);
    uint64_t v46 = *(void *)(v0 + 72);
    uint64_t v49 = *(void *)(v0 + 64);
    uint64_t v10 = *(void *)(v0 + 56);
    uint64_t v11 = *(void *)(v0 + 48);
    uint64_t v52 = *(void (**)(uint64_t))(v0 + 24);
    uint64_t v12 = *(void *)(v0 + 32);
    outlined init with copy of MLSoundClassifier.Model(*(void *)(v0 + 40), v10);
    swift_retain();
    uint64_t v40 = String.init<A>(describing:)(v10, v11);
    uint64_t v41 = v13;
    uint64_t v42 = v55[2];
    uint64_t v14 = type metadata accessor for MetricsKey(0);
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    uint64_t v16 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, (uint64_t (*)(uint64_t))&type metadata accessor for MetricsKey, (uint64_t)&protocol conformance descriptor for MetricsKey);
    char v17 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, v14, v15, v16);
    Event.init(origin:itemCount:totalItemCount:metrics:)(v40, v41, v42, v39, 0, v17);
    v52(v9);
    _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v52, v12);
    (*(void (**)(uint64_t, uint64_t))(v46 + 8))(v9, v49);
  }
  uint64_t v18 = *(void *)(v0 + 232) + 1;
  uint64_t v19 = *(void *)(v0 + 208);
  (*(void (**)(void, void))(*(void *)(v0 + 184) + 8))(*(void *)(v0 + 192), *(void *)(v0 + 176));
  if (v18 == v19)
  {
    __swift_storeEnumTagSinglePayload(*(void *)(v0 + 200), 1, 1, *(void *)(v0 + 176));
LABEL_8:
    uint64_t v23 = *(void *)(v0 + 200);
    Swift::String v24 = *(void *)(v0 + 192);
    uint64_t v25 = *(void *)(v0 + 168);
    uint64_t v26 = *(void *)(v0 + 144);
    uint64_t v53 = *(void *)(v0 + 128);
    uint64_t v50 = *(void *)(v0 + 104);
    uint64_t v47 = *(void *)(v0 + 80);
    uint64_t v44 = *(void *)(v0 + 56);
    swift_bridgeObjectRelease(*(void *)(v0 + 16));
    swift_task_dealloc(v23);
    swift_task_dealloc(v24);
    swift_task_dealloc(v25);
    swift_task_dealloc(v26);
    swift_task_dealloc(v53);
    swift_task_dealloc(v50);
    swift_task_dealloc(v47);
    swift_task_dealloc(v44);
    uint64_t v27 = *(uint64_t (**)(void *))(v0 + 8);
    uint64_t v28 = v55;
    return v27(v28);
  }
  uint64_t v20 = *(void *)(v0 + 232) + 1;
  *(void *)(v0 + 240) = v55;
  *(void *)(v0 + 232) = v20;
  uint64_t v21 = *(void *)(v0 + 176);
  uint64_t v22 = *(void *)(v0 + 200);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v0 + 224))(v22, *(void *)(v0 + 16)+ ((*(unsigned __int8 *)(v0 + 280) + 32) & ~*(unsigned __int8 *)(v0 + 280))+ *(void *)(v0 + 216) * v20, v21);
  __swift_storeEnumTagSinglePayload(v22, 0, 1, v21);
  if (__swift_getEnumTagSinglePayload(v22, 1, v21) == 1) {
    goto LABEL_8;
  }
  (*(void (**)(void, void, void))(*(void *)(v0 + 184) + 32))(*(void *)(v0 + 192), *(void *)(v0 + 200), *(void *)(v0 + 176));
  static Task<>.checkCancellation()();
  if (v43)
  {
    (*(void (**)(void, void))(*(void *)(v0 + 184) + 8))(*(void *)(v0 + 192), *(void *)(v0 + 176));
    swift_bridgeObjectRelease((_BYTE)v55);
    uint64_t v30 = *(void *)(v0 + 200);
    uint64_t v31 = *(void *)(v0 + 192);
    uint64_t v32 = *(void *)(v0 + 168);
    uint64_t v54 = *(void *)(v0 + 144);
    uint64_t v51 = *(void *)(v0 + 128);
    uint64_t v48 = *(void *)(v0 + 104);
    uint64_t v45 = *(void *)(v0 + 80);
    uint64_t v56 = *(void **)(v0 + 56);
    swift_bridgeObjectRelease(*(void *)(v0 + 16));
    swift_task_dealloc(v30);
    swift_task_dealloc(v31);
    swift_task_dealloc(v32);
    swift_task_dealloc(v54);
    swift_task_dealloc(v51);
    swift_task_dealloc(v48);
    swift_task_dealloc(v45);
    uint64_t v28 = v56;
    swift_task_dealloc(v56);
    uint64_t v27 = *(uint64_t (**)(void *))(v0 + 8);
    return v27(v28);
  }
  char v33 = *(void *)(v0 + 144);
  uint64_t v34 = *(void *)(v0 + 136);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 40) + *(int *)(*(void *)(v0 + 48) + 20), v33, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v33, v34);
  uint64_t v36 = *(void *)(v0 + 144);
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 96) + 32))(*(void *)(v0 + 104), v36, *(void *)(v0 + 88));
    uint64_t v37 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 264) = v37;
    *uint64_t v37 = v0;
    v37[1] = specialized Transformer.applied<A>(to:eventHandler:);
    return FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 168), *(void *)(v0 + 192), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void *)(v0 + 88));
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 120) + 32))(*(void *)(v0 + 128), v36, *(void *)(v0 + 112));
    unint64_t v38 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 248) = v38;
    *unint64_t v38 = v0;
    v38[1] = specialized Transformer.applied<A>(to:eventHandler:);
    return LogisticRegressionClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 168), *(void *)(v0 + 192), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void *)(v0 + 112));
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  int64_t v1 = *(void *)(v0 + 240);
  uint64_t v2 = *(void *)(v0 + 192);
  uint64_t v3 = *(void *)(v0 + 184);
  int v4 = *(void *)(v0 + 176);
  (*(void (**)(void, void))(*(void *)(v0 + 96) + 8))(*(void *)(v0 + 104), *(void *)(v0 + 88));
  swift_bridgeObjectRelease(v1);
  (*(void (**)(uint64_t, uint64_t))(v3 + 8))(v2, v4);
  uint64_t v5 = *(void *)(v0 + 200);
  uint64_t v6 = *(void *)(v0 + 192);
  uint64_t v7 = *(void *)(v0 + 168);
  uint64_t v8 = *(void *)(v0 + 144);
  uint64_t v13 = *(void *)(v0 + 128);
  uint64_t v12 = *(void *)(v0 + 104);
  uint64_t v11 = *(void *)(v0 + 80);
  uint64_t v10 = *(void *)(v0 + 56);
  swift_bridgeObjectRelease(*(void *)(v0 + 16));
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  return specialized Transformer.applied<A>(to:eventHandler:)();
}

uint64_t MLSupportVectorClassifier.Model.applied(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v5[13] = v4;
  v5[12] = a4;
  v5[11] = a3;
  v5[10] = a2;
  v5[9] = a1;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<ClassificationDistribution<Int>>);
  v5[14] = v6;
  uint64_t v7 = *(void *)(v6 - 8);
  v5[15] = v7;
  v5[16] = swift_task_alloc((*(void *)(v7 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  v5[17] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v5[18] = v9;
  v5[19] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>);
  v5[20] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v5[21] = v11;
  v5[22] = swift_task_alloc((*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<ClassificationDistribution<String>>);
  v5[23] = v12;
  uint64_t v13 = *(void *)(v12 - 8);
  v5[24] = v13;
  v5[25] = swift_task_alloc((*(void *)(v13 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  v5[26] = v14;
  uint64_t v15 = *(void *)(v14 - 8);
  v5[27] = v15;
  v5[28] = swift_task_alloc((*(void *)(v15 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>);
  v5[29] = v16;
  uint64_t v17 = *(void *)(v16 - 8);
  v5[30] = v17;
  v5[31] = swift_task_alloc((*(void *)(v17 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
  v5[32] = v18;
  v5[33] = swift_task_alloc((*(void *)(*(void *)(v18 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v19 = type metadata accessor for AnyColumn(0);
  v5[34] = v19;
  uint64_t v20 = *(void *)(v19 - 8);
  v5[35] = v20;
  unint64_t v21 = (*(void *)(v20 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v5[36] = swift_task_alloc(v21);
  v5[37] = swift_task_alloc(v21);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  v5[38] = v22;
  uint64_t v23 = *(void *)(v22 - 8);
  v5[39] = v23;
  v5[40] = swift_task_alloc((*(void *)(v23 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLSupportVectorClassifier.Model.applied(to:eventHandler:), 0, 0);
}

uint64_t MLSupportVectorClassifier.Model.applied(to:eventHandler:)()
{
  specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(v0[10], 0, *(void *)(v0[13] + 16), *(void *)(v0[13] + 24), *(void *)(v0[13] + 32));
  uint64_t v1 = v0[33];
  uint64_t v2 = v0[13];
  uint64_t v3 = v0[32];
  uint64_t v4 = static MLSupportVectorClassifier.Model.buildFeatures(from:)(v0[40]);
  v0[41] = (uint64_t)v4;
  uint64_t v5 = type metadata accessor for MLSupportVectorClassifier.Model(0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v2 + *(int *)(v5 + 24), v1, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v1, v3);
  uint64_t v7 = v0[33];
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v0[21] + 32))(v0[22], v7, v0[20]);
    uint64_t v8 = (char *)&async function pointer to specialized Transformer.applied<A>(to:eventHandler:)
       + async function pointer to specialized Transformer.applied<A>(to:eventHandler:);
    uint64_t v9 = (uint64_t **)swift_task_alloc(dword_3ADEB4);
    v0[45] = (uint64_t)v9;
    *uint64_t v9 = v0;
    v9[1] = (uint64_t *)MLSupportVectorClassifier.Model.applied(to:eventHandler:);
  }
  else
  {
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v0[30] + 32))(v0[31], v7, v0[29]);
    uint64_t v8 = (char *)&async function pointer to specialized Transformer.applied<A>(to:eventHandler:)
       + async function pointer to specialized Transformer.applied<A>(to:eventHandler:);
    uint64_t v10 = (uint64_t **)swift_task_alloc(dword_3ADEBC);
    v0[42] = (uint64_t)v10;
    *uint64_t v10 = v0;
    v10[1] = (uint64_t *)MLSupportVectorClassifier.Model.applied(to:eventHandler:);
  }
  return ((uint64_t (*)(void *, uint64_t, uint64_t))v8)(v4, v0[11], v0[12]);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  Swift::String v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;
  void (*v19)(uint64_t, uint64_t);
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;

  uint64_t v41 = *(void *)(v0 + 352);
  uint64_t v32 = *(void *)(v0 + 224);
  uint64_t v43 = *(void *)(v0 + 216);
  uint64_t v29 = *(void *)(v0 + 208);
  uint64_t v1 = *(uint64_t **)(v0 + 104);
  uint64_t v34 = *v1;
  uint64_t v2 = v1[1];
  swift_bridgeObjectRetain(v2);
  *(void *)(v0 + 56) = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d129ML25MLSupportVectorClassifierV5ModelV7applied2to12eventHandler11TabularData0L5FrameVAK_y0A12MLComponents5EventVYbcSgtYaKFSSSgAL26fG56VySSGcfu_32f90808cfe034de74f1d450820ef1a2faAsPTf3nnnpk_nTf1cn_n(v41);
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String?]);
  uint64_t v4 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [String?] and conformance [A], &demangling cache variable for type metadata for [String?], (uint64_t)&protocol conformance descriptor for [A]);
  Column.init<A>(name:contents:)(v34, v2, v0 + 56, &type metadata for String, v3, v4);
  Column.eraseToAnyColumn()(v29);
  (*(void (**)(uint64_t, uint64_t))(v43 + 8))(v32, v29);
  unint64_t v21 = *v1;
  uint64_t v22 = v1[1];
  swift_bridgeObjectRetain(v22);
  v5._uint64_t countAndFlagsBits = 0x6C696261626F7250;
  v5._char object = (void *)0xEB00000000797469;
  String.append(_:)(v5);
  *(void *)(v0 + 64) = v41;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [ClassificationDistribution<String>]);
  uint64_t v8 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [ClassificationDistribution<String>] and conformance [A], &demangling cache variable for type metadata for [ClassificationDistribution<String>], (uint64_t)&protocol conformance descriptor for [A]);
  Column.init<A>(name:contents:)(v21, v22, v0 + 64, v6, v7, v8);
  uint64_t v25 = *(void *)(v0 + 248);
  uint64_t v37 = *(void *)(v0 + 240);
  uint64_t v27 = *(void *)(v0 + 232);
  uint64_t v35 = *(void *)(v0 + 200);
  uint64_t v9 = *(void *)(v0 + 192);
  uint64_t v10 = *(void *)(v0 + 184);
  uint64_t v23 = *(void *)(v0 + 320);
  uint64_t v36 = *(void *)(v0 + 312);
  Swift::String v24 = *(void *)(v0 + 304);
  uint64_t v39 = *(void *)(v0 + 296);
  uint64_t v26 = *(void *)(v0 + 288);
  uint64_t v42 = *(void *)(v0 + 280);
  uint64_t v40 = *(void *)(v0 + 272);
  char v33 = *(void *)(v0 + 264);
  uint64_t v31 = *(void *)(v0 + 224);
  uint64_t v30 = *(void *)(v0 + 176);
  uint64_t v28 = *(void *)(v0 + 152);
  uint64_t v44 = *(void *)(v0 + 128);
  Column.eraseToAnyColumn()(v10);
  (*(void (**)(uint64_t, uint64_t))(v9 + 8))(v35, v10);
  (*(void (**)(uint64_t, uint64_t))(v37 + 8))(v25, v27);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  unint64_t v38 = *(void *)(v42 + 72);
  uint64_t v12 = *(unsigned __int8 *)(v42 + 80);
  uint64_t v13 = (v12 + 32) & ~v12;
  uint64_t v14 = swift_allocObject(v11, v13 + 2 * v38, v12 | 7);
  *(void *)(v14 + 16) = 2;
  *(void *)(v14 + 24) = 4;
  uint64_t v15 = v14 + v13;
  uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v42 + 16);
  v16(v15, v39, v40);
  v16(v38 + v15, v26, v40);
  *(void *)(v0 + 40) = v14;
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  uint64_t v18 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn], (uint64_t)&protocol conformance descriptor for [A]);
  DataFrame.init<A>(columns:)(v0 + 40, v17, v18);
  uint64_t v19 = *(void (**)(uint64_t, uint64_t))(v42 + 8);
  v19(v26, v40);
  v19(v39, v40);
  (*(void (**)(uint64_t, uint64_t))(v36 + 8))(v23, v24);
  swift_task_dealloc(v23);
  swift_task_dealloc(v39);
  swift_task_dealloc(v26);
  swift_task_dealloc(v33);
  swift_task_dealloc(v25);
  swift_task_dealloc(v31);
  swift_task_dealloc(v35);
  swift_task_dealloc(v30);
  swift_task_dealloc(v28);
  swift_task_dealloc(v44);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  Swift::String v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void (*v16)(uint64_t, uint64_t, uint64_t);
  uint64_t v17;
  uint64_t v18;
  void (*v19)(uint64_t, uint64_t);
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;

  uint64_t v41 = *(void *)(v0 + 376);
  uint64_t v32 = *(void *)(v0 + 152);
  uint64_t v43 = *(void *)(v0 + 144);
  uint64_t v30 = *(void *)(v0 + 136);
  uint64_t v1 = *(uint64_t **)(v0 + 104);
  uint64_t v34 = *v1;
  uint64_t v2 = v1[1];
  swift_bridgeObjectRetain(v2);
  *(void *)(v0 + 24) = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d129ML25MLSupportVectorClassifierV5ModelV7applied2to12eventHandler11TabularData0L5FrameVAK_y0A12MLComponents5EventVYbcSgtYaKFSiSgAL26fG57VySiGcfu0_32be6a1569bf578dffa8811060c9259ebeAsPTf3nnnpk_nTf1cn_n(v41);
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int?]);
  uint64_t v4 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Int?] and conformance [A], &demangling cache variable for type metadata for [Int?], (uint64_t)&protocol conformance descriptor for [A]);
  Column.init<A>(name:contents:)(v34, v2, v0 + 24, &type metadata for Int, v3, v4);
  Column.eraseToAnyColumn()(v30);
  (*(void (**)(uint64_t, uint64_t))(v43 + 8))(v32, v30);
  unint64_t v21 = *v1;
  uint64_t v22 = v1[1];
  swift_bridgeObjectRetain(v22);
  v5._uint64_t countAndFlagsBits = 0x6C696261626F7250;
  v5._char object = (void *)0xEB00000000797469;
  String.append(_:)(v5);
  *(void *)(v0 + 32) = v41;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<Int>);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [ClassificationDistribution<Int>]);
  uint64_t v8 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [ClassificationDistribution<Int>] and conformance [A], &demangling cache variable for type metadata for [ClassificationDistribution<Int>], (uint64_t)&protocol conformance descriptor for [A]);
  Column.init<A>(name:contents:)(v21, v22, v0 + 32, v6, v7, v8);
  uint64_t v36 = *(void *)(v0 + 176);
  uint64_t v37 = *(void *)(v0 + 168);
  uint64_t v27 = *(void *)(v0 + 160);
  uint64_t v28 = *(void *)(v0 + 128);
  uint64_t v9 = *(void *)(v0 + 120);
  uint64_t v10 = *(void *)(v0 + 112);
  Swift::String v24 = *(void *)(v0 + 320);
  uint64_t v23 = *(void *)(v0 + 312);
  uint64_t v25 = *(void *)(v0 + 304);
  uint64_t v39 = *(void *)(v0 + 296);
  uint64_t v26 = *(void *)(v0 + 288);
  uint64_t v42 = *(void *)(v0 + 280);
  uint64_t v40 = *(void *)(v0 + 272);
  uint64_t v35 = *(void *)(v0 + 264);
  char v33 = *(void *)(v0 + 248);
  uint64_t v31 = *(void *)(v0 + 224);
  uint64_t v29 = *(void *)(v0 + 200);
  uint64_t v44 = *(void *)(v0 + 152);
  Column.eraseToAnyColumn()(v10);
  (*(void (**)(uint64_t, uint64_t))(v9 + 8))(v28, v10);
  (*(void (**)(uint64_t, uint64_t))(v37 + 8))(v36, v27);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  unint64_t v38 = *(void *)(v42 + 72);
  uint64_t v12 = *(unsigned __int8 *)(v42 + 80);
  uint64_t v13 = (v12 + 32) & ~v12;
  uint64_t v14 = swift_allocObject(v11, v13 + 2 * v38, v12 | 7);
  *(void *)(v14 + 16) = 2;
  *(void *)(v14 + 24) = 4;
  uint64_t v15 = v14 + v13;
  uint64_t v16 = *(void (**)(uint64_t, uint64_t, uint64_t))(v42 + 16);
  v16(v15, v39, v40);
  v16(v38 + v15, v26, v40);
  *(void *)(v0 + 40) = v14;
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  uint64_t v18 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn], (uint64_t)&protocol conformance descriptor for [A]);
  DataFrame.init<A>(columns:)(v0 + 40, v17, v18);
  uint64_t v19 = *(void (**)(uint64_t, uint64_t))(v42 + 8);
  v19(v26, v40);
  v19(v39, v40);
  (*(void (**)(uint64_t, uint64_t))(v23 + 8))(v24, v25);
  swift_task_dealloc(v24);
  swift_task_dealloc(v39);
  swift_task_dealloc(v26);
  swift_task_dealloc(v35);
  swift_task_dealloc(v33);
  swift_task_dealloc(v31);
  swift_task_dealloc(v29);
  swift_task_dealloc(v36);
  swift_task_dealloc(v44);
  swift_task_dealloc(v28);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;

  uint64_t v1 = *(void *)(v0 + 328);
  uint64_t v2 = *(void *)(v0 + 320);
  uint64_t v3 = *(void *)(v0 + 312);
  uint64_t v4 = *(void *)(v0 + 304);
  (*(void (**)(void, void))(*(void *)(v0 + 240) + 8))(*(void *)(v0 + 248), *(void *)(v0 + 232));
  (*(void (**)(uint64_t, uint64_t))(v3 + 8))(v2, v4);
  swift_bridgeObjectRelease(v1);
  uint64_t v5 = *(void *)(v0 + 296);
  uint64_t v6 = *(void *)(v0 + 288);
  uint64_t v7 = *(void *)(v0 + 264);
  uint64_t v8 = *(void *)(v0 + 248);
  uint64_t v14 = *(void *)(v0 + 224);
  uint64_t v13 = *(void *)(v0 + 200);
  uint64_t v12 = *(void *)(v0 + 176);
  uint64_t v10 = *(void *)(v0 + 128);
  uint64_t v11 = *(void *)(v0 + 152);
  swift_task_dealloc(*(void *)(v0 + 320));
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;

  uint64_t v1 = *(void *)(v0 + 328);
  uint64_t v2 = *(void *)(v0 + 320);
  uint64_t v3 = *(void *)(v0 + 312);
  uint64_t v4 = *(void *)(v0 + 304);
  (*(void (**)(void, void))(*(void *)(v0 + 168) + 8))(*(void *)(v0 + 176), *(void *)(v0 + 160));
  (*(void (**)(uint64_t, uint64_t))(v3 + 8))(v2, v4);
  swift_bridgeObjectRelease(v1);
  uint64_t v5 = *(void *)(v0 + 296);
  uint64_t v6 = *(void *)(v0 + 288);
  uint64_t v7 = *(void *)(v0 + 264);
  uint64_t v8 = *(void *)(v0 + 248);
  uint64_t v14 = *(void *)(v0 + 224);
  uint64_t v13 = *(void *)(v0 + 200);
  uint64_t v12 = *(void *)(v0 + 176);
  uint64_t v10 = *(void *)(v0 + 128);
  uint64_t v11 = *(void *)(v0 + 152);
  swift_task_dealloc(*(void *)(v0 + 320));
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLSupportVectorClassifier.Model.applied(to:eventHandler:)(uint64_t a1)
{
  uint64_t v5 = *(void *)(*v2 + 336);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 344) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = MLSupportVectorClassifier.Model.applied(to:eventHandler:);
  }
  else
  {
    swift_bridgeObjectRelease(*(void *)(v4 + 328));
    *(void *)(v4 + 352) = a1;
    uint64_t v6 = MLSupportVectorClassifier.Model.applied(to:eventHandler:);
  }
  return swift_task_switch(v6, 0, 0);
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  uint64_t (*v6)();

  uint64_t v5 = *(void *)(*v2 + 360);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 368) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = MLSupportVectorClassifier.Model.applied(to:eventHandler:);
  }
  else
  {
    swift_bridgeObjectRelease(*(void *)(v4 + 328));
    *(void *)(v4 + 376) = a1;
    uint64_t v6 = MLSupportVectorClassifier.Model.applied(to:eventHandler:);
  }
  return swift_task_switch(v6, 0, 0);
}

void *static MLSupportVectorClassifier.Model.buildFeatures(from:)(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  uint64_t v2 = *(void *)(v1 - 8);
  int64_t v3 = *(void *)(v2 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v35 = &v28;
  uint64_t v6 = alloca(v3);
  uint64_t v7 = alloca(v3);
  uint64_t v37 = &v28;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  int64_t v9 = DenseMatrix.rowCount.getter(v8);
  if (v9 <= 0) {
    int64_t v9 = 0;
  }
  uint64_t v10 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v9, 0, (uint64_t)_swiftEmptyArrayStorage);
  uint64_t v32 = v8;
  uint64_t v31 = a1;
  uint64_t v11 = DenseMatrix.rowCount.getter(v8);
  uint64_t v33 = v11;
  if (v11 < 0) {
    BUG();
  }
  if (v11)
  {
    uint64_t v12 = 0;
    uint64_t v13 = v37;
    uint64_t v14 = 0;
    uint64_t v36 = v1;
    uint64_t v34 = v2;
    do
    {
      uint64_t v38 = v14;
      uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
      uint64_t v16 = (void *)swift_allocObject(v15, 40, 7);
      v16[2] = 1;
      void v16[3] = 2;
      uint64_t v17 = v12;
      uint64_t v18 = v31;
      void v16[4] = DenseMatrix.columnCount.getter(v32);
      uint64_t v19 = alloca(32);
      uint64_t v20 = alloca(32);
      uint64_t v30 = v18;
      uint64_t v29 = v17;
      uint64_t v31 = v17;
      uint64_t v21 = v38;
      MLShapedArray.init(unsafeUninitializedShape:initializingWith:)(v16, partial apply for closure #1 in static MLSupportVectorClassifier.Model.buildFeatures(from:), &v28, &type metadata for Double, &protocol witness table for Double);
      uint64_t v38 = v21;
      uint64_t v22 = v34;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v34 + 16))(v35, v13, v36);
      unint64_t v23 = v10[2];
      if (v10[3] >> 1 <= v23) {
        uint64_t v10 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v10[3] >= 2uLL, v23 + 1, 1, (uint64_t)v10);
      }
      uint64_t v24 = v29 + 1;
      void v10[2] = v23 + 1;
      uint64_t v12 = v24;
      uint64_t v25 = (char *)v10
          + ((*(unsigned __int8 *)(v22 + 80) + 32) & ~*(unsigned __int8 *)(v22 + 80))
          + *(void *)(v22 + 72) * v23;
      uint64_t v26 = v36;
      (*(void (**)(char *, uint64_t *, uint64_t))(v22 + 32))(v25, v35, v36);
      uint64_t v13 = v37;
      (*(void (**)(uint64_t *, uint64_t))(v22 + 8))(v37, v26);
      uint64_t v14 = v38;
    }
    while (v33 != v12);
  }
  return v10;
}

uint64_t key path getter for ClassificationDistribution.mostLikelyLabel : ClassificationDistribution<Int>()
{
  uint64_t v1 = v0;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<Int>);
  ClassificationDistribution.mostLikelyLabel.getter(v2);
  uint64_t result = v4;
  *(void *)uint64_t v1 = v4;
  *(unsigned char *)(v1 + 8) = v5;
  return result;
}

uint64_t closure #1 in static MLSupportVectorClassifier.Model.buildFeatures(from:)(uint64_t *a1, uint64_t a2, uint64_t a3, unint64_t a4)
{
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  uint64_t result = DenseMatrix.columnCount.getter(v5);
  if (result < 0) {
    BUG();
  }
  if (result)
  {
    unint64_t v7 = a4;
    uint64_t v15 = *a1;
    unint64_t v8 = 0;
    uint64_t v14 = result;
    do
    {
      unint64_t v9 = v7;
      uint64_t v10 = specialized DenseMatrix.subscript.read(v12, v7, v8);
      uint64_t v13 = *v11;
      ((void (*)(double *, void))v10)(v12, 0);
      unint64_t v7 = v9;
      uint64_t result = v14;
      *(void *)(v15 + 8 * v8++) = v13;
    }
    while (result != v8);
  }
  return result;
}

uint64_t protocol witness for Transformer.applied(to:eventHandler:) in conformance MLSupportVectorClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  unint64_t v7 = (void *)swift_task_alloc(dword_3ADEAC);
  *(void *)(v4 + 16) = v7;
  *unint64_t v7 = v4;
  v7[1] = protocol witness for SupervisedEstimator.fitted<A, B>(to:validateOn:eventHandler:) in conformance MLImageClassifier.Classifier;
  return MLSupportVectorClassifier.Model.applied(to:eventHandler:)(a1, a2, a3, a4);
}

uint64_t base witness table accessor for Transformer in MLSupportVectorClassifier.Model()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLSupportVectorClassifier.Model and conformance MLSupportVectorClassifier.Model, type metadata accessor for MLSupportVectorClassifier.Model, (uint64_t)&protocol conformance descriptor for MLSupportVectorClassifier.Model);
}

void MLSupportVectorClassifier.Model.export(userInfo:)()
{
  uint64_t v156 = v1;
  uint64_t v134 = v0;
  uint64_t v135 = type metadata accessor for ModelKind(0);
  uint64_t v136 = *(void *)(v135 - 8);
  int64_t v3 = *(void *)(v136 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  unint64_t v137 = &v118;
  uint64_t v143 = type metadata accessor for FeatureType(0);
  uint64_t v142 = *(void *)(v143 - 8);
  int64_t v6 = *(void *)(v142 + 64);
  unint64_t v7 = alloca(v6);
  unint64_t v8 = alloca(v6);
  unint64_t v141 = &v118;
  int64_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Model?)
                             - 8)
                 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  char v138 = &v118;
  uint64_t v139 = type metadata accessor for Model(0);
  uint64_t v145 = *(void *)(v139 - 8);
  int64_t v12 = *(void *)(v145 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  char v148 = &v118;
  uint64_t v15 = alloca(v12);
  uint64_t v16 = alloca(v12);
  int v155 = &v118;
  uint64_t v129 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>);
  uint64_t v150 = *(void *)(v129 - 8);
  int64_t v17 = *(void *)(v150 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  unsigned __int8 v130 = &v118;
  uint64_t v131 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>);
  uint64_t v152 = *(void *)(v131 - 8);
  int64_t v20 = *(void *)(v152 + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  unint64_t v132 = &v118;
  uint64_t v149 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
  int64_t v23 = *(void *)(*(void *)(v149 - 8) + 64);
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  uint64_t v140 = &v118;
  uint64_t v26 = alloca(v23);
  uint64_t v27 = alloca(v23);
  uint64_t v122 = &v118;
  uint64_t v123 = type metadata accessor for URL.DirectoryHint(0);
  uint64_t v124 = *(void *)(v123 - 8);
  int64_t v28 = *(void *)(v124 + 64);
  uint64_t v29 = alloca(v28);
  uint64_t v30 = alloca(v28);
  uint64_t v125 = &v118;
  uint64_t v126 = type metadata accessor for UUID(0);
  uint64_t v127 = *(void *)(v126 - 8);
  int64_t v31 = *(void *)(v127 + 64);
  uint64_t v32 = alloca(v31);
  uint64_t v33 = alloca(v31);
  uint64_t v128 = &v118;
  uint64_t v34 = type metadata accessor for URL(0);
  uint64_t v35 = *(void *)(v34 - 8);
  int64_t v36 = *(void *)(v35 + 64);
  uint64_t v37 = alloca(v36);
  uint64_t v38 = alloca(v36);
  uint64_t v133 = &v118;
  uint64_t v39 = alloca(v36);
  uint64_t v40 = alloca(v36);
  uint64_t v157 = &v118;
  uint64_t v41 = alloca(v36);
  uint64_t v42 = alloca(v36);
  uint64_t v154 = &v118;
  uint64_t v43 = alloca(v36);
  uint64_t v44 = alloca(v36);
  uint64_t v45 = v156;
  uint64_t v46 = specialized FeatureVectorizer.Transformer.exportEncoders()(v2[2], v2[3], v2[4]);
  if (!v45)
  {
    uint64_t v144 = v35;
    uint64_t v153 = v46;
    unint64_t v146 = &v118;
    uint64_t v151 = v34;
    long long v147 = v2;
    uint64_t v47 = objc_opt_self(NSFileManager);
    id v48 = [v47 defaultManager];
    id v49 = v48;
    NSFileManager.createTemporaryModelDirectory()();
    uint64_t v156 = v50;
    if (v50)
    {
      swift_bridgeObjectRelease(v153);

      return;
    }

    id v51 = [v47 defaultManager];
    id v52 = v51;
    NSFileManager.temporaryModelDirectory.getter();

    uint64_t v53 = v128;
    UUID.init()();
    uint64_t v54 = UUID.uuidString.getter();
    uint64_t v56 = v55;
    (*(void (**)(uint64_t *, uint64_t))(v127 + 8))(v53, v126);
    uint64_t v120 = v54;
    uint64_t v121 = v56;
    uint64_t v57 = v125;
    uint64_t v58 = v123;
    uint64_t v59 = v124;
    (*(void (**)(uint64_t *, void, uint64_t))(v124 + 104))(v125, enum case for URL.DirectoryHint.inferFromPath(_:), v123);
    uint64_t v60 = lazy protocol witness table accessor for type String and conformance String();
    uint64_t v61 = (uint64_t)v157;
    URL.appending<A>(component:directoryHint:)(&v120, v57, &type metadata for String, v60);
    (*(void (**)(uint64_t *, uint64_t))(v59 + 8))(v57, v58);
    swift_bridgeObjectRelease(v121);
    char v62 = *(void (**)(uint64_t, uint64_t))(v144 + 8);
    uint64_t v63 = v151;
    v62(v61, v151);
    uint64_t v64 = v146;
    uint64_t v65 = v154;
    URL.appendingPathExtension(_:)(0x6C65646F6D6C6D2ELL, 0xE800000000000000);
    uint64_t v154 = (uint64_t *)v62;
    v62((uint64_t)v65, v63);
    uint64_t v157 = (uint64_t *)((char *)v147 + *(int *)(type metadata accessor for MLSupportVectorClassifier.Model(0) + 24));
    uint64_t v66 = (uint64_t)v122;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v157, (uint64_t)v122, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
    if (swift_getEnumCaseMultiPayload(v66, v149) == 1)
    {
      uint64_t v67 = v130;
      uint64_t v68 = v66;
      uint64_t v69 = v129;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v150 + 32))(v130, v68, v129);
      uint64_t v70 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type LinearSupportVectorClassifierModel<Double, Int> and conformance LinearSupportVectorClassifierModel<A, B>, &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>, (uint64_t)&protocol conformance descriptor for LinearSupportVectorClassifierModel<A, B>);
      uint64_t v71 = v156;
      Transformer.export(to:)(v64, v69, v70);
      if (v71)
      {
        swift_bridgeObjectRelease(v153);
        uint64_t v72 = v67;
        uint64_t v73 = v69;
        uint64_t v74 = v150;
LABEL_9:
        (*(void (**)(uint64_t *, uint64_t))(v74 + 8))(v72, v73);
        ((void (*)(uint64_t *, uint64_t))v154)(v64, v151);
        return;
      }
      char v80 = v67;
      uint64_t v81 = v69;
      uint64_t v82 = v150;
    }
    else
    {
      uint64_t v75 = v132;
      uint64_t v76 = v66;
      uint64_t v77 = v131;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v152 + 32))(v132, v76, v131);
      uint64_t v78 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type LinearSupportVectorClassifierModel<Double, String> and conformance LinearSupportVectorClassifierModel<A, B>, &demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>, (uint64_t)&protocol conformance descriptor for LinearSupportVectorClassifierModel<A, B>);
      uint64_t v79 = v156;
      Transformer.export(to:)(v64, v77, v78);
      if (v79)
      {
        swift_bridgeObjectRelease(v153);
        uint64_t v72 = v75;
        uint64_t v73 = v77;
        uint64_t v74 = v152;
        goto LABEL_9;
      }
      char v80 = v75;
      uint64_t v81 = v77;
      uint64_t v82 = v152;
    }
    (*(void (**)(uint64_t *, uint64_t))(v82 + 8))(v80, v81);
    uint64_t v83 = v133;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v144 + 16))(v133, v146, v151);
    Model.init(contentsOf:)(v83);
    uint64_t v156 = 0;
    uint64_t v84 = v139;
    uint64_t v85 = (uint64_t)v138;
    specialized BidirectionalCollection.last.getter(v153);
    if (__swift_getEnumTagSinglePayload(v85, 1, v84) == 1) {
      BUG();
    }
    uint64_t v86 = Model.outputs.getter(v85, 1);
    uint64_t v150 = *(void *)(v145 + 8);
    ((void (*)(uint64_t, uint64_t))v150)(v85, v84);
    Model.inputs.setter(v86);
    uint64_t v87 = *v147;
    uint64_t v88 = v147[1];
    swift_bridgeObjectRetain(v88);
    uint64_t v152 = v87;
    Model.predictedFeatureName.setter(v87, v88);
    uint64_t v89 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for String, &protocol witness table for String);
    Model.metadata.setter(v89);
    uint64_t v90 = (uint64_t)v140;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v157, (uint64_t)v140, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
    LODWORD(v157) = swift_getEnumCaseMultiPayload(v90, v149);
    uint64_t v91 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
    uint64_t v92 = *(void *)(type metadata accessor for FeatureDescription(0) - 8);
    uint64_t v93 = swift_allocObject(v91, ((*(unsigned __int8 *)(v92 + 80) + 32) & ~*(unsigned __int8 *)(v92 + 80)) + 2 * *(void *)(v92 + 72), *(unsigned __int8 *)(v92 + 80) | 7);
    *(void *)(v93 + 16) = 2;
    *(void *)(v93 + 24) = 4;
    uint64_t v149 = v88;
    swift_bridgeObjectRetain(v88);
    uint64_t v94 = v141;
    if (v157 == 1)
    {
      FeatureType.IntParameters.init(optional:)(0);
      (*(void (**)(uint64_t *, void, uint64_t))(v142 + 104))(v94, enum case for FeatureType.int(_:), v143);
      FeatureDescription.init(name:type:description:)(v152, v149, v94, 0, 0xE000000000000000);
      uint64_t v95 = Model.predictedProbabilitiesName.getter();
      uint64_t v157 = (uint64_t *)v96;
      static FeatureType.dictionaryWithIntKeys(optional:)(0);
    }
    else
    {
      FeatureType.StringParameters.init(optional:)(0);
      (*(void (**)(uint64_t *, void, uint64_t))(v142 + 104))(v94, enum case for FeatureType.string(_:), v143);
      FeatureDescription.init(name:type:description:)(v152, v149, v94, 0, 0xE000000000000000);
      uint64_t v95 = Model.predictedProbabilitiesName.getter();
      uint64_t v157 = (uint64_t *)v97;
      static FeatureType.dictionaryWithStringKeys(optional:)(0);
    }
    FeatureDescription.init(name:type:description:)(v95, v157, v94, 0, 0xE000000000000000);
    Model.outputs.setter(v93);
    outlined destroy of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>((uint64_t)v140);
    Model.init()();
    Model.specificationVersion.setter(1);
    uint64_t v98 = v147;
    uint64_t v99 = v147[2];
    swift_bridgeObjectRetain(v99);
    uint64_t v100 = v156;
    ML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay8CreateML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n(v99);
    uint64_t v156 = v100;
    swift_bridgeObjectRelease(v99);
    Model.inputs.setter(ML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n);
    uint64_t v102 = Model.outputs.getter(ML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n, v119);
    Model.outputs.setter(v102);
    uint64_t v103 = *v98;
    uint64_t v104 = v98[1];
    swift_bridgeObjectRetain(v104);
    Model.predictedFeatureName.setter(v103, v104);
    uint64_t v105 = v155;
    uint64_t v106 = Model.predictedProbabilitiesName.getter();
    Model.predictedProbabilitiesName.setter(v106, v107);
    uint64_t v108 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Model>);
    uint64_t v109 = *(unsigned __int8 *)(v145 + 80);
    uint64_t v110 = ((int)v109 + 32) & ~*(unsigned __int8 *)(v145 + 80);
    uint64_t v111 = v145;
    uint64_t v112 = swift_allocObject(v108, v110 + *(void *)(v145 + 72), v109 | 7);
    *(void *)(v112 + 16) = 1;
    *(void *)(v112 + 24) = 2;
    uint64_t v113 = v105;
    uint64_t v114 = v139;
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v111 + 16))(v112 + v110, v113, v139);
    uint64_t v120 = v153;
    specialized Array.append<A>(contentsOf:)(v112);
    uint64_t v115 = v137;
    PipelineClassifierConfiguration.init(models:names:)(v120, _swiftEmptyArrayStorage);
    (*(void (**)(uint64_t *, void, uint64_t))(v136 + 104))(v115, enum case for ModelKind.pipelineClassifier(_:), v135);
    uint64_t v116 = v148;
    Model.kind.setter(v115);
    ((void (*)(uint64_t *, uint64_t))v150)(v155, v114);
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v145 + 32))(v134, v116, v114);
    uint64_t v117 = v146;
    $defer #1 () in MLSupportVectorClassifier.Model.export(userInfo:)();
    ((void (*)(uint64_t *, uint64_t))v154)(v117, v151);
  }
}

NSURL *$defer #1 () in MLSupportVectorClassifier.Model.export(userInfo:)()
{
  uint64_t v0 = objc_opt_self(NSFileManager);
  id v1 = [v0 defaultManager];
  uint64_t v2 = (NSURL *)v1;
  URL._bridgeToObjectiveC()(v2);
  uint64_t v4 = v3;
  id v10 = 0;
  unsigned __int8 v5 = [(NSURL *)v2 removeItemAtURL:v3 error:&v10];

  id v6 = v10;
  if (v5) {
    return (NSURL *)v10;
  }
  id v8 = v10;
  uint64_t v9 = _convertNSErrorToError(_:)(v6);

  swift_willThrow();
  swift_errorRelease(v9);
  return __stack_chk_guard;
}

void *sub_290112()
{
  return &protocol witness table for String;
}

uint64_t sub_29011F()
{
  return key path getter for ClassificationDistribution.mostLikelyLabel : ClassificationDistribution<String>();
}

void *sub_29012C()
{
  return &protocol witness table for Int;
}

uint64_t sub_290139()
{
  return key path getter for ClassificationDistribution.mostLikelyLabel : ClassificationDistribution<Int>();
}

uint64_t partial apply for closure #1 in static MLSupportVectorClassifier.Model.buildFeatures(from:)(uint64_t *a1, uint64_t a2)
{
  return closure #1 in static MLSupportVectorClassifier.Model.buildFeatures(from:)(a1, a2, *(void *)(v2 + 16), *(void *)(v2 + 24));
}

double specialized ContiguousArray.subscript.getter(uint64_t a1, uint64_t a2)
{
  if (a1 < 0) {
    BUG();
  }
  if (*(void *)(a2 + 16) <= (unint64_t)a1) {
    BUG();
  }
  return *(double *)(a2 + 8 * a1 + 32);
}

void (*specialized DenseMatrix.subscript.read(double *a1, unint64_t a2, unint64_t a3))()
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  char v5 = DenseMatrix.layout.getter(v4);
  uint64_t v14 = DenseMatrix.storage.getter(v4);
  if (v5)
  {
    unint64_t v10 = DenseMatrix.rowCount.getter(v4);
    unint64_t v12 = a3;
    unint64_t v11 = v10 * a3;
    if (!is_mul_ok(v10, v12)) {
      BUG();
    }
    uint64_t v9 = v11 + a2;
    if (__OFADD__(v11, a2)) {
      BUG();
    }
  }
  else
  {
    unint64_t v6 = DenseMatrix.columnCount.getter(v4);
    unint64_t v7 = v6 * a2;
    if (!is_mul_ok(v6, a2)) {
      BUG();
    }
    BOOL v8 = __OFADD__(a3, v7);
    uint64_t v9 = a3 + v7;
    if (v8) {
      BUG();
    }
  }
  *a1 = specialized ContiguousArray.subscript.getter(v9, v14);
  swift_release();
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t outlined init with copy of MLSoundClassifier.Model(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLSoundClassifier.Model(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lF11TabularData6ColumnVySSG_Sis5NeverOTg5047_s8CreateML6LabelsO17encodeAnnotationsySaySiG11d8Data9AnyF13VFSiSSSgXEfU_SDySSSiGTf1cn_n(uint64_t a1, uint64_t *a2)
{
  uint64_t v22 = a2;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v3 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v4 = dispatch thunk of Collection.count.getter(v2, v3);
  if (!v4) {
    return _swiftEmptyArrayStorage;
  }
  uint64_t v27 = _swiftEmptyArrayStorage;
  int64_t v5 = 0;
  if (v4 > 0) {
    int64_t v5 = v4;
  }
  uint64_t v28 = v4;
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v5, 0);
  uint64_t v29 = v27;
  dispatch thunk of Collection.startIndex.getter(v2, v3);
  uint64_t v6 = v28;
  if (v28 < 0) {
    BUG();
  }
  uint64_t v23 = a1;
  uint64_t v24 = v2;
  uint64_t v25 = v3;
  do
  {
    BOOL v7 = v6 == 0;
    uint64_t v8 = v6 - 1;
    if (v7) {
      BUG();
    }
    uint64_t v28 = v8;
    uint64_t v9 = (void (*)(unsigned char *, void))dispatch thunk of Collection.subscript.read(v21, v26, v2, v3);
    uint64_t v11 = *v10;
    uint64_t v12 = v10[1];
    swift_bridgeObjectRetain(v12);
    v9(v21, 0);
    uint64_t v13 = v12;
    if (!v12) {
      uint64_t v13 = 0xE000000000000000;
    }
    uint64_t v14 = *v22;
    if (!*(void *)(*v22 + 16))
    {
      swift_bridgeObjectRetain(v12);
LABEL_21:
      swift_bridgeObjectRelease(v13);
      BUG();
    }
    if (!v12) {
      uint64_t v11 = 0;
    }
    swift_bridgeObjectRetain(v12);
    unint64_t v15 = specialized __RawDictionaryStorage.find<A>(_:)(v11, v13);
    if ((v16 & 1) == 0) {
      goto LABEL_21;
    }
    uint64_t v17 = *(void *)(*(void *)(v14 + 56) + 8 * v15);
    swift_bridgeObjectRelease(v12);
    swift_bridgeObjectRelease(v13);
    uint64_t v18 = v29;
    uint64_t v27 = v29;
    unint64_t v19 = v29[2];
    if (v29[3] >> 1 <= v19)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v29[3] >= 2uLL, v19 + 1, 1);
      uint64_t v18 = v27;
    }
    void v18[2] = v19 + 1;
    uint64_t v29 = v18;
    v18[v19 + 4] = v17;
    uint64_t v2 = v24;
    uint64_t v3 = v25;
    dispatch thunk of Collection.formIndex(after:)(v26, v24, v25);
    uint64_t v6 = v28;
  }
  while (v28);
  return v29;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lF11TabularData6ColumnVySiG_Sis5NeverOTg5047_s8CreateML6LabelsO17encodeAnnotationsySaySiG11d8Data9AnyF13VFS2iSgXEfU0_SDyS2iGTf1cn_n(uint64_t a1, uint64_t *a2)
{
  int64_t v20 = a2;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v25 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Int> and conformance Column<A>, &demangling cache variable for type metadata for Column<Int>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v3 = dispatch thunk of Collection.count.getter(v2, v25);
  if (!v3) {
    return _swiftEmptyArrayStorage;
  }
  uint64_t v4 = v3;
  uint64_t v24 = _swiftEmptyArrayStorage;
  int64_t v5 = 0;
  if (v3 > 0) {
    int64_t v5 = v3;
  }
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v5, 0);
  uint64_t v26 = v24;
  dispatch thunk of Collection.startIndex.getter(v2, v25);
  if (v4 < 0) {
    BUG();
  }
  uint64_t v21 = a1;
  uint64_t v22 = v2;
  do
  {
    if (v4-- == 0) {
      BUG();
    }
    BOOL v7 = (void (*)(unsigned char *, void))dispatch thunk of Collection.subscript.read(v19, v23, v2, v25);
    uint64_t v9 = *(void *)v8;
    char v10 = *(unsigned char *)(v8 + 8);
    v7(v19, 0);
    uint64_t v11 = *v20;
    if (!*(void *)(*v20 + 16)) {
      BUG();
    }
    if (v10) {
      uint64_t v9 = 0;
    }
    unint64_t v12 = specialized __RawDictionaryStorage.find<A>(_:)(v9);
    if ((v13 & 1) == 0) {
      BUG();
    }
    uint64_t v14 = *(void **)(*(void *)(v11 + 56) + 8 * v12);
    unint64_t v15 = v26;
    uint64_t v24 = v26;
    unint64_t v16 = v26[2];
    unint64_t v17 = v26[3];
    if (v17 >> 1 <= v16)
    {
      uint64_t v26 = v14;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v17 >= 2, v16 + 1, 1);
      uint64_t v14 = v26;
      unint64_t v15 = v24;
    }
    v15[2] = v16 + 1;
    uint64_t v26 = v15;
    v15[v16 + 4] = v14;
    uint64_t v2 = v22;
    dispatch thunk of Collection.formIndex(after:)(v23, v22, v25);
  }
  while (v4);
  return v26;
}

uint64_t specialized Set.union<A>(_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v20 = a2;
  uint64_t v2 = 1 << *(unsigned char *)(a1 + 32);
  uint64_t v3 = ~(-1 << v2);
  if (v2 >= 64) {
    uint64_t v3 = -1;
  }
  uint64_t v22 = a1;
  unint64_t v4 = *(void *)(a1 + 56) & v3;
  int64_t v21 = (unint64_t)(v2 + 63) >> 6;
  int64_t v5 = 0;
  while (1)
  {
    if (v4)
    {
      _BitScanForward64(&v6, v4);
      v4 &= v4 - 1;
      unint64_t v7 = v6 | (v5 << 6);
      goto LABEL_17;
    }
    BOOL v8 = __OFADD__(1, v5);
    int64_t v9 = v5 + 1;
    if (v8) {
      BUG();
    }
    if (v9 >= v21) {
      break;
    }
    unint64_t i = *(void *)(v22 + 8 * v9 + 56);
    if (i)
    {
      int64_t v11 = v9;
    }
    else
    {
      int64_t v11 = v9 + 1;
      if (v9 + 1 >= v21) {
        break;
      }
      unint64_t i = *(void *)(v22 + 8 * v9 + 64);
      if (!i)
      {
        int64_t v11 = v9 + 2;
        if (v9 + 2 >= v21) {
          break;
        }
        unint64_t i = *(void *)(v22 + 8 * v9 + 72);
        if (!i)
        {
          int64_t v11 = v9 + 3;
          if (v9 + 3 >= v21) {
            break;
          }
          unint64_t i = *(void *)(v22 + 8 * v9 + 80);
          if (!i)
          {
            int64_t v11 = v9 + 4;
            if (v9 + 4 >= v21) {
              break;
            }
            for (unint64_t i = *(void *)(v22 + 8 * v9 + 88); !i; unint64_t i = *(void *)(v22 + 8 * v11 + 56))
            {
              BOOL v8 = __OFADD__(1, v11++);
              if (v8) {
                BUG();
              }
              if (v11 >= v21) {
                goto LABEL_24;
              }
            }
          }
        }
      }
    }
    _BitScanForward64(&v12, i);
    unint64_t v4 = i & (i - 1);
    unint64_t v7 = v12 + (v11 << 6);
    int64_t v5 = v11;
LABEL_17:
    uint64_t v13 = *(void *)(v22 + 48);
    uint64_t v14 = 16 * v7;
    uint64_t v15 = *(void *)(v13 + v14);
    uint64_t v16 = *(void *)(v13 + v14 + 8);
    swift_bridgeObjectRetain(v16);
    specialized Set._Variant.insert(_:)(&v18, v15, v16);
    swift_bridgeObjectRelease(v19);
  }
LABEL_24:
  swift_release();
  return v20;
}

{
  uint64_t v2;
  uint64_t v3;
  unint64_t v4;
  int64_t v5;
  int64_t v6;
  unint64_t v7;
  unint64_t v8;
  BOOL v9;
  int64_t v10;
  unint64_t i;
  int64_t v12;
  unint64_t v13;
  uint64_t v15;
  uint64_t v16;

  uint64_t v16 = a2;
  uint64_t v2 = 1 << *(unsigned char *)(a1 + 32);
  uint64_t v3 = ~(-1 << v2);
  if (v2 >= 64) {
    uint64_t v3 = -1;
  }
  unint64_t v4 = *(void *)(a1 + 56) & v3;
  int64_t v5 = (unint64_t)(v2 + 63) >> 6;
  unint64_t v6 = 0;
  while (1)
  {
    if (v4)
    {
      _BitScanForward64(&v7, v4);
      v4 &= v4 - 1;
      BOOL v8 = v7 | (v6 << 6);
      goto LABEL_17;
    }
    int64_t v9 = __OFADD__(1, v6);
    char v10 = v6 + 1;
    if (v9) {
      BUG();
    }
    if (v10 >= v5) {
      break;
    }
    unint64_t i = *(void *)(a1 + 8 * v10 + 56);
    if (i)
    {
      unint64_t v12 = v10;
    }
    else
    {
      unint64_t v12 = v10 + 1;
      if (v10 + 1 >= v5) {
        break;
      }
      unint64_t i = *(void *)(a1 + 8 * v10 + 64);
      if (!i)
      {
        unint64_t v12 = v10 + 2;
        if (v10 + 2 >= v5) {
          break;
        }
        unint64_t i = *(void *)(a1 + 8 * v10 + 72);
        if (!i)
        {
          unint64_t v12 = v10 + 3;
          if (v10 + 3 >= v5) {
            break;
          }
          unint64_t i = *(void *)(a1 + 8 * v10 + 80);
          if (!i)
          {
            unint64_t v12 = v10 + 4;
            if (v10 + 4 >= v5) {
              break;
            }
            for (unint64_t i = *(void *)(a1 + 8 * v10 + 88); !i; unint64_t i = *(void *)(a1 + 8 * v12 + 56))
            {
              int64_t v9 = __OFADD__(1, v12++);
              if (v9) {
                BUG();
              }
              if (v12 >= v5) {
                goto LABEL_24;
              }
            }
          }
        }
      }
    }
    _BitScanForward64(&v13, i);
    unint64_t v4 = i & (i - 1);
    BOOL v8 = v13 + (v12 << 6);
    unint64_t v6 = v12;
LABEL_17:
    specialized Set._Variant.insert(_:)(&v15, *(void *)(*(void *)(a1 + 48) + 8 * v8));
  }
LABEL_24:
  swift_release();
  return v16;
}

{
  uint64_t v2;
  uint64_t *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;

  int64_t v11 = a2;
  uint64_t v2 = *(void *)(a1 + 16);
  if (v2)
  {
    char v10 = a1;
    uint64_t v3 = (uint64_t *)(a1 + 40);
    do
    {
      unint64_t v4 = *(v3 - 1);
      int64_t v5 = *v3;
      swift_bridgeObjectRetain(*v3);
      specialized Set._Variant.insert(_:)(&v8, v4, v5);
      swift_bridgeObjectRelease(v9);
      v3 += 2;
      --v2;
    }
    while (v2);
    swift_bridgeObjectRelease(v10);
    return v11;
  }
  else
  {
    unint64_t v6 = a2;
    swift_bridgeObjectRelease(a1);
  }
  return v6;
}

uint64_t static Labels.collected(from:_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v64 = v2;
  uint64_t v65 = a2;
  uint64_t v73 = (void *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v61 = *(v73 - 1);
  int64_t v3 = *(void *)(v61 + 64);
  unint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  uint64_t v67 = &v59;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<Int>>)
                             - 8)
                 + 64);
  unint64_t v7 = alloca(v6);
  BOOL v8 = alloca(v6);
  uint64_t v76 = &v59;
  int64_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?)
                             - 8)
                 + 64);
  char v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  char v62 = &v59;
  unint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v74 = &v59;
  uint64_t v71 = type metadata accessor for AnyColumn(0);
  uint64_t v72 = *(void *)(v71 - 8);
  int64_t v14 = *(void *)(v72 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v68 = &v59;
  unint64_t v17 = alloca(v14);
  uint64_t v18 = alloca(v14);
  uint64_t v66 = &v59;
  uint64_t v63 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v19 = *(uint64_t **)(v63 - 8);
  int64_t v20 = v19[8];
  int64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  int64_t v23 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>)
                              - 8)
                  + 64);
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  uint64_t v75 = &v59;
  uint64_t v26 = AnyColumn.wrappedElementType.getter();
  if (!swift_dynamicCastMetatype(v26, &type metadata for String))
  {
    uint64_t v34 = v67;
    if (!swift_dynamicCastMetatype(v26, &type metadata for Int))
    {
      uint64_t v48 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v48, 0, 0);
      *(void *)uint64_t v49 = 0xD000000000000025;
      *(void *)(v49 + 8) = "start time column" + 0x8000000000000000;
      *(_OWORD *)(v49 + 16) = 0;
      *(_OWORD *)(v49 + 32) = 0;
      *(unsigned char *)(v49 + 48) = 1;
      return swift_willThrow(&type metadata for MLCreateError, v48, v49, v50, v51, v52);
    }
    double v35 = AnyColumn.assumingType<A>(_:)(&type metadata for Int, &type metadata for Int);
    uint64_t v69 = 0;
    uint64_t v36 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Int> and conformance Column<A>, &demangling cache variable for type metadata for Column<Int>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v37 = v73;
    uint64_t v74 = (uint64_t *)v36;
    OptionalColumnProtocol.filled(with:)(&v69, v73, v36);
    uint64_t v75 = *(uint64_t **)(v61 + 8);
    ((void (*)(uint64_t *, void *, double))v75)(v34, v37, v35);
    uint64_t v38 = (uint64_t)specialized Set.init<A>(_:)();
    uint64_t v39 = (uint64_t)v62;
    outlined init with copy of AnyColumn?(v65, (uint64_t)v62);
    uint64_t v40 = v71;
    if (__swift_getEnumTagSinglePayload(v39, 1, v71) == 1)
    {
      outlined destroy of AnyColumn?(v39);
    }
    else
    {
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v72 + 32))(v68, v39, v40);
      double v54 = AnyColumn.assumingType<A>(_:)(&type metadata for Int, &type metadata for Int);
      uint64_t v69 = 0;
      uint64_t v55 = v73;
      OptionalColumnProtocol.filled(with:)(&v69, v73, v74);
      ((void (*)(uint64_t *, void *, double))v75)(v34, v55, v54);
      uint64_t v56 = specialized Set.init<A>(_:)();
      uint64_t v38 = specialized Set.union<A>(_:)((uint64_t)v56, v38);
      (*(void (**)(uint64_t *, uint64_t))(v72 + 8))(v68, v71);
    }
    swift_bridgeObjectRetain(v38);
    uint64_t v57 = specialized _copyCollectionToContiguousArray<A>(_:)(v38);
    swift_bridgeObjectRelease(v38);
    uint64_t v69 = v57;
    uint64_t v58 = v64;
    specialized MutableCollection<>.sort(by:)(&v69);
    if (!v58)
    {
      char v47 = v38;
      goto LABEL_14;
    }
LABEL_15:
    swift_release();
    BUG();
  }
  uint64_t v76 = v19;
  double v27 = AnyColumn.assumingType<A>(_:)(&type metadata for String, &type metadata for String);
  uint64_t v69 = 0;
  unint64_t v70 = 0xE000000000000000;
  uint64_t v28 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v29 = v63;
  uint64_t v67 = (uint64_t *)v28;
  OptionalColumnProtocol.filled(with:)(&v69, v63, v28);
  uint64_t v30 = (void *)v76[1];
  uint64_t v76 = &v59;
  uint64_t v73 = v30;
  ((void (*)(uint64_t *, uint64_t, double))v30)(&v59, v29, v27);
  uint64_t v31 = specialized Set.init<A>(_:)();
  uint64_t v32 = (uint64_t)v74;
  outlined init with copy of AnyColumn?(v65, (uint64_t)v74);
  uint64_t v33 = v71;
  if (__swift_getEnumTagSinglePayload(v32, 1, v71) == 1)
  {
    outlined destroy of AnyColumn?((uint64_t)v74);
  }
  else
  {
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v72 + 32))(v66, v74, v33);
    uint64_t v41 = v76;
    double v42 = AnyColumn.assumingType<A>(_:)(&type metadata for String, &type metadata for String);
    uint64_t v69 = 0;
    unint64_t v70 = 0xE000000000000000;
    uint64_t v43 = v63;
    OptionalColumnProtocol.filled(with:)(&v69, v63, v67);
    ((void (*)(uint64_t *, uint64_t, double))v73)(v41, v43, v42);
    uint64_t v44 = specialized Set.init<A>(_:)();
    uint64_t v31 = specialized Set.union<A>(_:)(v44, v31);
    (*(void (**)(uint64_t *, uint64_t))(v72 + 8))(v66, v71);
  }
  swift_bridgeObjectRetain(v31);
  uint64_t v45 = specialized _copyCollectionToContiguousArray<A>(_:)(v31);
  swift_bridgeObjectRelease(v31);
  uint64_t v69 = v45;
  uint64_t v46 = v64;
  specialized MutableCollection<>.sort(by:)(&v69);
  if (v46) {
    goto LABEL_15;
  }
  char v47 = v31;
LABEL_14:
  swift_bridgeObjectRelease(v47);
  return (uint64_t)v69;
}

uint64_t outlined init with copy of AnyColumn?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

void *Labels.encodeAnnotations(_:)(uint64_t a1, uint64_t a2, char a3, double a4)
{
  uint64_t v5 = a2;
  uint64_t v63 = a1;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  unint64_t v7 = *(uint64_t **)(v6 - 8);
  int64_t v8 = v7[8];
  int64_t v9 = alloca(v8);
  char v10 = alloca(v8);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  unint64_t v12 = *(uint64_t **)(v11 - 8);
  int64_t v13 = v12[8];
  int64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v16 = &v59;
  uint64_t v62 = a2;
  if (a3)
  {
    uint64_t v60 = v11;
    uint64_t v66 = v12;
    uint64_t v37 = _swiftEmptyDictionarySingleton;
    uint64_t v69 = _swiftEmptyDictionarySingleton;
    uint64_t v65 = *(void *)(a2 + 16);
    if (!v65)
    {
LABEL_25:
      uint64_t v56 = (uint64_t)v16;
      AnyColumn.convertedToStrings()();
      ML6LabelsO17encodeAnnotationsySaySiG11d8Data9AnyF13VFSiSSSgXEfU_SDySSSiGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lF11TabularData6ColumnVySSG_Sis5NeverOTg5047_s8CreateML6LabelsO17encodeAnnotationsySaySiG11d8Data9AnyF13VFSiSSSgXEfU_SDySSSiGTf1cn_n(v56, (uint64_t *)&v69);
      uint64_t v34 = v56;
      uint64_t v35 = v60;
      uint64_t v36 = v66;
      goto LABEL_26;
    }
    uint64_t v61 = &v59;
    swift_bridgeObjectRetain(a2);
    uint64_t v38 = (uint64_t *)(a2 + 40);
    uint64_t v39 = 0;
    while (1)
    {
      uint64_t v70 = v39;
      uint64_t v40 = *(v38 - 1);
      uint64_t v64 = v38;
      uint64_t v41 = *v38;
      swift_bridgeObjectRetain(*v38);
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v37);
      uint64_t v71 = v37;
      uint64_t v68 = v40;
      uint64_t v67 = v41;
      unint64_t v44 = specialized __RawDictionaryStorage.find<A>(_:)(v40, v41);
      BOOL v45 = (v43 & 1) == 0;
      BOOL v24 = __OFADD__(v37[2], v45);
      Swift::Int v46 = v37[2] + v45;
      if (v24) {
        BUG();
      }
      char v47 = v43;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, Int>);
      Swift::Bool v48 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v46);
      uint64_t v49 = v67;
      if (v48)
      {
        unint64_t v44 = specialized __RawDictionaryStorage.find<A>(_:)(v68, v67);
        if ((v47 & 1) != (v50 & 1)) {
          break;
        }
      }
      uint64_t v37 = v71;
      if (v47)
      {
        uint64_t v51 = v70;
        *(void *)(v71[7] + 8 * v44) = v70;
      }
      else
      {
        v71[(v44 >> 6) + 8] |= 1 << v44;
        uint64_t v52 = v37[6];
        uint64_t v53 = 16 * v44;
        *(void *)(v52 + v53) = v68;
        *(void *)(v52 + v53 + 8) = v49;
        uint64_t v51 = v70;
        *(void *)(v37[7] + 8 * v44) = v70;
        uint64_t v54 = v37[2];
        BOOL v24 = __OFADD__(1, v54);
        uint64_t v55 = v54 + 1;
        if (v24) {
          BUG();
        }
        void v37[2] = v55;
        swift_bridgeObjectRetain(v49);
      }
      uint64_t v39 = v51 + 1;
      swift_bridgeObjectRelease(v49);
      swift_bridgeObjectRelease(0);
      uint64_t v38 = v64 + 2;
      if (v65 == v39)
      {
        uint64_t v69 = v37;
        swift_bridgeObjectRelease(v62);
        uint64_t v16 = v61;
        goto LABEL_25;
      }
    }
    uint64_t v58 = &type metadata for String;
LABEL_33:
    KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(v58);
    BUG();
  }
  uint64_t v66 = &v59;
  uint64_t v65 = v6;
  uint64_t v64 = v7;
  unint64_t v17 = _swiftEmptyDictionarySingleton;
  uint64_t v69 = _swiftEmptyDictionarySingleton;
  uint64_t v68 = *(void *)(a2 + 16);
  if (!v68) {
    goto LABEL_13;
  }
  swift_bridgeObjectRetain(a2);
  uint64_t v18 = 0;
  do
  {
    uint64_t v70 = v18;
    uint64_t v19 = *(void *)(v5 + 8 * v18 + 32);
    char v20 = swift_isUniquelyReferenced_nonNull_native(v17);
    uint64_t v71 = v17;
    uint64_t v67 = v19;
    unint64_t v22 = specialized __RawDictionaryStorage.find<A>(_:)(v19);
    BOOL v23 = (v21 & 1) == 0;
    BOOL v24 = __OFADD__(v17[2], v23);
    Swift::Int v25 = v17[2] + v23;
    if (v24) {
      BUG();
    }
    char v26 = v21;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<Int, Int>);
    Swift::Bool v27 = _NativeDictionary.ensureUnique(isUnique:capacity:)(v20, v25);
    uint64_t v5 = v62;
    if (v27)
    {
      unint64_t v22 = specialized __RawDictionaryStorage.find<A>(_:)(v67);
      if ((v26 & 1) != (v28 & 1))
      {
        uint64_t v58 = &type metadata for Int;
        goto LABEL_33;
      }
    }
    unint64_t v17 = v71;
    if (v26)
    {
      uint64_t v29 = v70;
      *(void *)(v71[7] + 8 * v22) = v70;
    }
    else
    {
      v71[(v22 >> 6) + 8] |= 1 << v22;
      *(void *)(v17[6] + 8 * v22) = v67;
      uint64_t v29 = v70;
      *(void *)(v17[7] + 8 * v22) = v70;
      uint64_t v30 = v17[2];
      BOOL v24 = __OFADD__(1, v30);
      uint64_t v31 = v30 + 1;
      if (v24) {
        BUG();
      }
      long long v17[2] = v31;
    }
    uint64_t v18 = v29 + 1;
    swift_bridgeObjectRelease(0);
  }
  while (v68 != v18);
  uint64_t v69 = v17;
  swift_bridgeObjectRelease(v5);
LABEL_13:
  uint64_t v32 = (uint64_t)v66;
  a4 = AnyColumn.assumingType<A>(_:)(&type metadata for Int, &type metadata for Int);
  ML6LabelsO17encodeAnnotationsySaySiG11d8Data9AnyF13VFSiSSSgXEfU_SDySSSiGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lF11TabularData6ColumnVySiG_Sis5NeverOTg5047_s8CreateML6LabelsO17encodeAnnotationsySaySiG11d8Data9AnyF13VFS2iSgXEfU0_SDyS2iGTf1cn_n(v32, (uint64_t *)&v69);
  uint64_t v34 = v32;
  uint64_t v35 = v65;
  uint64_t v36 = v64;
LABEL_26:
  ((void (*)(uint64_t, uint64_t, double))v36[1])(v34, v35, a4);
  swift_bridgeObjectRelease((_BYTE)v69);
  return ML6LabelsO17encodeAnnotationsySaySiG11d8Data9AnyF13VFSiSSSgXEfU_SDySSSiGTf1cn_n;
}

char static Labels.== infix(_:_:)(void *a1, char a2, void *a3, char a4)
{
  if ((a2 & 1) == 0)
  {
    if ((a4 & 1) == 0) {
      return specialized static Array<A>.== infix(_:_:)((uint64_t)a1, (uint64_t)a3);
    }
    return 0;
  }
  if ((a4 & 1) == 0) {
    return 0;
  }
  return specialized static Array<A>.== infix(_:_:)(a1, a3);
}

char protocol witness for static Equatable.== infix(_:_:) in conformance Labels(uint64_t a1, uint64_t a2)
{
  return static Labels.== infix(_:_:)(*(void **)a1, *(unsigned char *)(a1 + 8), *(void **)a2, *(unsigned char *)(a2 + 8));
}

uint64_t initializeBufferWithCopyOfBuffer for Labels(uint64_t a1, uint64_t *a2)
{
  uint64_t v3 = *a2;
  char v4 = *((unsigned char *)a2 + 8);
  *(void *)a1 = *a2;
  *(unsigned char *)(a1 + 8) = v4;
  swift_bridgeObjectRetain(v3);
  return a1;
}

uint64_t *assignWithCopy for Labels(uint64_t *a1, uint64_t *a2)
{
  uint64_t v3 = *a2;
  char v4 = *((unsigned char *)a2 + 8);
  uint64_t v5 = *a1;
  *a1 = *a2;
  *((unsigned char *)a1 + 8) = v4;
  swift_bridgeObjectRetain(v3);
  swift_bridgeObjectRelease(v5);
  return a1;
}

uint64_t *assignWithTake for Labels(uint64_t *a1, uint64_t *a2)
{
  char v3 = *((unsigned char *)a2 + 8);
  uint64_t v4 = *a1;
  *a1 = *a2;
  *((unsigned char *)a1 + 8) = v3;
  swift_bridgeObjectRelease(v4);
  return a1;
}

ValueMetadata *type metadata accessor for Labels()
{
  return &type metadata for Labels;
}

uint64_t initializeWithCopy for Labels(uint64_t a1, uint64_t *a2)
{
  return initializeBufferWithCopyOfBuffer for Labels(a1, a2);
}

uint64_t MLWordTagger.prediction(from:)()
{
  v9[0] = 32;
  v9[1] = 0xE100000000000000;
  uint64_t v1 = lazy protocol witness table accessor for type String and conformance String();
  char v2 = StringProtocol.components<A>(separatedBy:)(v9, &type metadata for String, &type metadata for String, v1, v1);
  char v3 = *v0;
  Class isa = Array._bridgeToObjectiveC()().super.isa;
  swift_bridgeObjectRelease(v2);
  id v5 = [v3 predictedLabelsForTokens:isa];
  id v6 = v5;

  uint64_t v7 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v6, &type metadata for String);
  return v7;
}

{
  void **v0;
  void *v1;
  Class isa;
  id v3;
  id v4;
  uint64_t v5;

  uint64_t v1 = *v0;
  Class isa = Array._bridgeToObjectiveC()().super.isa;
  char v3 = [v1 predictedLabelsForTokens:isa];
  uint64_t v4 = v3;

  id v5 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v4, &type metadata for String);
  return v5;
}

uint64_t specialized MLWordTagger.predictions<A>(from:)(uint64_t a1, uint64_t a2)
{
  id v5 = v3;
  uint64_t v59 = v4;
  uint64_t v6 = v2;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<[Int]>)
                             - 8)
                 + 64);
  int64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  uint64_t v69 = &v55;
  uint64_t v66 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int]>);
  uint64_t v64 = *(void *)(v66 - 8);
  int64_t v10 = *(void *)(v64 + 64);
  uint64_t v11 = alloca(v10);
  unint64_t v12 = alloca(v10);
  uint64_t v70 = &v55;
  int64_t v13 = alloca(v10);
  int64_t v14 = alloca(v10);
  uint64_t v71 = &v55;
  int64_t v15 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<[String]>)
                              - 8)
                  + 64);
  uint64_t v16 = alloca(v15);
  unint64_t v17 = alloca(v15);
  uint64_t v67 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String]>);
  uint64_t v65 = *(void *)(v67 - 8);
  int64_t v18 = *(void *)(v65 + 64);
  uint64_t v19 = alloca(v18);
  char v20 = alloca(v18);
  uint64_t v73 = &v55;
  char v21 = alloca(v18);
  unint64_t v22 = alloca(v18);
  uint64_t v72 = &v55;
  swift_bridgeObjectRetain(a1);
  uint64_t v63 = v6;
  DataFrame.init()(a1, a2, v23, v24);
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  ColumnID.init(_:_:)(1954047348, 0xE400000000000000, v25);
  uint64_t v68 = a1;
  uint64_t v26 = *(void *)(a1 + 16);
  Column.init(_:capacity:)(&v55, v26, v25);
  ColumnID.init(_:_:)(0x6C6562616CLL, 0xE500000000000000, v25);
  uint64_t v61 = v25;
  Column.init(_:capacity:)(&v55, v26, v25);
  uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int]);
  char v28 = v69;
  ColumnID.init(_:_:)(0x736874676E656CLL, 0xE700000000000000, v27);
  Column.init(_:capacity:)(v28, v26, v27);
  ColumnID.init(_:_:)(0x6E6F697461636F6CLL, 0xE900000000000073, v27);
  Column.init(_:capacity:)(v28, v26, v27);
  uint64_t v60 = v26;
  uint64_t v62 = v27;
  if (v26)
  {
    uint64_t v29 = (void *)(v68 + 40);
    while (1)
    {
      uint64_t v55 = v29;
      uint64_t v30 = *v29;
      swift_bridgeObjectRetain(*v29);
      uint64_t v31 = MLWordTagger.predictTokensAndLabels(text:)();
      uint64_t v69 = v5;
      if (v5) {
        break;
      }
      uint64_t v35 = v32;
      uint64_t v36 = v34;
      uint64_t v37 = v31;
      uint64_t v57 = v31;
      uint64_t v58 = v33;
      swift_bridgeObjectRelease(v30);
      v74[0] = v35;
      uint64_t v38 = v67;
      uint64_t v56 = v35;
      Column.append(_:)(v74, v67);
      v74[0] = v37;
      Column.append(_:)(v74, v38);
      v74[0] = v36;
      uint64_t v39 = v66;
      Column.append(_:)(v74, v66);
      LOBYTE(v37) = v58;
      v74[0] = v58;
      Column.append(_:)(v74, v39);
      swift_bridgeObjectRelease(v36);
      swift_bridgeObjectRelease((_BYTE)v37);
      swift_bridgeObjectRelease(v56);
      swift_bridgeObjectRelease((_BYTE)v57);
      uint64_t v29 = v55 + 2;
      BOOL v40 = v60-- == 1;
      id v5 = v69;
      if (v40) {
        goto LABEL_5;
      }
    }
    swift_bridgeObjectRelease(v68);
    swift_bridgeObjectRelease(v30);
    char v50 = *(void (**)(void *, uint64_t))(v64 + 8);
    uint64_t v51 = v66;
    v50(v70, v66);
    v50(v71, v51);
    uint64_t v52 = *(void (**)(void *, uint64_t))(v65 + 8);
    uint64_t v53 = v67;
    v52(v73, v67);
    v52(v72, v53);
    uint64_t v54 = type metadata accessor for DataFrame(0);
    return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v54 - 8) + 8))(v63, v54);
  }
  else
  {
LABEL_5:
    swift_bridgeObjectRelease(v68);
    uint64_t v41 = v61;
    DataFrame.append<A>(column:)(v72, v61);
    DataFrame.append<A>(column:)(v73, v41);
    uint64_t v42 = v62;
    DataFrame.append<A>(column:)(v71, v62);
    char v43 = v70;
    DataFrame.append<A>(column:)(v70, v42);
    unint64_t v44 = *(void (**)(void *, uint64_t))(v64 + 8);
    BOOL v45 = v43;
    uint64_t v46 = v66;
    v44(v45, v66);
    v44(v71, v46);
    char v47 = *(void (**)(void *, uint64_t))(v65 + 8);
    uint64_t v48 = v67;
    v47(v73, v67);
    return ((uint64_t (*)(void *, uint64_t))v47)(v72, v48);
  }
}

uint64_t MLWordTagger.predictions<A>(from:)(uint64_t a1, uint64_t a2, void *a3)
{
  uint64_t v75 = v4;
  uint64_t v69 = v5;
  uint64_t v77 = a3;
  uint64_t v6 = v3;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<[Int]>)
                             - 8)
                 + 64);
  int64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  uint64_t v76 = &v64;
  uint64_t v78 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int]>);
  uint64_t v73 = *(void *)(v78 - 8);
  int64_t v10 = *(void *)(v73 + 64);
  uint64_t v11 = alloca(v10);
  unint64_t v12 = alloca(v10);
  uint64_t v82 = &v64;
  int64_t v13 = alloca(v10);
  int64_t v14 = alloca(v10);
  uint64_t v81 = &v64;
  int64_t v15 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<[String]>)
                              - 8)
                  + 64);
  uint64_t v16 = alloca(v15);
  unint64_t v17 = alloca(v15);
  uint64_t v79 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String]>);
  uint64_t v74 = *(void *)(v79 - 8);
  int64_t v18 = *(void *)(v74 + 64);
  uint64_t v19 = alloca(v18);
  char v20 = alloca(v18);
  uint64_t v84 = &v64;
  char v21 = alloca(v18);
  unint64_t v22 = alloca(v18);
  uint64_t v83 = &v64;
  uint64_t v23 = *(void *)(a2 - 8);
  int64_t v24 = *(void *)(v23 + 64);
  uint64_t v25 = alloca(v24);
  uint64_t v26 = alloca(v24);
  (*(void (**)(uint64_t *, uint64_t))(v23 + 16))(&v64, a1);
  uint64_t v27 = Array.init<A>(_:)(&v64, &type metadata for String, a2, v77);
  uint64_t v80 = v27;
  uint64_t v72 = v6;
  DataFrame.init()(&v64, &type metadata for String, v28, v29);
  uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  ColumnID.init(_:_:)(1954047348, 0xE400000000000000, v30);
  uint64_t v31 = *(void *)(v27 + 16);
  Column.init(_:capacity:)(&v64, v31, v30);
  ColumnID.init(_:_:)(0x6C6562616CLL, 0xE500000000000000, v30);
  uint64_t v70 = v30;
  Column.init(_:capacity:)(&v64, v31, v30);
  uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int]);
  uint64_t v33 = v76;
  ColumnID.init(_:_:)(0x736874676E656CLL, 0xE700000000000000, v32);
  Column.init(_:capacity:)(v33, v31, v32);
  ColumnID.init(_:_:)(0x6E6F697461636F6CLL, 0xE900000000000073, v32);
  Column.init(_:capacity:)(v33, v31, v32);
  uint64_t v34 = *(uint64_t **)(v80 + 16);
  uint64_t v71 = v32;
  if (v34)
  {
    uint64_t v35 = (void *)(v80 + 40);
    while (1)
    {
      uint64_t v76 = v34;
      uint64_t v36 = *v35;
      swift_bridgeObjectRetain(*v35);
      uint64_t v37 = v75;
      uint64_t v38 = MLWordTagger.predictTokensAndLabels(text:)();
      if (v37) {
        break;
      }
      uint64_t v75 = 0;
      char v42 = v36;
      uint64_t v77 = v35;
      char v43 = v38;
      uint64_t v66 = v38;
      uint64_t v44 = v39;
      uint64_t v65 = v39;
      uint64_t v67 = v40;
      uint64_t v45 = v41;
      uint64_t v68 = v41;
      swift_bridgeObjectRelease(v42);
      v85[0] = v44;
      uint64_t v46 = v79;
      Column.append(_:)(v85, v79);
      v85[0] = v43;
      char v47 = v77;
      Column.append(_:)(v85, v46);
      v85[0] = v45;
      uint64_t v48 = v78;
      Column.append(_:)(v85, v78);
      LOBYTE(v45) = v67;
      v85[0] = v67;
      Column.append(_:)(v85, v48);
      swift_bridgeObjectRelease(v68);
      swift_bridgeObjectRelease(v45);
      swift_bridgeObjectRelease(v65);
      swift_bridgeObjectRelease((_BYTE)v66);
      uint64_t v35 = v47 + 2;
      uint64_t v34 = (uint64_t *)((char *)v76 - 1);
      if (v76 == (uint64_t *)((char *)&dword_0 + 1)) {
        goto LABEL_5;
      }
    }
    swift_bridgeObjectRelease(v80);
    swift_bridgeObjectRelease(v36);
    uint64_t v59 = *(void (**)(uint64_t *, uint64_t))(v73 + 8);
    uint64_t v60 = v78;
    v59(v82, v78);
    v59(v81, v60);
    uint64_t v61 = *(void (**)(uint64_t *, uint64_t))(v74 + 8);
    uint64_t v62 = v79;
    v61(v84, v79);
    v61(v83, v62);
    uint64_t v63 = type metadata accessor for DataFrame(0);
    return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v63 - 8) + 8))(v72, v63);
  }
  else
  {
LABEL_5:
    swift_bridgeObjectRelease(v80);
    uint64_t v49 = v70;
    DataFrame.append<A>(column:)(v83, v70);
    DataFrame.append<A>(column:)(v84, v49);
    char v50 = v81;
    uint64_t v51 = v71;
    DataFrame.append<A>(column:)(v81, v71);
    uint64_t v52 = v82;
    DataFrame.append<A>(column:)(v82, v51);
    uint64_t v53 = *(void (**)(uint64_t *, uint64_t))(v73 + 8);
    uint64_t v54 = v52;
    uint64_t v55 = v78;
    v53(v54, v78);
    v53(v50, v55);
    uint64_t v56 = *(void (**)(uint64_t *, uint64_t))(v74 + 8);
    uint64_t v57 = v79;
    v56(v84, v79);
    return ((uint64_t (*)(uint64_t *, uint64_t))v56)(v83, v57);
  }
}

unsigned char *MLWordTagger.predictTokensAndLabels(text:)()
{
  v17[5] = v0;
  id v2 = *v1;
  NSString v3 = String._bridgeToObjectiveC()();
  uint64_t v4 = (unsigned char *)NLPSequenceModelCopyPredictedTokensAndLabelsForText(v2, v3);

  if (!v4
    || (v17[0] = 0,
        static Dictionary._conditionallyBridgeFromObjectiveC(_:result:)(v4, v17, &type metadata for AnyHashable, (char *)&type metadata for Any + 8, &protocol witness table for AnyHashable), v4, (uint64_t v5 = v17[0]) == 0))
  {
    uint64_t v10 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v10, 0, 0);
    *(void *)uint64_t v11 = 0xD00000000000001DLL;
    int64_t v15 = "n the trained model.";
    goto LABEL_25;
  }
  unint64_t v21 = 0x7272416C6562614CLL;
  unint64_t v22 = (char *)0xEA00000000007961;
  AnyHashable.init<A>(_:)(&v21, &type metadata for String, &protocol witness table for String);
  uint64_t v4 = v19;
  specialized Dictionary.subscript.getter((uint64_t)v17, v5);
  outlined destroy of AnyHashable((uint64_t)v17);
  if (!v20)
  {
    swift_bridgeObjectRelease(v5);
    outlined destroy of Any?((uint64_t)v19);
LABEL_15:
    uint64_t v10 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v10, 0, 0);
    *(void *)uint64_t v11 = 0xD000000000000024;
    int64_t v15 = "No output returned for input.";
    goto LABEL_25;
  }
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  if (!swift_dynamicCast(&v21, v19, (char *)&type metadata for Any + 8, v6, 6))
  {
    swift_bridgeObjectRelease(v5);
    goto LABEL_15;
  }
  int64_t v24 = (unsigned char *)v21;
  unint64_t v21 = 0x7272416E656B6F54;
  unint64_t v22 = (char *)0xEA00000000007961;
  uint64_t v4 = v17;
  AnyHashable.init<A>(_:)(&v21, &type metadata for String, &protocol witness table for String);
  specialized Dictionary.subscript.getter((uint64_t)v17, v5);
  outlined destroy of AnyHashable((uint64_t)v17);
  if (!v20)
  {
    swift_bridgeObjectRelease((_BYTE)v24);
    swift_bridgeObjectRelease(v5);
    outlined destroy of Any?((uint64_t)v19);
LABEL_18:
    uint64_t v10 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v10, 0, 0);
    *(void *)uint64_t v11 = 0xD000000000000024;
    int64_t v15 = "ray from prediction.";
    goto LABEL_25;
  }
  if (!swift_dynamicCast(&v21, v19, (char *)&type metadata for Any + 8, v6, 6))
  {
    swift_bridgeObjectRelease((_BYTE)v24);
    swift_bridgeObjectRelease(v5);
    goto LABEL_18;
  }
  unint64_t v23 = v21;
  unint64_t v21 = 0xD000000000000017;
  unint64_t v22 = "ray from prediction." + 0x8000000000000000;
  AnyHashable.init<A>(_:)(&v21, &type metadata for String, &protocol witness table for String);
  specialized Dictionary.subscript.getter((uint64_t)v17, v5);
  outlined destroy of AnyHashable((uint64_t)v17);
  if (!v20)
  {
    swift_bridgeObjectRelease(v23);
    swift_bridgeObjectRelease((_BYTE)v24);
    swift_bridgeObjectRelease(v5);
    outlined destroy of Any?((uint64_t)v19);
LABEL_21:
    uint64_t v10 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v10, 0, 0);
    *(void *)uint64_t v11 = 0xD00000000000002DLL;
    int64_t v15 = "TokenRangeLocationArray";
    goto LABEL_25;
  }
  uint64_t v4 = (unsigned char *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int]);
  if (!swift_dynamicCast(&v21, v19, (char *)&type metadata for Any + 8, v4, 6))
  {
    swift_bridgeObjectRelease(v23);
    swift_bridgeObjectRelease((_BYTE)v24);
    swift_bridgeObjectRelease(v5);
    goto LABEL_21;
  }
  int64_t v18 = v4;
  char v7 = v21;
  unint64_t v21 = 0xD000000000000015;
  unint64_t v22 = "cation array from prediction." + 0x8000000000000000;
  uint64_t v4 = v17;
  AnyHashable.init<A>(_:)(&v21, &type metadata for String, &protocol witness table for String);
  specialized Dictionary.subscript.getter((uint64_t)v17, v5);
  swift_bridgeObjectRelease(v5);
  outlined destroy of AnyHashable((uint64_t)v17);
  if (v20)
  {
    char v8 = swift_dynamicCast(&v21, v19, (char *)&type metadata for Any + 8, v18, 6);
    uint64_t v4 = v24;
    char v9 = v23;
    if (v8) {
      return v4;
    }
    swift_bridgeObjectRelease(v7);
    swift_bridgeObjectRelease(v9);
    swift_bridgeObjectRelease((_BYTE)v4);
  }
  else
  {
    swift_bridgeObjectRelease(v7);
    swift_bridgeObjectRelease(v23);
    swift_bridgeObjectRelease((_BYTE)v24);
    outlined destroy of Any?((uint64_t)v19);
  }
  uint64_t v10 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  swift_allocError(&type metadata for MLCreateError, v10, 0, 0);
  *(void *)uint64_t v11 = 0xD00000000000002BLL;
  int64_t v15 = "TokenRangeLengthArray";
LABEL_25:
  *(void *)(v11 + 8) = (unint64_t)v15 | 0x8000000000000000;
  *(_OWORD *)(v11 + 16) = 0;
  *(_OWORD *)(v11 + 32) = 0;
  *(unsigned char *)(v11 + 48) = 0;
  swift_willThrow(&type metadata for MLCreateError, v10, v11, v12, v13, v14);
  return v4;
}

uint64_t MLWordTagger.predictions(from:)(uint64_t a1, __m128 a2)
{
  v23[0] = v3;
  v23[1] = v4;
  v23[2] = v2;
  uint64_t v5 = type metadata accessor for DataFrame(0);
  uint64_t v6 = *(void *)(v5 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  char v8 = alloca(v7);
  char v9 = alloca(v7);
  int64_t v24 = v23;
  uint64_t v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  if (*(unsigned char *)(a1 + 8)
    || (uint64_t v12 = *(void *)a1,
        outlined copy of Result<_DataTable, Error>(*(void *)a1, 0),
        _UntypedColumn.type.getter(),
        outlined consume of Result<_DataTable, Error>(v12, 0),
        v26 != 2))
  {
    uint64_t v18 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v18, 0, 0);
    *(void *)uint64_t v19 = 0xD00000000000002ALL;
    *(void *)(v19 + 8) = "logisticRegressor" + 0x8000000000000000;
    *(_OWORD *)(v19 + 16) = 0;
    *(_OWORD *)(v19 + 32) = 0;
    *(unsigned char *)(v19 + 48) = 1;
    return swift_willThrow(&type metadata for MLCreateError, v18, v19, v20, v21, v22);
  }
  else
  {
    uint64_t v25 = v6;
    outlined copy of Result<_DataTable, Error>(v12, 0);
    uint64_t v13 = specialized Array<A>.init(_:)(v12, 0, *(double *)a2.i64);
    char v14 = (char)v13;
    uint64_t v15 = v23[0];
    specialized MLWordTagger.predictions<A>(from:)((uint64_t)v13, 0);
    uint64_t result = swift_bridgeObjectRelease(v14);
    if (!v15)
    {
      uint64_t v17 = (uint64_t)v24;
      *(double *)a2.i64 = (*(double (**)(void *, void *, uint64_t))(v25 + 16))(v24, v23, v5);
      MLDataTable.init(_:convertArraysToShapedArrays:)(v17, 0, a2);
      return (*(uint64_t (**)(void *, uint64_t))(v25 + 8))(v23, v5);
    }
  }
  return result;
}

void *MLWordTagger.predictionWithConfidence(from:)()
{
  v6[0] = 32;
  v6[1] = 0xE100000000000000;
  uint64_t v1 = lazy protocol witness table accessor for type String and conformance String();
  uint64_t v2 = StringProtocol.components<A>(separatedBy:)(v6, &type metadata for String, &type metadata for String, v1, v1);
  char v3 = v2;
  uint64_t v4 = MLWordTagger.predictionWithAllTagsAndConfidences(tokens:tags:)(v2, *(void *)(v0 + 8));
  swift_bridgeObjectRelease(v3);
  return v4;
}

void *MLWordTagger.predictionWithAllTagsAndConfidences(tokens:tags:)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  uint64_t v3 = NLModel.predictedLabelHypotheses(forTokens:maximumCount:)(a1, *(void *)(a2 + 16));
  uint64_t v65 = *(void *)(v3 + 16);
  if (!v65)
  {
    swift_bridgeObjectRelease(v3);
    return _swiftEmptyArrayStorage;
  }
  uint64_t v4 = *(void **)(v3 + 32);
  unint64_t v5 = v4[2];
  unint64_t v6 = *(void *)(a2 + 16);
  int64_t v7 = _swiftEmptyArrayStorage;
  if (v6 < v5) {
    goto LABEL_3;
  }
  uint64_t v15 = 1;
  uint64_t v68 = v3;
  while (2)
  {
    uint64_t v72 = (uint64_t)v7;
    unint64_t v64 = v15;
    if (v5 == v6)
    {
      swift_bridgeObjectRetain((_BYTE)v4);
      goto LABEL_63;
    }
    specialized _NativeDictionary.makeIterator()((uint64_t)v4);
    int64_t v16 = v61;
    unint64_t v17 = v62;
    int64_t v18 = (unint64_t)(v60 + 64) >> 6;
    for (double i = 0.0; ; double i = i + *(double *)(*(void *)(v58 + 56) + 8 * v21))
    {
      if (v17)
      {
        _BitScanForward64(&v20, v17);
        v17 &= v17 - 1;
        unint64_t v21 = v20 | (v16 << 6);
        continue;
      }
      int64_t v22 = v16 + 1;
      if (__OFADD__(1, v16)) {
        BUG();
      }
      if (v22 >= v18) {
        goto LABEL_31;
      }
      unint64_t v23 = *(void *)(v59 + 8 * v22);
      if (!v23) {
        break;
      }
      int64_t v24 = v16 + 1;
LABEL_29:
      _BitScanForward64(&v26, v23);
      unint64_t v17 = v23 & (v23 - 1);
      unint64_t v21 = v26 + (v24 << 6);
      int64_t v16 = v24;
    }
    int64_t v24 = v16 + 2;
    if (v16 + 2 >= v18) {
      goto LABEL_31;
    }
    unint64_t v23 = *(void *)(v59 + 8 * v22 + 8);
    if (v23) {
      goto LABEL_29;
    }
    int64_t v24 = v16 + 3;
    if (v16 + 3 >= v18) {
      goto LABEL_31;
    }
    unint64_t v23 = *(void *)(v59 + 8 * v22 + 16);
    if (v23) {
      goto LABEL_29;
    }
    int64_t v24 = v16 + 4;
    if (v16 + 4 >= v18) {
      goto LABEL_31;
    }
    unint64_t v23 = *(void *)(v59 + 8 * v22 + 24);
    if (v23) {
      goto LABEL_29;
    }
    int64_t v24 = v16 + 5;
    if (v16 + 5 >= v18) {
      goto LABEL_31;
    }
    unint64_t v23 = *(void *)(v59 + 8 * v22 + 32);
    if (v23) {
      goto LABEL_29;
    }
    int64_t v24 = v16 + 6;
    if (v16 + 6 >= v18) {
      goto LABEL_31;
    }
    unint64_t v23 = *(void *)(v59 + 8 * v22 + 40);
    if (v23) {
      goto LABEL_29;
    }
    int64_t v25 = v16 + 7;
    while (v25 < v18)
    {
      unint64_t v23 = *(void *)(v59 + 8 * v25++);
      if (v23)
      {
        int64_t v24 = v25 - 1;
        goto LABEL_29;
      }
    }
LABEL_31:
    swift_bridgeObjectRetain_n(v4, 3);
    swift_release();
    uint64_t v27 = *(void *)(v2 + 16) - v4[2];
    swift_bridgeObjectRelease((_BYTE)v4);
    double v67 = (1.0 - i) / (double)(int)v27;
    uint64_t v28 = 1 << *(unsigned char *)(v2 + 32);
    uint64_t v29 = ~(-1 << v28);
    if (v28 >= 64) {
      uint64_t v29 = -1;
    }
    unint64_t v30 = *(void *)(v2 + 56) & v29;
    int64_t v71 = (unint64_t)(v28 + 63) >> 6;
    swift_bridgeObjectRetain(v2);
    int64_t v31 = 0;
    while (2)
    {
      if (v30)
      {
        _BitScanForward64(&v32, v30);
        uint64_t v69 = (v30 - 1) & v30;
        unint64_t v33 = v32 | (v31 << 6);
        int64_t v70 = v31;
LABEL_45:
        uint64_t v39 = *(void *)(v2 + 48);
        uint64_t v40 = 16 * v33;
        uint64_t v41 = *(void *)(v39 + v40);
        uint64_t v42 = *(void *)(v39 + v40 + 8);
        uint64_t v43 = v4[2];
        swift_bridgeObjectRetain(v42);
        if (v43
          && (swift_bridgeObjectRetain((_BYTE)v4),
              specialized __RawDictionaryStorage.find<A>(_:)(v41, v42),
              char v45 = v44,
              swift_bridgeObjectRelease((_BYTE)v4),
              (v45 & 1) != 0))
        {
          swift_bridgeObjectRelease(v42);
          int64_t v31 = v70;
          uint64_t v2 = a2;
          unint64_t v30 = v69;
        }
        else
        {
          char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v4);
          unint64_t v46 = specialized __RawDictionaryStorage.find<A>(_:)(v41, v42);
          char v73 = v47;
          BOOL v48 = (v47 & 1) == 0;
          BOOL v34 = __OFADD__(v4[2], v48);
          Swift::Int v49 = v4[2] + v48;
          if (v34) {
            BUG();
          }
          unint64_t v63 = v46;
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, Double>);
          unint64_t v50 = v63;
          if (_NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v49))
          {
            unint64_t v50 = specialized __RawDictionaryStorage.find<A>(_:)(v41, v42);
            if ((v73 & 1) != (v51 & 1))
            {
              KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
              BUG();
            }
          }
          if (v73)
          {
            *(double *)(v4[7] + 8 * v50) = v67;
          }
          else
          {
            v4[(v50 >> 6) + 8] |= 1 << v50;
            uint64_t v52 = v4[6];
            uint64_t v53 = 16 * v50;
            *(void *)(v52 + v53) = v41;
            *(void *)(v52 + v53 + 8) = v42;
            *(double *)(v4[7] + 8 * v50) = v67;
            uint64_t v54 = v4[2];
            BOOL v34 = __OFADD__(1, v54);
            uint64_t v55 = v54 + 1;
            if (v34) {
              BUG();
            }
            v4[2] = v55;
            swift_bridgeObjectRetain(v42);
          }
          swift_bridgeObjectRelease(v42);
          swift_bridgeObjectRelease(0);
          uint64_t v2 = a2;
          int64_t v31 = v70;
          unint64_t v30 = v69;
        }
        continue;
      }
      break;
    }
    BOOL v34 = __OFADD__(1, v31);
    int64_t v35 = v31 + 1;
    if (v34) {
      BUG();
    }
    if (v35 < v71)
    {
      unint64_t j = *(void *)(v2 + 8 * v35 + 56);
      if (j)
      {
        int64_t v37 = v35;
      }
      else
      {
        int64_t v37 = v35 + 1;
        if (v35 + 1 >= v71) {
          goto LABEL_62;
        }
        unint64_t j = *(void *)(v2 + 8 * v35 + 64);
        if (!j)
        {
          int64_t v37 = v35 + 2;
          if (v35 + 2 >= v71) {
            goto LABEL_62;
          }
          unint64_t j = *(void *)(v2 + 8 * v35 + 72);
          if (!j)
          {
            int64_t v37 = v35 + 3;
            if (v35 + 3 >= v71) {
              goto LABEL_62;
            }
            for (unint64_t j = *(void *)(v2 + 8 * v35 + 80); !j; unint64_t j = *(void *)(v2 + 8 * v37 + 56))
            {
              BOOL v34 = __OFADD__(1, v37++);
              if (v34) {
                BUG();
              }
              if (v37 >= v71) {
                goto LABEL_62;
              }
            }
          }
        }
      }
      _BitScanForward64(&v38, j);
      uint64_t v69 = j & (j - 1);
      int64_t v70 = v37;
      unint64_t v33 = v38 + (v37 << 6);
      goto LABEL_45;
    }
LABEL_62:
    swift_release();
LABEL_63:
    if (swift_isUniquelyReferenced_nonNull_native(v72)) {
      int64_t v7 = (void *)v72;
    }
    else {
      int64_t v7 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(v72 + 16) + 1, 1, v72);
    }
    unint64_t v56 = v7[2];
    if (v7[3] >> 1 <= v56) {
      int64_t v7 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v7[3] >= 2uLL, v56 + 1, 1, (uint64_t)v7);
    }
    void v7[2] = v56 + 1;
    v7[v56 + 4] = v4;
    if (v64 != v65)
    {
      LOBYTE(v3) = v68;
      if (v64 >= *(void *)(v68 + 16)) {
        BUG();
      }
      uint64_t v4 = *(void **)(v68 + 8 * v64 + 32);
      uint64_t v15 = v64 + 1;
      unint64_t v5 = v4[2];
      unint64_t v6 = *(void *)(v2 + 16);
      if (v6 < v5)
      {
LABEL_3:
        char v8 = (char)v7;
        swift_bridgeObjectRelease(v3);
        swift_bridgeObjectRelease(v8);
        uint64_t v9 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v9, 0, 0);
        *(void *)uint64_t v10 = 0xD000000000000034;
        *(void *)(v10 + 8) = " elements must be Strings." + 0x8000000000000000;
        *(_OWORD *)(v10 + 16) = 0;
        *(_OWORD *)(v10 + 32) = 0;
        *(unsigned char *)(v10 + 48) = 0;
        return (void *)swift_willThrow(&type metadata for MLCreateError, v9, v10, v11, v12, v13);
      }
      continue;
    }
    break;
  }
  uint64_t v57 = v7;
  swift_bridgeObjectRelease(v68);
  return v57;
}

void *MLWordTagger.predictionWithConfidence(from:)(uint64_t a1)
{
  return MLWordTagger.predictionWithAllTagsAndConfidences(tokens:tags:)(a1, *(void *)(v1 + 8));
}

uint64_t NeuralNetwork.Layer.ConvolutionParameters.init(from:)(uint64_t a1)
{
  uint64_t v65 = a1;
  uint64_t v2 = v1;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?)
                             - 8)
                 + 64);
  uint64_t v4 = alloca(v3);
  unint64_t v5 = alloca(v3);
  uint64_t v53 = (uint64_t)&v53;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.Extent<Int>)
                             - 8)
                 + 64);
  int64_t v7 = alloca(v6);
  char v8 = alloca(v6);
  uint64_t v54 = &v53;
  uint64_t v57 = type metadata accessor for TensorShape(0);
  uint64_t v67 = *(void *)(v57 - 8);
  int64_t v9 = *(void *)(v67 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v58 = &v53;
  int64_t v12 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.WeightParameters?)
                              - 8)
                  + 64);
  uint64_t v13 = alloca(v12);
  char v14 = alloca(v12);
  unint64_t v63 = &v53;
  int64_t v15 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?)
                              - 8)
                  + 64);
  int64_t v16 = alloca(v15);
  unint64_t v17 = alloca(v15);
  uint64_t v60 = &v53;
  uint64_t v66 = type metadata accessor for Tensor(0);
  int64_t v71 = *(void (**)(uint64_t, uint64_t))(v66 - 8);
  int64_t v18 = *((void *)v71 + 8);
  uint64_t v19 = alloca(v18);
  unint64_t v20 = alloca(v18);
  uint64_t v64 = type metadata accessor for NeuralNetwork.WeightParameters(0);
  int64_t v21 = *(void *)(*(void *)(v64 - 8) + 64);
  int64_t v22 = alloca(v21);
  unint64_t v23 = alloca(v21);
  unint64_t v62 = &v53;
  uint64_t v24 = type metadata accessor for Conv1D(0);
  uint64_t v25 = *(void *)(v24 - 8);
  int64_t v26 = *(void *)(v25 + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  NeuralNetwork.Layer.ConvolutionParameters.init()();
  uint64_t v29 = v65 + *(int *)(type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0) + 20);
  uint64_t v55 = v24;
  uint64_t v56 = v25;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v25 + 16))(&v53, v29, v24);
  Conv1D.weight.getter();
  uint64_t v30 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  int64_t v31 = (void (*)(uint64_t, uint64_t))*((void *)v71 + 1);
  uint64_t v32 = v2;
  uint64_t v61 = &v53;
  uint64_t v33 = v66;
  int64_t v71 = v31;
  v31((uint64_t)&v53, v66);
  BOOL v34 = v62;
  NeuralNetwork.WeightParameters.init(_:updatable:)(v30, 0);
  NeuralNetwork.Layer.ConvolutionParameters.weights.setter(v34);
  uint64_t v35 = (uint64_t)v60;
  int64_t v70 = &v53;
  Conv1D.bias.getter();
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v35, 1, v33);
  uint64_t v59 = v32;
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Tensor?(v35);
  }
  else
  {
    uint64_t v37 = v35;
    uint64_t v38 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
    v71(v37, v33);
    uint64_t v39 = (uint64_t)v63;
    NeuralNetwork.WeightParameters.init(_:updatable:)(v38, 0);
    __swift_storeEnumTagSinglePayload(v39, 0, 1, v64);
    NeuralNetwork.Layer.ConvolutionParameters.bias.setter(v39);
  }
  uint64_t v40 = v33;
  uint64_t v41 = v61;
  Conv1D.weight.getter();
  uint64_t v42 = v58;
  Tensor.shape.getter();
  v71((uint64_t)v41, v40);
  uint64_t v43 = TensorShape.subscript.getter(0);
  uint64_t v67 = *(void *)(v67 + 8);
  uint64_t v44 = v57;
  ((void (*)(uint64_t *, uint64_t))v67)(v42, v57);
  NeuralNetwork.Layer.ConvolutionParameters.outputChannelCount.setter(v43);
  Conv1D.weight.getter();
  Tensor.shape.getter();
  v71((uint64_t)v41, v66);
  uint64_t v45 = TensorShape.subscript.getter(1);
  ((void (*)(uint64_t *, uint64_t))v67)(v42, v44);
  NeuralNetwork.Layer.ConvolutionParameters.kernelChannelCount.setter(v45);
  uint64_t v46 = Conv1D.groupCount.getter();
  NeuralNetwork.Layer.ConvolutionParameters.groupCount.setter(v46);
  uint64_t v68 = 1;
  uint64_t v69 = Conv1D.kernelSize.getter(v46, v44, v47, &v68);
  BOOL v48 = v54;
  NeuralNetwork.Extent.init(height:width:)(&v68, &v69, &type metadata for Int, &protocol witness table for Int);
  NeuralNetwork.Layer.ConvolutionParameters.kernelSize.setter(v48);
  uint64_t v68 = 1;
  uint64_t v69 = Conv1D.stride.getter(v48, &v69, v49, &v68);
  NeuralNetwork.Extent.init(height:width:)(&v68, &v69, &type metadata for Int, &protocol witness table for Int);
  NeuralNetwork.Layer.ConvolutionParameters.strides.setter(v48);
  uint64_t v68 = 1;
  uint64_t v69 = Conv1D.dilation.getter();
  NeuralNetwork.Extent.init(height:width:)(&v68, &v69, &type metadata for Int, &protocol witness table for Int);
  NeuralNetwork.Layer.ConvolutionParameters.dilationFactor.setter(v48);
  uint64_t v50 = v53;
  NeuralNetwork.ValidPaddingParameters.init()();
  LODWORD(v43) = enum case for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind.valid(_:);
  uint64_t v51 = type metadata accessor for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind(0);
  (*(void (**)(uint64_t, void, uint64_t))(*(void *)(v51 - 8) + 104))(v50, v43, v51);
  __swift_storeEnumTagSinglePayload(v50, 0, 1, v51);
  NeuralNetwork.Layer.ConvolutionParameters.padding.setter(v50);
  outlined destroy of MLImageClassifier.ModelParameters.ValidationData(v65, type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v56 + 8))(v70, v55);
}

{
  uint64_t v1;
  uint64_t v2;
  int64_t v3;
  void *v4;
  void *v5;
  int64_t v6;
  void *v7;
  void *v8;
  int64_t v9;
  void *v10;
  void *v11;
  int64_t v12;
  void *v13;
  void *v14;
  int64_t v15;
  void *v16;
  void *v17;
  int64_t v18;
  void *v19;
  void *v20;
  int64_t v21;
  void *v22;
  void *v23;
  uint64_t v24;
  uint64_t v25;
  int64_t v26;
  void *v27;
  void *v28;
  uint64_t v29;
  void (*v30)(uint64_t, uint64_t);
  uint64_t v31;
  uint64_t v32;
  uint64_t *v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t *v37;
  uint64_t *v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t *v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t *v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v51;
  uint64_t *v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  uint64_t *v56;
  uint64_t *v57;
  uint64_t *v58;
  uint64_t *v59;
  uint64_t *v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  uint64_t v66;
  void v67[2];
  uint64_t *v68;

  unint64_t v63 = a1;
  uint64_t v2 = v1;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind?)
                             - 8)
                 + 64);
  uint64_t v4 = alloca(v3);
  unint64_t v5 = alloca(v3);
  uint64_t v51 = (uint64_t)&v51;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.Extent<Int>)
                             - 8)
                 + 64);
  int64_t v7 = alloca(v6);
  char v8 = alloca(v6);
  uint64_t v52 = &v51;
  uint64_t v55 = type metadata accessor for TensorShape(0);
  uint64_t v66 = *(void *)(v55 - 8);
  int64_t v9 = *(void *)(v66 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v56 = &v51;
  int64_t v12 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork.WeightParameters?)
                              - 8)
                  + 64);
  uint64_t v13 = alloca(v12);
  char v14 = alloca(v12);
  uint64_t v60 = &v51;
  int64_t v15 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?)
                              - 8)
                  + 64);
  int64_t v16 = alloca(v15);
  unint64_t v17 = alloca(v15);
  uint64_t v58 = &v51;
  uint64_t v64 = type metadata accessor for Tensor(0);
  uint64_t v68 = *(uint64_t **)(v64 - 8);
  int64_t v18 = v68[8];
  uint64_t v19 = alloca(v18);
  unint64_t v20 = alloca(v18);
  uint64_t v61 = type metadata accessor for NeuralNetwork.WeightParameters(0);
  int64_t v21 = *(void *)(*(void *)(v61 - 8) + 64);
  int64_t v22 = alloca(v21);
  unint64_t v23 = alloca(v21);
  uint64_t v59 = &v51;
  uint64_t v24 = type metadata accessor for Conv2D(0);
  uint64_t v25 = *(void *)(v24 - 8);
  int64_t v26 = *(void *)(v25 + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  v67[1] = v2;
  NeuralNetwork.Layer.ConvolutionParameters.init()();
  uint64_t v53 = v24;
  uint64_t v54 = v25;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v25 + 16))(&v51, v63, v24);
  Conv2D.weight.getter();
  uint64_t v29 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
  uint64_t v30 = (void (*)(uint64_t, uint64_t))v68[1];
  uint64_t v57 = &v51;
  int64_t v31 = (uint64_t)v58;
  uint64_t v32 = v64;
  uint64_t v65 = v30;
  v30((uint64_t)&v51, v64);
  uint64_t v33 = v59;
  NeuralNetwork.WeightParameters.init(_:updatable:)(v29, 0);
  NeuralNetwork.Layer.ConvolutionParameters.weights.setter(v33);
  uint64_t v68 = &v51;
  BOOL v34 = v32;
  Conv2D.bias.getter();
  if (__swift_getEnumTagSinglePayload(v31, 1, v32) == 1)
  {
    outlined destroy of Tensor?(v31);
  }
  else
  {
    uint64_t v35 = Tensor.scalars<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
    v65(v31, v34);
    uint64_t v36 = (uint64_t)v60;
    NeuralNetwork.WeightParameters.init(_:updatable:)(v35, 0);
    __swift_storeEnumTagSinglePayload(v36, 0, 1, v61);
    NeuralNetwork.Layer.ConvolutionParameters.bias.setter(v36);
  }
  uint64_t v37 = v57;
  Conv2D.weight.getter();
  uint64_t v38 = v56;
  Tensor.shape.getter();
  v65((uint64_t)v37, v34);
  uint64_t v39 = TensorShape.subscript.getter(0);
  uint64_t v66 = *(void *)(v66 + 8);
  uint64_t v40 = v55;
  ((void (*)(uint64_t *, uint64_t))v66)(v38, v55);
  NeuralNetwork.Layer.ConvolutionParameters.outputChannelCount.setter(v39);
  Conv2D.weight.getter();
  Tensor.shape.getter();
  v65((uint64_t)v37, v64);
  uint64_t v41 = TensorShape.subscript.getter(1);
  ((void (*)(uint64_t *, uint64_t))v66)(v38, v40);
  NeuralNetwork.Layer.ConvolutionParameters.kernelChannelCount.setter(v41);
  uint64_t v42 = v68;
  uint64_t v43 = Conv2D.groupCount.getter();
  NeuralNetwork.Layer.ConvolutionParameters.groupCount.setter(v43);
  unint64_t v62 = Conv2D.kernelSize.getter();
  Conv2D.kernelSize.getter();
  v67[0] = v44;
  uint64_t v45 = v52;
  NeuralNetwork.Extent.init(height:width:)(&v62, v67, &type metadata for Int, &protocol witness table for Int);
  NeuralNetwork.Layer.ConvolutionParameters.kernelSize.setter(v45);
  unint64_t v62 = Conv2D.stride.getter();
  Conv2D.stride.getter();
  v67[0] = v46;
  NeuralNetwork.Extent.init(height:width:)(&v62, v67, &type metadata for Int, &protocol witness table for Int);
  NeuralNetwork.Layer.ConvolutionParameters.strides.setter(v45);
  unint64_t v62 = Conv2D.dilation.getter();
  Conv2D.dilation.getter();
  v67[0] = v47;
  NeuralNetwork.Extent.init(height:width:)(&v62, v67, &type metadata for Int, &protocol witness table for Int);
  NeuralNetwork.Layer.ConvolutionParameters.dilationFactor.setter(v45);
  BOOL v48 = v51;
  NeuralNetwork.ValidPaddingParameters.init()();
  LODWORD(v41) = enum case for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind.valid(_:);
  uint64_t v49 = type metadata accessor for NeuralNetwork.Layer.ConvolutionParameters.PaddingKind(0);
  (*(void (**)(uint64_t, void, uint64_t))(*(void *)(v49 - 8) + 104))(v48, v41, v49);
  __swift_storeEnumTagSinglePayload(v48, 0, 1, v49);
  NeuralNetwork.Layer.ConvolutionParameters.padding.setter(v48);
  outlined destroy of MLImageClassifier.ModelParameters.ValidationData(v63, type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v54 + 8))(v42, v53);
}

BOOL static MLObjectDetector.ModelParameters.ModelAlgorithmType.== infix(_:_:)(uint64_t a1, uint64_t a2)
{
  char v2 = *(unsigned char *)(a2 + 8);
  if (!*(unsigned char *)(a1 + 8))
  {
    if ((v2 & 1) == 0) {
      return *(void *)a1 == *(void *)a2;
    }
    return 0;
  }
  BOOL result = 1;
  if ((v2 & 1) == 0) {
    return 0;
  }
  return result;
}

BOOL protocol witness for static Equatable.== infix(_:_:) in conformance MLObjectDetector.ModelParameters.ModelAlgorithmType(uint64_t a1, uint64_t a2)
{
  return static MLObjectDetector.ModelParameters.ModelAlgorithmType.== infix(_:_:)(a1, a2);
}

uint64_t getEnumTagSinglePayload for MLObjectDetector.ModelParameters.ModelAlgorithmType(uint64_t a1, int a2)
{
  uint64_t result = 0;
  if (a2)
  {
    if (*(unsigned char *)(a1 + 9)) {
      return (*(_DWORD *)a1 + 1);
    }
  }
  return result;
}

void storeEnumTagSinglePayload for MLObjectDetector.ModelParameters.ModelAlgorithmType(uint64_t a1, int a2, int a3)
{
  if (!a2)
  {
    if (!a3) {
      return;
    }
    char v3 = 0;
    goto LABEL_6;
  }
  *(void *)a1 = 0;
  *(unsigned char *)(a1 + 8) = 0;
  *(_DWORD *)a1 = a2 - 1;
  char v3 = 1;
  if (a3) {
LABEL_6:
  }
    *(unsigned char *)(a1 + 9) = v3;
}

uint64_t getEnumTag for MLObjectDetector.ModelParameters.ModelAlgorithmType(uint64_t a1)
{
  if (*(unsigned char *)(a1 + 8)) {
    return (*(_DWORD *)a1 + 1);
  }
  else {
    return 0;
  }
}

char destructiveInjectEnumTag for MLObjectDetector.ModelParameters.ModelAlgorithmType(uint64_t a1, int a2)
{
  if (a2)
  {
    *(void *)a1 = (a2 - 1);
    char result = 1;
  }
  else
  {
    char result = 0;
  }
  *(unsigned char *)(a1 + 8) = result;
  return result;
}

ValueMetadata *type metadata accessor for MLObjectDetector.ModelParameters.ModelAlgorithmType()
{
  return &type metadata for MLObjectDetector.ModelParameters.ModelAlgorithmType;
}

uint64_t MLImageClassifier.DataSource.labeledImages()()
{
  return static _ImageUtilities.getImageURLsAndLabels(from:)(v0);
}

void *MLImageClassifier.DataSource.stratifiedSplit(proportions:seed:)(uint64_t a1, uint64_t a2)
{
  uint64_t v10 = a1;
  if (a2 < 0)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, "Negative value is not representable", 35, 2, "Swift/Integers.swift", 20, 2, 3451, 1);
    BUG();
  }
  uint64_t v4 = (void *)v3;
  uint64_t v5 = type metadata accessor for MersenneTwisterGenerator();
  swift_allocObject(v5, 136, 7);
  int64_t v9 = MersenneTwisterGenerator.init(seed:)(a2);
  uint64_t v6 = static _ImageUtilities.getImageURLsAndLabels(from:)(v3);
  if (v2)
  {
    swift_release();
  }
  else
  {
    char v7 = v6;
    uint64_t v4 = specialized stratifiedSplitGenerator<A>(proportions:generator:fileURLAndLabel:)(v10, (uint64_t)&v9, v6);
    swift_release();
    swift_bridgeObjectRelease(v7);
  }
  return v4;
}

void *MLImageClassifier.DataSource.stratifiedSplit<A>(proportions:generator:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v6 = (void *)a2;
  uint64_t v7 = static _ImageUtilities.getImageURLsAndLabels(from:)(v5);
  if (!v4)
  {
    char v8 = v7;
    uint64_t v6 = stratifiedSplitGenerator<A>(proportions:generator:fileURLAndLabel:)(a1, a2, v7, a3, a4);
    swift_bridgeObjectRelease(v8);
  }
  return v6;
}

uint64_t *initializeBufferWithCopyOfBuffer for MLImageClassifier.DataSource(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) == 0)
  {
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, a3);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v9 = *a2;
      uint64_t *v3 = *a2;
      swift_bridgeObjectRetain(v9);
      uint64_t v14 = 2;
    }
    else
    {
      if (EnumCaseMultiPayload != 1)
      {
        uint64_t v12 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v12 - 8) + 16))(a1, a2, v12);
        uint64_t v11 = a3;
        uint64_t v10 = 0;
        goto LABEL_9;
      }
      uint64_t v7 = type metadata accessor for URL(0);
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v7 - 8) + 16))(a1, a2, v7);
      uint64_t v14 = 1;
    }
    uint64_t v10 = v14;
    a1 = v3;
    uint64_t v11 = a3;
LABEL_9:
    swift_storeEnumTagMultiPayload(a1, v11, v10);
    return v3;
  }
  uint64_t v8 = *a2;
  uint64_t *v3 = *a2;
  uint64_t v3 = (uint64_t *)(v8 + ((v4 + 16) & ~v4));
  swift_retain(v8);
  return v3;
}

uint64_t destroy for MLImageClassifier.DataSource(void *a1, uint64_t a2)
{
  uint64_t result = swift_getEnumCaseMultiPayload(a1, a2);
  if (result == 2) {
    return swift_bridgeObjectRelease(*a1);
  }
  if (result <= 1)
  {
    uint64_t v3 = type metadata accessor for URL(0);
    return (*(uint64_t (**)(void *, uint64_t))(*(void *)(v3 - 8) + 8))(a1, v3);
  }
  return result;
}

uint64_t *initializeWithCopy for MLImageClassifier.DataSource(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  int v4 = a1;
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, a3);
  if (EnumCaseMultiPayload == 2)
  {
    uint64_t v7 = *a2;
    uint64_t *v4 = *a2;
    swift_bridgeObjectRetain(v7);
    uint64_t v12 = 2;
  }
  else
  {
    if (EnumCaseMultiPayload != 1)
    {
      uint64_t v10 = type metadata accessor for URL(0);
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v10 - 8) + 16))(a1, a2, v10);
      uint64_t v9 = a3;
      uint64_t v8 = 0;
      goto LABEL_7;
    }
    uint64_t v6 = type metadata accessor for URL(0);
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
    uint64_t v12 = 1;
  }
  uint64_t v8 = v12;
  a1 = v4;
  uint64_t v9 = a3;
LABEL_7:
  swift_storeEnumTagMultiPayload(a1, v9, v8);
  return v4;
}

void *assignWithCopy for MLImageClassifier.DataSource(uint64_t a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v3 = (void *)a1;
  if ((uint64_t *)a1 != a2)
  {
    outlined destroy of MLImageClassifier.DataSource(a1);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, a3);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v7 = *a2;
      void *v3 = *a2;
      swift_bridgeObjectRetain(v7);
      uint64_t v12 = 2;
    }
    else
    {
      if (EnumCaseMultiPayload != 1)
      {
        uint64_t v10 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t *, uint64_t))(*(void *)(v10 - 8) + 16))(a1, a2, v10);
        uint64_t v9 = a3;
        uint64_t v8 = 0;
        goto LABEL_8;
      }
      uint64_t v6 = type metadata accessor for URL(0);
      (*(void (**)(uint64_t, uint64_t *, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
      uint64_t v12 = 1;
    }
    uint64_t v8 = v12;
    a1 = (uint64_t)v3;
    uint64_t v9 = a3;
LABEL_8:
    swift_storeEnumTagMultiPayload(a1, v9, v8);
  }
  return v3;
}

uint64_t type metadata accessor for MLImageClassifier.DataSource(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLImageClassifier.DataSource;
  if (!type metadata singleton initialization cache for MLImageClassifier.DataSource) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLImageClassifier.DataSource);
  }
  return result;
}

void *initializeWithTake for MLImageClassifier.DataSource(void *__dst, void *__src, uint64_t a3)
{
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
  if (EnumCaseMultiPayload == 1)
  {
    uint64_t v8 = type metadata accessor for URL(0);
    (*(void (**)(void *, void *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
    uint64_t v7 = 1;
    uint64_t v6 = a3;
  }
  else
  {
    if (EnumCaseMultiPayload)
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
      return __dst;
    }
    uint64_t v5 = type metadata accessor for URL(0);
    (*(void (**)(void *, void *, uint64_t))(*(void *)(v5 - 8) + 32))(__dst, __src, v5);
    uint64_t v6 = a3;
    uint64_t v7 = 0;
  }
  swift_storeEnumTagMultiPayload(__dst, v6, v7);
  return __dst;
}

void *assignWithTake for MLImageClassifier.DataSource(void *__dst, void *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLImageClassifier.DataSource((uint64_t)__dst);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
    if (EnumCaseMultiPayload == 1)
    {
      uint64_t v8 = type metadata accessor for URL(0);
      (*(void (**)(void *, void *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
      uint64_t v7 = 1;
      uint64_t v6 = a3;
    }
    else
    {
      if (EnumCaseMultiPayload)
      {
        memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
        return __dst;
      }
      uint64_t v5 = type metadata accessor for URL(0);
      (*(void (**)(void *, void *, uint64_t))(*(void *)(v5 - 8) + 32))(__dst, __src, v5);
      uint64_t v6 = a3;
      uint64_t v7 = 0;
    }
    swift_storeEnumTagMultiPayload(__dst, v6, v7);
  }
  return __dst;
}

uint64_t type metadata completion function for MLImageClassifier.DataSource(uint64_t a1)
{
  uint64_t result = type metadata accessor for URL(319);
  if (v4 <= 0x3F)
  {
    v5[0] = *(void *)(result - 8) + 64;
    v5[1] = v5[0];
    v5[2] = (char *)&value witness table for Builtin.BridgeObject + 64;
    swift_initEnumMetadataMultiPayload(a1, 256, 3, v5, v2, v3);
    return 0;
  }
  return result;
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML22MLBoostedTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML22ijk100V30trainWithRecommendedParameters12trainingData010validationK012targetColumn14featureColumnsSayACG07c5K00K5e24V_ALSgSSSaySSGSgtKFZAC05l6I0V010N21K0OALcASmcfu_AsLcfu0_AOXMtTf1ncn_nTm(uint64_t a1, uint64_t a2, uint64_t (*a3)(void))
{
  int64_t v21 = a3;
  uint64_t v20 = v3;
  uint64_t v4 = type metadata accessor for DataFrame(0);
  uint64_t v19 = *(void *)(v4 - 8);
  int64_t v5 = *(void *)(v19 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                             - 8)
                 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  outlined init with copy of DataFrame?(a1, (uint64_t)&v18);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v18, 1, v4) == 1)
  {
    uint64_t v11 = v21(0);
    uint64_t v12 = v20;
    uint64_t v13 = 1;
    uint64_t v14 = v11;
  }
  else
  {
    uint64_t v15 = v19;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v19 + 32))(&v18, &v18, v4);
    uint64_t v16 = v20;
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v15 + 16))(v20, &v18, v4);
    int64_t v21 = (uint64_t (*)(void))v21(0);
    swift_storeEnumTagMultiPayload(v16, v21, 2);
    (*(void (**)(uint64_t *, uint64_t))(v15 + 8))(&v18, v4);
    uint64_t v12 = v16;
    uint64_t v13 = 0;
    uint64_t v14 = (uint64_t)v21;
  }
  return __swift_storeEnumTagSinglePayload(v12, v13, 1, v14);
}

void *static MLLogisticRegressionClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v35 = v5;
  uint64_t v31 = a4;
  uint64_t v32 = a3;
  uint64_t v34 = a2;
  uint64_t v33 = a1;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLLogisticRegressionClassifier.ModelParameters.ValidationData?)
                             - 8)
                 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData(0);
  int64_t v11 = *(void *)(*(void *)(v10 - 8) + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  uint64_t v36 = v24;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML22MLBoostedTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML22ijk100V30trainWithRecommendedParameters12trainingData010validationK012targetColumn14featureColumnsSayACG07c5K00K5e24V_ALSgSSSaySSGSgtKFZAC05l6I0V010N21K0OALcASmcfu_AsLcfu0_AOXMtTf1ncn_nTm(a2, (uint64_t)v29, type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
  uint64_t v35 = v5;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v24, 1, v10);
  uint64_t v30 = a5;
  if (EnumTagSinglePayload == 1)
  {
    swift_storeEnumTagMultiPayload(v36, v10, 3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v24, &demangling cache variable for type metadata for MLLogisticRegressionClassifier.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)v24, (uint64_t)v36, type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
  }
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLLogisticRegressionClassifier.ModelParameters>);
  uint64_t inited = swift_initStackObject(v17, v24);
  *(void *)(inited + 16) = 2;
  *(void *)(inited + 24) = 4;
  uint64_t v19 = (uint64_t)v36;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v36, (uint64_t)v24, type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
  MLLogisticRegressionClassifier.ModelParameters.init(validation:maxIterations:l1Penalty:l2Penalty:stepSize:convergenceThreshold:featureRescaling:)((uint64_t)v24, 10, 1, 0.0, 0.01, 1.0, 0.01);
  outlined init with copy of MLTrainingSessionParameters(v19, (uint64_t)v24, type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
  MLLogisticRegressionClassifier.ModelParameters.init(validation:maxIterations:l1Penalty:l2Penalty:stepSize:convergenceThreshold:featureRescaling:)((uint64_t)v24, 10, 1, 0.01, 0.01, 1.0, 0.01);
  uint64_t v20 = alloca(48);
  int64_t v21 = alloca(48);
  uint64_t v25 = v33;
  uint64_t v26 = v32;
  uint64_t v27 = v31;
  uint64_t v28 = v30;
  ML30MLLogisticRegressionClassifierV15ModelParametersVG_AHsAE_pTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay8CreateML30MLLogisticRegressionClassifierV15ModelParametersVG_AHsAE_pTg5((void (*)(uint64_t, uint64_t *))partial apply for closure #1 in static MLLogisticRegressionClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:), (uint64_t)v24, inited);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v36, type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
  swift_setDeallocating(inited);
  specialized _ContiguousArrayStorage.__deallocating_deinit();
  return ML30MLLogisticRegressionClassifierV15ModelParametersVG_AHsAE_pTg5;
}

uint64_t closure #1 in static MLLogisticRegressionClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, void (*a5)(uint64_t *, uint64_t), void *a6)
{
  uint64_t v19 = a3;
  uint64_t v21 = v6;
  unint64_t v23 = a6;
  uint64_t v20 = v7;
  uint64_t v22 = a1;
  uint64_t v10 = type metadata accessor for DataFrame(0);
  uint64_t v11 = *(void *)(v10 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v11 + 16))(&v17, a2, v10);
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v22, (uint64_t)v18);
  swift_bridgeObjectRetain((_BYTE)a5);
  swift_bridgeObjectRetain((_BYTE)a4);
  uint64_t v15 = v20;
  uint64_t result = MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v17, v19, a4, a5, (uint64_t)v18);
  if (v15)
  {
    uint64_t result = (uint64_t)v23;
    *unint64_t v23 = v15;
  }
  return result;
}

void *protocol witness for static TabularTask.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:) in conformance MLLogisticRegressionClassifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return static MLLogisticRegressionClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(a1, a2, a3, a4, a5);
}

uint64_t static MLSupportVectorClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, uint64_t a5)
{
  uint64_t v54 = v5;
  uint64_t v46 = a3;
  uint64_t v53 = a2;
  uint64_t v56 = a1;
  uint64_t v47 = type metadata accessor for DataFrame(0);
  uint64_t v49 = *(void *)(v47 - 8);
  int64_t v8 = *(void *)(v49 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v52 = (void (*)(uint64_t *, uint64_t, uint64_t))&v38;
  int64_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSupportVectorClassifier.ModelParameters.ValidationData?)
                              - 8)
                  + 64);
  int64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData(0);
  int64_t v15 = *(void *)(*(void *)(v14 - 8) + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v50 = &v38;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  BOOL v48 = &v38;
  uint64_t v20 = alloca(v15);
  uint64_t v21 = alloca(v15);
  uint64_t v55 = &v38;
  uint64_t v22 = v54;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML22MLBoostedTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML22ijk100V30trainWithRecommendedParameters12trainingData010validationK012targetColumn14featureColumnsSayACG07c5K00K5e24V_ALSgSSSaySSGSgtKFZAC05l6I0V010N21K0OALcASmcfu_AsLcfu0_AOXMtTf1ncn_nTm(v53, (uint64_t)v43, type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData);
  uint64_t v53 = v22;
  uint64_t v54 = v14;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)&v38, 1, v14);
  uint64_t v44 = a5;
  uint64_t v45 = a4;
  if (EnumTagSinglePayload == 1)
  {
    swift_storeEnumTagMultiPayload(v55, v54, 3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v38, &demangling cache variable for type metadata for MLSupportVectorClassifier.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)&v38, (uint64_t)v55, type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData);
  }
  uint64_t v24 = v56;
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLSupportVectorClassifier>);
  uint64_t v26 = *(void *)(type metadata accessor for MLSupportVectorClassifier(0) - 8);
  uint64_t v27 = *(unsigned __int8 *)(v26 + 80);
  uint64_t v28 = ((int)v27 + 32) & ~*(unsigned __int8 *)(v26 + 80);
  uint64_t v29 = swift_allocObject(v25, v28 + *(void *)(v26 + 72), v27 | 7);
  *(void *)(v29 + 16) = 1;
  *(void *)(v29 + 24) = 2;
  uint64_t v56 = v29;
  uint64_t v51 = v28 + v29;
  (*(void (**)(void, uint64_t, uint64_t))(v49 + 16))(v52, v24, v47);
  uint64_t v30 = (uint64_t)v48;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v55, (uint64_t)v48, type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData);
  memset(v39, 0, sizeof(v39));
  uint64_t v38 = 11;
  long long v40 = xmmword_349110;
  char v41 = 1;
  uint64_t v31 = (uint64_t)v50;
  outlined init with copy of MLTrainingSessionParameters(v30, (uint64_t)v50, type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData);
  v42[3] = v54;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v42);
  outlined init with take of MLClassifierMetrics(v31, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData);
  uint64_t v33 = v44;
  swift_bridgeObjectRetain(v44);
  uint64_t v34 = v45;
  swift_bridgeObjectRetain((_BYTE)v45);
  outlined assign with take of Any?((uint64_t)v42, (uint64_t)v39);
  outlined destroy of MLActivityClassifier.ModelParameters(v30, type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData);
  uint64_t v35 = v53;
  MLSupportVectorClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(v52, v46, v34, v33, (uint64_t)&v38);
  if (v35)
  {
    uint64_t v36 = v56;
    *(void *)(v56 + 16) = 0;
    swift_release();
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v55, type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData);
    return v36;
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v55, type metadata accessor for MLSupportVectorClassifier.ModelParameters.ValidationData);
    return v56;
  }
}

uint64_t protocol witness for static TabularTask.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:) in conformance MLSupportVectorClassifier(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, uint64_t a5)
{
  return static MLSupportVectorClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(a1, a2, a3, a4, a5);
}

uint64_t static MLBoostedTreeClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, uint64_t a2, uint64_t a3, char *a4, void (*a5)(_OWORD *, void *, uint64_t))
{
  uint64_t v59 = v5;
  uint64_t v53 = a3;
  uint64_t v62 = a1;
  uint64_t v60 = type metadata accessor for DataFrame(0);
  uint64_t v55 = *(void *)(v60 - 8);
  int64_t v8 = *(void *)(v55 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v58 = (void (*)(uint64_t *, uint64_t, uint64_t))v40;
  int64_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLBoostedTreeClassifier.ModelParameters.ValidationData?)
                              - 8)
                  + 64);
  int64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
  int64_t v15 = *(void *)(*(void *)(v14 - 8) + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v56 = v40;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  uint64_t v54 = v40;
  uint64_t v20 = alloca(v15);
  uint64_t v21 = alloca(v15);
  uint64_t v61 = v40;
  uint64_t v22 = v14;
  uint64_t v23 = v59;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML22MLBoostedTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML22ijk100V30trainWithRecommendedParameters12trainingData010validationK012targetColumn14featureColumnsSayACG07c5K00K5e24V_ALSgSSSaySSGSgtKFZAC05l6I0V010N21K0OALcASmcfu_AsLcfu0_AOXMtTf1ncn_nTm(a2, (uint64_t)v50, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
  uint64_t v59 = v23;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v40, 1, v22);
  uint64_t v51 = a5;
  uint64_t v52 = a4;
  uint64_t v57 = v22;
  if (EnumTagSinglePayload == 1)
  {
    swift_storeEnumTagMultiPayload(v61, v22, 3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v40, &demangling cache variable for type metadata for MLBoostedTreeClassifier.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)v40, (uint64_t)v61, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
  }
  uint64_t v25 = v62;
  uint64_t v26 = v60;
  uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLBoostedTreeClassifier>);
  uint64_t v28 = *(void *)(type metadata accessor for MLBoostedTreeClassifier(0) - 8);
  uint64_t v29 = *(unsigned __int8 *)(v28 + 80);
  uint64_t v30 = ((int)v29 + 32) & ~*(unsigned __int8 *)(v28 + 80);
  uint64_t v31 = swift_allocObject(v27, v30 + *(void *)(v28 + 72), v29 | 7);
  *(void *)(v31 + 16) = 1;
  *(void *)(v31 + 24) = 2;
  uint64_t v62 = v31;
  uint64_t v60 = v30 + v31;
  (*(void (**)(void, uint64_t, uint64_t))(v55 + 16))(v58, v25, v26);
  uint64_t v32 = (uint64_t)v54;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v61, (uint64_t)v54, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
  memset(v40, 0, sizeof(v40));
  uint64_t v41 = 6;
  uint64_t v42 = 10;
  __m128 v43 = _mm_loadh_ps((const double *)&qword_346D50);
  uint64_t v44 = 42;
  uint64_t v45 = 0x3FD3333333333333;
  uint64_t v46 = 0;
  char v47 = 1;
  long long v48 = xmmword_34E1F0;
  uint64_t v33 = (uint64_t)v56;
  outlined init with copy of MLTrainingSessionParameters(v32, (uint64_t)v56, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
  v49[3] = v57;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v49);
  outlined init with take of MLClassifierMetrics(v33, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
  uint64_t v35 = v51;
  swift_bridgeObjectRetain((_BYTE)v51);
  uint64_t v36 = v52;
  swift_bridgeObjectRetain((_BYTE)v52);
  outlined assign with take of Any?((uint64_t)v49, (uint64_t)v40);
  outlined destroy of MLActivityClassifier.ModelParameters(v32, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
  uint64_t v37 = v59;
  MLBoostedTreeClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(v58, v53, v36, v35, (uint64_t)v40);
  if (v37)
  {
    uint64_t v38 = v62;
    *(void *)(v62 + 16) = 0;
    swift_release();
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v61, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
    return v38;
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v61, type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData);
    return v62;
  }
}

uint64_t protocol witness for static TabularTask.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:) in conformance MLBoostedTreeClassifier(uint64_t a1, uint64_t a2, uint64_t a3, char *a4, void (*a5)(_OWORD *, void *, uint64_t))
{
  return static MLBoostedTreeClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(a1, a2, a3, a4, a5);
}

uint64_t static MLDecisionTreeClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, uint64_t a2, uint64_t a3, char *a4, void (*a5)(unsigned char *, void *, uint64_t))
{
  uint64_t v55 = v5;
  char v47 = a4;
  uint64_t v48 = a3;
  uint64_t v57 = a1;
  uint64_t v49 = type metadata accessor for DataFrame(0);
  uint64_t v7 = *(void *)(v49 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v54 = (void (*)(uint64_t *, uint64_t, uint64_t))&v39;
  int64_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLDecisionTreeClassifier.ModelParameters.ValidationData?)
                              - 8)
                  + 64);
  int64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData(0);
  int64_t v15 = *(void *)(*(void *)(v14 - 8) + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v51 = &v39;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  uint64_t v50 = &v39;
  uint64_t v20 = alloca(v15);
  uint64_t v21 = alloca(v15);
  uint64_t v56 = &v39;
  uint64_t v22 = v14;
  uint64_t v23 = v55;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML22MLBoostedTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML22ijk100V30trainWithRecommendedParameters12trainingData010validationK012targetColumn14featureColumnsSayACG07c5K00K5e24V_ALSgSSSaySSGSgtKFZAC05l6I0V010N21K0OALcASmcfu_AsLcfu0_AOXMtTf1ncn_nTm(a2, (uint64_t)v45, type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData);
  uint64_t v55 = v23;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)&v39, 1, v22);
  uint64_t v46 = a5;
  uint64_t v52 = v22;
  if (EnumTagSinglePayload == 1)
  {
    swift_storeEnumTagMultiPayload(v56, v22, 3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v39, &demangling cache variable for type metadata for MLDecisionTreeClassifier.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)&v39, (uint64_t)v56, type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData);
  }
  uint64_t v25 = v57;
  uint64_t v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLDecisionTreeClassifier>);
  uint64_t v27 = *(void *)(type metadata accessor for MLDecisionTreeClassifier(0) - 8);
  uint64_t v28 = *(unsigned __int8 *)(v27 + 80);
  uint64_t v29 = ((int)v28 + 32) & ~*(unsigned __int8 *)(v27 + 80);
  uint64_t v30 = swift_allocObject(v26, v29 + *(void *)(v27 + 72), v28 | 7);
  *(void *)(v30 + 16) = 1;
  *(void *)(v30 + 24) = 2;
  uint64_t v57 = v30;
  uint64_t v53 = v29 + v30;
  (*(void (**)(void, uint64_t, uint64_t))(v7 + 16))(v54, v25, v49);
  uint64_t v31 = (uint64_t)v50;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v56, (uint64_t)v50, type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData);
  memset(v41, 0, sizeof(v41));
  uint64_t v40 = 6;
  __m128 v42 = _mm_loadh_ps((const double *)&qword_346D50);
  uint64_t v43 = 42;
  uint64_t v32 = (uint64_t)v51;
  outlined init with copy of MLTrainingSessionParameters(v31, (uint64_t)v51, type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData);
  v44[3] = v52;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v44);
  outlined init with take of MLClassifierMetrics(v32, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData);
  uint64_t v34 = v46;
  swift_bridgeObjectRetain((_BYTE)v46);
  uint64_t v35 = v47;
  swift_bridgeObjectRetain((_BYTE)v47);
  outlined assign with take of Any?((uint64_t)v44, (uint64_t)v41);
  outlined destroy of MLActivityClassifier.ModelParameters(v31, type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData);
  uint64_t v36 = v55;
  MLDecisionTreeClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(v54, v48, v35, v34, (uint64_t)&v40);
  if (v36)
  {
    uint64_t v37 = v57;
    *(void *)(v57 + 16) = 0;
    swift_release();
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v56, type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData);
    return v37;
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v56, type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData);
    return v57;
  }
}

uint64_t protocol witness for static TabularTask.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:) in conformance MLDecisionTreeClassifier(uint64_t a1, uint64_t a2, uint64_t a3, char *a4, void (*a5)(unsigned char *, void *, uint64_t))
{
  return static MLDecisionTreeClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(a1, a2, a3, a4, a5);
}

uint64_t static MLRandomForestClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, uint64_t a2, uint64_t a3, char *a4, void (*a5)(uint64_t *, uint64_t *, uint64_t))
{
  uint64_t v56 = v5;
  uint64_t v50 = a3;
  uint64_t v59 = a1;
  uint64_t v57 = type metadata accessor for DataFrame(0);
  uint64_t v52 = *(void *)(v57 - 8);
  int64_t v8 = *(void *)(v52 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v55 = (void (*)(uint64_t *, uint64_t, uint64_t))v40;
  int64_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLRandomForestClassifier.ModelParameters.ValidationData?)
                              - 8)
                  + 64);
  int64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData(0);
  int64_t v15 = *(void *)(*(void *)(v14 - 8) + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v53 = v40;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  uint64_t v51 = v40;
  uint64_t v20 = alloca(v15);
  uint64_t v21 = alloca(v15);
  uint64_t v58 = v40;
  uint64_t v22 = v14;
  uint64_t v23 = v56;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML22MLBoostedTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML22ijk100V30trainWithRecommendedParameters12trainingData010validationK012targetColumn14featureColumnsSayACG07c5K00K5e24V_ALSgSSSaySSGSgtKFZAC05l6I0V010N21K0OALcASmcfu_AsLcfu0_AOXMtTf1ncn_nTm(a2, (uint64_t)v47, type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData);
  uint64_t v56 = v23;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v40, 1, v22);
  uint64_t v48 = a5;
  uint64_t v49 = a4;
  uint64_t v54 = v22;
  if (EnumTagSinglePayload == 1)
  {
    swift_storeEnumTagMultiPayload(v58, v22, 3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v40, &demangling cache variable for type metadata for MLRandomForestClassifier.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)v40, (uint64_t)v58, type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData);
  }
  uint64_t v25 = v59;
  uint64_t v26 = v57;
  uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLRandomForestClassifier>);
  uint64_t v28 = *(void *)(type metadata accessor for MLRandomForestClassifier(0) - 8);
  uint64_t v29 = *(unsigned __int8 *)(v28 + 80);
  uint64_t v30 = ((int)v29 + 32) & ~*(unsigned __int8 *)(v28 + 80);
  uint64_t v31 = swift_allocObject(v27, v30 + *(void *)(v28 + 72), v29 | 7);
  *(void *)(v31 + 16) = 1;
  *(void *)(v31 + 24) = 2;
  uint64_t v59 = v31;
  uint64_t v57 = v30 + v31;
  (*(void (**)(void, uint64_t, uint64_t))(v52 + 16))(v55, v25, v26);
  uint64_t v32 = (uint64_t)v51;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v58, (uint64_t)v51, type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData);
  memset(v40, 0, sizeof(v40));
  uint64_t v41 = 6;
  uint64_t v42 = 10;
  __m128 v43 = _mm_loadh_ps((const double *)&qword_346D50);
  uint64_t v44 = 42;
  long long v45 = xmmword_347720;
  uint64_t v33 = (uint64_t)v53;
  outlined init with copy of MLTrainingSessionParameters(v32, (uint64_t)v53, type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData);
  v46[3] = v54;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v46);
  outlined init with take of MLClassifierMetrics(v33, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData);
  uint64_t v35 = v48;
  swift_bridgeObjectRetain((_BYTE)v48);
  uint64_t v36 = v49;
  swift_bridgeObjectRetain((_BYTE)v49);
  outlined assign with take of Any?((uint64_t)v46, (uint64_t)v40);
  outlined destroy of MLActivityClassifier.ModelParameters(v32, type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData);
  uint64_t v37 = v56;
  MLRandomForestClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(v55, v50, v36, v35, (uint64_t)v40);
  if (v37)
  {
    uint64_t v38 = v59;
    *(void *)(v59 + 16) = 0;
    swift_release();
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v58, type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData);
    return v38;
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v58, type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData);
    return v59;
  }
}

uint64_t protocol witness for static TabularTask.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:) in conformance MLRandomForestClassifier(uint64_t a1, uint64_t a2, uint64_t a3, char *a4, void (*a5)(uint64_t *, uint64_t *, uint64_t))
{
  return static MLRandomForestClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(a1, a2, a3, a4, a5);
}

void *static MLLinearRegressor.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v35 = v5;
  uint64_t v31 = a4;
  uint64_t v32 = a3;
  uint64_t v34 = a2;
  uint64_t v33 = a1;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLLinearRegressor.ModelParameters.ValidationData?)
                             - 8)
                 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  int64_t v11 = *(void *)(*(void *)(v10 - 8) + 64);
  int64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = alloca(v11);
  int64_t v15 = alloca(v11);
  uint64_t v36 = v24;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML22MLBoostedTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML22ijk100V30trainWithRecommendedParameters12trainingData010validationK012targetColumn14featureColumnsSayACG07c5K00K5e24V_ALSgSSSaySSGSgtKFZAC05l6I0V010N21K0OALcASmcfu_AsLcfu0_AOXMtTf1ncn_nTm(a2, (uint64_t)v29, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  uint64_t v35 = v5;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v24, 1, v10);
  uint64_t v30 = a5;
  if (EnumTagSinglePayload == 1)
  {
    swift_storeEnumTagMultiPayload(v36, v10, 3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v24, &demangling cache variable for type metadata for MLLinearRegressor.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)v24, (uint64_t)v36, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  }
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLLinearRegressor.ModelParameters>);
  uint64_t inited = swift_initStackObject(v17, v24);
  *(void *)(inited + 16) = 2;
  *(void *)(inited + 24) = 4;
  uint64_t v19 = (uint64_t)v36;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v36, (uint64_t)v24, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  MLLinearRegressor.ModelParameters.init(validation:maxIterations:l1Penalty:l2Penalty:stepSize:convergenceThreshold:featureRescaling:)((uint64_t)v24, 10, 1, 0.0, 0.01, 1.0, 0.01);
  outlined init with copy of MLTrainingSessionParameters(v19, (uint64_t)v24, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  MLLinearRegressor.ModelParameters.init(validation:maxIterations:l1Penalty:l2Penalty:stepSize:convergenceThreshold:featureRescaling:)((uint64_t)v24, 10, 1, 0.01, 0.01, 1.0, 0.01);
  uint64_t v20 = alloca(48);
  uint64_t v21 = alloca(48);
  uint64_t v25 = v33;
  uint64_t v26 = v32;
  uint64_t v27 = v31;
  uint64_t v28 = v30;
  ML17MLLinearRegressorV15ModelParametersVG_AHsAE_pTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay8CreateML17MLLinearRegressorV15ModelParametersVG_AHsAE_pTg5((void (*)(uint64_t, uint64_t *))partial apply for closure #1 in static MLLinearRegressor.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:), (uint64_t)v24, inited);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v36, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  swift_setDeallocating(inited);
  specialized _ContiguousArrayStorage.__deallocating_deinit();
  return ML17MLLinearRegressorV15ModelParametersVG_AHsAE_pTg5;
}

uint64_t closure #1 in static MLLinearRegressor.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, uint64_t a5, void *a6)
{
  uint64_t v19 = a3;
  uint64_t v21 = v6;
  uint64_t v23 = a6;
  uint64_t v20 = v7;
  uint64_t v22 = a1;
  uint64_t v10 = type metadata accessor for DataFrame(0);
  uint64_t v11 = *(void *)(v10 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v11 + 16))(&v17, a2, v10);
  outlined init with copy of MLLinearRegressor.ModelParameters(v22, (uint64_t)v18);
  swift_bridgeObjectRetain(a5);
  swift_bridgeObjectRetain((_BYTE)a4);
  uint64_t v15 = v20;
  uint64_t result = MLLinearRegressor.init(trainingData:targetColumn:featureColumns:parameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v17, v19, a4, a5, (uint64_t)v18);
  if (v15)
  {
    uint64_t result = (uint64_t)v23;
    *uint64_t v23 = v15;
  }
  return result;
}

void *protocol witness for static TabularTask.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:) in conformance MLLinearRegressor(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return static MLLinearRegressor.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(a1, a2, a3, a4, a5);
}

uint64_t static MLBoostedTreeRegressor.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, void *a5)
{
  uint64_t v59 = v5;
  uint64_t v53 = a3;
  uint64_t v62 = a1;
  uint64_t v60 = type metadata accessor for DataFrame(0);
  uint64_t v55 = *(void *)(v60 - 8);
  int64_t v8 = *(void *)(v55 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v58 = (void (*)(uint64_t *, uint64_t, uint64_t))v40;
  int64_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLBoostedTreeRegressor.ModelParameters.ValidationData?)
                              - 8)
                  + 64);
  int64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData(0);
  int64_t v15 = *(void *)(*(void *)(v14 - 8) + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v56 = v40;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  uint64_t v54 = v40;
  uint64_t v20 = alloca(v15);
  uint64_t v21 = alloca(v15);
  uint64_t v61 = v40;
  uint64_t v22 = v14;
  uint64_t v23 = v59;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML22MLBoostedTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML22ijk100V30trainWithRecommendedParameters12trainingData010validationK012targetColumn14featureColumnsSayACG07c5K00K5e24V_ALSgSSSaySSGSgtKFZAC05l6I0V010N21K0OALcASmcfu_AsLcfu0_AOXMtTf1ncn_nTm(a2, (uint64_t)v50, type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData);
  uint64_t v59 = v23;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v40, 1, v22);
  uint64_t v51 = a5;
  uint64_t v52 = a4;
  uint64_t v57 = v22;
  if (EnumTagSinglePayload == 1)
  {
    swift_storeEnumTagMultiPayload(v61, v22, 3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v40, &demangling cache variable for type metadata for MLBoostedTreeRegressor.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)v40, (uint64_t)v61, type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData);
  }
  uint64_t v25 = v62;
  uint64_t v26 = v60;
  uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLBoostedTreeRegressor>);
  uint64_t v28 = *(void *)(type metadata accessor for MLBoostedTreeRegressor(0) - 8);
  uint64_t v29 = *(unsigned __int8 *)(v28 + 80);
  uint64_t v30 = ((int)v29 + 32) & ~*(unsigned __int8 *)(v28 + 80);
  uint64_t v31 = swift_allocObject(v27, v30 + *(void *)(v28 + 72), v29 | 7);
  *(void *)(v31 + 16) = 1;
  *(void *)(v31 + 24) = 2;
  uint64_t v62 = v31;
  uint64_t v60 = v30 + v31;
  (*(void (**)(void, uint64_t, uint64_t))(v55 + 16))(v58, v25, v26);
  uint64_t v32 = (uint64_t)v54;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v61, (uint64_t)v54, type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData);
  memset(v40, 0, sizeof(v40));
  uint64_t v41 = 6;
  uint64_t v42 = 10;
  __m128 v43 = _mm_loadh_ps((const double *)&qword_346D50);
  uint64_t v44 = 42;
  uint64_t v45 = 0x3FD3333333333333;
  uint64_t v46 = 0;
  char v47 = 1;
  long long v48 = xmmword_34E1F0;
  uint64_t v33 = (uint64_t)v56;
  outlined init with copy of MLTrainingSessionParameters(v32, (uint64_t)v56, type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData);
  v49[3] = v57;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v49);
  outlined init with take of MLClassifierMetrics(v33, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData);
  uint64_t v35 = v51;
  swift_bridgeObjectRetain((_BYTE)v51);
  uint64_t v36 = v52;
  swift_bridgeObjectRetain((_BYTE)v52);
  outlined assign with take of Any?((uint64_t)v49, (uint64_t)v40);
  outlined destroy of MLActivityClassifier.ModelParameters(v32, type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData);
  uint64_t v37 = v59;
  MLBoostedTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(v58, v53, v36, v35, (uint64_t)v40);
  if (v37)
  {
    uint64_t v38 = v62;
    *(void *)(v62 + 16) = 0;
    swift_release();
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v61, type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData);
    return v38;
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v61, type metadata accessor for MLBoostedTreeRegressor.ModelParameters.ValidationData);
    return v62;
  }
}

uint64_t protocol witness for static TabularTask.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:) in conformance MLBoostedTreeRegressor(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, void *a5)
{
  return static MLBoostedTreeRegressor.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(a1, a2, a3, a4, a5);
}

uint64_t static MLDecisionTreeRegressor.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, Swift::Int a5)
{
  uint64_t v53 = v5;
  Swift::Int v44 = a5;
  uint64_t v46 = a3;
  uint64_t v52 = a2;
  uint64_t v55 = a1;
  uint64_t v47 = type metadata accessor for DataFrame(0);
  uint64_t v7 = *(void *)(v47 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v51 = (void (*)(uint64_t *, uint64_t, uint64_t))v38;
  int64_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLDecisionTreeRegressor.ModelParameters.ValidationData?)
                              - 8)
                  + 64);
  int64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData(0);
  int64_t v15 = *(void *)(*(void *)(v14 - 8) + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v49 = v38;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  long long v48 = v38;
  uint64_t v20 = alloca(v15);
  uint64_t v21 = alloca(v15);
  uint64_t v54 = v38;
  uint64_t v22 = v53;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML22MLBoostedTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML22ijk100V30trainWithRecommendedParameters12trainingData010validationK012targetColumn14featureColumnsSayACG07c5K00K5e24V_ALSgSSSaySSGSgtKFZAC05l6I0V010N21K0OALcASmcfu_AsLcfu0_AOXMtTf1ncn_nTm(v52, (uint64_t)v43, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  uint64_t v52 = v22;
  uint64_t v53 = v14;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v38, 1, v14);
  uint64_t v45 = a4;
  if (EnumTagSinglePayload == 1)
  {
    swift_storeEnumTagMultiPayload(v54, v53, 3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v38, &demangling cache variable for type metadata for MLDecisionTreeRegressor.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)v38, (uint64_t)v54, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  }
  uint64_t v24 = v55;
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLDecisionTreeRegressor>);
  uint64_t v26 = *(void *)(type metadata accessor for MLDecisionTreeRegressor(0) - 8);
  uint64_t v27 = *(unsigned __int8 *)(v26 + 80);
  uint64_t v28 = ((int)v27 + 32) & ~*(unsigned __int8 *)(v26 + 80);
  uint64_t v29 = swift_allocObject(v25, v28 + *(void *)(v26 + 72), v27 | 7);
  *(void *)(v29 + 16) = 1;
  *(void *)(v29 + 24) = 2;
  uint64_t v55 = v29;
  uint64_t v50 = v28 + v29;
  (*(void (**)(void, uint64_t, uint64_t))(v7 + 16))(v51, v24, v47);
  uint64_t v30 = (uint64_t)v48;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v54, (uint64_t)v48, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  memset(v38, 0, sizeof(v38));
  uint64_t v39 = 6;
  __m128 v40 = _mm_loadh_ps((const double *)&qword_346D50);
  uint64_t v41 = 42;
  uint64_t v31 = (uint64_t)v49;
  outlined init with copy of MLTrainingSessionParameters(v30, (uint64_t)v49, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  v42[3] = v53;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v42);
  outlined init with take of MLClassifierMetrics(v31, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  Swift::Int v33 = v44;
  swift_bridgeObjectRetain(v44);
  uint64_t v34 = v45;
  swift_bridgeObjectRetain((_BYTE)v45);
  outlined assign with take of Any?((uint64_t)v42, (uint64_t)v38);
  outlined destroy of MLActivityClassifier.ModelParameters(v30, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  uint64_t v35 = v52;
  MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(v51, v46, v34, v33, (uint64_t)v38);
  if (v35)
  {
    uint64_t v36 = v55;
    *(void *)(v55 + 16) = 0;
    swift_release();
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v54, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
    return v36;
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v54, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
    return v55;
  }
}

uint64_t protocol witness for static TabularTask.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:) in conformance MLDecisionTreeRegressor(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, Swift::Int a5)
{
  return static MLDecisionTreeRegressor.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(a1, a2, a3, a4, a5);
}

uint64_t static MLRandomForestRegressor.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, uint64_t a5)
{
  uint64_t v58 = v5;
  uint64_t v52 = a3;
  uint64_t v61 = a1;
  uint64_t v59 = type metadata accessor for DataFrame(0);
  uint64_t v54 = *(void *)(v59 - 8);
  int64_t v8 = *(void *)(v54 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v57 = (void (*)(uint64_t *, uint64_t, uint64_t))v40;
  int64_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLRandomForestRegressor.ModelParameters.ValidationData?)
                              - 8)
                  + 64);
  int64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData(0);
  int64_t v15 = *(void *)(*(void *)(v14 - 8) + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v55 = v40;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  uint64_t v53 = v40;
  uint64_t v20 = alloca(v15);
  uint64_t v21 = alloca(v15);
  uint64_t v60 = v40;
  uint64_t v22 = v14;
  uint64_t v23 = v58;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML22MLBoostedTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML22ijk100V30trainWithRecommendedParameters12trainingData010validationK012targetColumn14featureColumnsSayACG07c5K00K5e24V_ALSgSSSaySSGSgtKFZAC05l6I0V010N21K0OALcASmcfu_AsLcfu0_AOXMtTf1ncn_nTm(a2, (uint64_t)v49, type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData);
  uint64_t v58 = v23;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v40, 1, v22);
  uint64_t v50 = a5;
  uint64_t v51 = a4;
  uint64_t v56 = v22;
  if (EnumTagSinglePayload == 1)
  {
    swift_storeEnumTagMultiPayload(v60, v22, 3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v40, &demangling cache variable for type metadata for MLRandomForestRegressor.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)v40, (uint64_t)v60, type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData);
  }
  uint64_t v25 = v61;
  uint64_t v26 = v59;
  uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLRandomForestRegressor>);
  uint64_t v28 = *(void *)(type metadata accessor for MLRandomForestRegressor(0) - 8);
  uint64_t v29 = *(unsigned __int8 *)(v28 + 80);
  uint64_t v30 = ((int)v29 + 32) & ~*(unsigned __int8 *)(v28 + 80);
  uint64_t v31 = swift_allocObject(v27, v30 + *(void *)(v28 + 72), v29 | 7);
  *(void *)(v31 + 16) = 1;
  *(void *)(v31 + 24) = 2;
  uint64_t v61 = v31;
  uint64_t v59 = v30 + v31;
  (*(void (**)(void, uint64_t, uint64_t))(v54 + 16))(v57, v25, v26);
  uint64_t v32 = (uint64_t)v53;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v60, (uint64_t)v53, type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData);
  memset(v40, 0, sizeof(v40));
  long long v46 = 0;
  uint64_t v47 = 0;
  uint64_t v41 = 6;
  uint64_t v42 = 10;
  __m128 v43 = _mm_loadh_ps((const double *)&qword_346D50);
  uint64_t v44 = 42;
  long long v45 = xmmword_347720;
  uint64_t v33 = (uint64_t)v55;
  outlined init with copy of MLTrainingSessionParameters(v32, (uint64_t)v55, type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData);
  v48[3] = v56;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v48);
  outlined init with take of MLClassifierMetrics(v33, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData);
  uint64_t v35 = v50;
  swift_bridgeObjectRetain(v50);
  uint64_t v36 = v51;
  swift_bridgeObjectRetain((_BYTE)v51);
  outlined assign with take of Any?((uint64_t)v48, (uint64_t)v40);
  outlined destroy of MLActivityClassifier.ModelParameters(v32, type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData);
  uint64_t v37 = v58;
  MLRandomForestRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(v57, v52, v36, v35, (uint64_t)v40);
  if (v37)
  {
    uint64_t v38 = v61;
    *(void *)(v61 + 16) = 0;
    swift_release();
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v60, type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData);
    return v38;
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v60, type metadata accessor for MLRandomForestRegressor.ModelParameters.ValidationData);
    return v61;
  }
}

uint64_t protocol witness for static TabularTask.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:) in conformance MLRandomForestRegressor(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, uint64_t a5)
{
  return static MLRandomForestRegressor.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(a1, a2, a3, a4, a5);
}

uint64_t partial apply for closure #1 in static MLLinearRegressor.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, void *a2)
{
  return closure #1 in static MLLinearRegressor.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(a1, *(void *)(v2 + 16), *(void *)(v2 + 24), *(void **)(v2 + 32), *(void *)(v2 + 40), a2);
}

uint64_t partial apply for closure #1 in static MLLogisticRegressionClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(uint64_t a1, void *a2)
{
  return closure #1 in static MLLogisticRegressionClassifier.trainWithRecommendedParameters(trainingData:validationData:targetColumn:featureColumns:)(a1, *(void *)(v2 + 16), *(void *)(v2 + 24), *(void **)(v2 + 32), *(void (**)(uint64_t *, uint64_t))(v2 + 40), a2);
}

uint64_t outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  (*(void (**)(uint64_t, uint64_t))(*((void *)&type metadata for MLLogisticRegressionClassifier.ModelParameters
                                             - 1)
                                           + 16))(a2, a1);
  return a2;
}

uint64_t MLHandPoseClassifier.DataSource.keypointsWithAnnotations()(__m128 a1)
{
  uint64_t v86 = v2;
  uint64_t v91 = v3;
  uint64_t v77 = v1;
  uint64_t v76 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v75 = *(void *)(v76 - 8);
  int64_t v4 = *(void *)(v75 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  int64_t v70 = (uint64_t *)&v68;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?)
                             - 8)
                 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v69 = &v68;
  uint64_t v87 = (void *)type metadata accessor for AnyColumn(0);
  uint64_t v81 = (uint64_t *)*(v87 - 1);
  int64_t v10 = v81[8];
  int64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  int64_t v71 = (uint64_t *)&v68;
  uint64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  uint64_t v84 = (uint64_t *)&v68;
  uint64_t v15 = type metadata accessor for DataFrame(0);
  uint64_t v16 = *(void *)(v15 - 8);
  int64_t v17 = *(void *)(v16 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v85 = (uint64_t *)&v68;
  uint64_t v20 = alloca(v17);
  uint64_t v21 = alloca(v17);
  uint64_t v90 = (uint64_t *)&v68;
  uint64_t v22 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
  int64_t v23 = *(void *)(*(void *)(v22 - 8) + 64);
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  outlined init with copy of MLHandPoseClassifier.DataSource((uint64_t)v91, (uint64_t)&v68);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v68, v22);
  if (EnumCaseMultiPayload != 5)
  {
    if (EnumCaseMultiPayload == 3)
    {
      char v27 = (char)v69;
      uint64_t v81 = v70;
      uint64_t v91 = v71;
      uint64_t v84 = v72;
      uint64_t v87 = v73;
      uint64_t v28 = v74;
      uint64_t v29 = (void *)v75;
      uint64_t v92 = (uint64_t)v68;
      LOBYTE(v93) = v69 & 1;
      uint64_t v90 = v68;
      outlined copy of Result<_DataTable, Error>((uint64_t)v68, (char)v69);
      uint64_t v85 = v28;
      uint64_t v30 = v86;
      static MLHandPoseClassifier.reformatKeypointsDataTable(table:featureColumn:)(&v92, (uint64_t)v28, v29, *(double *)a1.i64);
      if (v30)
      {
        outlined consume of Result<_DataTable, Error>(v92, v93);
        swift_bridgeObjectRelease((_BYTE)v91);
        swift_bridgeObjectRelease((_BYTE)v87);
        swift_bridgeObjectRelease((_BYTE)v29);
        return outlined consume of Result<_DataTable, Error>((uint64_t)v90, v27);
      }
      char v48 = (char)v87;
      static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)((uint64_t)&v92, (uint64_t)v81, v91, v85, v29, (uint64_t)v84, v87);
      swift_bridgeObjectRelease((_BYTE)v91);
      swift_bridgeObjectRelease(v48);
      swift_bridgeObjectRelease((_BYTE)v29);
      outlined consume of Result<_DataTable, Error>((uint64_t)v90, v27);
    }
    else
    {
      type metadata accessor for MLHandPoseClassifier.FeatureExtractor();
      uint64_t v47 = v86;
      static MLHandPoseClassifier.FeatureExtractor.extractFeatures(from:startingSessionId:)((uint64_t)v91, 0, a1);
      if (v47) {
        return outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)&v68);
      }
      uint64_t v92 = v82;
      LOBYTE(v93) = v83;
      outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)&v68);
    }
    goto LABEL_19;
  }
  uint64_t v31 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
  uint64_t v32 = v31[12];
  char v73 = *(uint64_t **)((char *)&v68 + v32);
  uint64_t v79 = *(uint64_t **)((char *)&v68 + v32 + 8);
  uint64_t v33 = v31[16];
  uint64_t v72 = *(uint64_t **)((char *)&v68 + v33);
  uint64_t v78 = *(uint64_t **)((char *)&v68 + v33 + 8);
  uint64_t v34 = v31[20];
  uint64_t v35 = v15;
  uint64_t v36 = *(uint64_t *)((char *)&v68 + v34);
  uint64_t v37 = *(uint64_t **)((char *)&v68 + v34 + 8);
  uint64_t v89 = v35;
  uint64_t v88 = v16;
  (*(void (**)(uint64_t *, uint64_t **))(v16 + 32))(v90, &v68);
  uint64_t v38 = (uint64_t)v84;
  uint64_t v80 = v36;
  uint64_t v91 = v37;
  uint64_t v39 = v37;
  uint64_t v40 = (uint64_t)v90;
  DataFrame.subscript.getter(v36, v39);
  uint64_t v41 = (void *)AnyColumn.wrappedElementType.getter();
  uint64_t v42 = (uint64_t *)v81[1];
  ((void (*)(uint64_t, void *))v42)(v38, v87);
  uint64_t v43 = v40;
  if (v41 != &type metadata for String) {
    goto LABEL_6;
  }
  uint64_t v74 = v42;
  uint64_t v49 = v70;
  DataFrame.subscript.getter(v80, v91, &type metadata for String);
  uint64_t v50 = (uint64_t)v69;
  uint64_t v51 = v86;
  Column<A>.parseAsJSONArrays()();
  if (v51)
  {
    swift_errorRelease(v51);
    (*(void (**)(uint64_t *, uint64_t))(v75 + 8))(v49, v76);
    __swift_storeEnumTagSinglePayload(v50, 1, 1, (uint64_t)v87);
    uint64_t v52 = v50;
LABEL_14:
    uint64_t v45 = v89;
    uint64_t v86 = 0;
    outlined destroy of AnyColumn?(v52);
    long long v46 = v85;
    uint64_t v44 = v88;
    uint64_t v43 = (uint64_t)v90;
    goto LABEL_15;
  }
  (*(void (**)(uint64_t *, uint64_t))(v75 + 8))(v49, v76);
  uint64_t v53 = v50;
  uint64_t v52 = v50;
  uint64_t v54 = v87;
  __swift_storeEnumTagSinglePayload(v53, 0, 1, (uint64_t)v87);
  if (__swift_getEnumTagSinglePayload(v52, 1, (uint64_t)v54) == 1) {
    goto LABEL_14;
  }
  uint64_t v61 = v71;
  uint64_t v62 = v52;
  uint64_t v63 = (uint64_t)v81;
  ((void (*)(uint64_t *, uint64_t, void *))v81[4])(v71, v62, v54);
  (*(void (**)(uint64_t *, uint64_t *, void *))(v63 + 16))(v84, v61, v54);
  uint64_t v64 = v91;
  swift_bridgeObjectRetain((_BYTE)v91);
  uint64_t v86 = 0;
  uint64_t v65 = (uint64_t)v90;
  DataFrame.subscript.setter(v84, v80, v64);
  ((void (*)(uint64_t *, void *))v74)(v61, v54);
  uint64_t v43 = v65;
LABEL_6:
  uint64_t v44 = v88;
  uint64_t v45 = v89;
  long long v46 = v85;
LABEL_15:
  *(double *)a1.i64 = (*(double (**)(uint64_t *, uint64_t, uint64_t))(v44 + 16))(v46, v43, v45);
  uint64_t v55 = v86;
  MLDataTable.init(_:convertArraysToShapedArrays:)((uint64_t)v46, 0, a1);
  if (v55)
  {
    (*(void (**)(uint64_t, uint64_t))(v44 + 8))(v43, v45);
    swift_bridgeObjectRelease((_BYTE)v91);
    swift_bridgeObjectRelease((_BYTE)v78);
    return swift_bridgeObjectRelease((_BYTE)v79);
  }
  uint64_t v92 = v82;
  LOBYTE(v93) = v83;
  uint64_t v56 = v80;
  uint64_t v57 = v91;
  static MLHandPoseClassifier.reformatKeypointsDataTable(table:featureColumn:)(&v92, v80, v91, *(double *)a1.i64);
  char v58 = (char)v79;
  uint64_t v59 = (void *)v56;
  LOBYTE(v56) = (_BYTE)v78;
  static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)((uint64_t)&v92, (uint64_t)v73, v79, v59, v57, (uint64_t)v72, v78);
  (*(void (**)(uint64_t *, uint64_t))(v88 + 8))(v90, v89);
  swift_bridgeObjectRelease(v58);
  swift_bridgeObjectRelease(v56);
  swift_bridgeObjectRelease((_BYTE)v57);
LABEL_19:
  uint64_t v66 = v77;
  uint64_t result = v92;
  char v67 = v93;
  *uint64_t v77 = v92;
  *((unsigned char *)v66 + 8) = v67;
  return result;
}

uint64_t type metadata accessor for MLHandPoseClassifier.DataSource(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLHandPoseClassifier.DataSource;
  if (!type metadata singleton initialization cache for MLHandPoseClassifier.DataSource) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLHandPoseClassifier.DataSource);
  }
  return result;
}

uint64_t outlined init with copy of MLHandPoseClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t MLHandPoseClassifier.DataSource.labeledMedia()(__m128 a1)
{
  unsigned __int8 v3 = static _ImageUtilities.getDataSourceSynopsisForHandPoseClassifier(from:)(v2, a1);
  uint64_t v6 = v5;
  if (!v1)
  {
    unsigned __int8 v7 = v3;
    swift_bridgeObjectRelease(v4);
    swift_bridgeObjectRelease(v7);
  }
  return v6;
}

uint64_t MLHandPoseClassifier.DataSource.imagesWithAnnotations()(__m128 a1)
{
  *(void *)&long long v158 = v2;
  unint64_t v169 = v3;
  char v159 = v1;
  double v166 = (void *)type metadata accessor for DataFrame(0);
  v161._uint64_t countAndFlagsBits = *(v166 - 1);
  int64_t v4 = *(void *)(v161._countAndFlagsBits + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v145 = &v126;
  unsigned __int8 v7 = alloca(v4);
  int64_t v8 = alloca(v4);
  v161._char object = &v126;
  uint64_t v9 = (void *)type metadata accessor for UTType(0);
  int64_t v10 = (long long *)*(v9 - 1);
  int64_t v11 = *((void *)v10 + 8);
  int64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v162 = &v126;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  uint64_t v154 = &v126;
  uint64_t v163 = type metadata accessor for URL(0);
  uint64_t v165 = *(void **)(v163 - 8);
  int64_t v16 = v165[8];
  int64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v153 = &v126;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  unint64_t v146 = &v126;
  uint64_t v21 = alloca(v16);
  uint64_t v22 = alloca(v16);
  uint64_t v160 = &v126;
  int64_t v23 = alloca(v16);
  uint64_t v24 = alloca(v16);
  uint64_t v157 = &v126;
  uint64_t v25 = alloca(v16);
  uint64_t v26 = alloca(v16);
  uint64_t v156 = &v126;
  char v27 = alloca(v16);
  uint64_t v28 = alloca(v16);
  int v155 = &v126;
  uint64_t v29 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
  int64_t v30 = *(void *)(*(void *)(v29 - 8) + 64);
  uint64_t v31 = alloca(v30);
  uint64_t v32 = alloca(v30);
  outlined init with copy of MLHandPoseClassifier.DataSource((uint64_t)v169, (uint64_t)&v126);
  switch(swift_getEnumCaseMultiPayload(&v126, v29))
  {
    case 0u:
      uint64_t v33 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
      uint64_t v34 = (char *)&v126 + v33[12];
      uint64_t v35 = v33[16];
      v161._uint64_t countAndFlagsBits = *(void *)((char *)&v126 + v35);
      unint64_t v169 = *(long long **)((char *)&v126 + v35 + 8);
      uint64_t v36 = v33[20];
      v161._char object = *(void **)((char *)&v126 + v36);
      double v166 = *(void **)((char *)&v126 + v36 + 8);
      uint64_t v37 = (void (*)(long long *, long long *, uint64_t))v165[4];
      uint64_t v38 = v163;
      v37(v157, &v126, v163);
      uint64_t v39 = (uint64_t)v160;
      v37(v160, (long long *)v34, v38);
      uint64_t v40 = v146;
      uint64_t v41 = v165;
      ((void (*)(long long *, uint64_t, uint64_t))v165[2])(v146, v39, v38);
      LOBYTE(v126) = 1;
      *(_DWORD *)((char *)&v126 + 1) = *(_DWORD *)v147;
      DWORD1(v126) = *(_DWORD *)&v147[3];
      *((void *)&v126 + 1) = 44;
      uint64_t v127 = (long long *)0xE100000000000000;
      uint64_t v128 = 0;
      char v164 = 1;
      uint64_t v129 = (void *)0xE000000000000000;
      uint64_t v130 = 92;
      unint64_t v131 = 0xE100000000000000;
      char v132 = 1;
      *(_DWORD *)uint64_t v133 = *(_DWORD *)v148;
      *(_DWORD *)&v133[3] = *(_DWORD *)&v148[3];
      uint64_t v134 = 34;
      unint64_t v135 = 0xE100000000000000;
      char v136 = 1;
      *(_DWORD *)&v137[3] = *(_DWORD *)&v149[3];
      *(_DWORD *)unint64_t v137 = *(_DWORD *)v149;
      char v138 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
      uint64_t v139 = 10;
      unint64_t v140 = 0xE100000000000000;
      long long v141 = 0;
      char v142 = 1;
      *(_DWORD *)uint64_t v143 = *(_DWORD *)v150;
      *(_DWORD *)&v143[3] = *(_DWORD *)&v150[3];
      uint64_t v144 = 0;
      uint64_t v42 = v158;
      MLDataTable.init(contentsOf:options:)(v40, &v126);
      if (v42)
      {
        uint64_t v43 = (void (*)(long long *, uint64_t))v41[1];
        v43(v160, v38);
        swift_bridgeObjectRelease((_BYTE)v166);
        swift_bridgeObjectRelease((_BYTE)v169);
        return ((uint64_t (*)(long long *, uint64_t))v43)(v157, v38);
      }
      *(void *)&long long v158 = 0;
      uint64_t v167 = v151;
      LOBYTE(v168) = v152;
      v74._uint64_t countAndFlagsBits = v161._countAndFlagsBits;
      uint64_t v75 = v169;
      v74._char object = v169;
      MLDataTable.subscript.getter(v74);
      uint64_t v76 = v126;
      char v77 = BYTE8(v126);
      if (BYTE8(v126)
        || (outlined copy of Result<_DataTable, Error>(v126, 0),
            uint64_t v162 = (long long *)v76,
            _UntypedColumn.type.getter(),
            uint64_t v76 = (uint64_t)v162,
            outlined consume of Result<_DataTable, Error>((uint64_t)v162, 0),
            (_BYTE)v151 != 2))
      {
        outlined consume of Result<_DataTable, Error>(v76, v77);
        swift_bridgeObjectRelease((_BYTE)v166);
        *(void *)&long long v126 = 0;
        *((void *)&v126 + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(26);
        swift_bridgeObjectRelease(BYTE8(v126));
        *(void *)&long long v126 = 0x206E6D756C6F43;
        *((void *)&v126 + 1) = 0xE700000000000000;
        v113._uint64_t countAndFlagsBits = v161._countAndFlagsBits;
        v113._char object = v75;
        String.append(_:)(v113);
        swift_bridgeObjectRelease((_BYTE)v75);
        v113._uint64_t countAndFlagsBits = 0xD000000000000011;
        String.append(_:)(v113);
        long long v158 = v126;
        v113._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v113._object, 0, 0);
        *(_OWORD *)uint64_t v114 = v158;
        *(_OWORD *)(v114 + 16) = 0;
        *(_OWORD *)(v114 + 32) = 0;
        *(unsigned char *)(v114 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v113._object, v114, v115, v116, v117);
        uint64_t v107 = (void (*)(long long *, uint64_t))v165[1];
        uint64_t v108 = (uint64_t)v160;
        uint64_t v106 = v163;
        goto LABEL_30;
      }
      outlined copy of Result<_DataTable, Error>(v76, 0);
      _UntypedColumn.valueAtIndex(index:)(0, 0.0);
      unint64_t v78 = *((void *)&v126 + 1);
      uint64_t v79 = v126;
      if ((_BYTE)v127 != 2)
      {
        outlined consume of MLDataValue((void *)v126, *((void **)&v126 + 1), (char)v127);
        uint64_t v79 = 0;
        unint64_t v78 = 0xE000000000000000;
      }
      outlined consume of Result<_DataTable, Error>((uint64_t)v162, 0);
      *(void *)&long long v126 = v79;
      *((void *)&v126 + 1) = v78;
      uint64_t v80 = String.init<A>(_:)(&v126, &type metadata for String, &protocol witness table for String, &protocol witness table for String);
      char v82 = v81;
      URL.init(fileURLWithPath:)(v80, v81);
      swift_bridgeObjectRelease(v82);
      char v83 = objc_opt_self(NSFileManager);
      id v84 = [v83 defaultManager];
      id v85 = v84;
      URL.path.getter(v84);
      char v87 = v86;
      NSString v88 = String._bridgeToObjectiveC()();
      swift_bridgeObjectRelease(v87);
      unsigned __int8 v89 = [v85 fileExistsAtPath:v88];

      if (!v89)
      {
        uint64_t v90 = (uint64_t)v162;
        outlined copy of Result<_DataTable, Error>((uint64_t)v162, 0);
        uint64_t v91 = specialized Array<A>.init(_:)(v90, 0, 0.0);
        uint64_t v92 = alloca(24);
        int v93 = alloca(32);
        uint64_t v127 = v157;
        uint64_t v94 = v158;
        uint64_t v95 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_SSs5NeverOTg5((void (*)(void *))partial apply for closure #1 in static _VideoUtilities.getVideoURLsAndAnnotations(from:), (uint64_t)&v126, (uint64_t)v91);
        *(void *)&long long v158 = v94;
        swift_bridgeObjectRelease((_BYTE)v91);
        uint64_t v154 = &v126;
        *(void *)&long long v126 = v95;
        uint64_t v96 = alloca(24);
        uint64_t v97 = alloca(24);
        uint64_t v127 = &v126;
        uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
        char v100 = v99;
        swift_bridgeObjectRelease(v126);
        uint64_t v101 = (uint64_t)v169;
        swift_bridgeObjectRetain((_BYTE)v169);
        MLDataTable.willMutate()();
        *(void *)&long long v126 = ML14_UntypedColumnC_s5Error_pTgm5;
        BYTE8(v126) = v100 & 1;
        MLDataTable.setColumnImpl(newColumn:named:)((uint64_t)&v126, v161._countAndFlagsBits, v101);
        swift_bridgeObjectRelease(v101);
        outlined consume of Result<_DataTable, Error>(ML14_UntypedColumnC_s5Error_pTgm5, v100);
        if (!(_BYTE)v168)
        {
          uint64_t v102 = v167;
          outlined copy of Result<_DataTable, Error>(v167, 0);
          _DataTable.columnNamesDidChange()();
          outlined consume of Result<_DataTable, Error>(v102, 0);
        }
      }
      char v103 = (char)v166;
      char v104 = (char)v169;
      uint64_t v105 = v158;
      static _ImageUtilities.renameImageTableColumns(table:imageColumn:labelColumn:)((uint64_t)&v167, v161._countAndFlagsBits, v169, (uint64_t)v161._object, v166, 0.0);
      uint64_t v106 = v163;
      if (v105)
      {
        swift_bridgeObjectRelease(v104);
        swift_bridgeObjectRelease(v103);
        outlined consume of Result<_DataTable, Error>((uint64_t)v162, 0);
        uint64_t v107 = (void (*)(long long *, uint64_t))v165[1];
        v107(v153, v106);
        uint64_t v108 = (uint64_t)v160;
LABEL_30:
        v107((long long *)v108, v106);
        v107(v157, v106);
        return outlined consume of Result<_DataTable, Error>(v167, v168);
      }
      swift_bridgeObjectRelease(v104);
      swift_bridgeObjectRelease(v103);
      outlined consume of Result<_DataTable, Error>((uint64_t)v162, 0);
      uint64_t v123 = (void (*)(long long *, uint64_t))v165[1];
      v123(v153, v106);
      v123(v160, v106);
      v123(v157, v106);
LABEL_34:
      uint64_t v124 = v159;
      uint64_t result = v167;
      char v125 = v168;
      *char v159 = v167;
      *((unsigned char *)v124 + 8) = v125;
      return result;
    case 1u:
      double v166 = v9;
      unint64_t v169 = v10;
      uint64_t v45 = (uint64_t)v156;
      uint64_t v46 = v163;
      uint64_t v47 = v165;
      ((void (*)(long long *, long long *, uint64_t))v165[4])(v156, &v126, v163);
      uint64_t v48 = (uint64_t)v162;
      static UTType.image.getter();
      uint64_t v49 = v158;
      uint64_t v50 = static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)(v45, v48);
      if (v49)
      {
        (*((void (**)(long long *, void *))v169 + 1))(v162, v166);
        uint64_t v51 = v156;
        return ((uint64_t (*)(long long *, uint64_t))v47[1])(v51, v46);
      }
      uint64_t v109 = (uint64_t)v50;
      (*((void (**)(long long *, void *))v169 + 1))(v162, v166);
      static _ImageUtilities.generateImageTable(_:)(v109);
      swift_bridgeObjectRelease(v109);
      uint64_t v120 = v126;
      char v121 = BYTE8(v126);
      uint64_t v167 = v126;
      LOBYTE(v168) = BYTE8(v126) & 1;
      BYTE8(v126) &= 1u;
      outlined copy of Result<_DataTable, Error>(v126, v121);
      static _ImageUtilities.validateImageInput(trainingData:imageColumn:labelColumn:)((uint64_t)&v126, 0x7461506567616D69, 0xE900000000000068, 0x6C6562616CLL, 0xE500000000000000, *(double *)a1.i64);
      outlined consume of Result<_DataTable, Error>(v120, v121);
      uint64_t v122 = v156;
      goto LABEL_32;
    case 2u:
      double v166 = v9;
      unint64_t v169 = v10;
      uint64_t v52 = (uint64_t)v155;
      uint64_t v46 = v163;
      uint64_t v47 = v165;
      ((void (*)(long long *, long long *, uint64_t))v165[4])(v155, &v126, v163);
      uint64_t v53 = (uint64_t)v154;
      static UTType.image.getter();
      uint64_t v54 = v158;
      uint64_t v55 = static _FileUtilities.collectFilesLabeledByFileName(at:type:)(v52, v53);
      if (v54)
      {
        (*((void (**)(long long *, void *))v169 + 1))(v154, v166);
        uint64_t v51 = v155;
        return ((uint64_t (*)(long long *, uint64_t))v47[1])(v51, v46);
      }
      uint64_t v110 = v55;
      (*((void (**)(long long *, void *))v169 + 1))(v154, v166);
      static _ImageUtilities.generateImageTable(_:)(v110);
      swift_bridgeObjectRelease(v110);
      uint64_t v118 = v126;
      char v119 = BYTE8(v126);
      uint64_t v167 = v126;
      LOBYTE(v168) = BYTE8(v126) & 1;
      BYTE8(v126) &= 1u;
      outlined copy of Result<_DataTable, Error>(v126, v119);
      static _ImageUtilities.validateImageInput(trainingData:imageColumn:labelColumn:)((uint64_t)&v126, 0x7461506567616D69, 0xE900000000000068, 0x6C6562616CLL, 0xE500000000000000, *(double *)a1.i64);
      outlined consume of Result<_DataTable, Error>(v118, v119);
      uint64_t v122 = v155;
LABEL_32:
      ((void (*)(long long *, uint64_t))v165[1])(v122, v163);
      goto LABEL_34;
    case 3u:
      char v56 = (char)v128;
      char v57 = v130;
      char v58 = v132;
      outlined consume of Result<_DataTable, Error>(v126, SBYTE8(v126));
      swift_bridgeObjectRelease(v58);
      swift_bridgeObjectRelease(v57);
      swift_bridgeObjectRelease(v56);
      return MLDataTable.init()();
    case 4u:
      char v59 = BYTE8(v126);
      unint64_t v169 = v127;
      uint64_t v60 = v128;
      uint64_t v165 = v129;
      uint64_t v61 = (long long *)v130;
      uint64_t v167 = v126;
      LOBYTE(v168) = BYTE8(v126) & 1;
      uint64_t v163 = v126;
      outlined copy of Result<_DataTable, Error>(v126, SBYTE8(v126));
      uint64_t v62 = (uint64_t)v169;
      unint64_t v169 = v61;
      uint64_t v63 = v158;
      static _ImageUtilities.renameImageTableColumns(table:imageColumn:labelColumn:)((uint64_t)&v167, v62, v60, (uint64_t)v165, v61, *(double *)a1.i64);
      if (!v63)
      {
        swift_bridgeObjectRelease((_BYTE)v60);
        swift_bridgeObjectRelease((_BYTE)v169);
        outlined consume of Result<_DataTable, Error>(v163, v59);
        goto LABEL_34;
      }
      swift_bridgeObjectRelease((_BYTE)v60);
      swift_bridgeObjectRelease((_BYTE)v169);
      outlined consume of Result<_DataTable, Error>(v163, v59);
      return outlined consume of Result<_DataTable, Error>(v167, v168);
    case 5u:
      uint64_t v64 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      swift_bridgeObjectRelease(*(void *)((char *)&v126 + v64[12] + 8));
      swift_bridgeObjectRelease(*(void *)((char *)&v126 + v64[16] + 8));
      swift_bridgeObjectRelease(*(void *)((char *)&v126 + v64[20] + 8));
      MLDataTable.init()();
      return (*(uint64_t (**)(long long *, void *))(v161._countAndFlagsBits + 8))(&v126, v166);
    case 6u:
      uint64_t v65 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
      uint64_t v66 = *(int *)(v65 + 48);
      uint64_t v163 = *(void *)((char *)&v126 + v66);
      unint64_t v169 = *(long long **)((char *)&v126 + v66 + 8);
      uint64_t v67 = *(int *)(v65 + 64);
      uint64_t v160 = *(long long **)((char *)&v126 + v67);
      uint64_t v165 = *(void **)((char *)&v126 + v67 + 8);
      char object = v161._object;
      uint64_t v69 = v166;
      uint64_t countAndFlagsBits = v161._countAndFlagsBits;
      (*(void (**)(void *, long long *, void *))(v161._countAndFlagsBits + 32))(v161._object, &v126, v166);
      uint64_t v71 = (uint64_t)v145;
      *(double *)a1.i64 = (*(double (**)(long long *, void *, void *))(countAndFlagsBits + 16))(v145, object, v69);
      uint64_t v72 = v158;
      MLDataTable.init(_:convertArraysToShapedArrays:)(v71, 0, a1);
      uint64_t v73 = countAndFlagsBits;
      if (v72)
      {
        (*(void (**)(void *, void *))(countAndFlagsBits + 8))(v161._object, v166);
        swift_bridgeObjectRelease((_BYTE)v165);
        return swift_bridgeObjectRelease((_BYTE)v169);
      }
      uint64_t v111 = v161._object;
      uint64_t v167 = v126;
      LOBYTE(v168) = BYTE8(v126);
      char v112 = (char)v165;
      static _ImageUtilities.renameImageTableColumns(table:imageColumn:labelColumn:)((uint64_t)&v167, v163, v169, (uint64_t)v160, v165, *(double *)a1.i64);
      (*(void (**)(void *, void *))(v73 + 8))(v111, v166);
      swift_bridgeObjectRelease((_BYTE)v169);
      swift_bridgeObjectRelease(v112);
      goto LABEL_34;
  }
}

uint64_t MLHandPoseClassifier.DataSource.extractKeypoints()(__m128 a1)
{
  uint64_t v100 = v2;
  v105._uint64_t countAndFlagsBits = v3;
  uint64_t v91 = v1;
  uint64_t v88 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Data>);
  uint64_t v87 = *(void *)(v88 - 8);
  int64_t v4 = *(void *)(v87 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v92 = &v76;
  uint64_t v86 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v85 = *(void *)(v86 - 8);
  int64_t v7 = *(void *)(v85 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v79 = &v76;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?)
                              - 8)
                  + 64);
  int64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  uint64_t v80 = &v76;
  uint64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  unint64_t v78 = &v76;
  char v104 = (uint64_t *)type metadata accessor for AnyColumn(0);
  uint64_t v97 = *(v104 - 1);
  int64_t v15 = *(void *)(v97 + 64);
  int64_t v16 = alloca(v15);
  int64_t v17 = alloca(v15);
  uint64_t v94 = &v76;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  int v93 = &v76;
  uint64_t v20 = alloca(v15);
  uint64_t v21 = alloca(v15);
  id v84 = &v76;
  uint64_t v22 = type metadata accessor for DataFrame(0);
  uint64_t v23 = *(void *)(v22 - 8);
  int64_t v24 = *(void *)(v23 + 64);
  uint64_t v25 = alloca(v24);
  uint64_t v26 = alloca(v24);
  char v99 = &v76;
  uint64_t v27 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
  int64_t v28 = *(void *)(*(void *)(v27 - 8) + 64);
  uint64_t v29 = alloca(v28);
  int64_t v30 = alloca(v28);
  outlined init with copy of MLHandPoseClassifier.DataSource(v105._countAndFlagsBits, (uint64_t)&v76);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v76, v27);
  if (EnumCaseMultiPayload == 5)
  {
    uint64_t v37 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
    uint64_t v38 = v37[12];
    char v82 = *(void **)((char *)&v76 + v38);
    uint64_t v98 = *(void **)((char *)&v76 + v38 + 8);
    uint64_t v39 = v37[16];
    uint64_t v81 = *(void **)((char *)&v76 + v39);
    unsigned __int8 v89 = *(void **)((char *)&v76 + v39 + 8);
    uint64_t v40 = v37[20];
    v105._uint64_t countAndFlagsBits = *(uint64_t *)((char *)&v76 + v40);
    uint64_t v41 = *(void **)((char *)&v76 + v40 + 8);
    uint64_t v90 = v23;
    uint64_t v42 = *(void (**)(uint64_t, uint64_t, uint64_t))(v23 + 32);
    uint64_t v95 = v22;
    char v83 = v42;
    v42((uint64_t)v99, (uint64_t)&v76, v22);
    uint64_t v43 = v84;
    double in = v41;
    DataFrame.subscript.getter(v105._countAndFlagsBits, v41);
    uint64_t v44 = (void *)AnyColumn.wrappedElementType.getter();
    uint64_t v45 = *(void (**)(uint64_t *, uint64_t *))(v97 + 8);
    v45(v43, v104);
    uint64_t v96 = v45;
    if (v44 == &type metadata for String)
    {
      uint64_t v50 = v79;
      DataFrame.subscript.getter(v105._countAndFlagsBits, in, &type metadata for String);
      uint64_t v51 = (uint64_t)v78;
      uint64_t v52 = v100;
      Column<A>.parseAsJSONArrays()();
      if (v52)
      {
        swift_errorRelease(v52);
        (*(void (**)(uint64_t *, uint64_t))(v85 + 8))(v50, v86);
        __swift_storeEnumTagSinglePayload(v51, 1, 1, (uint64_t)v104);
        uint64_t v53 = v51;
      }
      else
      {
        uint64_t v100 = 0;
        (*(void (**)(uint64_t *, uint64_t))(v85 + 8))(v50, v86);
        uint64_t v53 = v51;
        uint64_t v58 = (uint64_t)v104;
        __swift_storeEnumTagSinglePayload(v51, 0, 1, (uint64_t)v104);
        if (__swift_getEnumTagSinglePayload(v51, 1, v58) != 1)
        {
          uint64_t v71 = v97;
          (*(void (**)(uint64_t *, uint64_t, uint64_t))(v97 + 32))(v93, v53, v58);
          uint64_t v72 = v84;
          (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v71 + 16))(v84, v93, v58);
          uint64_t v73 = in;
          swift_bridgeObjectRetain((_BYTE)in);
          Swift::String v74 = v72;
          uint64_t countAndFlagsBits = v105._countAndFlagsBits;
          DataFrame.subscript.setter(v74, v105._countAndFlagsBits, v73);
          uint64_t v48 = countAndFlagsBits;
          uint64_t v47 = v73;
          v96(v93, v104);
          goto LABEL_21;
        }
      }
      uint64_t v47 = in;
      uint64_t v48 = v105._countAndFlagsBits;
      uint64_t v59 = v53;
    }
    else
    {
      DataFrame.subscript.getter(v105._countAndFlagsBits, in);
      uint64_t v46 = (void *)AnyColumn.wrappedElementType.getter();
      v96(v43, v104);
      if (v46 != &type metadata for Data)
      {
        uint64_t v47 = in;
        uint64_t v48 = v105._countAndFlagsBits;
LABEL_21:
        v64._uint64_t countAndFlagsBits = v48;
        v64._char object = v47;
        uint64_t v65 = v48;
        uint64_t v66 = (uint64_t)v99;
        DataFrame.flattenNestedArrays(in:shape:)(v64, (Swift::OpaquePointer)&outlined read-only object #0 of MLHandPoseClassifier.DataSource.extractKeypoints());
        if (v67)
        {
          (*(void (**)(uint64_t, uint64_t))(v90 + 8))(v66, v95);
          swift_bridgeObjectRelease((_BYTE)v98);
          char v68 = (char)v89;
        }
        else
        {
          uint64_t v69 = v65;
          char v70 = (char)v89;
          static _VideoUtilities.renameFeatureColumns(dataFrame:sessionIdColumn:featureColumn:labelColumn:)(v66, (uint64_t)v82, v98, v69, v47, v81, v89);
          v83(v91, v66, v95);
          swift_bridgeObjectRelease((_BYTE)v98);
          char v68 = v70;
        }
        swift_bridgeObjectRelease(v68);
        char v36 = (char)v47;
        return swift_bridgeObjectRelease(v36);
      }
      DataFrame.subscript.getter(v105._countAndFlagsBits, in, &type metadata for Data);
      uint64_t v54 = (uint64_t)v80;
      uint64_t v55 = v100;
      Column<A>.parseAsJSONArrays()();
      if (v55)
      {
        swift_errorRelease(v55);
        (*(void (**)(uint64_t *, uint64_t))(v87 + 8))(v92, v88);
        __swift_storeEnumTagSinglePayload(v54, 1, 1, (uint64_t)v104);
        uint64_t v56 = v54;
        uint64_t v47 = in;
        uint64_t v48 = v105._countAndFlagsBits;
      }
      else
      {
        (*(void (**)(uint64_t *, uint64_t))(v87 + 8))(v92, v88);
        uint64_t v60 = v54;
        uint64_t v61 = v54;
        uint64_t v62 = (uint64_t)v104;
        __swift_storeEnumTagSinglePayload(v60, 0, 1, (uint64_t)v104);
        int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v61, 1, v62);
        uint64_t v56 = v61;
        uint64_t v47 = in;
        uint64_t v48 = v105._countAndFlagsBits;
        if (EnumTagSinglePayload != 1)
        {
          (*(void (**)(uint64_t *, uint64_t, uint64_t *))(v97 + 32))(v94, v56, v104);
          (*(void (**)(uint64_t *, uint64_t *, uint64_t *))(v97 + 16))(v43, v94, v104);
          swift_bridgeObjectRetain((_BYTE)v47);
          DataFrame.subscript.setter(v43, v48, v47);
          uint64_t v48 = v105._countAndFlagsBits;
          uint64_t v47 = in;
          v96(v94, v104);
          goto LABEL_21;
        }
      }
      uint64_t v59 = v56;
    }
    outlined destroy of AnyColumn?(v59);
    goto LABEL_21;
  }
  if (EnumCaseMultiPayload == 3)
  {
    char v99 = v78;
    v105._uint64_t countAndFlagsBits = (uint64_t)v79;
    char v104 = v80;
    uint64_t v32 = v81;
    uint64_t v33 = v82;
    uint64_t v34 = v83;
    uint64_t v101 = v76;
    LOBYTE(v102) = v77;
    uint64_t v35 = v100;
    static MLHandPoseClassifier.reformatKeypointsDataTable(table:featureColumn:)(&v101, (uint64_t)v82, v83, *(double *)a1.i64);
    if (!v35)
    {
      static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)((uint64_t)&v101, (uint64_t)v99, (void *)v105._countAndFlagsBits, v33, v34, (uint64_t)v104, v32);
      swift_bridgeObjectRelease((_BYTE)v34);
      swift_bridgeObjectRelease((_BYTE)v32);
      swift_bridgeObjectRelease(v105._countAndFlagsBits);
      uint64_t v76 = v101;
      char v77 = v102;
      return DataFrame.init(_:)((uint64_t)&v76);
    }
    outlined consume of Result<_DataTable, Error>(v101, v102);
    swift_bridgeObjectRelease(v105._countAndFlagsBits);
    swift_bridgeObjectRelease((_BYTE)v32);
    char v36 = (char)v34;
    return swift_bridgeObjectRelease(v36);
  }
  type metadata accessor for MLHandPoseClassifier.FeatureExtractor();
  uint64_t v49 = v100;
  static MLHandPoseClassifier.FeatureExtractor.extractFeatures(from:startingSessionId:)(v105._countAndFlagsBits, 0, a1);
  if (!v49)
  {
    uint64_t v76 = v101;
    char v77 = v102;
    DataFrame.init(_:)((uint64_t)&v76);
  }
  return outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)&v76);
}

uint64_t MLHandPoseClassifier.DataSource.gatherAnnotatedFileNames()()
{
  uint64_t v210 = v1;
  _._char object = v2;
  uint64_t v204 = v0;
  uint64_t v193 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v192 = *(void *)(v193 - 8);
  int64_t v3 = *(void *)(v192 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  long long v194 = &v185;
  uint64_t v191 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  uint64_t v190 = *(void *)(v191 - 8);
  int64_t v6 = *(void *)(v190 + 64);
  int64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  BOOL v199 = &v185;
  uint64_t v202 = type metadata accessor for CSVType(0);
  uint64_t v198 = *(void *)(v202 - 8);
  int64_t v9 = *(void *)(v198 + 64);
  int64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v196 = &v185;
  int64_t v12 = *(void *)(*(void *)(type metadata accessor for CSVReadingOptions(0) - 8) + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  char v195 = &v185;
  int64_t v15 = *(void *)(*(void *)(type metadata accessor for JSONReadingOptions(0) - 8) + 64);
  int64_t v16 = alloca(v15);
  int64_t v17 = alloca(v15);
  unint64_t v188 = &v185;
  v209._char object = (void *)type metadata accessor for DataFrame(0);
  uint64_t v211 = *((void *)v209._object - 1);
  int64_t v18 = *(void *)(v211 + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  v213._uint64_t countAndFlagsBits = (uint64_t)&v185;
  uint64_t v21 = alloca(v18);
  uint64_t v22 = alloca(v18);
  v212 = &v185;
  uint64_t v23 = alloca(v18);
  int64_t v24 = alloca(v18);
  unint64_t v197 = &v185;
  uint64_t v25 = alloca(v18);
  uint64_t v26 = alloca(v18);
  uint64_t v189 = &v185;
  uint64_t v27 = alloca(v18);
  int64_t v28 = alloca(v18);
  unint64_t v201 = &v185;
  uint64_t v29 = (void *)type metadata accessor for UTType(0);
  uint64_t v30 = *(v29 - 1);
  int64_t v31 = *(void *)(v30 + 64);
  uint64_t v32 = alloca(v31);
  uint64_t v33 = alloca(v31);
  v208._char object = &v185;
  uint64_t v34 = alloca(v31);
  uint64_t v35 = alloca(v31);
  v209._uint64_t countAndFlagsBits = (uint64_t)&v185;
  v213._char object = (void *)type metadata accessor for URL(0);
  _._uint64_t countAndFlagsBits = *((void *)v213._object - 1);
  int64_t v36 = *(void *)(_._countAndFlagsBits + 64);
  uint64_t v37 = alloca(v36);
  uint64_t v38 = alloca(v36);
  uint64_t v203 = &v185;
  uint64_t v39 = alloca(v36);
  uint64_t v40 = alloca(v36);
  uint64_t v206 = &v185;
  uint64_t v41 = alloca(v36);
  uint64_t v42 = alloca(v36);
  unint64_t v200 = &v185;
  uint64_t v43 = alloca(v36);
  uint64_t v44 = alloca(v36);
  unint64_t v207 = &v185;
  uint64_t v45 = alloca(v36);
  uint64_t v46 = alloca(v36);
  uint64_t v205 = &v185;
  uint64_t v47 = alloca(v36);
  uint64_t v48 = alloca(v36);
  v208._uint64_t countAndFlagsBits = (uint64_t)&v185;
  uint64_t v49 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
  int64_t v50 = *(void *)(*(void *)(v49 - 8) + 64);
  uint64_t v51 = alloca(v50);
  uint64_t v52 = alloca(v50);
  outlined init with copy of MLHandPoseClassifier.DataSource((uint64_t)_._object, (uint64_t)&v185);
  switch(swift_getEnumCaseMultiPayload(&v185, v49))
  {
    case 0u:
      uint64_t v53 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
      uint64_t v54 = (void **)((char *)&v185 + v53[12]);
      uint64_t v55 = v53[16];
      v213._uint64_t countAndFlagsBits = *(uint64_t *)((char *)&v185 + v55);
      _._char object = *(void **)((char *)&v185 + v55 + 8);
      uint64_t v56 = v53[20];
      v209._uint64_t countAndFlagsBits = *(uint64_t *)((char *)&v185 + v56);
      v212 = *(void ***)((char *)&v185 + v56 + 8);
      char v57 = *(void (**)(void **, void **, void *))(_._countAndFlagsBits + 32);
      char object = v213._object;
      v57(v207, &v185, v213._object);
      uint64_t v59 = v200;
      v57(v200, v54, object);
      uint64_t v60 = URL.pathExtension.getter();
      char v62 = v61;
      if (v60 == 1852797802 && v61 == 0xE400000000000000)
      {
        swift_bridgeObjectRelease(0);
        uint64_t v63 = v206;
LABEL_18:
        (*(void (**)(void **, void **, void *))(_._countAndFlagsBits + 16))(v63, v59, v213._object);
        uint64_t v101 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
        int v102 = (void **)swift_allocObject(v101, 64, 7);
        uint64_t v205 = v102;
        v102[2] = &dword_0 + 2;
        v102[3] = &dword_4;
        v102[4] = (void *)v213._countAndFlagsBits;
        v102[5] = _._object;
        v102[6] = (void *)v209._countAndFlagsBits;
        v102[7] = v212;
        uint64_t v103 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, JSONType)>);
        v208._uint64_t countAndFlagsBits = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, JSONType));
        uint64_t v104 = *(void *)(v208._countAndFlagsBits - 8);
        uint64_t v202 = *(void *)(v104 + 72);
        uint64_t v105 = *(unsigned __int8 *)(v104 + 80);
        uint64_t v106 = ((int)v105 + 32) & ~*(unsigned __int8 *)(v104 + 80);
        uint64_t v107 = swift_allocObject(v103, v106 + 2 * v202, v105 | 7);
        *(void *)(v107 + 16) = 2;
        *(void *)(v107 + 24) = 4;
        uint64_t v108 = v107 + v106;
        uint64_t v109 = v107 + v106 + *(int *)(v208._countAndFlagsBits + 48);
        *(void *)(v107 + v106) = v213._countAndFlagsBits;
        *(void *)(v107 + v106 + 8) = _._object;
        LODWORD(v208._object) = enum case for JSONType.string(_:);
        uint64_t v203 = (void **)type metadata accessor for JSONType(0);
        uint64_t v110 = (void (*)(uint64_t, void, void **))*((void *)*(v203 - 1) + 13);
        uint64_t v111 = v109;
        char v112 = v212;
        v110(v111, LODWORD(v208._object), v203);
        uint64_t v113 = v202;
        uint64_t v114 = v108 + v202 + *(int *)(v208._countAndFlagsBits + 48);
        *(void *)(v202 + v108) = v209._countAndFlagsBits;
        *(void *)(v113 + v108 + 8) = v112;
        uint64_t v115 = v203;
        v110(v114, LODWORD(v208._object), v203);
        swift_bridgeObjectRetain_n(_._object, 2);
        swift_bridgeObjectRetain_n(v112, 2);
        uint64_t v116 = Dictionary.init(dictionaryLiteral:)(v107, &type metadata for String, v115, &protocol witness table for String);
        uint64_t v117 = v188;
        JSONReadingOptions.init()();
        uint64_t v118 = v189;
        char v119 = v210;
        DataFrame.init(contentsOfJSONFile:columns:types:options:)(v206, v205, v116, v117);
        goto LABEL_29;
      }
      char v100 = _stringCompareWithSmolCheck(_:_:expecting:)(v60, v61, 1852797802, 0xE400000000000000, 0);
      swift_bridgeObjectRelease(v62);
      uint64_t v63 = v206;
      if (v100) {
        goto LABEL_18;
      }
      (*(void (**)(void **, void **, void *))(_._countAndFlagsBits + 16))(v203, v59, v213._object);
      uint64_t v136 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
      unint64_t v137 = (void *)swift_allocObject(v136, 64, 7);
      v208._uint64_t countAndFlagsBits = (uint64_t)v137;
      v137[2] = 2;
      v137[3] = 4;
      v137[4] = v213._countAndFlagsBits;
      v137[5] = _._object;
      v137[6] = v209._countAndFlagsBits;
      unsigned char v137[7] = v212;
      uint64_t v138 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, CSVType)>);
      uint64_t v139 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, CSVType));
      uint64_t v140 = *(void *)(v139 - 8);
      v208._char object = *(void **)(v140 + 72);
      uint64_t v141 = *(unsigned __int8 *)(v140 + 80);
      uint64_t v142 = ((int)v141 + 32) & ~*(unsigned __int8 *)(v140 + 80);
      uint64_t v143 = swift_allocObject(v138, v142 + 2 * (uint64_t)v208._object, v141 | 7);
      *(void *)(v143 + 16) = 2;
      *(void *)(v143 + 24) = 4;
      uint64_t v144 = (uint64_t *)(v143 + v142);
      uint64_t v145 = v143 + v142 + *(int *)(v139 + 48);
      *uint64_t v144 = v213._countAndFlagsBits;
      v144[1] = (uint64_t)_._object;
      LODWORD(v206) = enum case for CSVType.string(_:);
      unint64_t v146 = *(void ***)(v198 + 104);
      ((void (*)(uint64_t, void, uint64_t))v146)(v145, enum case for CSVType.string(_:), v202);
      uint64_t v205 = v146;
      long long v147 = v208._object;
      char v148 = (char *)v144 + (unint64_t)v208._object + *(int *)(v139 + 48);
      *(void *)((char *)v208._object + (unint64_t)v144) = v209._countAndFlagsBits;
      uint64_t v149 = v212;
      *(uint64_t *)((char *)v144 + (void)v147 + 8) = (uint64_t)v212;
      uint64_t v150 = v202;
      ((void (*)(char *, void, uint64_t))v146)(v148, v206, v202);
      swift_bridgeObjectRetain_n(_._object, 2);
      swift_bridgeObjectRetain_n(v149, 2);
      uint64_t v151 = v150;
      v208._char object = (void *)Dictionary.init(dictionaryLiteral:)(v143, &type metadata for String, v150, &protocol witness table for String);
      uint64_t v206 = (void **)default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
      char v152 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 2 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
      uint64_t v153 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 3 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
      uint64_t v154 = v196;
      ((void (*)(void **, void, uint64_t))v205)(v196, enum case for CSVType.double(_:), v151);
      int v155 = v195;
      CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)(1, v206, v152, v153, v154, 1, 1, 0, 44, 0xE100000000000000, 92, 0xE100000000000000);
      uint64_t v118 = v197;
      char v119 = v210;
      DataFrame.init(contentsOfCSVFile:columns:rows:types:options:)(v203, v208._countAndFlagsBits, 0, 0, 1, v208._object, v155);
LABEL_29:
      if (!v119)
      {
        uint64_t v210 = 0;
        uint64_t v211 = *(void *)(v211 + 32);
        ((void (*)(void **, void **, void *))v211)(v201, v118, v209._object);
        long long v158 = v194;
        char v159 = _._object;
        DataFrame.subscript.getter(v213._countAndFlagsBits, _._object, &type metadata for String);
        uint64_t v185 = 0;
        unint64_t v186 = 0xE000000000000000;
        uint64_t v160 = lazy protocol witness table accessor for type Column<String> and conformance Column<A>();
        uint64_t v161 = v193;
        OptionalColumnProtocol.filled(with:)(&v185, v193, v160);
        (*(void (**)(void **, uint64_t))(v192 + 8))(v158, v161);
        uint64_t v162 = alloca(24);
        uint64_t v163 = alloca(32);
        unint64_t v187 = v207;
        char v164 = v210;
        uint64_t v165 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lF11TabularData12FilledColumnVyAF0G0VySSGG_SSSgs5NeverOTg5((void (*)(void *))partial apply for closure #3 in MLObjectDetector.DataSource.gatherAnnotatedFileNames(), (uint64_t)&v185);
        uint64_t v210 = v164;
        swift_bridgeObjectRetain((_BYTE)v159);
        double v166 = v165;
        uint64_t countAndFlagsBits = v213._countAndFlagsBits;
        DataFrame.subscript.setter(v166, v213._countAndFlagsBits, v159, &type metadata for String, &type metadata for String);
        v168._uint64_t countAndFlagsBits = 0x7461506567616D69;
        v168._char object = (void *)0xE900000000000068;
        v169._uint64_t countAndFlagsBits = countAndFlagsBits;
        v169._char object = v159;
        DataFrame.renameColumn(_:to:)(v169, v168);
        swift_bridgeObjectRelease((_BYTE)v159);
        v170._uint64_t countAndFlagsBits = 0x6C6562616CLL;
        v170._char object = (void *)0xE500000000000000;
        v169._uint64_t countAndFlagsBits = v209._countAndFlagsBits;
        LOBYTE(v159) = (_BYTE)v212;
        v169._char object = v212;
        DataFrame.renameColumn(_:to:)(v169, v170);
        swift_bridgeObjectRelease((_BYTE)v159);
        (*(void (**)(void **, uint64_t))(v190 + 8))(v199, v191);
        unint64_t v171 = *(void (**)(void **, void *))(_._countAndFlagsBits + 8);
        uint64_t v172 = v213._object;
        v171(v200, v213._object);
        v171(v207, v172);
        uint64_t v173 = v204;
        uint64_t v174 = v209._object;
        ((void (*)(uint64_t, void **, void *))v211)(v204, v201, v209._object);
        goto LABEL_34;
      }
      uint64_t v156 = *(void (**)(void **, void *))(_._countAndFlagsBits + 8);
      uint64_t v157 = v213._object;
      v156(v200, v213._object);
      swift_bridgeObjectRelease((_BYTE)v212);
      swift_bridgeObjectRelease(_._object);
      return ((uint64_t (*)(void **, void *))v156)(v207, v157);
    case 1u:
      _._char object = v29;
      uint64_t v211 = v30;
      uint64_t v64 = (uint64_t)v205;
      uint64_t v65 = v205;
      uint64_t v66 = v213._object;
      uint64_t v67 = _._countAndFlagsBits;
      (*(void (**)(void **, void **, void *))(_._countAndFlagsBits + 32))(v205, &v185, v213._object);
      char v68 = v208._object;
      static UTType.image.getter(v65);
      uint64_t v69 = v210;
      char v70 = static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)(v64, (uint64_t)v68);
      if (v69)
      {
        (*(void (**)(void *, void *))(v211 + 8))(v208._object, _._object);
        uint64_t v71 = (uint64_t)v205;
        uint64_t v72 = v66;
        return (*(uint64_t (**)(uint64_t, void *))(v67 + 8))(v71, v72);
      }
      uint64_t v120 = (uint64_t)v70;
      (*(void (**)(void *, void *))(v211 + 8))(v208._object, _._object);
      uint64_t v210 = specialized _NativeDictionary.mapValues<A>(_:)(v120);
      swift_bridgeObjectRelease(v120);
      uint64_t v121 = v204;
      specialized DataFrame.init<A>(expanding:keysColumnName:valuesColumnName:)((uint64_t)v210, 0x6C6562616CLL, (uint64_t *)0xE500000000000000, (void *)0x7461506567616D69, 0xE900000000000068);
      uint64_t v122 = (uint64_t)v205;
      uint64_t v123 = v66;
      goto LABEL_21;
    case 2u:
      _._char object = v29;
      uint64_t v73 = v208._countAndFlagsBits;
      uint64_t v74 = v208._countAndFlagsBits;
      uint64_t v67 = _._countAndFlagsBits;
      (*(void (**)(uint64_t, void **, void *))(_._countAndFlagsBits + 32))(v208._countAndFlagsBits, &v185, v213._object);
      uint64_t v75 = v209._countAndFlagsBits;
      static UTType.image.getter(v74);
      uint64_t v76 = v210;
      uint64_t v77 = static _FileUtilities.collectFilesLabeledByFileName(at:type:)(v73, v75);
      if (v76)
      {
        (*(void (**)(uint64_t, void *))(v30 + 8))(v209._countAndFlagsBits, _._object);
        uint64_t v71 = v208._countAndFlagsBits;
        uint64_t v72 = v213._object;
        return (*(uint64_t (**)(uint64_t, void *))(v67 + 8))(v71, v72);
      }
      uint64_t v124 = v77;
      (*(void (**)(uint64_t, void *))(v30 + 8))(v209._countAndFlagsBits, _._object);
      char v125 = specialized _NativeDictionary.mapValues<A>(_:)(v124);
      swift_bridgeObjectRelease(v124);
      uint64_t v121 = v204;
      specialized DataFrame.init<A>(expanding:keysColumnName:valuesColumnName:)((uint64_t)v125, 0x6C6562616CLL, (uint64_t *)0xE500000000000000, (void *)0x7461506567616D69, 0xE900000000000068);
      uint64_t v122 = v208._countAndFlagsBits;
      uint64_t v123 = v213._object;
LABEL_21:
      (*(void (**)(uint64_t, void *))(_._countAndFlagsBits + 8))(v122, v123);
      uint64_t v126 = v121;
      uint64_t v127 = v209._object;
      return __swift_storeEnumTagSinglePayload(v126, 0, 1, (uint64_t)v127);
    case 3u:
      char v79 = (char)v188;
      char v80 = v190;
      char v81 = v192;
      outlined consume of Result<_DataTable, Error>((uint64_t)v185, v186);
      swift_bridgeObjectRelease(v81);
      swift_bridgeObjectRelease(v80);
      swift_bridgeObjectRelease(v79);
      return __swift_storeEnumTagSinglePayload(v204, 1, 1, (uint64_t)v209._object);
    case 4u:
      int v82 = v186;
      uint64_t v83 = (uint64_t)v187;
      id v84 = v188;
      v213._uint64_t countAndFlagsBits = (uint64_t)v189;
      unint64_t v207 = (void **)v190;
      LOBYTE(v186) = v186 & 1;
      v213._char object = v185;
      LODWORD(_._countAndFlagsBits) = v82;
      outlined copy of Result<_DataTable, Error>((uint64_t)v185, v82);
      DataFrame.init(_:)((uint64_t)&v185);
      v209._uint64_t countAndFlagsBits = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any.Type>);
      uint64_t v85 = (void *)swift_allocObject(v209._countAndFlagsBits, 40, 7);
      v85[2] = 1;
      v85[3] = 2;
      v85[4] = &type metadata for String;
      v208._uint64_t countAndFlagsBits = v83;
      v86._uint64_t countAndFlagsBits = v83;
      _._char object = v84;
      v86._char object = v84;
      DataFrame.validateColumnTypes(_:_:context:)(v86, (Swift::OpaquePointer)v85, (Swift::String)__PAIR128__(0xEF656D616E20656CLL, 0x6966206567616D49));
      if (v87)
      {
        swift_bridgeObjectRelease((_BYTE)v85);
        (*(void (**)(void **, void *))(v211 + 8))(v212, v209._object);
        outlined consume of Result<_DataTable, Error>((uint64_t)v213._object, _._countAndFlagsBits);
        char v88 = (char)v207;
LABEL_24:
        swift_bridgeObjectRelease(v88);
        char v99 = (char)_._object;
        return swift_bridgeObjectRelease(v99);
      }
      swift_bridgeObjectRelease((_BYTE)v85);
      uint64_t v128 = (void *)swift_allocObject(v209._countAndFlagsBits, 40, 7);
      v128[2] = 1;
      v128[3] = 2;
      v128[4] = &type metadata for String;
      v129._uint64_t countAndFlagsBits = v213._countAndFlagsBits;
      uint64_t v130 = v207;
      v129._char object = v207;
      DataFrame.validateColumnTypes(_:_:context:)(v129, (Swift::OpaquePointer)v128, (Swift::String)__PAIR128__(0xE500000000000000, 0x6C6562614CLL));
      if (v131)
      {
        swift_bridgeObjectRelease((_BYTE)v128);
        (*(void (**)(void **, void *))(v211 + 8))(v212, v209._object);
        outlined consume of Result<_DataTable, Error>((uint64_t)v213._object, _._countAndFlagsBits);
        char v88 = (char)v130;
        goto LABEL_24;
      }
      swift_bridgeObjectRelease((_BYTE)v128);
      v175._uint64_t countAndFlagsBits = 0x7461506567616D69;
      v175._char object = (void *)0xE900000000000068;
      v176._uint64_t countAndFlagsBits = v208._countAndFlagsBits;
      char v177 = (char)_._object;
      v176._char object = _._object;
      uint64_t v178 = v212;
      DataFrame.renameColumn(_:to:)(v176, v175);
      swift_bridgeObjectRelease(v177);
      v176._uint64_t countAndFlagsBits = v213._countAndFlagsBits;
      v176._char object = v130;
      v179._uint64_t countAndFlagsBits = 0x6C6562616CLL;
      v179._char object = (void *)0xE500000000000000;
      DataFrame.renameColumn(_:to:)(v176, v179);
      outlined consume of Result<_DataTable, Error>((uint64_t)v213._object, _._countAndFlagsBits);
      swift_bridgeObjectRelease((_BYTE)v130);
      uint64_t v173 = v204;
      uint64_t v174 = v209._object;
      (*(void (**)(uint64_t, void **, void *))(v211 + 32))(v204, v178, v209._object);
      goto LABEL_34;
    case 5u:
      unsigned __int8 v89 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      swift_bridgeObjectRelease(*(void **)((char *)&v185 + v89[12] + 8));
      swift_bridgeObjectRelease(*(void **)((char *)&v185 + v89[16] + 8));
      swift_bridgeObjectRelease(*(void **)((char *)&v185 + v89[20] + 8));
      uint64_t v90 = v209._object;
      __swift_storeEnumTagSinglePayload(v204, 1, 1, (uint64_t)v209._object);
      return (*(uint64_t (**)(void **, void *))(v211 + 8))(&v185, v90);
    case 6u:
      uint64_t v91 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
      uint64_t v92 = *(int *)(v91 + 48);
      uint64_t v93 = *(uint64_t *)((char *)&v185 + v92);
      _._char object = *(void **)((char *)&v185 + v92 + 8);
      uint64_t v94 = *(int *)(v91 + 64);
      _._uint64_t countAndFlagsBits = *(uint64_t *)((char *)&v185 + v94);
      v213._char object = *(void **)((char *)&v185 + v94 + 8);
      unint64_t v207 = *(void ***)(v211 + 32);
      ((void (*)(uint64_t, void **, void *))v207)(v213._countAndFlagsBits, &v185, v209._object);
      v212 = (void **)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any.Type>);
      uint64_t v95 = (void *)swift_allocObject(v212, 40, 7);
      v95[2] = 1;
      v95[3] = 2;
      v95[4] = &type metadata for String;
      v209._uint64_t countAndFlagsBits = v93;
      v96._uint64_t countAndFlagsBits = v93;
      char v97 = (char)_._object;
      v96._char object = _._object;
      DataFrame.validateColumnTypes(_:_:context:)(v96, (Swift::OpaquePointer)v95, (Swift::String)__PAIR128__(0xEF656D616E20656CLL, 0x6966206567616D49));
      if (v98)
      {
        swift_bridgeObjectRelease((_BYTE)v95);
        (*(void (**)(uint64_t, void *))(v211 + 8))(v213._countAndFlagsBits, v209._object);
        swift_bridgeObjectRelease(v97);
        char v99 = (char)v213._object;
        return swift_bridgeObjectRelease(v99);
      }
      swift_bridgeObjectRelease((_BYTE)v95);
      char v132 = (void *)swift_allocObject(v212, 40, 7);
      v132[2] = 1;
      v132[3] = 2;
      v132[4] = &type metadata for String;
      v133._uint64_t countAndFlagsBits = _._countAndFlagsBits;
      uint64_t v134 = v213._object;
      v133._char object = v213._object;
      DataFrame.validateColumnTypes(_:_:context:)(v133, (Swift::OpaquePointer)v132, (Swift::String)__PAIR128__(0xE500000000000000, 0x6C6562614CLL));
      if (v135)
      {
        swift_bridgeObjectRelease((_BYTE)v132);
        (*(void (**)(uint64_t, void *))(v211 + 8))(v213._countAndFlagsBits, v209._object);
        swift_bridgeObjectRelease(_._object);
        char v99 = (char)v134;
        return swift_bridgeObjectRelease(v99);
      }
      swift_bridgeObjectRelease((_BYTE)v132);
      v180._uint64_t countAndFlagsBits = 0x7461506567616D69;
      v180._char object = (void *)0xE900000000000068;
      v181._uint64_t countAndFlagsBits = v209._countAndFlagsBits;
      char v182 = (char)_._object;
      v181._char object = _._object;
      uint64_t v183 = v213._countAndFlagsBits;
      DataFrame.renameColumn(_:to:)(v181, v180);
      swift_bridgeObjectRelease(v182);
      v181._uint64_t countAndFlagsBits = _._countAndFlagsBits;
      v181._char object = v134;
      v184._uint64_t countAndFlagsBits = 0x6C6562616CLL;
      v184._char object = (void *)0xE500000000000000;
      DataFrame.renameColumn(_:to:)(v181, v184);
      swift_bridgeObjectRelease((_BYTE)v134);
      uint64_t v173 = v204;
      uint64_t v174 = v209._object;
      ((void (*)(uint64_t, uint64_t, void *))v207)(v204, v183, v209._object);
LABEL_34:
      uint64_t v126 = v173;
      uint64_t v127 = v174;
      return __swift_storeEnumTagSinglePayload(v126, 0, 1, (uint64_t)v127);
  }
}

uint64_t MLHandPoseClassifier.DataSource.stratifiedSplit(proportions:seed:labelColumn:)(void *a1, uint64_t a2, uint64_t a3, void *a4, __m128 a5)
{
  uint64_t v8 = v6;
  uint64_t v34 = a4;
  v35._uint64_t countAndFlagsBits = a3;
  uint64_t v39 = a2;
  v35._char object = a1;
  uint64_t v36 = v5;
  uint64_t v9 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
  int64_t v10 = *(void *)(*(void *)(v9 - 8) + 64);
  int64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  outlined init with copy of MLHandPoseClassifier.DataSource(v7, (uint64_t)&v32);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v32, v9);
  if (EnumCaseMultiPayload == 5)
  {
    int64_t v17 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
    uint64_t v18 = v17[12];
    *(void *)uint64_t v37 = *(uint64_t *)((char *)&v32 + v18);
    *(void *)uint64_t v42 = *(uint64_t *)((char *)&v32 + v18 + 8);
    swift_bridgeObjectRelease(*(uint64_t *)((char *)&v32 + v17[16] + 8));
    swift_bridgeObjectRelease(*(uint64_t *)((char *)&v32 + v17[20] + 8));
    uint64_t v19 = type metadata accessor for DataFrame(0);
    *(double *)a5.i64 = (*(double (**)(uint64_t *, uint64_t))(*(void *)(v19 - 8) + 8))(&v32, v19);
LABEL_5:
    MLHandPoseClassifier.DataSource.keypointsWithAnnotations()(a5);
    if (v8) {
      return swift_bridgeObjectRelease(v42[0]);
    }
    uint64_t v21 = v39;
    if (v39 >= 0)
    {
      uint64_t v22 = v40;
      uint64_t v33 = v40;
      LOBYTE(v38) = v41;
      uint64_t v23 = type metadata accessor for MersenneTwisterGenerator();
      swift_allocObject(v23, 136, 7);
      uint64_t v40 = MersenneTwisterGenerator.init(seed:)(v21);
      char v24 = v38;
      uint64_t v25 = (uint64_t)v22;
      LOBYTE(v22) = v42[0];
      v31._char object = v34;
      v31._uint64_t countAndFlagsBits = v35._countAndFlagsBits;
      specialized stratifiedSplitBySequenceGenerator<A>(proportions:generator:dataTable:by:on:)((uint64_t)v35._object, (uint64_t)&v40, v25, v38, *(uint64_t *)v37, *(void **)v42, *(double *)a5.i64, v31);
      swift_bridgeObjectRelease((_BYTE)v22);
      swift_release();
      return outlined consume of Result<_DataTable, Error>((uint64_t)v33, v24);
    }
LABEL_13:
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, "Negative value is not representable", 35, 2, "Swift/Integers.swift", 20, 2, 3451, 1);
    BUG();
  }
  if (EnumCaseMultiPayload == 3)
  {
    uint64_t v38 = v32;
    *(void *)uint64_t v37 = v34;
    *(void *)uint64_t v42 = v35._countAndFlagsBits;
    char v14 = v32;
    char v15 = (char)v33;
    swift_bridgeObjectRelease(v36);
    char v16 = v14;
    uint64_t v8 = v6;
    swift_bridgeObjectRelease(v16);
    outlined consume of Result<_DataTable, Error>(v38, v15);
    goto LABEL_5;
  }
  MLHandPoseClassifier.DataSource.imagesWithAnnotations()(a5);
  if (v6) {
    return outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)&v32);
  }
  uint64_t v26 = v39;
  if (v39 < 0) {
    goto LABEL_13;
  }
  *(void *)uint64_t v42 = v40;
  unsigned __int8 v27 = v41;
  uint64_t v28 = type metadata accessor for MersenneTwisterGenerator();
  swift_allocObject(v28, 136, 7);
  uint64_t v40 = MersenneTwisterGenerator.init(seed:)(v26);
  int v29 = v27;
  LODWORD(v39) = v27;
  uint64_t v30 = *(void **)v42;
  specialized stratifiedSplitGenerator<A>(proportions:generator:dataTable:on:)((uint64_t)v35._object, (uint64_t)&v40, *(void **)v42, v29, v35._countAndFlagsBits, v34, *(double *)a5.i64);
  swift_release();
  outlined consume of Result<_DataTable, Error>((uint64_t)v30, v39);
  return outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)&v32);
}

void *default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)()
{
  return specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
}

void *specialized Set.init(_nonEmptyArrayLiteral:)(uint64_t a1)
{
  uint64_t v1 = a1;
  uint64_t v2 = *(void *)(a1 + 16);
  if (v2)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _SetStorage<String>);
    int64_t v3 = (void *)static _SetStorage.allocate(capacity:)(v2);
    uint64_t v26 = *(void *)(a1 + 16);
    uint64_t v30 = v3;
    if (v26)
    {
      uint64_t v27 = a1 + 32;
      unint64_t v4 = 0;
      uint64_t v29 = a1;
      while (1)
      {
        if (v4 >= *(void *)(v1 + 16)) {
          BUG();
        }
        uint64_t v5 = *(void *)(v27 + 16 * v4);
        uint64_t v6 = *(void *)(v27 + 16 * v4 + 8);
        Hasher.init(_seed:)(v3[5]);
        swift_bridgeObjectRetain(v6);
        String.hash(into:)(v25, v5);
        Swift::Int v7 = Hasher._finalize()();
        int64_t v3 = v30;
        uint64_t v8 = ~(-1 << *((unsigned char *)v30 + 32));
        unint64_t v9 = v8 & v7;
        unint64_t v10 = (v8 & (unint64_t)v7) >> 6;
        uint64_t v11 = v30[v10 + 7];
        uint64_t v12 = 1 << v9;
        if (!_bittest64(&v11, v9))
        {
LABEL_12:
          uint64_t v18 = v5;
LABEL_13:
          v3[v10 + 7] = v11 | v12;
          uint64_t v19 = v3[6];
          uint64_t v20 = 16 * v9;
          *(void *)(v19 + v20) = v18;
          *(void *)(v19 + v20 + 8) = v6;
          uint64_t v21 = v3[2];
          BOOL v22 = __OFADD__(1, v21);
          uint64_t v23 = v21 + 1;
          if (v22) {
            BUG();
          }
          v3[2] = v23;
          uint64_t v1 = v29;
          goto LABEL_16;
        }
        uint64_t v13 = v30[6];
        uint64_t v14 = *(void *)(v13 + 16 * v9);
        uint64_t v15 = *(void *)(v13 + 16 * v9 + 8);
        if (v14 != v5 || v15 != v6)
        {
          uint64_t v28 = v30[6];
          if ((_stringCompareWithSmolCheck(_:_:expecting:)(v14, v15, v5, v6, 0) & 1) == 0) {
            break;
          }
        }
LABEL_15:
        swift_bridgeObjectRelease(v6);
        uint64_t v1 = v29;
        int64_t v3 = v30;
LABEL_16:
        if (++v4 == v26) {
          goto LABEL_24;
        }
      }
      unint64_t v9 = v8 & (v9 + 1);
      unint64_t v10 = v9 >> 6;
      int64_t v3 = v30;
      uint64_t v11 = v30[(v9 >> 6) + 7];
      uint64_t v12 = 1 << v9;
      if (!_bittest64(&v11, v9)) {
        goto LABEL_12;
      }
      uint64_t v16 = *(void *)(v28 + 16 * v9);
      uint64_t v17 = *(void *)(v28 + 16 * v9 + 8);
      uint64_t v18 = v5;
      if (v16 == v5) {
        goto LABEL_18;
      }
      while (1)
      {
        do
        {
          if (_stringCompareWithSmolCheck(_:_:expecting:)(v16, v17, v18, v6, 0)) {
            goto LABEL_15;
          }
          uint64_t v18 = v5;
          unint64_t v9 = v8 & (v9 + 1);
          unint64_t v10 = v9 >> 6;
          int64_t v3 = v30;
          uint64_t v11 = v30[(v9 >> 6) + 7];
          uint64_t v12 = 1 << v9;
          if (!_bittest64(&v11, v9)) {
            goto LABEL_13;
          }
          uint64_t v16 = *(void *)(v28 + 16 * v9);
          uint64_t v17 = *(void *)(v28 + 16 * v9 + 8);
        }
        while (v16 != v5);
LABEL_18:
        if (v17 == v6) {
          goto LABEL_15;
        }
      }
    }
  }
  else
  {
    uint64_t v30 = &_swiftEmptySetSingleton;
  }
LABEL_24:
  swift_bridgeObjectRelease(v1);
  return v30;
}

uint64_t lazy protocol witness table accessor for type Column<String> and conformance Column<A>()
{
  uint64_t result = lazy protocol witness table cache variable for type Column<String> and conformance Column<A>;
  if (!lazy protocol witness table cache variable for type Column<String> and conformance Column<A>)
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for Column<String>);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for Column<A>, v1);
    lazy protocol witness table cache variable for type Column<String> and conformance Column<A> = result;
  }
  return result;
}

void *initializeBufferWithCopyOfBuffer for MLHandPoseClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  int64_t v3 = (void *)a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v15 = *(void *)a2;
    void *v3 = *(void *)a2;
    int64_t v3 = (void *)(v15 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    switch(swift_getEnumCaseMultiPayload(a2, a3))
    {
      case 0u:
        uint64_t v6 = type metadata accessor for URL(0);
        uint64_t v43 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16);
        v43(a1, a2, v6);
        Swift::Int v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v43(a1 + v7[12], a2 + v7[12], v6);
        uint64_t v8 = v7[16];
        *(void *)(a1 + v8) = *(void *)(a2 + v8);
        uint64_t v9 = *(void *)(a2 + v8 + 8);
        *(void *)((char *)v3 + v8 + 8) = v9;
        uint64_t v10 = v7[20];
        *(void *)((char *)v3 + v10) = *(void *)(a2 + v10);
        uint64_t v11 = *(void *)(a2 + v10 + 8);
        *(void *)((char *)v3 + v10 + 8) = v11;
        swift_bridgeObjectRetain(v9);
        swift_bridgeObjectRetain(v11);
        uint64_t v12 = v3;
        uint64_t v13 = a3;
        uint64_t v14 = 0;
        goto LABEL_12;
      case 1u:
        uint64_t v16 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v16 - 8) + 16))(a1, a2, v16);
        uint64_t v42 = 1;
        goto LABEL_11;
      case 2u:
        uint64_t v17 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v17 - 8) + 16))(a1, a2, v17);
        uint64_t v42 = 2;
        goto LABEL_11;
      case 3u:
        uint64_t v18 = *(void *)a2;
        char v19 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(void *)a2, v19);
        *(void *)a1 = v18;
        *(unsigned char *)(a1 + 8) = v19;
        *(void *)(a1 + 16) = *(void *)(a2 + 16);
        uint64_t v20 = *(void *)(a2 + 24);
        v3[3] = v20;
        void v3[4] = *(void *)(a2 + 32);
        uint64_t v21 = *(void *)(a2 + 40);
        void v3[5] = v21;
        v3[6] = *(void *)(a2 + 48);
        uint64_t v22 = *(void *)(a2 + 56);
        v3[7] = v22;
        swift_bridgeObjectRetain(v20);
        swift_bridgeObjectRetain(v21);
        swift_bridgeObjectRetain(v22);
        uint64_t v42 = 3;
        goto LABEL_11;
      case 4u:
        uint64_t v23 = *(void *)a2;
        char v24 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(void *)a2, v24);
        *(void *)a1 = v23;
        *(unsigned char *)(a1 + 8) = v24;
        *(void *)(a1 + 16) = *(void *)(a2 + 16);
        uint64_t v25 = *(void *)(a2 + 24);
        v3[3] = v25;
        void v3[4] = *(void *)(a2 + 32);
        uint64_t v26 = *(void *)(a2 + 40);
        void v3[5] = v26;
        swift_bridgeObjectRetain(v25);
        swift_bridgeObjectRetain(v26);
        uint64_t v42 = 4;
        goto LABEL_11;
      case 5u:
        uint64_t v27 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v27 - 8) + 16))(a1, a2, v27);
        uint64_t v28 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v29 = v28[12];
        *(void *)(a1 + v29) = *(void *)(a2 + v29);
        uint64_t v30 = *(void *)(a2 + v29 + 8);
        *(void *)((char *)v3 + v29 + 8) = v30;
        uint64_t v31 = v28[16];
        *(void *)((char *)v3 + v31) = *(void *)(a2 + v31);
        uint64_t v32 = *(void *)(a2 + v31 + 8);
        *(void *)((char *)v3 + v31 + 8) = v32;
        uint64_t v33 = v28[20];
        *(void *)((char *)v3 + v33) = *(void *)(a2 + v33);
        uint64_t v34 = *(void *)(a2 + v33 + 8);
        *(void *)((char *)v3 + v33 + 8) = v34;
        swift_bridgeObjectRetain(v30);
        swift_bridgeObjectRetain(v32);
        swift_bridgeObjectRetain(v34);
        uint64_t v42 = 5;
        goto LABEL_11;
      case 6u:
        uint64_t v35 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v35 - 8) + 16))(a1, a2, v35);
        uint64_t v36 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        uint64_t v37 = *(int *)(v36 + 48);
        *(void *)(a1 + v37) = *(void *)(a2 + v37);
        uint64_t v38 = *(void *)(a2 + v37 + 8);
        *(void *)((char *)v3 + v37 + 8) = v38;
        uint64_t v39 = *(int *)(v36 + 64);
        *(void *)((char *)v3 + v39) = *(void *)(a2 + v39);
        uint64_t v40 = *(void *)(a2 + v39 + 8);
        *(void *)((char *)v3 + v39 + 8) = v40;
        swift_bridgeObjectRetain(v38);
        swift_bridgeObjectRetain(v40);
        uint64_t v42 = 6;
LABEL_11:
        uint64_t v14 = v42;
        uint64_t v12 = v3;
        uint64_t v13 = a3;
LABEL_12:
        swift_storeEnumTagMultiPayload(v12, v13, v14);
        break;
    }
  }
  return v3;
}

uint64_t destroy for MLHandPoseClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t result = swift_getEnumCaseMultiPayload(a1, a2);
  switch((int)result)
  {
    case 0:
      uint64_t v4 = type metadata accessor for URL(0);
      uint64_t v5 = *(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8);
      v5(a1, v4);
      uint64_t v6 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
      v5(a1 + v6[12], v4);
      swift_bridgeObjectRelease(*(void *)(a1 + v6[16] + 8));
      uint64_t v7 = v6[20];
      goto LABEL_8;
    case 1:
    case 2:
      uint64_t v3 = type metadata accessor for URL(0);
      return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8))(a1, v3);
    case 3:
      outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + 24));
      swift_bridgeObjectRelease(*(void *)(a1 + 40));
      return swift_bridgeObjectRelease(*(void *)(a1 + 56));
    case 4:
      outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + 24));
      return swift_bridgeObjectRelease(*(void *)(a1 + 40));
    case 5:
      uint64_t v8 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v8 - 8) + 8))(a1, v8);
      uint64_t v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      swift_bridgeObjectRelease(*(void *)(a1 + v9[12] + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + v9[16] + 8));
      uint64_t v7 = v9[20];
      goto LABEL_8;
    case 6:
      uint64_t v10 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v10 - 8) + 8))(a1, v10);
      uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
      swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(v11 + 48) + 8));
      uint64_t v7 = *(int *)(v11 + 64);
LABEL_8:
      uint64_t result = swift_bridgeObjectRelease(*(void *)(a1 + v7 + 8));
      break;
    default:
      return result;
  }
  return result;
}

uint64_t initializeWithCopy for MLHandPoseClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  switch(swift_getEnumCaseMultiPayload(a2, a3))
  {
    case 0u:
      uint64_t v5 = type metadata accessor for URL(0);
      unsigned __int8 v41 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16);
      v41(a1, a2, v5);
      uint64_t v6 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
      v41(a1 + v6[12], a2 + v6[12], v5);
      uint64_t v7 = v6[16];
      *(void *)(a1 + v7) = *(void *)(a2 + v7);
      uint64_t v8 = *(void *)(a2 + v7 + 8);
      *(void *)(a1 + v7 + 8) = v8;
      uint64_t v9 = v6[20];
      *(void *)(a1 + v9) = *(void *)(a2 + v9);
      uint64_t v10 = *(void *)(a2 + v9 + 8);
      *(void *)(a1 + v9 + 8) = v10;
      swift_bridgeObjectRetain(v8);
      swift_bridgeObjectRetain(v10);
      uint64_t v11 = a1;
      uint64_t v12 = a3;
      uint64_t v13 = 0;
      goto LABEL_10;
    case 1u:
      uint64_t v14 = type metadata accessor for URL(0);
      (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v14 - 8) + 16))(a1, a2, v14);
      uint64_t v40 = 1;
      goto LABEL_9;
    case 2u:
      uint64_t v15 = type metadata accessor for URL(0);
      (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v15 - 8) + 16))(a1, a2, v15);
      uint64_t v40 = 2;
      goto LABEL_9;
    case 3u:
      uint64_t v16 = *(void *)a2;
      char v17 = *(unsigned char *)(a2 + 8);
      outlined copy of Result<_DataTable, Error>(*(void *)a2, v17);
      *(void *)a1 = v16;
      *(unsigned char *)(a1 + 8) = v17;
      *(void *)(a1 + 16) = *(void *)(a2 + 16);
      uint64_t v18 = *(void *)(a2 + 24);
      *(void *)(a1 + 24) = v18;
      *(void *)(a1 + 32) = *(void *)(a2 + 32);
      uint64_t v19 = *(void *)(a2 + 40);
      *(void *)(a1 + 40) = v19;
      *(void *)(a1 + 48) = *(void *)(a2 + 48);
      uint64_t v20 = *(void *)(a2 + 56);
      *(void *)(a1 + 56) = v20;
      swift_bridgeObjectRetain(v18);
      swift_bridgeObjectRetain(v19);
      swift_bridgeObjectRetain(v20);
      uint64_t v40 = 3;
      goto LABEL_9;
    case 4u:
      uint64_t v21 = *(void *)a2;
      char v22 = *(unsigned char *)(a2 + 8);
      outlined copy of Result<_DataTable, Error>(*(void *)a2, v22);
      *(void *)a1 = v21;
      *(unsigned char *)(a1 + 8) = v22;
      *(void *)(a1 + 16) = *(void *)(a2 + 16);
      uint64_t v23 = *(void *)(a2 + 24);
      *(void *)(a1 + 24) = v23;
      *(void *)(a1 + 32) = *(void *)(a2 + 32);
      uint64_t v24 = *(void *)(a2 + 40);
      *(void *)(a1 + 40) = v24;
      swift_bridgeObjectRetain(v23);
      swift_bridgeObjectRetain(v24);
      uint64_t v40 = 4;
      goto LABEL_9;
    case 5u:
      uint64_t v25 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v25 - 8) + 16))(a1, a2, v25);
      uint64_t v26 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      uint64_t v27 = v26[12];
      *(void *)(a1 + v27) = *(void *)(a2 + v27);
      uint64_t v28 = *(void *)(a2 + v27 + 8);
      *(void *)(a1 + v27 + 8) = v28;
      uint64_t v29 = v26[16];
      *(void *)(a1 + v29) = *(void *)(a2 + v29);
      uint64_t v30 = *(void *)(a2 + v29 + 8);
      *(void *)(a1 + v29 + 8) = v30;
      uint64_t v31 = v26[20];
      *(void *)(a1 + v31) = *(void *)(a2 + v31);
      uint64_t v32 = *(void *)(a2 + v31 + 8);
      *(void *)(a1 + v31 + 8) = v32;
      swift_bridgeObjectRetain(v28);
      swift_bridgeObjectRetain(v30);
      swift_bridgeObjectRetain(v32);
      uint64_t v40 = 5;
      goto LABEL_9;
    case 6u:
      uint64_t v33 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v33 - 8) + 16))(a1, a2, v33);
      uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
      uint64_t v35 = *(int *)(v34 + 48);
      *(void *)(a1 + v35) = *(void *)(a2 + v35);
      uint64_t v36 = *(void *)(a2 + v35 + 8);
      *(void *)(a1 + v35 + 8) = v36;
      uint64_t v37 = *(int *)(v34 + 64);
      *(void *)(a1 + v37) = *(void *)(a2 + v37);
      uint64_t v38 = *(void *)(a2 + v37 + 8);
      *(void *)(a1 + v37 + 8) = v38;
      swift_bridgeObjectRetain(v36);
      swift_bridgeObjectRetain(v38);
      uint64_t v40 = 6;
LABEL_9:
      uint64_t v13 = v40;
      uint64_t v11 = a1;
      uint64_t v12 = a3;
LABEL_10:
      swift_storeEnumTagMultiPayload(v11, v12, v13);
      return a1;
  }
}

uint64_t assignWithCopy for MLHandPoseClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLHandPoseClassifier.DataSource(a1);
    switch(swift_getEnumCaseMultiPayload(a2, a3))
    {
      case 0u:
        uint64_t v5 = type metadata accessor for URL(0);
        unsigned __int8 v41 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16);
        v41(a1, a2, v5);
        uint64_t v6 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v41(a1 + v6[12], a2 + v6[12], v5);
        uint64_t v7 = v6[16];
        *(void *)(a1 + v7) = *(void *)(a2 + v7);
        uint64_t v8 = *(void *)(a2 + v7 + 8);
        *(void *)(a1 + v7 + 8) = v8;
        uint64_t v9 = v6[20];
        *(void *)(a1 + v9) = *(void *)(a2 + v9);
        uint64_t v10 = *(void *)(a2 + v9 + 8);
        *(void *)(a1 + v9 + 8) = v10;
        swift_bridgeObjectRetain(v8);
        swift_bridgeObjectRetain(v10);
        uint64_t v11 = a1;
        uint64_t v12 = a3;
        uint64_t v13 = 0;
        goto LABEL_11;
      case 1u:
        uint64_t v14 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v14 - 8) + 16))(a1, a2, v14);
        uint64_t v40 = 1;
        goto LABEL_10;
      case 2u:
        uint64_t v15 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v15 - 8) + 16))(a1, a2, v15);
        uint64_t v40 = 2;
        goto LABEL_10;
      case 3u:
        uint64_t v16 = *(void *)a2;
        char v17 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(void *)a2, v17);
        *(void *)a1 = v16;
        *(unsigned char *)(a1 + 8) = v17;
        *(void *)(a1 + 16) = *(void *)(a2 + 16);
        uint64_t v18 = *(void *)(a2 + 24);
        *(void *)(a1 + 24) = v18;
        *(void *)(a1 + 32) = *(void *)(a2 + 32);
        uint64_t v19 = *(void *)(a2 + 40);
        *(void *)(a1 + 40) = v19;
        *(void *)(a1 + 48) = *(void *)(a2 + 48);
        uint64_t v20 = *(void *)(a2 + 56);
        *(void *)(a1 + 56) = v20;
        swift_bridgeObjectRetain(v18);
        swift_bridgeObjectRetain(v19);
        swift_bridgeObjectRetain(v20);
        uint64_t v40 = 3;
        goto LABEL_10;
      case 4u:
        uint64_t v21 = *(void *)a2;
        char v22 = *(unsigned char *)(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*(void *)a2, v22);
        *(void *)a1 = v21;
        *(unsigned char *)(a1 + 8) = v22;
        *(void *)(a1 + 16) = *(void *)(a2 + 16);
        uint64_t v23 = *(void *)(a2 + 24);
        *(void *)(a1 + 24) = v23;
        *(void *)(a1 + 32) = *(void *)(a2 + 32);
        uint64_t v24 = *(void *)(a2 + 40);
        *(void *)(a1 + 40) = v24;
        swift_bridgeObjectRetain(v23);
        swift_bridgeObjectRetain(v24);
        uint64_t v40 = 4;
        goto LABEL_10;
      case 5u:
        uint64_t v25 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v25 - 8) + 16))(a1, a2, v25);
        uint64_t v26 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v27 = v26[12];
        *(void *)(a1 + v27) = *(void *)(a2 + v27);
        uint64_t v28 = *(void *)(a2 + v27 + 8);
        *(void *)(a1 + v27 + 8) = v28;
        uint64_t v29 = v26[16];
        *(void *)(a1 + v29) = *(void *)(a2 + v29);
        uint64_t v30 = *(void *)(a2 + v29 + 8);
        *(void *)(a1 + v29 + 8) = v30;
        uint64_t v31 = v26[20];
        *(void *)(a1 + v31) = *(void *)(a2 + v31);
        uint64_t v32 = *(void *)(a2 + v31 + 8);
        *(void *)(a1 + v31 + 8) = v32;
        swift_bridgeObjectRetain(v28);
        swift_bridgeObjectRetain(v30);
        swift_bridgeObjectRetain(v32);
        uint64_t v40 = 5;
        goto LABEL_10;
      case 6u:
        uint64_t v33 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v33 - 8) + 16))(a1, a2, v33);
        uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        uint64_t v35 = *(int *)(v34 + 48);
        *(void *)(a1 + v35) = *(void *)(a2 + v35);
        uint64_t v36 = *(void *)(a2 + v35 + 8);
        *(void *)(a1 + v35 + 8) = v36;
        uint64_t v37 = *(int *)(v34 + 64);
        *(void *)(a1 + v37) = *(void *)(a2 + v37);
        uint64_t v38 = *(void *)(a2 + v37 + 8);
        *(void *)(a1 + v37 + 8) = v38;
        swift_bridgeObjectRetain(v36);
        swift_bridgeObjectRetain(v38);
        uint64_t v40 = 6;
LABEL_10:
        uint64_t v13 = v40;
        uint64_t v11 = a1;
        uint64_t v12 = a3;
LABEL_11:
        swift_storeEnumTagMultiPayload(v11, v12, v13);
        break;
    }
  }
  return a1;
}

char *initializeWithTake for MLHandPoseClassifier.DataSource(char *__dst, char *__src, uint64_t a3)
{
  switch(swift_getEnumCaseMultiPayload(__src, a3))
  {
    case 0u:
      uint64_t v4 = type metadata accessor for URL(0);
      uint64_t v16 = *(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 32);
      v16(__dst, __src, v4);
      uint64_t v5 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
      v16(&__dst[v5[12]], &__src[v5[12]], v4);
      *(_OWORD *)&__dst[v5[16]] = *(_OWORD *)&__src[v5[16]];
      *(_OWORD *)&__dst[v5[20]] = *(_OWORD *)&__src[v5[20]];
      uint64_t v6 = a3;
      uint64_t v7 = 0;
      goto LABEL_9;
    case 1u:
      uint64_t v8 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
      uint64_t v15 = 1;
      goto LABEL_8;
    case 2u:
      uint64_t v9 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
      uint64_t v15 = 2;
      goto LABEL_8;
    case 5u:
      uint64_t v10 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
      uint64_t v11 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      *(_OWORD *)&__dst[v11[12]] = *(_OWORD *)&__src[v11[12]];
      *(_OWORD *)&__dst[v11[16]] = *(_OWORD *)&__src[v11[16]];
      *(_OWORD *)&__dst[v11[20]] = *(_OWORD *)&__src[v11[20]];
      uint64_t v15 = 5;
      goto LABEL_8;
    case 6u:
      uint64_t v12 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
      uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
      *(_OWORD *)&__dst[*(int *)(v13 + 48)] = *(_OWORD *)&__src[*(int *)(v13 + 48)];
      *(_OWORD *)&__dst[*(int *)(v13 + 64)] = *(_OWORD *)&__src[*(int *)(v13 + 64)];
      uint64_t v15 = 6;
LABEL_8:
      uint64_t v7 = v15;
      uint64_t v6 = a3;
LABEL_9:
      swift_storeEnumTagMultiPayload(__dst, v6, v7);
      break;
    default:
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
      break;
  }
  return __dst;
}

char *assignWithTake for MLHandPoseClassifier.DataSource(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)__dst);
    switch(swift_getEnumCaseMultiPayload(__src, a3))
    {
      case 0u:
        uint64_t v4 = type metadata accessor for URL(0);
        uint64_t v16 = *(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 32);
        v16(__dst, __src, v4);
        uint64_t v5 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v16(&__dst[v5[12]], &__src[v5[12]], v4);
        *(_OWORD *)&__dst[v5[16]] = *(_OWORD *)&__src[v5[16]];
        *(_OWORD *)&__dst[v5[20]] = *(_OWORD *)&__src[v5[20]];
        uint64_t v6 = a3;
        uint64_t v7 = 0;
        goto LABEL_10;
      case 1u:
        uint64_t v8 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
        uint64_t v15 = 1;
        goto LABEL_9;
      case 2u:
        uint64_t v9 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
        uint64_t v15 = 2;
        goto LABEL_9;
      case 5u:
        uint64_t v10 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
        uint64_t v11 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        *(_OWORD *)&__dst[v11[12]] = *(_OWORD *)&__src[v11[12]];
        *(_OWORD *)&__dst[v11[16]] = *(_OWORD *)&__src[v11[16]];
        *(_OWORD *)&__dst[v11[20]] = *(_OWORD *)&__src[v11[20]];
        uint64_t v15 = 5;
        goto LABEL_9;
      case 6u:
        uint64_t v12 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
        uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        *(_OWORD *)&__dst[*(int *)(v13 + 48)] = *(_OWORD *)&__src[*(int *)(v13 + 48)];
        *(_OWORD *)&__dst[*(int *)(v13 + 64)] = *(_OWORD *)&__src[*(int *)(v13 + 64)];
        uint64_t v15 = 6;
LABEL_9:
        uint64_t v7 = v15;
        uint64_t v6 = a3;
LABEL_10:
        swift_storeEnumTagMultiPayload(__dst, v6, v7);
        break;
      default:
        memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
        break;
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLHandPoseClassifier.DataSource(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for URL(319);
  uint64_t v2 = v1;
  if (v3 <= 0x3F)
  {
    uint64_t v4 = *(void *)(v1 - 8) + 64;
    uint64_t v14 = v4;
    uint64_t v15 = (void *)v4;
    uint64_t v16 = &unk_351048;
    char v17 = &unk_351048;
    swift_getTupleTypeLayout(v11, 0, 4);
    v18[0] = v11;
    v18[1] = v4;
    void v18[2] = v4;
    void v18[3] = &unk_351060;
    v18[4] = &unk_351078;
    uint64_t v5 = type metadata accessor for DataFrame(319);
    uint64_t v2 = v5;
    if (v6 <= 0x3F)
    {
      uint64_t v14 = *(void *)(v5 - 8) + 64;
      uint64_t v7 = v14;
      uint64_t v15 = &unk_351048;
      uint64_t v16 = &unk_351048;
      char v17 = &unk_351048;
      uint64_t v2 = 0;
      uint64_t v19 = a1;
      swift_getTupleTypeLayout(v12, 0, 4);
      v18[5] = v12;
      swift_getTupleTypeLayout3(v13, v7, &unk_351048, &unk_351048);
      uint64_t v18[6] = v13;
      swift_initEnumMetadataMultiPayload(v19, 256, 7, v18, v8, v9);
    }
  }
  return v2;
}

uint64_t static MLLinearRegressor.ModelParameters.firstIncompatibility(_:_:)(uint64_t a1, uint64_t a2)
{
  unint64_t v3 = v2;
  if (*(void *)(a1 + 32) == *(void *)(a2 + 32))
  {
    double v4 = *(double *)(a1 + 40);
    if (v4 == *(double *)(a2 + 40))
    {
      double v5 = *(double *)(a1 + 48);
      if (v5 == *(double *)(a2 + 48))
      {
        double v6 = *(double *)(a1 + 56);
        if (v6 == *(double *)(a2 + 56))
        {
          double v7 = *(double *)(a1 + 64);
          if (v7 == *(double *)(a2 + 64))
          {
            unsigned __int8 v8 = *(unsigned char *)(a1 + 72);
            unsigned __int8 v9 = *(unsigned char *)(a2 + 72);
            if (v8 == v9)
            {
              unint64_t v15 = 0;
              uint64_t v14 = 0;
              uint64_t v11 = 0;
              unint64_t v12 = 0;
              uint64_t result = 0;
              unint64_t v13 = 0;
            }
            else
            {
              uint64_t result = 0x65736C6166;
              uint64_t v11 = 0x65736C6166;
              if (v8) {
                uint64_t v11 = 1702195828;
              }
              unint64_t v12 = (v8 ^ 1u | 0xFFFFFFFFFFFFFFE4) << 56;
              if (v9) {
                uint64_t result = 1702195828;
              }
              unint64_t v13 = (v9 ^ 1u | 0xFFFFFFFFFFFFFFE4) << 56;
              uint64_t v14 = (char *)0xEF676E696C616373;
              unint64_t v15 = 0x2065727574616546;
            }
          }
          else
          {
            double v26 = *(double *)(a2 + 64);
            uint64_t v11 = Double.description.getter(v7);
            unint64_t v12 = v22;
            uint64_t result = Double.description.getter(v26);
            uint64_t v14 = "e at least one element" + 0x8000000000000000;
            unint64_t v15 = 0xD000000000000015;
          }
        }
        else
        {
          double v25 = *(double *)(a2 + 56);
          uint64_t v11 = Double.description.getter(v6);
          unint64_t v12 = v21;
          uint64_t result = Double.description.getter(v25);
          uint64_t v14 = (char *)0xE900000000000065;
          unint64_t v15 = 0x7A69732070657453;
        }
      }
      else
      {
        uint64_t v14 = (char *)0xEA00000000007974;
        double v24 = *(double *)(a2 + 48);
        uint64_t v11 = Double.description.getter(v5);
        unint64_t v12 = v20;
        uint64_t result = Double.description.getter(v24);
        unint64_t v15 = 0x6C616E657020324CLL;
      }
    }
    else
    {
      uint64_t v14 = (char *)0xEA00000000007974;
      unint64_t v15 = 0x6C616E657020314CLL;
      double v23 = *(double *)(a2 + 40);
      uint64_t v11 = Double.description.getter(v4);
      unint64_t v12 = v19;
      uint64_t result = Double.description.getter(v23);
    }
  }
  else
  {
    uint64_t v16 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    unint64_t v18 = v17;
    uint64_t v11 = v16;
    uint64_t result = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    unint64_t v12 = v18;
    uint64_t v14 = (char *)0xEF736E6F69746172;
    unint64_t v15 = 0x657469202E78614DLL;
  }
  unint64_t *v3 = v15;
  v3[1] = (unint64_t)v14;
  v3[2] = v11;
  v3[3] = v12;
  void v3[4] = result;
  void v3[5] = v13;
  return result;
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance TreeClassifierTrainingSessionDelegate(uint64_t a1)
{
  uint64_t v2 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized TrainingSessionDelegate.extractFeatures(from:)
                                       + async function pointer to specialized TrainingSessionDelegate.extractFeatures(from:));
  unint64_t v3 = (void *)swift_task_alloc(dword_3AE0E4);
  *(void *)(v1 + 16) = v3;
  void *v3 = v1;
  v3[1] = protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance TreeClassifierTrainingSessionDelegate;
  return v2(a1);
}

{
  return protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance SoundClassifierTrainingSessionDelegate(a1);
}

uint64_t specialized TrainingSessionDelegate.extractFeatures(from:)()
{
  return protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(*(uint64_t (**)(uint64_t, void))(v0 + 8), v0, 0, 1u);
}

{
  return specialized TrainingSessionDelegate.extractFeatures(from:)();
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance MLStyleTransfer.TrainingSessionDelegate()
{
  uint64_t v1 = (void *)swift_task_alloc(dword_3AE0AC);
  *(void *)(v0 + 16) = v1;
  *uint64_t v1 = v0;
  v1[1] = protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance SoundClassifierTrainingSessionDelegate;
  return specialized TrainingSessionDelegate.extractFeatures(from:)();
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance LogisticRegressionClassifierTrainingSessionDelegate(uint64_t a1)
{
  uint64_t v2 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized TrainingSessionDelegate.extractFeatures(from:)
                                       + async function pointer to specialized TrainingSessionDelegate.extractFeatures(from:));
  unint64_t v3 = (void *)swift_task_alloc(dword_3AE0D4);
  *(void *)(v1 + 16) = v3;
  void *v3 = v1;
  v3[1] = protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance TreeClassifierTrainingSessionDelegate;
  return v2(a1);
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance ActivityClassifierTrainingSessionDelegate()
{
  uint64_t v1 = (void *)swift_task_alloc(dword_3AE0AC);
  *(void *)(v0 + 16) = v1;
  *uint64_t v1 = v0;
  v1[1] = protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance TreeClassifierTrainingSessionDelegate;
  return specialized TrainingSessionDelegate.extractFeatures(from:)();
}

char protocol witness for TrainingSessionDelegate.shouldTransition(from:to:) in conformance ActivityClassifierTrainingSessionDelegate()
{
  return 1;
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance LinearRegressorTrainingSessionDelegate(uint64_t a1)
{
  uint64_t v2 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized TrainingSessionDelegate.extractFeatures(from:)
                                       + async function pointer to specialized TrainingSessionDelegate.extractFeatures(from:));
  unint64_t v3 = (void *)swift_task_alloc(dword_3AE0FC);
  *(void *)(v1 + 16) = v3;
  void *v3 = v1;
  v3[1] = protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance TreeClassifierTrainingSessionDelegate;
  return v2(a1);
}

void protocol witness for TrainingSessionDelegate.transitionTo(phase:) in conformance TreeRegressorTrainingSessionDelegate()
{
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance TreeRegressorTrainingSessionDelegate(uint64_t a1)
{
  uint64_t v2 = (uint64_t (*)(uint64_t))((char *)&async function pointer to specialized TrainingSessionDelegate.extractFeatures(from:)
                                       + async function pointer to specialized TrainingSessionDelegate.extractFeatures(from:));
  unint64_t v3 = (void *)swift_task_alloc(dword_3AE0BC);
  *(void *)(v1 + 16) = v3;
  void *v3 = v1;
  v3[1] = protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance TreeClassifierTrainingSessionDelegate;
  return v2(a1);
}

char protocol witness for TrainingSessionDelegate.shouldTransition(from:to:) in conformance TreeRegressorTrainingSessionDelegate()
{
  return protocol witness for static Equatable.== infix(_:_:) in conformance MLHandActionClassifier.ModelParameters.ModelAlgorithmType();
}

void protocol witness for TrainingSessionDelegate.transitionTo(phase:) in conformance LogisticRegressionClassifierTrainingSessionDelegate()
{
}

char protocol witness for TrainingSessionDelegate.shouldTransition(from:to:) in conformance TreeClassifierTrainingSessionDelegate()
{
  return protocol witness for TrainingSessionDelegate.shouldTransition(from:to:) in conformance TreeRegressorTrainingSessionDelegate();
}

void MLLinearRegressor.predictions(from:)(uint64_t a1)
{
  uint64_t v3 = v2;
  uint64_t v13 = v1;
  uint64_t v12 = type metadata accessor for DataFrame(0);
  uint64_t v11 = *(void *)(v12 - 8);
  int64_t v5 = *(void *)(v11 + 64);
  double v6 = alloca(v5);
  double v7 = alloca(v5);
  uint64_t v14 = &v11;
  uint64_t v8 = type metadata accessor for MLLinearRegressor(0);
  DataFrame.validateContainsColumns(_:context:)(*(Swift::OpaquePointer *)(v3 + *(int *)(v8 + 28)), (Swift::String)__PAIR128__(0xE700000000000000, 0x65727574616546));
  if (!v9)
  {
    MLLinearRegressor.Model.applied(to:eventHandler:)(a1, 0, 0);
    uint64_t v10 = v14;
    DataFrame.subscript.getter(*(void *)(v3 + *(int *)(v8 + 24)), *(void *)(v3 + *(int *)(v8 + 24) + 8));
    (*(void (**)(uint64_t *, uint64_t))(v11 + 8))(v10, v12);
  }
}

uint64_t type metadata accessor for MLLinearRegressor(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLLinearRegressor;
  if (!type metadata singleton initialization cache for MLLinearRegressor) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLLinearRegressor);
  }
  return result;
}

uint64_t MLLinearRegressor.predictions(from:)(uint64_t a1, __m128 a2)
{
  uint64_t v15 = v3;
  uint64_t v16 = v2;
  uint64_t v17 = type metadata accessor for DataFrame(0);
  uint64_t v18 = *(void *)(v17 - 8);
  int64_t v4 = *(void *)(v18 + 64);
  int64_t v5 = alloca(v4);
  double v6 = alloca(v4);
  int64_t v7 = *(void *)(*(void *)(type metadata accessor for AnyColumn(0) - 8) + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  char v10 = *(unsigned char *)(a1 + 8);
  uint64_t v13 = *(void *)a1;
  char v14 = v10;
  outlined copy of Result<_DataTable, Error>(v13, v10);
  DataFrame.init(_:)((uint64_t)&v13);
  uint64_t v11 = v15;
  MLLinearRegressor.predictions(from:)((uint64_t)&v13);
  if (v11) {
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v18 + 8))(&v13, v17);
  }
  *(double *)a2.i64 = (*(double (**)(uint64_t *, uint64_t))(v18 + 8))(&v13, v17);
  return MLUntypedColumn.init(_:convertArraysToShapedArrays:)((uint64_t)&v13, 1, a2);
}

void MLLinearRegressor.evaluation(on:)(uint64_t a1)
{
  uint64_t v3 = v2;
  uint64_t v5 = v1;
  uint64_t v6 = type metadata accessor for MLLinearRegressor(0);
  uint64_t v29 = *(void *)(v6 - 8);
  int64_t v27 = *(void *)(v29 + 64);
  int64_t v7 = alloca(v27);
  uint64_t v8 = alloca(v27);
  uint64_t v31 = v24;
  uint64_t v32 = type metadata accessor for DataFrame(0);
  uint64_t v28 = *(void *)(v32 - 8);
  int64_t v26 = *(void *)(v28 + 64);
  uint64_t v9 = alloca(v26);
  char v10 = alloca(v26);
  uint64_t v33 = v24;
  v11._uint64_t rawValue = *(void **)(v3 + *(int *)(v6 + 28));
  uint64_t v30 = a1;
  DataFrame.validateContainsColumns(_:context:)(v11, (Swift::String)__PAIR128__(0xE700000000000000, 0x65727574616546));
  if (v12) {
    goto LABEL_4;
  }
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t inited = swift_initStackObject(v13, v25);
  uint64_t v34 = v5;
  v15._uint64_t rawValue = (void *)inited;
  *(void *)(inited + 16) = 1;
  *(void *)(inited + 24) = 2;
  uint64_t v16 = *(int *)(v6 + 24);
  uint64_t v17 = *(void *)(v3 + v16 + 8);
  *((void *)v15._rawValue + 4) = *(void *)(v3 + v16);
  *((void *)v15._rawValue + 5) = v17;
  swift_bridgeObjectRetain(v17);
  DataFrame.validateContainsColumns(_:context:)(v15, (Swift::String)__PAIR128__(0xE500000000000000, 0x6C6562614CLL));
  swift_setDeallocating(v15._rawValue);
  uint64_t v5 = v34;
  specialized _ContiguousArrayStorage.__deallocating_deinit();
  if (v12)
  {
LABEL_4:
    *(void *)uint64_t v5 = v12;
    *(void *)(v5 + 8) = 0;
    *(unsigned char *)(v5 + 16) = 1;
  }
  else
  {
    uint64_t v18 = v28;
    (*(void (**)(unsigned char *, uint64_t, uint64_t))(v28 + 16))(v33, v30, v32);
    outlined init with copy of MLTrainingSessionParameters(v3, (uint64_t)v31, type metadata accessor for MLLinearRegressor);
    uint64_t v19 = *(unsigned __int8 *)(v18 + 80);
    uint64_t v20 = ~*(unsigned __int8 *)(v18 + 80) & (v19 + 16);
    uint64_t v21 = *(unsigned __int8 *)(v29 + 80);
    int64_t v22 = ~v21 & (v20 + v21 + v26);
    uint64_t v23 = swift_allocObject(&unk_39CCB8, v22 + v27, v21 | v19 | 7);
    (*(void (**)(uint64_t, unsigned char *, uint64_t))(v18 + 32))(v23 + v20, v33, v32);
    outlined init with take of MLClassifierMetrics((uint64_t)v31, v23 + v22, type metadata accessor for MLLinearRegressor);
    specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLLinearRegressor.computeMetrics(on:), v23);
    swift_release();
  }
}

uint64_t MLLinearRegressor.evaluation(on:)(uint64_t a1)
{
  uint64_t v11 = v1;
  uint64_t v2 = type metadata accessor for DataFrame(0);
  uint64_t v3 = *(void *)(v2 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  char v7 = *(unsigned char *)(a1 + 8);
  uint64_t v9 = *(void *)a1;
  char v10 = v7;
  outlined copy of Result<_DataTable, Error>(v9, v7);
  DataFrame.init(_:)((uint64_t)&v9);
  MLLinearRegressor.evaluation(on:)((uint64_t)&v9);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v3 + 8))(&v9, v2);
}

uint64_t MLLinearRegressor.write(to:metadata:)(uint64_t a1, uint64_t *a2)
{
  uint64_t v61 = v2;
  uint64_t v60 = v3;
  uint64_t v59 = a1;
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for MLLinearRegressor.Model(0) - 8) + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v42 = v40;
  uint64_t v53 = type metadata accessor for Model(0);
  uint64_t v52 = *(void *)(v53 - 8);
  int64_t v7 = *(void *)(v52 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  unsigned __int8 v41 = v40;
  uint64_t v10 = type metadata accessor for URL(0);
  uint64_t v11 = *(void *)(v10 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  uint64_t v13 = alloca(v12);
  char v14 = alloca(v12);
  uint64_t v45 = *a2;
  uint64_t v43 = a2[1];
  unint64_t v46 = a2[2];
  uint64_t v47 = (char *)a2[3];
  uint64_t v48 = a2[4];
  uint64_t v49 = a2[5];
  uint64_t v44 = a2[6];
  unint64_t v50 = a2[7];
  uint64_t v51 = a2[8];
  uint64_t v15 = v61;
  uint64_t result = static _ValidationUtilities.validateWriteLocation(atURL:defaultName:fileExtension:)(v59, 0x65527261656E694CLL, 0xEF726F7373657267, 0x6C65646F6D6C6DLL, (void *)0xE700000000000000);
  if (!v15)
  {
    uint64_t v55 = v40;
    uint64_t v56 = v10;
    uint64_t v54 = v11;
    outlined init with copy of MLTrainingSessionParameters(v60, (uint64_t)v42, type metadata accessor for MLLinearRegressor.Model);
    uint64_t v61 = 0;
    if (v43)
    {
      uint64_t v17 = v45;
      uint64_t v18 = v45;
      uint64_t v59 = v43;
      uint64_t v19 = v46;
      unint64_t v20 = v46;
      uint64_t v21 = (uint64_t)v47;
      int64_t v22 = v47;
      uint64_t v23 = v48;
      uint64_t v24 = v48;
      uint64_t v25 = v49;
      uint64_t v57 = v49;
      uint64_t v26 = v44;
      uint64_t v27 = v44;
      uint64_t v28 = v50;
      unint64_t v58 = v50;
      uint64_t v29 = v51;
      uint64_t v60 = v51;
    }
    else
    {
      uint64_t v30 = NSFullUserName();
      uint64_t v31 = v30;
      uint64_t v18 = static String._unconditionallyBridgeFromObjectiveC(_:)(v31);
      uint64_t v59 = v32;

      int64_t v22 = "RandomForestRegressor" + 0x8000000000000000;
      unint64_t v58 = 0xE100000000000000;
      uint64_t v27 = 49;
      unint64_t v20 = 0xD000000000000033;
      uint64_t v24 = 0;
      uint64_t v57 = 0;
      uint64_t v60 = 0;
      uint64_t v26 = v44;
      uint64_t v17 = v45;
      uint64_t v19 = v46;
      uint64_t v21 = (uint64_t)v47;
      uint64_t v23 = v48;
      uint64_t v25 = v49;
      uint64_t v28 = v50;
      uint64_t v29 = v51;
    }
    v40[0] = v18;
    v40[1] = v59;
    v40[2] = v20;
    v40[3] = v22;
    v40[4] = v24;
    v40[5] = v57;
    v40[6] = v27;
    v40[7] = v58;
    v40[8] = v60;
    outlined copy of MLModelMetadata?(v17, v43, v19, v21, v23, v25, v26, v28, v29);
    uint64_t v33 = v41;
    uint64_t v34 = (uint64_t)v42;
    uint64_t v35 = v61;
    specialized CoreMLExportable.export(metadata:)((uint64_t)v40);
    if (v35)
    {
      uint64_t v61 = v35;
      swift_bridgeObjectRelease(v58);
      swift_bridgeObjectRelease((_BYTE)v22);
      swift_bridgeObjectRelease(v59);
      swift_bridgeObjectRelease(v57);
      swift_bridgeObjectRelease(v60);
      outlined destroy of MLActivityClassifier.ModelParameters(v34, type metadata accessor for MLLinearRegressor.Model);
      uint64_t v36 = v54;
      uint64_t v37 = v56;
      uint64_t v39 = v55;
    }
    else
    {
      swift_bridgeObjectRelease(v58);
      swift_bridgeObjectRelease((_BYTE)v22);
      swift_bridgeObjectRelease(v59);
      swift_bridgeObjectRelease(v57);
      swift_bridgeObjectRelease(v60);
      outlined destroy of MLActivityClassifier.ModelParameters(v34, type metadata accessor for MLLinearRegressor.Model);
      uint64_t v38 = v55;
      Model.write(to:)(v55);
      uint64_t v61 = 0;
      uint64_t v36 = v54;
      (*(void (**)(void *, uint64_t))(v52 + 8))(v33, v53);
      uint64_t v39 = v38;
      uint64_t v37 = v56;
    }
    return (*(uint64_t (**)(void *, uint64_t))(v36 + 8))(v39, v37);
  }
  return result;
}

uint64_t MLLinearRegressor.write(toFile:metadata:)(uint64_t a1, uint64_t a2, long long *a3)
{
  uint64_t v23 = v3;
  uint64_t v25 = a2;
  uint64_t v24 = a1;
  uint64_t v26 = type metadata accessor for URL.DirectoryHint(0);
  uint64_t v27 = *(void *)(v26 - 8);
  int64_t v5 = *(void *)(v27 + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v11 = type metadata accessor for URL(0);
  uint64_t v29 = *(void *)(v11 - 8);
  int64_t v12 = *(void *)(v29 + 64);
  uint64_t v13 = alloca(v12);
  char v14 = alloca(v12);
  uint64_t v28 = *((void *)a3 + 8);
  long long v19 = *a3;
  long long v20 = a3[1];
  long long v21 = a3[2];
  long long v22 = a3[3];
  uint64_t v30 = v11;
  __swift_storeEnumTagSinglePayload((uint64_t)v17, 1, 1, v11);
  (*(void (**)(_OWORD *, void, uint64_t))(v27 + 104))(v17, enum case for URL.DirectoryHint.inferFromPath(_:), v26);
  uint64_t v15 = v25;
  swift_bridgeObjectRetain(v25);
  URL.init(filePath:directoryHint:relativeTo:)(v24, v15, v17, v17);
  v17[0] = v19;
  v17[1] = v20;
  long long v17[2] = v21;
  v17[3] = v22;
  uint64_t v18 = v28;
  MLLinearRegressor.write(to:metadata:)((uint64_t)v17, (uint64_t *)v17);
  return (*(uint64_t (**)(_OWORD *, uint64_t))(v29 + 8))(v17, v30);
}

id MLLinearRegressor.model.getter()
{
  uint64_t v1 = type metadata accessor for MLLinearRegressor(0);
  return *(id *)(v0 + *(int *)(v1 + 20));
}

unint64_t MLLinearRegressor.description.getter()
{
  uint64_t v1 = type metadata accessor for MLLinearRegressor(0);
  unint64_t v14 = MLLinearRegressor.ModelParameters.description.getter();
  uint64_t v3 = v2;
  unint64_t v16 = MLRegressorMetrics.description.getter();
  int64_t v5 = v4;
  char v13 = *(unsigned char *)(v0 + *(int *)(v1 + 40) + 16);
  v12._uint64_t countAndFlagsBits = MLRegressorMetrics.description.getter();
  v12._unsigned __int8 object = v6;
  v7._uint64_t countAndFlagsBits = v14;
  char v15 = (char)v3;
  v7._unsigned __int8 object = v3;
  String.append(_:)(v7);
  v7._uint64_t countAndFlagsBits = v16;
  v7._unsigned __int8 object = v5;
  String.append(_:)(v7);
  v7._uint64_t countAndFlagsBits = 0xD00000000000001ELL;
  v7._unsigned __int8 object = "ActivityClassifier\n\nParameters\n" + 0x8000000000000000;
  String.append(_:)(v7);
  swift_bridgeObjectRelease(("ActivityClassifier\n\nParameters\n" + 0x8000000000000000));
  if (v13)
  {
    char v8 = (char)v5;
    unsigned __int8 object = v12._object;
  }
  else
  {
    String.append(_:)(v12);
    v10._uint64_t countAndFlagsBits = 0xD000000000000020;
    unsigned __int8 object = ("\nPerformance on Training Data\n" + 0x8000000000000000);
    v10._unsigned __int8 object = "\nPerformance on Training Data\n" + 0x8000000000000000;
    String.append(_:)(v10);
    swift_bridgeObjectRelease((_BYTE)v5);
    char v8 = (char)v12._object;
  }
  swift_bridgeObjectRelease(v8);
  swift_bridgeObjectRelease(object);
  swift_bridgeObjectRelease(v15);
  return 0xD00000000000001CLL;
}

unint64_t MLLinearRegressor.debugDescription.getter()
{
  return MLLinearRegressor.description.getter();
}

NSAttributedString MLLinearRegressor.playgroundDescription.getter()
{
  uint64_t v1 = v0;
  uint64_t v2 = type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for NSAttributedString, NSAttributedString_ptr);
  v3._uint64_t countAndFlagsBits = MLLinearRegressor.description.getter();
  v3._unsigned __int8 object = v4;
  result.super.Class isa = NSAttributedString.__allocating_init(string:)(v3).super.isa;
  v1[3].super.Class isa = (Class)v2;
  v1->super.Class isa = result.super.isa;
  return result;
}

uint64_t specialized CoreMLExportable.exportAsCoreMLModel()()
{
  v1[11] = v0;
  uint64_t v2 = type metadata accessor for Model(0);
  v1[12] = v2;
  uint64_t v3 = *(void *)(v2 - 8);
  v1[13] = v3;
  v1[14] = swift_task_alloc((*(void *)(v3 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized CoreMLExportable.exportAsCoreMLModel(), 0, 0);
}

{
  uint64_t v0;
  NSString *v1;
  NSString *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  void *v9;

  uint64_t v1 = NSFullUserName();
  uint64_t v2 = v1;
  uint64_t v3 = static String._unconditionallyBridgeFromObjectiveC(_:)(v2);
  int64_t v5 = v4;

  *(void *)(v0 + 16) = v3;
  *(void *)(v0 + 24) = v5;
  *(void *)(v0 + 32) = 0xD000000000000033;
  *(void *)(v0 + 40) = "RandomForestRegressor" + 0x8000000000000000;
  *(_OWORD *)(v0 + 48) = 0;
  *(void *)(v0 + 64) = 49;
  *(void *)(v0 + 72) = 0xE100000000000000;
  *(void *)(v0 + 80) = 0;
  specialized CoreMLExportable.export(metadata:)(v0 + 16);
  swift_bridgeObjectRelease(v5);
  swift_bridgeObjectRelease(("RandomForestRegressor" + 0x8000000000000000));
  swift_bridgeObjectRelease_n(0, 2, v6, v7, v8);
  swift_bridgeObjectRelease(0);
  type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for MLModel, MLModel_ptr);
  uint64_t v9 = (void *)swift_task_alloc(dword_3A701C);
  *(void *)(v0 + 120) = v9;
  *uint64_t v9 = v0;
  v9[1] = specialized CoreMLExportable.exportAsCoreMLModel();
  return static MLModel.compile(_:)(*(void *)(v0 + 112));
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;

  v1[11] = v0;
  uint64_t v2 = type metadata accessor for Model(0);
  v1[12] = v2;
  uint64_t v3 = *(void *)(v2 - 8);
  v1[13] = v3;
  v1[14] = swift_task_alloc((*(void *)(v3 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized CoreMLExportable.exportAsCoreMLModel(), 0, 0);
}

{
  uint64_t v0;
  NSString *v1;
  NSString *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  void *v9;

  uint64_t v1 = NSFullUserName();
  uint64_t v2 = v1;
  uint64_t v3 = static String._unconditionallyBridgeFromObjectiveC(_:)(v2);
  int64_t v5 = v4;

  *(void *)(v0 + 16) = v3;
  *(void *)(v0 + 24) = v5;
  *(void *)(v0 + 32) = 0xD000000000000033;
  *(void *)(v0 + 40) = "RandomForestRegressor" + 0x8000000000000000;
  *(_OWORD *)(v0 + 48) = 0;
  *(void *)(v0 + 64) = 49;
  *(void *)(v0 + 72) = 0xE100000000000000;
  *(void *)(v0 + 80) = 0;
  specialized CoreMLExportable.export(metadata:)(v0 + 16);
  swift_bridgeObjectRelease(v5);
  swift_bridgeObjectRelease(("RandomForestRegressor" + 0x8000000000000000));
  swift_bridgeObjectRelease_n(0, 2, v6, v7, v8);
  swift_bridgeObjectRelease(0);
  type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for MLModel, MLModel_ptr);
  uint64_t v9 = (void *)swift_task_alloc(dword_3A701C);
  *(void *)(v0 + 120) = v9;
  *uint64_t v9 = v0;
  v9[1] = specialized CoreMLExportable.exportAsCoreMLModel();
  return static MLModel.compile(_:)(*(void *)(v0 + 112));
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;

  v1[11] = v0;
  uint64_t v2 = type metadata accessor for Model(0);
  v1[12] = v2;
  uint64_t v3 = *(void *)(v2 - 8);
  v1[13] = v3;
  v1[14] = swift_task_alloc((*(void *)(v3 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized CoreMLExportable.exportAsCoreMLModel(), 0, 0);
}

{
  uint64_t v0;
  NSString *v1;
  NSString *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  void *v9;

  uint64_t v1 = NSFullUserName();
  uint64_t v2 = v1;
  uint64_t v3 = static String._unconditionallyBridgeFromObjectiveC(_:)(v2);
  int64_t v5 = v4;

  *(void *)(v0 + 16) = v3;
  *(void *)(v0 + 24) = v5;
  *(void *)(v0 + 32) = 0xD000000000000033;
  *(void *)(v0 + 40) = "RandomForestRegressor" + 0x8000000000000000;
  *(_OWORD *)(v0 + 48) = 0;
  *(void *)(v0 + 64) = 49;
  *(void *)(v0 + 72) = 0xE100000000000000;
  *(void *)(v0 + 80) = 0;
  specialized CoreMLExportable.export(metadata:)(v0 + 16);
  swift_bridgeObjectRelease(v5);
  swift_bridgeObjectRelease(("RandomForestRegressor" + 0x8000000000000000));
  swift_bridgeObjectRelease_n(0, 2, v6, v7, v8);
  swift_bridgeObjectRelease(0);
  type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for MLModel, MLModel_ptr);
  uint64_t v9 = (void *)swift_task_alloc(dword_3A701C);
  *(void *)(v0 + 120) = v9;
  *uint64_t v9 = v0;
  v9[1] = specialized CoreMLExportable.exportAsCoreMLModel();
  return static MLModel.compile(_:)(*(void *)(v0 + 112));
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;

  v1[11] = v0;
  uint64_t v2 = type metadata accessor for Model(0);
  v1[12] = v2;
  uint64_t v3 = *(void *)(v2 - 8);
  v1[13] = v3;
  v1[14] = swift_task_alloc((*(void *)(v3 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized CoreMLExportable.exportAsCoreMLModel(), 0, 0);
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;

  v1[11] = v0;
  uint64_t v2 = type metadata accessor for Model(0);
  v1[12] = v2;
  uint64_t v3 = *(void *)(v2 - 8);
  v1[13] = v3;
  v1[14] = swift_task_alloc((*(void *)(v3 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized CoreMLExportable.exportAsCoreMLModel(), 0, 0);
}

{
  uint64_t v0;
  NSString *v1;
  NSString *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  void *v9;

  uint64_t v1 = NSFullUserName();
  uint64_t v2 = v1;
  uint64_t v3 = static String._unconditionallyBridgeFromObjectiveC(_:)(v2);
  int64_t v5 = v4;

  *(void *)(v0 + 16) = v3;
  *(void *)(v0 + 24) = v5;
  *(void *)(v0 + 32) = 0xD000000000000033;
  *(void *)(v0 + 40) = "RandomForestRegressor" + 0x8000000000000000;
  *(_OWORD *)(v0 + 48) = 0;
  *(void *)(v0 + 64) = 49;
  *(void *)(v0 + 72) = 0xE100000000000000;
  *(void *)(v0 + 80) = 0;
  specialized CoreMLExportable.export(metadata:)(v0 + 16);
  swift_bridgeObjectRelease(v5);
  swift_bridgeObjectRelease(("RandomForestRegressor" + 0x8000000000000000));
  swift_bridgeObjectRelease_n(0, 2, v6, v7, v8);
  swift_bridgeObjectRelease(0);
  type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for MLModel, MLModel_ptr);
  uint64_t v9 = (void *)swift_task_alloc(dword_3A701C);
  *(void *)(v0 + 120) = v9;
  *uint64_t v9 = v0;
  v9[1] = specialized CoreMLExportable.exportAsCoreMLModel();
  return static MLModel.compile(_:)(*(void *)(v0 + 112));
}

{
  uint64_t v0;
  uint64_t v1;

  uint64_t v1 = *(void *)(v0 + 112);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 104) + 8))(v1, *(void *)(v0 + 96));
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))(*(void *)(v0 + 136));
}

{
  uint64_t v0;

  (*(void (**)(void, void))(*(void *)(v0 + 104) + 8))(*(void *)(v0 + 112), *(void *)(v0 + 96));
  swift_task_dealloc(*(void *)(v0 + 112));
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  return specialized CoreMLExportable.exportAsCoreMLModel()();
}

{
  return specialized CoreMLExportable.exportAsCoreMLModel()();
}

{
  return specialized CoreMLExportable.exportAsCoreMLModel()();
}

uint64_t specialized CoreMLExportable.exportAsCoreMLModel()(uint64_t a1)
{
  uint64_t v5 = *(void *)(*v2 + 120);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 128) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = specialized CoreMLExportable.exportAsCoreMLModel();
  }
  else
  {
    *(void *)(v4 + 136) = a1;
    uint64_t v6 = specialized CoreMLExportable.exportAsCoreMLModel();
  }
  return swift_task_switch(v6, 0, 0);
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  uint64_t (*v6)();

  uint64_t v5 = *(void *)(*v2 + 120);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 128) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = specialized CoreMLExportable.exportAsCoreMLModel();
  }
  else
  {
    *(void *)(v4 + 136) = a1;
    uint64_t v6 = specialized CoreMLExportable.exportAsCoreMLModel();
  }
  return swift_task_switch(v6, 0, 0);
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  uint64_t (*v6)(void);

  uint64_t v5 = *(void *)(*v2 + 120);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 128) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = specialized CoreMLExportable.exportAsCoreMLModel();
  }
  else
  {
    *(void *)(v4 + 136) = a1;
    uint64_t v6 = specialized CoreMLExportable.exportAsCoreMLModel();
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t specialized CoreMLExportable.exportAsCoreMLModel()(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = NSFullUserName();
  uint64_t v4 = v3;
  uint64_t v5 = static String._unconditionallyBridgeFromObjectiveC(_:)(v4);
  uint64_t v7 = v6;

  *(void *)(v2 + 16) = v5;
  *(void *)(v2 + 24) = v7;
  *(void *)(v2 + 32) = 0xD000000000000033;
  *(void *)(v2 + 40) = "RandomForestRegressor" + 0x8000000000000000;
  *(_OWORD *)(v2 + 48) = 0;
  *(void *)(v2 + 64) = 49;
  *(void *)(v2 + 72) = 0xE100000000000000;
  *(void *)(v2 + 80) = 0;
  specialized CoreMLExportable.export(metadata:)(v2 + 16, a2);
  swift_bridgeObjectRelease(v7);
  swift_bridgeObjectRelease(("RandomForestRegressor" + 0x8000000000000000));
  swift_bridgeObjectRelease_n(0, 2, v8, v9, v10);
  swift_bridgeObjectRelease(0);
  type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for MLModel, MLModel_ptr);
  uint64_t v11 = (void *)swift_task_alloc(dword_3A701C);
  *(void *)(v2 + 120) = v11;
  *uint64_t v11 = v2;
  v11[1] = specialized CoreMLExportable.exportAsCoreMLModel();
  return static MLModel.compile(_:)(*(void *)(v2 + 112));
}

uint64_t specialized MLRegressorMetrics.init<A>(data:predictionColumnName:model:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  v5[12] = a5;
  v5[11] = a4;
  v5[10] = a3;
  v5[9] = a2;
  v5[8] = a1;
  uint64_t v6 = type metadata accessor for AnyColumn(0);
  v5[13] = v6;
  uint64_t v7 = *(void *)(v6 - 8);
  v5[14] = v7;
  v5[15] = swift_task_alloc((*(void *)(v7 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for DataFrame(0);
  v5[16] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v5[17] = v9;
  v5[18] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  MLLinearRegressor.Model.applied(to:eventHandler:)(a2, 0, 0);
  v5[19] = 0;
  return swift_task_switch(specialized MLRegressorMetrics.init<A>(data:predictionColumnName:model:), 0, 0);
}

uint64_t specialized MLRegressorMetrics.init<A>(data:predictionColumnName:model:)()
{
  uint64_t v1 = v0[15];
  uint64_t v2 = v0[14];
  uint64_t v3 = v0[13];
  DataFrame.subscript.getter(v0[10], v0[11]);
  uint64_t v4 = AnyColumn.convertedToDoubles()();
  uint64_t v5 = *(void (**)(uint64_t, uint64_t))(v2 + 8);
  v5(v1, v3);
  uint64_t v48 = v4;
  if (!v4)
  {
    uint64_t v62 = v0[17];
    uint64_t v49 = v0[16];
    uint64_t v16 = v0[15];
    uint64_t v46 = v0[13];
    uint64_t v54 = v0[12];
    uint64_t v17 = v0[11];
    uint64_t v51 = v0[9];
    uint64_t v57 = v5;
    uint64_t v18 = v0[10];
    *(void *)&long long v42 = 0;
    *((void *)&v42 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(52);
    v19._unsigned __int8 object = "Expected a linear classifier." + 0x8000000000000000;
    v19._uint64_t countAndFlagsBits = 0xD000000000000031;
    String.append(_:)(v19);
    DataFrame.subscript.getter(v18, v17);
    swift_bridgeObjectRelease(v17);
    uint64_t v20 = AnyColumn.wrappedElementType.getter();
    v57(v16, v46);
    uint64_t v21 = _typeName(_:qualified:)(v20, 0);
    LOBYTE(v18) = (_BYTE)v22;
    v19._uint64_t countAndFlagsBits = v21;
    v19._unsigned __int8 object = v22;
    String.append(_:)(v19);
    swift_bridgeObjectRelease(v18);
    v19._uint64_t countAndFlagsBits = 46;
    v19._unsigned __int8 object = (void *)0xE100000000000000;
    String.append(_:)(v19);
    v19._unsigned __int8 object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v19._object, 0, 0);
    *(_OWORD *)uint64_t v23 = v42;
    *(_OWORD *)(v23 + 16) = 0;
    *(_OWORD *)(v23 + 32) = 0;
    *(unsigned char *)(v23 + 48) = 1;
    swift_willThrow(&type metadata for MLCreateError, v19._object, v23, v24, v25, v26);
    outlined destroy of MLActivityClassifier.ModelParameters(v54, type metadata accessor for MLLinearRegressor.Model);
    uint64_t v27 = *(void (**)(uint64_t, uint64_t))(v62 + 8);
    v27(v51, v49);
LABEL_6:
    uint64_t v38 = v0[18];
    uint64_t v39 = v0[15];
    v27(v38, v0[16]);
    swift_task_dealloc(v38);
    swift_task_dealloc(v39);
    char v15 = (uint64_t (*)(void))v0[1];
    return v15();
  }
  uint64_t v6 = v0[15];
  uint64_t v7 = v0[13];
  DataFrame.subscript.getter(v0[10], v0[11]);
  uint64_t v8 = AnyColumn.convertedToDoubles()();
  v5(v6, v7);
  if (!v8)
  {
    uint64_t v55 = v0[17];
    uint64_t v52 = v0[16];
    uint64_t v28 = v0[15];
    uint64_t v58 = v0[13];
    uint64_t v47 = v0[12];
    uint64_t v29 = v0[11];
    uint64_t v63 = v0[9];
    uint64_t v60 = v0[10];
    swift_release();
    *(void *)&long long v43 = 0;
    *((void *)&v43 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(52);
    v30._unsigned __int8 object = "Expected a linear classifier." + 0x8000000000000000;
    v30._uint64_t countAndFlagsBits = 0xD000000000000031;
    String.append(_:)(v30);
    DataFrame.subscript.getter(v60, v29);
    swift_bridgeObjectRelease(v29);
    uint64_t v31 = AnyColumn.wrappedElementType.getter();
    v5(v28, v58);
    uint64_t v32 = _typeName(_:qualified:)(v31, 0);
    LOBYTE(v29) = (_BYTE)v33;
    v30._uint64_t countAndFlagsBits = v32;
    v30._unsigned __int8 object = v33;
    String.append(_:)(v30);
    swift_bridgeObjectRelease(v29);
    v30._uint64_t countAndFlagsBits = 46;
    v30._unsigned __int8 object = (void *)0xE100000000000000;
    String.append(_:)(v30);
    v30._unsigned __int8 object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v30._object, 0, 0);
    *(_OWORD *)uint64_t v34 = v43;
    *(_OWORD *)(v34 + 16) = 0;
    *(_OWORD *)(v34 + 32) = 0;
    *(unsigned char *)(v34 + 48) = 1;
    swift_willThrow(&type metadata for MLCreateError, v30._object, v34, v35, v36, v37);
    outlined destroy of MLActivityClassifier.ModelParameters(v47, type metadata accessor for MLLinearRegressor.Model);
    uint64_t v27 = *(void (**)(uint64_t, uint64_t))(v55 + 8);
    v27(v63, v52);
    goto LABEL_6;
  }
  uint64_t v53 = v0[18];
  uint64_t v56 = v0[17];
  uint64_t v45 = v0[16];
  uint64_t v61 = v0[15];
  uint64_t v41 = v0[12];
  uint64_t v50 = v0[8];
  uint64_t v59 = v0[9];
  swift_bridgeObjectRelease(v0[11]);
  v0[3] = v48;
  v0[4] = v8;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ContiguousArray<Double>);
  uint64_t v10 = lazy protocol witness table accessor for type Double and conformance Double();
  uint64_t v11 = v8;
  uint64_t v12 = lazy protocol witness table accessor for type ContiguousArray<Double> and conformance ContiguousArray<A>();
  maximumAbsoluteError<A, B, C>(_:_:)(v0 + 3, v0 + 4, &type metadata for Double, v9, v9, v10, v12, v12);
  uint64_t v44 = v0[2];
  v0[6] = v48;
  v0[7] = v11;
  rootMeanSquaredError<A, B, C>(_:_:)(v0 + 6, v0 + 7, &type metadata for Double, v9, v9, v10, v12, v12);
  outlined destroy of MLActivityClassifier.ModelParameters(v41, type metadata accessor for MLLinearRegressor.Model);
  char v13 = *(void (**)(uint64_t, uint64_t))(v56 + 8);
  v13(v59, v45);
  v13(v53, v45);
  swift_release();
  swift_release();
  uint64_t v14 = v0[5];
  *(void *)uint64_t v50 = v44;
  *(void *)(v50 + 8) = v14;
  *(unsigned char *)(v50 + 16) = 0;
  swift_task_dealloc(v53);
  swift_task_dealloc(v61);
  char v15 = (uint64_t (*)(void))v0[1];
  return v15();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v1 = *(void *)(v0 + 136);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 96), type metadata accessor for MLLinearRegressor.Model);
  uint64_t v2 = *(void *)(v0 + 144);
  uint64_t v3 = *(void *)(v0 + 120);
  (*(void (**)(void, void))(v1 + 8))(*(void *)(v0 + 72), *(void *)(v0 + 128));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLLinearRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(void (*a1)(uint64_t *, uint64_t, uint64_t), uint64_t a2, void *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v133 = a4;
  uint64_t v144 = a3;
  uint64_t v7 = v5;
  uint64_t v138 = a2;
  uint64_t v132 = v6;
  uint64_t v148 = a5;
  uint64_t v145 = a1;
  uint64_t v8 = type metadata accessor for MLLinearRegressor(0);
  uint64_t v123 = *(void *)(v8 - 8);
  int64_t v129 = *(void *)(v123 + 64);
  uint64_t v9 = alloca(v129);
  uint64_t v10 = alloca(v129);
  uint64_t v128 = &v107;
  uint64_t v147 = type metadata accessor for DataFrame(0);
  uint64_t v150 = *(void *)(v147 - 8);
  int64_t v11 = *(void *)(v150 + 64);
  uint64_t v12 = alloca(v11);
  char v13 = alloca(v11);
  uint64_t v131 = &v107;
  int64_t v130 = v11;
  uint64_t v14 = alloca(v11);
  char v15 = alloca(v11);
  uint64_t v136 = &v107;
  uint64_t v122 = *(void *)(type metadata accessor for MLLinearRegressor.Model(0) - 8);
  int64_t v16 = *(void *)(v122 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v120 = &v107;
  int64_t v121 = v16;
  Swift::String v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  unint64_t v146 = &v107;
  uint64_t v135 = (void (*)(uint64_t, long long *, uint64_t))type metadata accessor for BaseLinearRegressor(0);
  uint64_t v126 = *((void *)v135 - 1);
  int64_t v21 = *(void *)(v126 + 64);
  long long v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  uint64_t v139 = &v107;
  uint64_t v127 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearRegressor<Double>.Configuration);
  uint64_t v116 = *(void *)(v127 - 8);
  int64_t v24 = *(void *)(v116 + 64);
  uint64_t v25 = alloca(v24);
  uint64_t v26 = alloca(v24);
  uint64_t v117 = &v107;
  uint64_t v27 = alloca(v24);
  uint64_t v28 = alloca(v24);
  uint64_t v118 = &v107;
  uint64_t v119 = type metadata accessor for MLLinearRegressor.Regressor(0);
  int64_t v29 = *(void *)(*(void *)(v119 - 8) + 64);
  Swift::String v30 = alloca(v29);
  uint64_t v31 = alloca(v29);
  uint64_t v143 = &v107;
  uint64_t v141 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  int64_t v32 = *(void *)(*(void *)(v141 - 8) + 64);
  uint64_t v33 = alloca(v32);
  uint64_t v34 = alloca(v32);
  uint64_t v151 = &v107;
  uint64_t v137 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
  int64_t v35 = *(void *)(*(void *)(v137 - 8) + 64);
  uint64_t v36 = alloca(v35);
  uint64_t v37 = alloca(v35);
  uint64_t v124 = &v107;
  uint64_t v38 = alloca(v35);
  uint64_t v39 = alloca(v35);
  uint64_t v149 = &v107;
  uint64_t v40 = *(int *)(v8 + 36);
  *(unsigned char *)(v7 + v40 + 16) = 0;
  *(_OWORD *)(v7 + v40) = 0;
  uint64_t v125 = v8;
  uint64_t v41 = *(int *)(v8 + 40);
  uint64_t v42 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v43 = swift_allocError(&type metadata for MLCreateError, v42, 0, 0);
  *(void *)uint64_t v44 = 0xD0000000000000C0;
  *(void *)(v44 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v44 + 16) = 0;
  *(_OWORD *)(v44 + 32) = 0;
  *(unsigned char *)(v44 + 48) = 0;
  *(void *)(v7 + v41) = v43;
  *(void *)(v7 + v41 + 8) = 0;
  uint64_t v142 = v41;
  *(unsigned char *)(v7 + v41 + 16) = 1;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v148, (uint64_t)&v107, &demangling cache variable for type metadata for Any?);
  if (!v108) {
    BUG();
  }
  uint64_t v134 = v7;
  uint64_t v140 = v7 + v40;
  uint64_t v45 = (uint64_t)v149;
  uint64_t v46 = (char *)v149 + *(int *)(v137 + 48);
  outlined init with take of Any(&v107, &v114);
  uint64_t v47 = (uint64_t)v46;
  swift_dynamicCast(v151, &v114, (char *)&type metadata for Any + 8, v141, 7);
  uint64_t v48 = (uint64_t)v46;
  uint64_t v49 = v145;
  uint64_t v50 = v132;
  MLLinearRegressor.ModelParameters.ValidationData.generateDataFrames(trainingData:)(v45, v48, v145);
  if (v50)
  {
    swift_bridgeObjectRelease((_BYTE)v144);
    swift_bridgeObjectRelease(v133);
    outlined destroy of MLLinearRegressor.ModelParameters(v148);
    (*(void (**)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))(v150 + 8))(v49, v147);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v151, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
LABEL_6:
    uint64_t v66 = v142;
    uint64_t v67 = v134;
    uint64_t v68 = v140;
LABEL_7:
    outlined consume of Result<(Int, Int), Error>(*(void *)v68, *(void *)(v68 + 8), *(_DWORD *)(v68 + 16));
    return outlined consume of Result<(Int, Int), Error>(*(void *)(v67 + v66), *(void *)(v67 + v66 + 8), *(_DWORD *)(v67 + v66 + 16));
  }
  uint64_t v132 = v47;
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v151, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  char v51 = v133;
  uint64_t v52 = static _FeatureUtilities.selectFeaturesFromTrainingData(trainingData:targetColumn:featureColumns:)((uint64_t)v149, v138, v144, v133);
  swift_bridgeObjectRelease(v51);
  outlined init with copy of MLLinearRegressor.ModelParameters(v148, (uint64_t)&v114);
  uint64_t v53 = (uint64_t)v143;
  *(void *)uint64_t v143 = v138;
  char v54 = (char)v144;
  *(void *)(v53 + 8) = v144;
  *(void *)(v53 + 16) = v52;
  outlined init with copy of MLLinearRegressor.ModelParameters((uint64_t)&v114, v53 + 24);
  uint64_t v151 = 0;
  outlined init with copy of MLLinearRegressor.ModelParameters((uint64_t)&v114, (uint64_t)&v107);
  uint64_t v55 = lazy protocol witness table accessor for type Double and conformance Double();
  swift_bridgeObjectRetain(v54);
  uint64_t v141 = (uint64_t)v52;
  swift_bridgeObjectRetain((_BYTE)v52);
  uint64_t v56 = v118;
  LinearRegressor.Configuration.init()(&type metadata for Double, &protocol witness table for Double, v55);
  uint64_t v57 = v127;
  LinearRegressor.Configuration.maximumIterations.setter(v109, v127);
  LinearRegressor.Configuration.l1Penalty.setter(v57, v110);
  LinearRegressor.Configuration.l2Penalty.setter(v57, v111);
  LinearRegressor.Configuration.stepSize.setter(v57, v112);
  LinearRegressor.Configuration.convergenceThreshold.setter(v57, v113);
  outlined destroy of MLLinearRegressor.ModelParameters((uint64_t)&v107);
  uint64_t v58 = v117;
  uint64_t v59 = v116;
  (*(void (**)(long long *, long long *, uint64_t))(v116 + 16))(v117, v56, v57);
  uint64_t v60 = v58;
  uint64_t v61 = (uint64_t)v143;
  BaseLinearRegressor.init(configuration:)(v60);
  outlined destroy of MLLinearRegressor.ModelParameters((uint64_t)&v114);
  uint64_t v62 = v57;
  uint64_t v63 = (uint64_t)v149;
  (*(void (**)(long long *, uint64_t))(v59 + 8))(v56, v62);
  (*(void (**)(uint64_t, long long *, void *))(v126 + 32))(v61 + *(int *)(v119 + 28), v139, v135);
  uint64_t v64 = v63;
  uint64_t v65 = (uint64_t)v151;
  MLLinearRegressor.Regressor.fitted(to:validateOn:eventHandler:)(v63, v132, 0, 0);
  if (v65)
  {
    swift_bridgeObjectRelease((_BYTE)v144);
    swift_bridgeObjectRelease(v141);
    outlined destroy of MLLinearRegressor.ModelParameters(v148);
    (*(void (**)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))(v150 + 8))(v145, v147);
    outlined destroy of MLActivityClassifier.ModelParameters(v61, type metadata accessor for MLLinearRegressor.Regressor);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v63, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    goto LABEL_6;
  }
  uint64_t v70 = v141;
  uint64_t v151 = 0;
  BOOL v71 = AnalyticsReporter.init()();
  uint64_t v67 = v134;
  if (!v71)
  {
    Swift::Int v72 = DataFrame.shape.getter(v64);
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_linearRegressor, (Swift::String)__PAIR128__((unint64_t)("vectorized_features" + 0x8000000000000000), 0xD000000000000015), v72);
  }
  uint64_t v73 = v125;
  uint64_t v74 = *(int *)(v125 + 24);
  *(void *)(v67 + v74) = v138;
  uint64_t v133 = v74;
  *(void *)(v67 + v74 + 8) = v144;
  uint64_t v144 = (void *)(v67 + *(int *)(v73 + 32));
  outlined init with copy of MLLinearRegressor.ModelParameters(v148, (uint64_t)v144);
  uint64_t v138 = *(int *)(v73 + 28);
  *(void *)(v67 + v138) = v70;
  uint64_t v75 = (uint64_t)v120;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v146, (uint64_t)v120, type metadata accessor for MLLinearRegressor.Model);
  uint64_t v76 = *(unsigned __int8 *)(v122 + 80);
  uint64_t v77 = ~*(unsigned __int8 *)(v122 + 80) & (v76 + 16);
  uint64_t v78 = swift_allocObject(&unk_39CCE0, v77 + v121, v76 | 7);
  outlined init with take of MLClassifierMetrics(v75, v78 + v77, type metadata accessor for MLLinearRegressor.Model);
  uint64_t v79 = (uint64_t)v151;
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLLinearRegressor.init(trainingData:targetColumn:featureColumns:parameters:), v78);
  uint64_t v151 = (long long *)v79;
  if (v79)
  {
    swift_release();
    outlined destroy of MLLinearRegressor.ModelParameters(v148);
    (*(void (**)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))(v150 + 8))(v145, v147);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v146, type metadata accessor for MLLinearRegressor.Model);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v143, type metadata accessor for MLLinearRegressor.Regressor);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v149, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
LABEL_15:
    uint64_t v66 = v142;
    uint64_t v68 = v140;
    swift_bridgeObjectRelease(*(void *)(v67 + v133 + 8));
    swift_bridgeObjectRelease(*(void *)(v67 + v138));
    outlined destroy of MLLinearRegressor.ModelParameters((uint64_t)v144);
    goto LABEL_7;
  }
  uint64_t v81 = v80;
  swift_release();
  uint64_t v141 = *(int *)(v125 + 20);
  *(void *)(v67 + v141) = v81;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v146, v67, type metadata accessor for MLLinearRegressor.Model);
  uint64_t v82 = v150;
  uint64_t v139 = *(long long **)(v150 + 16);
  ((void (*)(long long *, long long *, uint64_t))v139)(v136, v149, v147);
  outlined init with copy of MLTrainingSessionParameters(v67, (uint64_t)v128, type metadata accessor for MLLinearRegressor);
  uint64_t v83 = *(unsigned __int8 *)(v82 + 80);
  uint64_t v84 = ~*(unsigned __int8 *)(v82 + 80) & (v83 + 16);
  uint64_t v85 = *(unsigned __int8 *)(v123 + 80);
  int64_t v86 = ~v85 & (v84 + v85 + v130);
  uint64_t v87 = v85 | v83 | 7;
  v129 += v86;
  uint64_t v88 = swift_allocObject(&unk_39CD08, v129, v87);
  uint64_t v126 = v84;
  uint64_t v89 = v88 + v84;
  uint64_t v90 = v88;
  uint64_t v135 = *(void (**)(uint64_t, long long *, uint64_t))(v150 + 32);
  v135(v89, v136, v147);
  outlined init with take of MLClassifierMetrics((uint64_t)v128, v90 + v86, type metadata accessor for MLLinearRegressor);
  uint64_t v91 = (uint64_t)v151;
  specialized blockAwait<A>(_:)((uint64_t)&closure #1 in MLLinearRegressor.computeMetrics(on:)partial apply, v90);
  uint64_t v151 = (long long *)v91;
  if (v91)
  {
    swift_release();
    outlined destroy of MLLinearRegressor.ModelParameters(v148);
    (*(void (**)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))(v150 + 8))(v145, v147);
LABEL_14:
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v146, type metadata accessor for MLLinearRegressor.Model);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v143, type metadata accessor for MLLinearRegressor.Regressor);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v149, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    outlined destroy of MLActivityClassifier.ModelParameters(v67, type metadata accessor for MLLinearRegressor.Model);

    goto LABEL_15;
  }
  uint64_t v127 = v87;
  int64_t v130 = v86;
  swift_release();
  char v92 = v115;
  uint64_t v93 = v140;
  outlined consume of Result<(Int, Int), Error>(*(void *)v140, *(void *)(v140 + 8), *(_DWORD *)(v140 + 16));
  *(_OWORD *)uint64_t v93 = v114;
  *(unsigned char *)(v93 + 16) = v92;
  uint64_t v94 = v124;
  uint64_t v95 = (uint64_t)v124 + *(int *)(v137 + 48);
  uint64_t v96 = v147;
  ((void (*)(long long *, long long *, uint64_t))v139)(v124, v149, v147);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v132, v95, &demangling cache variable for type metadata for DataFrame?);
  uint64_t v137 = v95;
  if (__swift_getEnumTagSinglePayload(v95, 1, v96) == 1)
  {
    outlined destroy of MLLinearRegressor.ModelParameters(v148);
    char v97 = *(void (**)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))(v150 + 8);
    v97(v145, v96);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v146, type metadata accessor for MLLinearRegressor.Model);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v143, type metadata accessor for MLLinearRegressor.Regressor);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v149, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v137, &demangling cache variable for type metadata for DataFrame?);
    return ((uint64_t (*)(long long *, uint64_t))v97)(v94, v96);
  }
  else
  {
    uint64_t v98 = v131;
    v135((uint64_t)v131, (long long *)v137, v96);
    uint64_t v150 = *(void *)(v150 + 8);
    ((void (*)(long long *, uint64_t))v150)(v94, v96);
    ((void (*)(long long *, long long *, uint64_t))v139)(v136, v98, v96);
    uint64_t v99 = (uint64_t)v128;
    outlined init with copy of MLTrainingSessionParameters(v67, (uint64_t)v128, type metadata accessor for MLLinearRegressor);
    uint64_t v100 = swift_allocObject(&unk_39CD30, v129, v127);
    v135(v100 + v126, v136, v96);
    outlined init with take of MLClassifierMetrics(v99, v100 + v130, type metadata accessor for MLLinearRegressor);
    uint64_t v101 = (uint64_t)v151;
    specialized blockAwait<A>(_:)((uint64_t)&closure #1 in MLLinearRegressor.computeMetrics(on:)partial apply, v100);
    uint64_t v151 = (long long *)v101;
    if (v101)
    {
      swift_release();
      outlined destroy of MLLinearRegressor.ModelParameters(v148);
      uint64_t v102 = v147;
      uint64_t v103 = (void (*)(long long *, uint64_t))v150;
      ((void (*)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))v150)(v145, v147);
      v103(v131, v102);
      goto LABEL_14;
    }
    swift_release();
    outlined destroy of MLLinearRegressor.ModelParameters(v148);
    uint64_t v104 = v147;
    uint64_t v105 = (void (*)(long long *, uint64_t))v150;
    ((void (*)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))v150)(v145, v147);
    v105(v131, v104);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v146, type metadata accessor for MLLinearRegressor.Model);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v143, type metadata accessor for MLLinearRegressor.Regressor);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v149, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    LOBYTE(v105) = v115;
    uint64_t v106 = v142;
    uint64_t result = outlined consume of Result<(Int, Int), Error>(*(void *)(v67 + v142), *(void *)(v67 + v142 + 8), *(_DWORD *)(v67 + v142 + 16));
    *(_OWORD *)(v67 + v106) = v114;
    *(unsigned char *)(v67 + v106 + 16) = (_BYTE)v105;
  }
  return result;
}

uint64_t MLLinearRegressor.trainingMetrics.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = *(int *)(type metadata accessor for MLLinearRegressor(0) + 36);
  uint64_t v4 = *(void *)(v1 + v3);
  uint64_t v5 = *(void *)(v1 + v3 + 8);
  char v6 = *(unsigned char *)(v1 + v3 + 16);
  *(void *)uint64_t v2 = v4;
  *(void *)(v2 + 8) = v5;
  *(unsigned char *)(v2 + 16) = v6;
  return outlined copy of Result<_RegressorMetrics, Error>(v4, v5, v6);
}

uint64_t protocol witness for TabularRegressionTask.validationMetrics.getter in conformance MLLinearRegressor()
{
  return MLLinearRegressor.validationMetrics.getter();
}

uint64_t MLLinearRegressor.validationMetrics.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = *(int *)(type metadata accessor for MLLinearRegressor(0) + 40);
  uint64_t v4 = *(void *)(v1 + v3);
  uint64_t v5 = *(void *)(v1 + v3 + 8);
  char v6 = *(unsigned char *)(v1 + v3 + 16);
  *(void *)uint64_t v2 = v4;
  *(void *)(v2 + 8) = v5;
  *(unsigned char *)(v2 + 16) = v6;
  return outlined copy of Result<_RegressorMetrics, Error>(v4, v5, v6);
}

uint64_t MLLinearRegressor.targetColumn.getter()
{
  uint64_t v1 = *(int *)(type metadata accessor for MLLinearRegressor(0) + 24);
  uint64_t v2 = *(void *)(v0 + v1);
  swift_bridgeObjectRetain(*(void *)(v0 + v1 + 8));
  return v2;
}

uint64_t MLLinearRegressor.featureColumns.getter()
{
  uint64_t v1 = type metadata accessor for MLLinearRegressor(0);
  return swift_bridgeObjectRetain(*(void *)(v0 + *(int *)(v1 + 28)));
}

void key path setter for MLLinearRegressor.model : MLLinearRegressor(id *a1)
{
  id v1 = *a1;
  MLLinearRegressor.model.setter((uint64_t)v1);
}

void MLLinearRegressor.model.setter(uint64_t a1)
{
  uint64_t v2 = *(int *)(type metadata accessor for MLLinearRegressor(0) + 20);

  *(void *)(v1 + v2) = a1;
}

void (*MLLinearRegressor.model.modify(uint64_t a1))(uint64_t a1, char a2)
{
  *(void *)(a1 + 8) = v1;
  uint64_t v3 = *(int *)(type metadata accessor for MLLinearRegressor(0) + 20);
  *(_DWORD *)(a1 + 16) = v3;
  uint64_t v4 = *(void **)(v1 + v3);
  *(void *)a1 = v4;
  v4;
  return MLActivityClassifier.model.modify;
}

uint64_t MLLinearRegressor.targetColumn.setter(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(int *)(type metadata accessor for MLLinearRegressor(0) + 24);
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v2 + v3 + 8));
  *(void *)(v2 + v3) = a1;
  *(void *)(v2 + v3 + 8) = a2;
  return result;
}

void (*MLLinearRegressor.targetColumn.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLLinearRegressor.featureColumns.setter(uint64_t a1)
{
  uint64_t v2 = *(int *)(type metadata accessor for MLLinearRegressor(0) + 28);
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v1 + v2));
  *(void *)(v1 + v2) = a1;
  return result;
}

void (*MLLinearRegressor.featureColumns.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLLinearRegressor.modelParameters.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLLinearRegressor(0);
  return outlined init with copy of MLLinearRegressor.ModelParameters(v1 + *(int *)(v3 + 32), v2);
}

uint64_t static MLLinearRegressor._defaultSessionParameters.getter()
{
  uint64_t v1 = v0;
  if (one-time initialization token for _defaultSessionParameters != -1) {
    swift_once(&one-time initialization token for _defaultSessionParameters, one-time initialization function for _defaultSessionParameters);
  }
  uint64_t v2 = type metadata accessor for MLTrainingSessionParameters(0);
  uint64_t v3 = __swift_project_value_buffer(v2, (uint64_t)static MLLinearRegressor._defaultSessionParameters);
  return outlined init with copy of MLTrainingSessionParameters(v3, v1, type metadata accessor for MLTrainingSessionParameters);
}

uint64_t MLLinearRegressor.init(_:targetColumn:featureColumns:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v6[7] = a6;
  void v6[6] = a5;
  v6[5] = a4;
  void v6[4] = a3;
  v6[3] = a2;
  void v6[2] = a1;
  return swift_task_switch(MLLinearRegressor.init(_:targetColumn:featureColumns:parameters:), 0, 0);
}

uint64_t MLLinearRegressor.init(_:targetColumn:featureColumns:parameters:)()
{
  uint64_t v15 = *(void *)(v0 + 48);
  long long v14 = *(_OWORD *)(v0 + 32);
  uint64_t v1 = *(void *)(v0 + 16);
  uint64_t v2 = *(void *)(v0 + 24);
  uint64_t v3 = (int *)type metadata accessor for MLLinearRegressor(0);
  *(void *)(v0 + 64) = v3;
  uint64_t v4 = v3[9];
  *(_DWORD *)(v0 + 96) = v4;
  *(unsigned char *)(v1 + v4 + 16) = 0;
  *(_OWORD *)(v1 + v4) = 0;
  uint64_t v5 = v3[10];
  *(_DWORD *)(v0 + 100) = v5;
  uint64_t v6 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v7 = swift_allocError(&type metadata for MLCreateError, v6, 0, 0);
  *(void *)uint64_t v8 = 0xD0000000000000C0;
  *(void *)(v8 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v8 + 16) = 0;
  *(_OWORD *)(v8 + 32) = 0;
  *(unsigned char *)(v8 + 48) = 0;
  *(void *)(v1 + v5) = v7;
  *(void *)(v1 + v5 + 8) = 0;
  *(unsigned char *)(v1 + v5 + 16) = 1;
  outlined init with copy of MLTrainingSessionParameters(v2, v1, type metadata accessor for MLLinearRegressor.Model);
  uint64_t v9 = v3[7];
  *(_DWORD *)(v0 + 104) = v9;
  *(void *)(v1 + v9) = v15;
  uint64_t v10 = v3[6];
  *(_DWORD *)(v0 + 108) = v10;
  *(_OWORD *)(v1 + v10) = v14;
  int64_t v11 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                          + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v12 = (void *)swift_task_alloc(dword_3AE244);
  *(void *)(v0 + 72) = v12;
  *uint64_t v12 = v0;
  v12[1] = MLLinearRegressor.init(_:targetColumn:featureColumns:parameters:);
  return v11();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  const void *v3;
  uint64_t v4;

  uint64_t v1 = *(void *)(v0 + 88);
  uint64_t v2 = *(void *)(v0 + 64);
  uint64_t v3 = *(const void **)(v0 + 56);
  uint64_t v4 = *(void *)(v0 + 16);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 24), type metadata accessor for MLLinearRegressor.Model);
  *(void *)(v4 + *(int *)(v2 + 20)) = v1;
  qmemcpy((void *)(v4 + *(int *)(v2 + 32)), v3, 0x49uLL);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;

  uint64_t v7 = *(int *)(v0 + 108);
  uint64_t v6 = *(int *)(v0 + 104);
  uint64_t v1 = *(int *)(v0 + 100);
  uint64_t v2 = *(int *)(v0 + 96);
  uint64_t v3 = *(void *)(v0 + 16);
  uint64_t v4 = *(void *)(v0 + 24);
  outlined destroy of MLLinearRegressor.ModelParameters(*(void *)(v0 + 56));
  outlined destroy of MLActivityClassifier.ModelParameters(v4, type metadata accessor for MLLinearRegressor.Model);
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLLinearRegressor.Model);
  swift_bridgeObjectRelease(*(void *)(v3 + v7 + 8));
  swift_bridgeObjectRelease(*(void *)(v3 + v6));
  outlined consume of Result<(Int, Int), Error>(*(void *)(v3 + v2), *(void *)(v3 + v2 + 8), *(_DWORD *)(v3 + v2 + 16));
  outlined consume of Result<(Int, Int), Error>(*(void *)(v3 + v1), *(void *)(v3 + v1 + 8), *(_DWORD *)(v3 + v1 + 16));
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLLinearRegressor.init(_:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  uint64_t v5 = *(void *)(*v2 + 72);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 80) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = MLLinearRegressor.init(_:targetColumn:featureColumns:parameters:);
  }
  else
  {
    *(void *)(v4 + 88) = a1;
    uint64_t v6 = MLLinearRegressor.init(_:targetColumn:featureColumns:parameters:);
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t closure #1 in MLLinearRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
  uint64_t v2 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                         + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v3 = (void *)swift_task_alloc(dword_3AE244);
  *(void *)(v1 + 24) = v3;
  void *v3 = v1;
  v3[1] = closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:);
  return v2();
}

uint64_t closure #1 in MLLinearRegressor.computeMetrics(on:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  void v3[4] = a3;
  v3[3] = a2;
  v3[2] = a1;
  uint64_t v4 = type metadata accessor for MLLinearRegressor.Model(0);
  void v3[5] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for DataFrame(0);
  v3[6] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v3[7] = v6;
  void v3[8] = swift_task_alloc((*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(closure #1 in MLLinearRegressor.computeMetrics(on:), 0, 0);
}

uint64_t closure #1 in MLLinearRegressor.computeMetrics(on:)()
{
  uint64_t v1 = v0[5];
  uint64_t v2 = v0[4];
  (*(void (**)(void, void, void))(v0[7] + 16))(v0[8], v0[3], v0[6]);
  uint64_t v3 = *(int *)(type metadata accessor for MLLinearRegressor(0) + 24);
  uint64_t v4 = *(void *)(v2 + v3);
  uint64_t v5 = *(void *)(v2 + v3 + 8);
  outlined init with copy of MLTrainingSessionParameters(v2, v1, type metadata accessor for MLLinearRegressor.Model);
  uint64_t v6 = (char *)&async function pointer to specialized MLRegressorMetrics.init<A>(data:predictionColumnName:model:)
     + async function pointer to specialized MLRegressorMetrics.init<A>(data:predictionColumnName:model:);
  uint64_t v7 = dword_3AE26C;
  swift_bridgeObjectRetain(v5);
  uint64_t v8 = (void *)swift_task_alloc(v7);
  v0[9] = v8;
  void *v8 = v0;
  v8[1] = closure #1 in MLLinearRegressor.computeMetrics(on:);
  return ((uint64_t (*)(void, void, uint64_t, uint64_t, void))v6)(v0[2], v0[8], v4, v5, v0[5]);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v5;

  uint64_t v2 = *(void *)(*v1 + 72);
  uint64_t v3 = *v1;
  *(void *)(v3 + 80) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    return swift_task_switch(closure #1 in MLLinearRegressor.computeMetrics(on:), 0, 0);
  }
  uint64_t v5 = *(void *)(v3 + 40);
  swift_task_dealloc(*(void *)(v3 + 64));
  swift_task_dealloc(v5);
  return (*(uint64_t (**)(void))(v3 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;

  uint64_t v1 = *(void *)(v0 + 40);
  swift_task_dealloc(*(void *)(v0 + 64));
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLLinearRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t *a1, uint64_t a2, void *a3, uint64_t a4, uint64_t a5)
{
  uint64_t v13 = a4;
  long long v14 = a3;
  uint64_t v15 = a2;
  int64_t v6 = *(void *)(*(void *)(type metadata accessor for DataFrame(0) - 8) + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  char v9 = *((unsigned char *)a1 + 8);
  uint64_t v11 = *a1;
  char v12 = v9;
  DataFrame.init(_:)((uint64_t)&v11);
  outlined init with copy of MLLinearRegressor.ModelParameters(a5, (uint64_t)&v11);
  MLLinearRegressor.init(trainingData:targetColumn:featureColumns:parameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v11, v15, v14, v13, (uint64_t)&v11);
  return outlined destroy of MLLinearRegressor.ModelParameters(a5);
}

uint64_t MLLinearRegressor.init(checkpoint:)(uint64_t a1)
{
  uint64_t v82 = v2;
  uint64_t v101 = a1;
  uint64_t v3 = v1;
  uint64_t v92 = *(void *)(type metadata accessor for MLLinearRegressor.Model(0) - 8);
  int64_t v4 = *(void *)(v92 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v90 = v75;
  int64_t v91 = v4;
  uint64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  uint64_t v99 = v75;
  uint64_t v83 = type metadata accessor for BaseLinearRegressor(0);
  uint64_t v84 = *(void *)(v83 - 8);
  int64_t v9 = *(void *)(v84 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v103 = v75;
  uint64_t v85 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearRegressor<Double>.Configuration);
  uint64_t v86 = *(void *)(v85 - 8);
  int64_t v12 = *(void *)(v86 + 64);
  uint64_t v13 = alloca(v12);
  long long v14 = alloca(v12);
  uint64_t v87 = v75;
  uint64_t v15 = alloca(v12);
  int64_t v16 = alloca(v12);
  uint64_t v88 = v75;
  uint64_t v97 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  int64_t v17 = *(void *)(*(void *)(v97 - 8) + 64);
  uint64_t v18 = alloca(v17);
  Swift::String v19 = alloca(v17);
  uint64_t v95 = v75;
  uint64_t v20 = alloca(v17);
  int64_t v21 = alloca(v17);
  uint64_t v94 = v75;
  uint64_t v89 = type metadata accessor for MLLinearRegressor.Regressor(0);
  int64_t v22 = *(void *)(*(void *)(v89 - 8) + 64);
  uint64_t v23 = alloca(v22);
  int64_t v24 = alloca(v22);
  uint64_t v98 = v75;
  uint64_t v25 = type metadata accessor for MLLinearRegressor(0);
  uint64_t v26 = *(int *)(v25 + 36);
  *(unsigned char *)(v3 + v26 + 16) = 0;
  *(_OWORD *)(v3 + v26) = 0;
  uint64_t v96 = v25;
  uint64_t v27 = *(int *)(v25 + 40);
  uint64_t v100 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v28 = swift_allocError(&type metadata for MLCreateError, v100, 0, 0);
  *(void *)uint64_t v29 = 0xD0000000000000C0;
  *(void *)(v29 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v29 + 16) = 0;
  *(_OWORD *)(v29 + 32) = 0;
  *(unsigned char *)(v29 + 48) = 0;
  *(void *)(v3 + v27) = v28;
  *(void *)(v3 + v27 + 8) = 0;
  uint64_t v102 = v27;
  *(unsigned char *)(v3 + v27 + 16) = 1;
  uint64_t v30 = *(unsigned __int8 *)(v101 + *(int *)(type metadata accessor for MLCheckpoint(0) + 20));
  uint64_t v93 = v3;
  switch(v30)
  {
    case 0:
      uint64_t v31 = 0x696C616974696E69;
      unint64_t v32 = 0xEB0000000064657ALL;
      break;
    case 1:
      uint64_t v31 = 0x6974636172747865;
      goto LABEL_6;
    case 2:
      swift_bridgeObjectRelease(0);
      goto LABEL_9;
    case 3:
      uint64_t v31 = 0x697461756C617665;
LABEL_6:
      unint64_t v32 = 0xEA0000000000676ELL;
      break;
    case 4:
      unint64_t v32 = 0xEB00000000676E69;
      uint64_t v31 = 0x636E657265666E69;
      break;
  }
  char v33 = v32;
  char v34 = _stringCompareWithSmolCheck(_:_:expecting:)(v31, v32, 0x676E696E69617274, 0xE800000000000000, 0);
  swift_bridgeObjectRelease(v33);
  if ((v34 & 1) == 0)
  {
    uint64_t v52 = v100;
    swift_allocError(&type metadata for MLCreateError, v100, 0, 0);
    *(void *)uint64_t v53 = 0xD00000000000003BLL;
    *(void *)(v53 + 8) = "LinearRegressor\n\nParameters\n" + 0x8000000000000000;
    *(_OWORD *)(v53 + 16) = 0;
    *(_OWORD *)(v53 + 32) = 0;
    *(unsigned char *)(v53 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v52, v53, v54, v55, v56);
    outlined destroy of MLActivityClassifier.ModelParameters(v101, type metadata accessor for MLCheckpoint);
    uint64_t v51 = v102;
    goto LABEL_14;
  }
LABEL_9:
  uint64_t v100 = v26;
  uint64_t v35 = (uint64_t)v94;
  *(_OWORD *)uint64_t v94 = 0;
  *(_WORD *)(v35 + 16) = 256;
  uint64_t v36 = v97;
  swift_storeEnumTagMultiPayload(v35, v97, 0);
  long long v77 = 0;
  long long v76 = 0;
  uint64_t v78 = 10;
  __m128 v79 = _mm_loadh_ps((const double *)&qword_349108);
  long long v80 = xmmword_349110;
  char v81 = 1;
  uint64_t v37 = (uint64_t)v95;
  outlined init with copy of MLTrainingSessionParameters(v35, (uint64_t)v95, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  *(void *)&v75[3] = v36;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v75);
  outlined init with take of MLClassifierMetrics(v37, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  outlined assign with take of Any?((uint64_t)v75, (uint64_t)&v76);
  outlined destroy of MLActivityClassifier.ModelParameters(v35, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  uint64_t v39 = (uint64_t)v98;
  *uint64_t v98 = 0.0;
  *(void *)(v39 + 8) = 0xE000000000000000;
  *(void *)(v39 + 16) = _swiftEmptyArrayStorage;
  outlined init with copy of MLLinearRegressor.ModelParameters((uint64_t)&v76, v39 + 24);
  outlined init with copy of MLLinearRegressor.ModelParameters((uint64_t)&v76, (uint64_t)v75);
  uint64_t v40 = lazy protocol witness table accessor for type Double and conformance Double();
  uint64_t v41 = v88;
  LinearRegressor.Configuration.init()(&type metadata for Double, &protocol witness table for Double, v40);
  uint64_t v42 = v85;
  LinearRegressor.Configuration.maximumIterations.setter(*(void *)&v75[4], v85);
  LinearRegressor.Configuration.l1Penalty.setter(v42, v75[5]);
  LinearRegressor.Configuration.l2Penalty.setter(v42, v75[6]);
  LinearRegressor.Configuration.stepSize.setter(v42, v75[7]);
  LinearRegressor.Configuration.convergenceThreshold.setter(v42, v75[8]);
  outlined destroy of MLLinearRegressor.ModelParameters((uint64_t)v75);
  uint64_t v43 = v87;
  uint64_t v44 = v86;
  (*(void (**)(double *, double *, uint64_t))(v86 + 16))(v87, v41, v42);
  BaseLinearRegressor.init(configuration:)(v43);
  outlined destroy of MLLinearRegressor.ModelParameters((uint64_t)&v76);
  (*(void (**)(double *, uint64_t))(v44 + 8))(v41, v42);
  uint64_t v45 = v89;
  uint64_t v46 = (uint64_t)v98;
  (*(void (**)(uint64_t, double *, uint64_t))(v84 + 32))((uint64_t)v98 + *(int *)(v89 + 28), v103, v83);
  uint64_t v47 = lazy protocol witness table accessor for type MLLinearRegressor.Regressor and conformance MLLinearRegressor.Regressor();
  uint64_t v48 = (uint64_t)v99;
  uint64_t v49 = v101;
  uint64_t v50 = v82;
  UpdatableSupervisedTabularEstimator.readWithOptimizer(from:)(v101, v45, v47);
  uint64_t v103 = v50;
  if (v50)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(v49, type metadata accessor for MLCheckpoint);
    outlined destroy of MLActivityClassifier.ModelParameters(v46, type metadata accessor for MLLinearRegressor.Regressor);
    uint64_t v51 = v102;
    uint64_t v26 = v100;
LABEL_14:
    uint64_t v64 = v93;
    outlined consume of Result<(Int, Int), Error>(*(void *)(v93 + v26), *(void *)(v93 + v26 + 8), *(_DWORD *)(v93 + v26 + 16));
    return outlined consume of Result<(Int, Int), Error>(*(void *)(v64 + v51), *(void *)(v64 + v51 + 8), *(_DWORD *)(v64 + v51 + 16));
  }
  uint64_t v57 = (uint64_t)v90;
  outlined init with copy of MLTrainingSessionParameters(v48, (uint64_t)v90, type metadata accessor for MLLinearRegressor.Model);
  uint64_t v58 = *(unsigned __int8 *)(v92 + 80);
  uint64_t v59 = ~*(unsigned __int8 *)(v92 + 80) & (v58 + 16);
  uint64_t v60 = swift_allocObject(&unk_39CD58, v59 + v91, v58 | 7);
  outlined init with take of MLClassifierMetrics(v57, v60 + v59, type metadata accessor for MLLinearRegressor.Model);
  uint64_t v61 = v103;
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLLinearRegressor.init(checkpoint:), v60);
  uint64_t v63 = v62;
  swift_release();
  if (v61)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(v101, type metadata accessor for MLCheckpoint);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v99, type metadata accessor for MLLinearRegressor.Model);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v98, type metadata accessor for MLLinearRegressor.Regressor);
    uint64_t v51 = v102;
    uint64_t v26 = v100;
    goto LABEL_14;
  }
  uint64_t v66 = v96;
  uint64_t v67 = v93;
  *(void *)(v93 + *(int *)(v96 + 20)) = v63;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v99, v67, type metadata accessor for MLLinearRegressor.Model);
  uint64_t v68 = (uint64_t)v94;
  *(_OWORD *)uint64_t v94 = 0;
  *(_WORD *)(v68 + 16) = 256;
  swift_storeEnumTagMultiPayload(v68, v97, 0);
  uint64_t v69 = *(int *)(v66 + 32);
  uint64_t v102 = v69 + v67;
  *(_OWORD *)(v67 + v69 + 16) = 0;
  *(_OWORD *)(v67 + v69) = 0;
  __m128 v70 = _mm_loadh_ps((const double *)&qword_349108);
  *(void *)(v67 + v69 + 32) = 10;
  *(__m128 *)(v67 + v69 + 40) = v70;
  *(_OWORD *)(v67 + v69 + 56) = xmmword_349110;
  *(unsigned char *)(v67 + v69 + 72) = 1;
  uint64_t v103 = 0;
  uint64_t v71 = (uint64_t)v95;
  outlined init with copy of MLTrainingSessionParameters(v68, (uint64_t)v95, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  *((void *)&v77 + 1) = v97;
  Swift::Int v72 = __swift_allocate_boxed_opaque_existential_1(&v76);
  outlined init with take of MLClassifierMetrics(v71, (uint64_t)v72, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  outlined assign with take of Any?((uint64_t)&v76, v102);
  outlined destroy of MLActivityClassifier.ModelParameters(v68, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  uint64_t v73 = v96;
  uint64_t v74 = *(int *)(v96 + 24);
  *(void *)(v67 + v74) = 0;
  *(void *)(v67 + v74 + 8) = 0xE000000000000000;
  outlined destroy of MLActivityClassifier.ModelParameters(v101, type metadata accessor for MLCheckpoint);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v99, type metadata accessor for MLLinearRegressor.Model);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v98, type metadata accessor for MLLinearRegressor.Regressor);
  uint64_t result = *(int *)(v73 + 28);
  *(void *)(v67 + result) = _swiftEmptyArrayStorage;
  return result;
}

uint64_t closure #1 in MLLinearRegressor.init(checkpoint:)(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
  uint64_t v2 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                         + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v3 = (void *)swift_task_alloc(dword_3AE244);
  *(void *)(v1 + 24) = v3;
  void *v3 = v1;
  v3[1] = closure #1 in MLRandomForestRegressor.init(checkpoint:);
  return v2();
}

void *static MLLinearRegressor.train(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, void *a3, char *a4, uint64_t a5, uint64_t a6)
{
  uint64_t v21 = a6;
  uint64_t v22 = a5;
  uint64_t v23 = a4;
  int64_t v24 = a3;
  uint64_t v25 = a2;
  uint64_t v7 = type metadata accessor for DataFrame(0);
  uint64_t v8 = *(void *)(v7 - 8);
  int64_t v9 = *(void *)(v8 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  char v12 = *(unsigned char *)(a1 + 8);
  uint64_t v19 = *(void *)a1;
  char v20 = v12;
  outlined copy of Result<_DataTable, Error>(v19, v12);
  DataFrame.init(_:)((uint64_t)&v19);
  uint64_t v13 = static MLLinearRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v19, v25, v24, v23, v22, v21);
  uint64_t v14 = v7;
  if (v6) {
    return (void *)(*(uint64_t (**)(uint64_t *, uint64_t))(v8 + 8))(&v19, v7);
  }
  uint64_t v16 = v13;
  (*(void (**)(uint64_t *, uint64_t))(v8 + 8))(&v19, v14);
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLLinearRegressor>);
  uint64_t v18 = (void *)swift_allocObject(v17, *(unsigned int *)(v17 + 48), *(unsigned __int16 *)(v17 + 52));
  return specialized MLJob.init(_:)(v18, v16);
}

uint64_t static MLLinearRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, void *a3, char *a4, uint64_t a5, uint64_t a6)
{
  uint64_t v16 = a6;
  uint64_t v17 = a5;
  uint64_t v18 = a4;
  uint64_t v19 = a3;
  uint64_t v7 = type metadata accessor for DataFrame(0);
  uint64_t v20 = *(void *)(v7 - 8);
  int64_t v8 = *(void *)(v20 + 64);
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  char v11 = *(unsigned char *)(a1 + 8);
  uint64_t v14 = *(void *)a1;
  char v15 = v11;
  outlined copy of Result<_DataTable, Error>(v14, v11);
  DataFrame.init(_:)((uint64_t)&v14);
  uint64_t v12 = static MLLinearRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v14, a2, v19, v18, v17, v16);
  (*(void (**)(uint64_t *, uint64_t))(v20 + 8))(&v14, v7);
  return v12;
}

void *static MLLinearRegressor.resume(_:)(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLLinearRegressor>);
  uint64_t v2 = (void *)swift_allocObject(v1, *(unsigned int *)(v1 + 48), *(unsigned __int16 *)(v1 + 52));
  swift_retain();
  return specialized MLJob.init(_:)(v2, a1);
}

void *static MLLinearRegressor.train(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(void (*a1)(uint64_t *, uint64_t, uint64_t), uint64_t a2, void *a3, char *a4, uint64_t a5, uint64_t a6)
{
  uint64_t result = (void *)static MLLinearRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(a1, a2, a3, a4, a5, a6);
  if (!v6)
  {
    uint64_t v8 = (uint64_t)result;
    uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLLinearRegressor>);
    uint64_t v10 = (void *)swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
    return specialized MLJob.init(_:)(v10, v8);
  }
  return result;
}

uint64_t static MLLinearRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(void (*a1)(uint64_t *, uint64_t, uint64_t), uint64_t a2, void *a3, char *a4, uint64_t a5, uint64_t a6)
{
  uint64_t v60 = v6;
  uint64_t v52 = a6;
  uint64_t v46 = a4;
  uint64_t v47 = a3;
  uint64_t v48 = a2;
  uint64_t v56 = a1;
  int64_t v8 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v50 = &v40;
  char v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v51 = &v40;
  uint64_t v57 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  int64_t v13 = *(void *)(*(void *)(v57 - 8) + 64);
  uint64_t v14 = alloca(v13);
  char v15 = alloca(v13);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
  int64_t v17 = *(void *)(*(void *)(v16 - 8) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v55 = &v40;
  uint64_t v20 = alloca(v17);
  uint64_t v21 = alloca(v17);
  uint64_t v54 = &v40;
  uint64_t v22 = alloca(v17);
  uint64_t v23 = alloca(v17);
  uint64_t v59 = &v40;
  uint64_t v49 = a5;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a5, (uint64_t)&v44, &demangling cache variable for type metadata for Any?);
  if (!v45) {
    BUG();
  }
  uint64_t v58 = v16;
  uint64_t v24 = (uint64_t)v59;
  uint64_t v25 = (uint64_t)v59 + *(int *)(v16 + 48);
  outlined init with take of Any(&v44, &v41);
  swift_dynamicCast(&v40, &v41, (char *)&type metadata for Any + 8, v57, 7);
  uint64_t v26 = v60;
  MLLinearRegressor.ModelParameters.ValidationData.generateDataFrames(trainingData:)(v24, v25, v56);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v40, type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData);
  uint64_t v60 = v26;
  if (!v26)
  {
    uint64_t v27 = (void (*)(uint64_t *, uint64_t, uint64_t))((char *)v54 + *(int *)(v58 + 48));
    uint64_t v28 = type metadata accessor for DataFrame(0);
    uint64_t v53 = *(void *)(v28 - 8);
    uint64_t v29 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v53 + 16);
    v29(v54, v59, v28);
    uint64_t v56 = v27;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v25, (uint64_t)v27, &demangling cache variable for type metadata for DataFrame?);
    uint64_t v30 = (uint64_t)v55 + *(int *)(v58 + 48);
    uint64_t v57 = v28;
    v29(v55, v59, v28);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v25, v30, &demangling cache variable for type metadata for DataFrame?);
    outlined init with copy of MLLinearRegressor.ModelParameters(v49, (uint64_t)&v41);
    outlined init with copy of MLTrainingSessionParameters(v52, (uint64_t)v51, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v25 = type metadata accessor for LinearRegressorTrainingSessionDelegate(0);
    uint64_t v58 = swift_allocObject(v25, *(unsigned int *)(v25 + 48), *(unsigned __int16 *)(v25 + 52));
    uint64_t v31 = v46;
    swift_bridgeObjectRetain((_BYTE)v46);
    unint64_t v32 = v47;
    swift_bridgeObjectRetain((_BYTE)v47);
    uint64_t v33 = v60;
    char v34 = LinearRegressorTrainingSessionDelegate.init(trainingData:validationData:targetColumn:featureColumns:parameters:sessionParameters:)((uint64_t)v54, v30, v48, v32, v31, (uint64_t)&v41, (uint64_t)v51);
    uint64_t v60 = v33;
    if (v33)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v59, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      (*(void (**)(uint64_t *, uint64_t))(v53 + 8))(v55, v57);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v56, &demangling cache variable for type metadata for DataFrame?);
    }
    else
    {
      uint64_t v35 = v34;
      (*(void (**)(uint64_t *, uint64_t))(v53 + 8))(v55, v57);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v56, &demangling cache variable for type metadata for DataFrame?);
      uint64_t v42 = v25;
      uint64_t v43 = &protocol witness table for LinearRegressorTrainingSessionDelegate;
      *(void *)&long long v41 = v35;
      uint64_t v36 = (uint64_t)v50;
      outlined init with copy of MLTrainingSessionParameters(v52, (uint64_t)v50, type metadata accessor for MLTrainingSessionParameters);
      uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>);
      swift_allocObject(v37, *(unsigned int *)(v37 + 48), *(unsigned __int16 *)(v37 + 52));
      swift_retain();
      uint64_t v38 = v60;
      uint64_t v25 = specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)&v41, v36, 6);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v59, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      swift_release();
      uint64_t v60 = v38;
    }
  }
  return v25;
}

uint64_t static MLLinearRegressor.restoreTrainingSession(sessionParameters:)(uint64_t a1)
{
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  uint64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  uint64_t v12 = v11;
  uint64_t v5 = alloca(v2);
  uint64_t v6 = alloca(v2);
  outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v11, type metadata accessor for MLTrainingSessionParameters);
  uint64_t v7 = type metadata accessor for LinearRegressorTrainingSessionDelegate(0);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  uint64_t result = LinearRegressorTrainingSessionDelegate.init(sessionParameters:)((uint64_t)v11);
  if (!v1)
  {
    v11[3] = v7;
    _OWORD v11[4] = &protocol witness table for LinearRegressorTrainingSessionDelegate;
    v11[0] = result;
    uint64_t v9 = (uint64_t)v12;
    outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v12, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLinearRegressor>);
    swift_allocObject(v10, *(unsigned int *)(v10 + 48), *(unsigned __int16 *)(v10 + 52));
    return specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)v11, v9, 6);
  }
  return result;
}

uint64_t closure #1 in closure #1 in static MLLinearRegressor.resume(_:)(uint64_t a1, char a2, uint64_t a3, void (*a4)(uint64_t *), uint64_t a5)
{
  uint64_t v22 = a5;
  uint64_t v23 = a4;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLLinearRegressor, Error>);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TaskPriority?)
                              - 8)
                  + 64);
  char v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  if (a2)
  {
    uint64_t v19 = a1;
    swift_storeEnumTagMultiPayload(&v19, v6, 1);
    swift_errorRetain(a1);
    v23(&v19);
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v19, &demangling cache variable for type metadata for Result<MLLinearRegressor, Error>);
  }
  else
  {
    outlined init with copy of TabularRegressionTask(direct field offset for MLTrainingSession.delegate + a3, (uint64_t)v20);
    uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingSessionDelegate);
    uint64_t v14 = type metadata accessor for LinearRegressorTrainingSessionDelegate(0);
    swift_dynamicCast(&v21, v20, v13, v14, 7);
    uint64_t v15 = v21;
    uint64_t v16 = type metadata accessor for TaskPriority(0);
    __swift_storeEnumTagSinglePayload((uint64_t)&v19, 1, 1, v16);
    uint64_t v17 = swift_allocObject(&unk_39CD90, 56, 7);
    *(_OWORD *)(v17 + 16) = 0;
    *(void *)(v17 + 32) = v15;
    *(void *)(v17 + 40) = v23;
    *(void *)(v17 + 48) = v22;
    swift_retain();
    _sScTss5NeverORs_rlE8priority9operationScTyxABGScPSg_xyYaYAcntcfCyt_Tgm5((uint64_t)&v19, (uint64_t)&async function pointer to partial apply for closure #1 in static MLLinearRegressor.handleResult(_:session:fulfill:), v17);
    return swift_release();
  }
}

uint64_t closure #1 in static MLLinearRegressor.handleResult(_:session:fulfill:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  void v6[4] = a6;
  v6[3] = a5;
  void v6[2] = a4;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLLinearRegressor, Error>);
  v6[5] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(closure #1 in static MLLinearRegressor.handleResult(_:session:fulfill:), 0, 0);
}

uint64_t closure #1 in static MLLinearRegressor.handleResult(_:session:fulfill:)()
{
  uint64_t v1 = (char *)&async function pointer to specialized Result<>.init(catching:)
     + async function pointer to specialized Result<>.init(catching:);
  uint64_t v2 = dword_3AE63C;
  swift_retain();
  uint64_t v3 = (void *)swift_task_alloc(v2);
  v0[6] = v3;
  void *v3 = v0;
  v3[1] = closure #1 in static MLLinearRegressor.handleResult(_:session:fulfill:);
  return ((uint64_t (*)(void, void))v1)(v0[5], v0[2]);
}

{
  uint64_t v0;

  swift_task_dealloc(*(void *)(*(void *)v0 + 48));
  return swift_task_switch(closure #1 in static MLLinearRegressor.handleResult(_:session:fulfill:), 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;

  uint64_t v1 = *(void *)(v0 + 40);
  (*(void (**)(uint64_t))(v0 + 24))(v1);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, &demangling cache variable for type metadata for Result<MLLinearRegressor, Error>);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLLinearRegressor.init(delegate:)(uint64_t a1, uint64_t a2)
{
  v2[29] = a2;
  v2[28] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLLinearRegressor.Model?);
  v2[30] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLLinearRegressor(0);
  v2[31] = v4;
  v2[32] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLLinearRegressor.PersistentParameters?);
  v2[33] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = type metadata accessor for MLLinearRegressor.PersistentParameters(0);
  v2[34] = v6;
  v2[35] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLLinearRegressor.init(delegate:), 0, 0);
}

uint64_t MLLinearRegressor.init(delegate:)()
{
  uint64_t v1 = v0[34];
  uint64_t v2 = v0[33];
  uint64_t v3 = OBJC_IVAR____TtC8CreateML38LinearRegressorTrainingSessionDelegate_trainingParameters + v0[29];
  swift_beginAccess(v3, v0 + 22, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v3, v2, &demangling cache variable for type metadata for MLLinearRegressor.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1) {
    BUG();
  }
  uint64_t v4 = v0[35];
  uint64_t v5 = (int *)v0[34];
  uint64_t v6 = v0[29];
  uint64_t v14 = v0[30];
  outlined init with take of MLClassifierMetrics(v0[33], v4, type metadata accessor for MLLinearRegressor.PersistentParameters);
  outlined init with copy of MLLinearRegressor.ModelParameters(v4 + v5[8], (uint64_t)(v0 + 2));
  uint64_t v7 = v5[6];
  uint64_t v15 = *(void *)(v4 + v7);
  uint64_t v16 = *(void *)(v4 + v7 + 8);
  uint64_t v8 = *(void *)(v4 + v5[7]);
  uint64_t v9 = OBJC_IVAR____TtC8CreateML38LinearRegressorTrainingSessionDelegate_model + v6;
  swift_beginAccess(v9, v0 + 25, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v9, v14, &demangling cache variable for type metadata for MLLinearRegressor.Model?);
  uint64_t v10 = type metadata accessor for MLLinearRegressor.Model(0);
  if (__swift_getEnumTagSinglePayload(v14, 1, v10) == 1) {
    BUG();
  }
  outlined init with copy of MLLinearRegressor.ModelParameters((uint64_t)(v0 + 2), (uint64_t)(v0 + 12));
  uint64_t v11 = dword_3AE23C;
  swift_bridgeObjectRetain(v16);
  swift_bridgeObjectRetain(v8);
  uint64_t v12 = (void *)swift_task_alloc(v11);
  v0[36] = v12;
  *uint64_t v12 = v0;
  v12[1] = MLLinearRegressor.init(delegate:);
  return MLLinearRegressor.init(_:targetColumn:featureColumns:parameters:)(v0[32], v0[30], v15, v16, v8, (uint64_t)(v0 + 12));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 288);
  *(void *)(*(void *)v1 + 296) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLLinearRegressor.init(delegate:);
  }
  else {
    uint64_t v3 = MLLinearRegressor.init(delegate:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  char v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 232);
  outlined init with take of MLClassifierMetrics(*(void *)(v0 + 256), *(void *)(v0 + 224), type metadata accessor for MLLinearRegressor);
  uint64_t v2 = *(unsigned char *)(v1 + OBJC_IVAR____TtC8CreateML38LinearRegressorTrainingSessionDelegate_trainingMetrics + 16);
  if (v2 == -1) {
    BUG();
  }
  uint64_t v16 = *(void *)(v0 + 280);
  uint64_t v15 = *(void *)(v0 + 248);
  uint64_t v3 = *(void *)(v0 + 224);
  uint64_t v4 = *(void *)(v0 + 232);
  uint64_t v17 = *(void *)(v1 + OBJC_IVAR____TtC8CreateML38LinearRegressorTrainingSessionDelegate_trainingMetrics);
  uint64_t v14 = *(void *)(v1 + OBJC_IVAR____TtC8CreateML38LinearRegressorTrainingSessionDelegate_trainingMetrics + 8);
  outlined copy of Result<_RegressorMetrics, Error>(v17, v14, v2);
  outlined destroy of MLLinearRegressor.ModelParameters(v0 + 16);
  outlined destroy of MLActivityClassifier.ModelParameters(v16, type metadata accessor for MLLinearRegressor.PersistentParameters);
  uint64_t v5 = *(int *)(v15 + 36);
  outlined consume of Result<(Int, Int), Error>(*(void *)(v3 + v5), *(void *)(v3 + v5 + 8), *(_DWORD *)(v3 + v5 + 16));
  *(void *)(v3 + v5) = v17;
  *(void *)(v3 + v5 + 8) = v14;
  *(unsigned char *)(v3 + v5 + 16) = v2 & 1;
  uint64_t v6 = *(void *)(v4 + OBJC_IVAR____TtC8CreateML38LinearRegressorTrainingSessionDelegate_validationMetrics + 8);
  uint64_t v7 = *(unsigned char *)(v4 + OBJC_IVAR____TtC8CreateML38LinearRegressorTrainingSessionDelegate_validationMetrics + 16);
  uint64_t v18 = *(void *)(v4 + OBJC_IVAR____TtC8CreateML38LinearRegressorTrainingSessionDelegate_validationMetrics);
  outlined copy of MLRegressorMetrics?(v18, v6, v7);
  swift_release();
  if (v7 != -1)
  {
    uint64_t v8 = *(void *)(v0 + 224);
    uint64_t v9 = *(int *)(*(void *)(v0 + 248) + 40);
    outlined consume of Result<(Int, Int), Error>(*(void *)(v8 + v9), *(void *)(v8 + v9 + 8), *(_DWORD *)(v8 + v9 + 16));
    *(void *)(v8 + v9) = v18;
    *(void *)(v8 + v9 + 8) = v6;
    *(unsigned char *)(v8 + v9 + 16) = v7 & 1;
  }
  uint64_t v10 = *(void *)(v0 + 264);
  uint64_t v11 = *(void *)(v0 + 240);
  uint64_t v12 = *(void *)(v0 + 256);
  swift_task_dealloc(*(void *)(v0 + 280));
  swift_task_dealloc(v10);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v5;

  uint64_t v1 = *(void *)(v0 + 280);
  uint64_t v2 = *(void *)(v0 + 264);
  uint64_t v3 = *(void *)(v0 + 256);
  uint64_t v5 = *(void *)(v0 + 240);
  swift_release();
  outlined destroy of MLLinearRegressor.ModelParameters(v0 + 16);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLLinearRegressor.PersistentParameters);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v5);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLLinearRegressor()
{
  return MLLinearRegressor.description.getter();
}

unint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLLinearRegressor()
{
  return MLLinearRegressor.debugDescription.getter();
}

NSAttributedString protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLLinearRegressor()
{
  return MLLinearRegressor.playgroundDescription.getter();
}

uint64_t sub_29E4F5()
{
  return objectdestroyTm_7();
}

uint64_t partial apply for closure #1 in MLLinearRegressor.computeMetrics(on:)(uint64_t a1)
{
  uint64_t v3 = *(void *)(type metadata accessor for DataFrame(0) - 8);
  uint64_t v4 = ~*(unsigned __int8 *)(v3 + 80) & (*(unsigned __int8 *)(v3 + 80) + 16);
  uint64_t v5 = v4 + *(void *)(v3 + 64);
  uint64_t v6 = *(unsigned __int8 *)(*(void *)(type metadata accessor for MLLinearRegressor(0) - 8) + 80);
  uint64_t v7 = (void *)swift_task_alloc(dword_3AE11C);
  *(void *)(v2 + 16) = v7;
  *uint64_t v7 = v2;
  v7[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLLinearRegressor.computeMetrics(on:)(a1, v1 + v4, v1 + ((v6 + v5) & ~v6));
}

uint64_t sub_29E5A5()
{
  return objectdestroy_3Tm();
}

uint64_t partial apply for closure #1 in MLLinearRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  type metadata accessor for MLLinearRegressor.Model(0);
  uint64_t v2 = (void *)swift_task_alloc(dword_3AE12C);
  *(void *)(v1 + 16) = v2;
  void *v2 = v1;
  v2[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLLinearRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(a1);
}

uint64_t sub_29E625()
{
  return objectdestroyTm_7();
}

uint64_t sub_29E63C()
{
  return objectdestroyTm_7();
}

uint64_t objectdestroyTm_7()
{
  uint64_t v1 = v0;
  uint64_t v17 = type metadata accessor for DataFrame(0);
  uint64_t v2 = *(void *)(v17 - 8);
  uint64_t v14 = *(unsigned __int8 *)(v2 + 80);
  uint64_t v3 = ~*(unsigned __int8 *)(v2 + 80) & (v14 + 16);
  uint64_t v4 = v3 + *(void *)(v2 + 64);
  uint64_t v5 = (int *)type metadata accessor for MLLinearRegressor(0);
  uint64_t v6 = *((void *)v5 - 1);
  uint64_t v15 = *(unsigned __int8 *)(v6 + 80);
  uint64_t v7 = ~v15 & (v15 + v4);
  uint64_t v16 = *(void *)(v6 + 64);
  (*(void (**)(uint64_t, uint64_t))(v2 + 8))(v1 + v3, v17);
  uint64_t v8 = v1 + v7;
  swift_bridgeObjectRelease(*(void *)(v1 + v7 + 8));
  uint64_t v9 = *(void *)(v1 + v7 + 16);
  if (v9)
  {
    swift_bridgeObjectRelease(v9);
    swift_bridgeObjectRelease(*(void *)(v8 + 32));
  }
  uint64_t v10 = v8 + *(int *)(type metadata accessor for MLLinearRegressor.Model(0) + 24);
  uint64_t v11 = type metadata accessor for BaseLinearRegressorModel(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v11 - 8) + 8))(v10, v11);

  swift_bridgeObjectRelease(*(void *)(v8 + v5[6] + 8));
  swift_bridgeObjectRelease(*(void *)(v8 + v5[7]));
  uint64_t v12 = v5[8];
  if (*(void *)(v8 + v12 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(v8 + v12));
  }
  outlined consume of Result<(Int, Int), Error>(*(void *)(v8 + v5[9]), *(void *)(v8 + v5[9] + 8), *(_DWORD *)(v8 + v5[9] + 16));
  outlined consume of Result<(Int, Int), Error>(*(void *)(v8 + v5[10]), *(void *)(v8 + v5[10] + 8), *(_DWORD *)(v8 + v5[10] + 16));
  return swift_deallocObject(v1, v16 + v7, v15 | v14 | 7);
}

uint64_t sub_29E7DF()
{
  return objectdestroy_3Tm();
}

uint64_t objectdestroy_3Tm()
{
  uint64_t v1 = type metadata accessor for MLLinearRegressor.Model(0);
  uint64_t v2 = *(void *)(v1 - 8);
  uint64_t v3 = *(unsigned __int8 *)(v2 + 80);
  uint64_t v4 = ~*(unsigned __int8 *)(v2 + 80) & (v3 + 16);
  uint64_t v10 = *(void *)(v2 + 64);
  uint64_t v5 = v4 + v0;
  swift_bridgeObjectRelease(*(void *)(v0 + v4 + 8));
  uint64_t v6 = *(void *)(v0 + v4 + 16);
  if (v6)
  {
    swift_bridgeObjectRelease(v6);
    swift_bridgeObjectRelease(*(void *)(v5 + 32));
  }
  uint64_t v7 = *(int *)(v1 + 24) + v5;
  uint64_t v8 = type metadata accessor for BaseLinearRegressorModel(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v8 - 8) + 8))(v7, v8);
  return swift_deallocObject(v0, v10 + v4, v3 | 7);
}

uint64_t partial apply for closure #1 in MLLinearRegressor.init(checkpoint:)(uint64_t a1)
{
  type metadata accessor for MLLinearRegressor.Model(0);
  uint64_t v2 = (void *)swift_task_alloc(dword_3AE154);
  *(void *)(v1 + 16) = v2;
  void *v2 = v1;
  v2[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLLinearRegressor.init(checkpoint:)(a1);
}

id sub_29E8FC()
{
  uint64_t v1 = v0;
  id result = MLLinearRegressor.model.getter();
  *uint64_t v1 = result;
  return result;
}

void sub_29E916(id *a1)
{
}

void *initializeBufferWithCopyOfBuffer for MLLinearRegressor(void *a1, void *a2, int *a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v9 = *a2;
    void *v3 = *a2;
    uint64_t v3 = (void *)(v9 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    *a1 = *a2;
    uint64_t v6 = a2[1];
    v3[1] = v6;
    uint64_t v7 = a2[2];
    swift_bridgeObjectRetain(v6);
    if (v7)
    {
      v3[2] = v7;
      v3[3] = a2[3];
      uint64_t v8 = a2[4];
      void v3[4] = v8;
      swift_bridgeObjectRetain(v7);
      swift_bridgeObjectRetain(v8);
    }
    else
    {
      void v3[4] = a2[4];
      *((_OWORD *)v3 + 1) = *((_OWORD *)a2 + 1);
    }
    uint64_t v10 = *(int *)(type metadata accessor for MLLinearRegressor.Model(0) + 24);
    uint64_t v11 = type metadata accessor for BaseLinearRegressorModel(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 16))((char *)v3 + v10, (char *)a2 + v10, v11);
    uint64_t v12 = a3[5];
    uint64_t v13 = *(void **)((char *)a2 + v12);
    *(void *)((char *)v3 + v12) = v13;
    uint64_t v14 = a3[6];
    *(void *)((char *)v3 + v14) = *(void *)((char *)a2 + v14);
    uint64_t v29 = *(void *)((char *)a2 + v14 + 8);
    *(void *)((char *)v3 + v14 + 8) = v29;
    uint64_t v15 = a3[7];
    uint64_t v31 = *(void *)((char *)a2 + v15);
    *(void *)((char *)v3 + v15) = v31;
    uint64_t v30 = a3;
    uint64_t v16 = a3[8];
    uint64_t v17 = (char *)v3 + v16;
    uint64_t v18 = (char *)a2 + v16;
    uint64_t v19 = *(void *)((char *)a2 + v16 + 24);
    v13;
    swift_bridgeObjectRetain(v29);
    swift_bridgeObjectRetain(v31);
    if (v19)
    {
      *((void *)v17 + 3) = v19;
      (**(void (***)(char *, char *, uint64_t))(v19 - 8))(v17, v18, v19);
    }
    else
    {
      long long v20 = *(_OWORD *)v18;
      *((_OWORD *)v17 + 1) = *((_OWORD *)v18 + 1);
      *(_OWORD *)uint64_t v17 = v20;
    }
    *((_OWORD *)v17 + 2) = *((_OWORD *)v18 + 2);
    *((_OWORD *)v17 + 3) = *((_OWORD *)v18 + 3);
    *((void *)v17 + 8) = *((void *)v18 + 8);
    v17[72] = v18[72];
    uint64_t v21 = v30[9];
    uint64_t v22 = *(void *)((char *)a2 + v21);
    uint64_t v23 = *(void *)((char *)a2 + v21 + 8);
    char v32 = *((unsigned char *)a2 + v21 + 16);
    outlined copy of Result<_RegressorMetrics, Error>(v22, v23, v32);
    *(void *)((char *)v3 + v21) = v22;
    *(void *)((char *)v3 + v21 + 8) = v23;
    *((unsigned char *)v3 + v21 + 16) = v32;
    uint64_t v24 = v30[10];
    uint64_t v25 = *(void *)((char *)a2 + v24);
    uint64_t v26 = *(void *)((char *)a2 + v24 + 8);
    char v27 = *((unsigned char *)a2 + v24 + 16);
    outlined copy of Result<_RegressorMetrics, Error>(v25, v26, v27);
    *(void *)((char *)v3 + v24) = v25;
    *(void *)((char *)v3 + v24 + 8) = v26;
    *((unsigned char *)v3 + v24 + 16) = v27;
  }
  return v3;
}

uint64_t destroy for MLLinearRegressor(void *a1, int *a2)
{
  swift_bridgeObjectRelease(a1[1]);
  uint64_t v3 = a1[2];
  if (v3)
  {
    swift_bridgeObjectRelease(v3);
    swift_bridgeObjectRelease(a1[4]);
  }
  int v4 = (char *)a1 + *(int *)(type metadata accessor for MLLinearRegressor.Model(0) + 24);
  uint64_t v5 = type metadata accessor for BaseLinearRegressorModel(0);
  (*(void (**)(char *, uint64_t))(*(void *)(v5 - 8) + 8))(v4, v5);

  swift_bridgeObjectRelease(*(void *)((char *)a1 + a2[6] + 8));
  swift_bridgeObjectRelease(*(void *)((char *)a1 + a2[7]));
  uint64_t v6 = a2[8];
  if (*(void *)((char *)a1 + v6 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)((char *)a1 + v6));
  }
  outlined consume of Result<(Int, Int), Error>(*(void *)((char *)a1 + a2[9]), *(void *)((char *)a1 + a2[9] + 8), *(_DWORD *)((char *)a1 + a2[9] + 16));
  return outlined consume of Result<(Int, Int), Error>(*(void *)((char *)a1 + a2[10]), *(void *)((char *)a1 + a2[10] + 8), *(_DWORD *)((char *)a1 + a2[10] + 16));
}

void *initializeWithCopy for MLLinearRegressor(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v5 = a2[1];
  a1[1] = v5;
  uint64_t v6 = a2[2];
  swift_bridgeObjectRetain(v5);
  if (v6)
  {
    a1[2] = v6;
    a1[3] = a2[3];
    uint64_t v7 = a2[4];
    a1[4] = v7;
    swift_bridgeObjectRetain(v6);
    swift_bridgeObjectRetain(v7);
  }
  else
  {
    a1[4] = a2[4];
    *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
  }
  uint64_t v8 = *(int *)(type metadata accessor for MLLinearRegressor.Model(0) + 24);
  uint64_t v9 = type metadata accessor for BaseLinearRegressorModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))((char *)a1 + v8, (char *)a2 + v8, v9);
  uint64_t v10 = a3[5];
  uint64_t v11 = *(void **)((char *)a2 + v10);
  *(void *)((char *)a1 + v10) = v11;
  uint64_t v12 = a3[6];
  *(void *)((char *)a1 + v12) = *(void *)((char *)a2 + v12);
  uint64_t v27 = *(void *)((char *)a2 + v12 + 8);
  *(void *)((char *)a1 + v12 + 8) = v27;
  uint64_t v13 = a3[7];
  uint64_t v29 = *(void *)((char *)a2 + v13);
  *(void *)((char *)a1 + v13) = v29;
  uint64_t v28 = a3;
  uint64_t v14 = a3[8];
  uint64_t v15 = (char *)a1 + v14;
  uint64_t v16 = (char *)a2 + v14;
  uint64_t v17 = *(void *)((char *)a2 + v14 + 24);
  v11;
  swift_bridgeObjectRetain(v27);
  swift_bridgeObjectRetain(v29);
  if (v17)
  {
    *((void *)v15 + 3) = v17;
    (**(void (***)(char *, char *, uint64_t))(v17 - 8))(v15, v16, v17);
  }
  else
  {
    long long v18 = *(_OWORD *)v16;
    *((_OWORD *)v15 + 1) = *((_OWORD *)v16 + 1);
    *(_OWORD *)uint64_t v15 = v18;
  }
  *((_OWORD *)v15 + 2) = *((_OWORD *)v16 + 2);
  *((_OWORD *)v15 + 3) = *((_OWORD *)v16 + 3);
  *((void *)v15 + 8) = *((void *)v16 + 8);
  v15[72] = v16[72];
  uint64_t v19 = v28[9];
  uint64_t v20 = *(void *)((char *)a2 + v19);
  uint64_t v21 = *(void *)((char *)a2 + v19 + 8);
  char v30 = *((unsigned char *)a2 + v19 + 16);
  outlined copy of Result<_RegressorMetrics, Error>(v20, v21, v30);
  *(void *)((char *)a1 + v19) = v20;
  *(void *)((char *)a1 + v19 + 8) = v21;
  *((unsigned char *)a1 + v19 + 16) = v30;
  uint64_t v22 = v28[10];
  uint64_t v23 = *(void *)((char *)a2 + v22);
  uint64_t v24 = *(void *)((char *)a2 + v22 + 8);
  char v25 = *((unsigned char *)a2 + v22 + 16);
  outlined copy of Result<_RegressorMetrics, Error>(v23, v24, v25);
  *(void *)((char *)a1 + v22) = v23;
  *(void *)((char *)a1 + v22 + 8) = v24;
  *((unsigned char *)a1 + v22 + 16) = v25;
  return a1;
}

void *assignWithCopy for MLLinearRegressor(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v4 = a2[1];
  uint64_t v5 = a1[1];
  a1[1] = v4;
  swift_bridgeObjectRetain(v4);
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = a1 + 2;
  uint64_t v7 = a2 + 2;
  uint64_t v8 = a1[2];
  uint64_t v9 = a2[2];
  if (v8)
  {
    if (v9)
    {
      a1[2] = v9;
      swift_bridgeObjectRetain(v9);
      swift_bridgeObjectRelease(v8);
      a1[3] = a2[3];
      uint64_t v10 = a2[4];
      uint64_t v11 = a1[4];
      a1[4] = v10;
      swift_bridgeObjectRetain(v10);
      swift_bridgeObjectRelease(v11);
    }
    else
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)(a1 + 2), &demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
      _OWORD *v6 = *v7;
      a1[4] = a2[4];
    }
  }
  else if (v9)
  {
    a1[2] = v9;
    a1[3] = a2[3];
    uint64_t v12 = a2[4];
    a1[4] = v12;
    swift_bridgeObjectRetain(v9);
    swift_bridgeObjectRetain(v12);
  }
  else
  {
    a1[4] = a2[4];
    _OWORD *v6 = *v7;
  }
  uint64_t v13 = *(int *)(type metadata accessor for MLLinearRegressor.Model(0) + 24);
  uint64_t v14 = type metadata accessor for BaseLinearRegressorModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 24))((char *)a1 + v13, (char *)a2 + v13, v14);
  uint64_t v15 = a3[5];
  uint64_t v16 = *(void **)((char *)a2 + v15);
  uint64_t v17 = *(void **)((char *)a1 + v15);
  *(void *)((char *)a1 + v15) = v16;
  v16;

  uint64_t v18 = a3[6];
  *(void *)((char *)a1 + v18) = *(void *)((char *)a2 + v18);
  uint64_t v19 = *(void *)((char *)a2 + v18 + 8);
  uint64_t v20 = *(void *)((char *)a1 + v18 + 8);
  *(void *)((char *)a1 + v18 + 8) = v19;
  swift_bridgeObjectRetain(v19);
  swift_bridgeObjectRelease(v20);
  uint64_t v21 = a3[7];
  uint64_t v22 = *(void *)((char *)a2 + v21);
  uint64_t v23 = *(void *)((char *)a1 + v21);
  *(void *)((char *)a1 + v21) = v22;
  swift_bridgeObjectRetain(v22);
  swift_bridgeObjectRelease(v23);
  uint64_t v24 = a3[8];
  char v25 = (char *)a1 + v24;
  uint64_t v26 = (char *)a2 + v24;
  uint64_t v27 = *(void *)((char *)a2 + v24 + 24);
  if (!*(void *)((char *)a1 + v24 + 24))
  {
    if (v27)
    {
      *((void *)v25 + 3) = v27;
      (**(void (***)(char *, char *))(v27 - 8))(v25, v26);
      goto LABEL_15;
    }
LABEL_14:
    long long v30 = *(_OWORD *)v26;
    *((_OWORD *)v25 + 1) = *((_OWORD *)v26 + 1);
    *(_OWORD *)char v25 = v30;
    goto LABEL_15;
  }
  uint64_t v29 = (void *)((char *)a1 + v24);
  if (!v27)
  {
    __swift_destroy_boxed_opaque_existential_1Tm(v29);
    goto LABEL_14;
  }
  __swift_assign_boxed_opaque_existential_0(v29, (void *)((char *)a2 + v24));
LABEL_15:
  *((void *)v25 + 4) = *((void *)v26 + 4);
  *((void *)v25 + 5) = *((void *)v26 + 5);
  *((void *)v25 + 6) = *((void *)v26 + 6);
  *((void *)v25 + 7) = *((void *)v26 + 7);
  *((void *)v25 + 8) = *((void *)v26 + 8);
  unsigned char v25[72] = v26[72];
  uint64_t v31 = a3[9];
  uint64_t v32 = *(void *)((char *)a2 + v31);
  uint64_t v33 = *(void *)((char *)a2 + v31 + 8);
  char v45 = *((unsigned char *)a2 + v31 + 16);
  outlined copy of Result<_RegressorMetrics, Error>(v32, v33, v45);
  uint64_t v34 = *(void *)((char *)a1 + v31);
  uint64_t v35 = *(void *)((char *)a1 + v31 + 8);
  *(void *)((char *)a1 + v31) = v32;
  *(void *)((char *)a1 + v31 + 8) = v33;
  int v36 = *(_DWORD *)((char *)a1 + v31 + 16);
  *((unsigned char *)a1 + v31 + 16) = v45;
  outlined consume of Result<(Int, Int), Error>(v34, v35, v36);
  uint64_t v37 = a3[10];
  uint64_t v38 = *(void *)((char *)a2 + v37);
  uint64_t v39 = *(void *)((char *)a2 + v37 + 8);
  char v40 = *((unsigned char *)a2 + v37 + 16);
  outlined copy of Result<_RegressorMetrics, Error>(v38, v39, v40);
  uint64_t v41 = *(void *)((char *)a1 + v37);
  uint64_t v42 = *(void *)((char *)a1 + v37 + 8);
  *(void *)((char *)a1 + v37) = v38;
  *(void *)((char *)a1 + v37 + 8) = v39;
  int v43 = *(_DWORD *)((char *)a1 + v37 + 16);
  *((unsigned char *)a1 + v37 + 16) = v40;
  outlined consume of Result<(Int, Int), Error>(v41, v42, v43);
  return a1;
}

uint64_t initializeWithTake for MLLinearRegressor(uint64_t a1, uint64_t a2, int *a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = *(_OWORD *)(a2 + 16);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v4 = *(int *)(type metadata accessor for MLLinearRegressor.Model(0) + 24);
  uint64_t v5 = type metadata accessor for BaseLinearRegressorModel(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 32))(a1 + v4, a2 + v4, v5);
  *(void *)(a1 + a3[5]) = *(void *)(a2 + a3[5]);
  *(_OWORD *)(a1 + a3[6]) = *(_OWORD *)(a2 + a3[6]);
  *(void *)(a1 + a3[7]) = *(void *)(a2 + a3[7]);
  qmemcpy((void *)(a1 + a3[8]), (const void *)(a2 + a3[8]), 0x49uLL);
  uint64_t v6 = a3[9];
  *(unsigned char *)(a1 + v6 + 16) = *(unsigned char *)(a2 + v6 + 16);
  *(_OWORD *)(a1 + v6) = *(_OWORD *)(a2 + v6);
  uint64_t v7 = a3[10];
  *(_OWORD *)(a1 + v7) = *(_OWORD *)(a2 + v7);
  *(unsigned char *)(a1 + v7 + 16) = *(unsigned char *)(a2 + v7 + 16);
  return a1;
}

void *assignWithTake for MLLinearRegressor(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v6 = a1[1];
  a1[1] = a2[1];
  swift_bridgeObjectRelease(v6);
  uint64_t v7 = a1 + 2;
  uint64_t v8 = a2 + 2;
  uint64_t v9 = a1[2];
  if (v9)
  {
    uint64_t v10 = a2[2];
    if (v10)
    {
      a1[2] = v10;
      swift_bridgeObjectRelease(v9);
      a1[3] = a2[3];
      uint64_t v11 = a1[4];
      a1[4] = a2[4];
      swift_bridgeObjectRelease(v11);
    }
    else
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)(a1 + 2), &demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
      *uint64_t v7 = *v8;
      a1[4] = a2[4];
    }
  }
  else
  {
    a1[4] = a2[4];
    *uint64_t v7 = *v8;
  }
  uint64_t v12 = *(int *)(type metadata accessor for MLLinearRegressor.Model(0) + 24);
  uint64_t v13 = type metadata accessor for BaseLinearRegressorModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v13 - 8) + 40))((char *)a1 + v12, (char *)a2 + v12, v13);
  uint64_t v14 = a3[5];
  uint64_t v15 = *(void **)((char *)a1 + v14);
  *(void *)((char *)a1 + v14) = *(void *)((char *)a2 + v14);

  uint64_t v16 = a3[6];
  *(void *)((char *)a1 + v16) = *(void *)((char *)a2 + v16);
  uint64_t v17 = *(void *)((char *)a1 + v16 + 8);
  *(void *)((char *)a1 + v16 + 8) = *(void *)((char *)a2 + v16 + 8);
  swift_bridgeObjectRelease(v17);
  uint64_t v18 = a3[7];
  uint64_t v19 = *(void *)((char *)a1 + v18);
  *(void *)((char *)a1 + v18) = *(void *)((char *)a2 + v18);
  swift_bridgeObjectRelease(v19);
  uint64_t v20 = a3[8];
  uint64_t v21 = (_OWORD *)((char *)a1 + v20);
  if (*(void *)((char *)a1 + v20 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)((char *)a1 + v20));
  }
  long long v22 = *(_OWORD *)((char *)a2 + v20);
  v21[1] = *(_OWORD *)((char *)a2 + v20 + 16);
  *uint64_t v21 = v22;
  *(void *)((char *)a1 + v20 + 32) = *(void *)((char *)a2 + v20 + 32);
  *(_OWORD *)((char *)a1 + v20 + 40) = *(_OWORD *)((char *)a2 + v20 + 40);
  *(_OWORD *)((char *)a1 + v20 + 56) = *(_OWORD *)((char *)a2 + v20 + 56);
  *((unsigned char *)a1 + v20 + 72) = *((unsigned char *)a2 + v20 + 72);
  uint64_t v23 = a3[9];
  char v24 = *((unsigned char *)a2 + v23 + 16);
  uint64_t v25 = *(void *)((char *)a1 + v23);
  uint64_t v26 = *(void *)((char *)a1 + v23 + 8);
  *(_OWORD *)((char *)a1 + v23) = *(_OWORD *)((char *)a2 + v23);
  int v27 = *(_DWORD *)((char *)a1 + v23 + 16);
  *((unsigned char *)a1 + v23 + 16) = v24;
  outlined consume of Result<(Int, Int), Error>(v25, v26, v27);
  uint64_t v28 = a3[10];
  char v29 = *((unsigned char *)a2 + v28 + 16);
  uint64_t v30 = *(void *)((char *)a1 + v28);
  uint64_t v31 = *(void *)((char *)a1 + v28 + 8);
  *(_OWORD *)((char *)a1 + v28) = *(_OWORD *)((char *)a2 + v28);
  int v32 = *(_DWORD *)((char *)a1 + v28 + 16);
  *((unsigned char *)a1 + v28 + 16) = v29;
  outlined consume of Result<(Int, Int), Error>(v30, v31, v32);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLinearRegressor(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_29F320);
}

uint64_t sub_29F320(uint64_t a1, unsigned int a2, uint64_t a3)
{
  unsigned int v4 = 0;
  uint64_t v5 = type metadata accessor for MLLinearRegressor.Model(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(a1, a2, v5);
  }
  if ((*(void *)(a1 + *(int *)(a3 + 20)) & 0xFFFFFFFF00000001) == 0) {
    return (*(void *)(a1 + *(int *)(a3 + 20)) >> 1) + 1;
  }
  return v4;
}

uint64_t storeEnumTagSinglePayload for MLLinearRegressor(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_29F39A);
}

uint64_t sub_29F39A(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = type metadata accessor for MLLinearRegressor.Model(0);
  if (*(_DWORD *)(*(void *)(v6 - 8) + 84) == a3) {
    return __swift_storeEnumTagSinglePayload(a1, a2, a2, v6);
  }
  uint64_t result = *(int *)(a4 + 20);
  *(void *)(a1 + result) = 2 * (a2 - 1);
  return result;
}

uint64_t type metadata completion function for MLLinearRegressor(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLLinearRegressor.Model(319);
  if (v2 <= 0x3F)
  {
    v3[0] = *(void *)(result - 8) + 64;
    v3[1] = (char *)&value witness table for Builtin.UnknownObject + 64;
    v3[2] = &unk_351198;
    v3[3] = (char *)&value witness table for Builtin.BridgeObject + 64;
    void v3[4] = &unk_3511B0;
    void v3[5] = &unk_3511C8;
    v3[6] = &unk_3511C8;
    swift_initStructMetadata(a1, 256, 7, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t sub_29F487()
{
  swift_unknownObjectRelease(v0[2]);
  swift_release(v0[4]);
  swift_release(v0[6]);
  return swift_deallocObject(v0, 56, 7);
}

uint64_t partial apply for closure #1 in static MLLinearRegressor.handleResult(_:session:fulfill:)(uint64_t a1)
{
  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v5 = v1[6];
  uint64_t v6 = (void *)swift_task_alloc(dword_3AE224);
  *(void *)(v2 + 16) = v6;
  void *v6 = v2;
  v6[1] = partial apply for specialized closure #1 in blockAwait<A>(_:);
  return closure #1 in static MLLinearRegressor.handleResult(_:session:fulfill:)(a1, v3, v4, v8, v9, v5);
}

uint64_t lazy protocol witness table accessor for type ContiguousArray<Double> and conformance ContiguousArray<A>()
{
  uint64_t result = lazy protocol witness table cache variable for type ContiguousArray<Double> and conformance ContiguousArray<A>;
  if (!lazy protocol witness table cache variable for type ContiguousArray<Double> and conformance ContiguousArray<A>)
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for ContiguousArray<Double>);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ContiguousArray<A>, v1);
    lazy protocol witness table cache variable for type ContiguousArray<Double> and conformance ContiguousArray<A> = result;
  }
  return result;
}

void *ObjectDetectorTrainingSessionDelegate.init(sessionParameters:)(uint64_t a1)
{
  uint64_t v31 = v1;
  uint64_t v33 = a1;
  v2[2] = 0xD000000000000011;
  uint64_t v34 = "on type changed." + 0x8000000000000000;
  v2[3] = "on type changed." + 0x8000000000000000;
  uint64_t v3 = (uint64_t)v2 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_trainingParameters;
  _s8CreateML16MLObjectDetectorV20PersistentParametersVSgWOi0_((uint64_t)v25);
  uint64_t v29 = v3;
  outlined init with take of MLObjectDetector.PersistentParameters?((uint64_t)v25, v3);
  uint64_t empty = tc_v1_parameters_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v5 = empty;
  uint64_t v6 = OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_args;
  uint64_t v7 = type metadata accessor for CMLParameters();
  uint64_t v8 = swift_allocObject(v7, 24, 7);
  *(void *)(v8 + 16) = v5;
  *(void *)((char *)v2 + v6) = v8;
  int v32 = v2;
  uint64_t v9 = (uint64_t)v2 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_sessionParameters;
  outlined init with copy of MLTrainingSessionParameters(v33, (uint64_t)v2 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  uint64_t v30 = v6;
  if (((unint64_t)"on type changed." & 0x1000000000000000) != 0)
  {
    uint64_t v23 = v31;
    _StringGuts._slowWithCString<A>(_:)(closure #1 in CMLModel.init(name:), 0, 0xD000000000000011, v34, &type metadata for OpaquePointer);
    if (!v23)
    {
      uint64_t v15 = v28[17];
      uint64_t v14 = v32;
      goto LABEL_10;
    }
    uint64_t v18 = v33;
    uint64_t v14 = v32;
  }
  else
  {
    uint64_t v34 = (char *)&v24;
    uint64_t v10 = alloca(32);
    uint64_t v11 = alloca(32);
    uint64_t v26 = closure #1 in CMLModel.init(name:);
    uint64_t v27 = 0;
    if (((unint64_t)"on type changed." & 0x2000000000000000) != 0)
    {
      v28[0] = 0xD000000000000011;
      v28[1] = (unint64_t)"on type changed." & 0xFFFFFFFFFFFFFFLL;
      uint64_t v16 = v31;
      uint64_t v17 = specialized handling<A, B>(_:_:)((uint64_t)v28);
      uint64_t v14 = v32;
      if (!v16)
      {
        uint64_t v15 = v17;
        if (!v17) {
          BUG();
        }
        goto LABEL_10;
      }
    }
    else
    {
      uint64_t v12 = v31;
      uint64_t v13 = _sSRsRi_zrlE17withMemoryRebound2to_qd_1_qd__m_qd_1_SRyqd__Gqd_0_YKXEtqd_0_YKs5ErrorRd_0_Ri_d__Ri_d_1_r1_lFSRyxGq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lys4Int8VsAD_pqd_1_Isgyrzr_SRys5UInt8VGqd_1_sAD_pAIRszAGRsd__sAD_pRsd_0_Ri_d_1_r_1_lIetMgyrzo_Tpq5s13OpaquePointerV_Tg507_sSRys4f5VGxs5e31_pIgyrzo_ACxsAD_pIegyrzr_lTRs13hI5V_TG5SRyAGGALsAD_pIgyrzo_Tf1cn_n(((unint64_t)"on type changed." & 0xFFFFFFFFFFFFFFFLL) + 32, 17, (uint64_t (*)(uint64_t))closure #1 in _StringGuts.withCString<A>(_:)specialized partial apply);
      uint64_t v14 = v32;
      if (!v12)
      {
        uint64_t v15 = v13;
LABEL_10:
        uint64_t v20 = type metadata accessor for CMLModel();
        uint64_t v21 = swift_allocObject(v20, 24, 7);
        *(void *)(v21 + 16) = v15;
        outlined destroy of MLActivityClassifier.ModelParameters(v33, type metadata accessor for MLTrainingSessionParameters);
        *(void *)((char *)v14 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_model) = v21;
        return v14;
      }
    }
    uint64_t v18 = v33;
  }
  outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLTrainingSessionParameters);
  swift_bridgeObjectRelease(v14[3]);
  outlined destroy of MLActivityClassifier.ModelParameters(v9, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of MLObjectDetector.PersistentParameters?(v29, (uint64_t)v28);
  outlined release of MLObjectDetector.PersistentParameters?(v28);
  swift_release();
  uint64_t v19 = type metadata accessor for ObjectDetectorTrainingSessionDelegate(0);
  swift_deallocPartialClassInstance(v14, v19, *(unsigned int *)(*v14 + 48), *(unsigned __int16 *)(*v14 + 52));
  return v14;
}

uint64_t ObjectDetectorTrainingSessionDelegate.init(trainingData:validationData:imageColumnName:annotationColumnName:annotationType:modelParameters:sessionParameters:)(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  uint64_t v57 = v9;
  uint64_t v11 = v10;
  uint64_t v60 = a6;
  uint64_t v58 = a5;
  uint64_t v61 = (uint64_t *)a4;
  uint64_t v59 = a3;
  int64_t v12 = *(void *)(*(void *)(type metadata accessor for MLObjectDetector.ModelParameters(0) - 8) + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v49 = &v41;
  uint64_t v51 = *(void *)a1;
  char v65 = *(unsigned char *)(a1 + 8);
  uint64_t v50 = *a2;
  char v64 = *((unsigned char *)a2 + 8);
  __int16 v62 = *(_WORD *)a7;
  char v63 = *(unsigned char *)(a7 + 2);
  *(void *)(v10 + 16) = 0xD000000000000011;
  *(void *)(v10 + 24) = "on type changed." + 0x8000000000000000;
  uint64_t v15 = v10 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_trainingParameters;
  _s8CreateML16MLObjectDetectorV20PersistentParametersVSgWOi0_((uint64_t)v42);
  outlined init with take of MLObjectDetector.PersistentParameters?((uint64_t)v42, v15);
  uint64_t empty = tc_v1_parameters_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v17 = empty;
  uint64_t v18 = OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_args;
  uint64_t v19 = type metadata accessor for CMLParameters();
  uint64_t v20 = swift_allocObject(v19, 24, 7);
  *(void *)(v20 + 16) = v17;
  uint64_t v52 = v18;
  *(void *)(v11 + v18) = v20;
  uint64_t v47 = v51;
  LOBYTE(v48) = v65 & 1;
  uint64_t v55 = v50;
  char v56 = v64;
  __int16 v53 = v62;
  char v54 = v63;
  uint64_t v21 = (uint64_t)v49;
  outlined init with copy of MLTrainingSessionParameters(a8, (uint64_t)v49, type metadata accessor for MLObjectDetector.ModelParameters);
  MLObjectDetector.PersistentParameters.init(trainingData:validationData:imageColumnName:annotationColumnName:annotationType:modelParameters:)((uint64_t)&v47, (uint64_t)&v55, v59, (uint64_t)v61, v58, v60, &v53, v21);
  MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
  outlined init with take of MLObjectDetector.PersistentParameters?(v15, (uint64_t)v45);
  uint64_t v58 = v15;
  outlined init with take of MLObjectDetector.PersistentParameters?((uint64_t)v46, v15);
  outlined release of MLObjectDetector.PersistentParameters?(v45);
  uint64_t v22 = v11 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_sessionParameters;
  outlined init with copy of MLTrainingSessionParameters(a9, v11 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  uint64_t v23 = *(void *)(v11 + 16);
  uint64_t v60 = v11;
  uint64_t v24 = *(void *)(v11 + 24);
  uint64_t v59 = v22;
  if ((v24 & 0x1000000000000000) != 0 || !(v24 & 0x2000000000000000 | v23 & 0x1000000000000000))
  {
    swift_bridgeObjectRetain(v24);
    uint64_t v39 = v57;
    _StringGuts._slowWithCString<A>(_:)(closure #1 in CMLModel.init(name:), 0, v23, v24, &type metadata for OpaquePointer);
    if (!v39)
    {
      swift_bridgeObjectRelease(v24);
      uint64_t v35 = v55;
      goto LABEL_14;
    }
  }
  else
  {
    uint64_t v61 = &v41;
    uint64_t v25 = alloca(32);
    uint64_t v26 = alloca(32);
    uint64_t v44 = 0;
    int v43 = closure #1 in CMLModel.init(name:);
    if ((v24 & 0x2000000000000000) == 0)
    {
      if ((v23 & 0x1000000000000000) != 0)
      {
        uint64_t v27 = (v24 & 0xFFFFFFFFFFFFFFFLL) + 32;
        uint64_t v28 = v23 & 0xFFFFFFFFFFFFLL;
      }
      else
      {
        uint64_t v27 = _StringObject.sharedUTF8.getter(v23, v24);
        uint64_t v28 = v40;
      }
      swift_bridgeObjectRetain(v24);
      uint64_t v29 = v57;
      uint64_t v30 = _sSRsRi_zrlE17withMemoryRebound2to_qd_1_qd__m_qd_1_SRyqd__Gqd_0_YKXEtqd_0_YKs5ErrorRd_0_Ri_d__Ri_d_1_r1_lFSRyxGq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lys4Int8VsAD_pqd_1_Isgyrzr_SRys5UInt8VGqd_1_sAD_pAIRszAGRsd__sAD_pRsd_0_Ri_d_1_r_1_lIetMgyrzo_Tpq5s13OpaquePointerV_Tg507_sSRys4f5VGxs5e31_pIgyrzo_ACxsAD_pIegyrzr_lTRs13hI5V_TG5SRyAGGALsAD_pIgyrzo_Tf1cn_n(v27, v28, (uint64_t (*)(uint64_t))closure #1 in _StringGuts.withCString<A>(_:)specialized partial apply);
      if (v29) {
        goto LABEL_10;
      }
      uint64_t v35 = v30;
      swift_bridgeObjectRelease(v24);
LABEL_14:
      uint64_t v36 = type metadata accessor for CMLModel();
      uint64_t v37 = swift_allocObject(v36, 24, 7);
      *(void *)(v37 + 16) = v35;
      outlined destroy of MLActivityClassifier.ModelParameters(a9, type metadata accessor for MLTrainingSessionParameters);
      outlined destroy of MLActivityClassifier.ModelParameters(a8, type metadata accessor for MLObjectDetector.ModelParameters);
      uint64_t v33 = v60;
      *(void *)(v60 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_model) = v37;
      return v33;
    }
    uint64_t v47 = v23;
    uint64_t v48 = v24 & 0xFFFFFFFFFFFFFFLL;
    swift_bridgeObjectRetain(v24);
    uint64_t v31 = v57;
    uint64_t v32 = specialized handling<A, B>(_:_:)((uint64_t)&v47);
    if (!v31)
    {
      uint64_t v35 = v32;
      if (!v32) {
        BUG();
      }
      swift_bridgeObjectRelease(v24);
      goto LABEL_14;
    }
  }
LABEL_10:
  swift_bridgeObjectRelease(v24);
  outlined destroy of MLActivityClassifier.ModelParameters(a9, type metadata accessor for MLTrainingSessionParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(a8, type metadata accessor for MLObjectDetector.ModelParameters);
  uint64_t v33 = v60;
  swift_bridgeObjectRelease(*(void *)(v60 + 24));
  outlined destroy of MLActivityClassifier.ModelParameters(v59, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of MLObjectDetector.PersistentParameters?(v58, (uint64_t)&v47);
  outlined release of MLObjectDetector.PersistentParameters?(&v47);
  swift_release();
  uint64_t v34 = type metadata accessor for ObjectDetectorTrainingSessionDelegate(0);
  swift_deallocPartialClassInstance(v33, v34, *(unsigned int *)(*(void *)v33 + 48), *(unsigned __int16 *)(*(void *)v33 + 52));
  return v33;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> ObjectDetectorTrainingSessionDelegate.setUp()()
{
  uint64_t v21 = v0;
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLObjectDetector.ModelParameters(0) - 8) + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  outlined init with take of MLObjectDetector.PersistentParameters?(v1 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_trainingParameters, (uint64_t)v20);
  outlined init with take of MLObjectDetector.PersistentParameters?((uint64_t)v20, (uint64_t)__src);
  if (_s8CreateML16MLObjectDetectorV20PersistentParametersVSgWOg((uint64_t)__src) == 1)
  {
    uint64_t v5 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v5, 0, 0);
    *(void *)uint64_t v6 = 0xD000000000000061;
    *(void *)(v6 + 8) = "tylized validation result" + 0x8000000000000000;
    *(_OWORD *)(v6 + 16) = 0;
    *(_OWORD *)(v6 + 32) = 0;
    *(unsigned char *)(v6 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v5, v6, v7, v8, v9);
  }
  else
  {
    v20[17] = v1;
    memcpy(__dst, __src, 0x81uLL);
    outlined init with take of MLObjectDetector.PersistentParameters?((uint64_t)v20, (uint64_t)v17);
    outlined retain of MLObjectDetector.PersistentParameters((uint64_t)v17);
    MLObjectDetector.PersistentParameters.modelParameters.getter();
    *(_WORD *)__dst = __src[8];
    __dst[2] = BYTE2(__src[8]);
    uint64_t v10 = v21;
    uint64_t v11 = static MLObjectDetector.validateAndConvertParameters(_:annotationType:imageColumn:annotationColumn:)((uint64_t)v17, __dst, __src[4], __src[5], __src[6], (int *)__src[7]);
    if (v10)
    {
      outlined release of MLObjectDetector.PersistentParameters?(v20);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v17, type metadata accessor for MLObjectDetector.ModelParameters);
    }
    else
    {
      uint64_t v12 = v11;
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v17, type metadata accessor for MLObjectDetector.ModelParameters);
      uint64_t v13 = __src[0];
      char v14 = __src[1];
      *(void *)__dst = __src[0];
      __dst[8] = __src[1] & 1;
      outlined copy of Result<_DataTable, Error>(__src[0], __src[1]);
      uint64_t v21 = v12;
      CMLParameters.setTraining(table:)(__dst);
      outlined consume of Result<_DataTable, Error>(v13, v14);
      if (LOBYTE(__src[3]) != 0xFF)
      {
        uint64_t v15 = __src[2];
        *(void *)__dst = __src[2];
        char v16 = __src[3];
        __dst[8] = __src[3] & 1;
        outlined copy of Result<_DataTable, Error>(__src[2], __src[3]);
        CMLParameters.setValidation(table:)(__dst);
        outlined consume of MLDataTable?(v15, v16);
      }
      swift_retain();
      CMLModel.callFunction(name:arguments:)(0, v21);
      swift_release();
      swift_release();
      swift_release();
      outlined release of MLObjectDetector.PersistentParameters?(v20);
    }
  }
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> ObjectDetectorTrainingSessionDelegate.resume(from:)(Swift::OpaquePointer from)
{
  uint64_t v66 = v1;
  uint64_t v67 = v2;
  uint64_t v64 = type metadata accessor for URL(0);
  uint64_t v62 = *(void *)(v64 - 8);
  int64_t v3 = *(void *)(v62 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  char v65 = v53;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                             - 8)
                 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v9 = type metadata accessor for MLCheckpoint(0);
  int64_t v10 = *(void *)(*(void *)(v9 - 8) + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  specialized BidirectionalCollection.last.getter((uint64_t)from._rawValue);
  if (__swift_getEnumTagSinglePayload((uint64_t)v53, 1, v9) == 1)
  {
    outlined destroy of MLCheckpoint?((uint64_t)v53);
    uint64_t v13 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v13, 0, 0);
    *(void *)uint64_t v14 = 0xD00000000000001DLL;
    *(void *)(v14 + 8) = "reated." + 0x8000000000000000;
    *(_OWORD *)(v14 + 16) = 0;
    *(_OWORD *)(v14 + 32) = 0;
    *(unsigned char *)(v14 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v13, v14, v15, v16, v17);
    return;
  }
  outlined init with take of MLCheckpoint((uint64_t)v53, (uint64_t)v53);
  outlined init with take of MLObjectDetector.PersistentParameters?(v67 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_trainingParameters, (uint64_t)v60);
  outlined init with take of MLObjectDetector.PersistentParameters?((uint64_t)v60, (uint64_t)&v56);
  if (_s8CreateML16MLObjectDetectorV20PersistentParametersVSgWOg((uint64_t)&v56) == 1)
  {
    uint64_t v18 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v18, 0, 0);
    *(void *)uint64_t v19 = 0xD000000000000061;
    *(void *)(v19 + 8) = "tylized validation result" + 0x8000000000000000;
    *(_OWORD *)(v19 + 16) = 0;
    *(_OWORD *)(v19 + 32) = 0;
    *(unsigned char *)(v19 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v18, v19, v20, v21, v22);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v53, type metadata accessor for MLCheckpoint);
    return;
  }
  uint64_t v68 = v53;
  uint64_t v23 = v62;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v62 + 16))(v65, v53, v64);
  outlined init with take of MLObjectDetector.PersistentParameters?((uint64_t)v60, (uint64_t)v53);
  outlined retain of MLObjectDetector.PersistentParameters((uint64_t)v53);
  uint64_t v25 = URL.absoluteString.getter();
  char v26 = v24;
  if ((v24 & 0x1000000000000000) != 0 || !(v24 & 0x2000000000000000 | v25 & 0x1000000000000000))
  {
    uint64_t v51 = v66;
    _StringGuts._slowWithCString<A>(_:)(closure #1 in CMLModel.init(url:), 0, v25, v24, &type metadata for OpaquePointer);
    if (!v51) {
      goto LABEL_12;
    }
    goto LABEL_14;
  }
  uint64_t v27 = alloca(32);
  uint64_t v28 = alloca(32);
  uint64_t v55 = 0;
  char v54 = closure #1 in CMLModel.init(url:);
  if ((v24 & 0x2000000000000000) == 0)
  {
    if ((v25 & 0x1000000000000000) != 0)
    {
      uint64_t v29 = (v24 & 0xFFFFFFFFFFFFFFFLL) + 32;
      uint64_t v30 = v25 & 0xFFFFFFFFFFFFLL;
    }
    else
    {
      uint64_t v29 = _StringObject.sharedUTF8.getter(v25, v24);
      uint64_t v30 = v52;
    }
    uint64_t v31 = v66;
    uint64_t v32 = _sSRsRi_zrlE17withMemoryRebound2to_qd_1_qd__m_qd_1_SRyqd__Gqd_0_YKXEtqd_0_YKs5ErrorRd_0_Ri_d__Ri_d_1_r1_lFSRyxGq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lys4Int8VsAD_pqd_1_Isgyrzr_SRys5UInt8VGqd_1_sAD_pAIRszAGRsd__sAD_pRsd_0_Ri_d_1_r_1_lIetMgyrzo_Tpq5s13OpaquePointerV_Tg507_sSRys4f5VGxs5e31_pIgyrzo_ACxsAD_pIegyrzr_lTRs13hI5V_TG5SRyAGGALsAD_pIgyrzo_Tf1cn_n(v29, v30, (uint64_t (*)(uint64_t))partial apply for specialized closure #1 in _StringGuts.withCString<A>(_:));
    if (!v31)
    {
      uint64_t v63 = v32;
LABEL_12:
      swift_bridgeObjectRelease(v26);
      goto LABEL_18;
    }
LABEL_14:
    (*(void (**)(unsigned char *, uint64_t))(v23 + 8))(v65, v64);
    swift_bridgeObjectRelease(v26);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v68, type metadata accessor for MLCheckpoint);
LABEL_15:
    outlined release of MLObjectDetector.PersistentParameters?(v60);
    return;
  }
  v61[0] = v25;
  v61[1] = v24 & 0xFFFFFFFFFFFFFFLL;
  uint64_t v33 = v66;
  uint64_t v34 = specialized handling<A, B>(_:_:)((uint64_t)v61);
  if (v33) {
    goto LABEL_14;
  }
  if (!v34) {
    BUG();
  }
  uint64_t v63 = v34;
  swift_bridgeObjectRelease(v26);
LABEL_18:
  uint64_t v35 = v63;
  (*(void (**)(unsigned char *, uint64_t))(v23 + 8))(v65, v64);
  uint64_t v36 = type metadata accessor for CMLModel();
  uint64_t v37 = swift_allocObject(v36, 24, 7);
  *(void *)(v37 + 16) = v35;
  *(void *)(v67 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_model) = v37;
  swift_release();
  uint64_t v38 = v56;
  if (v57)
  {
    outlined copy of Result<_DataTable, Error>(v56, 1);
    outlined copy of Result<_DataTable, Error>(v38, 1);
    swift_willThrow(v38, 1, v39, v40, v41, v42);
    outlined release of MLObjectDetector.PersistentParameters?(v60);
    outlined consume of Result<_DataTable, Error>(v38, 1);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v68, type metadata accessor for MLCheckpoint);
    return;
  }
  uint64_t v67 = *(void *)(v56 + 16);
  char v43 = v59;
  if (v59 == -1)
  {
    uint64_t v45 = 0;
    goto LABEL_24;
  }
  uint64_t v44 = v58;
  if ((v59 & 1) == 0)
  {
    uint64_t v45 = *(void *)(v58 + 16);
    swift_retain();
LABEL_24:
    swift_retain();
    uint64_t v46 = v67;
    swift_retain();
    CMLModel.resume(training:validation:)(v46, v45);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v68, type metadata accessor for MLCheckpoint);
    swift_release();
    swift_release();
    swift_release();
    goto LABEL_15;
  }
  outlined copy of Result<_DataTable, Error>(v58, 1);
  outlined copy of Result<_DataTable, Error>(v44, 1);
  swift_willThrow(v44, 1, v47, v48, v49, v50);
  outlined release of MLObjectDetector.PersistentParameters?(v60);
  outlined consume of MLDataTable?(v44, v43);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v68, type metadata accessor for MLCheckpoint);
}

Swift::Int_optional __swiftcall ObjectDetectorTrainingSessionDelegate.itemCount(phase:)(CreateML::MLPhase phase)
{
  switch(*(unsigned char *)phase)
  {
    case 0:
    case 3:
    case 4:
      char v2 = 1;
      v3.Swift::Int value = 0;
      break;
    case 1:
      v3.Swift::Int value = 0;
      char v2 = 0;
      break;
    case 2:
      uint64_t v4 = OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_sessionParameters + v1;
      char v2 = 0;
      v3.Swift::Int value = *(void *)(*(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 28) + v4);
      break;
  }
  v3.Swift::Bool is_nil = v2;
  return v3;
}

Swift::tuple_Int_metrics_OpaquePointer_finished_Bool __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> ObjectDetectorTrainingSessionDelegate.train(from:)(Swift::Int from)
{
  uint64_t v4 = (char *)v2 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_sessionParameters;
  uint64_t v5 = type metadata accessor for MLTrainingSessionParameters(0);
  uint64_t v6 = *(void *)&v4[*(int *)(v5 + 20)];
  uint64_t v25 = v6 + from;
  if (__OFADD__(v6, from)) {
    BUG();
  }
  Swift::Int v22 = *(void *)&v4[*(int *)(v5 + 28)];
  uint64_t v7 = v22 - from;
  if (__OFSUB__(v22, from)) {
    BUG();
  }
  if (v6 < v7) {
    uint64_t v7 = v6;
  }
  if (v7 < 0) {
    BUG();
  }
  uint64_t v26 = v1;
  uint64_t v23 = v7;
  if (v7)
  {
    uint64_t v24 = OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_model;
    uint64_t v20 = *(void *)((char *)v2 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_args);
    uint64_t inited = v23;
    uint64_t v21 = v2;
    while (1)
    {
      if (inited-- == 0) {
        BUG();
      }
      int64_t v10 = *(void **)((char *)v2 + v24);
      swift_retain();
      CMLModel.callFunction(name:arguments:)(1, v20);
      Swift::Int v11 = swift_release();
      if (v26) {
        break;
      }
      swift_release();
      char v2 = v21;
      if (!inited) {
        goto LABEL_11;
      }
    }
  }
  else
  {
LABEL_11:
    int64_t v10 = v2;
    uint64_t v24 = OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_model;
    uint64_t inited = *(void *)((char *)v2 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_args);
    swift_retain();
    LOBYTE(inited) = CMLModel.callFunction(name:arguments:)(2, inited);
    Swift::Int v11 = swift_release();
    if (!v26)
    {
      swift_release();
      uint64_t v12 = *(void *)((char *)v2 + v24);
      swift_retain();
      CMLModel.getValue(field:)(0x676E696E69617274, 0xED000073736F6C5FLL);
      swift_release();
      uint64_t v15 = CMLVariant.featureValue()(v12);
      swift_release();
      specialized handling<A, B>(_:_:)(*(void *)(v15 + 16));
      uint64_t v26 = v3;
      swift_release();
      uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(MLProgress.Metric, Double)>);
      uint64_t inited = swift_initStackObject(v16, v19);
      *(void *)(inited + 16) = 1;
      *(void *)(inited + 24) = 2;
      *(unsigned char *)(inited + 32) = 0;
      *(void *)(inited + 40) = v26;
      uint64_t v17 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
      uint64_t v18 = Dictionary.init(dictionaryLiteral:)(inited, &type metadata for MLProgress.Metric, &type metadata for Double, v17);
      LOBYTE(inited) = v25 >= v22;
      int64_t v10 = specialized _dictionaryUpCast<A, B, C, D>(_:)(v18);
      swift_bridgeObjectRelease(v18);
      Swift::Int v11 = v23;
    }
  }
  uint64_t v13 = v10;
  Swift::Bool v14 = inited;
  result.metrics._uint64_t rawValue = v13;
  result._0 = v11;
  result.BOOL finished = v14;
  return result;
}

Swift::tuple_Int_finished_Bool __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> ObjectDetectorTrainingSessionDelegate.evaluate(from:)(Swift::Int from)
{
  uint64_t v3 = *(void *)(v2 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_args);
  swift_retain();
  CMLModel.callFunction(name:arguments:)(4, v3);
  swift_release();
  if (!v1) {
    swift_release();
  }
  v4._0 = 1;
  v4.BOOL finished = 1;
  return v4;
}

uint64_t ObjectDetectorTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)(uint64_t a1, unsigned __int8 *a2)
{
  unint64_t v4 = 0xEB0000000064657ALL;
  uint64_t v5 = *a2;
  uint64_t v20 = v3;
  uint64_t v19 = a1;
  switch(v5)
  {
    case 0:
      uint64_t v6 = 0x696C616974696E69;
      break;
    case 1:
      uint64_t v6 = 0x6974636172747865;
      goto LABEL_6;
    case 2:
      swift_bridgeObjectRelease(0);
      goto LABEL_9;
    case 3:
      uint64_t v6 = 0x697461756C617665;
LABEL_6:
      unint64_t v4 = 0xEA0000000000676ELL;
      break;
    case 4:
      unint64_t v4 = 0xEB00000000676E69;
      uint64_t v6 = 0x636E657265666E69;
      break;
  }
  unsigned int v7 = 0;
  char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(v6, v4, 0x676E696E69617274, 0xE800000000000000, 0);
  swift_bridgeObjectRelease(v4);
  if (v8)
  {
LABEL_9:
    uint64_t empty = tc_v1_parameters_create_empty(0);
    if (!empty) {
      BUG();
    }
    uint64_t v10 = empty;
    uint64_t v11 = type metadata accessor for CMLParameters();
    uint64_t inited = swift_initStackObject(v11, v18);
    *(void *)(inited + 16) = v10;
    unsigned int v13 = type metadata accessor for CMLFeatureValue();
    uint64_t v21 = v10;
    unsigned int v7 = v13;
    uint64_t v14 = URL.path.getter(0);
    uint64_t v16 = CMLFeatureValue.__allocating_init(_:)(v14, v15);
    if (v2)
    {
      swift_release();
    }
    else
    {
      unsigned int v7 = v16;
      CMLParameters.add(key:featureValue:)(7, v16);
      swift_release();
      swift_retain();
      CMLModel.callFunction(name:arguments:)(6, inited);
      swift_release();
      swift_setDeallocating(inited);
      tc_v1_release(v21);
      swift_release();
      LOBYTE(v7) = 1;
    }
  }
  return v7;
}

NSURL *ObjectDetectorTrainingSessionDelegate.save(to:)(uint64_t a1)
{
  outlined init with take of MLObjectDetector.PersistentParameters?(OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_trainingParameters + v1, (uint64_t)v8);
  outlined init with take of MLObjectDetector.PersistentParameters?((uint64_t)v8, (uint64_t)__src);
  if (_s8CreateML16MLObjectDetectorV20PersistentParametersVSgWOg((uint64_t)__src) == 1)
  {
    uint64_t v2 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v2, 0, 0);
    *(void *)uint64_t v3 = 0xD000000000000030;
    *(void *)(v3 + 8) = "Feature Extractor" + 0x8000000000000000;
    *(_OWORD *)(v3 + 16) = 0;
    *(_OWORD *)(v3 + 32) = 0;
    *(unsigned char *)(v3 + 48) = 2;
    return (NSURL *)swift_willThrow(&type metadata for MLCreateError, v2, v3, v4, v5, v6);
  }
  else
  {
    memcpy(__dst, __src, sizeof(__dst));
    return MLObjectDetector.PersistentParameters.save(toSessionDirectory:)(a1);
  }
}

uint64_t *ObjectDetectorTrainingSessionDelegate.restore(from:phase:)(uint64_t a1, double a2)
{
  uint64_t v4 = type metadata accessor for URL(0);
  uint64_t v5 = *(void *)(v4 - 8);
  int64_t v6 = *(void *)(v5 + 64);
  unsigned int v7 = alloca(v6);
  char v8 = alloca(v6);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v5 + 16))(&v11, a1, v4);
  Swift::tuple_Int_metrics_OpaquePointer_finished_Bool result = (uint64_t *)MLObjectDetector.PersistentParameters.init(sessionDirectory:)((uint64_t)&v11);
  if (!v2)
  {
    memcpy(__dst, __src, 0x81uLL);
    uint64_t v10 = OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_trainingParameters + v3;
    outlined init with take of MLObjectDetector.PersistentParameters?(v10, (uint64_t)v15);
    outlined init with take of MLObjectDetector.PersistentParameters?((uint64_t)v15, (uint64_t)v14);
    if (_s8CreateML16MLObjectDetectorV20PersistentParametersVSgWOg((uint64_t)v14) == 1)
    {
      memcpy(v17, __dst, 0x81uLL);
      MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
      outlined init with take of MLObjectDetector.PersistentParameters?(v10, (uint64_t)v16);
      outlined init with take of MLObjectDetector.PersistentParameters?((uint64_t)v17, v10);
      return outlined release of MLObjectDetector.PersistentParameters?(v16);
    }
    else
    {
      memcpy(v17, __dst, 0x81uLL);
      memcpy(v12, v14, 0x81uLL);
      outlined init with take of MLObjectDetector.PersistentParameters?((uint64_t)v15, (uint64_t)v16);
      outlined retain of MLObjectDetector.PersistentParameters((uint64_t)v16);
      ObjectDetectorTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:phase:)((uint64_t)v17, (uint64_t)v12, a2);
      outlined release of MLObjectDetector.PersistentParameters?(v15);
      return (uint64_t *)outlined release of MLObjectDetector.PersistentParameters((uint64_t)__dst);
    }
  }
  return result;
}

uint64_t ObjectDetectorTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:phase:)(uint64_t a1, uint64_t a2, double a3)
{
  if (*(unsigned char *)(a1 + 64) != *(unsigned char *)(a2 + 64)
    || ((*(unsigned char *)(a2 + 65) ^ *(unsigned char *)(a1 + 65)) & 1) != 0
    || *(unsigned char *)(a1 + 66) != *(unsigned char *)(a2 + 66))
  {
    uint64_t v7 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v7, 0, 0);
    *(void *)uint64_t v8 = 0xD000000000000030;
    *(void *)(v8 + 8) = "iningSessionDelegate" + 0x8000000000000000;
    *(_OWORD *)(v8 + 16) = 0;
    *(_OWORD *)(v8 + 32) = 0;
    *(unsigned char *)(v8 + 48) = 0;
    return swift_willThrow(&type metadata for MLCreateError, v7, v8, v9, v10, v11);
  }
  uint64_t v3 = *(void **)a1;
  char v62 = *(unsigned char *)(a1 + 8);
  Swift::String v48 = *(Swift::String *)(a1 + 32);
  uint64_t v45 = *(void **)a2;
  char v4 = *(unsigned char *)(a2 + 8);
  uint64_t v47 = *(void *)(a2 + 32);
  uint64_t v42 = *(void **)(a2 + 40);
  char v5 = *(unsigned char *)(a2 + 80);
  char v6 = *(unsigned char *)(a2 + 96);
  uint64_t v50 = *(void **)(a2 + 112);
  uint64_t v44 = *(void *)(a1 + 48);
  char v43 = *(void **)(a1 + 56);
  uint64_t v52 = 0x7974706D65;
  if (*(unsigned char *)(a1 + 80))
  {
    if ((v5 & 1) == 0)
    {
      uint64_t v55 = 0x7974706D65;
      v60._uint64_t countAndFlagsBits = 0xE500000000000000;
      goto LABEL_10;
    }
  }
  else if (v5 & 1 | (*(void *)(a1 + 72) != *(void *)(a2 + 72)))
  {
    uint64_t v55 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    v60._uint64_t countAndFlagsBits = v12;
    BOOL v13 = (v5 & 1) == 0;
    unint64_t v14 = 0xE500000000000000;
    uint64_t v15 = 0x7974706D65;
    if (!v13)
    {
LABEL_11:
      uint64_t v7 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v7, 0, 0);
      *(void *)uint64_t v8 = 0x6953206863746142;
      *(void *)(v8 + 8) = 0xEA0000000000657ALL;
      *(void *)(v8 + 16) = v55;
      *(void *)(v8 + 24) = v60._countAndFlagsBits;
      *(void *)(v8 + 32) = v15;
      *(void *)(v8 + 40) = v14;
LABEL_25:
      *(unsigned char *)(v8 + 48) = 3;
      return swift_willThrow(&type metadata for MLCreateError, v7, v8, v9, v10, v11);
    }
LABEL_10:
    uint64_t v15 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    unint64_t v14 = v16;
    goto LABEL_11;
  }
  if (*(unsigned char *)(a1 + 96))
  {
    uint64_t v17 = 0x7974706D65;
    unint64_t v46 = 0xE500000000000000;
    if (v6) {
      goto LABEL_19;
    }
    goto LABEL_17;
  }
  unint64_t v18 = 0xE500000000000000;
  if (v6 & 1 | (*(void *)(a1 + 88) != *(void *)(a2 + 88)))
  {
    char v19 = *(unsigned char *)(a2 + 96);
    uint64_t v17 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    unint64_t v46 = v20;
    if (v19)
    {
LABEL_18:
      uint64_t v7 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v7, 0, 0);
      *(void *)uint64_t v8 = 0x657449202E78614DLL;
      *(void *)(v8 + 8) = 0xEF736E6F69746172;
      *(void *)(v8 + 16) = v17;
      *(void *)(v8 + 24) = v46;
      *(void *)(v8 + 32) = v52;
      *(void *)(v8 + 40) = v18;
      goto LABEL_25;
    }
LABEL_17:
    uint64_t v52 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    unint64_t v18 = v21;
    goto LABEL_18;
  }
LABEL_19:
  if (*(void *)(a1 + 104) != *(void *)(a2 + 104) || *(void **)(a1 + 112) != v50)
  {
    *(void *)&long long v58 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    *((void *)&v58 + 1) = v33;
    v34._unsigned __int8 object = (void *)0xE200000000000000;
    v34._uint64_t countAndFlagsBits = 8236;
    String.append(_:)(v34);
    uint64_t v35 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char v37 = (char)v36;
    v34._uint64_t countAndFlagsBits = v35;
    v34._unsigned __int8 object = v36;
    String.append(_:)(v34);
    swift_bridgeObjectRelease(v37);
    long long v54 = v58;
    *(void *)&long long v58 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    *((void *)&v58 + 1) = v38;
    v34._uint64_t countAndFlagsBits = 8236;
    v34._unsigned __int8 object = (void *)0xE200000000000000;
    String.append(_:)(v34);
    v60._unsigned __int8 object = v50;
    uint64_t v39 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char v41 = (char)v40;
    v34._uint64_t countAndFlagsBits = v39;
    v34._unsigned __int8 object = v40;
    String.append(_:)(v34);
    swift_bridgeObjectRelease(v41);
    uint64_t v7 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v7, 0, 0);
    *(void *)uint64_t v8 = 0x7A69532064697247;
    *(void *)(v8 + 8) = 0xE900000000000065;
    *(_OWORD *)(v8 + 16) = v54;
    *(_OWORD *)(v8 + 32) = v58;
    goto LABEL_25;
  }
  uint64_t v51 = *(void **)(a2 + 56);
  v60._uint64_t countAndFlagsBits = *(void *)(a2 + 48);
  char v22 = v62;
  v62 &= 1u;
  char v23 = v4;
  outlined copy of Result<_DataTable, Error>((uint64_t)v3, v22);
  MLDataTable.subscript.getter(v48);
  char v49 = v22;
  outlined consume of Result<_DataTable, Error>((uint64_t)v3, v22);
  v60._unsigned __int8 object = v57;
  char v61 = v59;
  uint64_t v56 = Array<A>.init(_:)((uint64_t)&v60._object, a3);
  v60._unsigned __int8 object = v45;
  char v61 = v23 & 1;
  outlined copy of Result<_DataTable, Error>((uint64_t)v45, v23);
  v24._uint64_t countAndFlagsBits = v47;
  v24._unsigned __int8 object = v42;
  MLDataTable.subscript.getter(v24);
  outlined consume of Result<_DataTable, Error>((uint64_t)v45, v23);
  v60._unsigned __int8 object = v57;
  char v61 = v59;
  uint64_t v25 = Array<A>.init(_:)((uint64_t)&v60._object, a3);
  char v26 = (char)v25;
  char v27 = specialized static Array<A>.== infix(_:_:)((uint64_t)v56, (uint64_t)v25);
  swift_bridgeObjectRelease((_BYTE)v56);
  swift_bridgeObjectRelease(v26);
  if ((v27 & 1) == 0) {
    goto LABEL_23;
  }
  v60._unsigned __int8 object = v3;
  char v61 = v62;
  outlined copy of Result<_DataTable, Error>((uint64_t)v3, v49);
  v28._uint64_t countAndFlagsBits = v44;
  v28._unsigned __int8 object = v43;
  MLDataTable.subscript.getter(v28);
  outlined consume of Result<_DataTable, Error>((uint64_t)v3, v49);
  v60._unsigned __int8 object = v57;
  char v61 = v59;
  __int16 v53 = Array<A>.init(_:)((uint64_t)&v60._object, a3);
  v60._unsigned __int8 object = v45;
  char v61 = v23 & 1;
  outlined copy of Result<_DataTable, Error>((uint64_t)v45, v23);
  v28._uint64_t countAndFlagsBits = v60._countAndFlagsBits;
  v28._unsigned __int8 object = v51;
  MLDataTable.subscript.getter(v28);
  outlined consume of Result<_DataTable, Error>((uint64_t)v45, v23);
  v60._unsigned __int8 object = v57;
  char v61 = v59;
  uint64_t v29 = Array<A>.init(_:)((uint64_t)&v60._object, a3);
  char v30 = (char)v29;
  char v31 = specialized static Array<A>.== infix(_:_:)((uint64_t)v53, (uint64_t)v29);
  swift_bridgeObjectRelease((_BYTE)v53);
  uint64_t result = swift_bridgeObjectRelease(v30);
  if ((v31 & 1) == 0)
  {
LABEL_23:
    uint64_t v7 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v7, 0, 0);
    *(void *)uint64_t v8 = 1;
    *(_OWORD *)(v8 + 8) = 0;
    *(_OWORD *)(v8 + 24) = 0;
    *(void *)(v8 + 40) = 0;
    *(unsigned char *)(v8 + 48) = 4;
    return swift_willThrow(&type metadata for MLCreateError, v7, v8, v9, v10, v11);
  }
  return result;
}

uint64_t ObjectDetectorTrainingSessionDelegate.deinit()
{
  swift_bridgeObjectRelease(*(void *)(v0 + 24));
  outlined destroy of MLActivityClassifier.ModelParameters(v0 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of MLObjectDetector.PersistentParameters?(v0 + OBJC_IVAR____TtC8CreateML37ObjectDetectorTrainingSessionDelegate_trainingParameters, (uint64_t)v2);
  outlined release of MLObjectDetector.PersistentParameters?(v2);
  swift_release();
  swift_release();
  return v0;
}

uint64_t ObjectDetectorTrainingSessionDelegate.__deallocating_deinit()
{
  ObjectDetectorTrainingSessionDelegate.deinit();
  return swift_deallocClassInstance(v0, *(unsigned int *)(*(void *)v0 + 48), *(unsigned __int16 *)(*(void *)v0 + 52));
}

uint64_t ObjC metadata update function for ObjectDetectorTrainingSessionDelegate()
{
  return type metadata accessor for ObjectDetectorTrainingSessionDelegate(0);
}

uint64_t type metadata accessor for ObjectDetectorTrainingSessionDelegate(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for ObjectDetectorTrainingSessionDelegate;
  if (!type metadata singleton initialization cache for ObjectDetectorTrainingSessionDelegate) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for ObjectDetectorTrainingSessionDelegate);
  }
  return result;
}

uint64_t type metadata completion function for ObjectDetectorTrainingSessionDelegate(uint64_t a1)
{
  v3[0] = &unk_351218;
  uint64_t result = type metadata accessor for MLTrainingSessionParameters(319);
  if (v2 <= 0x3F)
  {
    v3[1] = *(void *)(result - 8) + 64;
    v3[2] = &unk_351230;
    v3[3] = (char *)&value witness table for Builtin.NativeObject + 64;
    void v3[4] = (char *)&value witness table for Builtin.NativeObject + 64;
    uint64_t result = swift_updateClassMetadata2(a1, 256, 5, v3, a1 + 80);
    if (!result) {
      return 0;
    }
  }
  return result;
}

void protocol witness for TrainingSessionDelegate.setUp() in conformance ObjectDetectorTrainingSessionDelegate()
{
}

void protocol witness for TrainingSessionDelegate.resume(from:) in conformance ObjectDetectorTrainingSessionDelegate(Swift::OpaquePointer a1)
{
}

unint64_t protocol witness for TrainingSessionDelegate.itemCount(phase:) in conformance ObjectDetectorTrainingSessionDelegate(CreateML::MLPhase a1)
{
  return (unint64_t)ObjectDetectorTrainingSessionDelegate.itemCount(phase:)(a1);
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance ObjectDetectorTrainingSessionDelegate(Swift::Int a1)
{
  Swift::tuple_Int_metrics_OpaquePointer_finished_Bool v9 = ObjectDetectorTrainingSessionDelegate.train(from:)(a1);
  if (v4)
  {
    char v5 = *(uint64_t (**)(uint64_t, uint64_t, void))(v1 + 8);
    uint64_t v6 = v1;
  }
  else
  {
    uint64_t rawValue = v9.metrics._rawValue;
    char v5 = *(uint64_t (**)(uint64_t, uint64_t, void))(v1 + 8);
    BOOL finished = v9.finished;
    uint64_t v6 = v1;
    v9.metrics._uint64_t rawValue = (void *)v9._0;
    *(void *)&v9.BOOL finished = rawValue;
  }
  return protocol witness for TrainingSessionDelegate.train(from:) in conformance MLStyleTransfer.TrainingSessionDelegate(v5, v6, (uint64_t)v9.metrics._rawValue, *(uint64_t *)&v9.finished, finished);
}

uint64_t protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance ObjectDetectorTrainingSessionDelegate(Swift::Int a1)
{
  *(Swift::tuple_Int_finished_Bool *)&long long v2 = ObjectDetectorTrainingSessionDelegate.evaluate(from:)(a1);
  if (!v4)
  {
    *((void *)&v2 + 1) = 1;
    unsigned int v3 = 1;
  }
  return protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(*(uint64_t (**)(uint64_t, void))(v1 + 8), v1, *((uint64_t *)&v2 + 1), v3);
}

uint64_t protocol witness for TrainingSessionDelegate.saveCheckpoint(to:phase:iteration:) in conformance ObjectDetectorTrainingSessionDelegate(uint64_t a1, unsigned __int8 *a2)
{
  return ObjectDetectorTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)(a1, a2);
}

NSURL *protocol witness for TrainingSessionCodable.save(to:) in conformance ObjectDetectorTrainingSessionDelegate(uint64_t a1)
{
  return ObjectDetectorTrainingSessionDelegate.save(to:)(a1);
}

uint64_t *protocol witness for TrainingSessionCodable.restore(from:phase:) in conformance ObjectDetectorTrainingSessionDelegate(uint64_t a1, double a2)
{
  return ObjectDetectorTrainingSessionDelegate.restore(from:phase:)(a1, a2);
}

uint64_t outlined init with take of MLObjectDetector.PersistentParameters?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLObjectDetector.PersistentParameters?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t *outlined release of MLObjectDetector.PersistentParameters?(uint64_t *a1)
{
  return a1;
}

uint64_t outlined consume of MLObjectDetector.PersistentParameters?(uint64_t a1, char a2, uint64_t a3, char a4, uint64_t a5, uint64_t a6, uint64_t a7, char a8)
{
  if (a6)
  {
    char v8 = a6;
    outlined consume of Result<_DataTable, Error>(a1, a2 & 1);
    outlined consume of MLDataTable?(a3, a4);
    swift_bridgeObjectRelease(a8);
    return swift_bridgeObjectRelease(v8);
  }
  return result;
}

uint64_t outlined retain of MLObjectDetector.PersistentParameters(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 16);
  uint64_t v2 = *(void *)(a1 + 40);
  uint64_t v3 = *(void *)(a1 + 56);
  int v4 = *(_DWORD *)(a1 + 24);
  outlined copy of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
  outlined copy of MLDataTable?(v1, v4);
  swift_bridgeObjectRetain(v2);
  swift_bridgeObjectRetain(v3);
  return a1;
}

uint64_t outlined destroy of MLCheckpoint?(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t _s8CreateML16MLObjectDetectorV20PersistentParametersVSgWOi0_(uint64_t a1)
{
  return __bzero(a1, 129);
}

uint64_t getEnumTagSinglePayload for ModelType(unsigned __int8 *a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 < 0xE5) {
      goto LABEL_13;
    }
    unsigned int v2 = a2 + 27;
    int v3 = 1;
    if (v2 >= 0xFF00) {
      int v3 = 2 * (v2 >= 0xFFFF00) + 2;
    }
    if (v3 == 4) {
      int v4 = *(_DWORD *)(a1 + 1);
    }
    else {
      int v4 = v3 == 2 ? *(unsigned __int16 *)(a1 + 1) : a1[1];
    }
    if (v4)
    {
      int v5 = *a1 + (v4 << 8) - 28;
    }
    else
    {
LABEL_13:
      unsigned int v6 = *a1;
      int v7 = v6 - 28;
      BOOL v8 = v6 < 0x1C;
      int v5 = -1;
      if (!v8) {
        int v5 = v7;
      }
    }
  }
  else
  {
    int v5 = -1;
  }
  return (v5 + 1);
}

uint64_t storeEnumTagSinglePayload for ModelType(unsigned char *a1, unsigned int a2, unsigned int a3)
{
  LODWORD(result) = 0;
  if (a3 >= 0xE5)
  {
    unsigned int v4 = a3 + 27;
    LODWORD(result) = 1;
    if (v4 >= 0xFF00) {
      LODWORD(result) = 2 * (v4 >= 0xFFFF00) + 2;
    }
  }
  if (a2 > 0xE4)
  {
    unsigned int v5 = a2 - 229;
    int v6 = (v5 >> 8) + 1;
    *a1 = v5;
    uint64_t result = result;
    switch((int)result)
    {
      case 0:
        return result;
      case 1:
        a1[1] = v6;
        break;
      case 2:
        *(_WORD *)(a1 + 1) = v6;
        break;
      case 3:
LABEL_16:
        BUG();
      case 4:
        *(_DWORD *)(a1 + 1) = v6;
        break;
    }
  }
  else
  {
    uint64_t result = result;
    switch((int)result)
    {
      case 0:
        goto LABEL_11;
      case 1:
        a1[1] = 0;
        goto LABEL_11;
      case 2:
        *(_WORD *)(a1 + 1) = 0;
        goto LABEL_11;
      case 3:
        goto LABEL_16;
      case 4:
        *(_DWORD *)(a1 + 1) = 0;
LABEL_11:
        if (a2) {
          *a1 = a2 + 27;
        }
        break;
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for ModelType()
{
  return &type metadata for ModelType;
}

uint64_t base witness table accessor for Equatable in ModelType()
{
  return lazy protocol witness table accessor for type ModelType and conformance ModelType();
}

uint64_t lazy protocol witness table accessor for type ModelType and conformance ModelType()
{
  uint64_t result = lazy protocol witness table cache variable for type ModelType and conformance ModelType;
  if (!lazy protocol witness table cache variable for type ModelType and conformance ModelType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ModelType, &type metadata for ModelType);
    lazy protocol witness table cache variable for type ModelType and conformance ModelType = result;
  }
  return result;
}

unint64_t ModelType.description.getter(char a1)
{
  unint64_t result = 0xD000000000000015;
  switch(a1)
  {
    case 0:
    case 2:
    case 5:
    case 21:
    case 24:
      return result;
    case 1:
    case 3:
    case 20:
      unint64_t result = 0xD000000000000016;
      break;
    case 4:
    case 25:
      unint64_t result = 0xD000000000000014;
      break;
    case 6:
    case 7:
      unint64_t result = 0x65527261656E694CLL;
      break;
    case 8:
    case 9:
      unint64_t result = 0xD00000000000001CLL;
      break;
    case 10:
      unint64_t result = 0xD000000000000017;
      break;
    case 11:
      unint64_t result = 0xD000000000000019;
      break;
    case 12:
      unint64_t result = 0x616C436567616D49;
      break;
    case 13:
      unint64_t result = 0xD000000000000011;
      break;
    case 14:
      unint64_t result = 0x617254656C797453;
      break;
    case 15:
      unint64_t result = 0x73616C4374786554;
      break;
    case 16:
      unint64_t result = 0x6767615464726F57;
      break;
    case 17:
      unint64_t result = 0x65447463656A624FLL;
      break;
    case 18:
    case 23:
      unint64_t result = 0xD000000000000012;
      break;
    case 19:
      unint64_t result = 0x616C43646E756F53;
      break;
    case 22:
      unint64_t result = 0xD000000000000010;
      break;
    case 26:
      unint64_t result = 0x65657474657A6147;
      break;
    case 27:
      unint64_t result = 0x65626D4564726F57;
      break;
  }
  return result;
}

unint64_t ModelType.nameKey.getter(char a1)
{
  unint64_t result = 0xD000000000000018;
  switch(a1)
  {
    case 0:
    case 1:
    case 2:
    case 3:
    case 4:
    case 5:
      return result;
    case 6:
      unint64_t result = 0xD00000000000001CLL;
      break;
    case 7:
      unint64_t result = 0xD00000000000001FLL;
      break;
    case 8:
      unint64_t result = 0xD00000000000001ELL;
      break;
    case 9:
      unint64_t result = 0xD000000000000021;
      break;
    case 10:
      unint64_t result = 0x6966697373616C63;
      break;
    case 11:
      unint64_t result = 0x6D69735F6D657469;
      break;
    case 12:
    case 19:
      unint64_t result = 0xD000000000000010;
      break;
    case 13:
    case 16:
      unint64_t result = 0xD000000000000012;
      break;
    case 14:
      unint64_t result = 0x72745F656C797473;
      break;
    case 15:
    case 23:
      unint64_t result = 0xD000000000000014;
      break;
    case 17:
      unint64_t result = 0xD000000000000011;
      break;
    case 18:
      unint64_t result = 0xD000000000000013;
      break;
    case 20:
      unint64_t result = 0xD000000000000019;
      break;
    case 21:
    case 22:
    case 24:
      unint64_t result = 0xD000000000000017;
      break;
    case 25:
      unint64_t result = 0xD000000000000016;
      break;
    case 26:
      unint64_t result = 0x65657474657A6167;
      break;
    case 27:
      unint64_t result = 0x626D655F64726F77;
      break;
  }
  return result;
}

CreateML::ModelType_optional __swiftcall ModelType.init(nameKey:)(Swift::String nameKey)
{
  uint64_t countAndFlagsBits = nameKey._countAndFlagsBits;
  if (nameKey._countAndFlagsBits == 0xD000000000000018)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("object_recognizer" + 0x8000000000000000);
    if (nameKey._object == "object_recognizer" + 0x8000000000000000) {
      goto LABEL_5;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000018, "object_recognizer" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
LABEL_5:
    swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
    return (CreateML::ModelType_optional)2;
  }
  if (countAndFlagsBits == 0xD000000000000018)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("decision_tree_regression" + 0x8000000000000000);
    if (nameKey._object == "decision_tree_regression" + 0x8000000000000000)
    {
LABEL_11:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)3;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000018, "decision_tree_regression" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_11;
  }
  if (countAndFlagsBits == 0xD000000000000018)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("decision_tree_classifier" + 0x8000000000000000);
    if (nameKey._object == "decision_tree_classifier" + 0x8000000000000000)
    {
LABEL_16:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)4;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000018, "decision_tree_classifier" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_16;
  }
  if (countAndFlagsBits == 0xD000000000000018)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("boosted_trees_regression" + 0x8000000000000000);
    if (nameKey._object == "boosted_trees_regression" + 0x8000000000000000)
    {
LABEL_21:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)5;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000018, "boosted_trees_regression" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_21;
  }
  if (countAndFlagsBits == 0xD000000000000018)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("boosted_trees_classifier" + 0x8000000000000000);
    if (nameKey._object == "boosted_trees_classifier" + 0x8000000000000000)
    {
LABEL_26:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return 0;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000018, "boosted_trees_classifier" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_26;
  }
  if (countAndFlagsBits == 0xD000000000000018)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("random_forest_regression" + 0x8000000000000000);
    if (nameKey._object == "random_forest_regression" + 0x8000000000000000)
    {
LABEL_31:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)1;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000018, "random_forest_regression" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_31;
  }
  if (countAndFlagsBits == 0xD00000000000001CLL && nameKey._object == "random_forest_classifier" + 0x8000000000000000)
  {
    unsigned __int8 object = "random_forest_classifier" + 0x8000000000000000;
LABEL_37:
    swift_bridgeObjectRelease(object);
    return (CreateML::ModelType_optional)6;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD00000000000001CLL, "random_forest_classifier" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    unsigned __int8 object = (char *)nameKey._object;
    goto LABEL_37;
  }
  if (countAndFlagsBits == 0xD00000000000001FLL
    && nameKey._object == "regression_linear_regression" + 0x8000000000000000)
  {
    unsigned int v4 = "regression_linear_regression" + 0x8000000000000000;
LABEL_43:
    swift_bridgeObjectRelease(v4);
    return (CreateML::ModelType_optional)7;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD00000000000001FLL, "regression_linear_regression" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    unsigned int v4 = (char *)nameKey._object;
    goto LABEL_43;
  }
  if (countAndFlagsBits == 0xD00000000000001ELL
    && nameKey._object == "regression_linear_regression_v2" + 0x8000000000000000)
  {
    unsigned int v5 = "regression_linear_regression_v2" + 0x8000000000000000;
LABEL_49:
    swift_bridgeObjectRelease(v5);
    return (CreateML::ModelType_optional)8;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD00000000000001ELL, "regression_linear_regression_v2" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    unsigned int v5 = (char *)nameKey._object;
    goto LABEL_49;
  }
  if (countAndFlagsBits == 0xD000000000000021
    && nameKey._object == "classifier_logistic_regression" + 0x8000000000000000)
  {
    int v6 = "classifier_logistic_regression" + 0x8000000000000000;
LABEL_55:
    swift_bridgeObjectRelease(v6);
    return (CreateML::ModelType_optional)9;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000021, "classifier_logistic_regression" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    int v6 = (char *)nameKey._object;
    goto LABEL_55;
  }
  if (countAndFlagsBits == 0x6966697373616C63 && nameKey._object == (void *)0xEE006D76735F7265)
  {
    int v7 = (void *)0xEE006D76735F7265;
LABEL_61:
    swift_bridgeObjectRelease(v7);
    return (CreateML::ModelType_optional)10;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0x6966697373616C63, 0xEE006D76735F7265, countAndFlagsBits, nameKey._object, 0))
  {
    int v7 = nameKey._object;
    goto LABEL_61;
  }
  if (countAndFlagsBits == 0x6D69735F6D657469 && nameKey._object == (void *)0xEF79746972616C69)
  {
    BOOL v8 = (void *)0xEF79746972616C69;
LABEL_67:
    swift_bridgeObjectRelease(v8);
    return (CreateML::ModelType_optional)11;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0x6D69735F6D657469, 0xEF79746972616C69, countAndFlagsBits, nameKey._object, 0))
  {
    BOOL v8 = nameKey._object;
    goto LABEL_67;
  }
  if (countAndFlagsBits == 0xD000000000000010)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("tic_regression_v2" + 0x8000000000000000);
    if (nameKey._object == "tic_regression_v2" + 0x8000000000000000)
    {
LABEL_72:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)12;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000010, "tic_regression_v2" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_72;
  }
  if (countAndFlagsBits == 0xD000000000000012)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("image_classifier" + 0x8000000000000000);
    if (nameKey._object == "image_classifier" + 0x8000000000000000)
    {
LABEL_77:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)13;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000012, "image_classifier" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_77;
  }
  if (countAndFlagsBits == 0x72745F656C797473 && nameKey._object == (void *)0xEE00726566736E61)
  {
    Swift::tuple_Int_metrics_OpaquePointer_finished_Bool v9 = (void *)0xEE00726566736E61;
LABEL_83:
    swift_bridgeObjectRelease(v9);
    return (CreateML::ModelType_optional)14;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0x72745F656C797473, 0xEE00726566736E61, countAndFlagsBits, nameKey._object, 0))
  {
    Swift::tuple_Int_metrics_OpaquePointer_finished_Bool v9 = nameKey._object;
    goto LABEL_83;
  }
  if (countAndFlagsBits == 0xD000000000000012)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("drawing_classifier" + 0x8000000000000000);
    if (nameKey._object == "drawing_classifier" + 0x8000000000000000)
    {
LABEL_88:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)16;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000012, "drawing_classifier" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_88;
  }
  if (countAndFlagsBits == 0xD000000000000014)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("nlp_sequence_model" + 0x8000000000000000);
    if (nameKey._object == "nlp_sequence_model" + 0x8000000000000000)
    {
LABEL_93:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)15;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000014, "nlp_sequence_model" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_93;
  }
  if (countAndFlagsBits == 0xD000000000000011 && nameKey._object == "on type changed." + 0x8000000000000000)
  {
    uint64_t v10 = "on type changed." + 0x8000000000000000;
LABEL_99:
    swift_bridgeObjectRelease(v10);
    return (CreateML::ModelType_optional)17;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000011, "on type changed." + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    uint64_t v10 = (char *)nameKey._object;
    goto LABEL_99;
  }
  if (countAndFlagsBits == 0xD000000000000013
    && nameKey._object == "ot found in Configuration" + 0x8000000000000000)
  {
    uint64_t v11 = "ot found in Configuration" + 0x8000000000000000;
LABEL_105:
    swift_bridgeObjectRelease(v11);
    return (CreateML::ModelType_optional)18;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000013, "ot found in Configuration" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    uint64_t v11 = (char *)nameKey._object;
    goto LABEL_105;
  }
  if (countAndFlagsBits == 0xD000000000000010)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("rt a new session" + 0x8000000000000000);
    if (nameKey._object == "rt a new session" + 0x8000000000000000)
    {
LABEL_110:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)19;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000010, "rt a new session" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_110;
  }
  if (countAndFlagsBits == 0xD000000000000019 && nameKey._object == "nlp_classifier_model" + 0x8000000000000000)
  {
    uint64_t v12 = "nlp_classifier_model" + 0x8000000000000000;
LABEL_116:
    swift_bridgeObjectRelease(v12);
    return (CreateML::ModelType_optional)20;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000019, "nlp_classifier_model" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    uint64_t v12 = (char *)nameKey._object;
    goto LABEL_116;
  }
  if (countAndFlagsBits == 0xD000000000000017)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("training_accuracy" + 0x8000000000000000);
    if (nameKey._object == "training_accuracy" + 0x8000000000000000)
    {
LABEL_122:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)22;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000017, "training_accuracy" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0) & 1) != 0|| (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000017, "training_accuracy" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_122;
  }
  if (countAndFlagsBits == 0xD000000000000014)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("few_shot_sound_classifier" + 0x8000000000000000);
    if (nameKey._object == "few_shot_sound_classifier" + 0x8000000000000000)
    {
LABEL_127:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)23;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000014, "few_shot_sound_classifier" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_127;
  }
  if (countAndFlagsBits == 0xD000000000000017)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("hand_pose_classifier" + 0x8000000000000000);
    if (nameKey._object == "hand_pose_classifier" + 0x8000000000000000)
    {
LABEL_132:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)24;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000017, "hand_pose_classifier" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_132;
  }
  if (countAndFlagsBits == 0xD000000000000016)
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)("hand_gesture_classifier" + 0x8000000000000000);
    if (nameKey._object == "hand_gesture_classifier" + 0x8000000000000000)
    {
LABEL_137:
      swift_bridgeObjectRelease(nameKey._countAndFlagsBits);
      return (CreateML::ModelType_optional)25;
    }
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0xD000000000000016, "hand_gesture_classifier" + 0x8000000000000000, countAndFlagsBits, nameKey._object, 0))
  {
    nameKey._uint64_t countAndFlagsBits = (uint64_t)nameKey._object;
    goto LABEL_137;
  }
  if (countAndFlagsBits == 0x65657474657A6167 && nameKey._object == (void *)0xE900000000000072)
  {
    BOOL v13 = (void *)0xE900000000000072;
LABEL_143:
    swift_bridgeObjectRelease(v13);
    return (CreateML::ModelType_optional)26;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0x65657474657A6167, 0xE900000000000072, countAndFlagsBits, nameKey._object, 0))
  {
    BOOL v13 = nameKey._object;
    goto LABEL_143;
  }
  if (countAndFlagsBits == 0x626D655F64726F77 && nameKey._object == (void *)0xEE00676E69646465)
  {
    swift_bridgeObjectRelease(0xEE00676E69646465);
    return (CreateML::ModelType_optional)27;
  }
  else
  {
    char v14 = _stringCompareWithSmolCheck(_:_:expecting:)(0x626D655F64726F77, 0xEE00676E69646465, countAndFlagsBits, nameKey._object, 0);
    swift_bridgeObjectRelease(nameKey._object);
    return (CreateML::ModelType_optional)(28 - (v14 & 1));
  }
}

uint64_t ModelType.playgroundDescription.getter(char a1)
{
  unsigned int v2 = v1;
  unint64_t v3 = ModelType.description.getter(a1);
  char v5 = v4;
  objc_allocWithZone((Class)NSAttributedString);
  id v6 = @nonobjc NSAttributedString.init(string:attributes:)(v3, v5, 0);
  uint64_t result = type metadata accessor for NSAttributedString();
  v2[3] = result;
  void *v2 = v6;
  return result;
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance ModelType()
{
  return ModelType.description.getter(*v0);
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance ModelType()
{
  return ModelType.playgroundDescription.getter(*v0);
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySo8NSNumberCG_Sis5NeverOTg5071_s8CreateML16ColumnDescriptorV0c4TypeD0OyAESgSo12MLMultiArrayCKcfcSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_nTm(uint64_t a1)
{
  if ((a1 & 0x4000000000000001) != 0)
  {
    uint64_t v10 = a1 & 0xFFFFFFFFFFFFF8;
    if (a1) {
      uint64_t v10 = a1;
    }
    swift_bridgeObjectRetain(a1);
    uint64_t v1 = _CocoaArrayWrapper.endIndex.getter(v10);
    swift_bridgeObjectRelease(a1);
  }
  else
  {
    uint64_t v1 = *(void *)((char *)&dword_10 + (a1 & 0xFFFFFFFFFFFFF8));
  }
  if (v1)
  {
    int64_t v2 = 0;
    if (v1 > 0) {
      int64_t v2 = v1;
    }
    uint64_t v12 = v1;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    uint64_t v3 = v1;
    if (v1 < 0) {
      BUG();
    }
    uint64_t v4 = 0;
    do
    {
      if (v3 == v4) {
        BUG();
      }
      if ((a1 & 0xC000000000000003) != 0) {
        id v5 = (id)specialized _ArrayBuffer._getElementSlowPath(_:)(v4, a1);
      }
      else {
        id v5 = *(id *)(a1 + 8 * v4 + 32);
      }
      id v6 = v5;
      id v11 = [v5 integerValue];

      unint64_t v7 = _swiftEmptyArrayStorage[2];
      unint64_t v8 = v7 + 1;
      if (_swiftEmptyArrayStorage[3] >> 1 <= v7)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v7 + 1, 1);
        unint64_t v8 = v7 + 1;
      }
      ++v4;
      _swiftEmptyArrayStorage[2] = v8;
      _swiftEmptyArrayStorage[v7 + 4] = v11;
      uint64_t v3 = v12;
    }
    while (v12 != v4);
  }
  return _swiftEmptyArrayStorage;
}

uint64_t ColumnDescriptor.ColumnTypeDescriptor.featureSize.getter(uint64_t a1, char a2)
{
  uint64_t v2 = a1;
  switch(a2)
  {
    case 0:
    case 1:
    case 2:
    case 3:
      return v2;
    case 4:
      return *(void *)(a1 + 16);
    case 5:
      int64_t v4 = *(void *)(a1 + 16);
      if (v4)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v4, 0);
        id v5 = (unsigned __int8 *)(a1 + 56);
        do
        {
          int64_t v13 = v4;
          uint64_t v6 = *((void *)v5 - 2);
          uint64_t v7 = *((void *)v5 - 1);
          unsigned int v8 = *v5;
          swift_bridgeObjectRetain(v6);
          outlined copy of ColumnDescriptor.ColumnTypeDescriptor(v7, v8);
          uint64_t v14 = ColumnDescriptor.ColumnTypeDescriptor.featureSize.getter(v7, v8);
          swift_bridgeObjectRelease(v6);
          outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v7, v8);
          unint64_t v9 = _swiftEmptyArrayStorage[2];
          unint64_t v10 = v9 + 1;
          if (_swiftEmptyArrayStorage[3] >> 1 <= v9) {
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v9 + 1, 1);
          }
          _swiftEmptyArrayStorage[2] = v10;
          _swiftEmptyArrayStorage[v9 + 4] = v14;
          v5 += 32;
          int64_t v4 = v13 - 1;
        }
        while (v13 != 1);
      }
      else
      {
        unint64_t v10 = _swiftEmptyArrayStorage[2];
        if (!v10)
        {
          swift_bridgeObjectRelease(_swiftEmptyArrayStorage);
          return 0;
        }
      }
      uint64_t v11 = 0;
      uint64_t v2 = 0;
      do
      {
        BOOL v12 = __OFADD__(_swiftEmptyArrayStorage[v11 + 4], v2);
        v2 += _swiftEmptyArrayStorage[v11 + 4];
        if (v12) {
          BUG();
        }
        ++v11;
      }
      while (v10 != v11);
      swift_bridgeObjectRelease(_swiftEmptyArrayStorage);
      return v2;
    case 6:
      return 1;
  }
}

uint64_t ColumnDescriptor.featureDescription.getter(uint64_t a1, uint64_t a2, uint64_t a3, char a4)
{
  uint64_t v28 = a3;
  uint64_t v29 = a2;
  uint64_t v32 = a1;
  uint64_t v33 = v4;
  uint64_t v6 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType(0);
  uint64_t v27 = *(void *)(v6 - 8);
  int64_t v7 = *(void *)(v27 + 64);
  unsigned int v8 = alloca(v7);
  unint64_t v9 = alloca(v7);
  uint64_t v10 = type metadata accessor for FeatureType(0);
  uint64_t v11 = *(void *)(v10 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  int64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  switch(a4)
  {
    case 0:
      uint64_t v15 = (unsigned int *)&enum case for FeatureType.ShapedArrayParameters.DataType.int32(_:);
      goto LABEL_6;
    case 1:
      uint64_t v15 = (unsigned int *)&enum case for FeatureType.ShapedArrayParameters.DataType.float16(_:);
      goto LABEL_6;
    case 2:
      uint64_t v15 = (unsigned int *)&enum case for FeatureType.ShapedArrayParameters.DataType.float32(_:);
      goto LABEL_6;
    case 3:
      uint64_t v15 = (unsigned int *)&enum case for FeatureType.ShapedArrayParameters.DataType.double(_:);
LABEL_6:
      uint64_t v16 = *v15;
      char v31 = &v27;
      uint64_t v30 = v6;
      uint64_t v17 = v6;
      uint64_t v18 = v27;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v27 + 104))(&v27, v16, v17);
      uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
      unint64_t v20 = (void *)swift_allocObject(v19, 40, 7);
      void v20[2] = 1;
      v20[3] = 2;
      void v20[4] = v28;
      uint64_t v21 = v29;
      swift_bridgeObjectRetain(v29);
      char v22 = v31;
      static FeatureType.shapedArray(dataType:shape:optional:)(&v27, v20, 0);
      swift_bridgeObjectRelease((_BYTE)v20);
      (*(void (**)(uint64_t *, uint64_t))(v18 + 8))(&v27, v30);
      goto LABEL_7;
    case 4:
      uint64_t v21 = v29;
      char v22 = &v27;
      swift_bridgeObjectRetain(v29);
      FeatureType.StringParameters.init(optional:)(0);
      (*(void (**)(uint64_t *, void, uint64_t))(v11 + 104))(&v27, enum case for FeatureType.string(_:), v10);
LABEL_7:
      uint64_t v23 = v32;
      Swift::String v24 = v22;
      break;
    case 5:
      uint64_t v21 = v29;
      swift_bridgeObjectRetain(v29);
      static FeatureType.dictionaryWithStringKeys(optional:)(0);
      uint64_t v23 = v32;
      Swift::String v24 = &v27;
      break;
    case 6:
      uint64_t v21 = v29;
      swift_bridgeObjectRetain(v29);
      if (v28)
      {
        FeatureType.DoubleParameters.init(optional:)(0);
        char v26 = (unsigned int *)&enum case for FeatureType.double(_:);
      }
      else
      {
        FeatureType.IntParameters.init(optional:)(0);
        char v26 = (unsigned int *)&enum case for FeatureType.int(_:);
      }
      (*(void (**)(uint64_t *, void, uint64_t))(v11 + 104))(&v27, *v26, v10);
      Swift::String v24 = &v27;
      uint64_t v23 = v32;
      break;
  }
  return FeatureDescription.init(name:type:description:)(v23, v21, v24, 0, 0xE000000000000000);
}

uint64_t ColumnDescriptor.init(_:)(uint64_t a1)
{
  *(void *)&long long v308 = v1;
  uint64_t v296 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Any?]>);
  uint64_t v295 = *(void *)(v296 - 8);
  int64_t v2 = *(void *)(v295 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  v280 = &v244;
  id v5 = alloca(v2);
  uint64_t v6 = alloca(v2);
  v297 = &v244;
  uint64_t v299 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Float]>);
  uint64_t v298 = *(void *)(v299 - 8);
  int64_t v7 = *(void *)(v298 + 64);
  unsigned int v8 = alloca(v7);
  unint64_t v9 = alloca(v7);
  unint64_t v281 = &v244;
  uint64_t v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  v300 = &v244;
  uint64_t v302 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Double]>);
  uint64_t v301 = *(void *)(v302 - 8);
  int64_t v12 = *(void *)(v301 + 64);
  int64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  v282 = &v244;
  uint64_t v15 = alloca(v12);
  uint64_t v16 = alloca(v12);
  v303 = &v244;
  uint64_t v305 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Int32]>);
  uint64_t v304 = *(void *)(v305 - 8);
  int64_t v17 = *(void *)(v304 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  Swift::String v283 = &v244;
  unint64_t v20 = alloca(v17);
  uint64_t v21 = alloca(v17);
  v306 = &v244;
  uint64_t v293 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : UInt8]>);
  uint64_t v292 = *(void *)(v293 - 8);
  int64_t v22 = *(void *)(v292 + 64);
  uint64_t v23 = alloca(v22);
  Swift::String v24 = alloca(v22);
  v279 = &v244;
  uint64_t v25 = alloca(v22);
  char v26 = alloca(v22);
  v294 = &v244;
  uint64_t v290 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Int]>);
  uint64_t v289 = *(void *)(v290 - 8);
  int64_t v27 = *(void *)(v289 + 64);
  uint64_t v28 = alloca(v27);
  uint64_t v29 = alloca(v27);
  v278 = &v244;
  uint64_t v30 = alloca(v27);
  char v31 = alloca(v27);
  Swift::String v291 = &v244;
  uint64_t v276 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLMultiArray>);
  uint64_t v275 = *(void *)(v276 - 8);
  int64_t v32 = *(void *)(v275 + 64);
  uint64_t v33 = alloca(v32);
  Swift::String v34 = alloca(v32);
  v277 = &v244;
  int64_t v35 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>??)
                              - 8)
                  + 64);
  uint64_t v36 = alloca(v35);
  char v37 = alloca(v35);
  v286 = &v244;
  uint64_t v272 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLShapedArray<Double>>);
  uint64_t v271 = *(void *)(v272 - 8);
  int64_t v38 = *(void *)(v271 + 64);
  uint64_t v39 = alloca(v38);
  uint64_t v40 = alloca(v38);
  v274 = &v244;
  uint64_t v273 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>?);
  int64_t v41 = *(void *)(*(void *)(v273 - 8) + 64);
  uint64_t v42 = alloca(v41);
  char v43 = alloca(v41);
  char v288 = &v244;
  uint64_t v269 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Double]>);
  uint64_t v268 = *(void *)(v269 - 8);
  int64_t v44 = *(void *)(v268 + 64);
  uint64_t v45 = alloca(v44);
  unint64_t v46 = alloca(v44);
  char v270 = &v244;
  int64_t v47 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>??)
                              - 8)
                  + 64);
  Swift::String v48 = alloca(v47);
  char v49 = alloca(v47);
  Swift::String v285 = &v244;
  uint64_t v265 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLShapedArray<Float>>);
  uint64_t v264 = *(void *)(v265 - 8);
  int64_t v50 = *(void *)(v264 + 64);
  uint64_t v51 = alloca(v50);
  uint64_t v52 = alloca(v50);
  uint64_t v267 = &v244;
  uint64_t v266 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>?);
  int64_t v53 = *(void *)(*(void *)(v266 - 8) + 64);
  long long v54 = alloca(v53);
  uint64_t v55 = alloca(v53);
  Swift::String v287 = &v244;
  uint64_t v262 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Float]>);
  uint64_t v261 = *(void *)(v262 - 8);
  int64_t v56 = *(void *)(v261 + 64);
  char v57 = alloca(v56);
  long long v58 = alloca(v56);
  unint64_t v263 = &v244;
  int64_t v59 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Int32>??)
                              - 8)
                  + 64);
  Swift::String v60 = alloca(v59);
  char v61 = alloca(v59);
  unint64_t v255 = &v244;
  uint64_t v258 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLShapedArray<Int32>>);
  uint64_t v257 = *(void *)(v258 - 8);
  int64_t v62 = *(void *)(v257 + 64);
  uint64_t v63 = alloca(v62);
  uint64_t v64 = alloca(v62);
  char v260 = &v244;
  uint64_t v259 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Int32>?);
  int64_t v65 = *(void *)(*(void *)(v259 - 8) + 64);
  uint64_t v66 = alloca(v65);
  uint64_t v67 = alloca(v65);
  uint64_t v256 = &v244;
  uint64_t v253 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[UInt8]>);
  uint64_t v252 = *(void *)(v253 - 8);
  int64_t v68 = *(void *)(v252 + 64);
  uint64_t v69 = alloca(v68);
  __m128 v70 = alloca(v68);
  long long v254 = &v244;
  uint64_t v250 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int32]>);
  uint64_t v249 = *(void *)(v250 - 8);
  int64_t v71 = *(void *)(v249 + 64);
  Swift::Int v72 = alloca(v71);
  uint64_t v73 = alloca(v71);
  v251 = &v244;
  uint64_t v74 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int]>);
  uint64_t v247 = *(void *)(v74 - 8);
  int64_t v75 = *(void *)(v247 + 64);
  long long v76 = alloca(v75);
  long long v77 = alloca(v75);
  v248 = &v244;
  uint64_t v78 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v79 = *(void *)(v78 - 8);
  int64_t v80 = *(void *)(v79 + 64);
  char v81 = alloca(v80);
  uint64_t v82 = alloca(v80);
  v284 = &v244;
  int64_t v83 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>)
                              - 8)
                  + 64);
  uint64_t v84 = alloca(v83);
  uint64_t v85 = alloca(v83);
  uint64_t v246 = &v244;
  uint64_t v245 = AnyColumn.name.getter();
  uint64_t v309 = v86;
  uint64_t v310 = a1;
  uint64_t v87 = AnyColumn.wrappedElementType.getter();
  if (swift_dynamicCastMetatype(v87, &type metadata for Int)
    || swift_dynamicCastMetatype(v87, &type metadata for UInt8)
    || swift_dynamicCastMetatype(v87, &type metadata for Int32)
    || swift_dynamicCastMetatype(v87, &type metadata for Float)
    || swift_dynamicCastMetatype(v87, &type metadata for Double))
  {
LABEL_4:
    uint64_t v88 = type metadata accessor for AnyColumn(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v88 - 8) + 8))(v310, v88);
    return v245;
  }
  if (swift_dynamicCastMetatype(v87, &type metadata for String))
  {
    double v90 = AnyColumn.assumingType<A>(_:)(&type metadata for String, &type metadata for String);
    *(void *)&long long v307 = 0;
    *((void *)&v307 + 1) = 0xE000000000000000;
    uint64_t v91 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v92 = v284;
    OptionalColumnProtocol.filled(with:)(&v307, v78, v91);
    (*(void (**)(uint64_t *, uint64_t, double))(v79 + 8))(v92, v78, v90);
    uint64_t v93 = (void *)specialized Set.init<A>(_:)();
    swift_bridgeObjectRetain((_BYTE)v93);
    uint64_t v94 = specialized _copyCollectionToContiguousArray<A>(_:)((uint64_t)v93);
    swift_bridgeObjectRelease((_BYTE)v93);
    *(void *)&long long v307 = v94;
    uint64_t v95 = v308;
    specialized MutableCollection<>.sort(by:)(&v307);
    if (v95)
    {
      swift_release();
      BUG();
    }
LABEL_10:
    uint64_t v96 = type metadata accessor for AnyColumn(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v96 - 8) + 8))(v310, v96);
    swift_bridgeObjectRelease((_BYTE)v93);
    return v245;
  }
  uint64_t v97 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int]);
  if (swift_dynamicCastMetatype(v87, v97))
  {
    uint64_t v98 = v248;
    double v99 = AnyColumn.assumingType<A>(_:)(v97, v97);
    uint64_t v100 = specialized Collection.first.getter();
    (*(void (**)(uint64_t *, uint64_t, double))(v247 + 8))(v98, v74, v99);
    if (v100)
    {
      if (v100 == 2) {
        BUG();
      }
      outlined consume of MLImageClassifier.ModelParameters.ClassifierType?(v100);
    }
    uint64_t v105 = v310;
    goto LABEL_30;
  }
  uint64_t v101 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int32]);
  if (swift_dynamicCastMetatype(v87, v101))
  {
    uint64_t v102 = v251;
    uint64_t v103 = v101;
    uint64_t v104 = v101;
    uint64_t v105 = v310;
    double v106 = AnyColumn.assumingType<A>(_:)(v103, v104);
    uint64_t v107 = specialized Collection.first.getter();
    (*(void (**)(uint64_t *, uint64_t, double))(v249 + 8))(v102, v250, v106);
    if (!v107)
    {
LABEL_30:
      uint64_t v119 = type metadata accessor for AnyColumn(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v119 - 8) + 8))(v105, v119);
      return v245;
    }
    if (v107 == 2) {
      BUG();
    }
LABEL_24:
    outlined consume of MLImageClassifier.ModelParameters.ClassifierType?(v107);
    goto LABEL_30;
  }
  uint64_t v108 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [UInt8]);
  if (swift_dynamicCastMetatype(v87, v108))
  {
    uint64_t v109 = v254;
    uint64_t v110 = v108;
    uint64_t v111 = v108;
    uint64_t v112 = v310;
    double v113 = AnyColumn.assumingType<A>(_:)(v110, v111);
    uint64_t v107 = specialized Collection.first.getter();
    (*(void (**)(uint64_t *, uint64_t, double))(v252 + 8))(v109, v253, v113);
    if (!v107)
    {
      uint64_t v105 = v112;
      goto LABEL_30;
    }
    if (v107 == 2) {
      BUG();
    }
    uint64_t v105 = v112;
    goto LABEL_24;
  }
  uint64_t v114 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Int32>);
  if (swift_dynamicCastMetatype(v87, v114))
  {
    char v115 = v260;
    double v116 = AnyColumn.assumingType<A>(_:)(v114, v114);
    uint64_t v117 = (uint64_t)v255;
    specialized Collection.first.getter();
    (*(void (**)(uint64_t *, uint64_t, double))(v257 + 8))(v115, v258, v116);
    if (__swift_getEnumTagSinglePayload(v117, 1, v259) == 1) {
      BUG();
    }
    uint64_t v118 = (uint64_t)v256;
    outlined init with take of DataFrame?(v117, (uint64_t)v256, &demangling cache variable for type metadata for MLShapedArray<Int32>?);
    if (__swift_getEnumTagSinglePayload(v118, 1, v114) == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v118, &demangling cache variable for type metadata for MLShapedArray<Int32>?);
      uint64_t v93 = _swiftEmptyArrayStorage;
    }
    else
    {
      uint64_t v93 = (void *)MLShapedArray.shape.getter(v114);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v114 - 8) + 8))(v118, v114);
    }
    if (v93[2] < 2uLL) {
      goto LABEL_10;
    }
    uint64_t v124 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v124, 0, 0);
    *(void *)uint64_t v125 = 0xD000000000000031;
    *(void *)(v125 + 8) = " has a missing element." + 0x8000000000000000;
    *(_OWORD *)(v125 + 16) = 0;
    *(_OWORD *)(v125 + 32) = 0;
    *(unsigned char *)(v125 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v124, v125, v126, v127, v128);
    uint64_t v129 = type metadata accessor for AnyColumn(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v129 - 8) + 8))(v310, v129);
    swift_bridgeObjectRelease(v309);
    char v130 = (char)v93;
    return swift_bridgeObjectRelease(v130);
  }
  uint64_t v120 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  if (swift_dynamicCastMetatype(v87, v120))
  {
    int64_t v121 = v263;
    double v122 = AnyColumn.assumingType<A>(_:)(v120, v120);
    uint64_t v123 = specialized Collection.first.getter();
    (*(void (**)(uint64_t *, uint64_t, double))(v261 + 8))(v121, v262, v122);
    if (v123)
    {
      if (v123 == 2) {
        BUG();
      }
      outlined consume of MLImageClassifier.ModelParameters.ClassifierType?(v123);
    }
    goto LABEL_4;
  }
  uint64_t v131 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  if (swift_dynamicCastMetatype(v87, v131))
  {
    uint64_t v132 = v267;
    double v133 = AnyColumn.assumingType<A>(_:)(v131, v131);
    uint64_t v134 = (uint64_t)v285;
    specialized Collection.first.getter();
    (*(void (**)(uint64_t *, uint64_t, double))(v264 + 8))(v132, v265, v133);
    if (__swift_getEnumTagSinglePayload(v134, 1, v266) == 1) {
      BUG();
    }
    uint64_t v135 = (uint64_t)v287;
    outlined init with take of DataFrame?((uint64_t)v285, (uint64_t)v287, &demangling cache variable for type metadata for MLShapedArray<Float>?);
    if (__swift_getEnumTagSinglePayload(v135, 1, v131) == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v287, &demangling cache variable for type metadata for MLShapedArray<Float>?);
      uint64_t v136 = _swiftEmptyArrayStorage;
    }
    else
    {
      uint64_t v141 = (uint64_t)v287;
      uint64_t v136 = (void *)MLShapedArray.shape.getter(v131);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v131 - 8) + 8))(v141, v131);
    }
    if (v136[2] >= 2uLL)
    {
LABEL_52:
      uint64_t v142 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v142, 0, 0);
      *(void *)uint64_t v143 = 0xD000000000000031;
      *(void *)(v143 + 8) = " has a missing element." + 0x8000000000000000;
      *(_OWORD *)(v143 + 16) = 0;
      *(_OWORD *)(v143 + 32) = 0;
      *(unsigned char *)(v143 + 48) = 0;
      swift_willThrow(&type metadata for MLCreateError, v142, v143, v144, v145, v146);
      uint64_t v147 = type metadata accessor for AnyColumn(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v147 - 8) + 8))(v310, v147);
      swift_bridgeObjectRelease(v309);
      char v130 = (char)v136;
      return swift_bridgeObjectRelease(v130);
    }
LABEL_58:
    uint64_t v153 = type metadata accessor for AnyColumn(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v153 - 8) + 8))(v310, v153);
    swift_bridgeObjectRelease((_BYTE)v136);
    return v245;
  }
  uint64_t v137 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
  if (swift_dynamicCastMetatype(v87, v137))
  {
    uint64_t v138 = v270;
    double v139 = AnyColumn.assumingType<A>(_:)(v137, v137);
    uint64_t v140 = specialized Collection.first.getter();
    (*(void (**)(uint64_t *, uint64_t, double))(v268 + 8))(v138, v269, v139);
    if (v140)
    {
      if (v140 == 2) {
        BUG();
      }
      outlined consume of MLImageClassifier.ModelParameters.ClassifierType?(v140);
    }
    goto LABEL_4;
  }
  uint64_t v148 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  if (swift_dynamicCastMetatype(v87, v148))
  {
    uint64_t v149 = v274;
    double v150 = AnyColumn.assumingType<A>(_:)(v148, v148);
    uint64_t v151 = (uint64_t)v286;
    specialized Collection.first.getter();
    (*(void (**)(uint64_t *, uint64_t, double))(v271 + 8))(v149, v272, v150);
    if (__swift_getEnumTagSinglePayload(v151, 1, v273) == 1) {
      BUG();
    }
    uint64_t v152 = (uint64_t)v288;
    outlined init with take of DataFrame?((uint64_t)v286, (uint64_t)v288, &demangling cache variable for type metadata for MLShapedArray<Double>?);
    if (__swift_getEnumTagSinglePayload(v152, 1, v148) == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v288, &demangling cache variable for type metadata for MLShapedArray<Double>?);
      uint64_t v136 = _swiftEmptyArrayStorage;
    }
    else
    {
      uint64_t v170 = (uint64_t)v288;
      uint64_t v136 = (void *)MLShapedArray.shape.getter(v148);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v148 - 8) + 8))(v170, v148);
    }
    if (v136[2] >= 2uLL) {
      goto LABEL_52;
    }
    goto LABEL_58;
  }
  uint64_t v154 = type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for MLMultiArray, MLMultiArray_ptr);
  if (swift_dynamicCastMetatype(v87, v154))
  {
    int v155 = v277;
    double v156 = AnyColumn.assumingType<A>(_:)(v154, v154);
    uint64_t v157 = (char *)specialized Collection.first.getter();
    (*(void (**)(uint64_t *, uint64_t, double))(v275 + 8))(v155, v276, v156);
    if (v157)
    {
      if (v157 == (unsigned char *)&dword_0 + 2) {
        BUG();
      }
      id v158 = [v157 shape];
      id v159 = v158;
      uint64_t v160 = type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for NSNumber, NSNumber_ptr);
      uint64_t v161 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v159, v160);

      uint64_t v162 = v308;
      ML16ColumnDescriptorV0c4TypeD0OyAESgSo12MLMultiArrayCKcfcSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySo8NSNumberCG_Sis5NeverOTg5071_s8CreateML16ColumnDescriptorV0c4TypeD0OyAESgSo12MLMultiArrayCKcfcSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_nTm(v161);
      swift_bridgeObjectRelease(v161);
      if (ML16ColumnDescriptorV0c4TypeD0OyAESgSo12MLMultiArrayCKcfcSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_nTm[2] <= 1uLL)
      {
        swift_bridgeObjectRelease((_BYTE)ML16ColumnDescriptorV0c4TypeD0OyAESgSo12MLMultiArrayCKcfcSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_nTm);
        uint64_t v191 = v157;
        ColumnDescriptor.ColumnTypeDescriptor.init(_:)(v191);
        if (!v162)
        {
          if (v192 == -1) {
            BUG();
          }
          uint64_t v204 = type metadata accessor for AnyColumn(0);
          (*(void (**)(uint64_t, uint64_t))(*(void *)(v204 - 8) + 8))(v310, v204);
          outlined consume of MLMultiArray??(v157);
          return v245;
        }
        uint64_t v193 = type metadata accessor for AnyColumn(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v193 - 8) + 8))(v310, v193);
      }
      else
      {
        uint64_t v164 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v164, 0, 0);
        *(void *)uint64_t v165 = 0xD000000000000031;
        *(void *)(v165 + 8) = " has a missing element." + 0x8000000000000000;
        *(_OWORD *)(v165 + 16) = 0;
        *(_OWORD *)(v165 + 32) = 0;
        *(unsigned char *)(v165 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v164, v165, v166, v167, v168);
        uint64_t v169 = type metadata accessor for AnyColumn(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v169 - 8) + 8))(v310, v169);
        swift_bridgeObjectRelease((_BYTE)ML16ColumnDescriptorV0c4TypeD0OyAESgSo12MLMultiArrayCKcfcSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_nTm);
      }
      outlined consume of MLMultiArray??(v157);
      char v130 = v309;
      return swift_bridgeObjectRelease(v130);
    }
    swift_bridgeObjectRelease(v309);
    *(void *)&long long v307 = 0;
    *((void *)&v307 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(32);
    swift_bridgeObjectRelease(BYTE8(v307));
    *(void *)&long long v307 = 0x206E6D756C6F43;
    *((void *)&v307 + 1) = 0xE700000000000000;
    uint64_t v180 = v310;
    v181._uint64_t countAndFlagsBits = AnyColumn.name.getter();
    char object = (char)v181._object;
    String.append(_:)(v181);
    swift_bridgeObjectRelease(object);
    v183._uint64_t countAndFlagsBits = 0xD000000000000017;
    v183._char object = "unsupported type " + 0x8000000000000000;
    String.append(_:)(v183);
    long long v308 = v307;
    v183._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v183._object, 0, 0);
    *(_OWORD *)uint64_t v184 = v308;
    *(_OWORD *)(v184 + 16) = 0;
    *(_OWORD *)(v184 + 32) = 0;
    *(unsigned char *)(v184 + 48) = 1;
    swift_willThrow(&type metadata for MLCreateError, v183._object, v184, v185, v186, v187);
    uint64_t v188 = type metadata accessor for AnyColumn(0);
    uint64_t v189 = *(void *)(v188 - 8);
    uint64_t v190 = v180;
    return (*(uint64_t (**)(uint64_t, uint64_t))(v189 + 8))(v190, v188);
  }
  uint64_t v171 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Int]);
  if (!swift_dynamicCastMetatype(v87, v171))
  {
    uint64_t v194 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : UInt8]);
    if (swift_dynamicCastMetatype(v87, v194))
    {
      char v195 = v294;
      double v196 = AnyColumn.assumingType<A>(_:)(v194, v194);
      uint64_t v197 = (uint64_t)v279;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t, double))(v292 + 16))(v279, v195, v293, v196);
      uint64_t v198 = v308;
      specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)(v197);
      if (v198)
      {
        swift_bridgeObjectRelease(v309);
        uint64_t v199 = type metadata accessor for AnyColumn(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v199 - 8) + 8))(v310, v199);
        char v177 = v294;
        uint64_t v178 = v293;
        uint64_t v179 = v292;
        return (*(uint64_t (**)(uint64_t *, uint64_t))(v179 + 8))(v177, v178);
      }
      uint64_t v211 = type metadata accessor for AnyColumn(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v211 - 8) + 8))(v310, v211);
      unint64_t v201 = v294;
      uint64_t v202 = v293;
      uint64_t v203 = v292;
    }
    else
    {
      uint64_t v205 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Int32]);
      if (swift_dynamicCastMetatype(v87, v205))
      {
        uint64_t v206 = v306;
        double v207 = AnyColumn.assumingType<A>(_:)(v205, v205);
        uint64_t v208 = (uint64_t)v283;
        (*(void (**)(uint64_t *, uint64_t *, uint64_t, double))(v304 + 16))(v283, v206, v305, v207);
        uint64_t v209 = v308;
        specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)(v208);
        if (v209)
        {
          swift_bridgeObjectRelease(v309);
          uint64_t v210 = type metadata accessor for AnyColumn(0);
          (*(void (**)(uint64_t, uint64_t))(*(void *)(v210 - 8) + 8))(v310, v210);
          char v177 = v306;
          uint64_t v178 = v305;
          uint64_t v179 = v304;
          return (*(uint64_t (**)(uint64_t *, uint64_t))(v179 + 8))(v177, v178);
        }
        uint64_t v218 = type metadata accessor for AnyColumn(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v218 - 8) + 8))(v310, v218);
        unint64_t v201 = v306;
        uint64_t v202 = v305;
        uint64_t v203 = v304;
      }
      else
      {
        uint64_t v212 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Double]);
        if (swift_dynamicCastMetatype(v87, v212))
        {
          Swift::String v213 = v303;
          double v214 = AnyColumn.assumingType<A>(_:)(v212, v212);
          uint64_t v215 = (uint64_t)v282;
          (*(void (**)(uint64_t *, uint64_t *, uint64_t, double))(v301 + 16))(v282, v213, v302, v214);
          uint64_t v216 = v308;
          specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)(v215);
          if (v216)
          {
            swift_bridgeObjectRelease(v309);
            uint64_t v217 = type metadata accessor for AnyColumn(0);
            (*(void (**)(uint64_t, uint64_t))(*(void *)(v217 - 8) + 8))(v310, v217);
            char v177 = v303;
            uint64_t v178 = v302;
            uint64_t v179 = v301;
            return (*(uint64_t (**)(uint64_t *, uint64_t))(v179 + 8))(v177, v178);
          }
          uint64_t v225 = type metadata accessor for AnyColumn(0);
          (*(void (**)(uint64_t, uint64_t))(*(void *)(v225 - 8) + 8))(v310, v225);
          unint64_t v201 = v303;
          uint64_t v202 = v302;
          uint64_t v203 = v301;
        }
        else
        {
          uint64_t v219 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Float]);
          if (swift_dynamicCastMetatype(v87, v219))
          {
            char v220 = v300;
            double v221 = AnyColumn.assumingType<A>(_:)(v219, v219);
            uint64_t v222 = (uint64_t)v281;
            (*(void (**)(uint64_t *, uint64_t *, uint64_t, double))(v298 + 16))(v281, v220, v299, v221);
            uint64_t v223 = v308;
            specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)(v222);
            if (v223)
            {
              swift_bridgeObjectRelease(v309);
              uint64_t v224 = type metadata accessor for AnyColumn(0);
              (*(void (**)(uint64_t, uint64_t))(*(void *)(v224 - 8) + 8))(v310, v224);
              char v177 = v300;
              uint64_t v178 = v299;
              uint64_t v179 = v298;
              return (*(uint64_t (**)(uint64_t *, uint64_t))(v179 + 8))(v177, v178);
            }
            uint64_t v232 = type metadata accessor for AnyColumn(0);
            (*(void (**)(uint64_t, uint64_t))(*(void *)(v232 - 8) + 8))(v310, v232);
            unint64_t v201 = v300;
            uint64_t v202 = v299;
            uint64_t v203 = v298;
          }
          else
          {
            uint64_t v226 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any?]);
            if (!swift_dynamicCastMetatype(v87, v226))
            {
              swift_bridgeObjectRelease(v309);
              *(void *)&long long v307 = 0;
              *((void *)&v307 + 1) = 0xE000000000000000;
              _StringGuts.grow(_:)(45);
              swift_bridgeObjectRelease(BYTE8(v307));
              *(void *)&long long v307 = 0x206E6D756C6F43;
              *((void *)&v307 + 1) = 0xE700000000000000;
              v233._uint64_t countAndFlagsBits = AnyColumn.name.getter();
              char v234 = (char)v233._object;
              String.append(_:)(v233);
              swift_bridgeObjectRelease(v234);
              v235._uint64_t countAndFlagsBits = 0xD000000000000021;
              v235._char object = "SupportVectorClassifier" + 0x8000000000000000;
              String.append(_:)(v235);
              uint64_t v236 = AnyColumn.wrappedElementType.getter();
              v237._uint64_t countAndFlagsBits = _typeName(_:qualified:)(v236, 0);
              char v238 = (char)v237._object;
              String.append(_:)(v237);
              swift_bridgeObjectRelease(v238);
              v235._uint64_t countAndFlagsBits = 46;
              v235._char object = (void *)0xE100000000000000;
              String.append(_:)(v235);
              long long v308 = v307;
              v235._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
              swift_allocError(&type metadata for MLCreateError, v235._object, 0, 0);
              *(_OWORD *)uint64_t v239 = v308;
              *(_OWORD *)(v239 + 16) = 0;
              *(_OWORD *)(v239 + 32) = 0;
              *(unsigned char *)(v239 + 48) = 1;
              swift_willThrow(&type metadata for MLCreateError, v235._object, v239, v240, v241, v242);
              uint64_t v188 = type metadata accessor for AnyColumn(0);
              uint64_t v189 = *(void *)(v188 - 8);
              uint64_t v190 = v310;
              return (*(uint64_t (**)(uint64_t, uint64_t))(v189 + 8))(v190, v188);
            }
            char v227 = v297;
            double v228 = AnyColumn.assumingType<A>(_:)(v226, v226);
            uint64_t v229 = (uint64_t)v280;
            (*(void (**)(uint64_t *, uint64_t *, uint64_t, double))(v295 + 16))(v280, v227, v296, v228);
            uint64_t v230 = v308;
            specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)(v229);
            if (v230)
            {
              swift_bridgeObjectRelease(v309);
              uint64_t v231 = type metadata accessor for AnyColumn(0);
              (*(void (**)(uint64_t, uint64_t))(*(void *)(v231 - 8) + 8))(v310, v231);
              char v177 = v297;
              uint64_t v178 = v296;
              uint64_t v179 = v295;
              return (*(uint64_t (**)(uint64_t *, uint64_t))(v179 + 8))(v177, v178);
            }
            uint64_t v243 = type metadata accessor for AnyColumn(0);
            (*(void (**)(uint64_t, uint64_t))(*(void *)(v243 - 8) + 8))(v310, v243);
            unint64_t v201 = v297;
            uint64_t v202 = v296;
            uint64_t v203 = v295;
          }
        }
      }
    }
LABEL_101:
    (*(void (**)(uint64_t *, uint64_t))(v203 + 8))(v201, v202);
    return v245;
  }
  uint64_t v172 = v291;
  double v173 = AnyColumn.assumingType<A>(_:)(v171, v171);
  uint64_t v174 = (uint64_t)v278;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t, double))(v289 + 16))(v278, v172, v290, v173);
  uint64_t v175 = v308;
  specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)(v174);
  if (!v175)
  {
    uint64_t v200 = type metadata accessor for AnyColumn(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v200 - 8) + 8))(v310, v200);
    unint64_t v201 = v291;
    uint64_t v202 = v290;
    uint64_t v203 = v289;
    goto LABEL_101;
  }
  swift_bridgeObjectRelease(v309);
  uint64_t v176 = type metadata accessor for AnyColumn(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v176 - 8) + 8))(v310, v176);
  char v177 = v291;
  uint64_t v178 = v290;
  uint64_t v179 = v289;
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v179 + 8))(v177, v178);
}

char ColumnDescriptor.ColumnTypeDescriptor.featureType.getter(char a1, char a2)
{
  switch(a2)
  {
    case 0:
      char result = 4;
      break;
    case 1:
      char result = 5;
      break;
    case 2:
      char result = 6;
      break;
    case 3:
      char result = 7;
      break;
    case 4:
      char result = 8;
      break;
    case 5:
      char result = 9;
      break;
    case 6:
      char result = a1;
      break;
  }
  return result;
}

uint64_t ColumnDescriptor.ColumnTypeDescriptor.init(_:)(id a1)
{
  id v3 = [a1 shape];
  id v4 = v3;
  uint64_t v5 = type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for NSNumber, NSNumber_ptr);
  uint64_t v6 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v4, v5);

  ML16ColumnDescriptorV0c4TypeD0OyAESgSo12MLMultiArrayCKcfcSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySo8NSNumberCG_Sis5NeverOTg5071_s8CreateML16ColumnDescriptorV0c4TypeD0OyAESgSo12MLMultiArrayCKcfcSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_nTm(v6);
  v17[1] = v1;
  char v8 = v6;
  id v9 = a1;
  uint64_t v10 = 0;
  swift_bridgeObjectRelease(v8);
  if (ML16ColumnDescriptorV0c4TypeD0OyAESgSo12MLMultiArrayCKcfcSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_nTm[2] <= 1uLL)
  {
    uint64_t v11 = (char *)[v9 dataType];
    if (v11 != (char *)&loc_10010
      && v11 != (unsigned char *)&loc_1001D + 3
      && v11 != (unsigned char *)&loc_2001D + 3
      && v11 != (unsigned char *)&loc_1003E + 2)
    {
      uint64_t v15 = 0;
      unint64_t v16 = 0xE000000000000000;
      _StringGuts.grow(_:)(28);
      v13._char object = "CreateML/ColumnDescriptor.swift" + 0x8000000000000000;
      v13._uint64_t countAndFlagsBits = 0xD000000000000019;
      String.append(_:)(v13);
      v17[0] = [v9 dataType];
      uint64_t v14 = type metadata accessor for MLMultiArrayDataType(0);
      _print_unlocked<A, B>(_:_:)(v17, &v15, v14, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
      v13._uint64_t countAndFlagsBits = 46;
      v13._char object = (void *)0xE100000000000000;
      String.append(_:)(v13);
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v15, v16, "CreateML/ColumnDescriptor.swift", 31, 2, 402, 0);
      BUG();
    }
    if (ML16ColumnDescriptorV0c4TypeD0OyAESgSo12MLMultiArrayCKcfcSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_nTm[2]) {
      uint64_t v10 = ML16ColumnDescriptorV0c4TypeD0OyAESgSo12MLMultiArrayCKcfcSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_nTm[4];
    }
    else {
      uint64_t v10 = 1;
    }
  }
  swift_bridgeObjectRelease((_BYTE)ML16ColumnDescriptorV0c4TypeD0OyAESgSo12MLMultiArrayCKcfcSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_nTm);

  return v10;
}

void *specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)(uint64_t a1)
{
  uint64_t v112 = v1;
  uint64_t v117 = a1;
  uint64_t v121 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<[String : Int]>>);
  uint64_t v127 = *(void *)(v121 - 8);
  int64_t v2 = *(void *)(v127 + 64);
  id v3 = alloca(v2);
  id v4 = alloca(v2);
  unint64_t v129 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Int]>>>);
  int64_t v5 = *(void *)(*(void *)(v129 - 8) + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  *(void *)&long long v124 = &v108;
  char v8 = alloca(v5);
  id v9 = alloca(v5);
  double v116 = &v108;
  uint64_t v126 = _swiftEmptyArrayStorage;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for Int, &protocol witness table for String);
  char v11 = v10;
  *(void *)&v118[0] = v10;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Int]>);
  uint64_t v13 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[String : Int]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[String : Int]>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v113 = v12;
  OptionalColumnProtocol.filled(with:)(v118, v12, v13);
  swift_bridgeObjectRelease(v11);
  uint64_t v14 = v127;
  uint64_t v15 = v121;
  uint64_t v110 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v127 + 16);
  v110(&v108, &v108, v121);
  uint64_t v115 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<[String : Int]>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<[String : Int]>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
  dispatch thunk of Collection.startIndex.getter(v15, v115);
  unint64_t v16 = *(void (**)(uint64_t *, uint64_t))(v14 + 8);
  uint64_t v109 = &v108;
  uint64_t v111 = v16;
  v16(&v108, v15);
  unint64_t v17 = v129;
  uint64_t v18 = v124;
  *(void *)(v124 + *(int *)(v129 + 36)) = *(void *)&v118[0];
  uint64_t v19 = (uint64_t)v116;
  outlined init with take of DataFrame?(v18, (uint64_t)v116, &demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Int]>>>);
  uint64_t v20 = *(int *)(v17 + 36);
  uint64_t v21 = *(void *)(v19 + v20);
  uint64_t v22 = v15;
  uint64_t v23 = v115;
  dispatch thunk of Collection.endIndex.getter(v22, v115);
  if (v21 == *(void *)&v118[0])
  {
    unint64_t v129 = 0;
    uint64_t v125 = _swiftEmptyDictionarySingleton;
    uint64_t v127 = 0;
    uint64_t v24 = 0;
    uint64_t v25 = (uint64_t)v116;
    goto LABEL_36;
  }
  char v26 = (uint64_t *)((char *)v116 + v20);
  uint64_t v125 = _swiftEmptyDictionarySingleton;
  uint64_t v24 = 0;
  uint64_t v127 = 0;
  unint64_t v129 = 0;
  uint64_t v25 = (uint64_t)v116;
  uint64_t v114 = v26;
  do
  {
    int64_t v27 = v26;
    uint64_t v28 = v23;
    uint64_t v29 = v25;
    uint64_t v30 = v121;
    char v31 = (void (*)(_OWORD *, void))dispatch thunk of Collection.subscript.read(v118, v27, v121, v28);
    uint64_t v128 = *v32;
    swift_bridgeObjectRetain(v128);
    v31(v118, 0);
    uint64_t v33 = v109;
    v110(v109, (uint64_t *)v29, v30);
    dispatch thunk of Collection.formIndex(after:)(v114, v30, v115);
    v111(v33, v30);
    uint64_t v34 = 1 << *(unsigned char *)(v128 + 32);
    uint64_t v35 = ~(-1 << v34);
    if (v34 >= 64) {
      uint64_t v35 = -1;
    }
    unint64_t v36 = *(void *)(v128 + 64) & v35;
    int64_t v122 = (unint64_t)(v34 + 63) >> 6;
    int64_t v37 = 0;
    uint64_t v38 = v30;
    uint64_t v39 = (uint64_t (*)())v127;
    while (1)
    {
      if (v36)
      {
        uint64_t v40 = v24;
        _BitScanForward64(&v41, v36);
        uint64_t v120 = (uint64_t *)((v36 - 1) & v36);
        unint64_t v42 = v41 | (v37 << 6);
        int64_t v119 = v37;
        goto LABEL_18;
      }
      BOOL v43 = __OFADD__(1, v37);
      int64_t v44 = v37 + 1;
      if (v43) {
        BUG();
      }
      if (v44 >= v122) {
        break;
      }
      unint64_t i = *(void *)(v128 + 8 * v44 + 64);
      if (i)
      {
        int64_t v46 = v44;
      }
      else
      {
        int64_t v46 = v44 + 1;
        if (v44 + 1 >= v122) {
          break;
        }
        unint64_t i = *(void *)(v128 + 8 * v44 + 72);
        if (!i)
        {
          int64_t v46 = v44 + 2;
          if (v44 + 2 >= v122) {
            break;
          }
          unint64_t i = *(void *)(v128 + 8 * v44 + 80);
          if (!i)
          {
            int64_t v46 = v44 + 3;
            if (v44 + 3 >= v122) {
              break;
            }
            for (unint64_t i = *(void *)(v128 + 8 * v44 + 88); !i; unint64_t i = *(void *)(v128 + 8 * v46 + 64))
            {
              BOOL v43 = __OFADD__(1, v46++);
              if (v43) {
                BUG();
              }
              if (v46 >= v122) {
                goto LABEL_35;
              }
            }
          }
        }
      }
      _BitScanForward64(&v47, i);
      uint64_t v40 = v24;
      uint64_t v120 = (uint64_t *)(i & (i - 1));
      int64_t v119 = v46;
      unint64_t v42 = v47 + (v46 << 6);
LABEL_18:
      uint64_t v48 = *(void *)(v128 + 48);
      uint64_t v49 = *(void *)(v48 + 16 * v42);
      uint64_t v50 = *(void *)(v48 + 16 * v42 + 8);
      v123._char object = *(void **)(*(void *)(v128 + 56) + 8 * v42);
      swift_bridgeObjectRetain(v50);
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
      uint64_t v51 = swift_allocObject(&unk_39CEB8, 32, 7);
      *(void *)(v51 + 16) = specialized implicit closure #2 in static RecommenderModel.metrics<A, B>(expected:predicted:cutoffs:);
      *(void *)&long long v124 = v51;
      *(void *)(v51 + 24) = 0;
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v39, v40);
      uint64_t v52 = v125;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v125);
      *(void *)&v118[0] = v52;
      v123._uint64_t countAndFlagsBits = v49;
      uint64_t v127 = v50;
      unint64_t v129 = specialized __RawDictionaryStorage.find<A>(_:)(v49, v50);
      BOOL v55 = (v54 & 1) == 0;
      BOOL v43 = __OFADD__(v52[2], v55);
      Swift::Int v56 = v52[2] + v55;
      if (v43) {
        BUG();
      }
      char v57 = v54;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [Int]>);
      Swift::Bool v58 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v56);
      int64_t v59 = *(void **)&v118[0];
      uint64_t v60 = v127;
      if (v58)
      {
        unint64_t v129 = specialized __RawDictionaryStorage.find<A>(_:)(v123._countAndFlagsBits, v127);
        if ((v57 & 1) != (v61 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
          BUG();
        }
      }
      swift_bridgeObjectRelease(0);
      swift_bridgeObjectRetain((_BYTE)v59);
      if ((v57 & 1) == 0)
      {
        uint64_t v62 = (*(uint64_t (**)(void))(v124 + 16))();
        unint64_t v63 = v129;
        v59[(v129 >> 6) + 8] |= 1 << v129;
        uint64_t v64 = v59[6];
        uint64_t v65 = 16 * v63;
        *(void *)(v64 + v65) = v123._countAndFlagsBits;
        *(void *)(v64 + v65 + 8) = v60;
        *(void *)(v59[7] + 8 * v63) = v62;
        uint64_t v66 = v59[2];
        BOOL v43 = __OFADD__(1, v66);
        uint64_t v67 = v66 + 1;
        if (v43) {
          BUG();
        }
        v59[2] = v67;
        swift_bridgeObjectRetain(v60);
      }
      int64_t v68 = (void *)v59[7];
      swift_bridgeObjectRelease((_BYTE)v59);
      unint64_t v69 = v129;
      __m128 v70 = (char *)v68[v129];
      char v71 = swift_isUniquelyReferenced_nonNull_native(v70);
      v68[v69] = v70;
      uint64_t v125 = v68;
      Swift::Int v72 = v59;
      if (!v71)
      {
        __m128 v70 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v70 + 2) + 1, 1, (uint64_t)v70);
        v68[v129] = v70;
      }
      unint64_t v73 = *((void *)v70 + 2);
      if (*((void *)v70 + 3) >> 1 <= v73)
      {
        __m128 v70 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v70 + 3) >= 2uLL, v73 + 1, 1, (uint64_t)v70);
        v125[v129] = v70;
      }
      *((void *)v70 + 2) = v73 + 1;
      *(void *)&v70[8 * v73 + 32] = v123._object;
      swift_bridgeObjectRelease(v127);
      unint64_t v129 = (unint64_t)specialized implicit closure #2 in static RecommenderModel.metrics<A, B>(expected:predicted:cutoffs:);
      uint64_t v39 = thunk for @callee_guaranteed () -> (@owned [B])specialized partial apply;
      uint64_t v24 = v124;
      int64_t v37 = v119;
      uint64_t v125 = v72;
      uint64_t v38 = v121;
      unint64_t v36 = (unint64_t)v120;
    }
LABEL_35:
    uint64_t v127 = (uint64_t)v39;
    swift_release();
    uint64_t v74 = v38;
    *(void *)&long long v124 = *v114;
    uint64_t v75 = (uint64_t)v116;
    uint64_t v23 = v115;
    dispatch thunk of Collection.endIndex.getter(v74, v115);
    char v26 = v114;
    uint64_t v25 = v75;
  }
  while ((void)v124 != *(void *)&v118[0]);
LABEL_36:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v25, &demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Int]>>>);
  uint64_t v76 = (uint64_t)v125;
  swift_bridgeObjectRetain_n(v125, 2);
  long long v77 = specialized _copyCollectionToContiguousArray<A>(_:)(v76);
  swift_bridgeObjectRelease(v76);
  *(void *)&v118[0] = v77;
  uint64_t v78 = v112;
  specialized MutableCollection<>.sort(by:)(v118);
  if (v78)
  {
    swift_release();
    BUG();
  }
  swift_bridgeObjectRelease(v76);
  v123._char object = *(void **)&v118[0];
  uint64_t v79 = v127;
  if (*(void *)(*(void *)&v118[0] + 16))
  {
    if (!*(void *)(v76 + 16)) {
      BUG();
    }
    int64_t v119 = *(void *)(*(void *)&v118[0] + 16);
    uint64_t v121 = 0;
    uint64_t v80 = *((void *)v123._object + 5);
    uint64_t v81 = *((void *)v123._object + 4);
    swift_bridgeObjectRetain_n(v80, 2);
    v123._uint64_t countAndFlagsBits = v81;
    *(void *)&long long v124 = v80;
    unint64_t v82 = specialized __RawDictionaryStorage.find<A>(_:)(v81, v80);
    if ((v83 & 1) == 0)
    {
      LOBYTE(v84) = v124;
LABEL_61:
      swift_bridgeObjectRelease(v84);
      BUG();
    }
    uint64_t v128 = v24;
    uint64_t v120 = (uint64_t *)((char *)v123._object + 56);
    uint64_t v126 = _swiftEmptyArrayStorage;
    uint64_t v84 = v124;
    while (1)
    {
      uint64_t v85 = *(void *)(*(void *)(v76 + 56) + 8 * v82);
      swift_bridgeObjectRetain(v85);
      *(void *)&long long v124 = v84;
      swift_bridgeObjectRelease(v84);
      uint64_t v86 = specialized _arrayForceCast<A, B>(_:)(v85);
      swift_bridgeObjectRelease(v85);
      uint64_t v87 = specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)((uint64_t)v86);
      if (v88 == -1)
      {
        swift_bridgeObjectRelease((_BYTE)v126);
        swift_release();
        *(void *)&v118[0] = 0;
        *((void *)&v118[0] + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(77);
        v97._char object = "Unknown MLMultiArrayType " + 0x8000000000000000;
        v97._uint64_t countAndFlagsBits = 0xD000000000000014;
        String.append(_:)(v97);
        v97._uint64_t countAndFlagsBits = v123._countAndFlagsBits;
        char v98 = v124;
        v97._char object = (void *)v124;
        String.append(_:)(v97);
        swift_bridgeObjectRelease(v98);
        v97._uint64_t countAndFlagsBits = 0x6C6F63206E692027;
        v97._char object = (void *)0xED000027206E6D75;
        String.append(_:)(v97);
        uint64_t v125 = (void *)v76;
        uint64_t v99 = v113;
        uint64_t v100 = Column.name.getter(v113);
        char v102 = (char)v101;
        v97._uint64_t countAndFlagsBits = v100;
        v97._char object = v101;
        String.append(_:)(v97);
        swift_bridgeObjectRelease(v102);
        v97._char object = "Dictionary feature '" + 0x8000000000000000;
        v97._uint64_t countAndFlagsBits = 0xD000000000000028;
        String.append(_:)(v97);
        long long v124 = v118[0];
        v97._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v97._object, 0, 0);
        *(_OWORD *)uint64_t v103 = v124;
        *(_OWORD *)(v103 + 16) = 0;
        *(_OWORD *)(v103 + 32) = 0;
        *(unsigned char *)(v103 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v97._object, v103, v104, v105, v106);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v99 - 8) + 8))(v117, v99);
        swift_bridgeObjectRelease((_BYTE)v125);
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v127, v128);
        return v126;
      }
      uint64_t v89 = v87;
      char v90 = v88;
      if (!swift_isUniquelyReferenced_nonNull_native(v126)) {
        uint64_t v126 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v126[2] + 1, 1, (uint64_t)v126);
      }
      unint64_t v91 = v126[2];
      if (v126[3] >> 1 <= v91) {
        uint64_t v126 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v126[3] >= 2uLL, v91 + 1, 1, (uint64_t)v126);
      }
      uint64_t v92 = v126;
      v126[2] = v91 + 1;
      uint64_t v93 = 4 * v91;
      v92[v93 + 4] = v123._countAndFlagsBits;
      v92[v93 + 5] = v124;
      v92[v93 + 6] = v89;
      LOBYTE(v92[v93 + 7]) = v90;
      if (v119 == 1) {
        break;
      }
      uint64_t v76 = (uint64_t)v125;
      if (!v125[2]) {
        BUG();
      }
      --v119;
      uint64_t v94 = v120 + 2;
      uint64_t v95 = *(v120 - 1);
      uint64_t v84 = *v120;
      swift_bridgeObjectRetain_n(*v120, 2);
      v123._uint64_t countAndFlagsBits = v95;
      unint64_t v82 = specialized __RawDictionaryStorage.find<A>(_:)(v95, v84);
      uint64_t v120 = v94;
      if ((v96 & 1) == 0) {
        goto LABEL_61;
      }
    }
    LOBYTE(v76) = (_BYTE)v125;
    uint64_t v24 = v128;
    uint64_t v79 = v127;
  }
  (*(void (**)(uint64_t))(*(void *)(v113 - 8) + 8))(v117);
  swift_bridgeObjectRelease(v76);
  swift_release();
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v79, v24);
  return v126;
}

{
  uint64_t v1;
  int64_t v2;
  void *v3;
  void *v4;
  int64_t v5;
  void *v6;
  void *v7;
  void *v8;
  void *v9;
  uint64_t v10;
  char v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void (*v16)(uint64_t *, uint64_t);
  unint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  void *v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  void (*v31)(_OWORD *, void);
  uint64_t *v32;
  uint64_t *v33;
  uint64_t v34;
  uint64_t v35;
  unint64_t v36;
  int64_t v37;
  uint64_t v38;
  uint64_t (*v39)();
  uint64_t v40;
  unint64_t v41;
  unint64_t v42;
  BOOL v43;
  int64_t v44;
  unint64_t i;
  int64_t v46;
  unint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  void *v52;
  char isUniquelyReferenced_nonNull_native;
  char v54;
  BOOL v55;
  Swift::Int v56;
  char v57;
  Swift::Bool v58;
  void *v59;
  uint64_t v60;
  char v61;
  uint64_t v62;
  unint64_t v63;
  uint64_t v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  void *v68;
  unint64_t v69;
  char *v70;
  char v71;
  void *v72;
  unint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void *v77;
  uint64_t v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  unint64_t v82;
  char v83;
  uint64_t v84;
  uint64_t v85;
  void *v86;
  uint64_t v87;
  char v88;
  uint64_t v89;
  char v90;
  unint64_t v91;
  void *v92;
  uint64_t v93;
  uint64_t *v94;
  uint64_t v95;
  char v96;
  Swift::String v97;
  char v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  char v102;
  uint64_t v103;
  uint64_t v104;
  uint64_t v105;
  uint64_t v106;
  uint64_t v108;
  uint64_t *v109;
  void (*v110)(uint64_t *, uint64_t *, uint64_t);
  void (*v111)(uint64_t *, uint64_t);
  uint64_t v112;
  uint64_t v113;
  void *v114;
  uint64_t v115;
  uint64_t *v116;
  uint64_t v117;
  _OWORD v118[2];
  int64_t v119;
  uint64_t *v120;
  uint64_t v121;
  int64_t v122;
  Swift::String v123;
  long long v124;
  void *v125;
  void *v126;
  uint64_t v127;
  uint64_t v128;
  unint64_t v129;

  uint64_t v112 = v1;
  uint64_t v117 = a1;
  uint64_t v121 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<[String : UInt8]>>);
  uint64_t v127 = *(void *)(v121 - 8);
  int64_t v2 = *(void *)(v127 + 64);
  id v3 = alloca(v2);
  id v4 = alloca(v2);
  unint64_t v129 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : UInt8]>>>);
  int64_t v5 = *(void *)(*(void *)(v129 - 8) + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  *(void *)&long long v124 = &v108;
  char v8 = alloca(v5);
  id v9 = alloca(v5);
  double v116 = &v108;
  uint64_t v126 = _swiftEmptyArrayStorage;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for UInt8, &protocol witness table for String);
  char v11 = v10;
  *(void *)&v118[0] = v10;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : UInt8]>);
  uint64_t v13 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[String : UInt8]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[String : UInt8]>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v113 = v12;
  OptionalColumnProtocol.filled(with:)(v118, v12, v13);
  swift_bridgeObjectRelease(v11);
  uint64_t v14 = v127;
  uint64_t v15 = v121;
  uint64_t v110 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v127 + 16);
  v110(&v108, &v108, v121);
  uint64_t v115 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<[String : UInt8]>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<[String : UInt8]>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
  dispatch thunk of Collection.startIndex.getter(v15, v115);
  unint64_t v16 = *(void (**)(uint64_t *, uint64_t))(v14 + 8);
  uint64_t v109 = &v108;
  uint64_t v111 = v16;
  v16(&v108, v15);
  unint64_t v17 = v129;
  uint64_t v18 = v124;
  *(void *)(v124 + *(int *)(v129 + 36)) = *(void *)&v118[0];
  uint64_t v19 = (uint64_t)v116;
  outlined init with take of DataFrame?(v18, (uint64_t)v116, &demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : UInt8]>>>);
  uint64_t v20 = *(int *)(v17 + 36);
  uint64_t v21 = *(void *)(v19 + v20);
  uint64_t v22 = v15;
  uint64_t v23 = v115;
  dispatch thunk of Collection.endIndex.getter(v22, v115);
  if (v21 == *(void *)&v118[0])
  {
    unint64_t v129 = 0;
    uint64_t v125 = _swiftEmptyDictionarySingleton;
    uint64_t v127 = 0;
    uint64_t v24 = 0;
    uint64_t v25 = (uint64_t)v116;
    goto LABEL_36;
  }
  char v26 = (uint64_t *)((char *)v116 + v20);
  uint64_t v125 = _swiftEmptyDictionarySingleton;
  uint64_t v24 = 0;
  uint64_t v127 = 0;
  unint64_t v129 = 0;
  uint64_t v25 = (uint64_t)v116;
  uint64_t v114 = v26;
  do
  {
    int64_t v27 = v26;
    uint64_t v28 = v23;
    uint64_t v29 = v25;
    uint64_t v30 = v121;
    char v31 = (void (*)(_OWORD *, void))dispatch thunk of Collection.subscript.read(v118, v27, v121, v28);
    uint64_t v128 = *v32;
    swift_bridgeObjectRetain(v128);
    v31(v118, 0);
    uint64_t v33 = v109;
    v110(v109, (uint64_t *)v29, v30);
    dispatch thunk of Collection.formIndex(after:)(v114, v30, v115);
    v111(v33, v30);
    uint64_t v34 = 1 << *(unsigned char *)(v128 + 32);
    uint64_t v35 = ~(-1 << v34);
    if (v34 >= 64) {
      uint64_t v35 = -1;
    }
    unint64_t v36 = *(void *)(v128 + 64) & v35;
    int64_t v122 = (unint64_t)(v34 + 63) >> 6;
    int64_t v37 = 0;
    uint64_t v38 = v30;
    uint64_t v39 = (uint64_t (*)())v127;
    while (1)
    {
      if (v36)
      {
        uint64_t v40 = v24;
        _BitScanForward64(&v41, v36);
        uint64_t v120 = (uint64_t *)((v36 - 1) & v36);
        unint64_t v42 = v41 | (v37 << 6);
        int64_t v119 = v37;
        goto LABEL_18;
      }
      BOOL v43 = __OFADD__(1, v37);
      int64_t v44 = v37 + 1;
      if (v43) {
        BUG();
      }
      if (v44 >= v122) {
        break;
      }
      unint64_t i = *(void *)(v128 + 8 * v44 + 64);
      if (i)
      {
        int64_t v46 = v44;
      }
      else
      {
        int64_t v46 = v44 + 1;
        if (v44 + 1 >= v122) {
          break;
        }
        unint64_t i = *(void *)(v128 + 8 * v44 + 72);
        if (!i)
        {
          int64_t v46 = v44 + 2;
          if (v44 + 2 >= v122) {
            break;
          }
          unint64_t i = *(void *)(v128 + 8 * v44 + 80);
          if (!i)
          {
            int64_t v46 = v44 + 3;
            if (v44 + 3 >= v122) {
              break;
            }
            for (unint64_t i = *(void *)(v128 + 8 * v44 + 88); !i; unint64_t i = *(void *)(v128 + 8 * v46 + 64))
            {
              BOOL v43 = __OFADD__(1, v46++);
              if (v43) {
                BUG();
              }
              if (v46 >= v122) {
                goto LABEL_35;
              }
            }
          }
        }
      }
      _BitScanForward64(&v47, i);
      uint64_t v40 = v24;
      uint64_t v120 = (uint64_t *)(i & (i - 1));
      int64_t v119 = v46;
      unint64_t v42 = v47 + (v46 << 6);
LABEL_18:
      uint64_t v48 = *(void *)(v128 + 48);
      uint64_t v49 = *(void *)(v48 + 16 * v42);
      uint64_t v50 = *(void *)(v48 + 16 * v42 + 8);
      LOBYTE(v123._object) = *(unsigned char *)(*(void *)(v128 + 56) + v42);
      swift_bridgeObjectRetain(v50);
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
      uint64_t v51 = swift_allocObject(&unk_39CEE0, 32, 7);
      *(void *)(v51 + 16) = specialized implicit closure #2 in static RecommenderModel.metrics<A, B>(expected:predicted:cutoffs:);
      *(void *)&long long v124 = v51;
      *(void *)(v51 + 24) = 0;
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v39, v40);
      uint64_t v52 = v125;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v125);
      *(void *)&v118[0] = v52;
      v123._uint64_t countAndFlagsBits = v49;
      uint64_t v127 = v50;
      unint64_t v129 = specialized __RawDictionaryStorage.find<A>(_:)(v49, v50);
      BOOL v55 = (v54 & 1) == 0;
      BOOL v43 = __OFADD__(v52[2], v55);
      Swift::Int v56 = v52[2] + v55;
      if (v43) {
        BUG();
      }
      char v57 = v54;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [UInt8]>);
      Swift::Bool v58 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v56);
      int64_t v59 = *(void **)&v118[0];
      uint64_t v60 = v127;
      if (v58)
      {
        unint64_t v129 = specialized __RawDictionaryStorage.find<A>(_:)(v123._countAndFlagsBits, v127);
        if ((v57 & 1) != (v61 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
          BUG();
        }
      }
      swift_bridgeObjectRelease(0);
      swift_bridgeObjectRetain((_BYTE)v59);
      if ((v57 & 1) == 0)
      {
        uint64_t v62 = (*(uint64_t (**)(void))(v124 + 16))();
        unint64_t v63 = v129;
        v59[(v129 >> 6) + 8] |= 1 << v129;
        uint64_t v64 = v59[6];
        uint64_t v65 = 16 * v63;
        *(void *)(v64 + v65) = v123._countAndFlagsBits;
        *(void *)(v64 + v65 + 8) = v60;
        *(void *)(v59[7] + 8 * v63) = v62;
        uint64_t v66 = v59[2];
        BOOL v43 = __OFADD__(1, v66);
        uint64_t v67 = v66 + 1;
        if (v43) {
          BUG();
        }
        v59[2] = v67;
        swift_bridgeObjectRetain(v60);
      }
      int64_t v68 = (void *)v59[7];
      swift_bridgeObjectRelease((_BYTE)v59);
      unint64_t v69 = v129;
      __m128 v70 = (char *)v68[v129];
      char v71 = swift_isUniquelyReferenced_nonNull_native(v70);
      v68[v69] = v70;
      uint64_t v125 = v68;
      Swift::Int v72 = v59;
      if (!v71)
      {
        __m128 v70 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v70 + 2) + 1, 1, (uint64_t)v70);
        v68[v129] = v70;
      }
      unint64_t v73 = *((void *)v70 + 2);
      if (*((void *)v70 + 3) >> 1 <= v73)
      {
        __m128 v70 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v70 + 3) >= 2uLL, v73 + 1, 1, (uint64_t)v70);
        v125[v129] = v70;
      }
      *((void *)v70 + 2) = v73 + 1;
      v70[v73 + 32] = (char)v123._object;
      swift_bridgeObjectRelease(v127);
      unint64_t v129 = (unint64_t)specialized implicit closure #2 in static RecommenderModel.metrics<A, B>(expected:predicted:cutoffs:);
      uint64_t v39 = thunk for @callee_guaranteed () -> (@owned [B])specialized partial apply;
      uint64_t v24 = v124;
      int64_t v37 = v119;
      uint64_t v125 = v72;
      uint64_t v38 = v121;
      unint64_t v36 = (unint64_t)v120;
    }
LABEL_35:
    uint64_t v127 = (uint64_t)v39;
    swift_release();
    uint64_t v74 = v38;
    *(void *)&long long v124 = *v114;
    uint64_t v75 = (uint64_t)v116;
    uint64_t v23 = v115;
    dispatch thunk of Collection.endIndex.getter(v74, v115);
    char v26 = v114;
    uint64_t v25 = v75;
  }
  while ((void)v124 != *(void *)&v118[0]);
LABEL_36:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v25, &demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : UInt8]>>>);
  uint64_t v76 = (uint64_t)v125;
  swift_bridgeObjectRetain_n(v125, 2);
  long long v77 = specialized _copyCollectionToContiguousArray<A>(_:)(v76);
  swift_bridgeObjectRelease(v76);
  *(void *)&v118[0] = v77;
  uint64_t v78 = v112;
  specialized MutableCollection<>.sort(by:)(v118);
  if (v78)
  {
    swift_release();
    BUG();
  }
  swift_bridgeObjectRelease(v76);
  v123._char object = *(void **)&v118[0];
  uint64_t v79 = v127;
  if (*(void *)(*(void *)&v118[0] + 16))
  {
    if (!*(void *)(v76 + 16)) {
      BUG();
    }
    int64_t v119 = *(void *)(*(void *)&v118[0] + 16);
    uint64_t v121 = 0;
    uint64_t v80 = *((void *)v123._object + 5);
    uint64_t v81 = *((void *)v123._object + 4);
    swift_bridgeObjectRetain_n(v80, 2);
    v123._uint64_t countAndFlagsBits = v81;
    *(void *)&long long v124 = v80;
    unint64_t v82 = specialized __RawDictionaryStorage.find<A>(_:)(v81, v80);
    if ((v83 & 1) == 0)
    {
      LOBYTE(v84) = v124;
LABEL_61:
      swift_bridgeObjectRelease(v84);
      BUG();
    }
    uint64_t v128 = v24;
    uint64_t v120 = (uint64_t *)((char *)v123._object + 56);
    uint64_t v126 = _swiftEmptyArrayStorage;
    uint64_t v84 = v124;
    while (1)
    {
      uint64_t v85 = *(void *)(*(void *)(v76 + 56) + 8 * v82);
      swift_bridgeObjectRetain(v85);
      *(void *)&long long v124 = v84;
      swift_bridgeObjectRelease(v84);
      uint64_t v86 = specialized _arrayForceCast<A, B>(_:)(v85);
      swift_bridgeObjectRelease(v85);
      uint64_t v87 = specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)((uint64_t)v86);
      if (v88 == -1)
      {
        swift_bridgeObjectRelease((_BYTE)v126);
        swift_release();
        *(void *)&v118[0] = 0;
        *((void *)&v118[0] + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(77);
        v97._char object = "Unknown MLMultiArrayType " + 0x8000000000000000;
        v97._uint64_t countAndFlagsBits = 0xD000000000000014;
        String.append(_:)(v97);
        v97._uint64_t countAndFlagsBits = v123._countAndFlagsBits;
        char v98 = v124;
        v97._char object = (void *)v124;
        String.append(_:)(v97);
        swift_bridgeObjectRelease(v98);
        v97._uint64_t countAndFlagsBits = 0x6C6F63206E692027;
        v97._char object = (void *)0xED000027206E6D75;
        String.append(_:)(v97);
        uint64_t v125 = (void *)v76;
        uint64_t v99 = v113;
        uint64_t v100 = Column.name.getter(v113);
        char v102 = (char)v101;
        v97._uint64_t countAndFlagsBits = v100;
        v97._char object = v101;
        String.append(_:)(v97);
        swift_bridgeObjectRelease(v102);
        v97._char object = "Dictionary feature '" + 0x8000000000000000;
        v97._uint64_t countAndFlagsBits = 0xD000000000000028;
        String.append(_:)(v97);
        long long v124 = v118[0];
        v97._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v97._object, 0, 0);
        *(_OWORD *)uint64_t v103 = v124;
        *(_OWORD *)(v103 + 16) = 0;
        *(_OWORD *)(v103 + 32) = 0;
        *(unsigned char *)(v103 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v97._object, v103, v104, v105, v106);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v99 - 8) + 8))(v117, v99);
        swift_bridgeObjectRelease((_BYTE)v125);
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v127, v128);
        return v126;
      }
      uint64_t v89 = v87;
      char v90 = v88;
      if (!swift_isUniquelyReferenced_nonNull_native(v126)) {
        uint64_t v126 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v126[2] + 1, 1, (uint64_t)v126);
      }
      unint64_t v91 = v126[2];
      if (v126[3] >> 1 <= v91) {
        uint64_t v126 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v126[3] >= 2uLL, v91 + 1, 1, (uint64_t)v126);
      }
      uint64_t v92 = v126;
      v126[2] = v91 + 1;
      uint64_t v93 = 4 * v91;
      v92[v93 + 4] = v123._countAndFlagsBits;
      v92[v93 + 5] = v124;
      v92[v93 + 6] = v89;
      LOBYTE(v92[v93 + 7]) = v90;
      if (v119 == 1) {
        break;
      }
      uint64_t v76 = (uint64_t)v125;
      if (!v125[2]) {
        BUG();
      }
      --v119;
      uint64_t v94 = v120 + 2;
      uint64_t v95 = *(v120 - 1);
      uint64_t v84 = *v120;
      swift_bridgeObjectRetain_n(*v120, 2);
      v123._uint64_t countAndFlagsBits = v95;
      unint64_t v82 = specialized __RawDictionaryStorage.find<A>(_:)(v95, v84);
      uint64_t v120 = v94;
      if ((v96 & 1) == 0) {
        goto LABEL_61;
      }
    }
    LOBYTE(v76) = (_BYTE)v125;
    uint64_t v24 = v128;
    uint64_t v79 = v127;
  }
  (*(void (**)(uint64_t))(*(void *)(v113 - 8) + 8))(v117);
  swift_bridgeObjectRelease(v76);
  swift_release();
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v79, v24);
  return v126;
}

{
  uint64_t v1;
  int64_t v2;
  void *v3;
  void *v4;
  int64_t v5;
  void *v6;
  void *v7;
  void *v8;
  void *v9;
  uint64_t v10;
  char v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void (*v16)(uint64_t *, uint64_t);
  unint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  void *v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  void (*v31)(_OWORD *, void);
  uint64_t *v32;
  uint64_t *v33;
  uint64_t v34;
  uint64_t v35;
  unint64_t v36;
  int64_t v37;
  uint64_t v38;
  uint64_t (*v39)();
  uint64_t v40;
  unint64_t v41;
  unint64_t v42;
  BOOL v43;
  int64_t v44;
  unint64_t i;
  int64_t v46;
  unint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  void *v52;
  char isUniquelyReferenced_nonNull_native;
  char v54;
  BOOL v55;
  Swift::Int v56;
  char v57;
  Swift::Bool v58;
  void *v59;
  uint64_t v60;
  char v61;
  uint64_t v62;
  unint64_t v63;
  uint64_t v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  void *v68;
  unint64_t v69;
  void *v70;
  char v71;
  void *v72;
  unint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void *v77;
  uint64_t v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  unint64_t v82;
  char v83;
  uint64_t v84;
  uint64_t v85;
  void *v86;
  uint64_t v87;
  char v88;
  uint64_t v89;
  char v90;
  unint64_t v91;
  void *v92;
  uint64_t v93;
  uint64_t *v94;
  uint64_t v95;
  char v96;
  Swift::String v97;
  char v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  char v102;
  uint64_t v103;
  uint64_t v104;
  uint64_t v105;
  uint64_t v106;
  uint64_t v108;
  uint64_t *v109;
  void (*v110)(uint64_t *, uint64_t *, uint64_t);
  void (*v111)(uint64_t *, uint64_t);
  uint64_t v112;
  uint64_t v113;
  void *v114;
  uint64_t v115;
  uint64_t *v116;
  uint64_t v117;
  _OWORD v118[2];
  int64_t v119;
  uint64_t *v120;
  uint64_t v121;
  int64_t v122;
  Swift::String v123;
  long long v124;
  void *v125;
  void *v126;
  uint64_t v127;
  uint64_t v128;
  unint64_t v129;

  uint64_t v112 = v1;
  uint64_t v117 = a1;
  uint64_t v121 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<[String : Int32]>>);
  uint64_t v127 = *(void *)(v121 - 8);
  int64_t v2 = *(void *)(v127 + 64);
  id v3 = alloca(v2);
  id v4 = alloca(v2);
  unint64_t v129 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Int32]>>>);
  int64_t v5 = *(void *)(*(void *)(v129 - 8) + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  *(void *)&long long v124 = &v108;
  char v8 = alloca(v5);
  id v9 = alloca(v5);
  double v116 = &v108;
  uint64_t v126 = _swiftEmptyArrayStorage;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for Int32, &protocol witness table for String);
  char v11 = v10;
  *(void *)&v118[0] = v10;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Int32]>);
  uint64_t v13 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[String : Int32]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[String : Int32]>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v113 = v12;
  OptionalColumnProtocol.filled(with:)(v118, v12, v13);
  swift_bridgeObjectRelease(v11);
  uint64_t v14 = v127;
  uint64_t v15 = v121;
  uint64_t v110 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v127 + 16);
  v110(&v108, &v108, v121);
  uint64_t v115 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<[String : Int32]>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<[String : Int32]>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
  dispatch thunk of Collection.startIndex.getter(v15, v115);
  unint64_t v16 = *(void (**)(uint64_t *, uint64_t))(v14 + 8);
  uint64_t v109 = &v108;
  uint64_t v111 = v16;
  v16(&v108, v15);
  unint64_t v17 = v129;
  uint64_t v18 = v124;
  *(void *)(v124 + *(int *)(v129 + 36)) = *(void *)&v118[0];
  uint64_t v19 = (uint64_t)v116;
  outlined init with take of DataFrame?(v18, (uint64_t)v116, &demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Int32]>>>);
  uint64_t v20 = *(int *)(v17 + 36);
  uint64_t v21 = *(void *)(v19 + v20);
  uint64_t v22 = v15;
  uint64_t v23 = v115;
  dispatch thunk of Collection.endIndex.getter(v22, v115);
  if (v21 == *(void *)&v118[0])
  {
    unint64_t v129 = 0;
    uint64_t v125 = _swiftEmptyDictionarySingleton;
    uint64_t v127 = 0;
    uint64_t v24 = 0;
    uint64_t v25 = (uint64_t)v116;
    goto LABEL_36;
  }
  char v26 = (uint64_t *)((char *)v116 + v20);
  uint64_t v125 = _swiftEmptyDictionarySingleton;
  uint64_t v24 = 0;
  uint64_t v127 = 0;
  unint64_t v129 = 0;
  uint64_t v25 = (uint64_t)v116;
  uint64_t v114 = v26;
  do
  {
    int64_t v27 = v26;
    uint64_t v28 = v23;
    uint64_t v29 = v25;
    uint64_t v30 = v121;
    char v31 = (void (*)(_OWORD *, void))dispatch thunk of Collection.subscript.read(v118, v27, v121, v28);
    uint64_t v128 = *v32;
    swift_bridgeObjectRetain(v128);
    v31(v118, 0);
    uint64_t v33 = v109;
    v110(v109, (uint64_t *)v29, v30);
    dispatch thunk of Collection.formIndex(after:)(v114, v30, v115);
    v111(v33, v30);
    uint64_t v34 = 1 << *(unsigned char *)(v128 + 32);
    uint64_t v35 = ~(-1 << v34);
    if (v34 >= 64) {
      uint64_t v35 = -1;
    }
    unint64_t v36 = *(void *)(v128 + 64) & v35;
    int64_t v122 = (unint64_t)(v34 + 63) >> 6;
    int64_t v37 = 0;
    uint64_t v38 = v30;
    uint64_t v39 = (uint64_t (*)())v127;
    while (1)
    {
      if (v36)
      {
        uint64_t v40 = v24;
        _BitScanForward64(&v41, v36);
        uint64_t v120 = (uint64_t *)((v36 - 1) & v36);
        unint64_t v42 = v41 | (v37 << 6);
        int64_t v119 = v37;
        goto LABEL_18;
      }
      BOOL v43 = __OFADD__(1, v37);
      int64_t v44 = v37 + 1;
      if (v43) {
        BUG();
      }
      if (v44 >= v122) {
        break;
      }
      unint64_t i = *(void *)(v128 + 8 * v44 + 64);
      if (i)
      {
        int64_t v46 = v44;
      }
      else
      {
        int64_t v46 = v44 + 1;
        if (v44 + 1 >= v122) {
          break;
        }
        unint64_t i = *(void *)(v128 + 8 * v44 + 72);
        if (!i)
        {
          int64_t v46 = v44 + 2;
          if (v44 + 2 >= v122) {
            break;
          }
          unint64_t i = *(void *)(v128 + 8 * v44 + 80);
          if (!i)
          {
            int64_t v46 = v44 + 3;
            if (v44 + 3 >= v122) {
              break;
            }
            for (unint64_t i = *(void *)(v128 + 8 * v44 + 88); !i; unint64_t i = *(void *)(v128 + 8 * v46 + 64))
            {
              BOOL v43 = __OFADD__(1, v46++);
              if (v43) {
                BUG();
              }
              if (v46 >= v122) {
                goto LABEL_35;
              }
            }
          }
        }
      }
      _BitScanForward64(&v47, i);
      uint64_t v40 = v24;
      uint64_t v120 = (uint64_t *)(i & (i - 1));
      int64_t v119 = v46;
      unint64_t v42 = v47 + (v46 << 6);
LABEL_18:
      uint64_t v48 = *(void *)(v128 + 48);
      uint64_t v49 = *(void *)(v48 + 16 * v42);
      uint64_t v50 = *(void *)(v48 + 16 * v42 + 8);
      LODWORD(v123._object) = *(_DWORD *)(*(void *)(v128 + 56) + 4 * v42);
      swift_bridgeObjectRetain(v50);
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
      uint64_t v51 = swift_allocObject(&unk_39CF08, 32, 7);
      *(void *)(v51 + 16) = specialized implicit closure #2 in static RecommenderModel.metrics<A, B>(expected:predicted:cutoffs:);
      *(void *)&long long v124 = v51;
      *(void *)(v51 + 24) = 0;
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v39, v40);
      uint64_t v52 = v125;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v125);
      *(void *)&v118[0] = v52;
      v123._uint64_t countAndFlagsBits = v49;
      uint64_t v127 = v50;
      unint64_t v129 = specialized __RawDictionaryStorage.find<A>(_:)(v49, v50);
      BOOL v55 = (v54 & 1) == 0;
      BOOL v43 = __OFADD__(v52[2], v55);
      Swift::Int v56 = v52[2] + v55;
      if (v43) {
        BUG();
      }
      char v57 = v54;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [Int32]>);
      Swift::Bool v58 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v56);
      int64_t v59 = *(void **)&v118[0];
      uint64_t v60 = v127;
      if (v58)
      {
        unint64_t v129 = specialized __RawDictionaryStorage.find<A>(_:)(v123._countAndFlagsBits, v127);
        if ((v57 & 1) != (v61 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
          BUG();
        }
      }
      swift_bridgeObjectRelease(0);
      swift_bridgeObjectRetain((_BYTE)v59);
      if ((v57 & 1) == 0)
      {
        uint64_t v62 = (*(uint64_t (**)(void))(v124 + 16))();
        unint64_t v63 = v129;
        v59[(v129 >> 6) + 8] |= 1 << v129;
        uint64_t v64 = v59[6];
        uint64_t v65 = 16 * v63;
        *(void *)(v64 + v65) = v123._countAndFlagsBits;
        *(void *)(v64 + v65 + 8) = v60;
        *(void *)(v59[7] + 8 * v63) = v62;
        uint64_t v66 = v59[2];
        BOOL v43 = __OFADD__(1, v66);
        uint64_t v67 = v66 + 1;
        if (v43) {
          BUG();
        }
        v59[2] = v67;
        swift_bridgeObjectRetain(v60);
      }
      int64_t v68 = (void *)v59[7];
      swift_bridgeObjectRelease((_BYTE)v59);
      unint64_t v69 = v129;
      __m128 v70 = (void *)v68[v129];
      char v71 = swift_isUniquelyReferenced_nonNull_native(v70);
      v68[v69] = v70;
      uint64_t v125 = v68;
      Swift::Int v72 = v59;
      if (!v71)
      {
        __m128 v70 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v70[2] + 1, 1, (uint64_t)v70);
        v68[v129] = v70;
      }
      unint64_t v73 = v70[2];
      if (v70[3] >> 1 <= v73)
      {
        __m128 v70 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v70[3] >= 2uLL, v73 + 1, 1, (uint64_t)v70);
        v125[v129] = v70;
      }
      v70[2] = v73 + 1;
      *((_DWORD *)v70 + v73 + 8) = v123._object;
      swift_bridgeObjectRelease(v127);
      unint64_t v129 = (unint64_t)specialized implicit closure #2 in static RecommenderModel.metrics<A, B>(expected:predicted:cutoffs:);
      uint64_t v39 = thunk for @callee_guaranteed () -> (@owned [B])specialized partial apply;
      uint64_t v24 = v124;
      int64_t v37 = v119;
      uint64_t v125 = v72;
      uint64_t v38 = v121;
      unint64_t v36 = (unint64_t)v120;
    }
LABEL_35:
    uint64_t v127 = (uint64_t)v39;
    swift_release();
    uint64_t v74 = v38;
    *(void *)&long long v124 = *v114;
    uint64_t v75 = (uint64_t)v116;
    uint64_t v23 = v115;
    dispatch thunk of Collection.endIndex.getter(v74, v115);
    char v26 = v114;
    uint64_t v25 = v75;
  }
  while ((void)v124 != *(void *)&v118[0]);
LABEL_36:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v25, &demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Int32]>>>);
  uint64_t v76 = (uint64_t)v125;
  swift_bridgeObjectRetain_n(v125, 2);
  long long v77 = specialized _copyCollectionToContiguousArray<A>(_:)(v76);
  swift_bridgeObjectRelease(v76);
  *(void *)&v118[0] = v77;
  uint64_t v78 = v112;
  specialized MutableCollection<>.sort(by:)(v118);
  if (v78)
  {
    swift_release();
    BUG();
  }
  swift_bridgeObjectRelease(v76);
  v123._char object = *(void **)&v118[0];
  uint64_t v79 = v127;
  if (*(void *)(*(void *)&v118[0] + 16))
  {
    if (!*(void *)(v76 + 16)) {
      BUG();
    }
    int64_t v119 = *(void *)(*(void *)&v118[0] + 16);
    uint64_t v121 = 0;
    uint64_t v80 = *((void *)v123._object + 5);
    uint64_t v81 = *((void *)v123._object + 4);
    swift_bridgeObjectRetain_n(v80, 2);
    v123._uint64_t countAndFlagsBits = v81;
    *(void *)&long long v124 = v80;
    unint64_t v82 = specialized __RawDictionaryStorage.find<A>(_:)(v81, v80);
    if ((v83 & 1) == 0)
    {
      LOBYTE(v84) = v124;
LABEL_61:
      swift_bridgeObjectRelease(v84);
      BUG();
    }
    uint64_t v128 = v24;
    uint64_t v120 = (uint64_t *)((char *)v123._object + 56);
    uint64_t v126 = _swiftEmptyArrayStorage;
    uint64_t v84 = v124;
    while (1)
    {
      uint64_t v85 = *(void *)(*(void *)(v76 + 56) + 8 * v82);
      swift_bridgeObjectRetain(v85);
      *(void *)&long long v124 = v84;
      swift_bridgeObjectRelease(v84);
      uint64_t v86 = specialized _arrayForceCast<A, B>(_:)(v85);
      swift_bridgeObjectRelease(v85);
      uint64_t v87 = specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)((uint64_t)v86);
      if (v88 == -1)
      {
        swift_bridgeObjectRelease((_BYTE)v126);
        swift_release();
        *(void *)&v118[0] = 0;
        *((void *)&v118[0] + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(77);
        v97._char object = "Unknown MLMultiArrayType " + 0x8000000000000000;
        v97._uint64_t countAndFlagsBits = 0xD000000000000014;
        String.append(_:)(v97);
        v97._uint64_t countAndFlagsBits = v123._countAndFlagsBits;
        char v98 = v124;
        v97._char object = (void *)v124;
        String.append(_:)(v97);
        swift_bridgeObjectRelease(v98);
        v97._uint64_t countAndFlagsBits = 0x6C6F63206E692027;
        v97._char object = (void *)0xED000027206E6D75;
        String.append(_:)(v97);
        uint64_t v125 = (void *)v76;
        uint64_t v99 = v113;
        uint64_t v100 = Column.name.getter(v113);
        char v102 = (char)v101;
        v97._uint64_t countAndFlagsBits = v100;
        v97._char object = v101;
        String.append(_:)(v97);
        swift_bridgeObjectRelease(v102);
        v97._char object = "Dictionary feature '" + 0x8000000000000000;
        v97._uint64_t countAndFlagsBits = 0xD000000000000028;
        String.append(_:)(v97);
        long long v124 = v118[0];
        v97._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v97._object, 0, 0);
        *(_OWORD *)uint64_t v103 = v124;
        *(_OWORD *)(v103 + 16) = 0;
        *(_OWORD *)(v103 + 32) = 0;
        *(unsigned char *)(v103 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v97._object, v103, v104, v105, v106);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v99 - 8) + 8))(v117, v99);
        swift_bridgeObjectRelease((_BYTE)v125);
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v127, v128);
        return v126;
      }
      uint64_t v89 = v87;
      char v90 = v88;
      if (!swift_isUniquelyReferenced_nonNull_native(v126)) {
        uint64_t v126 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v126[2] + 1, 1, (uint64_t)v126);
      }
      unint64_t v91 = v126[2];
      if (v126[3] >> 1 <= v91) {
        uint64_t v126 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v126[3] >= 2uLL, v91 + 1, 1, (uint64_t)v126);
      }
      uint64_t v92 = v126;
      v126[2] = v91 + 1;
      uint64_t v93 = 4 * v91;
      v92[v93 + 4] = v123._countAndFlagsBits;
      v92[v93 + 5] = v124;
      v92[v93 + 6] = v89;
      LOBYTE(v92[v93 + 7]) = v90;
      if (v119 == 1) {
        break;
      }
      uint64_t v76 = (uint64_t)v125;
      if (!v125[2]) {
        BUG();
      }
      --v119;
      uint64_t v94 = v120 + 2;
      uint64_t v95 = *(v120 - 1);
      uint64_t v84 = *v120;
      swift_bridgeObjectRetain_n(*v120, 2);
      v123._uint64_t countAndFlagsBits = v95;
      unint64_t v82 = specialized __RawDictionaryStorage.find<A>(_:)(v95, v84);
      uint64_t v120 = v94;
      if ((v96 & 1) == 0) {
        goto LABEL_61;
      }
    }
    LOBYTE(v76) = (_BYTE)v125;
    uint64_t v24 = v128;
    uint64_t v79 = v127;
  }
  (*(void (**)(uint64_t))(*(void *)(v113 - 8) + 8))(v117);
  swift_bridgeObjectRelease(v76);
  swift_release();
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v79, v24);
  return v126;
}

{
  uint64_t v1;
  int64_t v2;
  void *v3;
  void *v4;
  int64_t v5;
  void *v6;
  void *v7;
  void *v8;
  void *v9;
  uint64_t v10;
  char v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void (*v16)(uint64_t *, uint64_t);
  unint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  void *v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  void (*v31)(_OWORD *, void);
  uint64_t *v32;
  uint64_t *v33;
  uint64_t v34;
  uint64_t v35;
  unint64_t v36;
  int64_t v37;
  uint64_t v38;
  uint64_t (*v39)(void);
  uint64_t v40;
  unint64_t v41;
  unint64_t v42;
  BOOL v43;
  int64_t v44;
  unint64_t i;
  int64_t v46;
  unint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  void *v52;
  char isUniquelyReferenced_nonNull_native;
  char v54;
  BOOL v55;
  Swift::Int v56;
  char v57;
  Swift::Bool v58;
  void *v59;
  uint64_t v60;
  char v61;
  uint64_t v62;
  unint64_t v63;
  uint64_t v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  void *v68;
  unint64_t v69;
  void *v70;
  char v71;
  void *v72;
  unint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void *v77;
  uint64_t v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  unint64_t v82;
  char v83;
  uint64_t v84;
  uint64_t v85;
  void *v86;
  uint64_t v87;
  char v88;
  uint64_t v89;
  char v90;
  unint64_t v91;
  void *v92;
  uint64_t v93;
  uint64_t *v94;
  uint64_t v95;
  char v96;
  Swift::String v97;
  char v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  char v102;
  uint64_t v103;
  uint64_t v104;
  uint64_t v105;
  uint64_t v106;
  uint64_t v108;
  uint64_t *v109;
  void (*v110)(uint64_t *, uint64_t *, uint64_t);
  void (*v111)(uint64_t *, uint64_t);
  uint64_t v112;
  uint64_t v113;
  void *v114;
  uint64_t v115;
  uint64_t *v116;
  uint64_t v117;
  _OWORD v118[2];
  int64_t v119;
  uint64_t *v120;
  uint64_t v121;
  int64_t v122;
  Swift::String v123;
  long long v124;
  void *v125;
  void *v126;
  uint64_t v127;
  uint64_t v128;
  unint64_t v129;

  uint64_t v112 = v1;
  uint64_t v117 = a1;
  uint64_t v121 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<[String : Double]>>);
  uint64_t v127 = *(void *)(v121 - 8);
  int64_t v2 = *(void *)(v127 + 64);
  id v3 = alloca(v2);
  id v4 = alloca(v2);
  unint64_t v129 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Double]>>>);
  int64_t v5 = *(void *)(*(void *)(v129 - 8) + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  *(void *)&long long v124 = &v108;
  char v8 = alloca(v5);
  id v9 = alloca(v5);
  double v116 = &v108;
  uint64_t v126 = _swiftEmptyArrayStorage;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for Double, &protocol witness table for String);
  char v11 = v10;
  *(void *)&v118[0] = v10;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Double]>);
  uint64_t v13 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[String : Double]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[String : Double]>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v113 = v12;
  OptionalColumnProtocol.filled(with:)(v118, v12, v13);
  swift_bridgeObjectRelease(v11);
  uint64_t v14 = v127;
  uint64_t v15 = v121;
  uint64_t v110 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v127 + 16);
  v110(&v108, &v108, v121);
  uint64_t v115 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<[String : Double]>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<[String : Double]>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
  dispatch thunk of Collection.startIndex.getter(v15, v115);
  unint64_t v16 = *(void (**)(uint64_t *, uint64_t))(v14 + 8);
  uint64_t v109 = &v108;
  uint64_t v111 = v16;
  v16(&v108, v15);
  unint64_t v17 = v129;
  uint64_t v18 = v124;
  *(void *)(v124 + *(int *)(v129 + 36)) = *(void *)&v118[0];
  uint64_t v19 = (uint64_t)v116;
  outlined init with take of DataFrame?(v18, (uint64_t)v116, &demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Double]>>>);
  uint64_t v20 = *(int *)(v17 + 36);
  uint64_t v21 = *(void *)(v19 + v20);
  uint64_t v22 = v15;
  uint64_t v23 = v115;
  dispatch thunk of Collection.endIndex.getter(v22, v115);
  if (v21 == *(void *)&v118[0])
  {
    unint64_t v129 = 0;
    uint64_t v125 = _swiftEmptyDictionarySingleton;
    uint64_t v127 = 0;
    uint64_t v24 = 0;
    uint64_t v25 = (uint64_t)v116;
    goto LABEL_36;
  }
  char v26 = (uint64_t *)((char *)v116 + v20);
  uint64_t v125 = _swiftEmptyDictionarySingleton;
  uint64_t v24 = 0;
  uint64_t v127 = 0;
  unint64_t v129 = 0;
  uint64_t v25 = (uint64_t)v116;
  uint64_t v114 = v26;
  do
  {
    int64_t v27 = v26;
    uint64_t v28 = v23;
    uint64_t v29 = v25;
    uint64_t v30 = v121;
    char v31 = (void (*)(_OWORD *, void))dispatch thunk of Collection.subscript.read(v118, v27, v121, v28);
    uint64_t v128 = *v32;
    swift_bridgeObjectRetain(v128);
    v31(v118, 0);
    uint64_t v33 = v109;
    v110(v109, (uint64_t *)v29, v30);
    dispatch thunk of Collection.formIndex(after:)(v114, v30, v115);
    v111(v33, v30);
    uint64_t v34 = 1 << *(unsigned char *)(v128 + 32);
    uint64_t v35 = ~(-1 << v34);
    if (v34 >= 64) {
      uint64_t v35 = -1;
    }
    unint64_t v36 = *(void *)(v128 + 64) & v35;
    int64_t v122 = (unint64_t)(v34 + 63) >> 6;
    int64_t v37 = 0;
    uint64_t v38 = v30;
    uint64_t v39 = (uint64_t (*)(void))v127;
    while (1)
    {
      if (v36)
      {
        uint64_t v40 = v24;
        _BitScanForward64(&v41, v36);
        uint64_t v120 = (uint64_t *)((v36 - 1) & v36);
        unint64_t v42 = v41 | (v37 << 6);
        int64_t v119 = v37;
        goto LABEL_18;
      }
      BOOL v43 = __OFADD__(1, v37);
      int64_t v44 = v37 + 1;
      if (v43) {
        BUG();
      }
      if (v44 >= v122) {
        break;
      }
      unint64_t i = *(void *)(v128 + 8 * v44 + 64);
      if (i)
      {
        int64_t v46 = v44;
      }
      else
      {
        int64_t v46 = v44 + 1;
        if (v44 + 1 >= v122) {
          break;
        }
        unint64_t i = *(void *)(v128 + 8 * v44 + 72);
        if (!i)
        {
          int64_t v46 = v44 + 2;
          if (v44 + 2 >= v122) {
            break;
          }
          unint64_t i = *(void *)(v128 + 8 * v44 + 80);
          if (!i)
          {
            int64_t v46 = v44 + 3;
            if (v44 + 3 >= v122) {
              break;
            }
            for (unint64_t i = *(void *)(v128 + 8 * v44 + 88); !i; unint64_t i = *(void *)(v128 + 8 * v46 + 64))
            {
              BOOL v43 = __OFADD__(1, v46++);
              if (v43) {
                BUG();
              }
              if (v46 >= v122) {
                goto LABEL_35;
              }
            }
          }
        }
      }
      _BitScanForward64(&v47, i);
      uint64_t v40 = v24;
      uint64_t v120 = (uint64_t *)(i & (i - 1));
      int64_t v119 = v46;
      unint64_t v42 = v47 + (v46 << 6);
LABEL_18:
      uint64_t v48 = *(void *)(v128 + 48);
      uint64_t v49 = *(void *)(v48 + 16 * v42);
      uint64_t v50 = *(void *)(v48 + 16 * v42 + 8);
      v123._char object = *(void **)(*(void *)(v128 + 56) + 8 * v42);
      swift_bridgeObjectRetain(v50);
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
      uint64_t v51 = swift_allocObject(&unk_39CF30, 32, 7);
      *(void *)(v51 + 16) = specialized implicit closure #2 in static RecommenderModel.metrics<A, B>(expected:predicted:cutoffs:);
      *(void *)&long long v124 = v51;
      *(void *)(v51 + 24) = 0;
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v39, v40);
      uint64_t v52 = v125;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v125);
      *(void *)&v118[0] = v52;
      v123._uint64_t countAndFlagsBits = v49;
      uint64_t v127 = v50;
      unint64_t v129 = specialized __RawDictionaryStorage.find<A>(_:)(v49, v50);
      BOOL v55 = (v54 & 1) == 0;
      BOOL v43 = __OFADD__(v52[2], v55);
      Swift::Int v56 = v52[2] + v55;
      if (v43) {
        BUG();
      }
      char v57 = v54;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [Double]>);
      Swift::Bool v58 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v56);
      int64_t v59 = *(void **)&v118[0];
      uint64_t v60 = v127;
      if (v58)
      {
        unint64_t v129 = specialized __RawDictionaryStorage.find<A>(_:)(v123._countAndFlagsBits, v127);
        if ((v57 & 1) != (v61 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
          BUG();
        }
      }
      swift_bridgeObjectRelease(0);
      swift_bridgeObjectRetain((_BYTE)v59);
      if ((v57 & 1) == 0)
      {
        uint64_t v62 = (*(uint64_t (**)(void))(v124 + 16))();
        unint64_t v63 = v129;
        v59[(v129 >> 6) + 8] |= 1 << v129;
        uint64_t v64 = v59[6];
        uint64_t v65 = 16 * v63;
        *(void *)(v64 + v65) = v123._countAndFlagsBits;
        *(void *)(v64 + v65 + 8) = v60;
        *(void *)(v59[7] + 8 * v63) = v62;
        uint64_t v66 = v59[2];
        BOOL v43 = __OFADD__(1, v66);
        uint64_t v67 = v66 + 1;
        if (v43) {
          BUG();
        }
        v59[2] = v67;
        swift_bridgeObjectRetain(v60);
      }
      int64_t v68 = (void *)v59[7];
      swift_bridgeObjectRelease((_BYTE)v59);
      unint64_t v69 = v129;
      __m128 v70 = (void *)v68[v129];
      char v71 = swift_isUniquelyReferenced_nonNull_native(v70);
      v68[v69] = v70;
      uint64_t v125 = v68;
      Swift::Int v72 = v59;
      if (!v71)
      {
        __m128 v70 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v70[2] + 1, 1, (uint64_t)v70);
        v68[v129] = v70;
      }
      unint64_t v73 = v70[2];
      if (v70[3] >> 1 <= v73)
      {
        __m128 v70 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v70[3] >= 2uLL, v73 + 1, 1, (uint64_t)v70);
        v125[v129] = v70;
      }
      v70[2] = v73 + 1;
      v70[v73 + 4] = v123._object;
      swift_bridgeObjectRelease(v127);
      unint64_t v129 = (unint64_t)specialized implicit closure #2 in static RecommenderModel.metrics<A, B>(expected:predicted:cutoffs:);
      uint64_t v39 = partial apply for specialized thunk for @callee_guaranteed () -> (@owned [B]);
      uint64_t v24 = v124;
      int64_t v37 = v119;
      uint64_t v125 = v72;
      uint64_t v38 = v121;
      unint64_t v36 = (unint64_t)v120;
    }
LABEL_35:
    uint64_t v127 = (uint64_t)v39;
    swift_release();
    uint64_t v74 = v38;
    *(void *)&long long v124 = *v114;
    uint64_t v75 = (uint64_t)v116;
    uint64_t v23 = v115;
    dispatch thunk of Collection.endIndex.getter(v74, v115);
    char v26 = v114;
    uint64_t v25 = v75;
  }
  while ((void)v124 != *(void *)&v118[0]);
LABEL_36:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v25, &demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Double]>>>);
  uint64_t v76 = (uint64_t)v125;
  swift_bridgeObjectRetain_n(v125, 2);
  long long v77 = specialized _copyCollectionToContiguousArray<A>(_:)(v76);
  swift_bridgeObjectRelease(v76);
  *(void *)&v118[0] = v77;
  uint64_t v78 = v112;
  specialized MutableCollection<>.sort(by:)(v118);
  if (v78)
  {
    swift_release();
    BUG();
  }
  swift_bridgeObjectRelease(v76);
  v123._char object = *(void **)&v118[0];
  uint64_t v79 = v127;
  if (*(void *)(*(void *)&v118[0] + 16))
  {
    if (!*(void *)(v76 + 16)) {
      BUG();
    }
    int64_t v119 = *(void *)(*(void *)&v118[0] + 16);
    uint64_t v121 = 0;
    uint64_t v80 = *((void *)v123._object + 5);
    uint64_t v81 = *((void *)v123._object + 4);
    swift_bridgeObjectRetain_n(v80, 2);
    v123._uint64_t countAndFlagsBits = v81;
    *(void *)&long long v124 = v80;
    unint64_t v82 = specialized __RawDictionaryStorage.find<A>(_:)(v81, v80);
    if ((v83 & 1) == 0)
    {
      LOBYTE(v84) = v124;
LABEL_61:
      swift_bridgeObjectRelease(v84);
      BUG();
    }
    uint64_t v128 = v24;
    uint64_t v120 = (uint64_t *)((char *)v123._object + 56);
    uint64_t v126 = _swiftEmptyArrayStorage;
    uint64_t v84 = v124;
    while (1)
    {
      uint64_t v85 = *(void *)(*(void *)(v76 + 56) + 8 * v82);
      swift_bridgeObjectRetain(v85);
      *(void *)&long long v124 = v84;
      swift_bridgeObjectRelease(v84);
      uint64_t v86 = specialized _arrayForceCast<A, B>(_:)(v85);
      swift_bridgeObjectRelease(v85);
      uint64_t v87 = specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)((uint64_t)v86);
      if (v88 == -1)
      {
        swift_bridgeObjectRelease((_BYTE)v126);
        swift_release();
        *(void *)&v118[0] = 0;
        *((void *)&v118[0] + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(77);
        v97._char object = "Unknown MLMultiArrayType " + 0x8000000000000000;
        v97._uint64_t countAndFlagsBits = 0xD000000000000014;
        String.append(_:)(v97);
        v97._uint64_t countAndFlagsBits = v123._countAndFlagsBits;
        char v98 = v124;
        v97._char object = (void *)v124;
        String.append(_:)(v97);
        swift_bridgeObjectRelease(v98);
        v97._uint64_t countAndFlagsBits = 0x6C6F63206E692027;
        v97._char object = (void *)0xED000027206E6D75;
        String.append(_:)(v97);
        uint64_t v125 = (void *)v76;
        uint64_t v99 = v113;
        uint64_t v100 = Column.name.getter(v113);
        char v102 = (char)v101;
        v97._uint64_t countAndFlagsBits = v100;
        v97._char object = v101;
        String.append(_:)(v97);
        swift_bridgeObjectRelease(v102);
        v97._char object = "Dictionary feature '" + 0x8000000000000000;
        v97._uint64_t countAndFlagsBits = 0xD000000000000028;
        String.append(_:)(v97);
        long long v124 = v118[0];
        v97._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v97._object, 0, 0);
        *(_OWORD *)uint64_t v103 = v124;
        *(_OWORD *)(v103 + 16) = 0;
        *(_OWORD *)(v103 + 32) = 0;
        *(unsigned char *)(v103 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v97._object, v103, v104, v105, v106);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v99 - 8) + 8))(v117, v99);
        swift_bridgeObjectRelease((_BYTE)v125);
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v127, v128);
        return v126;
      }
      uint64_t v89 = v87;
      char v90 = v88;
      if (!swift_isUniquelyReferenced_nonNull_native(v126)) {
        uint64_t v126 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v126[2] + 1, 1, (uint64_t)v126);
      }
      unint64_t v91 = v126[2];
      if (v126[3] >> 1 <= v91) {
        uint64_t v126 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v126[3] >= 2uLL, v91 + 1, 1, (uint64_t)v126);
      }
      uint64_t v92 = v126;
      v126[2] = v91 + 1;
      uint64_t v93 = 4 * v91;
      v92[v93 + 4] = v123._countAndFlagsBits;
      v92[v93 + 5] = v124;
      v92[v93 + 6] = v89;
      LOBYTE(v92[v93 + 7]) = v90;
      if (v119 == 1) {
        break;
      }
      uint64_t v76 = (uint64_t)v125;
      if (!v125[2]) {
        BUG();
      }
      --v119;
      uint64_t v94 = v120 + 2;
      uint64_t v95 = *(v120 - 1);
      uint64_t v84 = *v120;
      swift_bridgeObjectRetain_n(*v120, 2);
      v123._uint64_t countAndFlagsBits = v95;
      unint64_t v82 = specialized __RawDictionaryStorage.find<A>(_:)(v95, v84);
      uint64_t v120 = v94;
      if ((v96 & 1) == 0) {
        goto LABEL_61;
      }
    }
    LOBYTE(v76) = (_BYTE)v125;
    uint64_t v24 = v128;
    uint64_t v79 = v127;
  }
  (*(void (**)(uint64_t))(*(void *)(v113 - 8) + 8))(v117);
  swift_bridgeObjectRelease(v76);
  swift_release();
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v79, v24);
  return v126;
}

{
  uint64_t v1;
  int64_t v2;
  void *v3;
  void *v4;
  int64_t v5;
  void *v6;
  void *v7;
  void *v8;
  void *v9;
  uint64_t v10;
  char v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void (*v16)(uint64_t *, uint64_t);
  unint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  void *v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  void (*v31)(_OWORD *, void);
  uint64_t *v32;
  uint64_t *v33;
  uint64_t v34;
  uint64_t v35;
  unint64_t v36;
  int64_t v37;
  uint64_t v38;
  uint64_t (*v39)();
  uint64_t v40;
  unint64_t v41;
  unint64_t v42;
  BOOL v43;
  int64_t v44;
  unint64_t i;
  int64_t v46;
  unint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  void *v52;
  char isUniquelyReferenced_nonNull_native;
  char v54;
  BOOL v55;
  Swift::Int v56;
  char v57;
  Swift::Bool v58;
  void *v59;
  uint64_t v60;
  char v61;
  uint64_t v62;
  unint64_t v63;
  uint64_t v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  void *v68;
  unint64_t v69;
  void *v70;
  char v71;
  void *v72;
  unint64_t v73;
  uint64_t v74;
  uint64_t v75;
  uint64_t v76;
  void *v77;
  uint64_t v78;
  uint64_t v79;
  uint64_t v80;
  uint64_t v81;
  unint64_t v82;
  char v83;
  uint64_t v84;
  uint64_t v85;
  void *v86;
  uint64_t v87;
  char v88;
  uint64_t v89;
  char v90;
  unint64_t v91;
  void *v92;
  uint64_t v93;
  uint64_t *v94;
  uint64_t v95;
  char v96;
  Swift::String v97;
  char v98;
  uint64_t v99;
  uint64_t v100;
  void *v101;
  char v102;
  uint64_t v103;
  uint64_t v104;
  uint64_t v105;
  uint64_t v106;
  uint64_t v108;
  uint64_t *v109;
  void (*v110)(uint64_t *, uint64_t *, uint64_t);
  void (*v111)(uint64_t *, uint64_t);
  uint64_t v112;
  uint64_t v113;
  void *v114;
  uint64_t v115;
  uint64_t *v116;
  uint64_t v117;
  _OWORD v118[2];
  int64_t v119;
  uint64_t *v120;
  uint64_t v121;
  int64_t v122;
  Swift::String v123;
  long long v124;
  void *v125;
  void *v126;
  uint64_t v127;
  uint64_t v128;
  unint64_t v129;

  uint64_t v112 = v1;
  uint64_t v117 = a1;
  uint64_t v121 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<[String : Float]>>);
  uint64_t v127 = *(void *)(v121 - 8);
  int64_t v2 = *(void *)(v127 + 64);
  id v3 = alloca(v2);
  id v4 = alloca(v2);
  unint64_t v129 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Float]>>>);
  int64_t v5 = *(void *)(*(void *)(v129 - 8) + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  *(void *)&long long v124 = &v108;
  char v8 = alloca(v5);
  id v9 = alloca(v5);
  double v116 = &v108;
  uint64_t v126 = _swiftEmptyArrayStorage;
  uint64_t v10 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for Float, &protocol witness table for String);
  char v11 = v10;
  *(void *)&v118[0] = v10;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Float]>);
  uint64_t v13 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[String : Float]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[String : Float]>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v113 = v12;
  OptionalColumnProtocol.filled(with:)(v118, v12, v13);
  swift_bridgeObjectRelease(v11);
  uint64_t v14 = v127;
  uint64_t v15 = v121;
  uint64_t v110 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v127 + 16);
  v110(&v108, &v108, v121);
  uint64_t v115 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<[String : Float]>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<[String : Float]>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
  dispatch thunk of Collection.startIndex.getter(v15, v115);
  unint64_t v16 = *(void (**)(uint64_t *, uint64_t))(v14 + 8);
  uint64_t v109 = &v108;
  uint64_t v111 = v16;
  v16(&v108, v15);
  unint64_t v17 = v129;
  uint64_t v18 = v124;
  *(void *)(v124 + *(int *)(v129 + 36)) = *(void *)&v118[0];
  uint64_t v19 = (uint64_t)v116;
  outlined init with take of DataFrame?(v18, (uint64_t)v116, &demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Float]>>>);
  uint64_t v20 = *(int *)(v17 + 36);
  uint64_t v21 = *(void *)(v19 + v20);
  uint64_t v22 = v15;
  uint64_t v23 = v115;
  dispatch thunk of Collection.endIndex.getter(v22, v115);
  if (v21 == *(void *)&v118[0])
  {
    unint64_t v129 = 0;
    uint64_t v125 = _swiftEmptyDictionarySingleton;
    uint64_t v127 = 0;
    uint64_t v24 = 0;
    uint64_t v25 = (uint64_t)v116;
    goto LABEL_36;
  }
  char v26 = (uint64_t *)((char *)v116 + v20);
  uint64_t v125 = _swiftEmptyDictionarySingleton;
  uint64_t v24 = 0;
  uint64_t v127 = 0;
  unint64_t v129 = 0;
  uint64_t v25 = (uint64_t)v116;
  uint64_t v114 = v26;
  do
  {
    int64_t v27 = v26;
    uint64_t v28 = v23;
    uint64_t v29 = v25;
    uint64_t v30 = v121;
    char v31 = (void (*)(_OWORD *, void))dispatch thunk of Collection.subscript.read(v118, v27, v121, v28);
    uint64_t v128 = *v32;
    swift_bridgeObjectRetain(v128);
    v31(v118, 0);
    uint64_t v33 = v109;
    v110(v109, (uint64_t *)v29, v30);
    dispatch thunk of Collection.formIndex(after:)(v114, v30, v115);
    v111(v33, v30);
    uint64_t v34 = 1 << *(unsigned char *)(v128 + 32);
    uint64_t v35 = ~(-1 << v34);
    if (v34 >= 64) {
      uint64_t v35 = -1;
    }
    unint64_t v36 = *(void *)(v128 + 64) & v35;
    int64_t v122 = (unint64_t)(v34 + 63) >> 6;
    int64_t v37 = 0;
    uint64_t v38 = v30;
    uint64_t v39 = (uint64_t (*)())v127;
    while (1)
    {
      if (v36)
      {
        uint64_t v40 = v24;
        _BitScanForward64(&v41, v36);
        uint64_t v120 = (uint64_t *)((v36 - 1) & v36);
        unint64_t v42 = v41 | (v37 << 6);
        int64_t v119 = v37;
        goto LABEL_18;
      }
      BOOL v43 = __OFADD__(1, v37);
      int64_t v44 = v37 + 1;
      if (v43) {
        BUG();
      }
      if (v44 >= v122) {
        break;
      }
      unint64_t i = *(void *)(v128 + 8 * v44 + 64);
      if (i)
      {
        int64_t v46 = v44;
      }
      else
      {
        int64_t v46 = v44 + 1;
        if (v44 + 1 >= v122) {
          break;
        }
        unint64_t i = *(void *)(v128 + 8 * v44 + 72);
        if (!i)
        {
          int64_t v46 = v44 + 2;
          if (v44 + 2 >= v122) {
            break;
          }
          unint64_t i = *(void *)(v128 + 8 * v44 + 80);
          if (!i)
          {
            int64_t v46 = v44 + 3;
            if (v44 + 3 >= v122) {
              break;
            }
            for (unint64_t i = *(void *)(v128 + 8 * v44 + 88); !i; unint64_t i = *(void *)(v128 + 8 * v46 + 64))
            {
              BOOL v43 = __OFADD__(1, v46++);
              if (v43) {
                BUG();
              }
              if (v46 >= v122) {
                goto LABEL_35;
              }
            }
          }
        }
      }
      _BitScanForward64(&v47, i);
      uint64_t v40 = v24;
      uint64_t v120 = (uint64_t *)(i & (i - 1));
      int64_t v119 = v46;
      unint64_t v42 = v47 + (v46 << 6);
LABEL_18:
      uint64_t v48 = *(void *)(v128 + 48);
      uint64_t v49 = *(void *)(v48 + 16 * v42);
      uint64_t v50 = *(void *)(v48 + 16 * v42 + 8);
      LODWORD(v123._object) = *(_DWORD *)(*(void *)(v128 + 56) + 4 * v42);
      swift_bridgeObjectRetain(v50);
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
      uint64_t v51 = swift_allocObject(&unk_39CF58, 32, 7);
      *(void *)(v51 + 16) = specialized implicit closure #2 in static RecommenderModel.metrics<A, B>(expected:predicted:cutoffs:);
      *(void *)&long long v124 = v51;
      *(void *)(v51 + 24) = 0;
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v39, v40);
      uint64_t v52 = v125;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v125);
      *(void *)&v118[0] = v52;
      v123._uint64_t countAndFlagsBits = v49;
      uint64_t v127 = v50;
      unint64_t v129 = specialized __RawDictionaryStorage.find<A>(_:)(v49, v50);
      BOOL v55 = (v54 & 1) == 0;
      BOOL v43 = __OFADD__(v52[2], v55);
      Swift::Int v56 = v52[2] + v55;
      if (v43) {
        BUG();
      }
      char v57 = v54;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [Float]>);
      Swift::Bool v58 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v56);
      int64_t v59 = *(void **)&v118[0];
      uint64_t v60 = v127;
      if (v58)
      {
        unint64_t v129 = specialized __RawDictionaryStorage.find<A>(_:)(v123._countAndFlagsBits, v127);
        if ((v57 & 1) != (v61 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
          BUG();
        }
      }
      swift_bridgeObjectRelease(0);
      swift_bridgeObjectRetain((_BYTE)v59);
      if ((v57 & 1) == 0)
      {
        uint64_t v62 = (*(uint64_t (**)(void))(v124 + 16))();
        unint64_t v63 = v129;
        v59[(v129 >> 6) + 8] |= 1 << v129;
        uint64_t v64 = v59[6];
        uint64_t v65 = 16 * v63;
        *(void *)(v64 + v65) = v123._countAndFlagsBits;
        *(void *)(v64 + v65 + 8) = v60;
        *(void *)(v59[7] + 8 * v63) = v62;
        uint64_t v66 = v59[2];
        BOOL v43 = __OFADD__(1, v66);
        uint64_t v67 = v66 + 1;
        if (v43) {
          BUG();
        }
        v59[2] = v67;
        swift_bridgeObjectRetain(v60);
      }
      int64_t v68 = (void *)v59[7];
      swift_bridgeObjectRelease((_BYTE)v59);
      unint64_t v69 = v129;
      __m128 v70 = (void *)v68[v129];
      char v71 = swift_isUniquelyReferenced_nonNull_native(v70);
      v68[v69] = v70;
      uint64_t v125 = v68;
      Swift::Int v72 = v59;
      if (!v71)
      {
        __m128 v70 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v70[2] + 1, 1, (uint64_t)v70);
        v68[v129] = v70;
      }
      unint64_t v73 = v70[2];
      if (v70[3] >> 1 <= v73)
      {
        __m128 v70 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v70[3] >= 2uLL, v73 + 1, 1, (uint64_t)v70);
        v125[v129] = v70;
      }
      v70[2] = v73 + 1;
      *((_DWORD *)v70 + v73 + 8) = v123._object;
      swift_bridgeObjectRelease(v127);
      unint64_t v129 = (unint64_t)specialized implicit closure #2 in static RecommenderModel.metrics<A, B>(expected:predicted:cutoffs:);
      uint64_t v39 = thunk for @callee_guaranteed () -> (@owned [B])specialized partial apply;
      uint64_t v24 = v124;
      int64_t v37 = v119;
      uint64_t v125 = v72;
      uint64_t v38 = v121;
      unint64_t v36 = (unint64_t)v120;
    }
LABEL_35:
    uint64_t v127 = (uint64_t)v39;
    swift_release();
    uint64_t v74 = v38;
    *(void *)&long long v124 = *v114;
    uint64_t v75 = (uint64_t)v116;
    uint64_t v23 = v115;
    dispatch thunk of Collection.endIndex.getter(v74, v115);
    char v26 = v114;
    uint64_t v25 = v75;
  }
  while ((void)v124 != *(void *)&v118[0]);
LABEL_36:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v25, &demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Float]>>>);
  uint64_t v76 = (uint64_t)v125;
  swift_bridgeObjectRetain_n(v125, 2);
  long long v77 = specialized _copyCollectionToContiguousArray<A>(_:)(v76);
  swift_bridgeObjectRelease(v76);
  *(void *)&v118[0] = v77;
  uint64_t v78 = v112;
  specialized MutableCollection<>.sort(by:)(v118);
  if (v78)
  {
    swift_release();
    BUG();
  }
  swift_bridgeObjectRelease(v76);
  v123._char object = *(void **)&v118[0];
  uint64_t v79 = v127;
  if (*(void *)(*(void *)&v118[0] + 16))
  {
    if (!*(void *)(v76 + 16)) {
      BUG();
    }
    int64_t v119 = *(void *)(*(void *)&v118[0] + 16);
    uint64_t v121 = 0;
    uint64_t v80 = *((void *)v123._object + 5);
    uint64_t v81 = *((void *)v123._object + 4);
    swift_bridgeObjectRetain_n(v80, 2);
    v123._uint64_t countAndFlagsBits = v81;
    *(void *)&long long v124 = v80;
    unint64_t v82 = specialized __RawDictionaryStorage.find<A>(_:)(v81, v80);
    if ((v83 & 1) == 0)
    {
      LOBYTE(v84) = v124;
LABEL_61:
      swift_bridgeObjectRelease(v84);
      BUG();
    }
    uint64_t v128 = v24;
    uint64_t v120 = (uint64_t *)((char *)v123._object + 56);
    uint64_t v126 = _swiftEmptyArrayStorage;
    uint64_t v84 = v124;
    while (1)
    {
      uint64_t v85 = *(void *)(*(void *)(v76 + 56) + 8 * v82);
      swift_bridgeObjectRetain(v85);
      *(void *)&long long v124 = v84;
      swift_bridgeObjectRelease(v84);
      uint64_t v86 = specialized _arrayForceCast<A, B>(_:)(v85);
      swift_bridgeObjectRelease(v85);
      uint64_t v87 = specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)((uint64_t)v86);
      if (v88 == -1)
      {
        swift_bridgeObjectRelease((_BYTE)v126);
        swift_release();
        *(void *)&v118[0] = 0;
        *((void *)&v118[0] + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(77);
        v97._char object = "Unknown MLMultiArrayType " + 0x8000000000000000;
        v97._uint64_t countAndFlagsBits = 0xD000000000000014;
        String.append(_:)(v97);
        v97._uint64_t countAndFlagsBits = v123._countAndFlagsBits;
        char v98 = v124;
        v97._char object = (void *)v124;
        String.append(_:)(v97);
        swift_bridgeObjectRelease(v98);
        v97._uint64_t countAndFlagsBits = 0x6C6F63206E692027;
        v97._char object = (void *)0xED000027206E6D75;
        String.append(_:)(v97);
        uint64_t v125 = (void *)v76;
        uint64_t v99 = v113;
        uint64_t v100 = Column.name.getter(v113);
        char v102 = (char)v101;
        v97._uint64_t countAndFlagsBits = v100;
        v97._char object = v101;
        String.append(_:)(v97);
        swift_bridgeObjectRelease(v102);
        v97._char object = "Dictionary feature '" + 0x8000000000000000;
        v97._uint64_t countAndFlagsBits = 0xD000000000000028;
        String.append(_:)(v97);
        long long v124 = v118[0];
        v97._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v97._object, 0, 0);
        *(_OWORD *)uint64_t v103 = v124;
        *(_OWORD *)(v103 + 16) = 0;
        *(_OWORD *)(v103 + 32) = 0;
        *(unsigned char *)(v103 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v97._object, v103, v104, v105, v106);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v99 - 8) + 8))(v117, v99);
        swift_bridgeObjectRelease((_BYTE)v125);
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v127, v128);
        return v126;
      }
      uint64_t v89 = v87;
      char v90 = v88;
      if (!swift_isUniquelyReferenced_nonNull_native(v126)) {
        uint64_t v126 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v126[2] + 1, 1, (uint64_t)v126);
      }
      unint64_t v91 = v126[2];
      if (v126[3] >> 1 <= v91) {
        uint64_t v126 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v126[3] >= 2uLL, v91 + 1, 1, (uint64_t)v126);
      }
      uint64_t v92 = v126;
      v126[2] = v91 + 1;
      uint64_t v93 = 4 * v91;
      v92[v93 + 4] = v123._countAndFlagsBits;
      v92[v93 + 5] = v124;
      v92[v93 + 6] = v89;
      LOBYTE(v92[v93 + 7]) = v90;
      if (v119 == 1) {
        break;
      }
      uint64_t v76 = (uint64_t)v125;
      if (!v125[2]) {
        BUG();
      }
      --v119;
      uint64_t v94 = v120 + 2;
      uint64_t v95 = *(v120 - 1);
      uint64_t v84 = *v120;
      swift_bridgeObjectRetain_n(*v120, 2);
      v123._uint64_t countAndFlagsBits = v95;
      unint64_t v82 = specialized __RawDictionaryStorage.find<A>(_:)(v95, v84);
      uint64_t v120 = v94;
      if ((v96 & 1) == 0) {
        goto LABEL_61;
      }
    }
    LOBYTE(v76) = (_BYTE)v125;
    uint64_t v24 = v128;
    uint64_t v79 = v127;
  }
  (*(void (**)(uint64_t))(*(void *)(v113 - 8) + 8))(v117);
  swift_bridgeObjectRelease(v76);
  swift_release();
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v129, 0);
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v79, v24);
  return v126;
}

{
  uint64_t v1;
  int64_t v2;
  void *v3;
  void *v4;
  int64_t v5;
  void *v6;
  void *v7;
  void *v8;
  void *v9;
  uint64_t v10;
  uint64_t v11;
  char v12;
  uint64_t v13;
  uint64_t v14;
  unsigned char *v15;
  uint64_t v16;
  unsigned char *v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  void *v26;
  uint64_t v27;
  uint64_t v28;
  void (*v29)(long long *, void);
  uint64_t *v30;
  uint64_t v31;
  unsigned char *v32;
  uint64_t v33;
  uint64_t v34;
  unint64_t countAndFlagsBits;
  int64_t v36;
  uint64_t (*v37)();
  unint64_t v38;
  unint64_t v39;
  uint64_t v40;
  uint64_t v41;
  int64_t v42;
  unint64_t v43;
  unint64_t v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  void *object;
  char isUniquelyReferenced_nonNull_native;
  char v50;
  BOOL v51;
  BOOL v52;
  Swift::Int v53;
  char v54;
  Swift::Bool v55;
  void *v56;
  char v57;
  uint64_t v58;
  unint64_t v59;
  uint64_t v60;
  uint64_t v61;
  char v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  unint64_t v66;
  void *v67;
  char v68;
  uint64_t v69;
  unint64_t v70;
  uint64_t v71;
  void *v72;
  void *v73;
  uint64_t v74;
  int64_t v75;
  uint64_t v76;
  uint64_t v77;
  uint64_t v78;
  unint64_t v79;
  char v80;
  uint64_t v81;
  uint64_t v82;
  void *v83;
  uint64_t v84;
  char v85;
  uint64_t v86;
  char v87;
  unint64_t v88;
  void *v89;
  uint64_t v90;
  uint64_t *v91;
  uint64_t v92;
  char v93;
  Swift::String v94;
  char v95;
  uint64_t v96;
  void *v97;
  char v98;
  uint64_t v99;
  uint64_t v100;
  uint64_t v101;
  uint64_t v102;
  unsigned char v104[32];
  long long v105;
  _OWORD v106[2];
  void (*v107)(unint64_t, unsigned char *, uint64_t);
  void (*v108)(unsigned char *, uint64_t);
  int64_t v109;
  uint64_t v110;
  void *v111;
  unsigned char *v112;
  uint64_t v113;
  long long v114;
  char v115[32];
  uint64_t v116;
  uint64_t v117;
  uint64_t v118;
  uint64_t v119;
  void *v120;
  unsigned char *v121;
  long long v122;
  Swift::String v123;
  int64_t v124;
  uint64_t *v125;
  void *v126;
  uint64_t v127;
  uint64_t v128;
  unint64_t v129;

  uint64_t v110 = v1;
  uint64_t v118 = a1;
  uint64_t v117 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<[String : Any?]>>);
  uint64_t v128 = *(void *)(v117 - 8);
  int64_t v2 = *(void *)(v128 + 64);
  id v3 = alloca(v2);
  id v4 = alloca(v2);
  uint64_t v112 = v104;
  uint64_t v127 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Any?]>>>);
  int64_t v5 = *(void *)(*(void *)(v127 - 8) + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  unint64_t v129 = (unint64_t)v104;
  char v8 = alloca(v5);
  id v9 = alloca(v5);
  uint64_t v121 = v104;
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Any?);
  uint64_t v126 = _swiftEmptyArrayStorage;
  char v11 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, v10, &protocol witness table for String);
  uint64_t v12 = v11;
  *(void *)&uint64_t v114 = v11;
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Any?]>);
  uint64_t v14 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[String : Any?]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[String : Any?]>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v15 = v112;
  double v116 = v13;
  OptionalColumnProtocol.filled(with:)(&v114, v13, v14);
  swift_bridgeObjectRelease(v12);
  unint64_t v16 = v128;
  unint64_t v17 = v15;
  uint64_t v18 = v117;
  uint64_t v107 = *(void (**)(unint64_t, unsigned char *, uint64_t))(v128 + 16);
  v107(v129, v15, v117);
  uint64_t v19 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<[String : Any?]>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<[String : Any?]>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
  dispatch thunk of Collection.startIndex.getter(v18, v19);
  uint64_t v108 = *(void (**)(unsigned char *, uint64_t))(v16 + 8);
  v108(v17, v18);
  uint64_t v20 = v127;
  uint64_t v21 = v129;
  *(void *)(v129 + *(int *)(v127 + 36)) = v114;
  uint64_t v22 = (uint64_t)v121;
  outlined init with take of DataFrame?(v21, (uint64_t)v121, &demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Any?]>>>);
  uint64_t v23 = *(int *)(v20 + 36);
  uint64_t v24 = *(void *)(v22 + v23);
  uint64_t v113 = v19;
  dispatch thunk of Collection.endIndex.getter(v117, v19);
  if (v24 == (void)v114)
  {
    uint64_t v127 = 0;
    v123._char object = _swiftEmptyDictionarySingleton;
    uint64_t v128 = 0;
    unint64_t v129 = 0;
    uint64_t v25 = (uint64_t)v121;
    goto LABEL_43;
  }
  char v26 = &v121[v23];
  v123._char object = _swiftEmptyDictionarySingleton;
  unint64_t v129 = 0;
  uint64_t v128 = 0;
  uint64_t v127 = 0;
  int64_t v27 = v117;
  uint64_t v28 = v113;
  uint64_t v120 = v26;
  do
  {
    uint64_t v29 = (void (*)(long long *, void))dispatch thunk of Collection.subscript.read(&v114, v26, v27, v28);
    char v31 = *v30;
    swift_bridgeObjectRetain(*v30);
    v29(&v114, 0);
    int64_t v32 = v112;
    v107((unint64_t)v112, v121, v27);
    dispatch thunk of Collection.formIndex(after:)(v120, v27, v28);
    v108(v32, v27);
    uint64_t v33 = 1 << *(unsigned char *)(v31 + 32);
    uint64_t v34 = ~(-1 << v33);
    if (v33 >= 64) {
      uint64_t v34 = -1;
    }
    uint64_t v125 = (uint64_t *)v31;
    uint64_t countAndFlagsBits = *(void *)(v31 + 64) & v34;
    long long v124 = (unint64_t)(v33 + 63) >> 6;
    uint64_t v109 = v124 - 1;
    unint64_t v36 = 0;
    int64_t v37 = (uint64_t (*)())v128;
    while (1)
    {
      if (countAndFlagsBits)
      {
        _BitScanForward64(&v38, countAndFlagsBits);
        v123._uint64_t countAndFlagsBits = (countAndFlagsBits - 1) & countAndFlagsBits;
        *(void *)&int64_t v122 = v36;
        uint64_t v39 = v38 | (v36 << 6);
LABEL_9:
        uint64_t v40 = v125[6];
        unint64_t v41 = *(void *)(v40 + 16 * v39 + 8);
        *(void *)&uint64_t v105 = *(void *)(v40 + 16 * v39);
        *((void *)&v105 + 1) = v41;
        outlined init with copy of Any?(v125[7] + 32 * v39, (uint64_t)v106);
        swift_bridgeObjectRetain(v41);
        goto LABEL_22;
      }
      unint64_t v42 = v36 + 1;
      if (__OFADD__(1, v36)) {
        BUG();
      }
      if (v42 < v124)
      {
        BOOL v43 = v125[v42 + 8];
        if (v43)
        {
          ++v36;
LABEL_14:
          _BitScanForward64(&v44, v43);
          v123._uint64_t countAndFlagsBits = v43 & (v43 - 1);
          *(void *)&int64_t v122 = v36;
          uint64_t v39 = v44 + (v36 << 6);
          goto LABEL_9;
        }
        v36 += 2;
        if (v42 + 1 >= v124)
        {
          unint64_t v36 = v42;
        }
        else
        {
          BOOL v43 = v125[v42 + 9];
          if (v43) {
            goto LABEL_14;
          }
          if (v42 + 2 < v124)
          {
            BOOL v43 = v125[v42 + 10];
            if (v43)
            {
              unint64_t v36 = v42 + 2;
              goto LABEL_14;
            }
            unint64_t v36 = v42 + 2;
            if (v42 + 3 < v124)
            {
              BOOL v43 = v125[v42 + 11];
              unint64_t v36 = v42 + 3;
              while (!v43)
              {
                uint64_t v52 = __OFADD__(1, v36++);
                if (v52) {
                  BUG();
                }
                if (v36 >= v124)
                {
                  unint64_t v36 = v109;
                  goto LABEL_21;
                }
                BOOL v43 = v125[v36 + 8];
              }
              goto LABEL_14;
            }
          }
        }
      }
LABEL_21:
      *(void *)&int64_t v122 = v36;
      memset(v106, 0, sizeof(v106));
      uint64_t v105 = 0;
      v123._uint64_t countAndFlagsBits = 0;
LABEL_22:
      outlined init with take of DataFrame?((uint64_t)&v105, (uint64_t)&v114, &demangling cache variable for type metadata for (key: String, value: Any?)?);
      uint64_t v45 = *((void *)&v114 + 1);
      if (!*((void *)&v114 + 1)) {
        break;
      }
      int64_t v46 = v114;
      outlined init with take of DataFrame?((uint64_t)v115, (uint64_t)&v105, &demangling cache variable for type metadata for Any?);
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v127, 0);
      outlined init with copy of Any?((uint64_t)&v105, (uint64_t)v104);
      unint64_t v47 = swift_allocObject(&unk_39CF80, 32, 7);
      *(void *)(v47 + 16) = specialized implicit closure #2 in static RecommenderModel.metrics<A, B>(expected:predicted:cutoffs:);
      uint64_t v128 = v47;
      *(void *)(v47 + 24) = 0;
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v37, v129);
      char object = v123._object;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v123._object);
      uint64_t v111 = object;
      int64_t v119 = v46;
      uint64_t v127 = v45;
      unint64_t v129 = specialized __RawDictionaryStorage.find<A>(_:)(v46, v45);
      uint64_t v51 = (v50 & 1) == 0;
      uint64_t v52 = __OFADD__(object[2], v51);
      int64_t v53 = object[2] + v51;
      if (v52) {
        BUG();
      }
      char v54 = v50;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [Any?]>);
      BOOL v55 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v53);
      Swift::Int v56 = v111;
      if (v55)
      {
        unint64_t v129 = specialized __RawDictionaryStorage.find<A>(_:)(v119, v127);
        if ((v54 & 1) != (v57 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
          BUG();
        }
      }
      swift_bridgeObjectRelease(0);
      swift_bridgeObjectRetain((_BYTE)v56);
      if ((v54 & 1) == 0)
      {
        Swift::Bool v58 = (*(uint64_t (**)(void))(v128 + 16))();
        int64_t v59 = v129;
        v56[(v129 >> 6) + 8] |= 1 << v129;
        uint64_t v60 = v56[6];
        char v61 = 16 * v59;
        *(void *)(v60 + v61) = v119;
        uint64_t v62 = v127;
        *(void *)(v60 + v61 + 8) = v127;
        *(void *)(v56[7] + 8 * v59) = v58;
        unint64_t v63 = v56[2];
        uint64_t v52 = __OFADD__(1, v63);
        uint64_t v64 = v63 + 1;
        if (v52) {
          BUG();
        }
        v56[2] = v64;
        swift_bridgeObjectRetain(v62);
      }
      uint64_t v65 = v56[7];
      v123._char object = v56;
      swift_bridgeObjectRelease((_BYTE)v56);
      uint64_t v66 = v129;
      uint64_t v67 = *(void **)(v65 + 8 * v129);
      int64_t v68 = swift_isUniquelyReferenced_nonNull_native(v67);
      *(void *)(v65 + 8 * v66) = v67;
      if (v68)
      {
        unint64_t v69 = v65;
      }
      else
      {
        uint64_t v67 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v67[2] + 1, 1, (uint64_t)v67);
        unint64_t v69 = v65;
        *(void *)(v65 + 8 * v129) = v67;
      }
      __m128 v70 = v67[2];
      if (v67[3] >> 1 <= v70)
      {
        uint64_t v67 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v67[3] >= 2uLL, v70 + 1, 1, (uint64_t)v67);
        *(void *)(v69 + 8 * v129) = v67;
      }
      v67[2] = v70 + 1;
      outlined init with take of DataFrame?((uint64_t)v104, (uint64_t)&v67[4 * v70 + 4], &demangling cache variable for type metadata for Any?);
      swift_bridgeObjectRelease(v127);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v105, &demangling cache variable for type metadata for Any?);
      uint64_t v127 = (uint64_t)specialized implicit closure #2 in static RecommenderModel.metrics<A, B>(expected:predicted:cutoffs:);
      int64_t v37 = thunk for @callee_guaranteed () -> (@owned [B])specialized partial apply;
      unint64_t v129 = v128;
      unint64_t v36 = v122;
      uint64_t countAndFlagsBits = v123._countAndFlagsBits;
    }
    uint64_t v128 = (uint64_t)v37;
    swift_release();
    *(void *)&int64_t v122 = *v120;
    char v71 = (uint64_t)v121;
    int64_t v27 = v117;
    uint64_t v28 = v113;
    dispatch thunk of Collection.endIndex.getter(v117, v113);
    char v26 = v120;
    uint64_t v25 = v71;
  }
  while ((void)v122 != (void)v114);
LABEL_43:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v25, &demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[String : Any?]>>>);
  Swift::Int v72 = v123._object;
  swift_bridgeObjectRetain_n(v123._object, 2);
  unint64_t v73 = specialized _copyCollectionToContiguousArray<A>(_:)((uint64_t)v72);
  swift_bridgeObjectRelease((_BYTE)v72);
  *(void *)&uint64_t v114 = v73;
  uint64_t v74 = v110;
  specialized MutableCollection<>.sort(by:)(&v114);
  if (v74)
  {
    swift_release();
    BUG();
  }
  swift_bridgeObjectRelease((_BYTE)v72);
  uint64_t v75 = v114;
  uint64_t v76 = v128;
  if (*(void *)(v114 + 16))
  {
    if (!v72[2]) {
      BUG();
    }
    int64_t v119 = *(void *)(v114 + 16);
    uint64_t v120 = 0;
    long long v77 = *(void *)(v114 + 40);
    uint64_t v78 = *(void *)(v114 + 32);
    swift_bridgeObjectRetain_n(v77, 2);
    v123._uint64_t countAndFlagsBits = v78;
    *(void *)&int64_t v122 = v77;
    uint64_t v79 = specialized __RawDictionaryStorage.find<A>(_:)(v78, v77);
    if ((v80 & 1) == 0)
    {
      LOBYTE(v81) = v122;
LABEL_68:
      swift_bridgeObjectRelease(v81);
      BUG();
    }
    long long v124 = v75;
    uint64_t v125 = (uint64_t *)(v75 + 56);
    uint64_t v126 = _swiftEmptyArrayStorage;
    uint64_t v81 = v122;
    while (1)
    {
      unint64_t v82 = *(void *)(v72[7] + 8 * v79);
      swift_bridgeObjectRetain(v82);
      *(void *)&int64_t v122 = v81;
      swift_bridgeObjectRelease(v81);
      char v83 = specialized _arrayForceCast<A, B>(_:)(v82);
      swift_bridgeObjectRelease(v82);
      uint64_t v84 = specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)((uint64_t)v83);
      if (v85 == -1)
      {
        swift_bridgeObjectRelease((_BYTE)v126);
        swift_release();
        *(void *)&uint64_t v114 = 0;
        *((void *)&v114 + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(77);
        v94._char object = "Unknown MLMultiArrayType " + 0x8000000000000000;
        v94._uint64_t countAndFlagsBits = 0xD000000000000014;
        String.append(_:)(v94);
        v94._uint64_t countAndFlagsBits = v123._countAndFlagsBits;
        uint64_t v95 = v122;
        v94._char object = (void *)v122;
        String.append(_:)(v94);
        swift_bridgeObjectRelease(v95);
        v94._uint64_t countAndFlagsBits = 0x6C6F63206E692027;
        v94._char object = (void *)0xED000027206E6D75;
        String.append(_:)(v94);
        char v96 = Column.name.getter(v116);
        v123._char object = v72;
        char v98 = (char)v97;
        v94._uint64_t countAndFlagsBits = v96;
        v94._char object = v97;
        String.append(_:)(v94);
        swift_bridgeObjectRelease(v98);
        v94._char object = "Dictionary feature '" + 0x8000000000000000;
        v94._uint64_t countAndFlagsBits = 0xD000000000000028;
        String.append(_:)(v94);
        int64_t v122 = v114;
        v94._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v94._object, 0, 0);
        *(_OWORD *)uint64_t v99 = v122;
        *(_OWORD *)(v99 + 16) = 0;
        *(_OWORD *)(v99 + 32) = 0;
        *(unsigned char *)(v99 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v94._object, v99, v100, v101, v102);
        (*(void (**)(uint64_t))(*(void *)(v116 - 8) + 8))(v118);
        swift_bridgeObjectRelease(v123._object);
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v127, 0);
        _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v128, v129);
        return v126;
      }
      uint64_t v86 = v84;
      uint64_t v87 = v85;
      if (!swift_isUniquelyReferenced_nonNull_native(v126)) {
        uint64_t v126 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v126[2] + 1, 1, (uint64_t)v126);
      }
      char v88 = v126[2];
      if (v126[3] >> 1 <= v88) {
        uint64_t v126 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v126[3] >= 2uLL, v88 + 1, 1, (uint64_t)v126);
      }
      uint64_t v89 = v126;
      v126[2] = v88 + 1;
      char v90 = 4 * v88;
      v89[v90 + 4] = v123._countAndFlagsBits;
      v89[v90 + 5] = v122;
      v89[v90 + 6] = v86;
      LOBYTE(v89[v90 + 7]) = v87;
      if (v119 == 1) {
        break;
      }
      Swift::Int v72 = v123._object;
      if (!*((void *)v123._object + 2)) {
        BUG();
      }
      --v119;
      unint64_t v91 = v125 + 2;
      uint64_t v92 = *(v125 - 1);
      uint64_t v81 = *v125;
      swift_bridgeObjectRetain_n(*v125, 2);
      v123._uint64_t countAndFlagsBits = v92;
      uint64_t v79 = specialized __RawDictionaryStorage.find<A>(_:)(v92, v81);
      uint64_t v125 = v91;
      if ((v93 & 1) == 0) {
        goto LABEL_68;
      }
    }
    LOBYTE(v72) = v123._object;
    uint64_t v76 = v128;
  }
  (*(void (**)(uint64_t))(*(void *)(v116 - 8) + 8))(v118);
  swift_bridgeObjectRelease((_BYTE)v72);
  swift_release();
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v127, 0);
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v76, v129);
  return v126;
}

char static ColumnDescriptor.== infix(_:_:)(uint64_t a1, uint64_t a2, void *a3, char a4, uint64_t a5, uint64_t a6, void *a7, char a8)
{
  if (a1 == a5 && a2 == a6 || (_stringCompareWithSmolCheck(_:_:expecting:)(a1, a2, a5, a6, 0) & 1) != 0) {
    return static ColumnDescriptor.ColumnTypeDescriptor.== infix(_:_:)(a3, a4, a7, a8);
  }
  else {
    return 0;
  }
}

char ColumnDescriptor.CodingKeys.init(stringValue:)(uint64_t a1, unint64_t a2)
{
  if (a1 == 1701667182 && a2 == 0xE400000000000000)
  {
    unint64_t v2 = 0xE400000000000000;
LABEL_6:
    swift_bridgeObjectRelease(v2);
    return 0;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(1701667182, 0xE400000000000000, a1, a2, 0))
  {
    unint64_t v2 = a2;
    goto LABEL_6;
  }
  if (a1 == 0x6373654465707974 && a2 == 0xEE00726F74706972)
  {
    swift_bridgeObjectRelease(0xEE00726F74706972);
    return 1;
  }
  else
  {
    char v4 = _stringCompareWithSmolCheck(_:_:expecting:)(0x6373654465707974, 0xEE00726F74706972, a1, a2, 0);
    swift_bridgeObjectRelease(a2);
    return 2 - (v4 & 1);
  }
}

uint64_t ColumnDescriptor.CodingKeys.stringValue.getter(char a1)
{
  uint64_t result = 0x6373654465707974;
  if ((a1 & 1) == 0) {
    return 1701667182;
  }
  return result;
}

uint64_t ColumnDescriptor.encode(to:)(void *a1, uint64_t a2, uint64_t a3, uint64_t a4, int a5)
{
  uint64_t v17 = v5;
  int v23 = a5;
  uint64_t v21 = a4;
  uint64_t v18 = a3;
  uint64_t v19 = a2;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedEncodingContainer<ColumnDescriptor.CodingKeys>);
  uint64_t v22 = *(void *)(v6 - 8);
  int64_t v7 = *(void *)(v22 + 64);
  char v8 = alloca(v7);
  id v9 = alloca(v7);
  uint64_t v10 = a1[3];
  uint64_t v20 = a1[4];
  __swift_project_boxed_opaque_existential_0Tm(a1, v10);
  uint64_t v11 = lazy protocol witness table accessor for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys();
  dispatch thunk of Encoder.container<A>(keyedBy:)(&unk_39D248, &unk_39D248, v11, v10, v20);
  char v24 = 0;
  KeyedEncodingContainer.encode(_:forKey:)(a2, v18, &v24, v6);
  if (!v5)
  {
    uint64_t v15 = v21;
    char v16 = v23;
    v25[0] = 1;
    uint64_t v13 = lazy protocol witness table accessor for type ColumnDescriptor.ColumnTypeDescriptor and conformance ColumnDescriptor.ColumnTypeDescriptor();
    KeyedEncodingContainer.encode<A>(_:forKey:)(&v15, v25, v6, &type metadata for ColumnDescriptor.ColumnTypeDescriptor, v13);
  }
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v22 + 8))(&v14, v6);
}

uint64_t ColumnDescriptor.init(from:)(void *a1)
{
  uint64_t v21 = v1;
  uint64_t v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedDecodingContainer<ColumnDescriptor.CodingKeys>);
  uint64_t v15 = *(void *)(v23 - 8);
  int64_t v2 = *(void *)(v15 + 64);
  id v3 = alloca(v2);
  char v4 = alloca(v2);
  uint64_t v5 = a1[3];
  uint64_t v20 = a1[4];
  __swift_project_boxed_opaque_existential_0Tm(a1, v5);
  uint64_t v6 = lazy protocol witness table accessor for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys();
  uint64_t v19 = &v15;
  dispatch thunk of Decoder.container<A>(keyedBy:)(&unk_39D248, &unk_39D248, v6, v5, v20);
  if (v1) {
    return __swift_destroy_boxed_opaque_existential_1Tm(a1);
  }
  uint64_t v7 = v15;
  uint64_t v21 = a1;
  char v22 = 0;
  uint64_t v16 = KeyedDecodingContainer.decode(_:forKey:)(&v22, v23);
  v24[0] = 1;
  uint64_t v9 = v8;
  uint64_t v10 = lazy protocol witness table accessor for type ColumnDescriptor.ColumnTypeDescriptor and conformance ColumnDescriptor.ColumnTypeDescriptor();
  uint64_t v20 = v9;
  char v11 = v9;
  uint64_t v12 = v19;
  swift_bridgeObjectRetain(v11);
  KeyedDecodingContainer.decode<A>(_:forKey:)(&type metadata for ColumnDescriptor.ColumnTypeDescriptor, v24, v23, &type metadata for ColumnDescriptor.ColumnTypeDescriptor, v10);
  (*(void (**)(uint64_t *, uint64_t))(v7 + 8))(v12, v23);
  uint64_t v13 = v17;
  LODWORD(v23) = v18;
  outlined copy of ColumnDescriptor.ColumnTypeDescriptor(v17, v18);
  __swift_destroy_boxed_opaque_existential_1Tm(v21);
  swift_bridgeObjectRelease(v20);
  outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v13, v23);
  return v16;
}

char static ColumnDescriptor.ColumnTypeDescriptor.== infix(_:_:)(void *a1, char a2, void *a3, char a4)
{
  switch(a2)
  {
    case 0:
      if (!a4) {
        goto LABEL_9;
      }
      goto LABEL_23;
    case 1:
      if (a4 != 1) {
        goto LABEL_23;
      }
      goto LABEL_9;
    case 2:
      if (a4 != 2) {
        goto LABEL_23;
      }
      goto LABEL_9;
    case 3:
      if (a4 != 3) {
        goto LABEL_23;
      }
LABEL_9:
      char result = a1 == a3;
      break;
    case 4:
      if (a4 != 4) {
        goto LABEL_23;
      }
      char result = specialized static Array<A>.== infix(_:_:)(a1, a3);
      break;
    case 5:
      if (a4 == 5) {
        char result = specialized static Array<A>.== infix(_:_:)((uint64_t)a1, (uint64_t)a3);
      }
      else {
LABEL_23:
      }
        char result = 0;
      break;
    case 6:
      switch((unint64_t)a1)
      {
        case 0uLL:
          JUMPOUT(0x2A8A81);
        case 1uLL:
          if (a4 != 6) {
            goto LABEL_23;
          }
          char result = 1;
          if (a3 != (void *)((char *)&dword_0 + 1)) {
            goto LABEL_23;
          }
          return result;
        case 2uLL:
          if (a4 != 6) {
            goto LABEL_23;
          }
          char result = 1;
          if (a3 != (void *)((char *)&dword_0 + 2)) {
            goto LABEL_23;
          }
          return result;
        case 3uLL:
          if (a4 != 6) {
            goto LABEL_23;
          }
          char result = 1;
          if (a3 != (void *)((char *)&dword_0 + 3)) {
            goto LABEL_23;
          }
          return result;
      }
  }
  return result;
}

uint64_t protocol witness for CodingKey.stringValue.getter in conformance ColumnDescriptor.CodingKeys()
{
  return ColumnDescriptor.CodingKeys.stringValue.getter(*v0);
}

char protocol witness for CodingKey.init(stringValue:) in conformance ColumnDescriptor.CodingKeys(uint64_t a1, unint64_t a2)
{
  id v3 = v2;
  char result = ColumnDescriptor.CodingKeys.init(stringValue:)(a1, a2);
  char *v3 = result;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance ColumnDescriptor.CodingKeys(uint64_t a1)
{
  uint64_t v1 = lazy protocol witness table accessor for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys();
  return CodingKey.description.getter(a1, v1);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance ColumnDescriptor.CodingKeys(uint64_t a1)
{
  uint64_t v1 = lazy protocol witness table accessor for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys();
  return CodingKey.debugDescription.getter(a1, v1);
}

uint64_t protocol witness for Decodable.init(from:) in conformance ColumnDescriptor(void *a1)
{
  uint64_t v3 = v1;
  uint64_t result = ColumnDescriptor.init(from:)(a1);
  if (!v2)
  {
    *(void *)uint64_t v3 = result;
    *(void *)(v3 + 8) = v5;
    *(void *)(v3 + 16) = v6;
    *(unsigned char *)(v3 + 24) = v7;
  }
  return result;
}

uint64_t protocol witness for Encodable.encode(to:) in conformance ColumnDescriptor(void *a1)
{
  return ColumnDescriptor.encode(to:)(a1, *(void *)v1, *(void *)(v1 + 8), *(void *)(v1 + 16), *(_DWORD *)(v1 + 24));
}

char protocol witness for static Equatable.== infix(_:_:) in conformance ColumnDescriptor(uint64_t a1, uint64_t a2)
{
  return static ColumnDescriptor.== infix(_:_:)(*(void *)a1, *(void *)(a1 + 8), *(void **)(a1 + 16), *(_DWORD *)(a1 + 24), *(void *)a2, *(void *)(a2 + 8), *(void **)(a2 + 16), *(_DWORD *)(a2 + 24));
}

char protocol witness for static Equatable.== infix(_:_:) in conformance ColumnDescriptor.ColumnTypeDescriptor(uint64_t a1, uint64_t a2)
{
  return static ColumnDescriptor.ColumnTypeDescriptor.== infix(_:_:)(*(void **)a1, *(_DWORD *)(a1 + 8), *(void **)a2, *(_DWORD *)(a2 + 8));
}

uint64_t specialized ColumnDescriptor.ColumnTypeDescriptor.init<A>(_:)(uint64_t a1)
{
  uint64_t v1 = a1;
  uint64_t v2 = *(void *)(a1 + 16);
  uint64_t v41 = a1;
  if (v2)
  {
    uint64_t v3 = a1 + 32;
    swift_bridgeObjectRetain(a1);
    char v4 = _swiftEmptyArrayStorage;
    uint64_t v42 = v2;
    do
    {
      outlined init with copy of Any?(v3, (uint64_t)&v35);
      outlined init with take of DataFrame?((uint64_t)&v35, (uint64_t)&v29, &demangling cache variable for type metadata for Any?);
      if (v30)
      {
        outlined init with take of Any(&v29, &v37);
        outlined init with take of Any(&v37, &v29);
        if (!swift_isUniquelyReferenced_nonNull_native(v4)) {
          char v4 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v4[2] + 1, 1, (uint64_t)v4);
        }
        unint64_t v5 = v4[2];
        if (v4[3] >> 1 <= v5) {
          char v4 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v4[3] >= 2uLL, v5 + 1, 1, (uint64_t)v4);
        }
        v4[2] = v5 + 1;
        outlined init with take of Any(&v29, &v4[4 * v5 + 4]);
      }
      else
      {
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v29, &demangling cache variable for type metadata for Any?);
      }
      v3 += 32;
      --v2;
    }
    while (v2);
    uint64_t v1 = v41;
    swift_bridgeObjectRelease(v41);
    uint64_t v2 = v42;
  }
  else
  {
    char v4 = _swiftEmptyArrayStorage;
  }
  specialized Collection.first.getter((uint64_t)v4);
  swift_bridgeObjectRelease((_BYTE)v4);
  if (!v38)
  {
    swift_bridgeObjectRelease(v1);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v37, &demangling cache variable for type metadata for Any?);
    return 0;
  }
  outlined init with take of Any(&v37, &v35);
  uint64_t v6 = v36;
  char v7 = __swift_project_boxed_opaque_existential_0Tm(&v35, v36);
  uint64_t DynamicType = swift_getDynamicType(v7, v6, 1);
  uint64_t v9 = DynamicType;
  if (v2)
  {
    uint64_t v43 = DynamicType;
    uint64_t v10 = v1 + 32;
    swift_bridgeObjectRetain(v1);
    do
    {
      outlined init with copy of Any?(v10, (uint64_t)&v37);
      uint64_t v11 = v38;
      outlined init with copy of Any?((uint64_t)&v37, (uint64_t)&v29);
      if (v11)
      {
        outlined init with copy of Any?((uint64_t)&v29, (uint64_t)&v31);
        uint64_t v12 = v32;
        if (!v32) {
          BUG();
        }
        uint64_t v13 = __swift_project_boxed_opaque_existential_0Tm(&v31, v32);
        uint64_t v42 = swift_getDynamicType(v13, v12, 1);
        __swift_destroy_boxed_opaque_existential_1Tm(&v31);
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v29, &demangling cache variable for type metadata for Any?);
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v37, &demangling cache variable for type metadata for Any?);
        if (v42 != v43)
        {
          swift_bridgeObjectRelease_n(v41, 2, v14, v15, v16);
          goto LABEL_28;
        }
      }
      else
      {
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v29, &demangling cache variable for type metadata for Any?);
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v37, &demangling cache variable for type metadata for Any?);
      }
      v10 += 32;
      --v2;
    }
    while (v2);
    uint64_t v1 = v41;
    swift_bridgeObjectRelease(v41);
    uint64_t v9 = v43;
  }
  if (swift_dynamicCastMetatype(v9, &type metadata for Int))
  {
    swift_bridgeObjectRelease(v1);
    __swift_destroy_boxed_opaque_existential_1Tm(&v35);
    return 0;
  }
  if (swift_dynamicCastMetatype(v9, &type metadata for Float))
  {
    swift_bridgeObjectRelease(v1);
    __swift_destroy_boxed_opaque_existential_1Tm(&v35);
    return 2;
  }
  if (swift_dynamicCastMetatype(v9, &type metadata for Double)
    || (uint64_t v19 = type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for NSNumber, NSNumber_ptr), swift_dynamicCastMetatype(v9, v19)))
  {
    swift_bridgeObjectRelease(v1);
    __swift_destroy_boxed_opaque_existential_1Tm(&v35);
    return 3;
  }
  if (!swift_dynamicCastMetatype(v9, &type metadata for String))
  {
    swift_bridgeObjectRelease(v1);
LABEL_28:
    __swift_destroy_boxed_opaque_existential_1Tm(&v35);
    return 0;
  }
  int64_t v20 = *(void *)(v1 + 16);
  if (v20)
  {
    uint64_t v40 = _swiftEmptyArrayStorage;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v20, 0);
    uint64_t v21 = v1 + 32;
    uint64_t v34 = (char *)&type metadata for Any + 8;
    do
    {
      outlined init with copy of Any?(v21, (uint64_t)&v37);
      outlined init with copy of Any?((uint64_t)&v37, (uint64_t)&v31);
      if (v32)
      {
        outlined init with take of Any(&v31, &v29);
        swift_dynamicCast(v33, &v29, v34, &type metadata for String, 7);
        uint64_t v43 = v33[0];
        unint64_t v39 = v33[1];
      }
      else
      {
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v31, &demangling cache variable for type metadata for Any?);
        uint64_t v43 = 0;
        unint64_t v39 = 0xE000000000000000;
      }
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v37, &demangling cache variable for type metadata for Any?);
      char v22 = v40;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v40);
      uint64_t v42 = v20;
      if (!isUniquelyReferenced_nonNull_native)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v22[2] + 1, 1);
        char v22 = v40;
      }
      unint64_t v24 = v22[2];
      if (v22[3] >> 1 <= v24)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v22[3] >= 2uLL, v24 + 1, 1);
        char v22 = v40;
      }
      v22[2] = v24 + 1;
      uint64_t v25 = 2 * v24;
      v22[v25 + 4] = v43;
      v22[v25 + 5] = v39;
      v21 += 32;
      int64_t v20 = v42 - 1;
    }
    while (v42 != 1);
    LOBYTE(v1) = v41;
  }
  else
  {
    char v22 = _swiftEmptyArrayStorage;
  }
  uint64_t v26 = specialized Set.init<A>(_:)((uint64_t)v22);
  swift_bridgeObjectRetain(v26);
  int64_t v27 = specialized _copyCollectionToContiguousArray<A>(_:)(v26);
  swift_bridgeObjectRelease(v26);
  *(void *)&long long v37 = v27;
  specialized MutableCollection<>.sort(by:)(&v37);
  swift_bridgeObjectRelease(v1);
  uint64_t v17 = v37;
  __swift_destroy_boxed_opaque_existential_1Tm(&v35);
  swift_bridgeObjectRelease(v26);
  return v17;
}

CreateML::ColumnDescriptor::FeatureType_optional __swiftcall ColumnDescriptor.FeatureType.init(rawValue:)(Swift::String rawValue)
{
  unint64_t v1 = _findStringSwitchCase(cases:string:)((Swift::OpaquePointer)&outlined read-only object #0 of ColumnDescriptor.FeatureType.init(rawValue:), rawValue);
  swift_bridgeObjectRelease(rawValue._object);
  result.Swift::Int value = CreateML_ColumnDescriptor_FeatureType_unknownDefault;
  if (v1 < 0xA) {
    return (CreateML::ColumnDescriptor::FeatureType_optional)v1;
  }
  return result;
}

unint64_t ColumnDescriptor.FeatureType.rawValue.getter(char a1)
{
  switch(a1)
  {
    case 0:
      unint64_t result = 7630441;
      break;
    case 1:
      unint64_t result = 0x363174616F6C66;
      break;
    case 2:
      unint64_t result = 0x74616F6C66;
      break;
    case 3:
      unint64_t result = 0x656C62756F64;
      break;
    case 4:
      unint64_t result = 0x6570616853746E69;
      break;
    case 5:
    case 6:
      unint64_t result = 0xD000000000000012;
      break;
    case 7:
      unint64_t result = 0xD000000000000011;
      break;
    case 8:
      unint64_t result = 0x69726F6765746163;
      break;
    case 9:
      unint64_t result = 0x616E6F6974636964;
      break;
  }
  return result;
}

CreateML::ColumnDescriptor::ColumnTypeDescriptor::CodingKeys_optional __swiftcall ColumnDescriptor.ColumnTypeDescriptor.CodingKeys.init(rawValue:)(Swift::String rawValue)
{
  unint64_t v1 = _findStringSwitchCase(cases:string:)((Swift::OpaquePointer)&outlined read-only object #0 of ColumnDescriptor.ColumnTypeDescriptor.CodingKeys.init(rawValue:), rawValue);
  swift_bridgeObjectRelease(rawValue._object);
  result.Swift::Int value = CreateML_ColumnDescriptor_ColumnTypeDescriptor_CodingKeys_unknownDefault;
  if (v1 < 4) {
    return (CreateML::ColumnDescriptor::ColumnTypeDescriptor::CodingKeys_optional)v1;
  }
  return result;
}

CreateML::ColumnDescriptor::ColumnTypeDescriptor::CodingKeys_optional __swiftcall ColumnDescriptor.ColumnTypeDescriptor.CodingKeys.init(stringValue:)(Swift::String stringValue)
{
  return ColumnDescriptor.ColumnTypeDescriptor.CodingKeys.init(rawValue:)(stringValue);
}

uint64_t ColumnDescriptor.ColumnTypeDescriptor.CodingKeys.rawValue.getter(char a1)
{
  switch(a1)
  {
    case 0:
      uint64_t result = 0x54746E656D656C65;
      break;
    case 1:
      uint64_t result = 1702521203;
      break;
    case 2:
      uint64_t result = 0x69726F6765746163;
      break;
    case 3:
      uint64_t result = 0x7470697263736564;
      break;
  }
  return result;
}

uint64_t ColumnDescriptor.ColumnTypeDescriptor.CodingKeys.stringValue.getter(char a1)
{
  switch(a1)
  {
    case 0:
      uint64_t result = 0x54746E656D656C65;
      break;
    case 1:
      uint64_t result = 1702521203;
      break;
    case 2:
      uint64_t result = 0x69726F6765746163;
      break;
    case 3:
      uint64_t result = 0x7470697263736564;
      break;
  }
  return result;
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance ColumnDescriptor.FeatureType(char *a1, char *a2)
{
  return specialized == infix<A>(_:_:)(*a1, *a2);
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance ColumnDescriptor.FeatureType()
{
  return specialized RawRepresentable<>.hashValue.getter(*v0);
}

uint64_t protocol witness for Hashable.hash(into:) in conformance ColumnDescriptor.FeatureType(uint64_t a1)
{
  return specialized RawRepresentable<>.hash(into:)(a1, *v1);
}

Swift::Int protocol witness for Hashable._rawHashValue(seed:) in conformance ColumnDescriptor.FeatureType(uint64_t a1)
{
  return specialized RawRepresentable<>._rawHashValue(seed:)(a1, *v1);
}

CreateML::ColumnDescriptor::FeatureType_optional protocol witness for RawRepresentable.init(rawValue:) in conformance ColumnDescriptor.FeatureType(Swift::String *a1)
{
  uint64_t v2 = v1;
  result.Swift::Int value = ColumnDescriptor.FeatureType.init(rawValue:)(*a1).value;
  v2->Swift::Int value = result.value;
  return result;
}

unint64_t protocol witness for RawRepresentable.rawValue.getter in conformance ColumnDescriptor.FeatureType()
{
  uint64_t v2 = v0;
  unint64_t result = ColumnDescriptor.FeatureType.rawValue.getter(*v1);
  unint64_t *v2 = result;
  v2[1] = v4;
  return result;
}

uint64_t protocol witness for Decodable.init(from:) in conformance ColumnDescriptor.FeatureType(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = lazy protocol witness table accessor for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType();
  return RawRepresentable<>.init(from:)(a1, a2, a3, v3);
}

uint64_t protocol witness for Encodable.encode(to:) in conformance ColumnDescriptor.FeatureType(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = lazy protocol witness table accessor for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType();
  return RawRepresentable<>.encode(to:)(a1, a2, a3, v4);
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys(unsigned __int8 *a1, char *a2)
{
  return specialized == infix<A>(_:_:)(*a1, *a2);
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys()
{
  return specialized RawRepresentable<>.hashValue.getter(*v0);
}

uint64_t protocol witness for Hashable.hash(into:) in conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys(uint64_t a1)
{
  return specialized RawRepresentable<>.hash(into:)(a1, *v1);
}

Swift::Int protocol witness for Hashable._rawHashValue(seed:) in conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys(uint64_t a1)
{
  return specialized RawRepresentable<>._rawHashValue(seed:)(a1, *v1);
}

CreateML::ColumnDescriptor::ColumnTypeDescriptor::CodingKeys_optional protocol witness for RawRepresentable.init(rawValue:) in conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys(Swift::String *a1)
{
  uint64_t v2 = v1;
  result.Swift::Int value = ColumnDescriptor.ColumnTypeDescriptor.CodingKeys.init(rawValue:)(*a1).value;
  v2->Swift::Int value = result.value;
  return result;
}

uint64_t protocol witness for RawRepresentable.rawValue.getter in conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys()
{
  uint64_t v2 = v0;
  uint64_t result = ColumnDescriptor.ColumnTypeDescriptor.CodingKeys.rawValue.getter(*v1);
  uint64_t *v2 = result;
  v2[1] = v4;
  return result;
}

uint64_t protocol witness for CodingKey.stringValue.getter in conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys()
{
  return ColumnDescriptor.ColumnTypeDescriptor.CodingKeys.stringValue.getter(*v0);
}

CreateML::ColumnDescriptor::ColumnTypeDescriptor::CodingKeys_optional protocol witness for CodingKey.init(stringValue:) in conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys(Swift::String a1)
{
  uint64_t v2 = v1;
  result.Swift::Int value = ColumnDescriptor.ColumnTypeDescriptor.CodingKeys.init(stringValue:)(a1).value;
  v2->Swift::Int value = result.value;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys(uint64_t a1)
{
  uint64_t v1 = lazy protocol witness table accessor for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys();
  return CodingKey.description.getter(a1, v1);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys(uint64_t a1)
{
  uint64_t v1 = lazy protocol witness table accessor for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys();
  return CodingKey.debugDescription.getter(a1, v1);
}

void *ColumnDescriptor.ColumnTypeDescriptor.init(from:)(void *a1)
{
  uint64_t v24 = v1;
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedDecodingContainer<ColumnDescriptor.ColumnTypeDescriptor.CodingKeys>);
  uint64_t v26 = *(void *)(v25 - 8);
  int64_t v2 = *(void *)(v26 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v5 = a1[3];
  uint64_t v6 = a1[4];
  uint64_t v28 = a1;
  char v7 = __swift_project_boxed_opaque_existential_0Tm(a1, v5);
  uint64_t v8 = lazy protocol witness table accessor for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys();
  uint64_t v23 = &v22;
  uint64_t v9 = v24;
  dispatch thunk of Decoder.container<A>(keyedBy:)(&type metadata for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys, &type metadata for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys, v8, v5, v6);
  if (v9)
  {
    uint64_t v15 = v28;
  }
  else
  {
    uint64_t v10 = v26;
    v29[0] = 0;
    uint64_t v11 = lazy protocol witness table accessor for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType();
    uint64_t v12 = v25;
    uint64_t v13 = v23;
    KeyedDecodingContainer.decode<A>(_:forKey:)(&type metadata for ColumnDescriptor.FeatureType, v29, v25, &type metadata for ColumnDescriptor.FeatureType, v11);
    uint64_t v14 = v12;
    uint64_t v17 = v13;
    switch((char)v27)
    {
      case 0:
        (*(void (**)(uint64_t *, uint64_t))(v10 + 8))(v13, v14);
        char v7 = 0;
        goto LABEL_11;
      case 1:
        (*(void (**)(uint64_t *, uint64_t))(v10 + 8))(v13, v14);
        uint64_t v21 = 1;
        goto LABEL_10;
      case 2:
        (*(void (**)(uint64_t *, uint64_t))(v10 + 8))(v13, v14);
        uint64_t v21 = 2;
        goto LABEL_10;
      case 3:
        (*(void (**)(uint64_t *, uint64_t))(v10 + 8))(v13, v14);
        uint64_t v21 = 3;
LABEL_10:
        char v7 = (void *)v21;
        goto LABEL_11;
      case 4:
      case 5:
      case 6:
      case 7:
        LOBYTE(v27) = 1;
        char v7 = (void *)KeyedDecodingContainer.decode(_:forKey:)(&v27, v14);
        (*(void (**)(uint64_t *, uint64_t))(v26 + 8))(v17, v14);
        uint64_t v15 = v28;
        break;
      case 8:
        uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
        v29[0] = 2;
        uint64_t v19 = lazy protocol witness table accessor for type [String] and conformance <A> [A](&lazy protocol witness table cache variable for type [String] and conformance <A> [A], (uint64_t)&protocol witness table for String, (uint64_t)&protocol conformance descriptor for <A> [A]);
        KeyedDecodingContainer.decode<A>(_:forKey:)(v18, v29, v14, v18, v19);
        (*(void (**)(uint64_t *, uint64_t))(v26 + 8))(v13, v14);
        char v7 = v27;
        goto LABEL_11;
      case 9:
        uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [ColumnDescriptor]);
        v29[0] = 3;
        uint64_t v20 = lazy protocol witness table accessor for type [ColumnDescriptor] and conformance <A> [A](&lazy protocol witness table cache variable for type [ColumnDescriptor] and conformance <A> [A], (void (*)(void))lazy protocol witness table accessor for type ColumnDescriptor and conformance ColumnDescriptor, (uint64_t)&protocol conformance descriptor for <A> [A]);
        KeyedDecodingContainer.decode<A>(_:forKey:)(v24, v29, v14, v24, v20);
        (*(void (**)(uint64_t *, uint64_t))(v10 + 8))(v13, v25);
        char v7 = v27;
LABEL_11:
        uint64_t v15 = v28;
        break;
    }
  }
  __swift_destroy_boxed_opaque_existential_1Tm(v15);
  return v7;
}

uint64_t ColumnDescriptor.ColumnTypeDescriptor.encode(to:)(void *a1, uint64_t a2, int a3)
{
  v14[1] = v3;
  LODWORD(v19) = a3;
  uint64_t v16 = a2;
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedEncodingContainer<ColumnDescriptor.ColumnTypeDescriptor.CodingKeys>);
  uint64_t v18 = *(void *)(v15 - 8);
  int64_t v4 = *(void *)(v18 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v7 = a1[3];
  uint64_t v8 = a1[4];
  __swift_project_boxed_opaque_existential_0Tm(a1, v7);
  uint64_t v9 = lazy protocol witness table accessor for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys();
  dispatch thunk of Encoder.container<A>(keyedBy:)(&type metadata for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys, &type metadata for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys, v9, v7, v8);
  LOBYTE(v17) = ColumnDescriptor.ColumnTypeDescriptor.featureType.getter(a2, v19);
  v20[0] = 0;
  uint64_t v10 = lazy protocol witness table accessor for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType();
  KeyedEncodingContainer.encode<A>(_:forKey:)(&v17, v20, v15, &type metadata for ColumnDescriptor.FeatureType, v10);
  if (v3)
  {
    uint64_t v11 = v15;
    return (*(uint64_t (**)(void *, uint64_t))(v18 + 8))(v14, v11);
  }
  else
  {
    switch((char)v19)
    {
      case 0:
      case 1:
      case 2:
      case 3:
        LOBYTE(v17) = 1;
        KeyedEncodingContainer.encode(_:forKey:)(v16, &v17, v15);
        goto LABEL_9;
      case 4:
        uint64_t v17 = v16;
        v20[0] = 2;
        uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
        uint64_t v13 = lazy protocol witness table accessor for type [String] and conformance <A> [A](&lazy protocol witness table cache variable for type [String] and conformance <A> [A], (uint64_t)&protocol witness table for String, (uint64_t)&protocol conformance descriptor for <A> [A]);
        goto LABEL_8;
      case 5:
        uint64_t v17 = v16;
        v20[0] = 3;
        uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [ColumnDescriptor]);
        uint64_t v13 = lazy protocol witness table accessor for type [ColumnDescriptor] and conformance <A> [A](&lazy protocol witness table cache variable for type [ColumnDescriptor] and conformance <A> [A], (void (*)(void))lazy protocol witness table accessor for type ColumnDescriptor and conformance ColumnDescriptor, (uint64_t)&protocol conformance descriptor for <A> [A]);
LABEL_8:
        KeyedEncodingContainer.encode<A>(_:forKey:)(&v17, v20, v15, v19, v13);
LABEL_9:
        uint64_t result = (*(uint64_t (**)(void *, uint64_t))(v18 + 8))(v14, v15);
        break;
      case 6:
        uint64_t v11 = v15;
        return (*(uint64_t (**)(void *, uint64_t))(v18 + 8))(v14, v11);
    }
  }
  return result;
}

void *protocol witness for Decodable.init(from:) in conformance ColumnDescriptor.ColumnTypeDescriptor(void *a1)
{
  uint64_t v3 = v1;
  uint64_t result = ColumnDescriptor.ColumnTypeDescriptor.init(from:)(a1);
  if (!v2)
  {
    *(void *)uint64_t v3 = result;
    *(unsigned char *)(v3 + 8) = v5;
  }
  return result;
}

uint64_t protocol witness for Encodable.encode(to:) in conformance ColumnDescriptor.ColumnTypeDescriptor(void *a1)
{
  return ColumnDescriptor.ColumnTypeDescriptor.encode(to:)(a1, *(void *)v1, *(_DWORD *)(v1 + 8));
}

void outlined consume of MLMultiArray??(char *a1)
{
  if (a1 != (unsigned char *)&dword_0 + 2) {
}
  }

void *specialized _ContiguousArrayBuffer._consumeAndCreateNew()(uint64_t a1)
{
  return specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

char *specialized _ContiguousArrayBuffer._consumeAndCreateNew()(uint64_t a1)
{
  return specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1, (void (*)(char *, uint64_t, char *))specialized UnsafeMutablePointer.moveInitialize(from:count:));
}

{
  return specialized _ContiguousArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1, (void (*)(char *, uint64_t, char *))specialized UnsafeMutablePointer.moveInitialize(from:count:));
}

uint64_t sub_2A9DC2()
{
  return swift_deallocObject(v0, 32, 7);
}

uint64_t sub_2A9DEB()
{
  return swift_deallocObject(v0, 32, 7);
}

uint64_t sub_2A9E0C()
{
  return swift_deallocObject(v0, 32, 7);
}

uint64_t sub_2A9E31()
{
  return swift_deallocObject(v0, 32, 7);
}

uint64_t sub_2A9E5E()
{
  return swift_deallocObject(v0, 32, 7);
}

uint64_t sub_2A9E8C()
{
  return swift_deallocObject(v0, 32, 7);
}

uint64_t lazy protocol witness table accessor for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys()
{
  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys, &type metadata for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys);
    lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys, &type metadata for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys);
    lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys, &type metadata for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys);
    lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys, &type metadata for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys);
    lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType()
{
  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.FeatureType, &type metadata for ColumnDescriptor.FeatureType);
    lazy protocol witness table cache variable for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.FeatureType, &type metadata for ColumnDescriptor.FeatureType);
    lazy protocol witness table cache variable for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.FeatureType, &type metadata for ColumnDescriptor.FeatureType);
    lazy protocol witness table cache variable for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.FeatureType, &type metadata for ColumnDescriptor.FeatureType);
    lazy protocol witness table cache variable for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type [String] and conformance <A> [A](uint64_t *a1, uint64_t a2, uint64_t a3)
{
  uint64_t result = *a1;
  if (!*a1)
  {
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [String]);
    uint64_t result = swift_getWitnessTable(a3, v5);
    *a1 = result;
  }
  return result;
}

unsigned char *__swift_memcpy1_1(unsigned char *a1, unsigned char *a2)
{
  uint64_t result = a1;
  *a1 = *a2;
  return result;
}

uint64_t getEnumTagSinglePayload for ColumnDescriptor.FeatureType(unsigned __int8 *a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 < 0xF7) {
      goto LABEL_13;
    }
    unsigned int v2 = a2 + 9;
    int v3 = 1;
    if (v2 >= 0xFF00) {
      int v3 = 2 * (v2 >= 0xFFFF00) + 2;
    }
    if (v3 == 4) {
      int v4 = *(_DWORD *)(a1 + 1);
    }
    else {
      int v4 = v3 == 2 ? *(unsigned __int16 *)(a1 + 1) : a1[1];
    }
    if (v4)
    {
      int v5 = *a1 + (v4 << 8) - 10;
    }
    else
    {
LABEL_13:
      unsigned int v6 = *a1;
      int v7 = v6 - 10;
      BOOL v8 = v6 < 0xA;
      int v5 = -1;
      if (!v8) {
        int v5 = v7;
      }
    }
  }
  else
  {
    int v5 = -1;
  }
  return (v5 + 1);
}

uint64_t storeEnumTagSinglePayload for ColumnDescriptor.FeatureType(unsigned char *a1, unsigned int a2, unsigned int a3)
{
  LODWORD(result) = 0;
  if (a3 >= 0xF7)
  {
    unsigned int v4 = a3 + 9;
    LODWORD(result) = 1;
    if (v4 >= 0xFF00) {
      LODWORD(result) = 2 * (v4 >= 0xFFFF00) + 2;
    }
  }
  if (a2 > 0xF6)
  {
    unsigned int v5 = a2 - 247;
    int v6 = (v5 >> 8) + 1;
    *a1 = v5;
    uint64_t result = result;
    switch((int)result)
    {
      case 0:
        return result;
      case 1:
        a1[1] = v6;
        break;
      case 2:
        *(_WORD *)(a1 + 1) = v6;
        break;
      case 3:
LABEL_16:
        BUG();
      case 4:
        *(_DWORD *)(a1 + 1) = v6;
        break;
    }
  }
  else
  {
    uint64_t result = result;
    switch((int)result)
    {
      case 0:
        goto LABEL_11;
      case 1:
        a1[1] = 0;
        goto LABEL_11;
      case 2:
        *(_WORD *)(a1 + 1) = 0;
        goto LABEL_11;
      case 3:
        goto LABEL_16;
      case 4:
        *(_DWORD *)(a1 + 1) = 0;
LABEL_11:
        if (a2) {
          *a1 = a2 + 9;
        }
        break;
      case 5:
        JUMPOUT(0x2AA0C8);
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for ColumnDescriptor.FeatureType()
{
  return &type metadata for ColumnDescriptor.FeatureType;
}

ValueMetadata *type metadata accessor for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys()
{
  return &type metadata for ColumnDescriptor.ColumnTypeDescriptor.CodingKeys;
}

uint64_t initializeBufferWithCopyOfBuffer for ColumnDescriptor.ColumnTypeDescriptor(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)a2;
  int v3 = *(_DWORD *)(a2 + 8);
  outlined copy of ColumnDescriptor.ColumnTypeDescriptor(*(void *)a2, v3);
  *(void *)a1 = v2;
  *(unsigned char *)(a1 + 8) = v3;
  return a1;
}

uint64_t destroy for ColumnDescriptor.ColumnTypeDescriptor(uint64_t a1)
{
  return outlined consume of ColumnDescriptor.ColumnTypeDescriptor(*(void *)a1, *(_DWORD *)(a1 + 8));
}

uint64_t assignWithCopy for ColumnDescriptor.ColumnTypeDescriptor(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(void *)a2;
  int v4 = *(_DWORD *)(a2 + 8);
  outlined copy of ColumnDescriptor.ColumnTypeDescriptor(*(void *)a2, v4);
  uint64_t v5 = *(void *)a1;
  *(void *)a1 = v3;
  int v6 = *(_DWORD *)(a1 + 8);
  *(unsigned char *)(a1 + 8) = v4;
  outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v5, v6);
  return a1;
}

uint64_t __swift_memcpy9_8(uint64_t a1, uint64_t a2)
{
  uint64_t result = a1;
  *(unsigned char *)(a1 + 8) = *(unsigned char *)(a2 + 8);
  *(void *)a1 = *(void *)a2;
  return result;
}

uint64_t assignWithTake for ColumnDescriptor.ColumnTypeDescriptor(uint64_t a1, uint64_t a2)
{
  char v3 = *(unsigned char *)(a2 + 8);
  uint64_t v4 = *(void *)a1;
  *(void *)a1 = *(void *)a2;
  int v5 = *(_DWORD *)(a1 + 8);
  *(unsigned char *)(a1 + 8) = v3;
  outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v4, v5);
  return a1;
}

uint64_t getEnumTagSinglePayload for ColumnDescriptor.ColumnTypeDescriptor(uint64_t a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 >= 0xFA && *(unsigned char *)(a1 + 9))
    {
      int v2 = *(_DWORD *)a1 + 249;
    }
    else
    {
      int v2 = -1;
      if (*(unsigned __int8 *)(a1 + 8) >= 7u) {
        int v2 = *(unsigned __int8 *)(a1 + 8) ^ 0xFF;
      }
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for ColumnDescriptor.ColumnTypeDescriptor(uint64_t a1, unsigned int a2, unsigned int a3)
{
  if (a2 > 0xF9)
  {
    *(void *)a1 = a2 - 250;
    *(unsigned char *)(a1 + 8) = 0;
    if (a3 >= 0xFA) {
      *(unsigned char *)(a1 + 9) = 1;
    }
  }
  else
  {
    if (a3 >= 0xFA) {
      *(unsigned char *)(a1 + 9) = 0;
    }
    if (a2) {
      *(unsigned char *)(a1 + 8) = -(char)a2;
    }
  }
}

uint64_t getEnumTag for ColumnDescriptor.ColumnTypeDescriptor(uint64_t a1)
{
  uint64_t result = (*(_DWORD *)a1 + 6);
  if (*(unsigned __int8 *)(a1 + 8) < 6u) {
    return *(unsigned __int8 *)(a1 + 8);
  }
  return result;
}

void destructiveInjectEnumTag for ColumnDescriptor.ColumnTypeDescriptor(uint64_t a1, unsigned int a2)
{
  if (a2 >= 6)
  {
    *(void *)a1 = a2 - 6;
    LOBYTE(a2) = 6;
  }
  *(unsigned char *)(a1 + 8) = a2;
}

ValueMetadata *type metadata accessor for ColumnDescriptor.ColumnTypeDescriptor()
{
  return &type metadata for ColumnDescriptor.ColumnTypeDescriptor;
}

uint64_t destroy for ColumnDescriptor(uint64_t a1)
{
  return outlined consume of ColumnDescriptor.ColumnTypeDescriptor(*(void *)(a1 + 16), *(_DWORD *)(a1 + 24));
}

uint64_t initializeWithCopy for ColumnDescriptor(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v3 = *(void *)(a2 + 8);
  *(void *)(a1 + 8) = v3;
  uint64_t v4 = *(void *)(a2 + 16);
  int v5 = *(_DWORD *)(a2 + 24);
  swift_bridgeObjectRetain(v3);
  outlined copy of ColumnDescriptor.ColumnTypeDescriptor(v4, v5);
  *(void *)(a1 + 16) = v4;
  *(unsigned char *)(a1 + 24) = v5;
  return a1;
}

uint64_t assignWithCopy for ColumnDescriptor(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v3 = *(void *)(a2 + 8);
  uint64_t v4 = *(void *)(a1 + 8);
  *(void *)(a1 + 8) = v3;
  swift_bridgeObjectRetain(v3);
  swift_bridgeObjectRelease(v4);
  uint64_t v5 = *(void *)(a2 + 16);
  int v6 = *(_DWORD *)(a2 + 24);
  outlined copy of ColumnDescriptor.ColumnTypeDescriptor(v5, v6);
  uint64_t v7 = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = v5;
  int v8 = *(_DWORD *)(a1 + 24);
  *(unsigned char *)(a1 + 24) = v6;
  outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v7, v8);
  return a1;
}

_OWORD *__swift_memcpy25_8(_OWORD *a1, long long *a2)
{
  uint64_t result = a1;
  long long v3 = *a2;
  *(_OWORD *)((char *)a1 + 9) = *(long long *)((char *)a2 + 9);
  *a1 = v3;
  return result;
}

uint64_t assignWithTake for ColumnDescriptor(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v3 = *(void *)(a1 + 8);
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  swift_bridgeObjectRelease(v3);
  char v4 = *(unsigned char *)(a2 + 24);
  uint64_t v5 = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  int v6 = *(_DWORD *)(a1 + 24);
  *(unsigned char *)(a1 + 24) = v4;
  outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v5, v6);
  return a1;
}

uint64_t getEnumTagSinglePayload for ColumnDescriptor(uint64_t a1, int a2)
{
  if (a2)
  {
    if (a2 < 0 && *(unsigned char *)(a1 + 25)) {
      int v2 = *(_DWORD *)a1 + 0x7FFFFFFF;
    }
    else {
      int v2 = (*(void *)(a1 + 8) & 0xFFFFFFFF00000001) != 0 ? -1 : *(void *)(a1 + 8) >> 1;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for ColumnDescriptor(uint64_t a1, int a2, int a3)
{
  if (a2 < 0)
  {
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 + 0x80000000;
    *(unsigned char *)(a1 + 24) = 0;
    if (a3 < 0) {
      *(unsigned char *)(a1 + 25) = 1;
    }
  }
  else
  {
    if (a3 < 0) {
      *(unsigned char *)(a1 + 25) = 0;
    }
    if (a2) {
      *(void *)(a1 + 8) = 2 * (a2 - 1);
    }
  }
}

ValueMetadata *type metadata accessor for ColumnDescriptor()
{
  return &type metadata for ColumnDescriptor;
}

uint64_t base witness table accessor for Equatable in ColumnDescriptor.ColumnTypeDescriptor.CodingKeys()
{
  return lazy protocol witness table accessor for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys();
}

uint64_t base witness table accessor for Equatable in ColumnDescriptor.FeatureType()
{
  return lazy protocol witness table accessor for type ColumnDescriptor.FeatureType and conformance ColumnDescriptor.FeatureType();
}

uint64_t base witness table accessor for CustomDebugStringConvertible in ColumnDescriptor.ColumnTypeDescriptor.CodingKeys()
{
  return lazy protocol witness table accessor for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys();
}

uint64_t base witness table accessor for CustomStringConvertible in ColumnDescriptor.ColumnTypeDescriptor.CodingKeys()
{
  return lazy protocol witness table accessor for type ColumnDescriptor.ColumnTypeDescriptor.CodingKeys and conformance ColumnDescriptor.ColumnTypeDescriptor.CodingKeys();
}

uint64_t lazy protocol witness table accessor for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys()
{
  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.CodingKeys, &unk_39D248);
    lazy protocol witness table cache variable for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.CodingKeys, &unk_39D248);
    lazy protocol witness table cache variable for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.CodingKeys, &unk_39D248);
    lazy protocol witness table cache variable for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.CodingKeys, &unk_39D248);
    lazy protocol witness table cache variable for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type ColumnDescriptor.ColumnTypeDescriptor and conformance ColumnDescriptor.ColumnTypeDescriptor()
{
  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor and conformance ColumnDescriptor.ColumnTypeDescriptor;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor and conformance ColumnDescriptor.ColumnTypeDescriptor)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.ColumnTypeDescriptor, &type metadata for ColumnDescriptor.ColumnTypeDescriptor);
    lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor and conformance ColumnDescriptor.ColumnTypeDescriptor = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor and conformance ColumnDescriptor.ColumnTypeDescriptor;
  if (!lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor and conformance ColumnDescriptor.ColumnTypeDescriptor)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ColumnDescriptor.ColumnTypeDescriptor, &type metadata for ColumnDescriptor.ColumnTypeDescriptor);
    lazy protocol witness table cache variable for type ColumnDescriptor.ColumnTypeDescriptor and conformance ColumnDescriptor.ColumnTypeDescriptor = result;
  }
  return result;
}

void *type metadata accessor for ColumnDescriptor.CodingKeys()
{
  return &unk_39D248;
}

uint64_t base witness table accessor for Equatable in ColumnDescriptor.CodingKeys()
{
  return lazy protocol witness table accessor for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys();
}

uint64_t base witness table accessor for CustomDebugStringConvertible in ColumnDescriptor.CodingKeys()
{
  return lazy protocol witness table accessor for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys();
}

uint64_t base witness table accessor for CustomStringConvertible in ColumnDescriptor.CodingKeys()
{
  return lazy protocol witness table accessor for type ColumnDescriptor.CodingKeys and conformance ColumnDescriptor.CodingKeys();
}

uint64_t initializeWithCopy for ColumnDescriptor.ColumnTypeDescriptor(uint64_t a1, uint64_t a2)
{
  return initializeBufferWithCopyOfBuffer for ColumnDescriptor.ColumnTypeDescriptor(a1, a2);
}

uint64_t getEnumTag for ColumnDescriptor.FeatureType(unsigned __int8 *a1)
{
  return getEnumTag for Rectangle.CodingKeys(a1);
}

void MLSoundClassifier.Model.export(internalMetadata:)(void *a1, uint64_t a2)
{
  v26[1] = v2;
  uint64_t v28 = type metadata accessor for ModelKind(0);
  uint64_t v27 = *(void *)(v28 - 8);
  int64_t v4 = *(void *)(v27 + 64);
  uint64_t v5 = alloca(v4);
  int v6 = alloca(v4);
  long long v29 = v26;
  uint64_t v30 = type metadata accessor for Model(0);
  uint64_t v7 = *(void *)(v30 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v33 = v26;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v34 = a1;
  MLSoundClassifier.Model.createFeatureExtractorModel(internalMetadata:)(a1);
  if (!v3)
  {
    long long v31 = v26;
    uint64_t v32 = v7;
    uint64_t v13 = v34;
    MLSoundClassifier.Model.createClassifierModel(internalMetadata:)(v34);
    uint64_t v34 = 0;
    uint64_t v14 = Model.outputs.getter(v13, a2);
    Model.inputs.setter(v14);
    Model.init()();
    uint64_t v15 = Model.inputs.getter();
    Model.inputs.setter(v15);
    uint64_t v16 = Model.outputs.getter(v15, a2);
    Model.outputs.setter(v16);
    uint64_t v17 = Model.predictedFeatureName.getter();
    Model.predictedFeatureName.setter(v17, v18);
    uint64_t v19 = Model.predictedProbabilitiesName.getter();
    Model.predictedProbabilitiesName.setter(v19, v20);
    uint64_t v21 = Model.nestedModels.getter();
    uint64_t v22 = Model.nestedModels.getter();
    v26[0] = v21;
    specialized Array.append<A>(contentsOf:)(v22);
    uint64_t v23 = v29;
    PipelineClassifierConfiguration.init(models:names:)(v26[0], _swiftEmptyArrayStorage);
    (*(void (**)(void *, void, uint64_t))(v27 + 104))(v23, enum case for ModelKind.pipelineClassifier(_:), v28);
    Model.kind.setter(v23);
    uint64_t v24 = *(void (**)(void *, uint64_t))(v32 + 8);
    uint64_t v25 = v30;
    v24(v33, v30);
    v24(v31, v25);
  }
}

void MLSoundClassifier.Model.createFeatureExtractorModel(internalMetadata:)(void *a1)
{
  uint64_t v89 = v2;
  uint64_t v67 = v3;
  unint64_t v82 = a1;
  uint64_t v80 = v1;
  uint64_t v74 = type metadata accessor for AudioFeaturePrint(0);
  uint64_t v85 = *(void *)(v74 - 8);
  int64_t v4 = *(void *)(v85 + 64);
  uint64_t v5 = alloca(v4);
  int v6 = alloca(v4);
  uint64_t v87 = v63;
  uint64_t v81 = type metadata accessor for Model(0);
  uint64_t v7 = *(void *)(v81 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v75 = v63;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  long long v77 = v63;
  char v88 = (void *)type metadata accessor for URL.DirectoryHint(0);
  uint64_t v68 = *(v88 - 1);
  int64_t v13 = *(void *)(v68 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  unint64_t v69 = v63;
  uint64_t v71 = type metadata accessor for UUID(0);
  uint64_t v72 = *(void *)(v71 - 8);
  int64_t v16 = *(void *)(v72 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  unint64_t v73 = v63;
  uint64_t v19 = type metadata accessor for URL(0);
  uint64_t v79 = *(void *)(v19 - 8);
  int64_t v20 = *(void *)(v79 + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v76 = v63;
  uint64_t v23 = alloca(v20);
  uint64_t v24 = alloca(v20);
  uint64_t v78 = v63;
  uint64_t v25 = alloca(v20);
  uint64_t v26 = alloca(v20);
  __m128 v70 = v63;
  uint64_t v27 = alloca(v20);
  uint64_t v28 = alloca(v20);
  uint64_t v86 = v63;
  long long v29 = objc_opt_self(NSFileManager);
  id v30 = [v29 defaultManager];
  id v31 = v30;
  NSFileManager.createTemporaryModelDirectory()();

  if (!v32)
  {
    uint64_t v83 = 0;
    uint64_t v84 = v7;
    id v33 = [v29 defaultManager];
    id v34 = v33;
    NSFileManager.temporaryModelDirectory.getter();

    long long v35 = v73;
    UUID.init()();
    uint64_t v36 = UUID.uuidString.getter();
    uint64_t v38 = v37;
    (*(void (**)(unsigned char *, uint64_t))(v72 + 8))(v35, v71);
    uint64_t v64 = v36;
    uint64_t v65 = v38;
    unint64_t v39 = v69;
    uint64_t v89 = v19;
    uint64_t v40 = v68;
    (*(void (**)(unsigned char *, void, void *))(v68 + 104))(v69, enum case for URL.DirectoryHint.inferFromPath(_:), v88);
    uint64_t v41 = lazy protocol witness table accessor for type String and conformance String();
    uint64_t v42 = v70;
    uint64_t v43 = v78;
    URL.appending<A>(component:directoryHint:)(&v64, v39, &type metadata for String, v41);
    (*(void (**)(unsigned char *, void *))(v40 + 8))(v39, v88);
    swift_bridgeObjectRelease(v65);
    int64_t v44 = *(void **)(v79 + 8);
    uint64_t v45 = v89;
    ((void (*)(unsigned char *, uint64_t))v44)(v43, v89);
    URL.appendingPathExtension(_:)(0x6C65646F6D6C6D2ELL, 0xE800000000000000);
    char v88 = v44;
    ((void (*)(unsigned char *, uint64_t))v44)(v42, v45);
    uint64_t v46 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
    uint64_t v47 = v67;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v67 + *(int *)(v46 + 28), (uint64_t)&v64, &demangling cache variable for type metadata for Any?);
    if (v66)
    {
      char v48 = swift_dynamicCast(v63, &v64, (char *)&type metadata for Any + 8, &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType, 6);
      uint64_t v49 = v87;
      if (v48)
      {
        char v50 = v63[8];
        swift_bridgeObjectRelease(v63[16]);
        if (!v50)
        {
          uint64_t v51 = v77;
          uint64_t v52 = v83;
          static MLSoundClassifier.VGGishFeatureExtractor.buildCoreMLSpec(outputName:)(0x7365727574616566, 0xE800000000000000);
          if (!v52)
          {
            uint64_t v62 = Model.metadata.getter();
            specialized Dictionary._Variant.merge<A>(_:uniquingKeysWith:)(v62, (uint64_t)specialized thunk for @escaping @callee_guaranteed (@in_guaranteed A, @in_guaranteed B) -> (@out A, @out B), 0, v82);
            ((void (*)(unsigned char *, uint64_t))v88)(v86, v89);
            (*(void (**)(uint64_t, unsigned char *, uint64_t))(v84 + 32))(v80, v51, v81);
            return;
          }
          uint64_t v53 = v89;
          char v54 = v86;
          goto LABEL_11;
        }
      }
    }
    else
    {
      outlined destroy of Any?((uint64_t)&v64);
      uint64_t v49 = v87;
    }
    double v55 = MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.getter();
    AudioFeaturePrint.init(windowDuration:overlapFactor:)(v55, *(double *)(v47 + *(int *)(v46 + 24)));
    uint64_t v56 = lazy protocol witness table accessor for type AudioFeaturePrint and conformance AudioFeaturePrint();
    char v54 = v86;
    uint64_t v57 = v74;
    uint64_t v58 = v83;
    TemporalTransformer.export(to:)(v86, v74, v56);
    if (!v58)
    {
      int64_t v59 = v76;
      (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v79 + 16))(v76, v54, v89);
      uint64_t v60 = v75;
      Model.init(contentsOf:)(v59);
      uint64_t v61 = Model.metadata.getter();
      specialized Dictionary._Variant.merge<A>(_:uniquingKeysWith:)(v61, (uint64_t)specialized thunk for @escaping @callee_guaranteed (@in_guaranteed A, @in_guaranteed B) -> (@out A, @out B), 0, v82);
      (*(void (**)(uint64_t, unsigned char *, uint64_t))(v84 + 32))(v80, v60, v81);
      $defer #1 () in MLSoundClassifier.Model.createFeatureExtractorModel(internalMetadata:)();
      (*(void (**)(unsigned char *, uint64_t))(v85 + 8))(v87, v57);
      ((void (*)(unsigned char *, uint64_t))v88)(v54, v89);
      return;
    }
    (*(void (**)(unsigned char *, uint64_t))(v85 + 8))(v49, v57);
    uint64_t v53 = v89;
LABEL_11:
    ((void (*)(unsigned char *, uint64_t))v88)(v54, v53);
  }
}

void MLSoundClassifier.Model.createClassifierModel(internalMetadata:)(void *a1)
{
  uint64_t v74 = v2;
  char v90 = a1;
  uint64_t v87 = v1;
  uint64_t v89 = type metadata accessor for Model(0);
  uint64_t v88 = *(void *)(v89 - 8);
  int64_t v3 = *(void *)(v88 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v92 = &v71;
  uint64_t v83 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  uint64_t v95 = *(void *)(v83 - 8);
  int64_t v6 = *(void *)(v95 + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v84 = &v71;
  uint64_t v85 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  uint64_t v96 = *(void *)(v85 - 8);
  int64_t v9 = *(void *)(v96 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v86 = &v71;
  uint64_t v76 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int64_t v12 = *(void *)(*(void *)(v76 - 8) + 64);
  int64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v75 = &v71;
  uint64_t v77 = type metadata accessor for URL.DirectoryHint(0);
  uint64_t v78 = *(void *)(v77 - 8);
  int64_t v15 = *(void *)(v78 + 64);
  int64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v79 = &v71;
  uint64_t v80 = type metadata accessor for UUID(0);
  uint64_t v81 = *(void *)(v80 - 8);
  int64_t v18 = *(void *)(v81 + 64);
  uint64_t v19 = alloca(v18);
  int64_t v20 = alloca(v18);
  unint64_t v82 = &v71;
  uint64_t v97 = type metadata accessor for URL(0);
  uint64_t v94 = *(void *)(v97 - 8);
  int64_t v21 = *(void *)(v94 + 64);
  uint64_t v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  uint64_t v24 = alloca(v21);
  uint64_t v25 = alloca(v21);
  unint64_t v91 = &v71;
  uint64_t v26 = alloca(v21);
  uint64_t v27 = alloca(v21);
  uint64_t v100 = &v71;
  uint64_t v28 = alloca(v21);
  long long v29 = alloca(v21);
  char v98 = &v71;
  id v30 = objc_opt_self(NSFileManager);
  id v31 = [v30 defaultManager];
  id v32 = v31;
  NSFileManager.createTemporaryModelDirectory()();

  if (!v33)
  {
    uint64_t v93 = &v71;
    uint64_t v99 = 0;
    id v34 = [v30 defaultManager];
    id v35 = v34;
    NSFileManager.temporaryModelDirectory.getter();

    uint64_t v36 = v82;
    UUID.init()();
    uint64_t v37 = UUID.uuidString.getter();
    uint64_t v39 = v38;
    (*(void (**)(uint64_t *, uint64_t))(v81 + 8))(v36, v80);
    uint64_t v72 = v37;
    uint64_t v73 = v39;
    uint64_t v40 = v79;
    uint64_t v41 = v77;
    uint64_t v42 = v78;
    (*(void (**)(uint64_t *, void, uint64_t))(v78 + 104))(v79, enum case for URL.DirectoryHint.inferFromPath(_:), v77);
    uint64_t v43 = lazy protocol witness table accessor for type String and conformance String();
    int64_t v44 = v91;
    URL.appending<A>(component:directoryHint:)(&v72, v40, &type metadata for String, v43);
    (*(void (**)(uint64_t *, uint64_t))(v42 + 8))(v40, v41);
    swift_bridgeObjectRelease(v73);
    uint64_t v45 = *(void (**)(uint64_t *, uint64_t))(v94 + 8);
    uint64_t v46 = v97;
    v45(v44, v97);
    uint64_t v47 = v98;
    char v48 = v100;
    URL.appendingPathExtension(_:)(0x6C65646F6D6C6D2ELL, 0xE800000000000000);
    uint64_t v100 = (uint64_t *)v45;
    v45(v48, v46);
    uint64_t v49 = type metadata accessor for MLSoundClassifier.Model(0);
    uint64_t v50 = (uint64_t)v75;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(int *)(v49 + 20) + v74, (uint64_t)v75, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    if (swift_getEnumCaseMultiPayload(v50, v76) == 1)
    {
      uint64_t v51 = v84;
      uint64_t v52 = v83;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v95 + 32))(v84, v50, v83);
      uint64_t v53 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FullyConnectedNetworkClassifierModel<Float, String> and conformance FullyConnectedNetworkClassifierModel<A, B>, &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>, (uint64_t)&protocol conformance descriptor for FullyConnectedNetworkClassifierModel<A, B>);
      uint64_t v54 = v99;
      Transformer.export(to:)(v47, v52, v53);
      if (v54)
      {
        double v55 = v51;
        uint64_t v56 = v52;
        uint64_t v57 = v95;
LABEL_7:
        (*(void (**)(uint64_t *, uint64_t))(v57 + 8))(v55, v56);
        ((void (*)(uint64_t *, uint64_t))v100)(v98, v97);
        return;
      }
      uint64_t v99 = 0;
      uint64_t v62 = v51;
      uint64_t v63 = v52;
      uint64_t v64 = v95;
    }
    else
    {
      uint64_t v58 = v86;
      uint64_t v59 = v85;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v96 + 32))(v86, v50, v85);
      uint64_t v60 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type LogisticRegressionClassifierModel<Float, String> and conformance LogisticRegressionClassifierModel<A, B>, &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>, (uint64_t)&protocol conformance descriptor for LogisticRegressionClassifierModel<A, B>);
      uint64_t v61 = v99;
      Transformer.export(to:)(v47, v59, v60);
      if (v61)
      {
        double v55 = v58;
        uint64_t v56 = v59;
        uint64_t v57 = v96;
        goto LABEL_7;
      }
      uint64_t v99 = 0;
      uint64_t v62 = v58;
      uint64_t v63 = v59;
      uint64_t v64 = v96;
    }
    (*(void (**)(uint64_t *, uint64_t))(v64 + 8))(v62, v63);
    uint64_t v65 = v92;
    uint64_t v66 = v93;
    uint64_t v67 = v98;
    uint64_t v68 = v97;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v94 + 16))(v93, v98, v97);
    uint64_t v69 = v99;
    Model.init(contentsOf:)(v66);
    if (!v69)
    {
      uint64_t v70 = Model.metadata.getter();
      specialized Dictionary._Variant.merge<A>(_:uniquingKeysWith:)(v70, (uint64_t)specialized thunk for @escaping @callee_guaranteed (@in_guaranteed A, @in_guaranteed B) -> (@out A, @out B), 0, v90);
      (*(void (**)(uint64_t, uint64_t *, uint64_t))(v88 + 32))(v87, v65, v89);
    }
    $defer #1 () in MLSoundClassifier.Model.createFeatureExtractorModel(internalMetadata:)();
    ((void (*)(uint64_t *, uint64_t))v100)(v67, v68);
  }
}

NSURL *$defer #1 () in MLSoundClassifier.Model.createFeatureExtractorModel(internalMetadata:)()
{
  uint64_t v0 = objc_opt_self(NSFileManager);
  id v1 = [v0 defaultManager];
  uint64_t v2 = (NSURL *)v1;
  URL._bridgeToObjectiveC()(v2);
  int64_t v4 = v3;
  id v10 = 0;
  unsigned __int8 v5 = [(NSURL *)v2 removeItemAtURL:v3 error:&v10];

  id v6 = v10;
  if (v5) {
    return (NSURL *)v10;
  }
  id v8 = v10;
  uint64_t v9 = _convertNSErrorToError(_:)(v6);

  swift_willThrow();
  swift_errorRelease(v9);
  return __stack_chk_guard;
}

uint64_t lazy protocol witness table accessor for type AudioFeaturePrint and conformance AudioFeaturePrint()
{
  uint64_t result = lazy protocol witness table cache variable for type AudioFeaturePrint and conformance AudioFeaturePrint;
  if (!lazy protocol witness table cache variable for type AudioFeaturePrint and conformance AudioFeaturePrint)
  {
    uint64_t v1 = type metadata accessor for AudioFeaturePrint(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for AudioFeaturePrint, v1);
    lazy protocol witness table cache variable for type AudioFeaturePrint and conformance AudioFeaturePrint = result;
  }
  return result;
}

uint64_t static Dense.loadLayer(from:layerName:)(uint64_t a1, void *a2, uint64_t a3, double a4, double a5)
{
  v90[1] = v6;
  v90[2] = v5;
  int64_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?)
                             - 8)
                 + 64);
  id v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v97 = v90;
  int64_t v12 = alloca(v9);
  int64_t v13 = alloca(v9);
  uint64_t v100 = v90;
  int64_t v14 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TensorShape?)
                              - 8)
                  + 64);
  int64_t v15 = alloca(v14);
  int64_t v16 = alloca(v14);
  uint64_t v96 = v90;
  uint64_t v103 = type metadata accessor for Tensor(0);
  uint64_t v91 = *(void *)(v103 - 8);
  int64_t v17 = *(void *)(v91 + 64);
  int64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v92 = v90;
  int64_t v20 = alloca(v17);
  int64_t v21 = alloca(v17);
  uint64_t v99 = v90;
  uint64_t v105 = type metadata accessor for TensorShape(0);
  uint64_t v101 = *(void *)(v105 - 8);
  int64_t v22 = *(void *)(v101 + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  char v98 = v90;
  uint64_t v25 = alloca(v22);
  uint64_t v26 = alloca(v22);
  uint64_t v95 = v90;
  uint64_t v111 = a2;
  uint64_t v109 = a2;
  uint64_t v110 = a3;
  swift_bridgeObjectRetain(a3);
  v27._uint64_t countAndFlagsBits = 0x7468676965772ELL;
  v27._char object = (void *)0xE700000000000000;
  String.append(_:)(v27);
  char v28 = v110;
  uint64_t v29 = a1;
  uint64_t v30 = specialized Dictionary.subscript.getter((uint64_t)v109, v110, a1);
  swift_bridgeObjectRelease(v28);
  uint64_t v107 = v30;
  if (!v30)
  {
    uint64_t v109 = 0;
    uint64_t v110 = 0xE000000000000000;
    _StringGuts.grow(_:)(39);
    char v47 = v110;
    swift_bridgeObjectRetain(a3);
    swift_bridgeObjectRelease(v47);
    uint64_t v109 = v111;
    uint64_t v110 = a3;
    v48._char object = "predictionWindowSize" + 0x8000000000000000;
    v48._uint64_t countAndFlagsBits = 0xD000000000000025;
LABEL_14:
    String.append(_:)(v48);
    uint64_t v50 = v109;
    uint64_t v51 = v110;
    uint64_t v52 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v52, 0, 0);
    *(void *)uint64_t v53 = v50;
    *(void *)(v53 + 8) = v51;
    *(_OWORD *)(v53 + 16) = 0;
    *(_OWORD *)(v53 + 32) = 0;
    *(unsigned char *)(v53 + 48) = 2;
    return swift_willThrow(&type metadata for MLCreateError, v52, v53, v54, v55, v56);
  }
  uint64_t v106 = v29;
  id v31 = v111;
  uint64_t v109 = v111;
  uint64_t v110 = a3;
  swift_bridgeObjectRetain(a3);
  v32._uint64_t countAndFlagsBits = 0x2E7468676965772ELL;
  v32._char object = (void *)0xED00006570616873;
  String.append(_:)(v32);
  char v33 = v110;
  uint64_t v34 = specialized Dictionary.subscript.getter((uint64_t)v109, v110, v106);
  swift_bridgeObjectRelease(v33);
  if (!v34)
  {
    swift_bridgeObjectRelease(v107);
    uint64_t v109 = 0;
    uint64_t v110 = 0xE000000000000000;
    _StringGuts.grow(_:)(45);
    char v49 = v110;
    swift_bridgeObjectRetain(a3);
    swift_bridgeObjectRelease(v49);
    uint64_t v109 = v31;
    uint64_t v110 = a3;
    v48._uint64_t countAndFlagsBits = 0xD00000000000002BLL;
    v48._char object = "d in state dictionary" + 0x8000000000000000;
    goto LABEL_14;
  }
  uint64_t v102 = a3;
  int64_t v35 = *(void *)(v34 + 16);
  if (v35)
  {
    uint64_t v109 = _swiftEmptyArrayStorage;
    uint64_t v36 = 0;
    int64_t v104 = v34;
    uint64_t v108 = (char *)v35;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v35, 0);
    uint64_t v37 = v108;
    int64_t v38 = v104;
    uint64_t v39 = v109;
    a4 = -9.223372036854778e18;
    a5 = 9.223372036854776e18;
    int v40 = 1;
    do
    {
      double v41 = *(double *)(v38 + 8 * (void)v36 + 32);
      if ((~*(void *)&v41 & 0x7FF0000000000000) == 0) {
        BUG();
      }
      if (v41 <= -9.223372036854778e18) {
        BUG();
      }
      if (v41 >= 9.223372036854776e18) {
        BUG();
      }
      uint64_t v109 = v39;
      unint64_t v42 = v39[2];
      unint64_t v43 = v39[3];
      int64_t v44 = v42 + 1;
      if (v43 >> 1 <= v42)
      {
        int v46 = v40;
        double v93 = v41;
        int64_t v94 = v42 + 1;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v43 >= 2, v44, v40);
        int64_t v44 = v94;
        double v41 = v93;
        int v40 = v46;
        a5 = 9.223372036854776e18;
        a4 = -9.223372036854778e18;
        uint64_t v37 = v108;
        int64_t v38 = v104;
        uint64_t v39 = v109;
      }
      ++v36;
      v39[2] = v44;
      v39[v42 + 4] = (int)v41;
      uint64_t v45 = v105;
    }
    while (v37 != v36);
    swift_bridgeObjectRelease(v38);
  }
  else
  {
    swift_bridgeObjectRelease(v34);
    uint64_t v39 = _swiftEmptyArrayStorage;
    uint64_t v45 = v105;
  }
  uint64_t v58 = v95;
  TensorShape.init(_:)(v39, a4, a5);
  uint64_t v59 = (uint64_t)v96;
  uint64_t v108 = *(char **)(v101 + 16);
  ((void (*)(void *, void *, uint64_t))v108)(v96, v58, v45);
  __swift_storeEnumTagSinglePayload(v59, 0, 1, v45);
  LOBYTE(v58) = v107;
  Array<A>.floatTensor(shape:)(v59, v107);
  swift_bridgeObjectRelease((_BYTE)v58);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v59, &demangling cache variable for type metadata for TensorShape?);
  __swift_storeEnumTagSinglePayload((uint64_t)v100, 1, 1, v103);
  uint64_t v109 = v111;
  uint64_t v60 = v102;
  uint64_t v110 = v102;
  swift_bridgeObjectRetain(v102);
  v61._uint64_t countAndFlagsBits = 0x736169622ELL;
  v61._char object = (void *)0xE500000000000000;
  String.append(_:)(v61);
  char v62 = v110;
  uint64_t v63 = v106;
  uint64_t v64 = specialized Dictionary.subscript.getter((uint64_t)v109, v110, v106);
  swift_bridgeObjectRelease(v62);
  uint64_t v107 = v64;
  if (v64)
  {
    uint64_t v109 = v111;
    uint64_t v110 = v60;
    swift_bridgeObjectRetain(v60);
    v65._uint64_t countAndFlagsBits = 0x68732E736169622ELL;
    v65._char object = (void *)0xEB00000000657061;
    String.append(_:)(v65);
    char v66 = v110;
    uint64_t v67 = specialized Dictionary.subscript.getter((uint64_t)v109, v110, v63);
    swift_bridgeObjectRelease(v66);
    if (v67)
    {
      int64_t v68 = *(void *)(v67 + 16);
      if (v68)
      {
        uint64_t v109 = _swiftEmptyArrayStorage;
        uint64_t v69 = 0;
        uint64_t v106 = v67;
        uint64_t v111 = (void *)v68;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v68, 0);
        uint64_t v70 = v111;
        uint64_t v71 = v106;
        uint64_t v72 = v109;
        a4 = -9.223372036854778e18;
        a5 = 9.223372036854776e18;
        int v73 = 1;
        do
        {
          double v74 = *(double *)(v71 + 8 * (void)v69 + 32);
          if ((~*(void *)&v74 & 0x7FF0000000000000) == 0) {
            BUG();
          }
          if (v74 <= -9.223372036854778e18) {
            BUG();
          }
          if (v74 >= 9.223372036854776e18) {
            BUG();
          }
          uint64_t v109 = v72;
          unint64_t v75 = v72[2];
          unint64_t v76 = v72[3];
          int64_t v77 = v75 + 1;
          if (v76 >> 1 <= v75)
          {
            int v79 = v73;
            *(double *)&uint64_t v102 = v74;
            int64_t v104 = v75 + 1;
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v76 >= 2, v77, v73);
            int64_t v77 = v104;
            double v74 = *(double *)&v102;
            int v73 = v79;
            a5 = 9.223372036854776e18;
            a4 = -9.223372036854778e18;
            uint64_t v70 = v111;
            uint64_t v71 = v106;
            uint64_t v72 = v109;
          }
          uint64_t v69 = (void *)((char *)v69 + 1);
          v72[2] = v77;
          v72[v75 + 4] = (int)v74;
          uint64_t v78 = v105;
        }
        while (v70 != v69);
        swift_bridgeObjectRelease(v71);
      }
      else
      {
        swift_bridgeObjectRelease(v67);
        uint64_t v72 = _swiftEmptyArrayStorage;
        uint64_t v78 = v105;
      }
      uint64_t v80 = v98;
      TensorShape.init(_:)(v72, a4, a5);
      uint64_t v81 = (uint64_t)v96;
      ((void (*)(void *, void *, uint64_t))v108)(v96, v80, v78);
      uint64_t v82 = v78;
      __swift_storeEnumTagSinglePayload(v81, 0, 1, v78);
      uint64_t v83 = (uint64_t)v97;
      char v84 = v107;
      Array<A>.floatTensor(shape:)(v81, v107);
      swift_bridgeObjectRelease(v84);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v81, &demangling cache variable for type metadata for TensorShape?);
      (*(void (**)(void *, uint64_t))(v101 + 8))(v98, v82);
      uint64_t v85 = (uint64_t)v100;
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v100, &demangling cache variable for type metadata for Tensor?);
      __swift_storeEnumTagSinglePayload(v83, 0, 1, v103);
      outlined init with take of Tensor?(v83, v85);
    }
    else
    {
      swift_bridgeObjectRelease(v107);
    }
  }
  uint64_t v86 = v92;
  uint64_t v87 = v91;
  (*(void (**)(void *, void *, uint64_t))(v91 + 16))(v92, v99, v103);
  uint64_t v88 = (uint64_t)v100;
  uint64_t v89 = (uint64_t)v97;
  outlined init with copy of Tensor?((uint64_t)v100, (uint64_t)v97);
  Dense.init(weight:bias:)(v86, v89);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v88, &demangling cache variable for type metadata for Tensor?);
  (*(void (**)(void *, uint64_t))(v87 + 8))(v99, v103);
  return (*(uint64_t (**)(void *, uint64_t))(v101 + 8))(v95, v105);
}

uint64_t outlined init with take of Tensor?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t MLDecisionTreeClassifier.ModelParameters.init(validation:maxDepth:minLossReduction:minChildWeight:randomSeed:)(uint64_t a1, uint64_t a2, uint64_t a3, double a4, double a5)
{
  uint64_t v15 = a3;
  double v16 = a5;
  double v18 = a4;
  uint64_t v6 = v5;
  uint64_t v7 = type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData(0);
  int64_t v8 = *(void *)(*(void *)(v7 - 8) + 64);
  int64_t v9 = alloca(v8);
  id v10 = alloca(v8);
  uint64_t v17 = v6 + 8;
  *(_OWORD *)(v6 + 24) = 0;
  *(_OWORD *)(v6 + 8) = 0;
  *(void *)uint64_t v6 = a2;
  *(double *)(v6 + 40) = v18;
  *(double *)(v6 + 48) = v16;
  *(void *)(v6 + 56) = v15;
  outlined init with copy of MLDecisionTreeClassifier.ModelParameters.ValidationData(a1, (uint64_t)&v13);
  void v14[3] = v7;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v14);
  outlined init with take of MLDecisionTreeClassifier.ModelParameters.ValidationData((uint64_t)&v13, (uint64_t)boxed_opaque_existential_1);
  outlined assign with take of Any?((uint64_t)v14, v17);
  return outlined destroy of MLDecisionTreeClassifier.ModelParameters.ValidationData(a1);
}

uint64_t MLDecisionTreeClassifier.ModelParameters.validation.getter()
{
  uint64_t v2 = v0;
  outlined init with copy of Any?(v1 + 8, (uint64_t)&v6);
  if (!v7) {
    BUG();
  }
  outlined init with take of Any(&v6, v5);
  uint64_t v3 = type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData(0);
  return swift_dynamicCast(v2, v5, (char *)&type metadata for Any + 8, v3, 7);
}

uint64_t MLDecisionTreeClassifier.ModelParameters.init(validationData:maxDepth:minLossReduction:minChildWeight:randomSeed:)(uint64_t *a1, uint64_t a2, uint64_t a3, double a4, double a5)
{
  uint64_t v6 = *a1;
  char v7 = *((unsigned char *)a1 + 8);
  *(_OWORD *)(v5 + 24) = 0;
  *(_OWORD *)(v5 + 8) = 0;
  *(void *)uint64_t v5 = a2;
  *(double *)(v5 + 40) = a4;
  *(double *)(v5 + 48) = a5;
  *(void *)(v5 + 56) = a3;
  uint64_t v9 = v6;
  char v10 = v7;
  return MLDecisionTreeClassifier.ModelParameters.validationData.setter((uint64_t)&v9);
}

uint64_t MLDecisionTreeClassifier.ModelParameters.description.getter()
{
  v0._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  char object = v0._object;
  String.append(_:)(v0);
  swift_bridgeObjectRelease(object);
  v2._char object = (void *)0xE100000000000000;
  v2._uint64_t countAndFlagsBits = 10;
  String.append(_:)(v2);
  v9._uint64_t countAndFlagsBits = 0;
  v9._char object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(23);
  v2._uint64_t countAndFlagsBits = 0xD000000000000014;
  v2._char object = "Max Iterations: " + 0x8000000000000000;
  String.append(_:)(v2);
  Double.write<A>(to:)(&v9, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v2._uint64_t countAndFlagsBits = 10;
  v2._char object = (void *)0xE100000000000000;
  String.append(_:)(v2);
  uint64_t v3 = v9._object;
  String.append(_:)(v9);
  swift_bridgeObjectRelease(v3);
  v9._uint64_t countAndFlagsBits = 0;
  v9._char object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(21);
  v2._char object = "Min Loss Reduction: " + 0x8000000000000000;
  v2._uint64_t countAndFlagsBits = 0xD000000000000012;
  String.append(_:)(v2);
  Double.write<A>(to:)(&v9, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v2._uint64_t countAndFlagsBits = 10;
  v2._char object = (void *)0xE100000000000000;
  String.append(_:)(v2);
  int64_t v4 = v9._object;
  String.append(_:)(v9);
  swift_bridgeObjectRelease(v4);
  v9._uint64_t countAndFlagsBits = 0;
  v9._char object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(16);
  swift_bridgeObjectRelease(v9._object);
  strcpy((char *)&v9, "Random Seed: ");
  HIWORD(v9._object) = -4864;
  v5._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  uint64_t v6 = v5._object;
  String.append(_:)(v5);
  swift_bridgeObjectRelease(v6);
  v2._uint64_t countAndFlagsBits = 10;
  v2._char object = (void *)0xE100000000000000;
  String.append(_:)(v2);
  char v7 = v9._object;
  String.append(_:)(v9);
  swift_bridgeObjectRelease(v7);
  return 0x747065442078614DLL;
}

uint64_t MLDecisionTreeClassifier.ModelParameters.maxDepth.getter()
{
  return *(void *)v0;
}

void MLDecisionTreeClassifier.ModelParameters.maxDepth.setter(uint64_t a1)
{
  *uint64_t v1 = a1;
}

void (*MLDecisionTreeClassifier.ModelParameters.maxDepth.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLDecisionTreeClassifier.ModelParameters.validationData.getter(__m128 a1)
{
  uint64_t v2 = type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData(0);
  int64_t v3 = *(void *)(*(void *)(v2 - 8) + 64);
  int64_t v4 = alloca(v3);
  Swift::String v5 = alloca(v3);
  outlined init with copy of Any?(v1 + 8, (uint64_t)&v9);
  if (!v10) {
    BUG();
  }
  outlined init with take of Any(&v9, v8);
  swift_dynamicCast(&v7, v8, (char *)&type metadata for Any + 8, v2, 7);
  MLDecisionTreeClassifier.ModelParameters.ValidationData.asTable()(a1);
  return outlined destroy of MLDecisionTreeClassifier.ModelParameters.ValidationData((uint64_t)&v7);
}

uint64_t key path getter for MLDecisionTreeClassifier.ModelParameters.validationData : MLDecisionTreeClassifier.ModelParameters(__m128 a1)
{
  uint64_t v2 = v1;
  MLDecisionTreeClassifier.ModelParameters.validationData.getter(a1);
  uint64_t result = v4;
  *(void *)uint64_t v2 = v4;
  *(unsigned char *)(v2 + 8) = v5;
  return result;
}

uint64_t key path setter for MLDecisionTreeClassifier.ModelParameters.validationData : MLDecisionTreeClassifier.ModelParameters(uint64_t a1)
{
  int v1 = *(_DWORD *)(a1 + 8);
  uint64_t v3 = *(void *)a1;
  char v4 = v1;
  outlined copy of MLDataTable?(v3, v1);
  return MLDecisionTreeClassifier.ModelParameters.validationData.setter((uint64_t)&v3);
}

uint64_t MLDecisionTreeClassifier.ModelParameters.validationData.setter(uint64_t a1)
{
  uint64_t v18 = v1;
  unsigned int v2 = 0;
  uint64_t v3 = type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData(0);
  int64_t v4 = *(void *)(*(void *)(v3 - 8) + 64);
  char v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v17 = *(void *)a1;
  char v7 = *(unsigned char *)(a1 + 8);
  uint64_t v13 = v3;
  double v16 = __swift_allocate_boxed_opaque_existential_1(&v11);
  if (v7 == -1)
  {
    long long v11 = 0;
    __int16 v12 = 256;
  }
  else
  {
    uint64_t v14 = v17;
    char v15 = v7 & 1;
    if (MLDataTable.size.getter())
    {
      *(void *)&long long v11 = v17;
      BYTE8(v11) = v7 & 1;
      int v10 = 1;
    }
    else
    {
      outlined consume of MLDataTable?(v17, v7);
      int v10 = 3;
    }
    unsigned int v2 = v10;
  }
  uint64_t v8 = v18;
  swift_storeEnumTagMultiPayload(&v11, v3, v2);
  outlined init with take of MLDecisionTreeClassifier.ModelParameters.ValidationData((uint64_t)&v11, (uint64_t)v16);
  return outlined assign with take of Any?((uint64_t)&v11, v8 + 8);
}

uint64_t (*MLDecisionTreeClassifier.ModelParameters.validationData.modify(uint64_t a1, __m128 a2))(uint64_t a1, char a2)
{
  *(void *)(a1 + 16) = v2;
  MLDecisionTreeClassifier.ModelParameters.validationData.getter(a2);
  return MLDecisionTreeClassifier.ModelParameters.validationData.modify;
}

uint64_t MLDecisionTreeClassifier.ModelParameters.validationData.modify(uint64_t a1, char a2)
{
  uint64_t v2 = *(void *)a1;
  char v3 = *(unsigned char *)(a1 + 8);
  uint64_t v6 = *(void *)a1;
  char v7 = v3;
  if ((a2 & 1) == 0) {
    return MLDecisionTreeClassifier.ModelParameters.validationData.setter((uint64_t)&v6);
  }
  char v4 = v3;
  outlined copy of MLDataTable?(v2, v3);
  MLDecisionTreeClassifier.ModelParameters.validationData.setter((uint64_t)&v6);
  return outlined consume of MLDataTable?(v2, v4);
}

uint64_t key path setter for MLDecisionTreeClassifier.ModelParameters.validation : MLDecisionTreeClassifier.ModelParameters(uint64_t a1)
{
  v6[0] = v1;
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData(0)
                             - 8)
                 + 64);
  char v3 = alloca(v2);
  char v4 = alloca(v2);
  outlined init with copy of MLDecisionTreeClassifier.ModelParameters.ValidationData(a1, (uint64_t)v6);
  return MLDecisionTreeClassifier.ModelParameters.validation.setter((uint64_t)v6);
}

uint64_t MLDecisionTreeClassifier.ModelParameters.validation.setter(uint64_t a1)
{
  v4[3] = type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData(0);
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v4);
  outlined init with take of MLDecisionTreeClassifier.ModelParameters.ValidationData(a1, (uint64_t)boxed_opaque_existential_1);
  return outlined assign with take of Any?((uint64_t)v4, v1 + 8);
}

uint64_t outlined init with take of MLDecisionTreeClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t outlined destroy of MLDecisionTreeClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

void (*MLDecisionTreeClassifier.ModelParameters.validation.modify(void *a1))(uint64_t a1, char a2)
{
  uint64_t v2 = malloc(0xA0uLL);
  *a1 = v2;
  *((void *)v2 + 16) = v1;
  uint64_t v3 = type metadata accessor for MLDecisionTreeClassifier.ModelParameters.ValidationData(0);
  *((void *)v2 + 17) = v3;
  size_t v4 = *(void *)(*(void *)(v3 - 8) + 64);
  *((void *)v2 + 18) = malloc(v4);
  char v5 = malloc(v4);
  *((void *)v2 + 19) = v5;
  outlined init with copy of Any?(v1 + 8, (uint64_t)(v2 + 2));
  if (!*((void *)v2 + 7)) {
    BUG();
  }
  outlined init with take of Any(v2 + 2, v2);
  swift_dynamicCast(v5, v2, (char *)&type metadata for Any + 8, v3, 7);
  return MLDecisionTreeClassifier.ModelParameters.validation.modify;
}

void MLDecisionTreeClassifier.ModelParameters.validation.modify(uint64_t a1, char a2)
{
  uint64_t v2 = *(void **)a1;
  uint64_t v3 = *(void **)(*(void *)a1 + 152);
  uint64_t v4 = *(void *)(*(void *)a1 + 144);
  uint64_t v5 = *(void *)(*(void *)a1 + 136);
  uint64_t v6 = *(void *)(*(void *)a1 + 128) + 8;
  if (a2)
  {
    int v10 = *(void **)(*(void *)a1 + 144);
    outlined init with copy of MLDecisionTreeClassifier.ModelParameters.ValidationData(*(void *)(*(void *)a1 + 152), v4);
    v2[11] = v5;
    char v7 = v10;
    boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v2 + 8);
    outlined init with take of MLDecisionTreeClassifier.ModelParameters.ValidationData((uint64_t)v10, (uint64_t)boxed_opaque_existential_1);
    outlined assign with take of Any?((uint64_t)(v2 + 8), v6);
    outlined destroy of MLDecisionTreeClassifier.ModelParameters.ValidationData((uint64_t)v3);
  }
  else
  {
    v2[15] = v5;
    char v7 = (void *)v4;
    long long v9 = __swift_allocate_boxed_opaque_existential_1(v2 + 12);
    outlined init with take of MLDecisionTreeClassifier.ModelParameters.ValidationData((uint64_t)v3, (uint64_t)v9);
    outlined assign with take of Any?((uint64_t)(v2 + 12), v6);
  }
  free(v3);
  free(v7);
  free(v2);
}

double MLDecisionTreeClassifier.ModelParameters.minLossReduction.getter()
{
  return *(double *)(v0 + 40);
}

void MLDecisionTreeClassifier.ModelParameters.minLossReduction.setter(double a1)
{
  *(double *)(v1 + 40) = a1;
}

void (*MLDecisionTreeClassifier.ModelParameters.minLossReduction.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLDecisionTreeClassifier.ModelParameters.minChildWeight.getter()
{
  return *(double *)(v0 + 48);
}

void MLDecisionTreeClassifier.ModelParameters.minChildWeight.setter(double a1)
{
  *(double *)(v1 + 48) = a1;
}

void (*MLDecisionTreeClassifier.ModelParameters.minChildWeight.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLDecisionTreeClassifier.ModelParameters.randomSeed.getter()
{
  return *(void *)(v0 + 56);
}

void MLDecisionTreeClassifier.ModelParameters.randomSeed.setter(uint64_t a1)
{
  *(void *)(v1 + 56) = a1;
}

void (*MLDecisionTreeClassifier.ModelParameters.randomSeed.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLDecisionTreeClassifier.ModelParameters.debugDescription.getter()
{
  return MLDecisionTreeClassifier.ModelParameters.description.getter();
}

uint64_t MLDecisionTreeClassifier.ModelParameters.playgroundDescription.getter()
{
  uint64_t v1 = v0;
  uint64_t result = MLDecisionTreeClassifier.ModelParameters.description.getter();
  v1[3] = (uint64_t)&type metadata for String;
  *uint64_t v1 = result;
  v1[1] = v3;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLDecisionTreeClassifier.ModelParameters()
{
  return MLDecisionTreeClassifier.ModelParameters.description.getter();
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLDecisionTreeClassifier.ModelParameters()
{
  return MLDecisionTreeClassifier.ModelParameters.debugDescription.getter();
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLDecisionTreeClassifier.ModelParameters()
{
  return MLDecisionTreeClassifier.ModelParameters.playgroundDescription.getter();
}

uint64_t sub_2AC613(__m128 a1)
{
  return key path getter for MLDecisionTreeClassifier.ModelParameters.validationData : MLDecisionTreeClassifier.ModelParameters(a1);
}

uint64_t sub_2AC61D(uint64_t a1)
{
  return key path setter for MLDecisionTreeClassifier.ModelParameters.validationData : MLDecisionTreeClassifier.ModelParameters(a1);
}

uint64_t sub_2AC627(uint64_t a1)
{
  return MLDecisionTreeClassifier.ModelParameters.validation.getter(a1);
}

uint64_t sub_2AC63E(uint64_t a1)
{
  return key path setter for MLDecisionTreeClassifier.ModelParameters.validation : MLDecisionTreeClassifier.ModelParameters(a1);
}

uint64_t initializeWithCopy for MLDecisionTreeClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v4 = (_OWORD *)(a1 + 8);
  uint64_t v5 = (long long *)(a2 + 8);
  uint64_t v6 = *(void *)(a2 + 32);
  if (v6)
  {
    *(void *)(a1 + 32) = v6;
    (**(void (***)(_OWORD *, long long *))(v6 - 8))(v4, v5);
  }
  else
  {
    long long v7 = *v5;
    v4[1] = v5[1];
    _OWORD *v4 = v7;
  }
  *(_OWORD *)(a1 + 40) = *(_OWORD *)(a2 + 40);
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  return a1;
}

uint64_t assignWithCopy for MLDecisionTreeClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v2 = *(void *)(a2 + 32);
  if (!*(void *)(a1 + 32))
  {
    if (v2)
    {
      *(void *)(a1 + 32) = v2;
      (**(void (***)(uint64_t, uint64_t))(v2 - 8))(a1 + 8, a2 + 8);
      goto LABEL_8;
    }
LABEL_7:
    long long v3 = *(_OWORD *)(a2 + 8);
    *(_OWORD *)(a1 + 24) = *(_OWORD *)(a2 + 24);
    *(_OWORD *)(a1 + 8) = v3;
    goto LABEL_8;
  }
  if (!v2)
  {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 8));
    goto LABEL_7;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)(a1 + 8), (uint64_t *)(a2 + 8));
LABEL_8:
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  *(void *)(a1 + 48) = *(void *)(a2 + 48);
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  return a1;
}

_OWORD *__swift_memcpy64_8(_OWORD *a1, long long *a2)
{
  uint64_t result = a1;
  long long v3 = *a2;
  long long v4 = a2[1];
  long long v5 = a2[2];
  a1[3] = a2[3];
  a1[2] = v5;
  a1[1] = v4;
  *a1 = v3;
  return result;
}

uint64_t assignWithTake for MLDecisionTreeClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  if (*(void *)(a1 + 32)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 8));
  }
  long long v2 = *(_OWORD *)(a2 + 8);
  *(_OWORD *)(a1 + 24) = *(_OWORD *)(a2 + 24);
  *(_OWORD *)(a1 + 8) = v2;
  *(_OWORD *)(a1 + 40) = *(_OWORD *)(a2 + 40);
  *(void *)(a1 + 56) = *(void *)(a2 + 56);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLDecisionTreeClassifier.ModelParameters(uint64_t a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 >= 0x7FFFFFFF && *(unsigned char *)(a1 + 64))
    {
      int v2 = *(_DWORD *)a1 + 2147483646;
    }
    else
    {
      unint64_t v3 = *(void *)(a1 + 32);
      unint64_t v4 = v3 & 0xFFFFFFFF00000001;
      int v5 = (v3 >> 1) - 1;
      int v6 = -1;
      if (v5 >= 0) {
        int v6 = v5;
      }
      int v2 = v4 != 0 ? -1 : v6;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

uint64_t storeEnumTagSinglePayload for MLDecisionTreeClassifier.ModelParameters(uint64_t a1, unsigned int a2, unsigned int a3)
{
  if (a2 > 0x7FFFFFFE)
  {
    *(void *)(a1 + 56) = 0;
    *(_OWORD *)(a1 + 40) = 0;
    *(_OWORD *)(a1 + 24) = 0;
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 - 0x7FFFFFFF;
    if (a3 >= 0x7FFFFFFF) {
      *(unsigned char *)(a1 + 64) = 1;
    }
  }
  else
  {
    if (a3 >= 0x7FFFFFFF) {
      *(unsigned char *)(a1 + 64) = 0;
    }
    if (a2)
    {
      uint64_t result = 2 * a2;
      *(void *)(a1 + 32) = result;
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for MLDecisionTreeClassifier.ModelParameters()
{
  return &type metadata for MLDecisionTreeClassifier.ModelParameters;
}

uint64_t specialized Result<>.init(catching:)(uint64_t a1, uint64_t a2)
{
  v2[3] = a2;
  v2[2] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLRandomForestRegressor, Error>);
  v2[4] = v3;
  unint64_t v4 = (*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  uint64_t v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);
  uint64_t v6 = dword_3A4B2C;
  swift_retain();
  long long v7 = (void *)swift_task_alloc(v6);
  v2[7] = v7;
  *long long v7 = v2;
  v7[1] = specialized Result<>.init(catching:);
  return MLRandomForestRegressor.init(delegate:)(v5, a2);
}

{
  void *v2;
  uint64_t v3;
  unint64_t v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;

  v2[3] = a2;
  v2[2] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLDecisionTreeRegressor, Error>);
  v2[4] = v3;
  unint64_t v4 = (*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  uint64_t v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);
  uint64_t v6 = dword_3A7134;
  swift_retain();
  long long v7 = (void *)swift_task_alloc(v6);
  v2[7] = v7;
  *long long v7 = v2;
  v7[1] = specialized Result<>.init(catching:);
  return MLDecisionTreeRegressor.init(delegate:)(v5, a2);
}

{
  void *v2;
  uint64_t v3;
  unint64_t v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;

  v2[3] = a2;
  v2[2] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLRandomForestClassifier, Error>);
  v2[4] = v3;
  unint64_t v4 = (*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  uint64_t v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);
  uint64_t v6 = dword_3AAE84;
  swift_retain();
  long long v7 = (void *)swift_task_alloc(v6);
  v2[7] = v7;
  *long long v7 = v2;
  v7[1] = specialized Result<>.init(catching:);
  return MLRandomForestClassifier.init(delegate:)(v5, a2);
}

{
  void *v2;
  uint64_t v3;
  unint64_t v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;

  v2[3] = a2;
  v2[2] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLBoostedTreeRegressor, Error>);
  v2[4] = v3;
  unint64_t v4 = (*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  uint64_t v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);
  uint64_t v6 = dword_3AB534;
  swift_retain();
  long long v7 = (void *)swift_task_alloc(v6);
  v2[7] = v7;
  *long long v7 = v2;
  v7[1] = specialized Result<>.init(catching:);
  return MLBoostedTreeRegressor.init(delegate:)(v5, a2);
}

{
  void *v2;
  uint64_t v3;
  unint64_t v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;

  v2[3] = a2;
  v2[2] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLDecisionTreeClassifier, Error>);
  v2[4] = v3;
  unint64_t v4 = (*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  uint64_t v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);
  uint64_t v6 = dword_3ACBD4;
  swift_retain();
  long long v7 = (void *)swift_task_alloc(v6);
  v2[7] = v7;
  *long long v7 = v2;
  v7[1] = specialized Result<>.init(catching:);
  return MLDecisionTreeClassifier.init(delegate:)(v5, a2);
}

{
  void *v2;
  uint64_t v3;
  unint64_t v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;

  v2[3] = a2;
  v2[2] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLSoundClassifier, Error>);
  v2[4] = v3;
  unint64_t v4 = (*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  uint64_t v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);
  uint64_t v6 = dword_3ACEEC;
  swift_retain();
  long long v7 = (void *)swift_task_alloc(v6);
  v2[7] = v7;
  *long long v7 = v2;
  v7[1] = specialized Result<>.init(catching:);
  return MLSoundClassifier.init(delegate:)(v5, a2);
}

{
  void *v2;
  uint64_t v3;
  unint64_t v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;

  v2[3] = a2;
  v2[2] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLBoostedTreeClassifier, Error>);
  v2[4] = v3;
  unint64_t v4 = (*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  uint64_t v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);
  uint64_t v6 = dword_3ADCF4;
  swift_retain();
  long long v7 = (void *)swift_task_alloc(v6);
  v2[7] = v7;
  *long long v7 = v2;
  v7[1] = specialized Result<>.init(catching:);
  return MLBoostedTreeClassifier.init(delegate:)(v5, a2);
}

{
  void *v2;
  uint64_t v3;
  unint64_t v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;

  v2[3] = a2;
  v2[2] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLLinearRegressor, Error>);
  v2[4] = v3;
  unint64_t v4 = (*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  uint64_t v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);
  uint64_t v6 = dword_3AE234;
  swift_retain();
  long long v7 = (void *)swift_task_alloc(v6);
  v2[7] = v7;
  *long long v7 = v2;
  v7[1] = specialized Result<>.init(catching:);
  return MLLinearRegressor.init(delegate:)(v5, a2);
}

{
  void *v2;
  uint64_t v3;
  unint64_t v4;
  uint64_t v5;
  uint64_t v6;
  void *v7;

  v2[3] = a2;
  v2[2] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLImageClassifier, Error>);
  v2[4] = v3;
  unint64_t v4 = (*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  uint64_t v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);
  uint64_t v6 = dword_3A9104;
  swift_retain();
  long long v7 = (void *)swift_task_alloc(v6);
  v2[7] = v7;
  *long long v7 = v2;
  v7[1] = specialized Result<>.init(catching:);
  return MLImageClassifier.init(delegate:)(v5, a2);
}

uint64_t ResultBox.__deallocating_deinit()
{
  outlined destroy of Result<Any, Error>?(v0 + 16);
  return swift_deallocClassInstance(v0, 49, 7);
}

uint64_t type metadata accessor for ResultBox()
{
  return objc_opt_self(_TtC8CreateMLP33_34E10FFAF45112124B0FBBF2DF2369379ResultBox);
}

uint64_t outlined destroy of Result<Any, Error>?(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<Any, Error>?);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t static MLHandPoseClassifier.FeatureExtractor.extractFeatures(from:startingSessionId:)(uint64_t a1, uint64_t a2)
{
  uint64_t v10 = a2;
  uint64_t v11 = v2;
  uint64_t v5 = *(void *)a1;
  char v6 = *(unsigned char *)(a1 + 8);
  uint64_t inited = swift_initStackObject(v4, v9);
  *(void *)(inited + 32) = _swiftEmptyArrayStorage;
  *(void *)(inited + 40) = _swiftEmptyArrayStorage;
  *(void *)(inited + 48) = _swiftEmptyArrayStorage;
  *(void *)(inited + 56) = _swiftEmptyArrayStorage;
  *(void *)(inited + 16) = v5;
  *(unsigned char *)(inited + 24) = v6;
  if (v3) {
    return outlined copy of Result<_DataTable, Error>(v5, v6);
  }
  outlined copy of Result<_DataTable, Error>(v5, v6);
  MLHandPoseClassifier.FeatureExtractor.extractFeaturesFromFileTable(startingSessionId:)(v10);
  return swift_release();
}

uint64_t static MLHandPoseClassifier.FeatureExtractor.extractFeatures(from:startingSessionId:)(uint64_t a1, uint64_t a2, __m128 a3)
{
  v9[0] = a2;
  v9[1] = v3;
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for MLHandPoseClassifier.DataSource(0) - 8) + 64);
  char v6 = alloca(v5);
  long long v7 = alloca(v5);
  outlined init with copy of MLHandPoseClassifier.DataSource(a1, (uint64_t)v9);
  uint64_t result = MLHandPoseClassifier.FeatureExtractor.__allocating_init(source:)((uint64_t)v9, a3);
  if (!v4)
  {
    MLHandPoseClassifier.FeatureExtractor.extractFeaturesFromFileTable(startingSessionId:)(v9[0]);
    return swift_release();
  }
  return result;
}

uint64_t MLHandPoseClassifier.FeatureExtractor.__allocating_init(source:)(uint64_t a1, __m128 a2)
{
  MLHandPoseClassifier.DataSource.imagesWithAnnotations()(a2);
  uint64_t result = outlined destroy of MLActivityClassifier.ModelParameters(a1, type metadata accessor for MLHandPoseClassifier.DataSource);
  if (!v2)
  {
    uint64_t result = swift_allocObject(v3, 64, 7);
    *(void *)(result + 32) = _swiftEmptyArrayStorage;
    *(void *)(result + 40) = _swiftEmptyArrayStorage;
    *(void *)(result + 48) = _swiftEmptyArrayStorage;
    *(void *)(result + 56) = _swiftEmptyArrayStorage;
    *(void *)(result + 16) = v5;
    *(unsigned char *)(result + 24) = v6;
  }
  return result;
}

uint64_t MLHandPoseClassifier.FeatureExtractor.extractFeaturesFromFileTable(startingSessionId:)(uint64_t a1)
{
  uint64_t v160 = v2;
  uint64_t v131 = a1;
  uint64_t v136 = v1;
  uint64_t v141 = type metadata accessor for URL(0);
  uint64_t v142 = *(void *)(v141 - 8);
  int64_t v4 = *(void *)(v142 + 64);
  uint64_t v5 = alloca(v4);
  char v6 = alloca(v4);
  uint64_t v143 = v128;
  v155._char object = (void *)type metadata accessor for Date(0);
  currentFileIndex[0] = *((void *)v155._object - 1);
  int64_t v7 = *(void *)(currentFileIndex[0] + 64);
  uint64_t v8 = alloca(v7);
  long long v9 = alloca(v7);
  v155._uint64_t countAndFlagsBits = (uint64_t)v128;
  uint64_t v153 = type metadata accessor for _TablePrinter(0);
  int64_t v10 = *(void *)(*(void *)(v153 - 8) + 64);
  uint64_t v11 = alloca(v10);
  __int16 v12 = alloca(v10);
  id v158 = (uint64_t *)v128;
  uint64_t v152 = (uint64_t *)v3;
  uint64_t v13 = *(void *)(v3 + 16);
  int v14 = *(unsigned __int8 *)(v3 + 24);
  uint64_t v149 = v13;
  LOBYTE(v150) = v14;
  uint64_t v144 = v13;
  LODWORD(v161) = v14;
  outlined copy of Result<_DataTable, Error>(v13, v14);
  Swift::Int v15 = MLDataTable.size.getter();
  uint64_t v16 = specialized RandomAccessCollection<>.distance(from:to:)(0, v15);
  outlined consume of Result<_DataTable, Error>(v13, v14);
  uint64_t v149 = 0;
  unint64_t v150 = 0xE000000000000000;
  _StringGuts.grow(_:)(30);
  swift_bridgeObjectRelease(v150);
  uint64_t v149 = 0x69737365636F7250;
  unint64_t v150 = 0xEB0000000020676ELL;
  _._uint64_t countAndFlagsBits = v16;
  v17._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  LOBYTE(v13) = v17._object;
  String.append(_:)(v17);
  swift_bridgeObjectRelease(v13);
  v18._uint64_t countAndFlagsBits = 0xD000000000000011;
  v18._char object = "ractor" + 0x8000000000000000;
  String.append(_:)(v18);
  uint64_t v19 = v149;
  int64_t v20 = (void *)v150;
  os_log_type_t v21 = static os_log_type_t.info.getter();
  v18._uint64_t countAndFlagsBits = v19;
  v18._char object = v20;
  log(_:type:)(v18, v21);
  v18._uint64_t countAndFlagsBits = (uint64_t)v20;
  swift_bridgeObjectRelease((_BYTE)v20);
  uint64_t v22 = v153;
  uint64_t v23 = v158;
  uint64_t v24 = (char *)v158 + *(int *)(v153 + 20);
  Date.init()(v18._countAndFlagsBits);
  *uint64_t v23 = v16;
  type metadata accessor for OS_os_log();
  uint64_t v25 = OS_os_log.init(subsystem:category:)(0xD000000000000025, " annotated images" + 0x8000000000000000, 0x72705F656C626174, 0xED00007265746E69);
  uint64_t v135 = *(int *)(v22 + 24);
  *(uint64_t *)((char *)v23 + v135) = v25;
  uint64_t v26 = *(int *)(v22 + 28);
  *(uint64_t *)((char *)v23 + v26) = 0xD000000000000010;
  *(uint64_t *)((char *)v23 + v26 + 8) = (uint64_t)("ml.handPoseClassifier" + 0x8000000000000000);
  uint64_t countAndFlagsBits = v155._countAndFlagsBits;
  Date.init()(0xD000000000000025);
  uint64_t v132 = v24;
  (*(void (**)(char *, uint64_t, void *))(currentFileIndex[0] + 40))(v24, countAndFlagsBits, v155._object);
  _TablePrinter.beginTable()();
  _TablePrinter.printRow(currentFileIndex:)(0);
  uint64_t v28 = v144;
  uint64_t v149 = v144;
  LOBYTE(v22) = v161;
  LOBYTE(v150) = v161;
  uint64_t v138 = v152 + 4;
  double v139 = v152 + 6;
  uint64_t v140 = v152 + 5;
  v152 += 7;
  __m128 v29 = 0;
  long long v151 = 0;
  outlined copy of Result<_DataTable, Error>(v144, v161);
  uint64_t v30 = v28;
  _._uint64_t countAndFlagsBits = v28;
  LOBYTE(_._object) = v22;
  if (MLDataTable.size.getter())
  {
    uint64_t v31 = 0;
    double v133 = "h or label string at row " + 0x8000000000000000;
    uint64_t v134 = "Extracted features from " + 0x8000000000000000;
    char v32 = v161;
    while (1)
    {
      currentFileIndex[0] = v31;
      MLDataTable.Rows.subscript.getter(v31);
      uint64_t v161 = _._countAndFlagsBits;
      char object = _._object;
      v155._char object = v157;
      char v34 = v32;
      outlined copy of Result<_DataTable, Error>(v30, v32);
      uint64_t v35 = specialized RandomAccessCollection<>.index(after:)(currentFileIndex[0]);
      outlined consume of Result<_DataTable, Error>(v30, v34);
      *(void *)&long long v151 = v35;
      Swift::Int v36 = *((void *)&v151 + 1);
      uint64_t v37 = *((void *)&v151 + 1) + 1;
      if (__OFADD__(1, *((void *)&v151 + 1))) {
        BUG();
      }
      ++*((void *)&v151 + 1);
      LOBYTE(v38) = (_BYTE)object;
      if (!object[2]) {
        goto LABEL_27;
      }
      currentFileIndex[0] = v36;
      swift_retain();
      swift_bridgeObjectRetain((_BYTE)object);
      uint64_t v39 = v155._object;
      swift_retain();
      unint64_t v40 = specialized __RawDictionaryStorage.find<A>(_:)(0x7461506567616D69, 0xE900000000000068);
      if ((v41 & 1) == 0) {
        break;
      }
      uint64_t v144 = v37;
      uint64_t v42 = *(void *)(object[7] + 8 * v40);
      swift_retain_n(v39);
      unint64_t v43 = v160;
      uint64_t v44 = CMLSequence.value(at:)(v42);
      if (v43)
      {
        swift_release();
        swift_unexpectedError(v43, "CreateML/MLDataTable.Row.swift", 30, 1, 85);
        BUG();
      }
      uint64_t v45 = v44;
      swift_release();
      MLDataValue.init(_:)(v45, *(double *)v29.i64);
      swift_bridgeObjectRelease((_BYTE)object);
      swift_release();
      swift_release_n(v39);
      int v46 = (void *)_._countAndFlagsBits;
      char v47 = _._object;
      uint64_t v38 = (uint64_t)object;
      if ((_BYTE)v157 != 2)
      {
        char v110 = (char)v157;
        goto LABEL_25;
      }
      if (!object[2])
      {
        char v110 = 2;
        goto LABEL_25;
      }
      v155._uint64_t countAndFlagsBits = _._countAndFlagsBits;
      uint64_t v160 = _._object;
      swift_retain();
      swift_bridgeObjectRetain((_BYTE)object);
      Swift::String v48 = v155._object;
      swift_retain();
      unint64_t v49 = specialized __RawDictionaryStorage.find<A>(_:)(0x6C6562616CLL, 0xE500000000000000);
      if ((v50 & 1) == 0)
      {
        swift_release();
        swift_bridgeObjectRelease((_BYTE)object);
        swift_release();
LABEL_24:
        char v110 = 2;
        int v46 = (void *)v155._countAndFlagsBits;
        char v47 = v160;
LABEL_25:
        outlined consume of MLDataValue(v46, v47, v110);
        goto LABEL_26;
      }
      uint64_t v51 = *(void *)(object[7] + 8 * v49);
      swift_retain_n(v48);
      uint64_t v52 = CMLSequence.value(at:)(v51);
      swift_release();
      MLDataValue.init(_:)(v52, *(double *)v29.i64);
      swift_bridgeObjectRelease(v38);
      swift_release();
      swift_release_n(v48);
      if ((_BYTE)v157 != 2)
      {
        outlined consume of MLDataValue((void *)_._countAndFlagsBits, _._object, (char)v157);
        goto LABEL_24;
      }
      uint64_t v145 = (void *)_._countAndFlagsBits;
      uint64_t v154 = _._object;
      uint64_t v146 = 0;
      uint64_t v153 = v38;
      uint64_t v53 = objc_opt_self(NSFileManager);
      id v54 = [v53 defaultManager];
      id v55 = v54;
      uint64_t v56 = (void *)v155._countAndFlagsBits;
      NSString v57 = String._bridgeToObjectiveC()();
      unsigned __int8 v58 = [v55 fileExistsAtPath:v57];

      if (!v58)
      {
        outlined consume of MLDataValue(v145, v154, 2);
        _._uint64_t countAndFlagsBits = 0;
        _._char object = (void *)0xE000000000000000;
        _StringGuts.grow(_:)(26);
        swift_bridgeObjectRelease(_._object);
        _._uint64_t countAndFlagsBits = 0xD000000000000018;
        _._char object = " clips, elapsed time: " + 0x8000000000000000;
        v122._uint64_t countAndFlagsBits = (uint64_t)v56;
        Swift::String v123 = v160;
        v122._char object = v160;
        String.append(_:)(v122);
        outlined consume of MLDataValue(v56, v123, 2);
        *(Swift::String *)currentFileIndex = _;
        v122._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v122._object, 0, 0);
        *(_OWORD *)uint64_t v124 = *(_OWORD *)currentFileIndex;
        *(_OWORD *)(v124 + 16) = 0;
        *(_OWORD *)(v124 + 32) = 0;
        *(unsigned char *)(v124 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v122._object, v124, v125, v126, v127);
        swift_release();
        char v120 = v153;
        goto LABEL_28;
      }
      uint64_t v59 = (uint64_t)v143;
      uint64_t v60 = v160;
      URL.init(fileURLWithPath:)(v56, v160);
      outlined consume of MLDataValue(v56, v60, 2);
      uint64_t v61 = URL.lastPathComponent.getter();
      uint64_t v63 = v62;
      uint64_t v64 = v146;
      Swift::String v65 = static _VideoUtilities.getHandKeyPointsFromImageUrl(url:)(v59);
      uint64_t v160 = v64;
      uint64_t v66 = (uint64_t)v158;
      if (v64)
      {
        outlined consume of MLDataValue(v145, v154, 2);
        swift_release();
        swift_bridgeObjectRelease(v153);
        swift_release();
        swift_bridgeObjectRelease(v63);
        (*(void (**)(unsigned char *, uint64_t))(v142 + 8))(v143, v141);
        outlined consume of Result<_DataTable, Error>(v149, v150);
        return outlined destroy of MLActivityClassifier.ModelParameters(v66, type metadata accessor for _TablePrinter);
      }
      if (__OFADD__(v131, currentFileIndex[0])) {
        BUG();
      }
      uint64_t v67 = (uint64_t)v65;
      uint64_t v68 = (uint64_t)v65[2];
      uint64_t v146 = specialized Array.init(repeating:count:)(v131 + currentFileIndex[0], v68);
      uint64_t v154 = specialized Array.init(repeating:count:)((uint64_t)v145, (uint64_t)v154, v68);
      v155._uint64_t countAndFlagsBits = (uint64_t)specialized Array.init(repeating:count:)(v61, v63, v68);
      swift_beginAccess(v138, &_, 33, 0);
      specialized Array.append<A>(contentsOf:)(v67);
      swift_endAccess(&_);
      swift_beginAccess(v139, &_, 33, 0);
      specialized Array.append<A>(contentsOf:)((uint64_t)v146);
      swift_endAccess(&_);
      swift_beginAccess(v140, &_, 33, 0);
      specialized Array.append<A>(contentsOf:)((uint64_t)v154);
      swift_endAccess(&_);
      swift_beginAccess(v152, &_, 33, 0);
      specialized Array.append<A>(contentsOf:)(v155._countAndFlagsBits);
      swift_endAccess(&_);
      _TablePrinter.printRow(currentFileIndex:)(currentFileIndex[0]);
      uint64_t v69 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
      uint64_t v70 = swift_allocObject(v69, 72, 7);
      *(void *)(v70 + 16) = 1;
      *(void *)(v70 + 24) = 2;
      *(double *)v29.i64 = Date.timeIntervalSinceNow.getter();
      __m128 v29 = _mm_xor_ps(v29, (__m128)xmmword_3474C0);
      *(void *)(v70 + 56) = &type metadata for Double;
      *(void *)(v70 + 64) = &protocol witness table for Double;
      _mm_storel_ps((double *)(v70 + 32), v29);
      currentFileIndex[0] = String.init(format:_:)(1714826789, 0xE400000000000000, v70);
      uint64_t v72 = v71;
      _._uint64_t countAndFlagsBits = 0;
      _._char object = (void *)0xE000000000000000;
      _StringGuts.grow(_:)(76);
      v73._uint64_t countAndFlagsBits = 0xD000000000000018;
      v73._char object = v133;
      String.append(_:)(v73);
      v137[0] = v144;
      uint64_t v74 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
      LOBYTE(v67) = (_BYTE)v75;
      v73._uint64_t countAndFlagsBits = v74;
      v73._char object = v75;
      String.append(_:)(v73);
      swift_bridgeObjectRelease(v67);
      v73._uint64_t countAndFlagsBits = 0x20666F2074756F20;
      v73._char object = (void *)0xE800000000000000;
      String.append(_:)(v73);
      v137[0] = *v158;
      uint64_t v76 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
      LOBYTE(v67) = (_BYTE)v77;
      v73._uint64_t countAndFlagsBits = v76;
      v73._char object = v77;
      String.append(_:)(v73);
      swift_bridgeObjectRelease(v67);
      v73._uint64_t countAndFlagsBits = 0xD000000000000026;
      v73._char object = v134;
      String.append(_:)(v73);
      v73._uint64_t countAndFlagsBits = currentFileIndex[0];
      v73._char object = v72;
      String.append(_:)(v73);
      v73._uint64_t countAndFlagsBits = (uint64_t)v72;
      swift_bridgeObjectRelease((_BYTE)v72);
      uint64_t v78 = _._countAndFlagsBits;
      int v79 = _._object;
      os_log_type_t v80 = static os_log_type_t.default.getter(v73._countAndFlagsBits);
      v73._uint64_t countAndFlagsBits = v78;
      v73._char object = v79;
      log(_:type:)(v73, v80);
      swift_release();
      swift_bridgeObjectRelease(v153);
      swift_release();
      swift_bridgeObjectRelease((_BYTE)v79);
      (*(void (**)(unsigned char *, uint64_t))(v142 + 8))(v143, v141);
      currentFileIndex[0] = v151;
      uint64_t v30 = v149;
      char v32 = v150;
      _._uint64_t countAndFlagsBits = v149;
      LOBYTE(_._object) = v150;
      Swift::Int v81 = MLDataTable.size.getter();
      uint64_t v31 = currentFileIndex[0];
      if (currentFileIndex[0] == v81) {
        goto LABEL_17;
      }
    }
    swift_release();
    swift_bridgeObjectRelease((_BYTE)object);
    swift_release();
LABEL_26:
    Swift::Int v36 = currentFileIndex[0];
LABEL_27:
    _._uint64_t countAndFlagsBits = 0;
    _._char object = (void *)0xE000000000000000;
    _StringGuts.grow(_:)(52);
    v111._uint64_t countAndFlagsBits = 0xD000000000000029;
    v111._char object = "Annotated images" + 0x8000000000000000;
    String.append(_:)(v111);
    v137[0] = v36;
    uint64_t v112 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char v113 = v38;
    char v115 = (char)v114;
    v111._uint64_t countAndFlagsBits = v112;
    v111._char object = v114;
    String.append(_:)(v111);
    swift_bridgeObjectRelease(v115);
    v111._char object = (void *)0xE900000000000065;
    v111._uint64_t countAndFlagsBits = 0x6C626174206E6920;
    String.append(_:)(v111);
    *(Swift::String *)currentFileIndex = _;
    v111._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v111._object, 0, 0);
    *(_OWORD *)uint64_t v116 = *(_OWORD *)currentFileIndex;
    *(_OWORD *)(v116 + 16) = 0;
    *(_OWORD *)(v116 + 32) = 0;
    *(unsigned char *)(v116 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v111._object, v116, v117, v118, v119);
    swift_release();
    char v120 = v113;
LABEL_28:
    swift_bridgeObjectRelease(v120);
    swift_release();
    outlined consume of Result<_DataTable, Error>(v149, v150);
    return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v158, type metadata accessor for _TablePrinter);
  }
  char v32 = v161;
LABEL_17:
  outlined consume of Result<_DataTable, Error>(v30, v32);
  static os_log_type_t.info.getter();
  uint64_t v82 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v83 = swift_allocObject(v82, 72, 7);
  *(void *)(v83 + 16) = 1;
  *(void *)(v83 + 24) = 2;
  *(void *)(v83 + 56) = &type metadata for Int;
  *(void *)(v83 + 64) = &protocol witness table for Int;
  *(void *)(v83 + 32) = 3;
  os_log(_:dso:log:type:_:)("event: %lu", 10);
  swift_bridgeObjectRelease(v83);
  uint64_t v84 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MLUntypedColumn)>);
  uint64_t inited = swift_initStackObject(v84, v128);
  *(void *)(inited + 16) = 4;
  *(void *)(inited + 24) = 8;
  *(void *)(inited + 32) = 0x6C6562616CLL;
  *(void *)(inited + 40) = 0xE500000000000000;
  uint64_t v86 = v140;
  swift_beginAccess(v140, &v149, 0, 0);
  _._uint64_t countAndFlagsBits = *v86;
  uint64_t v87 = alloca(24);
  uint64_t v88 = alloca(32);
  unint64_t v129 = &_;
  swift_bridgeObjectRetain(_._countAndFlagsBits);
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
  LOBYTE(v86) = v90;
  swift_bridgeObjectRelease(_._countAndFlagsBits);
  *(void *)(inited + 48) = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(inited + 56) = v86 & 1;
  *(void *)(inited + 64) = 0x5F6E6F6973736573;
  *(void *)(inited + 72) = 0xEA00000000006469;
  uint64_t v91 = v139;
  swift_beginAccess(v139, &_, 0, 0);
  v137[0] = *v91;
  uint64_t v92 = alloca(24);
  double v93 = alloca(32);
  unint64_t v129 = (Swift::String *)v137;
  swift_bridgeObjectRetain(v137[0]);
  uint64_t v94 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
  LOBYTE(v83) = v95;
  swift_bridgeObjectRelease(v137[0]);
  *(void *)(inited + 80) = v94;
  *(unsigned char *)(inited + 88) = v83 & 1;
  *(void *)(inited + 96) = 0x746E696F7079656BLL;
  *(void *)(inited + 104) = 0xE900000000000073;
  uint64_t v96 = v138;
  swift_beginAccess(v138, v137, 0, 0);
  v130[0] = *v96;
  uint64_t v97 = alloca(24);
  char v98 = alloca(32);
  unint64_t v129 = (Swift::String *)v130;
  swift_bridgeObjectRetain(v130[0]);
  uint64_t v99 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
  LOBYTE(v83) = v100;
  swift_bridgeObjectRelease(v130[0]);
  *(void *)(inited + 112) = v99;
  *(unsigned char *)(inited + 120) = v83 & 1;
  *(void *)(inited + 128) = 0x7461506567616D69;
  *(void *)(inited + 136) = 0xE900000000000068;
  uint64_t v101 = v152;
  swift_beginAccess(v152, v130, 0, 0);
  uint64_t v147 = *v101;
  uint64_t v102 = alloca(24);
  uint64_t v103 = alloca(32);
  unint64_t v129 = (Swift::String *)&v147;
  swift_bridgeObjectRetain(v147);
  uint64_t v104 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
  LOBYTE(v83) = v105;
  swift_bridgeObjectRelease(v147);
  *(void *)(inited + 144) = v104;
  *(unsigned char *)(inited + 152) = v83 & 1;
  uint64_t v106 = Dictionary.init(dictionaryLiteral:)(inited, &type metadata for String, &type metadata for MLUntypedColumn, &protocol witness table for String);
  uint64_t v107 = v160;
  specialized MLDataTable.init<A>(uniqueKeysWithValues:)(v106);
  if (!v107)
  {
    char v108 = v148;
    uint64_t v109 = v136;
    void *v136 = v147;
    *((unsigned char *)v109 + 8) = v108;
  }
  return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v158, type metadata accessor for _TablePrinter);
}

uint64_t type metadata accessor for MLHandPoseClassifier.FeatureExtractor()
{
  return objc_opt_self(_TtCV8CreateML20MLHandPoseClassifier16FeatureExtractor);
}

uint64_t static MLActivityClassifier.validateAndConvertParameters(_:featureColumns:labelColumn:recordingFileColumn:table:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4, void *a5, void *a6, __m128 a7, uint64_t *a8)
{
  char v10 = *((unsigned char *)a8 + 8);
  uint64_t v14 = *a8;
  char v15 = v10;
  MLActivityClassifier.ModelParameters.generateTables(trainingData:featureColumns:labelColumn:recordingFileColumn:)(&v16, &v18, (uint64_t)&v14, a2, a3, a4, a7, a5, a6);
  uint64_t result = v13;
  if (!v8)
  {
    uint64_t v20 = v16;
    uint64_t v12 = v18;
    int v22 = v19;
    int v21 = v17;
    static MLActivityClassifier.validateAndConvertParameters(parameters:featureColumns:trainingTable:validationTable:)(a1, a2, (uint64_t)&v16, (uint64_t)&v18);
    outlined consume of MLDataTable?(v12, v22);
    return outlined consume of Result<_DataTable, Error>(v20, v21);
  }
  return result;
}

uint64_t static MLActivityClassifier.validateAndConvertParameters(parameters:featureColumns:trainingTable:validationTable:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v7 = v4;
  uint64_t v48 = a2;
  uint64_t v47 = a1;
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                             - 8)
                 + 64);
  long long v9 = alloca(v8);
  char v10 = alloca(v8);
  uint64_t v44 = &v31;
  uint64_t v11 = *(void *)a3;
  LODWORD(a3) = *(_DWORD *)(a3 + 8);
  uint64_t v39 = *(void *)a4;
  LOBYTE(v46) = *(unsigned char *)(a4 + 8);
  uint64_t v38 = type metadata accessor for MLActivityClassifier.Configuration(0);
  uint64_t v12 = v7 + *(int *)(v38 + 44);
  *(void *)&long long v42 = v11;
  char v49 = a3 & 1;
  BYTE8(v42) = a3 & 1;
  swift_bridgeObjectRetain(v48);
  uint64_t v41 = v11;
  outlined copy of Result<_DataTable, Error>(v11, a3);
  DataFrame.init(_:)((uint64_t)&v42);
  uint64_t v13 = type metadata accessor for DataFrame(0);
  uint64_t v40 = v12;
  __swift_storeEnumTagSinglePayload(v12, 0, 1, v13);
  uint64_t v14 = v7 + *(int *)(v38 + 48);
  __swift_storeEnumTagSinglePayload(v14, 1, 1, v13);
  *(void *)uint64_t v7 = 10;
  *(void *)(v7 + 8) = 0;
  *(unsigned char *)(v7 + 16) = 0;
  *(void *)(v7 + 24) = 32;
  *(void *)(v7 + 32) = 100;
  *(void *)(v7 + 40) = v48;
  *(void *)(v7 + 48) = 0x6C6562616CLL;
  *(void *)(v7 + 56) = 0xE500000000000000;
  *(void *)(v7 + 64) = 0x5F6E6F6973736573;
  *(void *)(v7 + 72) = 0xEA00000000006469;
  char v15 = (int *)type metadata accessor for MLActivityClassifier.ModelParameters(0);
  uint64_t v16 = v47;
  uint64_t v17 = v15[6];
  if (!*(unsigned char *)(v47 + v17 + 8)) {
    *(void *)uint64_t v7 = *(void *)(v47 + v17);
  }
  uint64_t v18 = v15[7];
  if (!*(unsigned char *)(v16 + v18 + 8)) {
    *(void *)(v7 + 24) = *(void *)(v16 + v18);
  }
  uint64_t v19 = v15[8];
  if (!*(unsigned char *)(v16 + v19 + 8)) {
    *(void *)(v7 + 32) = *(void *)(v16 + v19);
  }
  uint64_t v45 = v13;
  if ((_BYTE)v46 == 0xFF)
  {
    uint64_t v46 = v14;
    uint64_t v36 = v41;
    char v37 = v49;
    long long v42 = 0;
    __int16 v43 = 256;
    MLDataTable.randomSplitBySequence(strategy:by:on:)(&v32, &v34, (uint64_t)&v42, 0x5F6E6F6973736573, (void *)0xEA00000000006469, 0x6C6562616CLL, (void *)0xE500000000000000);
    uint64_t v47 = v32;
    char v24 = v33;
    char v25 = v35;
    *(void *)&long long v42 = v34;
    BYTE8(v42) = v35 & 1;
    uint64_t v48 = v34;
    outlined copy of Result<_DataTable, Error>(v34, v35);
    uint64_t v26 = (uint64_t)v44;
    DataFrame.init(_:)((uint64_t)&v42);
    __swift_storeEnumTagSinglePayload(v26, 0, 1, v45);
    outlined assign with take of DataFrame?(v26, v40);
    if (v24 == -1) {
      return outlined consume of Result<_DataTable, Error>(v48, v25);
    }
    uint64_t v27 = v47;
    *(void *)&long long v42 = v47;
    char v28 = v24;
    BYTE8(v42) = v24 & 1;
    outlined copy of Result<_DataTable, Error>(v47, v24);
    uint64_t v29 = (uint64_t)v44;
    DataFrame.init(_:)((uint64_t)&v42);
    outlined consume of Result<_DataTable, Error>(v48, v25);
    outlined consume of MLDataTable?(v27, v28);
    __swift_storeEnumTagSinglePayload(v29, 0, 1, v45);
    uint64_t v22 = v29;
    uint64_t v23 = v46;
  }
  else
  {
    *(void *)&long long v42 = v39;
    BYTE8(v42) = v46 & 1;
    outlined copy of Result<_DataTable, Error>(v39, v46);
    uint64_t v20 = v14;
    uint64_t v21 = (uint64_t)v44;
    DataFrame.init(_:)((uint64_t)&v42);
    __swift_storeEnumTagSinglePayload(v21, 0, 1, v45);
    uint64_t v22 = v21;
    uint64_t v23 = v20;
  }
  return outlined assign with take of DataFrame?(v22, v23);
}

uint64_t MLActivityClassifier.write(to:metadata:)(uint64_t a1, uint64_t *a2, double a3, double a4)
{
  uint64_t v92 = v4;
  uint64_t v110 = v5;
  int64_t v6 = *(void *)(*(void *)(type metadata accessor for MLActivityClassifier.Model(0) - 8) + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v109 = &v83;
  long long v9 = alloca(v6);
  char v10 = alloca(v6);
  char v108 = &v83;
  uint64_t v11 = alloca(v6);
  uint64_t v12 = alloca(v6);
  uint64_t v107 = &v83;
  uint64_t v13 = type metadata accessor for URL(0);
  uint64_t v14 = *(void *)(v13 - 8);
  int64_t v15 = *(void *)(v14 + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v104 = *a2;
  char v95 = (double *)a2[1];
  unint64_t v103 = a2[2];
  uint64_t v94 = (char *)a2[3];
  uint64_t v102 = a2[4];
  uint64_t v100 = a2[5];
  uint64_t v98 = a2[6];
  uint64_t v99 = a2[7];
  uint64_t v101 = a2[8];
  uint64_t v97 = v13;
  uint64_t v96 = v14;
  (*(void (**)(double *, uint64_t))(v14 + 16))(&v83, a1);
  char v105 = &v83;
  char v18 = URL.hasDirectoryPath.getter();
  uint64_t v93 = a1;
  if (v18)
  {
    v19._uint64_t countAndFlagsBits = 0xD00000000000001CLL;
    v19._char object = "l, appending that to file name." + 0x8000000000000000;
    URL.appendPathComponent(_:)(v19);
    double v83 = 0.0;
    unint64_t v84 = 0xE000000000000000;
    _StringGuts.grow(_:)(69);
    a3 = v83;
    v19._char object = " be an empty string." + 0x8000000000000000;
    v19._uint64_t countAndFlagsBits = 0xD000000000000041;
    String.append(_:)(v19);
    v19._uint64_t countAndFlagsBits = 0xD00000000000001CLL;
    v19._char object = "l, appending that to file name." + 0x8000000000000000;
    String.append(_:)(v19);
    v19._char object = (void *)0xE200000000000000;
    v19._uint64_t countAndFlagsBits = 11815;
    String.append(_:)(v19);
    uint64_t v20 = *(void *)&v83;
    uint64_t v21 = (void *)v84;
    os_log_type_t v22 = static os_log_type_t.info.getter();
    v19._uint64_t countAndFlagsBits = v20;
    v19._char object = v21;
    log(_:type:)(v19, v22);
    swift_bridgeObjectRelease((_BYTE)v21);
  }
  uint64_t v23 = URL.pathExtension.getter();
  uint64_t v25 = v23;
  uint64_t v26 = v24;
  if (v23 == 0x67616B6361706C6DLL && v24 == 0xE900000000000065)
  {
    char v27 = 101;
LABEL_8:
    swift_bridgeObjectRelease(v27);
    outlined init with copy of MLActivityClassifier.Model(v110, (uint64_t)v107);
    uint64_t v28 = (uint64_t)v95;
    uint64_t v29 = v94;
    if (v95)
    {
      uint64_t v30 = v104;
      uint64_t v31 = v104;
      uint64_t v110 = (uint64_t)v95;
      uint64_t v32 = v103;
      uint64_t v106 = v103;
      uint64_t v33 = v102;
      uint64_t v34 = v102;
      uint64_t v35 = v100;
      uint64_t v109 = (double *)v100;
      uint64_t v36 = v98;
      uint64_t v37 = v98;
      uint64_t v38 = v99;
      unint64_t v39 = v99;
      uint64_t v40 = v101;
      char v108 = (double *)v101;
    }
    else
    {
      uint64_t v106 = 0xD000000000000033;
      uint64_t v41 = NSFullUserName();
      long long v42 = v41;
      uint64_t v31 = static String._unconditionallyBridgeFromObjectiveC(_:)(v42);
      uint64_t v110 = v43;

      uint64_t v28 = (uint64_t)v95;
      uint64_t v29 = "RandomForestRegressor" + 0x8000000000000000;
      uint64_t v37 = 49;
      unint64_t v39 = 0xE100000000000000;
      uint64_t v34 = 0;
      uint64_t v109 = 0;
      char v108 = 0;
      uint64_t v36 = v98;
      uint64_t v38 = v99;
      uint64_t v35 = v100;
      uint64_t v40 = v101;
      uint64_t v33 = v102;
      uint64_t v32 = v103;
      uint64_t v30 = v104;
    }
    double v83 = *(double *)&v31;
    unint64_t v84 = v110;
    unint64_t v85 = v106;
    uint64_t v86 = v29;
    uint64_t v87 = v34;
    uint64_t v88 = (uint64_t)v109;
    uint64_t v89 = v37;
    uint64_t v90 = v39;
    uint64_t v91 = (uint64_t)v108;
    outlined copy of MLModelMetadata?(v30, v28, v32, (uint64_t)v94, v33, v35, v36, v38, v40);
    uint64_t v44 = (uint64_t)v107;
    MLActivityClassifier.Model.writeMLPackage(to:metadata:)(v93, (uint64_t)&v83, a3, a4);
    swift_bridgeObjectRelease(v39);
    swift_bridgeObjectRelease((_BYTE)v29);
    swift_bridgeObjectRelease(v110);
    swift_bridgeObjectRelease((_BYTE)v109);
    char v45 = (char)v108;
    goto LABEL_12;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0x67616B6361706C6DLL, 0xE900000000000065, v23, v24, 0))
  {
    char v27 = v26;
    goto LABEL_8;
  }
  if (v25 == 0x6C65646F6D6C6DLL && v26 == 0xE700000000000000)
  {
    swift_bridgeObjectRelease(0);
LABEL_17:
    outlined init with copy of MLActivityClassifier.Model(v110, (uint64_t)v108);
    if (v95)
    {
      uint64_t v48 = v104;
      uint64_t v49 = v104;
      uint64_t v107 = v95;
      uint64_t v50 = v103;
      uint64_t v106 = v103;
      uint64_t v51 = (uint64_t)v94;
      uint64_t v52 = v94;
      uint64_t v53 = v102;
      uint64_t v54 = v102;
      uint64_t v55 = v100;
      uint64_t v109 = (double *)v100;
      uint64_t v56 = v98;
      uint64_t v57 = v98;
      uint64_t v58 = v99;
      unint64_t v59 = v99;
      uint64_t v60 = v101;
      uint64_t v110 = v101;
    }
    else
    {
      uint64_t v106 = 0xD000000000000033;
      uint64_t v61 = NSFullUserName();
      uint64_t v62 = v61;
      uint64_t v49 = static String._unconditionallyBridgeFromObjectiveC(_:)(v62);
      uint64_t v107 = (double *)v63;

      uint64_t v52 = "RandomForestRegressor" + 0x8000000000000000;
      uint64_t v57 = 49;
      unint64_t v59 = 0xE100000000000000;
      uint64_t v54 = 0;
      uint64_t v109 = 0;
      uint64_t v110 = 0;
      uint64_t v56 = v98;
      uint64_t v58 = v99;
      uint64_t v55 = v100;
      uint64_t v60 = v101;
      uint64_t v53 = v102;
      uint64_t v51 = (uint64_t)v94;
      uint64_t v50 = v103;
      uint64_t v48 = v104;
    }
    double v83 = *(double *)&v49;
    unint64_t v84 = (unint64_t)v107;
    unint64_t v85 = v106;
    uint64_t v86 = v52;
    uint64_t v87 = v54;
    uint64_t v88 = (uint64_t)v109;
    uint64_t v89 = v57;
    uint64_t v90 = v59;
    uint64_t v91 = v110;
    outlined copy of MLModelMetadata?(v48, (uint64_t)v95, v50, v51, v53, v55, v56, v58, v60);
    uint64_t v44 = (uint64_t)v108;
    MLActivityClassifier.Model.writeMLModel(to:metadata:)(v93, (uint64_t)&v83);
    swift_bridgeObjectRelease(v59);
    swift_bridgeObjectRelease((_BYTE)v52);
    swift_bridgeObjectRelease((_BYTE)v107);
    swift_bridgeObjectRelease((_BYTE)v109);
    char v45 = v110;
    goto LABEL_12;
  }
  char v47 = _stringCompareWithSmolCheck(_:_:expecting:)(0x6C65646F6D6C6DLL, 0xE700000000000000, v25, v26, 0);
  swift_bridgeObjectRelease(v26);
  if (v47) {
    goto LABEL_17;
  }
  os_log_type_t v64 = static os_log_type_t.info.getter();
  v65._uint64_t countAndFlagsBits = 0xD00000000000004FLL;
  v65._char object = "Image does not exist at " + 0x8000000000000000;
  log(_:type:)(v65, v64);
  v65._uint64_t countAndFlagsBits = 0x67616B6361706C6DLL;
  v65._char object = (void *)0xE900000000000065;
  URL.appendPathExtension(_:)(v65);
  outlined init with copy of MLActivityClassifier.Model(v110, (uint64_t)v109);
  if (v95)
  {
    uint64_t v66 = v104;
    uint64_t v67 = v104;
    uint64_t v107 = v95;
    uint64_t v68 = v103;
    unint64_t v69 = v103;
    uint64_t v70 = (uint64_t)v94;
    uint64_t v71 = v94;
    uint64_t v72 = v102;
    uint64_t v73 = v102;
    uint64_t v74 = v100;
    uint64_t v110 = v100;
    uint64_t v75 = v98;
    uint64_t v106 = v98;
    uint64_t v76 = v99;
    char v108 = (double *)v99;
    uint64_t v77 = v101;
    uint64_t v78 = v101;
  }
  else
  {
    int v79 = NSFullUserName();
    os_log_type_t v80 = v79;
    uint64_t v67 = static String._unconditionallyBridgeFromObjectiveC(_:)(v80);
    uint64_t v107 = (double *)v81;

    uint64_t v71 = "RandomForestRegressor" + 0x8000000000000000;
    uint64_t v106 = 49;
    char v108 = (double *)0xE100000000000000;
    uint64_t v73 = 0;
    uint64_t v110 = 0;
    uint64_t v78 = 0;
    uint64_t v75 = v98;
    uint64_t v76 = v99;
    uint64_t v74 = v100;
    uint64_t v77 = v101;
    uint64_t v72 = v102;
    uint64_t v70 = (uint64_t)v94;
    uint64_t v68 = v103;
    uint64_t v66 = v104;
    unint64_t v69 = 0xD000000000000033;
  }
  double v83 = *(double *)&v67;
  unint64_t v84 = (unint64_t)v107;
  unint64_t v85 = v69;
  uint64_t v86 = v71;
  uint64_t v87 = v73;
  uint64_t v88 = v110;
  uint64_t v89 = v106;
  uint64_t v90 = (uint64_t)v108;
  char v82 = v78;
  uint64_t v91 = v78;
  outlined copy of MLModelMetadata?(v66, (uint64_t)v95, v68, v70, v72, v74, v75, v76, v77);
  uint64_t v44 = (uint64_t)v109;
  MLActivityClassifier.Model.writeMLPackage(to:metadata:)(v93, (uint64_t)&v83, a3, a4);
  swift_bridgeObjectRelease((_BYTE)v108);
  swift_bridgeObjectRelease((_BYTE)v71);
  swift_bridgeObjectRelease((_BYTE)v107);
  swift_bridgeObjectRelease(v110);
  char v45 = v82;
LABEL_12:
  swift_bridgeObjectRelease(v45);
  outlined destroy of MLActivityClassifier.Model(v44);
  return (*(uint64_t (**)(double *, uint64_t))(v96 + 8))(v105, v97);
}

uint64_t outlined init with copy of MLActivityClassifier.Model(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLActivityClassifier.Model(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined destroy of MLActivityClassifier.Model(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLActivityClassifier.Model(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t MLActivityClassifier.write(toFile:metadata:)(uint64_t a1, uint64_t a2, uint64_t a3, double a4, double a5)
{
  uint64_t v15 = v5;
  uint64_t v16 = a2;
  uint64_t v17 = type metadata accessor for URL(0);
  uint64_t v18 = *(void *)(v17 - 8);
  int64_t v7 = *(void *)(v18 + 64);
  int64_t v8 = alloca(v7);
  long long v9 = alloca(v7);
  uint64_t v10 = *(void *)(a3 + 64);
  URL.init(fileURLWithPath:)(a1, a2);
  v12[0] = *(_OWORD *)a3;
  v12[1] = *(_OWORD *)(a3 + 16);
  _OWORD v12[2] = *(_OWORD *)(a3 + 32);
  long long v13 = *(_OWORD *)(a3 + 48);
  uint64_t v14 = v10;
  MLActivityClassifier.write(to:metadata:)((uint64_t)v12, (uint64_t *)v12, *(double *)&v13, a5);
  return (*(uint64_t (**)(_OWORD *, uint64_t))(v18 + 8))(v12, v17);
}

void *_sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVy11TabularData6ColumnVySSGAKG_SS4text_SS5labelts5NeverOTg5043_sSSSgAAS2SIgggoo_AA_AAtSS4text_SS5labelts5k106OIegnrzr_TR143_s8CreateML16MLTextClassifierV10evaluation2on10textColumn05labelH0AA19MLClassifierMetricsV11f31Data0M5FrameV_S2StFSS0G0_SS0I0tM19_AOtXEfU_Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v81 = *(void **)(v1 - 8);
  int64_t v2 = v81[8];
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  unint64_t v84 = &v73;
  uint64_t v90 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>);
  int64_t v5 = *(void *)(*(void *)(v90 - 8) + 64);
  int64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v89 = &v73;
  uint64_t v85 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>.Iterator);
  int64_t v8 = *(void *)(*(void *)(v85 - 8) + 64);
  long long v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  double v83 = &v73;
  uint64_t v11 = lazy protocol witness table accessor for type Column<String> and conformance Column<A>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v78 = v1;
  uint64_t v86 = (char *)v11;
  uint64_t v88 = dispatch thunk of Sequence.underestimatedCount.getter(v1, v11);
  uint64_t v12 = dispatch thunk of Sequence.underestimatedCount.getter(v1, v11);
  uint64_t v13 = v88;
  if (v12 < v88) {
    uint64_t v13 = v12;
  }
  uint64_t v88 = v13;
  uint64_t v87 = _swiftEmptyArrayStorage;
  int64_t v14 = 0;
  if (v13 > 0) {
    int64_t v14 = v13;
  }
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v14, 0);
  uint64_t v15 = (uint64_t)v89;
  outlined init with copy of Zip2Sequence<Column<String>, Column<String>>(a1, (uint64_t)v89);
  uint64_t v16 = (void (*)(unint64_t *, uint64_t, uint64_t))v81[4];
  uint64_t v17 = v78;
  v16(v84, v15, v78);
  uint64_t v18 = v83;
  dispatch thunk of Sequence.makeIterator()(v17, v86);
  v16(v84, (uint64_t)v89 + *(int *)(v90 + 52), v17);
  uint64_t v19 = v17;
  uint64_t v20 = v85;
  uint64_t v21 = v18;
  int v79 = (char *)v18 + *(int *)(v85 + 52);
  uint64_t v22 = v88;
  dispatch thunk of Sequence.makeIterator()(v19, v86);
  uint64_t v80 = *(int *)(v20 + 56);
  *((unsigned char *)v21 + v80) = 0;
  if (v22 < 0) {
    BUG();
  }
  uint64_t v23 = (uint64_t)v83;
  if (!v22) {
    goto LABEL_24;
  }
  uint64_t v24 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<Column<String>>)
               + 36);
  uint64_t v25 = (uint64_t *)(v24 + v23);
  uint64_t v86 = &v79[v24];
  uint64_t v74 = (uint64_t *)(v24 + v23);
  do
  {
    BOOL v26 = v22 == 0;
    uint64_t v27 = v22 - 1;
    if (v26) {
      BUG();
    }
    if (*(unsigned char *)(v23 + v80)) {
      BUG();
    }
    uint64_t v88 = v27;
    uint64_t v89 = (void *)*v25;
    uint64_t v28 = lazy protocol witness table accessor for type Column<String> and conformance Column<A>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v29 = v23;
    uint64_t v30 = v78;
    uint64_t v90 = v28;
    dispatch thunk of Collection.endIndex.getter(v78, v28);
    if (v89 == (void *)v75[0]) {
      BUG();
    }
    uint64_t v31 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v75, v25, v30, v90);
    uint64_t v89 = (void *)*v32;
    uint64_t v85 = v32[1];
    swift_bridgeObjectRetain(v85);
    v31(v75, 0);
    uint64_t v33 = v84;
    uint64_t v76 = (void (*)(unint64_t *, uint64_t, uint64_t))v81[2];
    v76(v84, v29, v30);
    uint64_t v34 = v25;
    uint64_t v35 = v90;
    dispatch thunk of Collection.formIndex(after:)(v34, v30, v90);
    uint64_t v77 = (void (*)(unint64_t *, uint64_t))v81[1];
    v77(v33, v30);
    uint64_t v36 = v86;
    char v82 = *(void (**)(unint64_t *, uint64_t))v86;
    uint64_t v37 = v79;
    dispatch thunk of Collection.endIndex.getter(v30, v35);
    if (v82 == (void (*)(unint64_t *, uint64_t))v75[0])
    {
      swift_bridgeObjectRelease(v85);
      BUG();
    }
    unint64_t v39 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v75, v36, v30, v90);
    uint64_t v40 = v38[1];
    uint64_t v41 = v40;
    unint64_t v42 = 0xE000000000000000;
    if (v40)
    {
      uint64_t v41 = *v38;
      unint64_t v42 = (unint64_t)v38[1];
    }
    unint64_t v73 = v42;
    char v82 = v41;
    swift_bridgeObjectRetain((_BYTE)v40);
    v39(v75, 0);
    uint64_t v43 = v84;
    v76(v84, (uint64_t)v37, v30);
    dispatch thunk of Collection.formIndex(after:)(v86, v30, v90);
    v77(v43, v30);
    unint64_t v44 = v85;
    uint64_t v45 = (uint64_t)v89;
    if (!v85) {
      uint64_t v45 = 0;
    }
    uint64_t v89 = (void *)v45;
    if (!v85) {
      unint64_t v44 = 0xE000000000000000;
    }
    uint64_t v46 = v87;
    if (!swift_isUniquelyReferenced_nonNull_native(v87))
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v46[2] + 1, 1);
      uint64_t v46 = v87;
    }
    unint64_t v47 = v46[2];
    if (v46[3] >> 1 <= v47)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v46[3] >= 2uLL, v47 + 1, 1);
      uint64_t v46 = v87;
    }
    void v46[2] = v47 + 1;
    uint64_t v48 = 4 * v47;
    v46[v48 + 4] = v89;
    v46[v48 + 5] = v44;
    v46[v48 + 6] = v82;
    v46[v48 + 7] = v73;
    uint64_t v22 = v88;
    uint64_t v23 = (uint64_t)v83;
    uint64_t v25 = v74;
  }
  while (v88);
  if (!*((unsigned char *)v83 + v80))
  {
LABEL_24:
    uint64_t v90 = lazy protocol witness table accessor for type Column<String> and conformance Column<A>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, (uint64_t)&protocol conformance descriptor for Column<A>);
    while (1)
    {
      uint64_t v88 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<Column<String>>);
      uint64_t v49 = *(int *)(v88 + 36);
      uint64_t v50 = *(void *)(v23 + v49);
      uint64_t v51 = v78;
      dispatch thunk of Collection.endIndex.getter(v78, v90);
      if (v50 == v75[0]) {
        break;
      }
      uint64_t v52 = v23 + v49;
      uint64_t v53 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v75, v52, v51, v90);
      uint64_t v89 = (void *)*v54;
      uint64_t v86 = (char *)v54[1];
      swift_bridgeObjectRetain((_BYTE)v86);
      v53(v75, 0);
      uint64_t v55 = v84;
      uint64_t v85 = v81[2];
      ((void (*)(unint64_t *, uint64_t, uint64_t))v85)(v84, v23, v51);
      uint64_t v56 = v52;
      uint64_t v57 = v90;
      dispatch thunk of Collection.formIndex(after:)(v56, v51, v90);
      char v82 = (void (*)(unint64_t *, uint64_t))v81[1];
      v82(v55, v51);
      uint64_t v58 = *(int *)(v88 + 36);
      unint64_t v59 = v79;
      uint64_t v88 = *(void *)&v79[v58];
      dispatch thunk of Collection.endIndex.getter(v51, v57);
      if (v88 == v75[0])
      {
        swift_bridgeObjectRelease((_BYTE)v86);
        uint64_t v23 = (uint64_t)v83;
        break;
      }
      uint64_t v60 = &v59[v58];
      uint64_t v77 = (void (*)(unint64_t *, uint64_t))dispatch thunk of Collection.subscript.read(v75, v60, v51, v90);
      uint64_t v62 = v61[1];
      uint64_t v63 = v62;
      unint64_t v64 = 0xE000000000000000;
      Swift::String v65 = v59;
      if (v62)
      {
        uint64_t v63 = *v61;
        unint64_t v64 = v61[1];
      }
      uint64_t v76 = (void (*)(unint64_t *, uint64_t, uint64_t))v64;
      uint64_t v88 = v63;
      swift_bridgeObjectRetain(v62);
      v77(v75, 0);
      uint64_t v66 = v84;
      ((void (*)(unint64_t *, char *, uint64_t))v85)(v84, v65, v51);
      dispatch thunk of Collection.formIndex(after:)(v60, v51, v90);
      v82(v66, v51);
      unint64_t v67 = (unint64_t)v86;
      uint64_t v68 = (uint64_t)v89;
      if (!v86) {
        uint64_t v68 = 0;
      }
      uint64_t v89 = (void *)v68;
      if (!v86) {
        unint64_t v67 = 0xE000000000000000;
      }
      unint64_t v69 = v87;
      if (!swift_isUniquelyReferenced_nonNull_native(v87))
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v69[2] + 1, 1);
        unint64_t v69 = v87;
      }
      unint64_t v70 = v69[2];
      if (v69[3] >> 1 <= v70)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v69[3] >= 2uLL, v70 + 1, 1);
        unint64_t v69 = v87;
      }
      v69[2] = v70 + 1;
      uint64_t v71 = 4 * v70;
      v69[v71 + 4] = v89;
      v69[v71 + 5] = v67;
      v69[v71 + 6] = v88;
      v69[v71 + 7] = v76;
      uint64_t v23 = (uint64_t)v83;
      if (*((unsigned char *)v83 + v80)) {
        goto LABEL_41;
      }
    }
    *(unsigned char *)(v23 + v80) = 1;
  }
LABEL_41:
  outlined destroy of Zip2Sequence<Column<String>, Column<String>>(v23, &demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>.Iterator);
  return v87;
}

uint64_t MLTextClassifier.evaluation(on:)(uint64_t a1, double a2)
{
  uint64_t v3 = static _TextUtilities.getTextLabeledDictionary(from:)(a1, a2);
  char v4 = (char)v3;
  int64_t v5 = unpackLabeledTexts(_:)((uint64_t)v3);
  char v6 = (char)v5;
  specialized static MLTextClassifier.evaluation<A>(on:using:)((uint64_t)v5, *v2);
  swift_bridgeObjectRelease(v4);
  return swift_bridgeObjectRelease(v6);
}

uint64_t MLTextClassifier.evaluation(on:)(uint64_t a1)
{
  int64_t v2 = unpackLabeledTexts(_:)(a1);
  char v3 = (char)v2;
  specialized static MLTextClassifier.evaluation<A>(on:using:)((uint64_t)v2, *v1);
  return swift_bridgeObjectRelease(v3);
}

uint64_t MLTextClassifier.evaluation(on:textColumn:labelColumn:)(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, void *a5)
{
  uint64_t v36 = v6;
  Swift::String _ = a5;
  v45._uint64_t countAndFlagsBits = a4;
  uint64_t v43 = v5;
  uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>);
  int64_t v8 = *(void *)(*(void *)(v40 - 8) + 64);
  long long v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  unint64_t v39 = v35;
  uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v38 = *(void *)(v37 - 8);
  int64_t v11 = *(void *)(v38 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v46 = v35;
  int64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  v45._char object = v35;
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any.Type>);
  uint64_t v17 = (void *)swift_allocObject(v16, 40, 7);
  char v18 = (char)v17;
  long long v17[2] = 1;
  v17[3] = 2;
  _OWORD v17[4] = &type metadata for String;
  uint64_t v42 = a2;
  v19._uint64_t countAndFlagsBits = a2;
  uint64_t v41 = a3;
  v19._char object = a3;
  DataFrame.validateColumnTypes(_:_:context:)(v19, (Swift::OpaquePointer)v17, (Swift::String)__PAIR128__(0xE400000000000000, 1954047316));
  swift_bridgeObjectRelease(v18);
  if (v20) {
    goto LABEL_3;
  }
  uint64_t v21 = (void *)swift_allocObject(v16, 40, 7);
  char v22 = (char)v21;
  Swift::Int v21[2] = 1;
  v21[3] = 2;
  v21[4] = &type metadata for String;
  v23._uint64_t countAndFlagsBits = v45._countAndFlagsBits;
  v23._char object = _;
  DataFrame.validateColumnTypes(_:_:context:)(v23, (Swift::OpaquePointer)v21, (Swift::String)__PAIR128__(0xE500000000000000, 0x6C6562614CLL));
  swift_bridgeObjectRelease(v22);
  if (v20)
  {
LABEL_3:
    uint64_t v24 = v43;
    *uint64_t v43 = v20;
    uint64_t v25 = type metadata accessor for MLClassifierMetrics.Contents(0);
    return swift_storeEnumTagMultiPayload(v24, v25, 2);
  }
  else
  {
    char object = v45._object;
    DataFrame.subscript.getter(v42, v41, &type metadata for String);
    DataFrame.subscript.getter(v45._countAndFlagsBits, _, &type metadata for String);
    uint64_t v28 = v38;
    uint64_t v29 = *(void (**)(unsigned char *, void *, uint64_t))(v38 + 16);
    uint64_t v30 = (uint64_t)v39;
    uint64_t v31 = object;
    uint64_t v32 = v37;
    v29(v39, v31, v37);
    v29((unsigned char *)(v30 + *(int *)(v40 + 52)), v46, v32);
    ML16MLTextClassifierV10evaluation2on10textColumn05labelH0AA19MLClassifierMetricsV11f31Data0M5FrameV_S2StFSS0G0_SS0I0tM19_AOtXEfU_Tf3nnnpf_nTf1cn_n = _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVy11TabularData6ColumnVySSGAKG_SS4text_SS5labelts5NeverOTg5043_sSSSgAAS2SIgggoo_AA_AAtSS4text_SS5labelts5k106OIegnrzr_TR143_s8CreateML16MLTextClassifierV10evaluation2on10textColumn05labelH0AA19MLClassifierMetricsV11f31Data0M5FrameV_S2StFSS0G0_SS0I0tM19_AOtXEfU_Tf3nnnpf_nTf1cn_n(v30);
    outlined destroy of Zip2Sequence<Column<String>, Column<String>>(v30, &demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>);
    specialized static MLTextClassifier.evaluation<A>(on:using:)((uint64_t)ML16MLTextClassifierV10evaluation2on10textColumn05labelH0AA19MLClassifierMetricsV11f31Data0M5FrameV_S2StFSS0G0_SS0I0tM19_AOtXEfU_Tf3nnnpf_nTf1cn_n, *v36);
    uint64_t v34 = *(void (**)(unsigned char *, uint64_t))(v28 + 8);
    v34(v46, v32);
    v34((unsigned char *)v45._object, v32);
    return swift_bridgeObjectRelease((_BYTE)ML16MLTextClassifierV10evaluation2on10textColumn05labelH0AA19MLClassifierMetricsV11f31Data0M5FrameV_S2StFSS0G0_SS0I0tM19_AOtXEfU_Tf3nnnpf_nTf1cn_n);
  }
}

{
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  int64_t v8;
  void *v9;
  void *v10;
  char v11;
  uint64_t v13;
  char v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  void *v18;
  uint64_t v19;

  uint64_t v15 = v5;
  uint64_t v16 = a5;
  uint64_t v17 = a4;
  char v18 = a3;
  Swift::String v19 = a2;
  char v6 = type metadata accessor for DataFrame(0);
  int64_t v7 = *(void *)(v6 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  long long v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  int64_t v11 = *(unsigned char *)(a1 + 8);
  uint64_t v13 = *(void *)a1;
  int64_t v14 = v11;
  outlined copy of Result<_DataTable, Error>(v13, v11);
  DataFrame.init(_:)((uint64_t)&v13);
  MLTextClassifier.evaluation(on:textColumn:labelColumn:)((uint64_t)&v13, v19, v18, v17, v16);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v7 + 8))(&v13, v6);
}

uint64_t outlined init with copy of Zip2Sequence<Column<String>, Column<String>>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined destroy of Zip2Sequence<Column<String>, Column<String>>(uint64_t a1, uint64_t *a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(a2);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

void *initializeBufferWithCopyOfBuffer for MLSupportVectorClassifier.Classifier(void *a1, uint64_t *a2, uint64_t a3)
{
  char v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v9 = *a2;
    void *v3 = *a2;
    char v3 = (void *)(v9 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    *a1 = *a2;
    uint64_t v6 = a2[1];
    v3[1] = v6;
    uint64_t v7 = a2[2];
    v3[2] = v7;
    v3[3] = a2[3];
    uint64_t v21 = v3 + 4;
    char v22 = (long long *)(a2 + 4);
    uint64_t v8 = a2[7];
    swift_bridgeObjectRetain(v6);
    swift_bridgeObjectRetain(v7);
    if (v8)
    {
      v3[7] = v8;
      (**(void (***)(_OWORD *, long long *, uint64_t))(v8 - 8))(v21, v22, v8);
    }
    else
    {
      long long v10 = *v22;
      *((_OWORD *)v3 + 3) = *((_OWORD *)a2 + 3);
      *uint64_t v21 = v10;
    }
    *((_OWORD *)v3 + 4) = *((_OWORD *)a2 + 4);
    *((unsigned char *)v3 + 80) = *((unsigned char *)a2 + 80);
    uint64_t v11 = *(int *)(a3 + 28);
    uint64_t v12 = (char *)v3 + v11;
    uint64_t v13 = (uint64_t)a2 + v11;
    uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    if (swift_getEnumCaseMultiPayload(v13, v14) == 1)
    {
      uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>);
      (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v15 - 8) + 16))(v12, v13, v15);
      uint64_t v16 = 1;
      uint64_t v17 = v12;
      uint64_t v18 = v14;
    }
    else
    {
      uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>);
      (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v19 - 8) + 16))(v12, v13, v19);
      uint64_t v17 = v12;
      uint64_t v18 = v14;
      uint64_t v16 = 0;
    }
    swift_storeEnumTagMultiPayload(v17, v18, v16);
  }
  return v3;
}

uint64_t destroy for MLSupportVectorClassifier.Classifier(void *a1, uint64_t a2)
{
  swift_bridgeObjectRelease(a1[1]);
  swift_bridgeObjectRelease(a1[2]);
  if (a1[7]) {
    __swift_destroy_boxed_opaque_existential_1Tm(a1 + 4);
  }
  uint64_t v2 = (char *)a1 + *(int *)(a2 + 28);
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  int v4 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>;
  if (swift_getEnumCaseMultiPayload(v2, v3) == 1) {
    int v4 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>;
  }
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(v4);
  return (*(uint64_t (**)(char *, uint64_t))(*(void *)(v5 - 8) + 8))(v2, v5);
}

uint64_t initializeWithCopy for MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v4 = *(void *)(a2 + 8);
  *(void *)(a1 + 8) = v4;
  uint64_t v5 = *(void *)(a2 + 16);
  *(void *)(a1 + 16) = v5;
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  uint64_t v18 = (_OWORD *)(a1 + 32);
  uint64_t v6 = *(void *)(a2 + 56);
  swift_bridgeObjectRetain(v4);
  swift_bridgeObjectRetain(v5);
  if (v6)
  {
    *(void *)(a1 + 56) = v6;
    (**(void (***)(_OWORD *, uint64_t, uint64_t))(v6 - 8))(v18, a2 + 32, v6);
  }
  else
  {
    long long v7 = *(_OWORD *)(a2 + 32);
    *(_OWORD *)(a1 + 48) = *(_OWORD *)(a2 + 48);
    *uint64_t v18 = v7;
  }
  *(_OWORD *)(a1 + 64) = *(_OWORD *)(a2 + 64);
  *(unsigned char *)(a1 + 80) = *(unsigned char *)(a2 + 80);
  uint64_t v8 = *(int *)(a3 + 28);
  uint64_t v9 = a1 + v8;
  uint64_t v10 = v8 + a2;
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v10, v11);
  BOOL v13 = EnumCaseMultiPayload == 1;
  uint64_t v14 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>;
  if (EnumCaseMultiPayload == 1) {
    uint64_t v14 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>;
  }
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(v14);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v15 - 8) + 16))(v9, v10, v15);
  swift_storeEnumTagMultiPayload(v9, v11, v13);
  return a1;
}

uint64_t assignWithCopy for MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v5 = *(void *)(a2 + 8);
  uint64_t v6 = *(void *)(a1 + 8);
  *(void *)(a1 + 8) = v5;
  swift_bridgeObjectRetain(v5);
  swift_bridgeObjectRelease(v6);
  uint64_t v7 = *(void *)(a2 + 16);
  uint64_t v8 = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = v7;
  swift_bridgeObjectRetain(v7);
  swift_bridgeObjectRelease(v8);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  uint64_t v9 = *(void *)(a2 + 56);
  if (*(void *)(a1 + 56))
  {
    if (v9)
    {
      __swift_assign_boxed_opaque_existential_0((uint64_t *)(a1 + 32), (uint64_t *)(a2 + 32));
      goto LABEL_8;
    }
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 32));
  }
  else if (v9)
  {
    *(void *)(a1 + 56) = v9;
    (**(void (***)(uint64_t, uint64_t))(v9 - 8))(a1 + 32, a2 + 32);
    goto LABEL_8;
  }
  long long v10 = *(_OWORD *)(a2 + 32);
  *(_OWORD *)(a1 + 48) = *(_OWORD *)(a2 + 48);
  *(_OWORD *)(a1 + 32) = v10;
LABEL_8:
  *(void *)(a1 + 64) = *(void *)(a2 + 64);
  *(void *)(a1 + 72) = *(void *)(a2 + 72);
  *(unsigned char *)(a1 + 80) = *(unsigned char *)(a2 + 80);
  if (a1 != a2)
  {
    uint64_t v11 = *(int *)(a3 + 28);
    uint64_t v12 = v11 + a2;
    uint64_t v13 = a1 + v11;
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v13, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v12, v14);
    BOOL v16 = EnumCaseMultiPayload == 1;
    uint64_t v17 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>;
    if (EnumCaseMultiPayload == 1) {
      uint64_t v17 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>;
    }
    uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(v17);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v18 - 8) + 16))(v13, v12, v18);
    swift_storeEnumTagMultiPayload(v13, v14, v16);
  }
  return a1;
}

uint64_t initializeWithTake for MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  long long v4 = *(_OWORD *)(a2 + 24);
  long long v5 = *(_OWORD *)(a2 + 40);
  long long v6 = *(_OWORD *)(a2 + 56);
  *(_OWORD *)(a1 + 65) = *(_OWORD *)(a2 + 65);
  *(_OWORD *)(a1 + 56) = v6;
  *(_OWORD *)(a1 + 40) = v5;
  *(_OWORD *)(a1 + 24) = v4;
  uint64_t v7 = *(int *)(a3 + 28);
  uint64_t v8 = a1 + v7;
  uint64_t v9 = v7 + a2;
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v9, v10);
  BOOL v12 = EnumCaseMultiPayload == 1;
  uint64_t v13 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>;
  if (EnumCaseMultiPayload == 1) {
    uint64_t v13 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>;
  }
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(v13);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v14 - 8) + 32))(v8, v9, v14);
  swift_storeEnumTagMultiPayload(v8, v10, v12);
  return a1;
}

uint64_t assignWithTake for MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v5 = *(void *)(a1 + 8);
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  swift_bridgeObjectRelease(v6);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  if (*(void *)(a1 + 56)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 32));
  }
  long long v7 = *(_OWORD *)(a2 + 32);
  *(_OWORD *)(a1 + 48) = *(_OWORD *)(a2 + 48);
  *(_OWORD *)(a1 + 32) = v7;
  *(_OWORD *)(a1 + 64) = *(_OWORD *)(a2 + 64);
  *(unsigned char *)(a1 + 80) = *(unsigned char *)(a2 + 80);
  if (a1 != a2)
  {
    uint64_t v8 = *(int *)(a3 + 28);
    uint64_t v9 = v8 + a2;
    uint64_t v10 = a1 + v8;
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v9, v11);
    BOOL v13 = EnumCaseMultiPayload == 1;
    uint64_t v14 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>;
    if (EnumCaseMultiPayload == 1) {
      uint64_t v14 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>;
    }
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(v14);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v15 - 8) + 32))(v10, v9, v15);
    swift_storeEnumTagMultiPayload(v10, v11, v13);
  }
  return a1;
}

uint64_t getEnumTagSinglePayload for MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_2B0C13);
}

uint64_t sub_2B0C13(uint64_t a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t result = 0;
    if ((*(void *)(a1 + 8) & 0xFFFFFFFF00000001) == 0) {
      return (*(void *)(a1 + 8) >> 1) + 1;
    }
  }
  else
  {
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    return __swift_getEnumTagSinglePayload(*(int *)(a3 + 28) + a1, a2, v5);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_2B0CA0);
}

uint64_t sub_2B0CA0(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(a1 + 8) = 2 * (a2 - 1);
  }
  else
  {
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    return __swift_storeEnumTagSinglePayload(*(int *)(a4 + 28) + a1, a2, a2, v5);
  }
  return result;
}

uint64_t type metadata accessor for MLSupportVectorClassifier.Classifier(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLSupportVectorClassifier.Classifier;
  if (!type metadata singleton initialization cache for MLSupportVectorClassifier.Classifier) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLSupportVectorClassifier.Classifier);
  }
  return result;
}

uint64_t type metadata completion function for MLSupportVectorClassifier.Classifier(uint64_t a1)
{
  v3[0] = &unk_3518D8;
  v3[1] = (char *)&value witness table for Builtin.BridgeObject + 64;
  v3[2] = &unk_3518F0;
  uint64_t result = type metadata accessor for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>(319);
  if (v2 <= 0x3F)
  {
    v3[3] = *(void *)(result - 8) + 64;
    swift_initStructMetadata(a1, 256, 4, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t type metadata accessor for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>(uint64_t a1)
{
  uint64_t result = lazy cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>;
  if (!lazy cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>)
  {
    uint64_t v2 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>);
    uint64_t result = type metadata accessor for Either(a1, v2, v3, v4);
    if (!v5) {
      lazy cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>> = result;
    }
  }
  return result;
}

uint64_t associated type witness table accessor for SupervisedTabularEstimator.Transformer : TabularTransformer in MLSupportVectorClassifier.Classifier()
{
  return lazy protocol witness table accessor for type MLSupportVectorClassifier.Model and conformance MLSupportVectorClassifier.Model();
}

uint64_t lazy protocol witness table accessor for type MLSupportVectorClassifier.Model and conformance MLSupportVectorClassifier.Model()
{
  uint64_t result = lazy protocol witness table cache variable for type MLSupportVectorClassifier.Model and conformance MLSupportVectorClassifier.Model;
  if (!lazy protocol witness table cache variable for type MLSupportVectorClassifier.Model and conformance MLSupportVectorClassifier.Model)
  {
    uint64_t v1 = type metadata accessor for MLSupportVectorClassifier.Model(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLSupportVectorClassifier.Model, v1);
    lazy protocol witness table cache variable for type MLSupportVectorClassifier.Model and conformance MLSupportVectorClassifier.Model = result;
  }
  return result;
}

char *_sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySay6CoreML13MLShapedArrayVySdGG11TabularData12FilledColumnVyAM0M0VySSGGG_18CreateMLComponents16AnnotatedFeatureVyAKSSGs5NeverOTg503_s6f4ML13hi9VySdGSS18n14MLComponents16pqu22ADSSGIegngr_AD_SStAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSSGAY_SStcfu0_Tf3nnnpf_nTf1cn_nTm(uint64_t a1)
{
  uint64_t v102 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Double>, String>);
  uint64_t v103 = *(void *)(v102 - 8);
  int64_t v1 = *(void *)(v103 + 64);
  uint64_t v2 = alloca(v1);
  uint64_t v3 = alloca(v1);
  char v115 = &v96;
  uint64_t v4 = alloca(v1);
  uint64_t v5 = alloca(v1);
  uint64_t v106 = &v96;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>?)
                             - 8)
                 + 64);
  long long v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v118 = &v96;
  uint64_t v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  uint64_t v107 = &v96;
  uint64_t v125 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  uint64_t v11 = *(void *)(v125 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  BOOL v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  char v120 = &v96;
  uint64_t v15 = alloca(v12);
  BOOL v16 = alloca(v12);
  uint64_t v104 = &v96;
  uint64_t v17 = alloca(v12);
  uint64_t v18 = alloca(v12);
  uint64_t v114 = &v96;
  uint64_t v105 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLShapedArray<Double>, String));
  int64_t v19 = *(void *)(*(void *)(v105 - 8) + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  uint64_t v98 = &v96;
  char v22 = alloca(v19);
  Swift::String v23 = alloca(v19);
  uint64_t v99 = &v96;
  uint64_t v24 = alloca(v19);
  uint64_t v25 = alloca(v19);
  uint64_t v100 = &v96;
  uint64_t v112 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  uint64_t v119 = *(void *)(v112 - 8);
  int64_t v26 = *(void *)(v119 + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  char v113 = &v96;
  uint64_t v29 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>);
  uint64_t v30 = *(void *)(v29 - 8);
  uint64_t v111 = v29;
  int64_t v31 = *(void *)(v30 + 64);
  uint64_t v32 = alloca(v31);
  uint64_t v33 = alloca(v31);
  uint64_t v121 = &v96;
  uint64_t v123 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>.Iterator);
  int64_t v34 = *(void *)(*(void *)(v123 - 8) + 64);
  uint64_t v35 = alloca(v34);
  uint64_t v36 = alloca(v34);
  Swift::String v122 = &v96;
  uint64_t v126 = *(void *)(*(void *)a1 + 16);
  uint64_t v110 = (void (*)(uint64_t *, uint64_t, uint64_t))lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<String>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<String>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
  uint64_t v37 = v112;
  uint64_t v38 = dispatch thunk of Sequence.underestimatedCount.getter(v112, v110);
  uint64_t v39 = v126;
  if (v38 < v126) {
    uint64_t v39 = v38;
  }
  uint64_t v126 = v39;
  uint64_t v124 = (char *)_swiftEmptyArrayStorage;
  int64_t v40 = 0;
  if (v39 > 0) {
    int64_t v40 = v39;
  }
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v40, 0);
  uint64_t v41 = (char *)v121;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, (uint64_t)v121, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>);
  uint64_t v42 = *(void *)v41;
  uint64_t v43 = v41;
  unint64_t v44 = v122;
  *Swift::String v122 = v42;
  v44[1] = 0;
  (*(void (**)(uint64_t *, char *, uint64_t))(v119 + 32))(v113, &v43[*(int *)(v111 + 52)], v37);
  uint64_t v101 = (char *)v44 + *(int *)(v123 + 52);
  dispatch thunk of Sequence.makeIterator()(v37, v110);
  uint64_t v45 = v126;
  uint64_t v116 = *(int *)(v123 + 56);
  *((unsigned char *)v44 + v116) = 0;
  if (v45 < 0) {
    BUG();
  }
  uint64_t v46 = v125;
  uint64_t v117 = v11;
  unint64_t v47 = v122;
  if (v45)
  {
    uint64_t v48 = (uint64_t)v118;
    do
    {
      BOOL v49 = v45 == 0;
      uint64_t v50 = v45 - 1;
      if (v49) {
        BUG();
      }
      if (*((unsigned char *)v47 + v116)) {
        BUG();
      }
      uint64_t v51 = *v47;
      unint64_t v52 = v47[1];
      if (v52 == *(void *)(*v47 + 16))
      {
        __swift_storeEnumTagSinglePayload(v48, 1, 1, v125);
LABEL_41:
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v48, &demangling cache variable for type metadata for MLShapedArray<Double>?);
LABEL_43:
        BUG();
      }
      if (v52 >= *(void *)(*v47 + 16)) {
        BUG();
      }
      uint64_t v126 = v50;
      uint64_t v53 = ((*(unsigned __int8 *)(v11 + 80) + 32) & ~*(unsigned __int8 *)(v11 + 80))
          + v51
          + v52 * *(void *)(v11 + 72);
      uint64_t v54 = *(uint64_t **)(v11 + 16);
      uint64_t v55 = v11;
      uint64_t v56 = v125;
      uint64_t v121 = v54;
      ((void (*)(uint64_t, uint64_t, uint64_t))v54)(v48, v53, v125);
      v122[1] = v52 + 1;
      __swift_storeEnumTagSinglePayload(v48, 0, 1, v56);
      if (__swift_getEnumTagSinglePayload(v48, 1, v56) == 1) {
        goto LABEL_41;
      }
      uint64_t v110 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v55 + 32);
      v110(v120, v48, v56);
      uint64_t v57 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<String>>>)
                   + 36);
      uint64_t v58 = v101;
      uint64_t v123 = *(void *)&v101[v57];
      uint64_t v59 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<String>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<String>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
      uint64_t v60 = v112;
      uint64_t v61 = v59;
      dispatch thunk of Collection.endIndex.getter(v112, v59);
      if (v123 == v108)
      {
        (*(void (**)(uint64_t *, uint64_t))(v117 + 8))(v120, v125);
        goto LABEL_43;
      }
      uint64_t v62 = &v58[v57];
      uint64_t v97 = v61;
      uint64_t v63 = (void (*)(uint64_t *, void))dispatch thunk of Collection.subscript.read(&v108, v62, v60, v61);
      uint64_t v123 = *v64;
      uint64_t v111 = v64[1];
      swift_bridgeObjectRetain(v111);
      v63(&v108, 0);
      Swift::String v65 = v113;
      (*(void (**)(uint64_t *, char *, uint64_t))(v119 + 16))(v113, v58, v60);
      dispatch thunk of Collection.formIndex(after:)(v62, v60, v97);
      (*(void (**)(uint64_t *, uint64_t))(v119 + 8))(v65, v60);
      uint64_t v66 = *(int *)(v105 + 48);
      uint64_t v67 = (uint64_t)v98;
      uint64_t v68 = v125;
      v110(v98, (uint64_t)v120, v125);
      *(void *)(v67 + v66) = v123;
      uint64_t v69 = v111;
      *(void *)(v67 + v66 + 8) = v111;
      unint64_t v70 = v104;
      ((void (*)(uint64_t *, uint64_t, uint64_t))v121)(v104, v67, v68);
      uint64_t v108 = v123;
      uint64_t v109 = v69;
      swift_bridgeObjectRetain(v69);
      AnnotatedFeature.init(feature:annotation:)(v70, &v108, v68, &type metadata for String);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v67, &demangling cache variable for type metadata for (MLShapedArray<Double>, String));
      uint64_t v71 = v124;
      if (!swift_isUniquelyReferenced_nonNull_native(v124))
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v71 + 2) + 1, 1);
        uint64_t v71 = v124;
      }
      uint64_t v48 = (uint64_t)v118;
      unint64_t v72 = *((void *)v71 + 2);
      if (*((void *)v71 + 3) >> 1 <= v72)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v71 + 3) >= 2uLL, v72 + 1, 1);
        uint64_t v48 = (uint64_t)v118;
        uint64_t v71 = v124;
      }
      *((void *)v71 + 2) = v72 + 1;
      (*(void (**)(char *, uint64_t *, uint64_t))(v103 + 32))(&v71[((*(unsigned __int8 *)(v103 + 80) + 32) & ~*(unsigned __int8 *)(v103 + 80)) + *(void *)(v103 + 72) * v72], v115, v102);
      uint64_t v45 = v126;
      uint64_t v11 = v117;
      unint64_t v47 = v122;
    }
    while (v126);
    uint64_t v46 = v125;
    if (!*((unsigned char *)v122 + v116)) {
      goto LABEL_20;
    }
  }
  else
  {
    while (1)
    {
LABEL_20:
      unint64_t v73 = v47[1];
      if (v73 == *(void *)(*v47 + 16))
      {
        uint64_t v76 = (uint64_t)v107;
        __swift_storeEnumTagSinglePayload((uint64_t)v107, 1, 1, v46);
LABEL_31:
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v76, &demangling cache variable for type metadata for MLShapedArray<Double>?);
        goto LABEL_33;
      }
      if (v73 >= *(void *)(*v47 + 16)) {
        BUG();
      }
      uint64_t v74 = ((*(unsigned __int8 *)(v11 + 80) + 32) & ~*(unsigned __int8 *)(v11 + 80))
          + *v47
          + v73 * *(void *)(v11 + 72);
      uint64_t v75 = (uint64_t)v107;
      uint64_t v123 = *(void *)(v11 + 16);
      ((void (*)(uint64_t *, uint64_t, uint64_t))v123)(v107, v74, v46);
      v122[1] = v73 + 1;
      uint64_t v76 = v75;
      __swift_storeEnumTagSinglePayload(v75, 0, 1, v46);
      if (__swift_getEnumTagSinglePayload(v75, 1, v46) == 1) {
        goto LABEL_31;
      }
      char v120 = *(uint64_t **)(v11 + 32);
      ((void (*)(uint64_t *, uint64_t, uint64_t))v120)(v114, v75, v46);
      uint64_t v77 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<String>>>)
                   + 36);
      uint64_t v78 = v101;
      uint64_t v126 = *(void *)&v101[v77];
      uint64_t v79 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<String>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<String>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
      uint64_t v80 = v112;
      uint64_t v81 = v79;
      dispatch thunk of Collection.endIndex.getter(v112, v79);
      if (v126 == v108) {
        break;
      }
      char v82 = &v78[v77];
      uint64_t v121 = (uint64_t *)v81;
      double v83 = (void (*)(uint64_t *, void))dispatch thunk of Collection.subscript.read(&v108, v82, v80, v81);
      uint64_t v126 = *v84;
      char v115 = (uint64_t *)v84[1];
      swift_bridgeObjectRetain((_BYTE)v115);
      v83(&v108, 0);
      uint64_t v85 = v113;
      (*(void (**)(uint64_t *, char *, uint64_t))(v119 + 16))(v113, v78, v80);
      dispatch thunk of Collection.formIndex(after:)(v82, v80, v121);
      (*(void (**)(uint64_t *, uint64_t))(v119 + 8))(v85, v80);
      uint64_t v86 = v105;
      uint64_t v87 = *(int *)(v105 + 48);
      uint64_t v88 = (uint64_t)v99;
      ((void (*)(uint64_t *, uint64_t *, uint64_t))v120)(v99, v114, v125);
      *(void *)(v88 + v87) = v126;
      *(void *)(v88 + v87 + 8) = v115;
      uint64_t v89 = (uint64_t)v100;
      outlined init with take of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(v88, (uint64_t)v100, &demangling cache variable for type metadata for (MLShapedArray<Double>, String));
      uint64_t v90 = *(int *)(v86 + 48);
      uint64_t v126 = *(void *)(v89 + v90);
      uint64_t v91 = *(void *)(v89 + v90 + 8);
      uint64_t v92 = v104;
      uint64_t v46 = v125;
      ((void (*)(uint64_t *, uint64_t, uint64_t))v123)(v104, v89, v125);
      uint64_t v108 = v126;
      uint64_t v109 = v91;
      swift_bridgeObjectRetain(v91);
      AnnotatedFeature.init(feature:annotation:)(v92, &v108, v46, &type metadata for String);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v89, &demangling cache variable for type metadata for (MLShapedArray<Double>, String));
      uint64_t v93 = v124;
      if (!swift_isUniquelyReferenced_nonNull_native(v124))
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v93 + 2) + 1, 1);
        uint64_t v46 = v125;
        uint64_t v93 = v124;
      }
      unint64_t v94 = *((void *)v93 + 2);
      if (*((void *)v93 + 3) >> 1 <= v94)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v93 + 3) >= 2uLL, v94 + 1, 1);
        uint64_t v46 = v125;
        uint64_t v93 = v124;
      }
      *((void *)v93 + 2) = v94 + 1;
      (*(void (**)(char *, uint64_t *, uint64_t))(v103 + 32))(&v93[((*(unsigned __int8 *)(v103 + 80) + 32) & ~*(unsigned __int8 *)(v103 + 80)) + *(void *)(v103 + 72) * v94], v106, v102);
      unint64_t v47 = v122;
      uint64_t v11 = v117;
      if (*((unsigned char *)v122 + v116)) {
        goto LABEL_34;
      }
    }
    (*(void (**)(uint64_t *, uint64_t))(v117 + 8))(v114, v125);
LABEL_33:
    unint64_t v47 = v122;
    *((unsigned char *)v122 + v116) = 1;
  }
LABEL_34:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v47, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>.Iterator);
  return v124;
}

char *_sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySay6CoreML13MLShapedArrayVySdGG11TabularData12FilledColumnVyAM0M0VySiGGG_18CreateMLComponents16AnnotatedFeatureVyAKSiGs5NeverOTg503_s6f4ML13hi9VySdGSi18n14MLComponents16pqu22ADSiGIegnyr_AD_SitAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSiGAY_Sitcfu2_Tf3nnnpf_nTf1cn_nTm(uint64_t a1)
{
  uint64_t v102 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Double>, Int>);
  uint64_t v103 = *(void *)(v102 - 8);
  int64_t v1 = *(void *)(v103 + 64);
  uint64_t v2 = alloca(v1);
  uint64_t v3 = alloca(v1);
  char v113 = &v97;
  uint64_t v4 = alloca(v1);
  uint64_t v5 = alloca(v1);
  uint64_t v106 = &v97;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>?)
                             - 8)
                 + 64);
  long long v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  char v115 = &v97;
  uint64_t v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  uint64_t v107 = &v97;
  uint64_t v122 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  uint64_t v11 = *(void *)(v122 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  BOOL v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v117 = &v97;
  uint64_t v15 = alloca(v12);
  BOOL v16 = alloca(v12);
  uint64_t v104 = &v97;
  uint64_t v17 = alloca(v12);
  uint64_t v18 = alloca(v12);
  uint64_t v112 = &v97;
  uint64_t v105 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLShapedArray<Double>, Int));
  int64_t v19 = *(void *)(*(void *)(v105 - 8) + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  uint64_t v97 = (uint64_t)&v97;
  char v22 = alloca(v19);
  Swift::String v23 = alloca(v19);
  uint64_t v98 = &v97;
  uint64_t v24 = alloca(v19);
  uint64_t v25 = alloca(v19);
  uint64_t v99 = &v97;
  uint64_t v110 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<Int>>);
  uint64_t v116 = *(void *)(v110 - 8);
  int64_t v26 = *(void *)(v116 + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  uint64_t v111 = &v97;
  uint64_t v29 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>);
  uint64_t v30 = *(void *)(v29 - 8);
  uint64_t v109 = v29;
  int64_t v31 = *(void *)(v30 + 64);
  uint64_t v32 = alloca(v31);
  uint64_t v33 = alloca(v31);
  uint64_t v118 = &v97;
  uint64_t v120 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>.Iterator);
  int64_t v34 = *(void *)(*(void *)(v120 - 8) + 64);
  uint64_t v35 = alloca(v34);
  uint64_t v36 = alloca(v34);
  uint64_t v121 = &v97;
  uint64_t v124 = *(void *)(*(void *)a1 + 16);
  uint64_t v108 = (void (*)(uint64_t *, uint64_t, uint64_t))lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<Int>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<Int>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
  uint64_t v37 = v110;
  uint64_t v38 = dispatch thunk of Sequence.underestimatedCount.getter(v110, v108);
  uint64_t v39 = v124;
  if (v38 < v124) {
    uint64_t v39 = v38;
  }
  uint64_t v124 = v39;
  uint64_t v123 = (char *)_swiftEmptyArrayStorage;
  int64_t v40 = 0;
  if (v39 > 0) {
    int64_t v40 = v39;
  }
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v40, 0);
  uint64_t v41 = v118;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, (uint64_t)v118, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>);
  uint64_t v42 = *v41;
  uint64_t v43 = v41;
  unint64_t v44 = v121;
  uint64_t *v121 = v42;
  v44[1] = 0;
  (*(void (**)(uint64_t *, char *, uint64_t))(v116 + 32))(v111, (char *)v43 + *(int *)(v109 + 52), v37);
  uint64_t v101 = (char *)v44 + *(int *)(v120 + 52);
  dispatch thunk of Sequence.makeIterator()(v37, v108);
  uint64_t v45 = v124;
  uint64_t v114 = *(int *)(v120 + 56);
  *((unsigned char *)v44 + v114) = 0;
  if (v45 < 0) {
    BUG();
  }
  uint64_t v46 = v122;
  uint64_t v119 = v11;
  unint64_t v47 = v121;
  if (v45)
  {
    uint64_t v48 = (uint64_t)v115;
    do
    {
      BOOL v49 = v45 == 0;
      uint64_t v50 = v45 - 1;
      if (v49) {
        BUG();
      }
      if (*((unsigned char *)v47 + v114)) {
        BUG();
      }
      uint64_t v51 = *v47;
      unint64_t v52 = v47[1];
      if (v52 == *(void *)(*v47 + 16))
      {
        __swift_storeEnumTagSinglePayload(v48, 1, 1, v122);
LABEL_42:
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v48, &demangling cache variable for type metadata for MLShapedArray<Double>?);
LABEL_44:
        BUG();
      }
      if (v52 >= *(void *)(*v47 + 16)) {
        BUG();
      }
      uint64_t v124 = v50;
      uint64_t v53 = ((*(unsigned __int8 *)(v11 + 80) + 32) & ~*(unsigned __int8 *)(v11 + 80))
          + v51
          + v52 * *(void *)(v11 + 72);
      uint64_t v54 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v11 + 16);
      uint64_t v55 = v11;
      uint64_t v56 = v122;
      uint64_t v108 = v54;
      v54((uint64_t *)v48, v53, v122);
      v121[1] = v52 + 1;
      __swift_storeEnumTagSinglePayload(v48, 0, 1, v56);
      if (__swift_getEnumTagSinglePayload(v48, 1, v56) == 1) {
        goto LABEL_42;
      }
      uint64_t v109 = *(void *)(v55 + 32);
      ((void (*)(uint64_t *, uint64_t, uint64_t))v109)(v117, v48, v56);
      uint64_t v57 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<Int>>>)
                   + 36);
      uint64_t v58 = v101;
      uint64_t v118 = *(uint64_t **)&v101[v57];
      uint64_t v59 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<Int>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<Int>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
      uint64_t v60 = v110;
      uint64_t v120 = v59;
      dispatch thunk of Collection.endIndex.getter(v110, v59);
      if (v118 == (uint64_t *)v100[0])
      {
        (*(void (**)(uint64_t *, uint64_t))(v119 + 8))(v117, v122);
        goto LABEL_44;
      }
      uint64_t v61 = &v58[v57];
      uint64_t v62 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v100, v61, v60, v120);
      uint64_t v118 = (uint64_t *)*v63;
      v62(v100, 0);
      unint64_t v64 = v111;
      (*(void (**)(uint64_t *, char *, uint64_t))(v116 + 16))(v111, v58, v60);
      dispatch thunk of Collection.formIndex(after:)(v61, v60, v120);
      (*(void (**)(uint64_t *, uint64_t))(v116 + 8))(v64, v60);
      uint64_t v65 = *(int *)(v105 + 48);
      uint64_t v66 = v97;
      uint64_t v67 = v122;
      ((void (*)(uint64_t, uint64_t *, uint64_t))v109)(v97, v117, v122);
      uint64_t v68 = (uint64_t)v118;
      *(void *)(v66 + v65) = v118;
      uint64_t v69 = v104;
      v108(v104, v66, v67);
      v100[0] = v68;
      AnnotatedFeature.init(feature:annotation:)(v69, v100, v67, &type metadata for Int);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v66, &demangling cache variable for type metadata for (MLShapedArray<Double>, Int));
      unint64_t v70 = v123;
      if (!swift_isUniquelyReferenced_nonNull_native(v123))
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v70 + 2) + 1, 1);
        unint64_t v70 = v123;
      }
      uint64_t v48 = (uint64_t)v115;
      unint64_t v71 = *((void *)v70 + 2);
      if (*((void *)v70 + 3) >> 1 <= v71)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v70 + 3) >= 2uLL, v71 + 1, 1);
        uint64_t v48 = (uint64_t)v115;
        unint64_t v70 = v123;
      }
      *((void *)v70 + 2) = v71 + 1;
      (*(void (**)(char *, uint64_t *, uint64_t))(v103 + 32))(&v70[((*(unsigned __int8 *)(v103 + 80) + 32) & ~*(unsigned __int8 *)(v103 + 80)) + *(void *)(v103 + 72) * v71], v113, v102);
      uint64_t v45 = v124;
      uint64_t v11 = v119;
      unint64_t v47 = v121;
    }
    while (v124);
    uint64_t v46 = v122;
    if (!*((unsigned char *)v121 + v114)) {
      goto LABEL_20;
    }
  }
  else
  {
    while (1)
    {
LABEL_20:
      unint64_t v72 = v47[1];
      if (v72 == *(void *)(*v47 + 16))
      {
        uint64_t v75 = (uint64_t)v107;
        __swift_storeEnumTagSinglePayload((uint64_t)v107, 1, 1, v46);
LABEL_32:
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v75, &demangling cache variable for type metadata for MLShapedArray<Double>?);
        goto LABEL_34;
      }
      if (v72 >= *(void *)(*v47 + 16)) {
        BUG();
      }
      uint64_t v73 = ((*(unsigned __int8 *)(v11 + 80) + 32) & ~*(unsigned __int8 *)(v11 + 80))
          + *v47
          + v72 * *(void *)(v11 + 72);
      uint64_t v74 = (uint64_t)v107;
      uint64_t v120 = *(void *)(v11 + 16);
      ((void (*)(uint64_t *, uint64_t, uint64_t))v120)(v107, v73, v46);
      v121[1] = v72 + 1;
      uint64_t v75 = v74;
      __swift_storeEnumTagSinglePayload(v74, 0, 1, v46);
      if (__swift_getEnumTagSinglePayload(v74, 1, v46) == 1) {
        goto LABEL_32;
      }
      uint64_t v117 = *(uint64_t **)(v11 + 32);
      ((void (*)(uint64_t *, uint64_t, uint64_t))v117)(v112, v74, v46);
      uint64_t v76 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<Int>>>)
                   + 36);
      uint64_t v77 = v101;
      uint64_t v124 = *(void *)&v101[v76];
      uint64_t v78 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<Int>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<Int>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
      uint64_t v79 = v110;
      uint64_t v80 = (uint64_t *)v78;
      dispatch thunk of Collection.endIndex.getter(v110, v78);
      if (v124 == v100[0]) {
        break;
      }
      uint64_t v81 = &v77[v76];
      char v113 = v80;
      char v82 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v100, v81, v79, v80);
      uint64_t v124 = *v83;
      v82(v100, 0);
      unint64_t v84 = v111;
      (*(void (**)(uint64_t *, char *, uint64_t))(v116 + 16))(v111, v77, v79);
      dispatch thunk of Collection.formIndex(after:)(v81, v79, v113);
      (*(void (**)(uint64_t *, uint64_t))(v116 + 8))(v84, v79);
      uint64_t v85 = v105;
      uint64_t v86 = *(int *)(v105 + 48);
      uint64_t v87 = v98;
      uint64_t v88 = v122;
      ((void (*)(uint64_t *, uint64_t *, uint64_t))v117)(v98, v112, v122);
      *(uint64_t *)((char *)v87 + v86) = v124;
      uint64_t v89 = (uint64_t)v87;
      uint64_t v90 = (uint64_t)v99;
      outlined init with take of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(v89, (uint64_t)v99, &demangling cache variable for type metadata for (MLShapedArray<Double>, Int));
      uint64_t v124 = *(void *)(v90 + *(int *)(v85 + 48));
      uint64_t v91 = v104;
      ((void (*)(uint64_t *, uint64_t, uint64_t))v120)(v104, v90, v88);
      v100[0] = v124;
      uint64_t v92 = v88;
      AnnotatedFeature.init(feature:annotation:)(v91, v100, v88, &type metadata for Int);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v90, &demangling cache variable for type metadata for (MLShapedArray<Double>, Int));
      uint64_t v93 = v123;
      if (swift_isUniquelyReferenced_nonNull_native(v123))
      {
        uint64_t v46 = v92;
      }
      else
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v93 + 2) + 1, 1);
        uint64_t v46 = v122;
        uint64_t v93 = v123;
      }
      uint64_t v11 = v119;
      unint64_t v94 = *((void *)v93 + 2);
      unint64_t v95 = v94 + 1;
      if (*((void *)v93 + 3) >> 1 <= v94)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v93 + 3) >= 2uLL, v94 + 1, 1);
        unint64_t v95 = v94 + 1;
        uint64_t v46 = v122;
        uint64_t v93 = v123;
      }
      *((void *)v93 + 2) = v95;
      (*(void (**)(char *, uint64_t *, uint64_t))(v103 + 32))(&v93[((*(unsigned __int8 *)(v103 + 80) + 32) & ~*(unsigned __int8 *)(v103 + 80)) + *(void *)(v103 + 72) * v94], v106, v102);
      unint64_t v47 = v121;
      if (*((unsigned char *)v121 + v114)) {
        goto LABEL_35;
      }
    }
    (*(void (**)(uint64_t *, uint64_t))(v119 + 8))(v112, v122);
LABEL_34:
    unint64_t v47 = v121;
    *((unsigned char *)v121 + v114) = 1;
  }
LABEL_35:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v47, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>.Iterator);
  return v123;
}

uint64_t MLSupportVectorClassifier.Classifier.init(labelsColumn:targetColumnName:featureColumnNames:parameters:)(uint64_t a1, uint64_t a2, void *a3, uint64_t *a4, uint64_t a5)
{
  uint64_t v104 = v6;
  uint64_t v116 = a4;
  char v113 = a3;
  uint64_t v110 = a2;
  uint64_t v117 = a1;
  uint64_t v8 = v5;
  uint64_t v102 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>);
  uint64_t v101 = *(void *)(v102 - 8);
  int64_t v9 = *(void *)(v101 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v108 = v84;
  uint64_t v93 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v92 = *(void *)(v93 - 8);
  int64_t v12 = *(void *)(v92 + 64);
  BOOL v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v97 = v84;
  int64_t v15 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<Int>>)
                              - 8)
                  + 64);
  BOOL v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v98 = v84;
  uint64_t v112 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>.Configuration);
  uint64_t v111 = *(void *)(v112 - 8);
  int64_t v18 = *(void *)(v111 + 64);
  int64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v99 = v84;
  uint64_t v21 = alloca(v18);
  char v22 = alloca(v18);
  uint64_t v106 = v84;
  uint64_t v94 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>);
  uint64_t v95 = *(void *)(v94 - 8);
  int64_t v23 = *(void *)(v95 + 64);
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  uint64_t v105 = v84;
  uint64_t v107 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  int64_t v26 = *(void *)(*(void *)(v107 - 8) + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  uint64_t v103 = v84;
  uint64_t v29 = alloca(v26);
  uint64_t v30 = alloca(v26);
  uint64_t v96 = v84;
  uint64_t v88 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v89 = *(void *)(v88 - 8);
  int64_t v31 = *(void *)(v89 + 64);
  uint64_t v32 = alloca(v31);
  uint64_t v33 = alloca(v31);
  int64_t v34 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>)
                              - 8)
                  + 64);
  uint64_t v35 = alloca(v34);
  uint64_t v36 = alloca(v34);
  uint64_t v90 = v84;
  uint64_t v114 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>.Configuration);
  uint64_t v109 = *(void *)(v114 - 8);
  int64_t v37 = *(void *)(v109 + 64);
  uint64_t v38 = alloca(v37);
  uint64_t v39 = alloca(v37);
  uint64_t v91 = v84;
  int64_t v40 = alloca(v37);
  uint64_t v41 = alloca(v37);
  uint64_t *v8 = v110;
  v8[1] = (uint64_t)v113;
  _OWORD v8[2] = (uint64_t)v116;
  uint64_t v116 = v8;
  uint64_t v115 = a5;
  char v113 = v8 + 3;
  outlined init with copy of MLSupportVectorClassifier.ModelParameters(a5, (uint64_t)(v8 + 3));
  uint64_t v42 = AnyColumn.wrappedElementType.getter();
  if (swift_dynamicCastMetatype(v42, &type metadata for String))
  {
    outlined init with copy of MLSupportVectorClassifier.ModelParameters(v115, (uint64_t)v84);
    uint64_t v110 = lazy protocol witness table accessor for type Double and conformance Double();
    LinearSupportVectorClassifier.Configuration.init()(&type metadata for Double, &type metadata for String, &protocol witness table for Double, v110, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String);
    uint64_t v100 = v84;
    uint64_t v43 = v114;
    LinearSupportVectorClassifier.Configuration.maximumIterations.setter(v84[0], v114);
    LinearSupportVectorClassifier.Configuration.penalty.setter(v43, v85);
    LinearSupportVectorClassifier.Configuration.convergenceThreshold.setter(v43, v86);
    LinearSupportVectorClassifier.Configuration.scaleFeatures.setter(v87, v43);
    outlined destroy of MLSupportVectorClassifier.ModelParameters((uint64_t)v84);
    double v44 = AnyColumn.assumingType<A>(_:)(&type metadata for String, &type metadata for String);
    v84[0] = 0;
    v84[1] = 0xE000000000000000;
    uint64_t v45 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v46 = v88;
    OptionalColumnProtocol.filled(with:)(v84, v88, v45);
    (*(void (**)(void *, uint64_t, double))(v89 + 8))(v84, v46, v44);
    uint64_t v47 = specialized Set.init<A>(_:)();
    uint64_t v48 = v91;
    BOOL v49 = v100;
    (*(void (**)(void *, void *, uint64_t))(v109 + 16))(v91, v100, v114);
    uint64_t v50 = v104;
    LinearSupportVectorClassifier.init(labels:configuration:)(v47, v48, &type metadata for Double, &type metadata for String, &protocol witness table for Double, v110, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String);
    if (v50)
    {
      outlined destroy of MLSupportVectorClassifier.ModelParameters(v115);
      uint64_t v51 = type metadata accessor for AnyColumn(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v51 - 8) + 8))(v117, v51);
      unint64_t v52 = v49;
      uint64_t v53 = v114;
      uint64_t v54 = v109;
LABEL_7:
      (*(void (**)(void *, uint64_t))(v54 + 8))(v52, v53);
LABEL_10:
      uint64_t v78 = v116;
      uint64_t v79 = (uint64_t)v113;
      swift_bridgeObjectRelease(v116[1]);
      swift_bridgeObjectRelease(v78[2]);
      return outlined destroy of MLSupportVectorClassifier.ModelParameters(v79);
    }
    outlined destroy of MLSupportVectorClassifier.ModelParameters(v115);
    uint64_t v67 = type metadata accessor for AnyColumn(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v67 - 8) + 8))(v117, v67);
    (*(void (**)(void *, uint64_t))(v109 + 8))(v49, v114);
    uint64_t v68 = (uint64_t)v96;
    (*(void (**)(void *, void *, uint64_t))(v95 + 32))(v96, v105, v94);
    uint64_t v69 = v68;
    uint64_t v70 = v107;
    uint64_t v71 = 0;
  }
  else
  {
    uint64_t v55 = v115;
    if (!swift_dynamicCastMetatype(v42, &type metadata for Int))
    {
      uint64_t v72 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v72, 0, 0);
      *(void *)uint64_t v73 = 0xD000000000000025;
      *(void *)(v73 + 8) = "start time column" + 0x8000000000000000;
      *(_OWORD *)(v73 + 16) = 0;
      *(_OWORD *)(v73 + 32) = 0;
      *(unsigned char *)(v73 + 48) = 1;
      swift_willThrow(&type metadata for MLCreateError, v72, v73, v74, v75, v76);
      outlined destroy of MLSupportVectorClassifier.ModelParameters(v55);
      uint64_t v77 = type metadata accessor for AnyColumn(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v77 - 8) + 8))(v117, v77);
      goto LABEL_10;
    }
    outlined init with copy of MLSupportVectorClassifier.ModelParameters(v55, (uint64_t)v84);
    uint64_t v114 = lazy protocol witness table accessor for type Double and conformance Double();
    LinearSupportVectorClassifier.Configuration.init()(&type metadata for Double, &type metadata for Int, &protocol witness table for Double, v114, &protocol witness table for Int, &protocol witness table for Int, &protocol witness table for Int, &protocol witness table for Int);
    uint64_t v56 = v112;
    LinearSupportVectorClassifier.Configuration.maximumIterations.setter(v84[0], v112);
    LinearSupportVectorClassifier.Configuration.penalty.setter(v56, v85);
    LinearSupportVectorClassifier.Configuration.convergenceThreshold.setter(v56, v86);
    LinearSupportVectorClassifier.Configuration.scaleFeatures.setter(v87, v56);
    outlined destroy of MLSupportVectorClassifier.ModelParameters((uint64_t)v84);
    uint64_t v57 = v97;
    double v58 = AnyColumn.assumingType<A>(_:)(&type metadata for Int, &type metadata for Int);
    v84[0] = 0;
    uint64_t v59 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Int> and conformance Column<A>, &demangling cache variable for type metadata for Column<Int>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v60 = v93;
    OptionalColumnProtocol.filled(with:)(v84, v93, v59);
    uint64_t v61 = v57;
    uint64_t v62 = v106;
    (*(void (**)(void *, uint64_t, double))(v92 + 8))(v61, v60, v58);
    uint64_t v63 = specialized Set.init<A>(_:)();
    unint64_t v64 = v99;
    (*(void (**)(void *, void *, uint64_t))(v111 + 16))(v99, v62, v112);
    uint64_t v65 = v104;
    LinearSupportVectorClassifier.init(labels:configuration:)(v63, v64, &type metadata for Double, &type metadata for Int, &protocol witness table for Double, v114, &protocol witness table for Int, &protocol witness table for Int, &protocol witness table for Int, &protocol witness table for Int);
    if (v65)
    {
      outlined destroy of MLSupportVectorClassifier.ModelParameters(v115);
      uint64_t v66 = type metadata accessor for AnyColumn(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v66 - 8) + 8))(v117, v66);
      unint64_t v52 = v62;
      uint64_t v53 = v112;
      uint64_t v54 = v111;
      goto LABEL_7;
    }
    outlined destroy of MLSupportVectorClassifier.ModelParameters(v115);
    uint64_t v81 = type metadata accessor for AnyColumn(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v81 - 8) + 8))(v117, v81);
    (*(void (**)(void *, uint64_t))(v111 + 8))(v62, v112);
    uint64_t v68 = (uint64_t)v103;
    (*(void (**)(void *, void *, uint64_t))(v101 + 32))(v103, v108, v102);
    uint64_t v71 = 1;
    uint64_t v69 = v68;
    uint64_t v70 = v107;
  }
  swift_storeEnumTagMultiPayload(v69, v70, v71);
  char v82 = v116;
  uint64_t v83 = type metadata accessor for MLSupportVectorClassifier.Classifier(0);
  return outlined init with take of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(v68, (uint64_t)v82 + *(int *)(v83 + 28), &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
}

uint64_t MLSupportVectorClassifier.Classifier.fitted(to:validateOn:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v302 = v5;
  uint64_t v291 = a4;
  uint64_t v292 = a3;
  v320._uint64_t countAndFlagsBits = a2;
  *(void *)&long long v321 = a1;
  uint64_t v293 = v4;
  uint64_t v280 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>);
  uint64_t v279 = *(void *)(v280 - 8);
  int64_t v7 = *(void *)(v279 + 64);
  uint64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  v277 = v261;
  uint64_t v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  Swift::String v283 = v261;
  uint64_t v274 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>);
  int64_t v12 = *(void *)(*(void *)(v274 - 8) + 64);
  BOOL v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v268 = (char **)v261;
  uint64_t v271 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v266 = *(void *)(v271 - 8);
  int64_t v15 = *(void *)(v266 + 64);
  BOOL v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  Swift::String v285 = v261;
  uint64_t v299 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<Int>>);
  uint64_t v303 = *(void *)(v299 - 8);
  int64_t v18 = *(void *)(v303 + 64);
  int64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v295 = v261;
  uint64_t v21 = alloca(v18);
  char v22 = alloca(v18);
  v306 = v261;
  v318 = (char *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>);
  v313 = (void *)*((void *)v318 - 1);
  int64_t v23 = v313[8];
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  uint64_t v310 = v261;
  uint64_t v289 = type metadata accessor for AnyColumn(0);
  uint64_t v288 = *(void *)(v289 - 8);
  int64_t v26 = *(void *)(v288 + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  uint64_t v290 = v261;
  uint64_t v282 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>);
  uint64_t v281 = *(void *)(v282 - 8);
  int64_t v29 = *(void *)(v281 + 64);
  uint64_t v30 = alloca(v29);
  int64_t v31 = alloca(v29);
  v278 = v261;
  uint64_t v32 = alloca(v29);
  uint64_t v33 = alloca(v29);
  v284 = v261;
  uint64_t v317 = type metadata accessor for DataFrame(0);
  uint64_t v309 = *(void *)(v317 - 8);
  int64_t v34 = *(void *)(v309 + 64);
  uint64_t v35 = alloca(v34);
  uint64_t v36 = alloca(v34);
  uint64_t v296 = v261;
  int64_t v37 = alloca(v34);
  uint64_t v38 = alloca(v34);
  v297 = v261;
  uint64_t v276 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>);
  int64_t v39 = *(void *)(*(void *)(v276 - 8) + 64);
  int64_t v40 = alloca(v39);
  uint64_t v41 = alloca(v39);
  uint64_t v275 = (char **)v261;
  uint64_t v315 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  uint64_t v316 = *(void *)(v315 - 8);
  int64_t v42 = *(void *)(v316 + 64);
  uint64_t v43 = alloca(v42);
  double v44 = alloca(v42);
  v294 = v261;
  uint64_t v45 = alloca(v42);
  uint64_t v46 = alloca(v42);
  v300 = v261;
  uint64_t v47 = alloca(v42);
  uint64_t v48 = alloca(v42);
  v286 = v261;
  BOOL v49 = alloca(v42);
  uint64_t v50 = alloca(v42);
  uint64_t v301 = v261;
  uint64_t v272 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v267 = *(void *)(v272 - 8);
  int64_t v51 = *(void *)(v267 + 64);
  unint64_t v52 = alloca(v51);
  uint64_t v53 = alloca(v51);
  uint64_t v273 = v261;
  uint64_t v308 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  uint64_t v304 = *(void *)(v308 - 8);
  int64_t v54 = *(void *)(v304 + 64);
  uint64_t v55 = alloca(v54);
  uint64_t v56 = alloca(v54);
  Swift::String v287 = v261;
  uint64_t v57 = alloca(v54);
  double v58 = alloca(v54);
  long long v307 = v261;
  v311 = (char *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>);
  v314 = (void *)*((void *)v311 - 1);
  int64_t v59 = v314[8];
  uint64_t v60 = alloca(v59);
  uint64_t v61 = alloca(v59);
  v312 = v261;
  uint64_t v264 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  int64_t v62 = *(void *)(*(void *)(v264 - 8) + 64);
  uint64_t v63 = alloca(v62);
  unint64_t v64 = alloca(v62);
  unint64_t v263 = v261;
  uint64_t v265 = type metadata accessor for MLSupportVectorClassifier.Classifier(0);
  int64_t v65 = *(void *)(*(void *)(v265 - 8) + 64);
  uint64_t v66 = alloca(v65);
  uint64_t v67 = alloca(v65);
  v322 = (Swift::String *)v261;
  int64_t v68 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                              - 8)
                  + 64);
  uint64_t v69 = alloca(v68);
  uint64_t v70 = alloca(v68);
  uint64_t v269 = v261;
  uint64_t v71 = alloca(v68);
  uint64_t v72 = alloca(v68);
  char v270 = v261;
  uint64_t v73 = alloca(v68);
  uint64_t v74 = alloca(v68);
  uint64_t v298 = (char *)v261;
  uint64_t v75 = alloca(v68);
  uint64_t v76 = alloca(v68);
  v320._char object = v261;
  uint64_t v77 = *v6;
  uint64_t v78 = (void *)v6[1];
  v79._uint64_t countAndFlagsBits = *v6;
  v79._char object = v78;
  if (DataFrame.indexOfColumn(_:)(v79).is_nil)
  {
    *(void *)&long long v319 = 0;
    *((void *)&v319 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(53);
    v83._uint64_t countAndFlagsBits = 0xD00000000000001ELL;
    v83._char object = "er.Classifier.swift" + 0x8000000000000000;
    String.append(_:)(v83);
    swift_bridgeObjectRetain((_BYTE)v78);
    v83._uint64_t countAndFlagsBits = v77;
    v83._char object = v78;
    String.append(_:)(v83);
    swift_bridgeObjectRelease((_BYTE)v78);
    v84._char object = "Training data must contain a '" + 0x8000000000000000;
    v84._uint64_t countAndFlagsBits = 0xD000000000000015;
LABEL_5:
    String.append(_:)(v84);
    long long v321 = v319;
    uint64_t v85 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v85, 0, 0);
    *(_OWORD *)uint64_t v86 = v321;
    *(_OWORD *)(v86 + 16) = 0;
    *(_OWORD *)(v86 + 32) = 0;
    *(unsigned char *)(v86 + 48) = 0;
    return swift_willThrow(&type metadata for MLCreateError, v85, v86, v87, v88, v89);
  }
  uint64_t countAndFlagsBits = v320._countAndFlagsBits;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v320._countAndFlagsBits, 1, v317);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(countAndFlagsBits, (uint64_t)v320._object, &demangling cache variable for type metadata for DataFrame?);
  uint64_t v305 = v6;
  char v82 = v322;
  outlined init with copy of MLSupportVectorClassifier.Classifier((uint64_t)v6, (uint64_t)v322);
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v320._object, &demangling cache variable for type metadata for DataFrame?);
    outlined destroy of MLSupportVectorClassifier.Classifier((uint64_t)v82);
    goto LABEL_8;
  }
  uint64_t v91 = (uint64_t)v298;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v320._object, (uint64_t)v298, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload(v91, 1, v317) == 1) {
    BUG();
  }
  uint64_t v92 = v91;
  Swift::Bool is_nil = DataFrame.indexOfColumn(_:)(*v82).is_nil;
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v320._object, &demangling cache variable for type metadata for DataFrame?);
  (*(void (**)(uint64_t, uint64_t))(v309 + 8))(v92, v317);
  outlined destroy of MLSupportVectorClassifier.Classifier((uint64_t)v82);
  if (is_nil)
  {
    *(void *)&long long v319 = 0;
    *((void *)&v319 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(55);
    v117._uint64_t countAndFlagsBits = 0xD000000000000020;
    v117._char object = "' column with labels." + 0x8000000000000000;
    String.append(_:)(v117);
    uint64_t v118 = *v305;
    uint64_t v119 = (void *)v305[1];
    swift_bridgeObjectRetain((_BYTE)v119);
    v117._uint64_t countAndFlagsBits = v118;
    v117._char object = v119;
    String.append(_:)(v117);
    swift_bridgeObjectRelease((_BYTE)v119);
    v84._char object = "Training data must contain a '" + 0x8000000000000000;
    v84._uint64_t countAndFlagsBits = 0xD000000000000015;
    goto LABEL_5;
  }
LABEL_8:
  uint64_t v94 = v305;
  uint64_t v95 = v305[2];
  uint64_t v96 = alloca(24);
  uint64_t v97 = alloca(32);
  v261[2] = v321;
  swift_bridgeObjectRetain(v95);
  uint64_t v98 = v302;
  ML16ColumnDescriptorVsAE_pTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_8CreateML16ColumnDescriptorVsAE_pTg5((void (*)(void *, uint64_t *))partial apply for closure #1 in FeatureVectorizer.fitted(to:), (uint64_t)v261, v95);
  if (v98) {
    return swift_bridgeObjectRelease(v95);
  }
  v320._char object = ML16ColumnDescriptorVsAE_pTg5;
  v322 = 0;
  swift_bridgeObjectRelease(v95);
  uint64_t v100 = (uint64_t)v263;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v94 + *(int *)(v265 + 28), (uint64_t)v263, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  if (swift_getEnumCaseMultiPayload(v100, v264) != 1)
  {
    ((void (*)(void *, uint64_t, char *))v314[4])(v312, v100, v311);
    uint64_t v120 = *v94;
    uint64_t v121 = (void *)v94[1];
    v122._uint64_t countAndFlagsBits = *v94;
    v122._char object = v121;
    if ((specialized DataFrame.containsColumn<A>(_:_:)(v122) & 1) == 0)
    {
      swift_bridgeObjectRelease(v320._object);
      *(void *)&long long v319 = 0;
      *((void *)&v319 + 1) = 0xE000000000000000;
      _StringGuts.grow(_:)(59);
      v143._uint64_t countAndFlagsBits = 0x6320736C6562614CLL;
      v143._char object = (void *)0xEF27206E6D756C6FLL;
      String.append(_:)(v143);
      swift_bridgeObjectRetain((_BYTE)v121);
      v143._uint64_t countAndFlagsBits = v120;
      v143._char object = v121;
      String.append(_:)(v143);
      swift_bridgeObjectRelease((_BYTE)v121);
      v143._uint64_t countAndFlagsBits = 0xD000000000000027;
      v143._char object = "Validation labels column '" + 0x8000000000000000;
      String.append(_:)(v143);
      uint64_t v144 = v290;
      DataFrame.subscript.getter(v120, v121);
      uint64_t v145 = AnyColumn.wrappedElementType.getter();
      (*(void (**)(void *, uint64_t))(v288 + 8))(v144, v289);
      uint64_t v146 = _typeName(_:qualified:)(v145, 0);
      LOBYTE(v145) = (_BYTE)v147;
      v143._uint64_t countAndFlagsBits = v146;
      v143._char object = v147;
      String.append(_:)(v143);
      swift_bridgeObjectRelease(v145);
      v143._uint64_t countAndFlagsBits = 46;
      v143._char object = (void *)0xE100000000000000;
      String.append(_:)(v143);
      long long v321 = v319;
      v143._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v143._object, 0, 0);
      *(_OWORD *)uint64_t v148 = v321;
      *(_OWORD *)(v148 + 16) = 0;
      *(_OWORD *)(v148 + 32) = 0;
      *(unsigned char *)(v148 + 48) = 1;
      swift_willThrow(&type metadata for MLCreateError, v143._object, v148, v149, v150, v151);
      goto LABEL_23;
    }
    uint64_t v123 = v273;
    uint64_t v124 = v120;
    uint64_t v125 = v321;
    DataFrame.subscript.getter(v124, v121, &type metadata for String);
    *(void *)&long long v319 = 0;
    *((void *)&v319 + 1) = 0xE000000000000000;
    uint64_t v126 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v127 = v272;
    uint64_t v302 = v126;
    OptionalColumnProtocol.filled(with:)(&v319, v272, v126);
    uint64_t v298 = *(char **)(v267 + 8);
    ((void (*)(void *, uint64_t))v298)(v123, v127);
    uint64_t v128 = (uint64_t)v301;
    char object = (char)v320._object;
    uint64_t v130 = (uint64_t)v322;
    specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(v125, 0, (uint64_t)v320._object, 0xD000000000000013, (uint64_t)("raining samples." + 0x8000000000000000));
    if (v130)
    {
      swift_bridgeObjectRelease(object);
LABEL_19:
      (*(void (**)(void *, uint64_t))(v304 + 8))(v307, v308);
LABEL_23:
      uint64_t v140 = v312;
      uint64_t v141 = v311;
      uint64_t v142 = v314;
      return ((uint64_t (*)(void *, char *))v142[1])(v140, v141);
    }
    v318 = "raining samples." + 0x8000000000000000;
    uint64_t v166 = (char *)static MLSupportVectorClassifier.Model.buildFeatures(from:)(v128);
    uint64_t v167 = (uint64_t)v275;
    *uint64_t v275 = v166;
    uint64_t v168 = *(void **)(v304 + 16);
    ((void (*)(uint64_t, void *, uint64_t))v168)(v167 + *(int *)(v276 + 52), v307, v308);
    MLComponents16AnnotatedFeatureVyAKSSGs5NeverOTg503_s6f4ML13hi9VySdGSS18n14MLComponents16pqu22ADSSGIegngr_AD_SStAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSSGAY_SStcfu0_Tf3nnnpf_nTf1cn_nTm = _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySay6CoreML13MLShapedArrayVySdGG11TabularData12FilledColumnVyAM0M0VySSGGG_18CreateMLComponents16AnnotatedFeatureVyAKSSGs5NeverOTg503_s6f4ML13hi9VySdGSS18n14MLComponents16pqu22ADSSGIegngr_AD_SStAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSSGAY_SStcfu0_Tf3nnnpf_nTf1cn_nTm(v167);
    v322 = 0;
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v167, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>);
    uint64_t v170 = (uint64_t)v270;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v320._countAndFlagsBits, (uint64_t)v270, &demangling cache variable for type metadata for DataFrame?);
    uint64_t v171 = v317;
    int v172 = __swift_getEnumTagSinglePayload(v170, 1, v317);
    *(void *)&long long v321 = MLComponents16AnnotatedFeatureVyAKSSGs5NeverOTg503_s6f4ML13hi9VySdGSS18n14MLComponents16pqu22ADSSGIegngr_AD_SStAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSSGAY_SStcfu0_Tf3nnnpf_nTf1cn_nTm;
    if (v172 == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v170, &demangling cache variable for type metadata for DataFrame?);
      *(void *)&long long v319 = MLComponents16AnnotatedFeatureVyAKSSGs5NeverOTg503_s6f4ML13hi9VySdGSS18n14MLComponents16pqu22ADSSGIegngr_AD_SStAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSSGAY_SStcfu0_Tf3nnnpf_nTf1cn_nTm;
      uint64_t v173 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, String>]);
      uint64_t v174 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Double>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, String>], (uint64_t)&protocol conformance descriptor for [A]);
      uint64_t v175 = v312;
      uint64_t v176 = (uint64_t)v322;
      char v177 = v311;
      LinearSupportVectorClassifier.fitted<A>(to:eventHandler:)(&v319, v292, v291, v311, v173, v174);
      if (v176)
      {
        swift_bridgeObjectRelease(v320._object);
        (*(void (**)(void *, uint64_t))(v316 + 8))(v301, v315);
        (*(void (**)(void *, uint64_t))(v304 + 8))(v307, v308);
        uint64_t v163 = v175;
        uint64_t v164 = v177;
        uint64_t v165 = v314;
        goto LABEL_31;
      }
      v322 = 0;
      (*(void (**)(void *, uint64_t))(v316 + 8))(v301, v315);
      (*(void (**)(void *, uint64_t))(v304 + 8))(v307, v308);
      ((void (*)(void *, char *))v314[1])(v175, v177);
      swift_bridgeObjectRelease(v321);
      uint64_t v210 = *v305;
      uint64_t v211 = v305[1];
      uint64_t v221 = type metadata accessor for MLSupportVectorClassifier.Model(0);
      Swift::String v213 = v293;
      uint64_t v222 = (char *)v293 + *(int *)(v221 + 24);
      uint64_t v223 = v222;
      uint64_t v224 = v278;
      goto LABEL_44;
    }
    uint64_t v310 = v168;
    (*(void (**)(void *, uint64_t, uint64_t))(v309 + 32))(v297, v170, v171);
    uint64_t v185 = (void *)v305[1];
    v320._uint64_t countAndFlagsBits = *v305;
    v184._uint64_t countAndFlagsBits = v320._countAndFlagsBits;
    v184._char object = v185;
    if (specialized DataFrame.containsColumn<A>(_:_:)(v184))
    {
      v313 = v185;
      uint64_t v186 = (uint64_t)v286;
      uint64_t v187 = (uint64_t)v297;
      char v188 = (char)v320._object;
      uint64_t v189 = (uint64_t)v322;
      specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)((uint64_t)v297, 0, (uint64_t)v320._object, 0xD000000000000013, (uint64_t)v318);
      if (!v189)
      {
        char v238 = (char *)static MLSupportVectorClassifier.Model.buildFeatures(from:)(v186);
        v322 = 0;
        v318 = v238;
        uint64_t v239 = v273;
        DataFrame.subscript.getter(v320._countAndFlagsBits, v313, &type metadata for String);
        *(void *)&long long v319 = 0;
        *((void *)&v319 + 1) = 0xE000000000000000;
        uint64_t v240 = v287;
        uint64_t v241 = v272;
        OptionalColumnProtocol.filled(with:)(&v319, v272, v302);
        ((void (*)(void *, uint64_t))v298)(v239, v241);
        uint64_t v242 = (uint64_t)v275;
        *uint64_t v275 = v318;
        ((void (*)(uint64_t, void *, uint64_t))v310)(*(int *)(v276 + 52) + v242, v240, v308);
        uint64_t v243 = (uint64_t)v322;
        uint64_t v244 = _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySay6CoreML13MLShapedArrayVySdGG11TabularData12FilledColumnVyAM0M0VySSGGG_18CreateMLComponents16AnnotatedFeatureVyAKSSGs5NeverOTg503_s6f4ML13hi9VySdGSS18n14MLComponents16pqu22ADSSGIegngr_AD_SStAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSSGAY_SStcfu0_Tf3nnnpf_nTf1cn_nTm(v242);
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v242, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>);
        *(void *)&long long v319 = v321;
        v320._uint64_t countAndFlagsBits = (uint64_t)v244;
        uint64_t v262 = v244;
        uint64_t v245 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, String>]);
        uint64_t v246 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Double>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, String>], (uint64_t)&protocol conformance descriptor for [A]);
        LinearSupportVectorClassifier.fitted<A, B>(to:validateOn:eventHandler:)(&v319, &v262, v292, v291, v311, v245, v245, v246, v246);
        v322 = (Swift::String *)v243;
        if (v243)
        {
          swift_bridgeObjectRelease(v320._object);
          uint64_t v247 = *(void (**)(void *, uint64_t))(v304 + 8);
          uint64_t v248 = v308;
          v247(v287, v308);
          uint64_t v249 = *(void (**)(void *, uint64_t))(v316 + 8);
          uint64_t v250 = v315;
          v249(v286, v315);
          (*(void (**)(void *, uint64_t))(v309 + 8))(v297, v317);
          v249(v301, v250);
          v247(v307, v248);
          ((void (*)(void *, char *))v314[1])(v312, v311);
          swift_bridgeObjectRelease(v321);
          char v237 = v320._countAndFlagsBits;
          return swift_bridgeObjectRelease(v237);
        }
        uint64_t v256 = *(void (**)(void *, uint64_t))(v304 + 8);
        uint64_t v257 = v308;
        v256(v287, v308);
        uint64_t v258 = *(void (**)(void *, uint64_t))(v316 + 8);
        uint64_t v259 = v315;
        v258(v286, v315);
        (*(void (**)(void *, uint64_t))(v309 + 8))(v297, v317);
        v258(v301, v259);
        v256(v307, v257);
        ((void (*)(void *, char *))v314[1])(v312, v311);
        swift_bridgeObjectRelease(v321);
        swift_bridgeObjectRelease(v320._countAndFlagsBits);
        uint64_t v210 = *v305;
        uint64_t v211 = v305[1];
        uint64_t v260 = type metadata accessor for MLSupportVectorClassifier.Model(0);
        Swift::String v213 = v293;
        uint64_t v222 = (char *)v293 + *(int *)(v260 + 24);
        uint64_t v223 = v222;
        uint64_t v224 = v284;
LABEL_44:
        (*(void (**)(char *, void *, uint64_t))(v281 + 32))(v223, v224, v282);
        uint64_t v219 = v222;
        uint64_t v220 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
        uint64_t v218 = 0;
        goto LABEL_45;
      }
      swift_bridgeObjectRelease(v188);
      swift_bridgeObjectRelease(v321);
      uint64_t v190 = v187;
    }
    else
    {
      swift_bridgeObjectRelease(v321);
      swift_bridgeObjectRelease(v320._object);
      *(void *)&long long v319 = 0;
      *((void *)&v319 + 1) = 0xE000000000000000;
      _StringGuts.grow(_:)(70);
      v201._uint64_t countAndFlagsBits = 0xD00000000000001ALL;
      v201._char object = "ntegers but it contains " + 0x8000000000000000;
      String.append(_:)(v201);
      swift_bridgeObjectRetain((_BYTE)v185);
      v201._uint64_t countAndFlagsBits = v320._countAndFlagsBits;
      v201._char object = v185;
      String.append(_:)(v201);
      swift_bridgeObjectRelease((_BYTE)v185);
      v201._char object = "Validation labels column '" + 0x8000000000000000;
      v201._uint64_t countAndFlagsBits = 0xD000000000000027;
      String.append(_:)(v201);
      uint64_t v202 = v290;
      DataFrame.subscript.getter(v320._countAndFlagsBits, v185);
      uint64_t v203 = AnyColumn.wrappedElementType.getter();
      (*(void (**)(void *, uint64_t))(v288 + 8))(v202, v289);
      uint64_t v204 = _typeName(_:qualified:)(v203, 0);
      LOBYTE(v203) = (_BYTE)v205;
      v201._uint64_t countAndFlagsBits = v204;
      v201._char object = v205;
      String.append(_:)(v201);
      swift_bridgeObjectRelease(v203);
      v201._uint64_t countAndFlagsBits = 46;
      v201._char object = (void *)0xE100000000000000;
      String.append(_:)(v201);
      long long v321 = v319;
      v201._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v201._object, 0, 0);
      *(_OWORD *)uint64_t v206 = v321;
      *(_OWORD *)(v206 + 16) = 0;
      *(_OWORD *)(v206 + 32) = 0;
      *(unsigned char *)(v206 + 48) = 1;
      swift_willThrow(&type metadata for MLCreateError, v201._object, v206, v207, v208, v209);
      uint64_t v190 = (uint64_t)v297;
    }
    (*(void (**)(uint64_t, uint64_t))(v309 + 8))(v190, v317);
    (*(void (**)(void *, uint64_t))(v316 + 8))(v301, v315);
    goto LABEL_19;
  }
  ((void (*)(void *, uint64_t, char *))v313[4])(v310, v100, v318);
  uint64_t v101 = *v94;
  uint64_t v102 = (void *)v94[1];
  v103._uint64_t countAndFlagsBits = *v94;
  v103._char object = v102;
  if ((specialized DataFrame.containsColumn<A>(_:_:)(v103) & 1) == 0)
  {
    swift_bridgeObjectRelease(v320._object);
    *(void *)&long long v319 = 0;
    *((void *)&v319 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(60);
    v131._uint64_t countAndFlagsBits = 0x6320736C6562614CLL;
    v131._char object = (void *)0xEF27206E6D756C6FLL;
    String.append(_:)(v131);
    swift_bridgeObjectRetain((_BYTE)v102);
    v131._uint64_t countAndFlagsBits = v101;
    v131._char object = v102;
    String.append(_:)(v131);
    swift_bridgeObjectRelease((_BYTE)v102);
    v131._uint64_t countAndFlagsBits = 0xD000000000000028;
    v131._char object = "must contain a '" + 0x8000000000000000;
    String.append(_:)(v131);
    uint64_t v132 = v290;
    DataFrame.subscript.getter(v101, v102);
    uint64_t v133 = AnyColumn.wrappedElementType.getter();
    (*(void (**)(void *, uint64_t))(v288 + 8))(v132, v289);
    uint64_t v134 = _typeName(_:qualified:)(v133, 0);
    LOBYTE(v133) = (_BYTE)v135;
    v131._uint64_t countAndFlagsBits = v134;
    v131._char object = v135;
    String.append(_:)(v131);
    swift_bridgeObjectRelease(v133);
    v131._uint64_t countAndFlagsBits = 46;
    v131._char object = (void *)0xE100000000000000;
    String.append(_:)(v131);
    long long v321 = v319;
    v131._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v131._object, 0, 0);
    *(_OWORD *)uint64_t v136 = v321;
    *(_OWORD *)(v136 + 16) = 0;
    *(_OWORD *)(v136 + 32) = 0;
    *(unsigned char *)(v136 + 48) = 1;
    swift_willThrow(&type metadata for MLCreateError, v131._object, v136, v137, v138, v139);
LABEL_21:
    uint64_t v140 = v310;
    uint64_t v141 = v318;
    uint64_t v142 = v313;
    return ((uint64_t (*)(void *, char *))v142[1])(v140, v141);
  }
  uint64_t v104 = v285;
  uint64_t v105 = v101;
  uint64_t v106 = v321;
  DataFrame.subscript.getter(v105, v102, &type metadata for Int);
  *(void *)&long long v319 = 0;
  uint64_t v107 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Int> and conformance Column<A>, &demangling cache variable for type metadata for Column<Int>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v108 = v271;
  uint64_t v302 = v107;
  OptionalColumnProtocol.filled(with:)(&v319, v271, v107);
  uint64_t v109 = v104;
  uint64_t v110 = *(void **)(v266 + 8);
  ((void (*)(void *, uint64_t))v110)(v109, v108);
  uint64_t v111 = (uint64_t)v300;
  uint64_t v112 = v106;
  char v113 = (char)v320._object;
  uint64_t v114 = (uint64_t)v322;
  specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(v112, 0, (uint64_t)v320._object, 0xD000000000000013, (uint64_t)("raining samples." + 0x8000000000000000));
  v322 = (Swift::String *)v114;
  if (v114)
  {
    swift_bridgeObjectRelease(v113);
    uint64_t v115 = v306;
    uint64_t v116 = v299;
LABEL_14:
    (*(void (**)(void *, uint64_t))(v303 + 8))(v115, v116);
    return ((uint64_t (*)(void *, char *))v313[1])(v310, v318);
  }
  uint64_t v298 = "raining samples." + 0x8000000000000000;
  v311 = (char *)v110;
  uint64_t v152 = (char *)static MLSupportVectorClassifier.Model.buildFeatures(from:)(v111);
  uint64_t v153 = v268;
  *uint64_t v268 = v152;
  uint64_t v154 = *(void **)(v303 + 16);
  ((void (*)(char *, void *, uint64_t))v154)((char *)v153 + *(int *)(v274 + 52), v306, v299);
  uint64_t v155 = (uint64_t)v322;
  *(void *)&long long v321 = _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySay6CoreML13MLShapedArrayVySdGG11TabularData12FilledColumnVyAM0M0VySiGGG_18CreateMLComponents16AnnotatedFeatureVyAKSiGs5NeverOTg503_s6f4ML13hi9VySdGSi18n14MLComponents16pqu22ADSiGIegnyr_AD_SitAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSiGAY_Sitcfu2_Tf3nnnpf_nTf1cn_nTm((uint64_t)v153);
  v322 = (Swift::String *)v155;
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v153, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>);
  uint64_t v156 = (uint64_t)v269;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v320._countAndFlagsBits, (uint64_t)v269, &demangling cache variable for type metadata for DataFrame?);
  uint64_t v157 = v317;
  if (__swift_getEnumTagSinglePayload(v156, 1, v317) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v156, &demangling cache variable for type metadata for DataFrame?);
    *(void *)&long long v319 = v321;
    uint64_t v158 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, Int>]);
    uint64_t v159 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Double>, Int>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, Int>], (uint64_t)&protocol conformance descriptor for [A]);
    uint64_t v160 = v310;
    uint64_t v161 = (uint64_t)v322;
    uint64_t v162 = v318;
    LinearSupportVectorClassifier.fitted<A>(to:eventHandler:)(&v319, v292, v291, v318, v158, v159);
    if (v161)
    {
      swift_bridgeObjectRelease(v320._object);
      (*(void (**)(void *, uint64_t))(v316 + 8))(v300, v315);
      (*(void (**)(void *, uint64_t))(v303 + 8))(v306, v299);
      uint64_t v163 = v160;
      uint64_t v164 = v162;
      uint64_t v165 = v313;
LABEL_31:
      ((void (*)(void *, char *))v165[1])(v163, v164);
      return swift_bridgeObjectRelease(v321);
    }
    v322 = 0;
    (*(void (**)(void *, uint64_t))(v316 + 8))(v300, v315);
    (*(void (**)(void *, uint64_t))(v303 + 8))(v306, v299);
    ((void (*)(void *, char *))v313[1])(v160, v162);
    swift_bridgeObjectRelease(v321);
    uint64_t v210 = *v305;
    uint64_t v211 = v305[1];
    uint64_t v212 = type metadata accessor for MLSupportVectorClassifier.Model(0);
    Swift::String v213 = v293;
    double v214 = (char *)v293 + *(int *)(v212 + 24);
    uint64_t v215 = v214;
    uint64_t v216 = v277;
    goto LABEL_42;
  }
  v312 = v154;
  uint64_t v178 = (uint64_t)v296;
  (*(void (**)(void *, uint64_t, uint64_t))(v309 + 32))(v296, v156, v157);
  v179._char object = (void *)v305[1];
  v320._uint64_t countAndFlagsBits = *v305;
  v179._uint64_t countAndFlagsBits = v320._countAndFlagsBits;
  uint64_t v180 = v179._object;
  if ((specialized DataFrame.containsColumn<A>(_:_:)(v179) & 1) == 0)
  {
    swift_bridgeObjectRelease(v321);
    swift_bridgeObjectRelease(v320._object);
    *(void *)&long long v319 = 0;
    *((void *)&v319 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(71);
    v191._uint64_t countAndFlagsBits = 0xD00000000000001ALL;
    v191._char object = "ntegers but it contains " + 0x8000000000000000;
    String.append(_:)(v191);
    char v192 = v180;
    swift_bridgeObjectRetain((_BYTE)v180);
    v191._uint64_t countAndFlagsBits = v320._countAndFlagsBits;
    v191._char object = v180;
    String.append(_:)(v191);
    swift_bridgeObjectRelease((_BYTE)v180);
    v191._char object = "must contain a '" + 0x8000000000000000;
    v191._uint64_t countAndFlagsBits = 0xD000000000000028;
    String.append(_:)(v191);
    uint64_t v193 = v290;
    DataFrame.subscript.getter(v320._countAndFlagsBits, v192);
    uint64_t v194 = AnyColumn.wrappedElementType.getter();
    (*(void (**)(void *, uint64_t))(v288 + 8))(v193, v289);
    uint64_t v195 = _typeName(_:qualified:)(v194, 0);
    LOBYTE(v194) = (_BYTE)v196;
    v191._uint64_t countAndFlagsBits = v195;
    v191._char object = v196;
    String.append(_:)(v191);
    swift_bridgeObjectRelease(v194);
    v191._uint64_t countAndFlagsBits = 46;
    v191._char object = (void *)0xE100000000000000;
    String.append(_:)(v191);
    long long v321 = v319;
    v191._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v191._object, 0, 0);
    *(_OWORD *)uint64_t v197 = v321;
    *(_OWORD *)(v197 + 16) = 0;
    *(_OWORD *)(v197 + 32) = 0;
    *(unsigned char *)(v197 + 48) = 1;
    swift_willThrow(&type metadata for MLCreateError, v191._object, v197, v198, v199, v200);
    (*(void (**)(void *, uint64_t))(v309 + 8))(v296, v317);
    (*(void (**)(void *, uint64_t))(v316 + 8))(v300, v315);
    (*(void (**)(void *, uint64_t))(v303 + 8))(v306, v299);
    goto LABEL_21;
  }
  v314 = v179._object;
  char v181 = (char)v320._object;
  uint64_t v182 = (uint64_t)v322;
  specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(v178, 0, (uint64_t)v320._object, 0xD000000000000013, (uint64_t)v298);
  v322 = (Swift::String *)v182;
  uint64_t v183 = v299;
  if (v182)
  {
    swift_bridgeObjectRelease(v321);
    swift_bridgeObjectRelease(v181);
    (*(void (**)(uint64_t, uint64_t))(v309 + 8))(v178, v317);
    (*(void (**)(void *, uint64_t))(v316 + 8))(v300, v315);
    uint64_t v115 = v306;
    uint64_t v116 = v183;
    goto LABEL_14;
  }
  uint64_t v298 = (char *)static MLSupportVectorClassifier.Model.buildFeatures(from:)((uint64_t)v294);
  DataFrame.subscript.getter(v320._countAndFlagsBits, v314, &type metadata for Int);
  *(void *)&long long v319 = 0;
  uint64_t v225 = v271;
  uint64_t v226 = v285;
  OptionalColumnProtocol.filled(with:)(&v319, v271, v302);
  ((void (*)(void *, uint64_t))v311)(v226, v225);
  void *v153 = v298;
  uint64_t v227 = v299;
  ((void (*)(char *, void *))v312)((char *)v153 + *(int *)(v274 + 52), v295);
  uint64_t v228 = (uint64_t)v322;
  MLComponents16AnnotatedFeatureVyAKSiGs5NeverOTg503_s6f4ML13hi9VySdGSi18n14MLComponents16pqu22ADSiGIegnyr_AD_SitAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSiGAY_Sitcfu2_Tf3nnnpf_nTf1cn_nTm = _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySay6CoreML13MLShapedArrayVySdGG11TabularData12FilledColumnVyAM0M0VySiGGG_18CreateMLComponents16AnnotatedFeatureVyAKSiGs5NeverOTg503_s6f4ML13hi9VySdGSi18n14MLComponents16pqu22ADSiGIegnyr_AD_SitAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSiGAY_Sitcfu2_Tf3nnnpf_nTf1cn_nTm((uint64_t)v153);
  v320._uint64_t countAndFlagsBits = v228;
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v153, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>);
  *(void *)&long long v319 = v321;
  uint64_t v302 = (uint64_t)MLComponents16AnnotatedFeatureVyAKSiGs5NeverOTg503_s6f4ML13hi9VySdGSi18n14MLComponents16pqu22ADSiGIegnyr_AD_SitAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSiGAY_Sitcfu2_Tf3nnnpf_nTf1cn_nTm;
  uint64_t v262 = MLComponents16AnnotatedFeatureVyAKSiGs5NeverOTg503_s6f4ML13hi9VySdGSi18n14MLComponents16pqu22ADSiGIegnyr_AD_SitAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSiGAY_Sitcfu2_Tf3nnnpf_nTf1cn_nTm;
  uint64_t v230 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, Int>]);
  uint64_t v231 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Double>, Int>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, Int>], (uint64_t)&protocol conformance descriptor for [A]);
  uint64_t v232 = v320._countAndFlagsBits;
  LinearSupportVectorClassifier.fitted<A, B>(to:validateOn:eventHandler:)(&v319, &v262, v292, v291, v318, v230, v230, v231, v231);
  v322 = (Swift::String *)v232;
  if (!v232)
  {
    v251 = *(void (**)(void *, uint64_t))(v303 + 8);
    uint64_t v252 = v227;
    v251(v295, v227);
    uint64_t v253 = *(void (**)(void *, uint64_t))(v316 + 8);
    uint64_t v254 = v315;
    v253(v294, v315);
    (*(void (**)(void *, uint64_t))(v309 + 8))(v296, v317);
    v253(v300, v254);
    v251(v306, v252);
    ((void (*)(void *, char *))v313[1])(v310, v318);
    swift_bridgeObjectRelease(v321);
    swift_bridgeObjectRelease(v302);
    uint64_t v210 = *v305;
    uint64_t v211 = v305[1];
    uint64_t v255 = type metadata accessor for MLSupportVectorClassifier.Model(0);
    Swift::String v213 = v293;
    double v214 = (char *)v293 + *(int *)(v255 + 24);
    uint64_t v215 = v214;
    uint64_t v216 = v283;
LABEL_42:
    (*(void (**)(char *, void *, uint64_t))(v279 + 32))(v215, v216, v280);
    uint64_t v217 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
    uint64_t v218 = 1;
    uint64_t v219 = v214;
    uint64_t v220 = v217;
LABEL_45:
    swift_storeEnumTagMultiPayload(v219, v220, v218);
    *Swift::String v213 = v210;
    v213[1] = v211;
    v213[2] = (uint64_t)v320._object;
    v213[3] = 0xD000000000000013;
    v213[4] = (uint64_t)("raining samples." + 0x8000000000000000);
    return swift_bridgeObjectRetain(v211);
  }
  swift_bridgeObjectRelease(v320._object);
  Swift::String v233 = *(void (**)(void *, uint64_t))(v303 + 8);
  uint64_t v234 = v227;
  v233(v295, v227);
  Swift::String v235 = *(void (**)(void *, uint64_t))(v316 + 8);
  uint64_t v236 = v315;
  v235(v294, v315);
  (*(void (**)(void *, uint64_t))(v309 + 8))(v296, v317);
  v235(v300, v236);
  v233(v306, v234);
  ((void (*)(void *, char *))v313[1])(v310, v318);
  swift_bridgeObjectRelease(v321);
  char v237 = v302;
  return swift_bridgeObjectRelease(v237);
}

uint64_t MLSupportVectorClassifier.Classifier.encode(_:to:)(uint64_t a1, uint64_t a2)
{
  uint64_t v70 = v2;
  uint64_t v53 = v3;
  uint64_t v60 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>);
  uint64_t v59 = *(void *)(v60 - 8);
  int64_t v4 = *(void *)(v59 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v56 = &v48;
  uint64_t v66 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>);
  uint64_t v67 = *(void *)(v66 - 8);
  int64_t v7 = *(void *)(v67 + 64);
  uint64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  unint64_t v64 = &v48;
  uint64_t v62 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>);
  uint64_t v61 = *(void *)(v62 - 8);
  int64_t v10 = *(void *)(v61 + 64);
  uint64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  uint64_t v57 = &v48;
  uint64_t v68 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>);
  uint64_t v71 = *(void *)(v68 - 8);
  int64_t v13 = *(void *)(v71 + 64);
  uint64_t v14 = alloca(v13);
  int64_t v15 = alloca(v13);
  uint64_t v63 = &v48;
  uint64_t v54 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  int64_t v16 = *(void *)(*(void *)(v54 - 8) + 64);
  uint64_t v17 = alloca(v16);
  int64_t v18 = alloca(v16);
  double v58 = &v48;
  int64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v69 = &v48;
  uint64_t v55 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>, Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>));
  int64_t v21 = *(void *)(*(void *)(v55 - 8) + 64);
  char v22 = alloca(v21);
  int64_t v23 = alloca(v21);
  uint64_t v72 = &v48;
  long long v24 = *(_OWORD *)(a1 + 16);
  uint64_t v52 = a1;
  uint64_t v25 = *(void *)(a1 + 32);
  long long v49 = v24;
  uint64_t v50 = v25;
  uint64_t v26 = *(void *)(a2 + 24);
  uint64_t v51 = *(void *)(a2 + 32);
  uint64_t v65 = a2;
  __swift_mutable_project_boxed_opaque_existential_1(a2, v26);
  uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
  uint64_t v28 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer, &demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer, (uint64_t)&protocol conformance descriptor for FeatureVectorizer<A>.Transformer);
  uint64_t v29 = v70;
  uint64_t result = ((uint64_t (*)(long long *, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))dispatch thunk of EstimatorEncoder.encode<A>(_:))(&v49, v27, v28, v26, v51, v30, v48);
  if (!v29)
  {
    uint64_t v70 = 0;
    uint64_t v32 = *(int *)(type metadata accessor for MLSupportVectorClassifier.Classifier(0) + 28) + v53;
    uint64_t v33 = *(int *)(type metadata accessor for MLSupportVectorClassifier.Model(0) + 24) + v52;
    uint64_t v34 = (uint64_t)v72;
    uint64_t v35 = (uint64_t)v72 + *(int *)(v55 + 48);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v32, (uint64_t)v72, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v33, v35, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
    if (swift_getEnumCaseMultiPayload(v34, v54) == 1)
    {
      uint64_t v36 = (uint64_t)v58;
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v72, (uint64_t)v58, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
      uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
      if (swift_getEnumCaseMultiPayload(v35, v37) == 1)
      {
        uint64_t v38 = v36;
        uint64_t v39 = v66;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v67 + 32))(v64, v38, v66);
        int64_t v40 = v56;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v59 + 32))(v56, v35, v60);
        LinearSupportVectorClassifier.encode(_:to:)(v40, v65, v39);
        (*(void (**)(uint64_t *, uint64_t))(v59 + 8))(v40, v60);
        uint64_t v41 = v64;
        uint64_t v42 = v39;
        uint64_t v43 = v67;
LABEL_7:
        (*(void (**)(uint64_t *, uint64_t))(v43 + 8))(v41, v42);
        return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v72, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
      }
      uint64_t v71 = v67;
      uint64_t v68 = v66;
      uint64_t v69 = (uint64_t *)v36;
    }
    else
    {
      uint64_t v44 = (uint64_t)v69;
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v72, (uint64_t)v69, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
      uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
      if (swift_getEnumCaseMultiPayload(v35, v45) != 1)
      {
        uint64_t v46 = v68;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v71 + 32))(v63, v44, v68);
        uint64_t v47 = v57;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v61 + 32))(v57, v35, v62);
        LinearSupportVectorClassifier.encode(_:to:)(v47, v65, v46);
        (*(void (**)(uint64_t *, uint64_t))(v61 + 8))(v47, v62);
        uint64_t v41 = v63;
        uint64_t v42 = v46;
        uint64_t v43 = v71;
        goto LABEL_7;
      }
    }
    (*(void (**)(uint64_t *, uint64_t))(v71 + 8))(v69, v68);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000002FLL, "Classifier.Classifier.swift" + 0x8000000000000000, "CreateML/MLSupportVectorClassifier.Classifier.swift", 51, 2, 175, 0);
    BUG();
  }
  return result;
}

uint64_t MLSupportVectorClassifier.Classifier.decode(from:)(uint64_t a1)
{
  uint64_t v71 = v2;
  uint64_t v73 = v3;
  unint64_t v64 = v1;
  uint64_t v58 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>);
  uint64_t v57 = *(void *)(v58 - 8);
  int64_t v4 = *(void *)(v57 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v66 = v49;
  uint64_t v50 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>);
  uint64_t v54 = *(void *)(v50 - 8);
  int64_t v7 = *(void *)(v54 + 64);
  uint64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  uint64_t v51 = v49;
  uint64_t v60 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>);
  uint64_t v61 = *(void *)(v60 - 8);
  int64_t v10 = *(void *)(v61 + 64);
  uint64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  uint64_t v67 = v49;
  uint64_t v68 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
  int64_t v13 = *(void *)(*(void *)(v68 - 8) + 64);
  uint64_t v14 = alloca(v13);
  int64_t v15 = alloca(v13);
  uint64_t v62 = v49;
  int64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v59 = v49;
  uint64_t v56 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>);
  uint64_t v55 = *(void *)(v56 - 8);
  int64_t v18 = *(void *)(v55 + 64);
  int64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v53 = v49;
  uint64_t v52 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  int64_t v21 = *(void *)(*(void *)(v52 - 8) + 64);
  char v22 = alloca(v21);
  int64_t v23 = alloca(v21);
  uint64_t v72 = v49;
  uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
  uint64_t v25 = *(void *)(a1 + 24);
  uint64_t v26 = *(void *)(a1 + 32);
  uint64_t v65 = a1;
  __swift_mutable_project_boxed_opaque_existential_1(a1, v25);
  uint64_t v27 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer, &demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer, (uint64_t)&protocol conformance descriptor for FeatureVectorizer<A>.Transformer);
  uint64_t v28 = v71;
  uint64_t result = dispatch thunk of EstimatorDecoder.decode<A>(_:)(v24, v24, v27, v25, v26);
  if (!v28)
  {
    uint64_t v30 = v53;
    int64_t v31 = v51;
    uint64_t v32 = v50;
    uint64_t v71 = 0;
    uint64_t v69 = v49[1];
    uint64_t v63 = v49[2];
    uint64_t v70 = v49[3];
    uint64_t v33 = type metadata accessor for MLSupportVectorClassifier.Classifier(0);
    uint64_t v34 = (uint64_t)v72;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v73 + *(int *)(v33 + 28), (uint64_t)v72, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    if (swift_getEnumCaseMultiPayload(v34, v52) == 1)
    {
      uint64_t v35 = v54;
      (*(void (**)(void *, void *, uint64_t))(v54 + 32))(v31, v72, v32);
      uint64_t v72 = (void *)*v73;
      uint64_t v73 = (uint64_t *)v73[1];
      swift_bridgeObjectRetain((_BYTE)v73);
      uint64_t v36 = v71;
      LinearSupportVectorClassifier.decode(from:)(v65, v32);
      (*(void (**)(void *, uint64_t))(v35 + 8))(v31, v32);
      uint64_t v37 = v64;
      if (!v36)
      {
        uint64_t v38 = (uint64_t)v72;
        uint64_t v39 = (uint64_t)v62;
        (*(void (**)(void *, void *, uint64_t))(v57 + 32))(v62, v66, v58);
        uint64_t v40 = 1;
        uint64_t v41 = v39;
        uint64_t v42 = v68;
LABEL_8:
        swift_storeEnumTagMultiPayload(v41, v42, v40);
        *uint64_t v37 = v38;
        v37[1] = (uint64_t)v73;
        int v37[2] = v69;
        v37[3] = v63;
        v37[4] = v70;
        uint64_t v48 = type metadata accessor for MLSupportVectorClassifier.Model(0);
        return outlined init with take of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(v39, (uint64_t)v37 + *(int *)(v48 + 24), &demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
      }
    }
    else
    {
      uint64_t v43 = v30;
      uint64_t v44 = v30;
      uint64_t v45 = v56;
      uint64_t v46 = v55;
      (*(void (**)(void *, void *, uint64_t))(v55 + 32))(v44, v72, v56);
      uint64_t v72 = (void *)*v73;
      uint64_t v73 = (uint64_t *)v73[1];
      swift_bridgeObjectRetain((_BYTE)v73);
      uint64_t v47 = v71;
      LinearSupportVectorClassifier.decode(from:)(v65, v45);
      (*(void (**)(void *, uint64_t))(v46 + 8))(v43, v45);
      uint64_t v37 = v64;
      if (!v47)
      {
        uint64_t v38 = (uint64_t)v72;
        uint64_t v39 = (uint64_t)v59;
        (*(void (**)(void *, void *, uint64_t))(v61 + 32))(v59, v67, v60);
        uint64_t v41 = v39;
        uint64_t v42 = v68;
        uint64_t v40 = 0;
        goto LABEL_8;
      }
    }
    swift_bridgeObjectRelease(v70);
    swift_bridgeObjectRelease(v69);
    return swift_bridgeObjectRelease((_BYTE)v73);
  }
  return result;
}

uint64_t protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  MLSupportVectorClassifier.Classifier.fitted(to:validateOn:eventHandler:)(a2, a3, a4, a5);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(*(uint64_t (**)(void))(v5 + 8));
}

uint64_t protocol witness for SupervisedTabularEstimator.encode(_:to:) in conformance MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2)
{
  return MLSupportVectorClassifier.Classifier.encode(_:to:)(a1, a2);
}

uint64_t protocol witness for SupervisedTabularEstimator.decode(from:) in conformance MLSupportVectorClassifier.Classifier(uint64_t a1)
{
  return MLSupportVectorClassifier.Classifier.decode(from:)(a1);
}

uint64_t outlined init with copy of MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLSupportVectorClassifier.Classifier(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined destroy of MLSupportVectorClassifier.Classifier(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLSupportVectorClassifier.Classifier(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t outlined init with copy of MLSupportVectorClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  (*(void (**)(uint64_t, uint64_t))(*((void *)&type metadata for MLSupportVectorClassifier.ModelParameters - 1)
                                           + 16))(a2, a1);
  return a2;
}

uint64_t outlined init with take of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(a3);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v3 - 8) + 32))(a2, a1, v3);
  return a2;
}

uint64_t MLHandActionClassifier.GraphCNN.iterateTraining(trainingData:validationData:epochCount:)(uint64_t a1, uint64_t a2, Swift::Int a3, double a4)
{
  int64_t v9 = _swiftEmptyDictionarySingleton;
  closure #1 in MLHandActionClassifier.GraphCNN.iterateTraining(trainingData:validationData:epochCount:)(v5, a1, (uint64_t)&v9, a3, a2, a4);
  if (v4) {
    return swift_bridgeObjectRelease((_BYTE)v9);
  }
  else {
    return (uint64_t)v9;
  }
}

uint64_t MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)(v4 + 112) = v3;
  uint64_t v5 = type metadata accessor for Event(0, a2, a3);
  *(void *)(v4 + 120) = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  *(void *)(v4 + 128) = v6;
  *(void *)(v4 + 136) = swift_task_alloc((*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for MetricsKey(0);
  *(void *)(v4 + 144) = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  *(void *)(v4 + 152) = v8;
  *(void *)(v4 + 160) = swift_task_alloc((*(void *)(v8 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v9 = type metadata accessor for Tensor(0);
  *(void *)(v4 + 168) = v9;
  uint64_t v10 = *(void *)(v9 - 8);
  *(void *)(v4 + 176) = v10;
  *(void *)(v4 + 184) = swift_task_alloc((*(void *)(v10 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v11 = (*(void *)(*(void *)(type metadata accessor for MLClassifierMetrics(0) - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  *(void *)(v4 + 192) = swift_task_alloc(v11);
  *(void *)(v4 + 200) = swift_task_alloc(v11);
  uint64_t v12 = type metadata accessor for TrainingTablePrinter(0);
  *(void *)(v4 + 208) = v12;
  *(void *)(v4 + 216) = swift_task_alloc((*(void *)(*(void *)(v12 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MetricsKey?);
  *(void *)(v4 + 224) = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);
  *(void *)(v4 + 232) = swift_task_alloc((*(void *)(*(void *)(v14 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
  *(void *)(v4 + 240) = v15;
  uint64_t v16 = *(void *)(v15 - 8);
  *(void *)(v4 + 248) = v16;
  *(void *)(v4 + 256) = swift_task_alloc((*(void *)(v16 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  *(void *)(v4 + 264) = *(void *)a1;
  *(unsigned char *)(v4 + 304) = *(unsigned char *)(a1 + 8);
  *(void *)(v4 + 272) = *(void *)a2;
  *(unsigned char *)(v4 + 305) = *(unsigned char *)(a2 + 8);
  return swift_task_switch(MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:), 0, 0);
}

uint64_t MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:)(double a1)
{
  uint64_t v116 = v1 | 0x1000000000000000;
  uint64_t v115 = v2;
  char v3 = *((unsigned char *)v2 + 305);
  uint64_t v4 = v2[34];
  char v5 = *((unsigned char *)v2 + 304);
  uint64_t v6 = v2[33];
  uint64_t v114 = (void *)v2[32];
  uint64_t v7 = (void **)v2[14];
  uint64_t v113 = v2[29];
  uint64_t v8 = *v7;
  uint64_t v86 = v6;
  char v87 = v5;
  *(void *)&long long v105 = v4;
  BYTE8(v105) = v3;
  uint64_t v9 = type metadata accessor for MLHandActionClassifier(0);
  uint64_t v10 = (uint64_t)v7 + *(int *)(v9 + 28);
  static MLHandActionClassifier.prepareDataset(classLabels:trainingFeatures:validationFeatures:parameters:)((uint64_t)v114, v113, v8, (uint64_t)&v86, (uint64_t)&v105, v10, a1);
  uint64_t v113 = v10;
  uint64_t v110 = v9;
  uint64_t v11 = v2[14];
  MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel()();
  if (v12)
  {
    *(void *)&long long v111 = v12;
    uint64_t v15 = v2[29];
    (*(void (**)(void, void))(v2[31] + 8))(v2[32], v2[30]);
    uint64_t v16 = v15;
LABEL_3:
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v16, &demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);
    uint64_t v17 = v2[32];
    uint64_t v18 = v2[29];
    uint64_t v19 = v2[28];
    uint64_t v20 = v2[27];
    uint64_t v21 = v2[25];
    uint64_t v110 = v2[24];
    Swift::Int v112 = v2[23];
    uint64_t v114 = (void *)v2[17];
    uint64_t v113 = v2[20];
    swift_task_dealloc(v17);
    swift_task_dealloc(v18);
    swift_task_dealloc(v19);
    swift_task_dealloc(v20);
    swift_task_dealloc(v21);
    swift_task_dealloc(v110);
    swift_task_dealloc(v112);
    swift_task_dealloc(v113);
    swift_task_dealloc(v114);
    return ((uint64_t (*)(void))v2[1])();
  }
  uint64_t v107 = v11;
  Swift::Int v112 = v2[30];
  uint64_t v114 = v2;
  uint64_t v23 = v2[18];
  uint64_t v24 = v2[29];
  MLHandActionClassifier.GraphCNN.initDevice()();
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MetricsKey)>);
  uint64_t v26 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, MetricsKey))
                  - 8);
  uint64_t v27 = *(unsigned __int8 *)(v26 + 80);
  uint64_t v28 = ((int)v27 + 32) & ~*(unsigned __int8 *)(v26 + 80);
  uint64_t v29 = swift_allocObject(v25, v28 + *(void *)(v26 + 72), v27 | 7);
  *(void *)(v29 + 16) = 1;
  *(void *)(v29 + 24) = 2;
  *(void *)(v29 + v28) = 0xD000000000000011;
  *(void *)(v29 + v28 + 8) = "eature extractor should be " + 0x8000000000000000;
  static MetricsKey.trainingAccuracy.getter();
  uint64_t v30 = v23;
  int64_t v31 = v114;
  uint64_t v32 = Dictionary.init(dictionaryLiteral:)(v29, &type metadata for String, v30, &protocol witness table for String);
  v31[10] = v32;
  if (__swift_getEnumTagSinglePayload(v24, 1, v112) != 1)
  {
    uint64_t v33 = v31[18];
    uint64_t v34 = v114[28];
    static MetricsKey.validationAccuracy.getter();
    __swift_storeEnumTagSinglePayload(v34, 0, 1, v33);
    uint64_t v35 = v34;
    int64_t v31 = v114;
    specialized Dictionary.subscript.setter(v35, 0xD000000000000013, (uint64_t)("Swift/Array.swift" + 0x8000000000000000));
    uint64_t v32 = v31[10];
  }
  uint64_t v88 = v31 + 2;
  uint64_t v91 = v31 + 6;
  uint64_t v104 = v31 + 11;
  uint64_t v89 = v31 + 12;
  uint64_t v99 = v31 + 13;
  uint64_t v36 = v31[26];
  uint64_t v37 = v31[27];
  *(void *)(v37 + *(int *)(v36 + 24)) = v32;
  type metadata accessor for OS_os_log();
  uint64_t v38 = OS_os_log.init(subsystem:category:)(0xD000000000000027, "Swift/UnsafeBufferPointer.swift" + 0x8000000000000000, 0x72705F656C626174, 0xED00007265746E69);
  uint64_t v103 = *(int *)(v36 + 20);
  *(void *)(v37 + v103) = v38;
  Date.init()(0xD000000000000027);
  uint64_t v102 = v37;
  TrainingTablePrinter.beginTable()();
  uint64_t v39 = *(void *)(v113 + *(int *)(type metadata accessor for MLHandActionClassifier.ModelParameters(0) + 24));
  uint64_t v94 = v39;
  if (v39 < 0) {
    BUG();
  }
  if (v39)
  {
    uint64_t v95 = v31[22];
    uint64_t v97 = v31[16];
    uint64_t v101 = v31[19];
    Swift::Int v40 = 0;
    uint64_t v92 = 0xD000000000000012;
    uint64_t v93 = "oseClassifier.swift" + 0x8000000000000000;
    uint64_t v106 = (char *)&type metadata for Any + 8;
    uint64_t v96 = "ve training confusion matrix" + 0x8000000000000000;
    uint64_t v98 = "usion matrix at iteration " + 0x8000000000000000;
    while (1)
    {
      uint64_t v41 = MLHandActionClassifier.GraphCNN.iterateTraining(trainingData:validationData:epochCount:)(v31[32], v31[29], v40, *(double *)v13.i64);
      Swift::Int v112 = v40;
      uint64_t v42 = (uint64_t)v88;
      specialized Dictionary.subscript.getter(v92, (uint64_t)v93, v41);
      if (!v31[5])
      {
        swift_bridgeObjectRelease(v41);
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v42, &demangling cache variable for type metadata for Any?);
        goto LABEL_19;
      }
      uint64_t v43 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
      if (!swift_dynamicCast(v89, v42, v106, v43, 6)) {
        break;
      }
      uint64_t v109 = v43;
      uint64_t v44 = v31[12];
      static _MetricUtilities.makeClassifierMetrics(confusionMeter:classLabels:)(*(double *)v13.i64, v14, v44, *(void *)v31[14]);
      uint64_t v45 = v31[25];
      uint64_t v46 = v31[23];
      uint64_t v47 = v31[21];
      uint64_t v48 = (uint64_t *)v114[14];
      uint64_t v113 = v114[18];
      outlined assign with take of MLClassifierMetrics(v45, (uint64_t)v48 + *(int *)(v110 + 32));
      uint64_t v108 = v44;
      _MetricUtilities.ConfusionMatrixMeter.value(normalized:)(0, *(double *)v13.i64, v14);
      uint64_t v49 = *v48;
      uint64_t v50 = v114;
      *(void *)&long long v111 = static _MetricUtilities.top1Accuracy(confusionMatrix:classCount:)(v46, *(void *)(v49 + 16));
      uint64_t v90 = *(void (**)(uint64_t, uint64_t))(v95 + 8);
      v90(v46, v47);
      uint64_t v51 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(MetricsKey, Double)>);
      uint64_t v52 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MetricsKey, Double));
      uint64_t v53 = *(void *)(v52 - 8);
      uint64_t v54 = *(unsigned __int8 *)(v53 + 80);
      uint64_t v55 = ((int)v54 + 32) & ~*(unsigned __int8 *)(v53 + 80);
      uint64_t v56 = swift_allocObject(v51, v55 + *(void *)(v53 + 72), v54 | 7);
      *(void *)(v56 + 16) = 1;
      *(void *)(v56 + 24) = 2;
      uint64_t v57 = *(int *)(v52 + 48);
      static MetricsKey.trainingAccuracy.getter();
      __m128 v13 = (__m128)(unint64_t)v111;
      *(void *)(v57 + v56 + v55) = v111;
      uint64_t v58 = lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, (uint64_t (*)(uint64_t))&type metadata accessor for MetricsKey, (uint64_t)&protocol conformance descriptor for MetricsKey);
      uint64_t v113 = Dictionary.init(dictionaryLiteral:)(v56, v113, &type metadata for Double, v58);
      uint64_t v59 = (uint64_t)v91;
      specialized Dictionary.subscript.getter(0xD000000000000014, (uint64_t)v96, v41);
      swift_bridgeObjectRelease(v41);
      if (v50[9])
      {
        if (swift_dynamicCast(v99, v59, v106, v109, 6))
        {
          static _MetricUtilities.makeClassifierMetrics(confusionMeter:classLabels:)(*(double *)v13.i64, v14, v50[13], *(void *)v50[14]);
          uint64_t v60 = v50[24];
          uint64_t v61 = v50[23];
          uint64_t v109 = v50[21];
          uint64_t v62 = v114[20];
          uint64_t v63 = v114[14];
          *(void *)&long long v111 = v114[18];
          outlined assign with take of MLClassifierMetrics(v60, v63 + *(int *)(v110 + 36));
          double v64 = static MetricsKey.validationAccuracy.getter();
          _MetricUtilities.ConfusionMatrixMeter.value(normalized:)(0, v64, v14);
          double v100 = static _MetricUtilities.top1Accuracy(confusionMatrix:classCount:)(v61, *(void *)(*(void *)v63 + 16));
          v90(v61, v109);
          uint64_t v65 = v113;
          unsigned __int8 isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v113);
          *(void *)&long long v105 = v65;
          __m128 v13 = (__m128)*(unint64_t *)&v100;
          specialized _NativeDictionary.setValue(_:forKey:isUnique:)(v62, isUniquelyReferenced_nonNull_native, v100);
          uint64_t v113 = v105;
          swift_bridgeObjectRelease(0);
          (*(void (**)(uint64_t, void))(v101 + 8))(v62, v111);
          swift_release();
        }
      }
      else
      {
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v59, &demangling cache variable for type metadata for Any?);
      }
      uint64_t v67 = v112;
      *(void *)&long long v111 = v112 + 1;
      uint64_t v109 = v114[15];
      uint64_t v68 = v114[17];
      char v69 = v113;
      uint64_t v70 = specialized _dictionaryUpCast<A, B, C, D>(_:)(v113);
      swift_bridgeObjectRelease(v69);
      Event.init(origin:itemCount:totalItemCount:metrics:)(0xD000000000000016, v98, v67, 0, 1, v70);
      TrainingTablePrinter.print(_:)(v68, v13);
      swift_release();
      int64_t v31 = v114;
      (*(void (**)(uint64_t, uint64_t))(v97 + 8))(v68, v109);
      Swift::Int v40 = v111;
      if (v94 == (void)v111) {
        goto LABEL_16;
      }
    }
    swift_bridgeObjectRelease(v41);
LABEL_19:
    uint64_t v75 = v112;
    uint64_t v110 = v31[32];
    Swift::Int v112 = v31[31];
    uint64_t v108 = v31[30];
    uint64_t v76 = v31[27];
    uint64_t v113 = v31[29];
    *(void *)&long long v105 = 0;
    *((void *)&v105 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(60);
    v77._uint64_t countAndFlagsBits = 0xD00000000000003ALL;
    v77._char object = "ml.handactionclassifier" + 0x8000000000000000;
    String.append(_:)(v77);
    v31[11] = v75;
    uint64_t v78 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char v80 = (char)v79;
    v77._uint64_t countAndFlagsBits = v78;
    v77._char object = v79;
    String.append(_:)(v77);
    uint64_t v2 = v114;
    swift_bridgeObjectRelease(v80);
    long long v111 = v105;
    v77._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v81 = swift_allocError(&type metadata for MLCreateError, v77._object, 0, 0);
    *(_OWORD *)uint64_t v82 = v111;
    *(_OWORD *)(v82 + 16) = 0;
    *(_OWORD *)(v82 + 32) = 0;
    *(unsigned char *)(v82 + 48) = 0;
    *(void *)&long long v111 = v81;
    swift_willThrow(&type metadata for MLCreateError, v77._object, v82, v83, v84, v85);
    outlined destroy of MLActivityClassifier.ModelParameters(v76, type metadata accessor for TrainingTablePrinter);
    (*(void (**)(uint64_t, uint64_t))(v112 + 8))(v110, v108);
    uint64_t v16 = v113;
    goto LABEL_3;
  }
LABEL_16:
  static os_log_type_t.info.getter();
  uint64_t v71 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v72 = v31;
  uint64_t v73 = (void *)swift_allocObject(v71, 72, 7);
  v73[2] = 1;
  v73[3] = 2;
  v73[7] = &type metadata for Int;
  v73[8] = &protocol witness table for Int;
  v73[4] = 3;
  os_log(_:dso:log:type:_:)("event: %lu", 10);
  swift_bridgeObjectRelease((_BYTE)v73);
  uint64_t v74 = (void *)swift_task_alloc(dword_3AEB4C);
  v72[35] = v74;
  *uint64_t v74 = v72;
  v74[1] = MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:);
  return MLHandActionClassifier.GraphCNN.compile()();
}

uint64_t MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:)(uint64_t a1)
{
  uint64_t v5 = *(void *)(*v2 + 280);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 288) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:);
  }
  else
  {
    *(void *)(v4 + 296) = a1;
    uint64_t v6 = MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:);
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:)()
{
  uint64_t v12 = *(void *)(v0 + 296);
  uint64_t v1 = *(void *)(v0 + 256);
  uint64_t v14 = *(void *)(v0 + 248);
  uint64_t v2 = *(void *)(v0 + 240);
  uint64_t v3 = *(void *)(v0 + 232);
  uint64_t v11 = *(void *)(v0 + 224);
  uint64_t v13 = *(void *)(v0 + 216);
  uint64_t v10 = *(void *)(v0 + 200);
  uint64_t v9 = *(void *)(v0 + 192);
  uint64_t v8 = *(void *)(v0 + 184);
  uint64_t v7 = *(void *)(v0 + 160);
  uint64_t v4 = *(void *)(v0 + 112);
  uint64_t v6 = *(void *)(v0 + 136);
  outlined destroy of MLActivityClassifier.ModelParameters(v13, type metadata accessor for TrainingTablePrinter);
  (*(void (**)(uint64_t, uint64_t))(v14 + 8))(v1, v2);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v3, &demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);

  *(void *)(v4 + 16) = v12;
  swift_task_dealloc(v1);
  swift_task_dealloc(v3);
  swift_task_dealloc(v11);
  swift_task_dealloc(v13);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v1 = *(void *)(v0 + 256);
  uint64_t v2 = *(void *)(v0 + 248);
  uint64_t v3 = *(void *)(v0 + 240);
  uint64_t v4 = *(void *)(v0 + 232);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 216), type metadata accessor for TrainingTablePrinter);
  (*(void (**)(uint64_t, uint64_t))(v2 + 8))(v1, v3);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v4, &demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);
  uint64_t v5 = *(void *)(v0 + 232);
  uint64_t v6 = *(void *)(v0 + 224);
  uint64_t v7 = *(void *)(v0 + 216);
  uint64_t v8 = *(void *)(v0 + 200);
  uint64_t v13 = *(void *)(v0 + 192);
  uint64_t v12 = *(void *)(v0 + 184);
  uint64_t v10 = *(void *)(v0 + 136);
  uint64_t v11 = *(void *)(v0 + 160);
  swift_task_dealloc(*(void *)(v0 + 256));
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLHandActionClassifier.GraphCNN.evaluate(_:)(void *a1)
{
  uint64_t v74 = v2;
  context = a1;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LossReduction?)
                             - 8)
                 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v58 = &v55;
  uint64_t v63 = type metadata accessor for Tensor(0);
  uint64_t v62 = *(void *)(v63 - 8);
  int64_t v6 = *(void *)(v62 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v59 = &v55;
  uint64_t v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  uint64_t v61 = &v55;
  uint64_t v11 = alloca(v6);
  uint64_t v12 = alloca(v6);
  uint64_t v60 = &v55;
  uint64_t v13 = alloca(v6);
  uint64_t v14 = alloca(v6);
  uint64_t v71 = &v55;
  uint64_t v72 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>);
  uint64_t v66 = *(void *)(v72 - 8);
  int64_t v15 = *(void *)(v66 + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v67 = &v55;
  int64_t v18 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>?)
                              - 8)
                  + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v68 = &v55;
  uint64_t v76 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>, DataSample<Tensor, Tensor>>.Iterator);
  int64_t v21 = *(void *)(*(void *)(v76 - 8) + 64);
  char v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  uint64_t v75 = &v55;
  uint64_t v24 = type metadata accessor for LearningPhase(0);
  uint64_t v25 = *(void *)(v24 - 8);
  int64_t v26 = *(void *)(v25 + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  (*(void (**)(uint64_t *, void, uint64_t))(v25 + 104))(&v55, enum case for LearningPhase.inference(_:), v24);
  swift_beginAccess(v74 + OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model, v56, 33, 0);
  uint64_t v78 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  uint64_t v29 = lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, (uint64_t)&protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  Layer.prepare(for:)(&v55, v78, v29);
  swift_endAccess(v56);
  (*(void (**)(uint64_t *, uint64_t))(v25 + 8))(&v55, v24);
  uint64_t v30 = *(void *)(*(void *)(v74 + 16) + 16);
  uint64_t v31 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
  swift_allocObject(v31, *(unsigned int *)(v31 + 48), *(unsigned __int16 *)(v31 + 52));
  uint64_t result = _MetricUtilities.ConfusionMatrixMeter.init(classCount:)(v30);
  if (!v1)
  {
    uint64_t v69 = result;
    uint64_t v65 = 0;
    uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
    uint64_t v34 = (uint64_t)v75;
    Dataset.makeIterator()(v33);
    uint64_t v64 = *(int *)(v76 + 44);
    uint64_t v76 = lazy protocol witness table accessor for type Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>.Iterator and conformance Batches<A>.Iterator();
    unsigned int v70 = enum case for LossReduction.mean(_:);
    LODWORD(v78) = 0;
    uint64_t v77 = 0;
    for (uint64_t i = v34; ; uint64_t i = (uint64_t)v75)
    {
      uint64_t v36 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>.Iterator);
      dispatch thunk of IteratorProtocol.next()(v36, v76);
      char v37 = LOBYTE(v56[0]);
      if (*(void *)v56)
      {
        uint64_t v38 = *(void (**)(void))(i + v64);
        uint64_t v57 = *(void *)v56;
        uint64_t v39 = (uint64_t)v68;
        v38(&v57);
        swift_bridgeObjectRelease(v37);
        uint64_t v40 = v39;
        uint64_t v41 = 0;
      }
      else
      {
        uint64_t v39 = (uint64_t)v68;
        uint64_t v40 = (uint64_t)v68;
        uint64_t v41 = 1;
      }
      uint64_t v42 = v72;
      __swift_storeEnumTagSinglePayload(v40, v41, 1, v72);
      uint64_t v43 = (uint64_t)v71;
      if (__swift_getEnumTagSinglePayload(v39, 1, v42) == 1) {
        break;
      }
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v66 + 32))(v67, v39, v42);
      DataSample.features.getter(v42);
      uint64_t v44 = (uint64_t)v60;
      uint64_t v45 = v42;
      uint64_t v46 = (uint64_t)v61;
      DataSample.labels.getter(v45);
      MLHandActionClassifier.GraphCNN.callAsFunction(_:)(v43);
      uint64_t v47 = type metadata accessor for LossReduction(0);
      uint64_t v48 = (uint64_t)v58;
      (*(void (**)(uint64_t *, void, uint64_t))(*(void *)(v47 - 8) + 104))(v58, v70, v47);
      __swift_storeEnumTagSinglePayload(v48, 0, 1, v47);
      uint64_t v49 = v59;
      softmaxCrossEntropy(logits:labels:labelSmoothing:axis:reduction:)(v46, v44, -1, v48, 0.0);
      uint64_t v50 = v48;
      uint64_t v51 = v49;
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v50, &demangling cache variable for type metadata for LossReduction?);
      _MetricUtilities.ConfusionMatrixMeter.add(predicted:target:)(v46, v44);
      Tensor.scalar<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
      if (__OFADD__(1, v77)) {
        BUG();
      }
      ++v77;
      *(float *)&uint64_t v78 = *(float *)&v78 + v56[0];
      uint64_t v52 = *(void (**)(void, void))(v62 + 8);
      uint64_t v53 = v51;
      uint64_t v54 = v63;
      v52(v53, v63);
      v52(v46, v54);
      v52(v44, v54);
      v52(v71, v54);
      (*(void (**)(uint64_t *, uint64_t))(v66 + 8))(v67, v72);
    }
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v75, &demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>, DataSample<Tensor, Tensor>>.Iterator);
    return v69;
  }
  return result;
}

BOOL specialized Dataset.isEmpty.getter()
{
  int64_t v0 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>?)
                             - 8)
                 + 64);
  uint64_t v1 = alloca(v0);
  uint64_t v2 = alloca(v0);
  uint64_t v20 = v19;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>, DataSample<Tensor, Tensor>>.Iterator);
  int64_t v4 = *(void *)(*(void *)(v3 - 8) + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
  Dataset.makeIterator()(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>.Iterator);
  uint64_t v9 = lazy protocol witness table accessor for type Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>.Iterator and conformance Batches<A>.Iterator();
  dispatch thunk of IteratorProtocol.next()(v8, v9);
  char v10 = v19[0];
  if (v19[0])
  {
    uint64_t v11 = *(void (**)(void))((char *)v19 + *(int *)(v3 + 44));
    v19[1] = v19[0];
    uint64_t v12 = (uint64_t)v20;
    v11();
    swift_bridgeObjectRelease(v10);
    uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>);
    uint64_t v14 = v12;
    uint64_t v15 = 0;
  }
  else
  {
    uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>);
    uint64_t v12 = (uint64_t)v20;
    uint64_t v14 = (uint64_t)v20;
    uint64_t v15 = 1;
  }
  __swift_storeEnumTagSinglePayload(v14, v15, 1, v13);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v19, &demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>, DataSample<Tensor, Tensor>>.Iterator);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v12, 1, v16);
  if (EnumTagSinglePayload != 1) {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v12, &demangling cache variable for type metadata for DataSample<Tensor, Tensor>?);
  }
  return EnumTagSinglePayload == 1;
}

Swift::Void __swiftcall MLHandActionClassifier.GraphCNN.initDevice()()
{
  uint64_t v30 = v0;
  int64_t v1 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?)
                             - 8)
                 + 64);
  uint64_t v2 = alloca(v1);
  uint64_t v3 = alloca(v1);
  uint64_t v4 = type metadata accessor for ComputeDevice(0);
  uint64_t v5 = *(void *)(v4 - 8);
  int64_t v6 = *(void *)(v5 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v9 = alloca(v6);
  char v10 = alloca(v6);
  static ComputeDevice.gpu.getter();
  if (__swift_getEnumTagSinglePayload((uint64_t)&v27, 1, v4) == 1)
  {
    static ComputeDevice.cpu.getter();
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v27, &demangling cache variable for type metadata for ComputeDevice?);
  }
  else
  {
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v5 + 32))(&v27, &v27, v4);
  }
  if (one-time initialization token for logger != -1) {
    swift_once(&one-time initialization token for logger, one-time initialization function for logger);
  }
  uint64_t v11 = type metadata accessor for Logger(0);
  __swift_project_value_buffer(v11, (uint64_t)static MLHandActionClassifier.logger);
  uint64_t v31 = &v27;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v5 + 16))(&v27, &v27, v4);
  uint64_t v12 = (os_log_s *)Logger.logObject.getter();
  uint64_t v13 = v5;
  os_log_type_t v14 = static os_log_type_t.info.getter();
  if (os_log_type_enabled(v12, v14))
  {
    uint64_t v35 = v13;
    uint64_t v15 = swift_slowAlloc(12, -1);
    os_log_t log = v12;
    uint64_t v16 = (uint8_t *)v15;
    uint64_t v32 = swift_slowAlloc(32, -1);
    v28[0] = v32;
    *(_DWORD *)uint64_t v16 = 136315138;
    uint64_t v34 = v16 + 4;
    uint64_t v17 = lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(&lazy protocol witness table cache variable for type ComputeDevice and conformance ComputeDevice, (uint64_t (*)(uint64_t))&type metadata accessor for ComputeDevice, (uint64_t)&protocol conformance descriptor for ComputeDevice);
    uint64_t v18 = dispatch thunk of CustomStringConvertible.description.getter(v4, v17);
    char v20 = v19;
    uint64_t v29 = getNullTerminatedUTF8PointerImpl(_:storingStringOwnersIn:)(v18, v19, v28);
    UnsafeMutableRawBufferPointer.copyMemory(from:)(&v29, &v30, v34, v16 + 12);
    swift_bridgeObjectRelease(v20);
    uint64_t v35 = *(void *)(v35 + 8);
    ((void (*)(uint64_t *, uint64_t))v35)(&v27, v4);
    os_log_t v21 = log;
    _os_log_impl(&dword_0, log, v14, "Using %s to create model", v16, 0xCu);
    uint64_t v22 = v32;
    swift_arrayDestroy(v32, 1, (char *)&type metadata for Any + 8);
    swift_slowDealloc(v22, -1, -1);
    swift_slowDealloc(v16, -1, -1);
    os_log_t v23 = v21;
  }
  else
  {
    uint64_t v35 = *(void *)(v13 + 8);
    ((void (*)(uint64_t *, uint64_t))v35)(&v27, v4);
    os_log_t v23 = v12;
  }

  swift_beginAccess(OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model + v30, v28, 33, 0);
  uint64_t v24 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  uint64_t v25 = lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, (uint64_t)&protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  int64_t v26 = v31;
  Layer.place(on:)(v31, v24, v25);
  swift_endAccess(v28);
  ((void (*)(uint64_t *, uint64_t))v35)(v26, v4);
}

uint64_t closure #1 in MLHandActionClassifier.GraphCNN.iterateTraining(trainingData:validationData:epochCount:)(uint64_t a1, uint64_t a2, uint64_t a3, Swift::Int a4, uint64_t a5, double a6)
{
  uint64_t v31 = v6;
  uint64_t v30 = a5;
  Swift::Int epoch = a4;
  uint64_t v25 = a3;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?)
                             - 8)
                 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  os_log_t v23 = &v20;
  uint64_t v29 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
  uint64_t v10 = *(void *)(v29 - 8);
  int64_t v11 = *(void *)(v10 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v27 = a1;
  uint64_t v14 = v31;
  uint64_t result = MLHandActionClassifier.GraphCNN.train(_:)(a2);
  if (!v14)
  {
    uint64_t v28 = &v20;
    uint64_t v31 = v10;
    uint64_t v22 = &type metadata for Double;
    v21[0] = a6;
    uint64_t v16 = result;
    specialized Dictionary.subscript.setter((uint64_t)v21, 0x676E696E69617274, 0xED000073736F6C5FLL);
    uint64_t v26 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
    uint64_t v22 = (void *)v26;
    *(void *)&v21[0] = v16;
    swift_retain();
    specialized Dictionary.subscript.setter((uint64_t)v21, 0xD000000000000012, (uint64_t)("oseClassifier.swift" + 0x8000000000000000));
    MLHandActionClassifier.GraphCNN.adjustLearningRate(epoch:)(epoch);
    uint64_t v17 = (uint64_t)v23;
    outlined init with copy of Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?(v30, (uint64_t)v23);
    if (__swift_getEnumTagSinglePayload(v17, 1, v29) == 1)
    {
      swift_release();
      return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v17, &demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);
    }
    else
    {
      uint64_t v30 = v16;
      uint64_t v18 = v28;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v31 + 32))(v28, v17, v29);
      uint64_t v19 = MLHandActionClassifier.GraphCNN.evaluate(_:)(v18);
      uint64_t v22 = &type metadata for Double;
      v21[0] = a6;
      specialized Dictionary.subscript.setter((uint64_t)v21, 0x69746164696C6176, 0xEF73736F6C5F6E6FLL);
      uint64_t v22 = (void *)v26;
      *(void *)&v21[0] = v19;
      specialized Dictionary.subscript.setter((uint64_t)v21, 0xD000000000000014, (uint64_t)("ve training confusion matrix" + 0x8000000000000000));
      swift_release();
      return (*(uint64_t (**)(uint64_t *, uint64_t))(v31 + 8))(v28, v29);
    }
  }
  return result;
}

uint64_t MLHandActionClassifier.GraphCNN.train(_:)(uint64_t a1)
{
  uint64_t v90 = v1;
  uint64_t v88 = v2;
  uint64_t v89 = a1;
  uint64_t v81 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  int64_t v3 = *(void *)(*(void *)(v81 - 8) + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v67 = v65;
  uint64_t v68 = type metadata accessor for Tensor(0);
  uint64_t v69 = *(void *)(v68 - 8);
  int64_t v6 = *(void *)(v69 + 64);
  int64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  unsigned int v70 = v65;
  uint64_t v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  uint64_t v76 = v65;
  int64_t v11 = alloca(v6);
  uint64_t v12 = alloca(v6);
  uint64_t v78 = v65;
  uint64_t v13 = alloca(v6);
  uint64_t v14 = alloca(v6);
  Swift::String v79 = v65;
  uint64_t v82 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>);
  uint64_t v85 = *(void *)(v82 - 8);
  int64_t v15 = *(void *)(v85 + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  char v80 = v65;
  int64_t v18 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>?)
                              - 8)
                  + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v83 = v65;
  uint64_t v86 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>, DataSample<Tensor, Tensor>>.Iterator);
  int64_t v21 = *(void *)(*(void *)(v86 - 8) + 64);
  uint64_t v22 = alloca(v21);
  os_log_t v23 = alloca(v21);
  char v87 = v65;
  uint64_t v24 = type metadata accessor for LearningPhase(0);
  uint64_t v25 = *(void *)(v24 - 8);
  int64_t v26 = *(void *)(v25 + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  (*(void (**)(void *, void, uint64_t))(v25 + 104))(v65, enum case for LearningPhase.training(_:), v24);
  uint64_t v29 = v88 + OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model;
  swift_beginAccess(v88 + OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model, v75, 33, 0);
  uint64_t v71 = lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, (uint64_t)&protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  uint64_t v77 = v29;
  Layer.prepare(for:)(v65, v81, v71);
  swift_endAccess(v75);
  (*(void (**)(void *, uint64_t))(v25 + 8))(v65, v24);
  if (specialized Dataset.isEmpty.getter())
  {
    uint64_t v30 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v30, 0, 0);
    *(void *)uint64_t v31 = 0xD000000000000036;
    *(void *)(v31 + 8) = "trings but it contains " + 0x8000000000000000;
    *(_OWORD *)(v31 + 16) = 0;
    *(_OWORD *)(v31 + 32) = 0;
    *(unsigned char *)(v31 + 48) = 1;
    return swift_willThrow(&type metadata for MLCreateError, v30, v31, v32, v33, v34);
  }
  else
  {
    uint64_t v36 = v88;
    uint64_t v37 = *(void *)(*(void *)(v88 + 16) + 16);
    uint64_t v38 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
    swift_allocObject(v38, *(unsigned int *)(v38 + 48), *(unsigned __int16 *)(v38 + 52));
    uint64_t v39 = v90;
    uint64_t result = _MetricUtilities.ConfusionMatrixMeter.init(classCount:)(v37);
    if (!v39)
    {
      uint64_t v84 = result;
      uint64_t v74 = 0;
      uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
      uint64_t v41 = (uint64_t)v87;
      Dataset.makeIterator()(v40);
      uint64_t v73 = *(int *)(v86 + 44);
      uint64_t v88 = OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_optimizer + v36;
      LODWORD(v90) = 0;
      uint64_t v89 = 0;
      uint64_t v72 = lazy protocol witness table accessor for type Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>.Iterator and conformance Batches<A>.Iterator();
      uint64_t v42 = v82;
      while (1)
      {
        uint64_t v43 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>.Iterator);
        dispatch thunk of IteratorProtocol.next()(v43, v72);
        char v44 = LOBYTE(v75[0]);
        if (*(void *)v75)
        {
          uint64_t v45 = *(void (**)(void *))(v41 + v73);
          v65[0] = *(void *)v75;
          uint64_t v46 = (uint64_t)v83;
          v45(v65);
          swift_bridgeObjectRelease(v44);
          __swift_storeEnumTagSinglePayload(v46, 0, 1, v42);
          uint64_t v47 = v46;
        }
        else
        {
          uint64_t v48 = (uint64_t)v83;
          __swift_storeEnumTagSinglePayload((uint64_t)v83, 1, 1, v42);
          uint64_t v47 = v48;
        }
        uint64_t v49 = v85;
        if (__swift_getEnumTagSinglePayload(v47, 1, v42) == 1) {
          break;
        }
        (*(void (**)(void *, uint64_t, uint64_t))(v49 + 32))(v80, v47, v42);
        uint64_t v50 = v79;
        DataSample.features.getter(v42);
        uint64_t v51 = v78;
        DataSample.labels.getter(v42);
        uint64_t v52 = (uint64_t)v67;
        outlined init with copy of MLHandActionClassifier.GraphCNNModel(v77, (uint64_t)v67);
        uint64_t v53 = alloca(40);
        uint64_t v54 = alloca(48);
        v65[2] = v50;
        context = v51;
        uint64_t v67 = (void *)v84;
        uint64_t v55 = v70;
        uint64_t v86 = valueWithGradient<A>(at:of:)(v70, v52, partial apply for closure #1 in closure #1 in MLHandActionClassifier.GraphCNN.train(_:), v65, v81, v71);
        uint64_t v56 = v52;
        uint64_t v57 = v68;
        outlined destroy of MLActivityClassifier.ModelParameters(v56, type metadata accessor for MLHandActionClassifier.GraphCNNModel);
        uint64_t v58 = v55;
        uint64_t v59 = v69;
        (*(void (**)(void *, void *, uint64_t))(v69 + 32))(v76, v58, v57);
        swift_beginAccess(v88, v75, 33, 0);
        uint64_t v60 = v77;
        swift_beginAccess(v77, v65, 33, 0);
        uint64_t v61 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for SGD<MLHandActionClassifier.GraphCNNModel>);
        uint64_t v62 = v60;
        LOBYTE(v60) = v86;
        SGD.update(_:with:)(v62, v86, v61);
        swift_endAccess(v65);
        swift_endAccess(v75);
        uint64_t v63 = v76;
        swift_bridgeObjectRelease(v60);
        Tensor.scalar<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
        if (__OFADD__(1, v89)) {
          BUG();
        }
        ++v89;
        *(float *)&uint64_t v90 = *(float *)&v90 + v75[0];
        uint64_t v64 = *(void (**)(void *, uint64_t))(v59 + 8);
        v64(v63, v57);
        v64(v78, v57);
        v64(v79, v57);
        uint64_t v42 = v82;
        (*(void (**)(void *, uint64_t))(v85 + 8))(v80, v82);
        uint64_t v41 = (uint64_t)v87;
      }
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v87, &demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>, DataSample<Tensor, Tensor>>.Iterator);
      return v84;
    }
  }
  return result;
}

Swift::Void __swiftcall MLHandActionClassifier.GraphCNN.adjustLearningRate(epoch:)(Swift::Int epoch)
{
  if (one-time initialization token for adjustLearningRateSteps != -1) {
    swift_once(&one-time initialization token for adjustLearningRateSteps, one-time initialization function for adjustLearningRateSteps);
  }
  uint64_t v2 = *(void *)(static MLHandActionClassifier.GraphCNN.ModelTrainingInternalParameters.adjustLearningRateSteps + 16);
  long long v3 = 0x3C23D70Au;
  if (v2)
  {
    for (uint64_t i = 0; i != v2; ++i)
    {
      long long v5 = v3;
      if (*(void *)(static MLHandActionClassifier.GraphCNN.ModelTrainingInternalParameters.adjustLearningRateSteps
                     + 8 * i
                     + 32) <= epoch)
      {
        *(float *)&long long v5 = *(float *)&v3 * 0.1;
        long long v3 = v5;
      }
    }
  }
  int v8 = v3;
  uint64_t v6 = OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_optimizer;
  swift_beginAccess(OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_optimizer + v1, v7, 1, 0);
  *(_DWORD *)(v1 + v6) = v8;
}

uint64_t outlined init with copy of MLHandActionClassifier.GraphCNNModel(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t closure #1 in closure #1 in MLHandActionClassifier.GraphCNN.train(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v23 = a4;
  uint64_t v24 = a3;
  uint64_t v27 = a1;
  uint64_t v26 = v4;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LossReduction?)
                             - 8)
                 + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v8 = type metadata accessor for Tensor(0);
  uint64_t v25 = *(void *)(v8 - 8);
  int64_t v9 = *(void *)(v25 + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v12 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  uint64_t v13 = lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, (uint64_t)&protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  Layer.callAsFunction(_:)(a2, v12, v13);
  unsigned int v14 = enum case for LossReduction.mean(_:);
  uint64_t v15 = type metadata accessor for LossReduction(0);
  (*(void (**)(unsigned char *, void, uint64_t))(*(void *)(v15 - 8) + 104))(v18, v14, v15);
  __swift_storeEnumTagSinglePayload((uint64_t)v18, 0, 1, v15);
  uint64_t v16 = v24;
  softmaxCrossEntropy(logits:labels:labelSmoothing:axis:reduction:)(v18, v24, -1, v18, 0.0);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v18, &demangling cache variable for type metadata for LossReduction?);
  uint64_t v20 = v23;
  int64_t v21 = v18;
  uint64_t v22 = v16;
  withoutGradient<A>(_:)(partial apply for closure #1 in closure #1 in closure #1 in MLHandActionClassifier.GraphCNN.train(_:), v19, (char *)&type metadata for () + 8);
  return (*(uint64_t (**)(unsigned char *, uint64_t))(v25 + 8))(v18, v8);
}

uint64_t partial apply for closure #1 in closure #1 in MLHandActionClassifier.GraphCNN.train(_:)(uint64_t a1)
{
  return closure #1 in closure #1 in MLHandActionClassifier.GraphCNN.train(_:)(a1, v1[2], v1[3], v1[4]);
}

uint64_t partial apply for closure #1 in closure #1 in closure #1 in MLHandActionClassifier.GraphCNN.train(_:)()
{
  return _MetricUtilities.ConfusionMatrixMeter.add(predicted:target:)(*(void *)(v0 + 24), *(void *)(v0 + 32));
}

uint64_t getNullTerminatedUTF8PointerImpl(_:storingStringOwnersIn:)(uint64_t a1, int64_t a2, uint64_t *a3)
{
  uint64_t v4 = specialized _StringGuts._deconstructUTF8<A>(scratch:)(v10, 0, 0, 1, a1, a2);
  uint64_t v5 = v10[0];
  if (v4)
  {
    uint64_t v6 = v4;
    ObjectType = (void *)swift_getObjectType(v4);
    v10[0] = v6;
    uint64_t v7 = *a3;
    if (*a3)
    {
      outlined init with copy of Any((uint64_t)v10, *a3);
      *a3 = v7 + 32;
    }
  }
  else
  {
    ObjectType = &type metadata for _StringGuts;
    v10[0] = a1;
    v10[1] = a2;
    uint64_t v8 = *a3;
    if (*a3)
    {
      outlined init with copy of Any((uint64_t)v10, *a3);
      *a3 = v8 + 32;
    }
    swift_bridgeObjectRetain(a2);
  }
  __swift_destroy_boxed_opaque_existential_1Tm(v10);
  return v5;
}

uint64_t specialized _StringGuts._deconstructUTF8<A>(scratch:)(uint64_t *a1, char *a2, uint64_t a3, char a4, uint64_t a5, int64_t a6)
{
  if ((a6 & 0x2000000000000000) != 0)
  {
    if ((a4 & 1) == 0)
    {
      if (a2)
      {
        int64_t v10 = HIBYTE(a6) & 0xF;
        if (a3 - (uint64_t)a2 > v10)
        {
          unsigned int v14 = (char **)a1;
          __src[0] = a5;
          __src[1] = a6 & 0xFFFFFFFFFFFFFFLL;
          specialized UnsafeMutableRawPointer.initializeMemory<A>(as:from:count:)((char *)__src, v10, a2);
          uint64_t v8 = 0;
          UnsafeMutableRawBufferPointer.subscript.setter(0, v10, a2, a3);
          *unsigned int v14 = a2;
          return v8;
        }
      }
    }
LABEL_11:
    uint64_t v8 = (uint64_t)_StringGuts._allocateForDeconstruct()(a5, a6);
    *a1 = v11;
    return v8;
  }
  if ((a6 & 0x1000000000000000) != 0) {
    goto LABEL_11;
  }
  if ((a5 & 0x1000000000000000) != 0)
  {
    uint64_t v7 = (a6 & 0xFFFFFFFFFFFFFFFLL) + 32;
  }
  else
  {
    uint64_t v7 = _StringObject.sharedUTF8.getter(a5, a6);
    if (!v7)
    {
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, "Unexpectedly found nil while unwrapping an Optional value", 57, 2, "Swift/StringTesting.swift", 25, 2, 151, 1);
      BUG();
    }
  }
  *a1 = v7;
  if (a6 < 0) {
    return 0;
  }
  uint64_t v8 = a6 & 0xFFFFFFFFFFFFFFFLL;
  swift_unknownObjectRetain(v8);
  return v8;
}

void *_StringGuts._allocateForDeconstruct()(uint64_t a1, unint64_t a2)
{
  uint64_t v2 = specialized _copyCollectionToContiguousArray<A>(_:)(a1, a2);
  if (!swift_isUniquelyReferenced_nonNull_native(v2)) {
    uint64_t v2 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2[2] + 1, 1, (uint64_t)v2);
  }
  unint64_t v3 = v2[2];
  if (v2[3] >> 1 <= v3) {
    uint64_t v2 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v2[3] >= 2uLL, v3 + 1, 1, (uint64_t)v2);
  }
  v2[2] = v3 + 1;
  *((unsigned char *)v2 + v3 + 32) = 0;
  return v2;
}

void *specialized _copyCollectionToContiguousArray<A>(_:)(uint64_t a1, unint64_t a2)
{
  if ((a2 & 0x1000000000000000) != 0)
  {
    Swift::Int v2 = String.UTF8View._foreignCount()();
  }
  else if ((a2 & 0x2000000000000000) != 0)
  {
    Swift::Int v2 = HIBYTE(a2) & 0xF;
  }
  else
  {
    Swift::Int v2 = a1 & 0xFFFFFFFFFFFFLL;
  }
  if (!v2) {
    return _swiftEmptyArrayStorage;
  }
  unint64_t v3 = specialized _ContiguousArrayBuffer.init(_uninitializedCount:minimumCapacity:)(v2, 0);
  if (v2 < 0)
  {
    _fatalErrorMessage(_:_:file:line:flags:)("Fatal error", 11, 2, "UnsafeMutableBufferPointer with negative count", 46, 2, "Swift/UnsafeBufferPointer.swift", 31, 2, 71, 1);
    goto LABEL_15;
  }
  uint64_t v4 = v3;
  uint64_t v5 = _StringGuts.copyUTF8(into:)(v3 + 4, v2, a1, a2);
  if (v6)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, "Insufficient space allocated to copy string contents", 52, 2, "Swift/StringUTF8View.swift", 26, 2, 430, 1);
LABEL_15:
    BUG();
  }
  if (v5 != v2)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, "invalid Collection: less than 'count' elements in collection", 60, 2, "Swift/ContiguousArrayBuffer.swift", 33, 2, 1122, 1);
    goto LABEL_15;
  }
  return v4;
}

void *specialized _ContiguousArrayBuffer.init(_uninitializedCount:minimumCapacity:)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;
  if (a2 <= a1) {
    uint64_t v2 = a1;
  }
  if (!v2) {
    return _swiftEmptyArrayStorage;
  }
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<UInt8>);
  uint64_t v4 = (void *)swift_allocObject(v3, v2 + 32, 7);
  size_t v5 = _swift_stdlib_malloc_size(v4);
  v4[2] = a1;
  v4[3] = 2 * v5 - 64;
  return v4;
}

uint64_t _StringGuts._slowEnsureMatchingEncoding(_:)(unint64_t a1, uint64_t a2, uint64_t a3)
{
  unint64_t v5 = a1 >> 16;
  uint64_t v6 = (unsigned __int16)a1 >> 14;
  if ((a3 & 0x1000000000000000) == 0 || (a2 & 0x800000000000000) != 0)
  {
    uint64_t v9 = String.UTF16View.index(_:offsetBy:)(15, v5, a2);
    if ((unsigned __int16)a1 >> 14) {
      unint64_t v10 = ((v6 << 16) + v9) & 0xFFFFFFFFFFFF0000;
    }
    else {
      unint64_t v10 = a1 & 3 | v9 & 0xFFFFFFFFFFFFFFFCLL;
    }
    return v10 | 4;
  }
  else
  {
    uint64_t v7 = String.UTF8View._foreignIndex(_:offsetBy:)(15, v5);
    if ((unsigned __int16)a1 >> 14) {
      unint64_t v8 = ((v6 << 16) + v7) & 0xFFFFFFFFFFFF0000;
    }
    else {
      unint64_t v8 = a1 & 3 | v7 & 0xFFFFFFFFFFFFFFFCLL;
    }
    return v8 | 8;
  }
}

uint64_t type metadata accessor for OS_os_log()
{
  uint64_t result = lazy cache variable for type metadata for OS_os_log;
  if (!lazy cache variable for type metadata for OS_os_log)
  {
    uint64_t v1 = objc_opt_self(OS_os_log);
    uint64_t result = swift_getObjCClassMetadata(v1);
    lazy cache variable for type metadata for OS_os_os_log_t log = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(uint64_t *a1, uint64_t (*a2)(uint64_t), uint64_t a3)
{
  uint64_t result = *a1;
  if (!*a1)
  {
    uint64_t v5 = a2(255);
    uint64_t result = swift_getWitnessTable(a3, v5);
    *a1 = result;
  }
  return result;
}

uint64_t *initializeBufferWithCopyOfBuffer for TrainingTablePrinter(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v11 = *a2;
    uint64_t *v3 = *a2;
    uint64_t v3 = (uint64_t *)(v11 + ((v4 + 16) & ~v4));
    swift_retain(v11);
  }
  else
  {
    uint64_t v6 = type metadata accessor for Date(0);
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
    uint64_t v7 = *(int *)(a3 + 20);
    unint64_t v8 = *(void **)((char *)a2 + v7);
    *(uint64_t *)((char *)v3 + v7) = (uint64_t)v8;
    uint64_t v9 = *(int *)(a3 + 24);
    uint64_t v10 = *(uint64_t *)((char *)a2 + v9);
    *(uint64_t *)((char *)v3 + v9) = v10;
    v8;
    swift_bridgeObjectRetain(v10);
  }
  return v3;
}

uint64_t destroy for TrainingTablePrinter(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);

  return swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(a2 + 24)));
}

uint64_t initializeWithCopy for TrainingTablePrinter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16))(a1, a2, v5);
  uint64_t v6 = *(int *)(a3 + 20);
  uint64_t v7 = *(void **)(a2 + v6);
  *(void *)(a1 + v6) = v7;
  uint64_t v8 = *(int *)(a3 + 24);
  uint64_t v9 = *(void *)(a2 + v8);
  *(void *)(a1 + v8) = v9;
  v7;
  swift_bridgeObjectRetain(v9);
  return a1;
}

uint64_t assignWithCopy for TrainingTablePrinter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 24))(a1, a2, v5);
  uint64_t v6 = *(int *)(a3 + 20);
  uint64_t v7 = *(void **)(a2 + v6);
  uint64_t v8 = *(void **)(a1 + v6);
  *(void *)(a1 + v6) = v7;
  v7;

  uint64_t v9 = *(int *)(a3 + 24);
  uint64_t v10 = *(void *)(a2 + v9);
  uint64_t v11 = *(void *)(a1 + v9);
  *(void *)(a1 + v9) = v10;
  swift_bridgeObjectRetain(v10);
  swift_bridgeObjectRelease(v11);
  return a1;
}

uint64_t initializeWithTake for TrainingTablePrinter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a1, a2, v4);
  *(void *)(a1 + *(int *)(a3 + 20)) = *(void *)(a2 + *(int *)(a3 + 20));
  *(void *)(a1 + *(int *)(a3 + 24)) = *(void *)(a2 + *(int *)(a3 + 24));
  return a1;
}

uint64_t assignWithTake for TrainingTablePrinter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 40))(a1, a2, v5);
  uint64_t v6 = *(int *)(a3 + 20);
  uint64_t v7 = *(void **)(a1 + v6);
  *(void *)(a1 + v6) = *(void *)(a2 + v6);

  uint64_t v8 = *(int *)(a3 + 24);
  uint64_t v9 = *(void *)(a1 + v8);
  *(void *)(a1 + v8) = *(void *)(a2 + v8);
  swift_bridgeObjectRelease(v9);
  return a1;
}

uint64_t getEnumTagSinglePayload for TrainingTablePrinter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_2B7BBA);
}

uint64_t sub_2B7BBA(uint64_t a1, unsigned int a2, uint64_t a3)
{
  unsigned int v4 = 0;
  uint64_t v5 = type metadata accessor for Date(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(a1, a2, v5);
  }
  if ((*(void *)(a1 + *(int *)(a3 + 20)) & 0xFFFFFFFF00000001) == 0) {
    return (*(void *)(a1 + *(int *)(a3 + 20)) >> 1) + 1;
  }
  return v4;
}

uint64_t storeEnumTagSinglePayload for TrainingTablePrinter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_2B7C43);
}

uint64_t sub_2B7C43(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = type metadata accessor for Date(0);
  if (*(_DWORD *)(*(void *)(v6 - 8) + 84) == a3) {
    return __swift_storeEnumTagSinglePayload(a1, a2, a2, v6);
  }
  uint64_t result = *(int *)(a4 + 20);
  *(void *)(a1 + result) = 2 * (a2 - 1);
  return result;
}

uint64_t type metadata accessor for TrainingTablePrinter(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for TrainingTablePrinter, (uint64_t)&nominal type descriptor for TrainingTablePrinter);
}

uint64_t type metadata completion function for TrainingTablePrinter(uint64_t a1)
{
  uint64_t result = type metadata accessor for Date(319);
  if (v2 <= 0x3F)
  {
    v3[0] = *(void *)(result - 8) + 64;
    v3[1] = (char *)&value witness table for Builtin.UnknownObject + 64;
    v3[2] = (char *)&value witness table for Builtin.BridgeObject + 64;
    swift_initStructMetadata(a1, 256, 3, v3, a1 + 16);
    return 0;
  }
  return result;
}

Swift::Void __swiftcall TrainingTablePrinter.beginTable()()
{
  uint64_t v27 = v0;
  uint64_t v26 = type metadata accessor for TrainingTablePrinter(0);
  uint64_t v1 = *(void *)(v0 + *(int *)(v26 + 20));
  static os_log_type_t.info.getter();
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v3 = (void *)swift_allocObject(v2, 72, 7);
  char v4 = (char)v3;
  v3[2] = 1;
  v3[3] = 2;
  v3[7] = &type metadata for Int;
  void v3[8] = &protocol witness table for Int;
  void v3[4] = 0;
  os_log(_:dso:log:type:_:)("event: %lu", 10);
  swift_bridgeObjectRelease(v4);
  unsigned __int8 v5 = static os_log_type_t.info.getter();
  uint64_t v6 = (void *)swift_allocObject(v2, 152, 7);
  void v6[2] = 3;
  v6[3] = 6;
  v6[7] = &type metadata for Int;
  v6[8] = &protocol witness table for Int;
  void v6[4] = 1;
  v6[12] = &type metadata for Int;
  v6[13] = &protocol witness table for Int;
  v6[9] = 0;
  v6[17] = &type metadata for String;
  uint64_t v7 = lazy protocol witness table accessor for type String and conformance String();
  v6[18] = v7;
  v6[14] = 0x6F69746172657449;
  v6[15] = 0xE90000000000006ELL;
  uint64_t v8 = v5;
  uint64_t v9 = v1;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %{public}s", 42, 2, &dword_0, v1, v8, v6);
  swift_bridgeObjectRelease((_BYTE)v6);
  LOBYTE(v1) = static os_log_type_t.info.getter();
  uint64_t v24 = v2;
  uint64_t v10 = swift_allocObject(v2, 152, 7);
  LOBYTE(v6) = v10;
  *(void *)(v10 + 16) = 3;
  *(void *)(v10 + 24) = 6;
  *(void *)(v10 + 56) = &type metadata for Int;
  *(void *)(v10 + 64) = &protocol witness table for Int;
  *(void *)(v10 + 32) = 1;
  *(void *)(v10 + 96) = &type metadata for Int;
  *(void *)(v10 + 104) = &protocol witness table for Int;
  *(void *)(v10 + 72) = 1;
  *(void *)(v10 + 136) = &type metadata for String;
  uint64_t v25 = v7;
  *(void *)(v10 + 144) = v7;
  strcpy((char *)(v10 + 112), "Elapsed Time");
  *(unsigned char *)(v10 + 125) = 0;
  *(_WORD *)(v10 + 126) = -5120;
  uint64_t v23 = v9;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %{public}s", 42, 2, &dword_0, v9, v1, v10);
  swift_bridgeObjectRelease((_BYTE)v6);
  uint64_t v11 = *(void *)(v27 + *(int *)(v26 + 24));
  specialized EnumeratedSequence.makeIterator()(v11);
  char v28 = v11;
  swift_bridgeObjectRetain_n(v11, 2);
  uint64_t v12 = specialized EnumeratedSequence.Iterator.next()();
  if (v14)
  {
    uint64_t v15 = v12;
    uint64_t v16 = v13;
    uint64_t v17 = v14;
    do
    {
      unsigned __int8 v18 = static os_log_type_t.info.getter();
      uint64_t v19 = (void *)swift_allocObject(v24, 152, 7);
      void v19[2] = 3;
      v19[3] = 6;
      uint64_t v19[7] = &type metadata for Int;
      v19[8] = &protocol witness table for Int;
      void v19[4] = 1;
      if (v15 < 0)
      {
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, "Negative value is not representable", 35, 2, "Swift/Integers.swift", 20, 2, 3451, 1);
        BUG();
      }
      v19[12] = &type metadata for UInt64;
      v19[13] = &protocol witness table for UInt64;
      v19[9] = v15 + 2;
      v19[17] = &type metadata for String;
      v19[18] = v25;
      v19[14] = v16;
      v19[15] = v17;
      os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %{public}s", 42, 2, &dword_0, v23, v18, v19);
      swift_bridgeObjectRelease((_BYTE)v19);
      uint64_t v15 = specialized EnumeratedSequence.Iterator.next()();
      uint64_t v16 = v20;
      uint64_t v17 = v21;
    }
    while (v21);
  }
  outlined consume of [String : [Int]].Iterator._Variant(v22);
  swift_bridgeObjectRelease(v28);
}

Swift::Void __swiftcall TrainingTablePrinter.print(iteration:metrics:)(Swift::Int iteration, Swift::OpaquePointer metrics)
{
  uint64_t v66 = v2;
  uint64_t rawValue = metrics._rawValue;
  Swift::Int v73 = iteration;
  uint64_t v63 = type metadata accessor for MetricsKey(0);
  uint64_t v67 = *(void **)(v63 - 8);
  int64_t v4 = v67[8];
  unsigned __int8 v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v69 = &v57;
  uint64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  uint64_t v60 = &v57;
  uint64_t v9 = alloca(v4);
  uint64_t v10 = alloca(v4);
  uint64_t v68 = &v57;
  uint64_t v11 = alloca(v4);
  uint64_t v12 = alloca(v4);
  unsigned int v70 = &v57;
  int64_t v13 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey)?)
                              - 8)
                  + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v64 = &v57;
  uint64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v65 = &v57;
  uint64_t v74 = type metadata accessor for TrainingTablePrinter(0);
  uint64_t v62 = *(int *)(v74 + 20);
  uint64_t v71 = *(void (**)(uint64_t *, char *, uint64_t))(v2 + v62);
  LOBYTE(v72) = static os_log_type_t.info.getter();
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v19 = (void *)swift_allocObject(v18, 152, 7);
  char v20 = (char)v19;
  void v19[2] = 3;
  v19[3] = 6;
  uint64_t v19[7] = &type metadata for Int;
  v19[8] = &protocol witness table for Int;
  void v19[4] = 2;
  v19[12] = &type metadata for Int;
  v19[13] = &protocol witness table for Int;
  v19[9] = 0;
  v19[17] = &type metadata for Int;
  v19[18] = &protocol witness table for Int;
  v19[14] = v73;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %d", 34, 2, &dword_0);
  swift_bridgeObjectRelease(v20);
  LOBYTE(v73) = static os_log_type_t.info.getter();
  uint64_t v72 = v18;
  uint64_t v21 = swift_allocObject(v18, 152, 7);
  *(void *)(v21 + 16) = 3;
  *(void *)(v21 + 24) = 6;
  *(void *)(v21 + 56) = &type metadata for Int;
  *(void *)(v21 + 64) = &protocol witness table for Int;
  *(void *)(v21 + 32) = 2;
  uint64_t v22 = v63;
  *(void *)(v21 + 96) = &type metadata for Int;
  *(void *)(v21 + 104) = &protocol witness table for Int;
  *(void *)(v21 + 72) = 1;
  uint64_t v23 = v66;
  *(double *)v3.i64 = Date.timeIntervalSinceNow.getter();
  *(void *)(v21 + 136) = &type metadata for Double;
  *(void *)(v21 + 144) = &protocol witness table for Double;
  _mm_storel_ps((double *)(v21 + 112), _mm_xor_ps(v3, (__m128)xmmword_3474C0));
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %f", 34, 2, &dword_0, v71, v73, v21);
  swift_bridgeObjectRelease(v21);
  uint64_t v24 = *(void *)(v23 + *(int *)(v74 + 24));
  uint64_t v25 = v70;
  specialized EnumeratedSequence.makeIterator()(v24);
  swift_bridgeObjectRetain(v24);
  uint64_t v26 = v64;
  specialized EnumeratedSequence.Iterator.next()();
  uint64_t v27 = (uint64_t)v26;
  char v28 = v65;
  outlined init with take of (offset: Int, element: MetricsKey)?(v27, (uint64_t)v65);
  uint64_t v29 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey));
  if (__swift_getEnumTagSinglePayload((uint64_t)v28, 1, v29) != 1)
  {
    uint64_t v71 = (void (*)(uint64_t *, char *, uint64_t))v67[4];
    while (1)
    {
      Swift::Int v73 = *v28;
      v71(v25, (char *)v28 + *(int *)(v29 + 48), v22);
      uint64_t v30 = v25;
      uint64_t v31 = (void (*)(uint64_t *, uint64_t *, uint64_t))v67[2];
      uint64_t v32 = v68;
      v31(v68, v30, v22);
      uint64_t v33 = v60;
      v31(v60, v32, v22);
      uint64_t v34 = v69;
      static MetricsKey.trainingLoss.getter();
      uint64_t v35 = v22;
      uint64_t v74 = lazy protocol witness table accessor for type MetricsKey and conformance MetricsKey();
      char v36 = dispatch thunk of static Equatable.== infix(_:_:)(v34, v33, v22, v74);
      uint64_t v37 = (void (*)(uint64_t *, uint64_t))v67[1];
      v37(v34, v35);
      if (v36) {
        break;
      }
      static MetricsKey.trainingAccuracy.getter();
      char v39 = dispatch thunk of static Equatable.== infix(_:_:)(v34, v33, v35, v74);
      v37(v34, v35);
      char v38 = 3;
      if (v39) {
        goto LABEL_8;
      }
      uint64_t v40 = v69;
      static MetricsKey.validationLoss.getter();
      char v41 = dispatch thunk of static Equatable.== infix(_:_:)(v40, v33, v35, v74);
      v37(v40, v35);
      char v38 = 4;
      if (v41) {
        goto LABEL_8;
      }
      uint64_t v53 = v69;
      static MetricsKey.validationAccuracy.getter();
      char v54 = dispatch thunk of static Equatable.== infix(_:_:)(v53, v33, v35, v74);
      v37(v68, v35);
      v37(v53, v35);
      v37(v33, v35);
      char v38 = 5;
      BOOL v55 = (v54 & 1) == 0;
      uint64_t v22 = v35;
      uint64_t v42 = v37;
      if (!v55) {
        goto LABEL_9;
      }
LABEL_13:
      uint64_t v25 = v70;
      v42(v70, v22);
      uint64_t v51 = v64;
      specialized EnumeratedSequence.Iterator.next()();
      uint64_t v52 = (uint64_t)v51;
      char v28 = v65;
      outlined init with take of (offset: Int, element: MetricsKey)?(v52, (uint64_t)v65);
      uint64_t v29 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey));
      if (__swift_getEnumTagSinglePayload((uint64_t)v28, 1, v29) == 1) {
        goto LABEL_2;
      }
    }
    char v38 = 0;
LABEL_8:
    v37(v68, v35);
    v37(v33, v35);
    uint64_t v22 = v35;
    uint64_t v42 = v37;
LABEL_9:
    uint64_t v43 = v22;
    char v44 = rawValue;
    if (!rawValue[2] || (unint64_t v45 = specialized __RawDictionaryStorage.find<A>(_:)(v38), (v46 & 1) == 0))
    {
      uint64_t v57 = 0;
      unint64_t v58 = 0xE000000000000000;
      _StringGuts.grow(_:)(32);
      v56._char object = "gUtilities.swift" + 0x8000000000000000;
      v56._uint64_t countAndFlagsBits = 0xD00000000000001DLL;
      String.append(_:)(v56);
      _print_unlocked<A, B>(_:_:)(v70, &v57, v22, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
      v56._uint64_t countAndFlagsBits = 46;
      v56._char object = (void *)0xE100000000000000;
      String.append(_:)(v56);
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v57, v58, "CreateML/_LoggingUtilities.swift", 32, 2, 122, 0);
      BUG();
    }
    uint64_t v74 = *(void *)(v44[7] + 8 * v45);
    uint64_t v47 = *(void *)(v66 + v62);
    unsigned __int8 v48 = static os_log_type_t.info.getter();
    uint64_t v49 = (void *)swift_allocObject(v72, 152, 7);
    v49[2] = 3;
    v49[3] = 6;
    v49[7] = &type metadata for Int;
    char v49[8] = &protocol witness table for Int;
    void v49[4] = 2;
    Swift::Int v50 = v73 + 2;
    if (__OFADD__(2, v73)) {
      BUG();
    }
    v49[12] = &type metadata for Int;
    v49[13] = &protocol witness table for Int;
    v49[9] = v50;
    v49[17] = &type metadata for Double;
    v49[18] = &protocol witness table for Double;
    v49[14] = v74;
    os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %f", 34, 2, &dword_0, v47, v48, v49);
    swift_bridgeObjectRelease((_BYTE)v49);
    uint64_t v22 = v43;
    goto LABEL_13;
  }
LABEL_2:
  outlined consume of [String : [Int]].Iterator._Variant(v59);
}

Swift::Void __swiftcall _TablePrinter.beginTable()()
{
  uint64_t v22 = 0;
  uint64_t v1 = type metadata accessor for _TablePrinter(0);
  uint64_t v2 = *(void *)(v0 + *(int *)(v1 + 24));
  static os_log_type_t.info.getter();
  uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  __m128 v3 = (void *)swift_allocObject(v20, 72, 7);
  v3[2] = 1;
  v3[3] = 2;
  v3[7] = &type metadata for Int;
  void v3[8] = &protocol witness table for Int;
  void v3[4] = 0;
  uint64_t v19 = v2;
  os_log(_:dso:log:type:_:)("event: %lu", 10);
  swift_bridgeObjectRelease(v3);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t inited = swift_initStackObject(v4, v16);
  *(void *)(inited + 16) = 3;
  *(void *)(inited + 24) = 6;
  *(void *)(inited + 32) = 0x2064657370616C45;
  uint64_t v6 = (void *)(inited + 40);
  *(void *)(inited + 40) = 0xEC000000656D6954;
  uint64_t v7 = *(int *)(v1 + 28);
  uint64_t v9 = *(void **)(v0 + v7 + 8);
  *(void *)&long long v17 = *(void *)(v0 + v7);
  uint64_t v8 = v17;
  *((void *)&v17 + 1) = v9;
  swift_bridgeObjectRetain(v9);
  v10._uint64_t countAndFlagsBits = 0x737365636F725020;
  v10._char object = (void *)0xEA00000000006465;
  String.append(_:)(v10);
  *(_OWORD *)(inited + 48) = v17;
  *(void *)&long long v17 = 0;
  *((void *)&v17 + 1) = 0xE000000000000000;
  _StringGuts.grow(_:)(18);
  swift_bridgeObjectRelease(*((void *)&v17 + 1));
  *(void *)&long long v17 = 0xD000000000000010;
  *((void *)&v17 + 1) = "mn: %lu, value: %d" + 0x8000000000000000;
  swift_bridgeObjectRetain(v9);
  v10._uint64_t countAndFlagsBits = v8;
  v10._char object = v9;
  String.append(_:)(v10);
  swift_bridgeObjectRelease(v9);
  *(_OWORD *)(inited + 64) = v17;
  uint64_t v21 = inited;
  swift_bridgeObjectRetain(inited);
  do
  {
    uint64_t v18 = *(v6 - 1);
    uint64_t v11 = *v6;
    swift_bridgeObjectRetain(*v6);
    unsigned __int8 v12 = static os_log_type_t.info.getter();
    int64_t v13 = (void *)swift_allocObject(v20, 152, 7);
    v13[2] = 3;
    void v13[3] = 6;
    void v13[7] = &type metadata for Int;
    v13[8] = &protocol witness table for Int;
    v13[4] = 1;
    v13[12] = &type metadata for UInt64;
    v13[13] = &protocol witness table for UInt64;
    uint64_t v14 = v22;
    v13[9] = v22;
    v13[17] = &type metadata for String;
    v13[18] = lazy protocol witness table accessor for type String and conformance String();
    v13[14] = v18;
    v13[15] = v11;
    swift_bridgeObjectRetain(v11);
    os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %{public}s", 42, 2, &dword_0, v19, v12, v13);
    swift_bridgeObjectRelease(v11);
    swift_bridgeObjectRelease(v13);
    v6 += 2;
    uint64_t v22 = v14 + 1;
  }
  while (v14 != 2);
  uint64_t v15 = v21;
  swift_bridgeObjectRelease(v21);
  swift_setDeallocating(v15);
  specialized _ContiguousArrayStorage.__deallocating_deinit();
}

Swift::Void __swiftcall _TablePrinter.printRow(currentFileIndex:)(Swift::Int currentFileIndex)
{
  uint64_t v7 = *(uint64_t *)((char *)v1 + *(int *)(type metadata accessor for _TablePrinter(0) + 24));
  unsigned __int8 v9 = static os_log_type_t.info.getter();
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v3 = swift_allocObject(v8, 152, 7);
  *(void *)(v3 + 16) = 3;
  *(void *)(v3 + 24) = 6;
  *(void *)(v3 + 56) = &type metadata for Int;
  *(void *)(v3 + 64) = &protocol witness table for Int;
  *(void *)(v3 + 32) = 2;
  *(void *)(v3 + 96) = &type metadata for Int;
  *(void *)(v3 + 104) = &protocol witness table for Int;
  *(void *)(v3 + 72) = 0;
  *(double *)v2.i64 = Date.timeIntervalSinceNow.getter();
  *(void *)(v3 + 136) = &type metadata for Double;
  *(void *)(v3 + 144) = &protocol witness table for Double;
  _mm_storel_ps((double *)(v3 + 112), _mm_xor_ps(v2, (__m128)xmmword_3474C0));
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %f", 34, 2, &dword_0, v7, v9, v3);
  swift_bridgeObjectRelease(v3);
  static os_log_type_t.info.getter();
  uint64_t v4 = (void *)swift_allocObject(v8, 152, 7);
  v4[2] = 3;
  v4[3] = 6;
  v4[7] = &type metadata for Int;
  void v4[8] = &protocol witness table for Int;
  _OWORD v4[4] = 2;
  void v4[12] = &type metadata for Int;
  v4[13] = &protocol witness table for Int;
  v4[9] = 1;
  v4[17] = &type metadata for Int;
  v4[18] = &protocol witness table for Int;
  v4[14] = currentFileIndex;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %d", 34, 2, &dword_0);
  swift_bridgeObjectRelease(v4);
  static os_log_type_t.info.getter();
  unsigned __int8 v5 = (void *)swift_allocObject(v8, 152, 7);
  _OWORD v5[2] = 3;
  void v5[3] = 6;
  v5[7] = &type metadata for Int;
  v5[8] = &protocol witness table for Int;
  void v5[4] = 2;
  v5[12] = &type metadata for Int;
  v5[13] = &protocol witness table for Int;
  v5[9] = 2;
  uint64_t v6 = *v1;
  v5[17] = &type metadata for Int;
  v5[18] = &protocol witness table for Int;
  v5[14] = v6;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %d", 34, 2, &dword_0);
  swift_bridgeObjectRelease(v5);
}

uint64_t type metadata accessor for _TablePrinter(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for _TablePrinter, (uint64_t)&nominal type descriptor for _TablePrinter);
}

void *specialized EnumeratedSequence.makeIterator()(uint64_t a1)
{
  uint64_t v2 = -(-1 << *(unsigned char *)(a1 + 32));
  uint64_t v3 = ~(-1 << v2);
  if (v2 >= 64) {
    uint64_t v3 = -1;
  }
  uint64_t v4 = *(void *)(a1 + 64) & v3;
  uint64_t v5 = ~(-1 << *(unsigned char *)(a1 + 32));
  *uint64_t result = a1;
  result[1] = a1 + 64;
  result[2] = v5;
  result[3] = 0;
  result[4] = v4;
  result[5] = 0;
  return result;
}

uint64_t specialized EnumeratedSequence.Iterator.next()()
{
  uint64_t v1 = v0[3];
  unint64_t v2 = v0[4];
  if (!v2)
  {
    int64_t v9 = v1 + 1;
    if (__OFADD__(1, v1)) {
      BUG();
    }
    int64_t v10 = (unint64_t)(v0[2] + 64) >> 6;
    if (v9 >= v10)
    {
      int64_t v14 = v0[3];
    }
    else
    {
      uint64_t v11 = v0[1];
      unint64_t v12 = *(void *)(v11 + 8 * v9);
      if (v12)
      {
        int64_t v6 = v1 + 1;
LABEL_9:
        _BitScanForward64(&v13, v12);
        uint64_t v4 = v12 & (v12 - 1);
        unint64_t v5 = v13 + (v6 << 6);
        goto LABEL_3;
      }
      int64_t v14 = v1 + 2;
      if (v1 + 2 >= v10)
      {
        int64_t v14 = v1 + 1;
      }
      else
      {
        unint64_t v12 = *(void *)(v11 + 8 * v9 + 8);
        if (v12)
        {
          int64_t v6 = v1 + 2;
          goto LABEL_9;
        }
        int64_t v6 = v1 + 3;
        if (v1 + 3 < v10)
        {
          unint64_t v12 = *(void *)(v11 + 8 * v9 + 16);
          if (v12) {
            goto LABEL_9;
          }
          int64_t v14 = v1 + 3;
          if (v1 + 4 < v10)
          {
            unint64_t v12 = *(void *)(v11 + 8 * v9 + 24);
            if (v12)
            {
              int64_t v6 = v1 + 4;
              goto LABEL_9;
            }
            int64_t v6 = v1 + 5;
            int64_t v14 = v1 + 4;
            if (v1 + 5 < v10)
            {
              unint64_t v12 = *(void *)(v11 + 8 * v9 + 32);
              if (v12) {
                goto LABEL_9;
              }
              int64_t v14 = v10 - 1;
              int64_t v16 = v1 + 6;
              while (v16 < v10)
              {
                unint64_t v12 = *(void *)(v11 + 8 * v16++);
                if (v12)
                {
                  int64_t v6 = v16 - 1;
                  goto LABEL_9;
                }
              }
            }
          }
        }
      }
    }
    v0[3] = v14;
    v0[4] = 0;
    return 0;
  }
  _BitScanForward64(&v3, v2);
  uint64_t v4 = v2 & (v2 - 1);
  unint64_t v5 = v3 | (v1 << 6);
  int64_t v6 = v0[3];
LABEL_3:
  uint64_t v7 = *(void *)(*(void *)(*v0 + 48) + 16 * v5 + 8);
  v0[3] = v6;
  v0[4] = v4;
  uint64_t v8 = v0[5];
  if (__OFADD__(1, v8)) {
    BUG();
  }
  v0[5] = v8 + 1;
  swift_bridgeObjectRetain(v7);
  return v8;
}

{
  int64_t *v0;
  uint64_t *v1;
  int64_t *v2;
  uint64_t v3;
  int64_t v4;
  void *v5;
  void *v6;
  int64_t v7;
  void *v8;
  void *v9;
  uint64_t v10;
  uint64_t v11;
  int64_t v12;
  void *v13;
  void *v14;
  uint64_t v15;
  void (*v16)(char *, char *, uint64_t);
  uint64_t v17;
  int64_t v18;
  unint64_t v19;
  unint64_t v20;
  unint64_t v21;
  uint64_t v22;
  uint64_t v23;
  int64_t v24;
  int64_t v25;
  unint64_t v26;
  int64_t v27;
  unint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  void (*v32)(uint64_t *, uint64_t *, uint64_t);
  uint64_t *v33;
  char *v34;
  int64_t v35;
  uint64_t v36;
  int64_t *v37;
  char *v38;
  int64_t v40;
  uint64_t v41;
  uint64_t *v42;
  uint64_t *v43;
  uint64_t v44;
  int64_t *v45;
  uint64_t v46;
  void (*v47)(char *, char *, uint64_t);
  uint64_t v48;
  int64_t v49;

  unint64_t v2 = v0;
  unint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey));
  uint64_t v4 = *(void *)(*(void *)(v3 - 8) + 64);
  unint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v42 = &v41;
  uint64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MetricsKey?)
                             - 8)
                 + 64);
  uint64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  int64_t v10 = type metadata accessor for MetricsKey(0);
  uint64_t v11 = *(void *)(v10 - 8);
  unint64_t v12 = *(void *)(v11 + 64);
  unint64_t v13 = alloca(v12);
  int64_t v14 = alloca(v12);
  uint64_t v43 = &v41;
  uint64_t v15 = *v1;
  int64_t v16 = (void *)v1[1];
  long long v17 = v1[2];
  uint64_t v18 = v1[3];
  uint64_t v19 = v1[4];
  char v46 = v3;
  unint64_t v45 = v2;
  char v44 = v11;
  uint64_t v47 = (void (*)(char *, char *, uint64_t))v16;
  char v41 = v17;
  if (v19)
  {
    _BitScanForward64(&v20, v19);
    unsigned __int8 v48 = v19 & (v19 - 1);
    uint64_t v49 = v18;
    uint64_t v21 = v20 | (v18 << 6);
LABEL_3:
    uint64_t v22 = v15;
    (*(void (**)(uint64_t *, unint64_t, uint64_t))(v11 + 16))(&v41, *(void *)(v15 + 56) + *(void *)(v11 + 72) * v21, v10);
    uint64_t v23 = 0;
    goto LABEL_11;
  }
  uint64_t v24 = v18 + 1;
  if (__OFADD__(1, v18)) {
    BUG();
  }
  uint64_t v23 = 1;
  uint64_t v25 = (unint64_t)(v17 + 64) >> 6;
  if (v24 >= v25)
  {
    uint64_t v49 = v18;
    unsigned __int8 v48 = 0;
  }
  else
  {
    uint64_t v26 = v16[v24];
    if (v26)
    {
LABEL_7:
      uint64_t v27 = v24;
LABEL_8:
      _BitScanForward64(&v28, v26);
      unsigned __int8 v48 = v26 & (v26 - 1);
      uint64_t v21 = v28 + (v27 << 6);
      uint64_t v49 = v27;
      goto LABEL_3;
    }
    uint64_t v27 = v18 + 2;
    if (v18 + 2 >= v25)
    {
      unsigned __int8 v48 = 0;
      uint64_t v49 = v18 + 1;
    }
    else
    {
      uint64_t v26 = v16[v24 + 1];
      if (v26) {
        goto LABEL_8;
      }
      uint64_t v49 = v18;
      if (v18 + 3 >= v25)
      {
        unsigned __int8 v48 = 0;
      }
      else
      {
        uint64_t v26 = v16[v24 + 2];
        if (v26)
        {
          uint64_t v27 = v18 + 3;
          goto LABEL_8;
        }
        if (v18 + 4 >= v25)
        {
          unsigned __int8 v48 = 0;
          uint64_t v49 = v18 + 3;
          goto LABEL_10;
        }
        uint64_t v26 = *((void *)v47 + v24 + 3);
        if (v26)
        {
          uint64_t v27 = v18 + 4;
          goto LABEL_8;
        }
        uint64_t v27 = v18 + 5;
        if (v18 + 5 >= v25)
        {
          unsigned __int8 v48 = 0;
          uint64_t v49 = v18 + 4;
          goto LABEL_10;
        }
        uint64_t v26 = *((void *)v47 + v24 + 4);
        if (v26) {
          goto LABEL_8;
        }
        uint64_t v27 = v25 - 1;
        uint64_t v40 = v49 + 6;
        unsigned __int8 v48 = 0;
        while (v40 < v25)
        {
          uint64_t v26 = *((void *)v47 + v40++);
          if (v26)
          {
            uint64_t v24 = v40 - 1;
            goto LABEL_7;
          }
        }
      }
      uint64_t v49 = v27;
    }
  }
LABEL_10:
  uint64_t v22 = v15;
LABEL_11:
  __swift_storeEnumTagSinglePayload((uint64_t)&v41, v23, 1, v10);
  *uint64_t v1 = v22;
  v1[1] = (uint64_t)v47;
  v1[2] = v41;
  v1[3] = v49;
  v1[4] = v48;
  if (__swift_getEnumTagSinglePayload((uint64_t)&v41, 1, v10) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v41, &demangling cache variable for type metadata for MetricsKey?);
    uint64_t v29 = (uint64_t)v45;
    uint64_t v30 = 1;
    uint64_t v31 = v46;
  }
  else
  {
    uint64_t v32 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v44 + 32);
    uint64_t v33 = v43;
    v32(v43, &v41, v10);
    uint64_t v34 = (char *)v42 + *(int *)(v46 + 48);
    uint64_t v49 = v1[5];
    uint64_t v47 = (void (*)(char *, char *, uint64_t))v32;
    v32((uint64_t *)v34, v33, v10);
    uint64_t v35 = v49;
    if (__OFADD__(1, v49)) {
      BUG();
    }
    v1[5] = v49 + 1;
    char v36 = v46;
    uint64_t v37 = v45;
    char v38 = (char *)v45 + *(int *)(v46 + 48);
    *unint64_t v45 = v35;
    v47(v38, v34, v10);
    uint64_t v29 = (uint64_t)v37;
    uint64_t v30 = 0;
    uint64_t v31 = v36;
  }
  return __swift_storeEnumTagSinglePayload(v29, v30, 1, v31);
}

char specialized EnumeratedSequence.Iterator.next()(double a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = *(void *)(v2 + 8);
  uint64_t v5 = CMLSequence.size.getter();
  if (v4 == v5)
  {
    *(_OWORD *)uint64_t v3 = 0;
    *(void *)(v3 + 16) = 0;
    *(unsigned char *)(v3 + 24) = -1;
  }
  else
  {
    swift_retain();
    uint64_t v10 = CMLSequence.value(at:)(v4);
    swift_release();
    MLDataValue.init(_:)(v10, a1);
    swift_retain();
    uint64_t v6 = CMLSequence.size.getter();
    swift_release();
    if (v4 < 0 || v4 >= v6) {
      BUG();
    }
    *(void *)(v2 + 8) = v4 + 1;
    uint64_t v5 = *(void *)(v2 + 16);
    if (__OFADD__(1, v5)) {
      BUG();
    }
    *(void *)(v2 + 16) = v5 + 1;
    *(void *)uint64_t v3 = v5;
    *(_OWORD *)(v3 + 8) = v8;
    LOBYTE(v5) = v9;
    *(unsigned char *)(v3 + 24) = v9;
  }
  return v5;
}

Swift::Void __swiftcall log(_:type:)(Swift::String _, os_log_type_t type)
{
  unsigned int v7 = type;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
  uint64_t v3 = (Swift::String *)swift_allocObject(v2, 64, 7);
  v3[1]._uint64_t countAndFlagsBits = 1;
  v3[1]._char object = &dword_0 + 2;
  v3[3]._char object = &type metadata for String;
  v3[2] = _;
  swift_bridgeObjectRetain(_._object);
  print(_:separator:terminator:)(v3, 32, 0xE100000000000000, 10, 0xE100000000000000);
  swift_bridgeObjectRelease(v3);
  type metadata accessor for OS_os_log();
  uint64_t v4 = (void *)static OS_os_log.default.getter(0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v6 = (Swift::String *)swift_allocObject(v5, 72, 7);
  v6[1]._uint64_t countAndFlagsBits = 1;
  v6[1]._char object = &dword_0 + 2;
  v6[3]._char object = &type metadata for String;
  v6[4]._uint64_t countAndFlagsBits = lazy protocol witness table accessor for type String and conformance String();
  void v6[2] = _;
  swift_bridgeObjectRetain(_._object);
  os_log(_:dso:log:type:_:)("%@\n", 3, 2, &dword_0, v4, v7, v6);

  swift_bridgeObjectRelease(v6);
}

Swift::String __swiftcall getOSVersion()()
{
  id v22 = (id)objc_opt_self(NSProcessInfo);
  id v0 = [v22 processInfo];
  uint64_t v1 = (char *)v0;
  objc_msgSend_stret(&v23, v1, "operatingSystemVersion");
  uint64_t countAndFlagsBits = v23._countAndFlagsBits;

  v23._uint64_t countAndFlagsBits = countAndFlagsBits;
  v3._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  char object = v3._object;
  Swift::String v23 = v3;
  swift_bridgeObjectRetain(v3._object);
  v5._uint64_t countAndFlagsBits = 46;
  v5._char object = (void *)0xE100000000000000;
  String.append(_:)(v5);
  swift_bridgeObjectRelease(object);
  Swift::String v6 = v23;
  id v7 = [v22 processInfo];
  long long v8 = (char *)v7;
  [v8 operatingSystemVersion:&v23];
  char v9 = v23._object;

  v23._uint64_t countAndFlagsBits = (uint64_t)v9;
  uint64_t v10 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  unint64_t v12 = v11;
  Swift::String v23 = v6;
  swift_bridgeObjectRetain(v6._object);
  v5._uint64_t countAndFlagsBits = v10;
  v5._char object = v12;
  String.append(_:)(v5);
  swift_bridgeObjectRelease(v6._object);
  swift_bridgeObjectRelease(v12);
  unint64_t v13 = v23._object;
  swift_bridgeObjectRetain(v23._object);
  v5._uint64_t countAndFlagsBits = 46;
  v5._char object = (void *)0xE100000000000000;
  String.append(_:)(v5);
  swift_bridgeObjectRelease(v13);
  Swift::String v14 = v23;
  id v15 = [v22 processInfo];
  int64_t v16 = (char *)v15;
  objc_msgSend_stret(&v23, v16, "operatingSystemVersion");
  uint64_t v17 = v24;

  v23._uint64_t countAndFlagsBits = v17;
  uint64_t v18 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  uint64_t v20 = v19;
  Swift::String v23 = v14;
  swift_bridgeObjectRetain(v14._object);
  v5._uint64_t countAndFlagsBits = v18;
  v5._char object = v20;
  String.append(_:)(v5);
  swift_bridgeObjectRelease(v14._object);
  swift_bridgeObjectRelease(v20);
  return v23;
}

uint64_t TrainingTablePrinter.print(_:)(uint64_t a1, __m128 a2)
{
  uint64_t v42 = v2;
  uint64_t v43 = a1;
  uint64_t v46 = type metadata accessor for MetricsKey(0);
  uint64_t v45 = *(void *)(v46 - 8);
  int64_t v3 = *(void *)(v45 + 64);
  uint64_t v4 = alloca(v3);
  Swift::String v5 = alloca(v3);
  uint64_t v47 = v36;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey)?)
                             - 8)
                 + 64);
  id v7 = alloca(v6);
  long long v8 = alloca(v6);
  char v44 = v36;
  char v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  char v39 = v36;
  uint64_t v49 = type metadata accessor for TrainingTablePrinter(0);
  uint64_t v38 = *(int *)(v49 + 20);
  uint64_t v50 = *(void *)(v2 + v38);
  LOBYTE(v48) = static os_log_type_t.info.getter();
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  unint64_t v12 = (void *)swift_allocObject(v11, 152, 7);
  _OWORD v12[2] = 3;
  _OWORD v12[3] = 6;
  v12[7] = &type metadata for Int;
  v12[8] = &protocol witness table for Int;
  double v12[4] = 2;
  v12[12] = &type metadata for Int;
  v12[13] = &protocol witness table for Int;
  v12[9] = 0;
  uint64_t v13 = Event.itemCount.getter();
  v12[17] = &type metadata for Int;
  v12[18] = &protocol witness table for Int;
  v12[14] = v13;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %d", 34, 2, &dword_0);
  swift_bridgeObjectRelease((_BYTE)v12);
  unsigned __int8 v51 = static os_log_type_t.info.getter();
  uint64_t v48 = v11;
  uint64_t v14 = swift_allocObject(v11, 152, 7);
  *(void *)(v14 + 16) = 3;
  *(void *)(v14 + 24) = 6;
  uint64_t v15 = (uint64_t)v47;
  *(void *)(v14 + 56) = &type metadata for Int;
  *(void *)(v14 + 64) = &protocol witness table for Int;
  *(void *)(v14 + 32) = 2;
  *(void *)(v14 + 96) = &type metadata for Int;
  *(void *)(v14 + 104) = &protocol witness table for Int;
  *(void *)(v14 + 72) = 1;
  uint64_t v16 = v42;
  *(double *)a2.i64 = Date.timeIntervalSinceNow.getter();
  *(void *)(v14 + 136) = &type metadata for Double;
  *(void *)(v14 + 144) = &protocol witness table for Double;
  _mm_storel_ps((double *)(v14 + 112), _mm_xor_ps(a2, (__m128)xmmword_3474C0));
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %f", 34, 2, &dword_0, v50, v51, v14);
  swift_bridgeObjectRelease(v14);
  uint64_t v17 = *(void *)(v16 + *(int *)(v49 + 24));
  uint64_t v18 = v39;
  specialized EnumeratedSequence.makeIterator()(v17);
  char v19 = v17;
  uint64_t v20 = v46;
  swift_bridgeObjectRetain(v19);
  uint64_t v21 = (uint64_t)v44;
  specialized EnumeratedSequence.Iterator.next()();
  outlined init with take of (offset: Int, element: MetricsKey)?(v21, (uint64_t)v18);
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey));
  if (__swift_getEnumTagSinglePayload((uint64_t)v18, 1, v22) != 1)
  {
    uint64_t v49 = *(void *)(v45 + 32);
    do
    {
      uint64_t v23 = *v18;
      ((void (*)(uint64_t, char *, uint64_t))v49)(v15, (char *)v18 + *(int *)(v22 + 48), v20);
      uint64_t v24 = Event.metrics.getter();
      if (*(void *)(v24 + 16) && (unint64_t v25 = specialized __RawDictionaryStorage.find<A>(_:)(v15), (v26 & 1) != 0))
      {
        outlined init with copy of Any(*(void *)(v24 + 56) + 32 * v25, (uint64_t)&v40);
      }
      else
      {
        long long v41 = 0;
        long long v40 = 0;
      }
      swift_bridgeObjectRelease(v24);
      if (!*((void *)&v41 + 1))
      {
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v40, &demangling cache variable for type metadata for Sendable?);
LABEL_14:
        *(void *)&long long v40 = 0;
        *((void *)&v40 + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(32);
        v35._char object = "gUtilities.swift" + 0x8000000000000000;
        v35._uint64_t countAndFlagsBits = 0xD00000000000001DLL;
        String.append(_:)(v35);
        _print_unlocked<A, B>(_:_:)(v47, &v40, v46, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
        v35._uint64_t countAndFlagsBits = 46;
        v35._char object = (void *)0xE100000000000000;
        String.append(_:)(v35);
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v40, *((void *)&v40 + 1), "CreateML/_LoggingUtilities.swift", 32, 2, 103, 0);
        BUG();
      }
      uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
      if (!swift_dynamicCast(&v37, &v40, v27, &type metadata for Double, 6)) {
        goto LABEL_14;
      }
      uint64_t v50 = v37;
      uint64_t v28 = *(void *)(v42 + v38);
      unsigned __int8 v29 = static os_log_type_t.info.getter();
      uint64_t v30 = (void *)swift_allocObject(v48, 152, 7);
      v30[2] = 3;
      uint64_t v30[3] = 6;
      v30[7] = &type metadata for Int;
      v30[8] = &protocol witness table for Int;
      v30[4] = 2;
      BOOL v31 = __OFADD__(2, v23);
      uint64_t v32 = v23 + 2;
      if (v31) {
        BUG();
      }
      v30[12] = &type metadata for Int;
      v30[13] = &protocol witness table for Int;
      v30[9] = v32;
      v30[17] = &type metadata for Double;
      v30[18] = &protocol witness table for Double;
      v30[14] = v50;
      os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %f", 34, 2, &dword_0, v28, v29, v30);
      swift_bridgeObjectRelease((_BYTE)v30);
      uint64_t v15 = (uint64_t)v47;
      uint64_t v20 = v46;
      (*(void (**)(uint64_t *, uint64_t))(v45 + 8))(v47, v46);
      uint64_t v33 = (uint64_t)v44;
      specialized EnumeratedSequence.Iterator.next()();
      outlined init with take of (offset: Int, element: MetricsKey)?(v33, (uint64_t)v18);
      uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey));
    }
    while (__swift_getEnumTagSinglePayload((uint64_t)v18, 1, v22) != 1);
  }
  return outlined consume of [String : [Int]].Iterator._Variant(v36[1]);
}

uint64_t outlined init with take of (offset: Int, element: MetricsKey)?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey)?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t lazy protocol witness table accessor for type MetricsKey and conformance MetricsKey()
{
  uint64_t result = lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey;
  if (!lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey)
  {
    uint64_t v1 = type metadata accessor for MetricsKey(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MetricsKey, v1);
    lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey = result;
  }
  return result;
}

void *initializeBufferWithCopyOfBuffer for _TablePrinter(void *a1, char *a2, int *a3)
{
  int64_t v3 = a1;
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v12 = *(void *)a2;
    void *v3 = *(void *)a2;
    int64_t v3 = (void *)(v12 + ((v4 + 16) & ~v4));
    swift_retain(v12);
  }
  else
  {
    *a1 = *(void *)a2;
    uint64_t v6 = a3[5];
    uint64_t v7 = type metadata accessor for Date(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 16))((char *)a1 + v6, &a2[v6], v7);
    uint64_t v8 = a3[6];
    char v9 = *(void **)&a2[v8];
    *(void *)((char *)v3 + v8) = v9;
    uint64_t v10 = a3[7];
    *(void *)((char *)v3 + v10) = *(void *)&a2[v10];
    uint64_t v11 = *(void *)&a2[v10 + 8];
    *(void *)((char *)v3 + v10 + 8) = v11;
    v9;
    swift_bridgeObjectRetain(v11);
  }
  return v3;
}

uint64_t destroy for _TablePrinter(uint64_t a1, int *a2)
{
  uint64_t v2 = a1 + a2[5];
  uint64_t v3 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8))(v2, v3);

  return swift_bridgeObjectRelease(*(void *)(a1 + a2[7] + 8));
}

char *initializeWithCopy for _TablePrinter(char *a1, char *a2, int *a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v5 = a3[5];
  uint64_t v6 = type metadata accessor for Date(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16))(&a1[v5], &a2[v5], v6);
  uint64_t v7 = a3[6];
  uint64_t v8 = *(void **)&a2[v7];
  *(void *)&a1[v7] = v8;
  uint64_t v9 = a3[7];
  *(void *)&a1[v9] = *(void *)&a2[v9];
  uint64_t v10 = *(void *)&a2[v9 + 8];
  *(void *)&a1[v9 + 8] = v10;
  v8;
  swift_bridgeObjectRetain(v10);
  return a1;
}

char *assignWithCopy for _TablePrinter(char *a1, char *a2, int *a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v5 = a3[5];
  uint64_t v6 = type metadata accessor for Date(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 24))(&a1[v5], &a2[v5], v6);
  uint64_t v7 = a3[6];
  uint64_t v8 = *(void **)&a2[v7];
  uint64_t v9 = *(void **)&a1[v7];
  *(void *)&a1[v7] = v8;
  v8;

  uint64_t v10 = a3[7];
  *(void *)&a1[v10] = *(void *)&a2[v10];
  uint64_t v11 = *(void *)&a2[v10 + 8];
  uint64_t v12 = *(void *)&a1[v10 + 8];
  *(void *)&a1[v10 + 8] = v11;
  swift_bridgeObjectRetain(v11);
  swift_bridgeObjectRelease(v12);
  return a1;
}

char *initializeWithTake for _TablePrinter(char *a1, char *a2, int *a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v4 = a3[5];
  uint64_t v5 = type metadata accessor for Date(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v5 - 8) + 32))(&a1[v4], &a2[v4], v5);
  *(void *)&a1[a3[6]] = *(void *)&a2[a3[6]];
  *(_OWORD *)&a1[a3[7]] = *(_OWORD *)&a2[a3[7]];
  return a1;
}

char *assignWithTake for _TablePrinter(char *a1, char *a2, int *a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v5 = a3[5];
  uint64_t v6 = type metadata accessor for Date(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 40))(&a1[v5], &a2[v5], v6);
  uint64_t v7 = a3[6];
  uint64_t v8 = *(void **)&a1[v7];
  *(void *)&a1[v7] = *(void *)&a2[v7];

  uint64_t v9 = a3[7];
  *(void *)&a1[v9] = *(void *)&a2[v9];
  uint64_t v10 = *(void *)&a1[v9 + 8];
  *(void *)&a1[v9 + 8] = *(void *)&a2[v9 + 8];
  swift_bridgeObjectRelease(v10);
  return a1;
}

uint64_t getEnumTagSinglePayload for _TablePrinter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_2B9E88);
}

uint64_t sub_2B9E88(uint64_t a1, unsigned int a2, uint64_t a3)
{
  unsigned int v4 = 0;
  uint64_t v5 = type metadata accessor for Date(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(*(int *)(a3 + 20) + a1, a2, v5);
  }
  if ((*(void *)(a1 + *(int *)(a3 + 24)) & 0xFFFFFFFF00000001) == 0) {
    return (*(void *)(a1 + *(int *)(a3 + 24)) >> 1) + 1;
  }
  return v4;
}

uint64_t storeEnumTagSinglePayload for _TablePrinter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_2B9F0A);
}

uint64_t sub_2B9F0A(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = type metadata accessor for Date(0);
  if (*(_DWORD *)(*(void *)(v6 - 8) + 84) == a3) {
    return __swift_storeEnumTagSinglePayload(*(int *)(a4 + 20) + a1, a2, a2, v6);
  }
  uint64_t result = *(int *)(a4 + 24);
  *(void *)(a1 + result) = 2 * (a2 - 1);
  return result;
}

uint64_t type metadata completion function for _TablePrinter(uint64_t a1)
{
  v3[0] = (char *)&value witness table for Builtin.Int64 + 64;
  uint64_t result = type metadata accessor for Date(319);
  if (v2 <= 0x3F)
  {
    v3[1] = *(void *)(result - 8) + 64;
    v3[2] = (char *)&value witness table for Builtin.UnknownObject + 64;
    v3[3] = &unk_351998;
    swift_initStructMetadata(a1, 256, 4, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t MLActionClassifier.DataSource.videosWithAnnotations()(__m128 a1)
{
  *(void *)&long long v164 = v2;
  v173._char countAndFlagsBits = v3;
  uint64_t v163 = v1;
  v168._char object = (void *)type metadata accessor for DataFrame(0);
  v173._char object = (void *)*((void *)v168._object - 1);
  int64_t v4 = *((void *)v173._object + 8);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v165 = &v135;
  uint64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  uint64_t named = (uint64_t)&v135;
  uint64_t v9 = (void *)type metadata accessor for UTType(0);
  uint64_t v10 = *(v9 - 1);
  int64_t v11 = *(void *)(v10 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  v168._char countAndFlagsBits = (uint64_t)&v135;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  *(void *)uint64_t v166 = &v135;
  uint64_t v172 = type metadata accessor for URL(0);
  *(void *)uint64_t v176 = *(void *)(v172 - 8);
  int64_t v16 = *(void *)(*(void *)v176 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v162 = &v135;
  char v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v161 = &v135;
  uint64_t v21 = alloca(v16);
  uint64_t v22 = alloca(v16);
  uint64_t v160 = &v135;
  uint64_t v23 = alloca(v16);
  uint64_t v24 = alloca(v16);
  v170._char object = &v135;
  unint64_t v25 = alloca(v16);
  char v26 = alloca(v16);
  v170._char countAndFlagsBits = (uint64_t)&v135;
  uint64_t v27 = alloca(v16);
  uint64_t v28 = alloca(v16);
  *(void *)uint64_t v169 = &v135;
  uint64_t v29 = type metadata accessor for MLActionClassifier.DataSource(0);
  int64_t v30 = *(void *)(*(void *)(v29 - 8) + 64);
  BOOL v31 = alloca(v30);
  uint64_t v32 = alloca(v30);
  outlined init with copy of MLActionClassifier.DataSource(v173._countAndFlagsBits, (uint64_t)&v135);
  switch(swift_getEnumCaseMultiPayload(&v135, v29))
  {
    case 0u:
      uint64_t v33 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      uint64_t v34 = (void **)((char *)&v135 + v33[12]);
      uint64_t v35 = v33[16];
      v168._char countAndFlagsBits = *(uint64_t *)((char *)&v135 + v35);
      v173._char countAndFlagsBits = *(uint64_t *)((char *)&v135 + v35 + 8);
      uint64_t v36 = v33[20];
      *(void *)uint64_t v166 = *(void **)((char *)&v135 + v36);
      v173._char object = *(void **)((char *)&v135 + v36 + 8);
      uint64_t v37 = v33[24];
      *(void *)uint64_t v169 = *(void **)((char *)&v135 + v37);
      uint64_t named = *(uint64_t *)((char *)&v135 + v37 + 8);
      uint64_t v38 = v33[28];
      v170._char countAndFlagsBits = *(uint64_t *)((char *)&v135 + v38);
      v168._char object = *(void **)((char *)&v135 + v38 + 8);
      char v39 = *(void (**)(void *, void **, uint64_t))(*(void *)v176 + 32);
      uint64_t v40 = v172;
      v39(v170._object, &v135, v172);
      long long v41 = v160;
      v39(v160, v34, v40);
      uint64_t v42 = v161;
      (*(void (**)(void **, void **, uint64_t))(*(void *)v176 + 16))(v161, v41, v40);
      LOBYTE(v136) = 1;
      *(_DWORD *)((char *)&v136 + 1) = *(_DWORD *)v154;
      DWORD1(v136) = *(_DWORD *)&v154[3];
      *((void *)&v136 + 1) = 44;
      unint64_t v137 = 0xE100000000000000;
      uint64_t v138 = 0;
      char v171 = 1;
      unint64_t v139 = 0xE000000000000000;
      uint64_t v140 = &stru_20 + 60;
      uint64_t v141 = (void *)0xE100000000000000;
      LOBYTE(v142) = 1;
      *(_DWORD *)((char *)&v142 + 1) = *(_DWORD *)v155;
      HIDWORD(v142) = *(_DWORD *)&v155[3];
      uint64_t v143 = 34;
      unint64_t v144 = 0xE100000000000000;
      char v145 = 1;
      *(_DWORD *)&v146[3] = *(_DWORD *)&v156[3];
      *(_DWORD *)uint64_t v146 = *(_DWORD *)v156;
      uint64_t v147 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
      uint64_t v148 = 10;
      unint64_t v149 = 0xE100000000000000;
      long long v150 = 0;
      char v151 = 1;
      *(_DWORD *)uint64_t v152 = *(_DWORD *)v157;
      *(_DWORD *)&v152[3] = *(_DWORD *)&v157[3];
      uint64_t v153 = 0;
      uint64_t v43 = v164;
      MLDataTable.init(contentsOf:options:)(v42, &v136);
      char v44 = v41;
      if (v43)
      {
        uint64_t v45 = *(void (**)(void **, uint64_t))(*(void *)v176 + 8);
        v45(v41, v40);
        swift_bridgeObjectRelease(v173._object);
        swift_bridgeObjectRelease(v173._countAndFlagsBits);
        swift_bridgeObjectRelease(named);
        swift_bridgeObjectRelease(v168._object);
        return ((uint64_t (*)(void *, uint64_t))v45)(v170._object, v40);
      }
      *(void *)&long long v164 = 0;
      *(void *)uint64_t v174 = v158;
      LOBYTE(v175) = v159;
      v79._char countAndFlagsBits = v168._countAndFlagsBits;
      v79._char object = (void *)v173._countAndFlagsBits;
      MLDataTable.subscript.getter(v79);
      uint64_t v80 = v136;
      char v81 = BYTE8(v136);
      if (BYTE8(v136)
        || (outlined copy of Result<_DataTable, Error>(v136, 0),
            uint64_t v165 = (void **)v80,
            _UntypedColumn.type.getter(),
            uint64_t v80 = (uint64_t)v165,
            outlined consume of Result<_DataTable, Error>((uint64_t)v165, 0),
            (_BYTE)v158 != 2))
      {
        outlined consume of Result<_DataTable, Error>(v80, v81);
        swift_bridgeObjectRelease(v173._object);
        swift_bridgeObjectRelease(named);
        swift_bridgeObjectRelease(v168._object);
        *(void *)&long long v136 = 0;
        *((void *)&v136 + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(26);
        swift_bridgeObjectRelease(BYTE8(v136));
        *(void *)&long long v136 = 0x206E6D756C6F43;
        *((void *)&v136 + 1) = 0xE700000000000000;
        v119._char countAndFlagsBits = v168._countAndFlagsBits;
        char countAndFlagsBits = v173._countAndFlagsBits;
        v119._char object = (void *)v173._countAndFlagsBits;
        String.append(_:)(v119);
        swift_bridgeObjectRelease(countAndFlagsBits);
        v119._char countAndFlagsBits = 0xD000000000000011;
        String.append(_:)(v119);
        long long v164 = v136;
        v119._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v119._object, 0, 0);
        *(_OWORD *)uint64_t v121 = v164;
        *(_OWORD *)(v121 + 16) = 0;
        *(_OWORD *)(v121 + 32) = 0;
        *(unsigned char *)(v121 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v119._object, v121, v122, v123, v124);
        long long v111 = *(void (**)(void **, uint64_t))(*(void *)v176 + 8);
        uint64_t v113 = v44;
        uint64_t v112 = v172;
        goto LABEL_29;
      }
      outlined copy of Result<_DataTable, Error>(v80, 0);
      _UntypedColumn.valueAtIndex(index:)(0, 0.0);
      unint64_t v83 = *((void *)&v136 + 1);
      uint64_t v82 = v136;
      if ((_BYTE)v137 != 2)
      {
        outlined consume of MLDataValue((void *)v136, *((void **)&v136 + 1), v137);
        uint64_t v82 = 0;
        unint64_t v83 = 0xE000000000000000;
      }
      outlined consume of Result<_DataTable, Error>((uint64_t)v165, 0);
      *(void *)&long long v136 = v82;
      *((void *)&v136 + 1) = v83;
      uint64_t v84 = String.init<A>(_:)(&v136, &type metadata for String, &protocol witness table for String, &protocol witness table for String);
      char v86 = v85;
      URL.init(fileURLWithPath:)(v84, v85);
      swift_bridgeObjectRelease(v86);
      char v87 = objc_opt_self(NSFileManager);
      id v88 = [v87 defaultManager];
      id v89 = v88;
      URL.path.getter(v88);
      char v91 = v90;
      NSString v92 = String._bridgeToObjectiveC()();
      swift_bridgeObjectRelease(v91);
      unsigned __int8 v93 = [v89 fileExistsAtPath:v92];

      if (!v93)
      {
        uint64_t v94 = (uint64_t)v165;
        outlined copy of Result<_DataTable, Error>((uint64_t)v165, 0);
        uint64_t v95 = specialized Array<A>.init(_:)(v94, 0, 0.0);
        uint64_t v96 = alloca(24);
        uint64_t v97 = alloca(32);
        *((void *)&v136 + 1) = v170._object;
        uint64_t v98 = v164;
        uint64_t v99 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_SSs5NeverOTg5((void (*)(void *))partial apply for closure #1 in static _VideoUtilities.getVideoURLsAndAnnotations(from:), (uint64_t)&v135, (uint64_t)v95);
        *(void *)&long long v164 = v98;
        swift_bridgeObjectRelease((_BYTE)v95);
        uint64_t v161 = &v135;
        *(void *)&long long v136 = v99;
        double v100 = alloca(24);
        uint64_t v101 = alloca(24);
        *((void *)&v136 + 1) = &v136;
        uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
        char v104 = v103;
        swift_bridgeObjectRelease(v136);
        uint64_t v105 = v173._countAndFlagsBits;
        swift_bridgeObjectRetain(v173._countAndFlagsBits);
        MLDataTable.willMutate()();
        *(void *)&long long v136 = ML14_UntypedColumnC_s5Error_pTgm5;
        BYTE8(v136) = v104 & 1;
        MLDataTable.setColumnImpl(newColumn:named:)((uint64_t)&v136, v168._countAndFlagsBits, v105);
        swift_bridgeObjectRelease(v105);
        outlined consume of Result<_DataTable, Error>(ML14_UntypedColumnC_s5Error_pTgm5, v104);
        if (!(_BYTE)v175)
        {
          uint64_t v106 = *(void *)v174;
          outlined copy of Result<_DataTable, Error>(*(uint64_t *)v174, 0);
          _DataTable.columnNamesDidChange()();
          outlined consume of Result<_DataTable, Error>(v106, 0);
        }
      }
      uint64_t v107 = v164;
      char v108 = v173._countAndFlagsBits;
      char object = (char)v168._object;
      v134._char object = v168._object;
      v134._char countAndFlagsBits = v170._countAndFlagsBits;
      char v110 = named;
      static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v174, v168._countAndFlagsBits, (void *)v173._countAndFlagsBits, *(void **)v166, v173._object, *(uint64_t *)v169, 0.0, (void *)named, v134);
      if (v107)
      {
        swift_bridgeObjectRelease(v108);
        swift_bridgeObjectRelease(v173._object);
        swift_bridgeObjectRelease(v110);
        swift_bridgeObjectRelease(object);
        outlined consume of Result<_DataTable, Error>((uint64_t)v165, 0);
        long long v111 = *(void (**)(void **, uint64_t))(*(void *)v176 + 8);
        uint64_t v112 = v172;
        v111(v162, v172);
        uint64_t v113 = v160;
LABEL_29:
        v111(v113, v112);
        v111((void **)v170._object, v112);
        return outlined consume of Result<_DataTable, Error>(*(uint64_t *)v174, v175);
      }
      swift_bridgeObjectRelease(v108);
      swift_bridgeObjectRelease(v173._object);
      swift_bridgeObjectRelease(v110);
      swift_bridgeObjectRelease(object);
      outlined consume of Result<_DataTable, Error>((uint64_t)v165, 0);
      unint64_t v129 = *(void (**)(void **, uint64_t))(*(void *)v176 + 8);
      uint64_t v130 = v172;
      v129(v162, v172);
      v129(v160, v130);
      v129((void **)v170._object, v130);
LABEL_33:
      Swift::String v131 = v163;
      uint64_t result = *(void *)v174;
      char v132 = v175;
      void *v163 = *(void *)v174;
      *((unsigned char *)v131 + 8) = v132;
      return result;
    case 1u:
      v173._char object = v9;
      v173._char countAndFlagsBits = v10;
      uint64_t v47 = v170._countAndFlagsBits;
      uint64_t v48 = v172;
      uint64_t v49 = *(void *)v176;
      (*(void (**)(uint64_t, void **, uint64_t))(*(void *)v176 + 32))(v170._countAndFlagsBits, &v135, v172);
      uint64_t v50 = v168._countAndFlagsBits;
      static UTType.movie.getter();
      uint64_t v51 = v164;
      uint64_t v52 = static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)(v47, v50);
      if (v51)
      {
        (*(void (**)(uint64_t, void *))(v173._countAndFlagsBits + 8))(v168._countAndFlagsBits, v173._object);
        return (*(uint64_t (**)(uint64_t, uint64_t))(v49 + 8))(v170._countAndFlagsBits, v48);
      }
      uint64_t v114 = (uint64_t)v52;
      (*(void (**)(uint64_t, void *))(v173._countAndFlagsBits + 8))(v168._countAndFlagsBits, v173._object);
      static _VideoUtilities.generateVideoTable(_:)(v114);
      swift_bridgeObjectRelease(v114);
      uint64_t v126 = v136;
      char v127 = BYTE8(v136);
      *(void *)uint64_t v174 = v136;
      LOBYTE(v175) = BYTE8(v136) & 1;
      BYTE8(v136) &= 1u;
      outlined copy of Result<_DataTable, Error>(v136, v127);
      static _VideoUtilities.validateVideoInput(trainingData:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)&v136, 0x7461506F65646976, 0xE900000000000068, 0x6C6562616CLL, 0xE500000000000000, 0, 0.0, 0, 0, 0);
      outlined consume of Result<_DataTable, Error>(v126, v127);
      uint64_t v128 = v170._countAndFlagsBits;
      goto LABEL_31;
    case 2u:
      v173._char object = v9;
      v173._char countAndFlagsBits = v10;
      uint64_t v53 = *(void *)v169;
      uint64_t v54 = v172;
      uint64_t v55 = *(void *)v176;
      (*(void (**)(void, void **, uint64_t))(*(void *)v176 + 32))(*(void *)v169, &v135, v172);
      Swift::String v56 = *(void **)v166;
      static UTType.movie.getter();
      uint64_t v57 = v164;
      uint64_t v58 = static _FileUtilities.collectFilesLabeledByFileName(at:type:)(v53, (uint64_t)v56);
      if (v57)
      {
        (*(void (**)(void, void *))(v173._countAndFlagsBits + 8))(*(void *)v166, v173._object);
        return (*(uint64_t (**)(void, uint64_t))(v55 + 8))(*(void *)v169, v54);
      }
      uint64_t v115 = v58;
      (*(void (**)(void, void *))(v173._countAndFlagsBits + 8))(*(void *)v166, v173._object);
      static _VideoUtilities.generateVideoTable(_:)(v115);
      swift_bridgeObjectRelease(v115);
      uint64_t v125 = v136;
      LOBYTE(v115) = BYTE8(v136);
      *(void *)uint64_t v174 = v136;
      LOBYTE(v175) = BYTE8(v136) & 1;
      BYTE8(v136) &= 1u;
      outlined copy of Result<_DataTable, Error>(v136, v115);
      static _VideoUtilities.validateVideoInput(trainingData:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)&v136, 0x7461506F65646976, 0xE900000000000068, 0x6C6562616CLL, 0xE500000000000000, 0, 0.0, 0, 0, 0);
      outlined consume of Result<_DataTable, Error>(v125, v115);
      uint64_t v128 = *(void *)v169;
LABEL_31:
      (*(void (**)(uint64_t, uint64_t))(*(void *)v176 + 8))(v128, v172);
      goto LABEL_33;
    case 3u:
      char v59 = v137;
      char v60 = v139;
      char v61 = (char)v141;
      outlined consume of Result<_DataTable, Error>((uint64_t)v135, v136);
      swift_bridgeObjectRelease(v61);
      swift_bridgeObjectRelease(v60);
      swift_bridgeObjectRelease(v59);
      return MLDataTable.init()();
    case 4u:
      *(void *)uint64_t v176 = *((void *)&v136 + 1);
      uint64_t v62 = (void *)v137;
      uint64_t v172 = v138;
      uint64_t v63 = (void *)v139;
      v173._char object = v140;
      v168._char object = v141;
      v173._char countAndFlagsBits = v142;
      uint64_t v64 = (void *)v143;
      *(void *)uint64_t v174 = v135;
      LOBYTE(v175) = v136 & 1;
      v170._char object = v135;
      LODWORD(named) = v136;
      outlined copy of Result<_DataTable, Error>((uint64_t)v135, v136);
      uint64_t v65 = *(void *)v176;
      *(void *)uint64_t v176 = v63;
      uint64_t v66 = v63;
      uint64_t v67 = v164;
      v133._char object = v64;
      v133._char countAndFlagsBits = v173._countAndFlagsBits;
      char v68 = (char)v168._object;
      static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v174, v65, v62, (void *)v172, v66, (uint64_t)v173._object, *(double *)a1.i64, v168._object, v133);
      if (!v67)
      {
        swift_bridgeObjectRelease((_BYTE)v62);
        swift_bridgeObjectRelease(v176[0]);
        swift_bridgeObjectRelease((_BYTE)v64);
        swift_bridgeObjectRelease(v68);
        outlined consume of Result<_DataTable, Error>((uint64_t)v170._object, named);
        goto LABEL_33;
      }
      swift_bridgeObjectRelease((_BYTE)v62);
      swift_bridgeObjectRelease(v176[0]);
      swift_bridgeObjectRelease((_BYTE)v64);
      swift_bridgeObjectRelease(v68);
      outlined consume of Result<_DataTable, Error>((uint64_t)v170._object, named);
      return outlined consume of Result<_DataTable, Error>(*(uint64_t *)v174, v175);
    case 5u:
      uint64_t v69 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      swift_bridgeObjectRelease(*(void **)((char *)&v135 + v69[12] + 8));
      swift_bridgeObjectRelease(*(void **)((char *)&v135 + v69[16] + 8));
      swift_bridgeObjectRelease(*(void **)((char *)&v135 + v69[20] + 8));
      (*((void (**)(void **, void *))v173._object + 1))(&v135, v168._object);
      return MLDataTable.init()();
    case 6u:
      unsigned int v70 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      uint64_t v71 = v70[12];
      v168._char countAndFlagsBits = *(uint64_t *)((char *)&v135 + v71);
      *(void *)uint64_t v176 = *(void **)((char *)&v135 + v71 + 8);
      uint64_t v72 = v70[16];
      *(void *)uint64_t v166 = *(void **)((char *)&v135 + v72);
      v173._char countAndFlagsBits = *(uint64_t *)((char *)&v135 + v72 + 8);
      uint64_t v73 = v70[20];
      *(void *)uint64_t v169 = *(void **)((char *)&v135 + v73);
      uint64_t v172 = *(uint64_t *)((char *)&v135 + v73 + 8);
      Swift::String v170 = *(Swift::String *)((char *)&v135 + v70[24]);
      uint64_t v74 = named;
      uint64_t v75 = v168._object;
      uint64_t v76 = (double (**)(void **, uint64_t, void *))v173._object;
      (*((void (**)(uint64_t, void **, void *))v173._object + 4))(named, &v135, v168._object);
      uint64_t v77 = (uint64_t)v165;
      *(double *)a1.i64 = v76[2](v165, v74, v75);
      uint64_t v78 = v164;
      MLDataTable.init(_:convertArraysToShapedArrays:)(v77, 0, a1);
      if (v78)
      {
        (*((void (**)(uint64_t, void *))v173._object + 1))(named, v168._object);
        swift_bridgeObjectRelease(v173._countAndFlagsBits);
        swift_bridgeObjectRelease(v176[0]);
        swift_bridgeObjectRelease(v172);
        return swift_bridgeObjectRelease(v170._object);
      }
      uint64_t v116 = named;
      *(void *)uint64_t v174 = v136;
      LOBYTE(v175) = BYTE8(v136);
      char v117 = (char)v170._object;
      char v118 = v172;
      static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)((uint64_t)v174, v168._countAndFlagsBits, *(void **)v176, *(void **)v166, (void *)v173._countAndFlagsBits, *(uint64_t *)v169, *(double *)a1.i64, (void *)v172, v170);
      (*((void (**)(uint64_t, void *))v173._object + 1))(v116, v168._object);
      swift_bridgeObjectRelease(v176[0]);
      swift_bridgeObjectRelease(v173._countAndFlagsBits);
      swift_bridgeObjectRelease(v117);
      swift_bridgeObjectRelease(v118);
      goto LABEL_33;
  }
}