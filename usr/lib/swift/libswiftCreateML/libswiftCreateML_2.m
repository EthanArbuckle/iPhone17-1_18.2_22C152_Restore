ValueMetadata *type metadata accessor for MLDataTable.Rows()
{
  return &type metadata for MLDataTable.Rows;
}

uint64_t initializeWithCopy for MLDataTable.Rows(uint64_t a1, uint64_t a2)
{
  return initializeBufferWithCopyOfBuffer for MLDataTable.Rows(a1, a2);
}

uint64_t protocol witness for RandomAccessCollection.index(_:offsetBy:) in conformance MLDataTable.Rows(uint64_t *a1, uint64_t a2)
{
  return protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance MLDataTable.Rows(a1, a2);
}

uint64_t protocol witness for RandomAccessCollection.distance(from:to:) in conformance MLDataTable.Rows(uint64_t *a1, uint64_t *a2)
{
  return protocol witness for BidirectionalCollection.distance(from:to:) in conformance MLDataTable.Rows(a1, a2);
}

uint64_t _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML30MLLogisticRegressionClassifierV_s5Error_pTgm503_s8c4ML30efg80V12handleResult33_66687B25F10324110578427E448BFE6CLL_7session7fulfillys0G0Oyyts5H55_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZACyKXEfU_AE08Logisticfg8TrainingW8DelegateCTf1nc_n(uint64_t a1)
{
  uint64_t v10 = v1;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLLogisticRegressionClassifier, Error>);
  int64_t v3 = *(void *)(*(void *)(v2 - 8) + 64);
  v4 = alloca(v3);
  v5 = alloca(v3);
  v6 = alloca(v3);
  v7 = alloca(v3);
  swift_retain();
  MLLogisticRegressionClassifier.init(delegate:)(a1);
  swift_storeEnumTagMultiPayload(v9, v2, 0);
  outlined init with take of DataFrame?((uint64_t)v9, (uint64_t)v9, &demangling cache variable for type metadata for Result<MLLogisticRegressionClassifier, Error>);
  outlined init with take of DataFrame?((uint64_t)v9, v10, &demangling cache variable for type metadata for Result<MLLogisticRegressionClassifier, Error>);
  return swift_release();
}

void MLLogisticRegressionClassifier.predictions(from:)(uint64_t a1)
{
  int64_t v3 = v2;
  uint64_t v14 = v1;
  uint64_t v5 = type metadata accessor for DataFrame(0);
  uint64_t v13 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v13 + 64);
  v7 = alloca(v6);
  v8 = alloca(v6);
  v15 = &v12;
  uint64_t v9 = type metadata accessor for MLLogisticRegressionClassifier(0);
  DataFrame.validateContainsColumns(_:context:)(*(Swift::OpaquePointer *)((char *)v3 + *(int *)(v9 + 28)), (Swift::String)__PAIR128__(0xE700000000000000, 0x65727574616546));
  if (!v10)
  {
    MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)(a1, 0, 0);
    v11 = v15;
    DataFrame.subscript.getter(*v3, v3[1]);
    (*(void (**)(uint64_t *, uint64_t))(v13 + 8))(v11, v5);
  }
}

uint64_t type metadata accessor for MLLogisticRegressionClassifier(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLLogisticRegressionClassifier;
  if (!type metadata singleton initialization cache for MLLogisticRegressionClassifier) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLLogisticRegressionClassifier);
  }
  return result;
}

uint64_t MLLogisticRegressionClassifier.predictions(from:)(uint64_t a1, __m128 a2)
{
  uint64_t v15 = v3;
  uint64_t v16 = v2;
  uint64_t v17 = type metadata accessor for DataFrame(0);
  uint64_t v18 = *(void *)(v17 - 8);
  int64_t v4 = *(void *)(v18 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  int64_t v7 = *(void *)(*(void *)(type metadata accessor for AnyColumn(0) - 8) + 64);
  v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  char v10 = *(unsigned char *)(a1 + 8);
  uint64_t v13 = *(void *)a1;
  char v14 = v10;
  outlined copy of Result<_DataTable, Error>(v13, v10);
  DataFrame.init(_:)((uint64_t)&v13);
  uint64_t v11 = v15;
  MLLogisticRegressionClassifier.predictions(from:)((uint64_t)&v13);
  if (v11) {
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v18 + 8))(&v13, v17);
  }
  *(double *)a2.i64 = (*(double (**)(uint64_t *, uint64_t))(v18 + 8))(&v13, v17);
  return MLUntypedColumn.init(_:convertArraysToShapedArrays:)((uint64_t)&v13, 1, a2);
}

uint64_t MLLogisticRegressionClassifier.evaluation(on:)(uint64_t a1)
{
  int64_t v4 = v1;
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for AnyClassificationMetrics(0) - 8) + 64);
  int64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v8 = type metadata accessor for MLLogisticRegressionClassifier(0);
  uint64_t v9 = *(int *)(v8 + 28);
  uint64_t v28 = v2;
  v10._rawValue = *(void **)(v2 + v9);
  uint64_t v27 = a1;
  DataFrame.validateContainsColumns(_:context:)(v10, (Swift::String)__PAIR128__(0xE700000000000000, 0x65727574616546));
  if (v11) {
    goto LABEL_6;
  }
  v29 = &v25;
  v30 = v4;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  inited = (void *)swift_initStackObject(v12, v26);
  inited[2] = 1;
  inited[3] = 2;
  uint64_t v14 = *(int *)(v8 + 24);
  uint64_t v15 = *(void *)(v28 + v14 + 8);
  inited[4] = *(void *)(v28 + v14);
  inited[5] = v15;
  swift_bridgeObjectRetain(v15);
  uint64_t v16 = v27;
  DataFrame.validateContainsColumns(_:context:)((Swift::OpaquePointer)inited, (Swift::String)__PAIR128__(0xE500000000000000, 0x6C6562614CLL));
  if (v11)
  {
    swift_setDeallocating(inited);
    specialized _ContiguousArrayStorage.__deallocating_deinit();
    int64_t v4 = v30;
LABEL_6:
    void *v4 = v11;
    uint64_t v18 = type metadata accessor for MLClassifierMetrics.Contents(0);
    uint64_t v19 = 2;
    v20 = v4;
    uint64_t v21 = v18;
    return swift_storeEnumTagMultiPayload(v20, v21, v19);
  }
  swift_setDeallocating(inited);
  specialized _ContiguousArrayStorage.__deallocating_deinit();
  uint64_t v17 = v29;
  MLLogisticRegressionClassifier.Model.computeMetrics(on:)(v16);
  uint64_t v23 = (uint64_t)v17;
  uint64_t v24 = (uint64_t)v30;
  outlined init with take of MLClassifierMetrics(v23, (uint64_t)v30, type metadata accessor for AnyClassificationMetrics);
  v20 = (void *)v24;
  uint64_t v21 = type metadata accessor for MLClassifierMetrics.Contents(0);
  uint64_t v19 = 0;
  return swift_storeEnumTagMultiPayload(v20, v21, v19);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  int64_t v4;
  void *v5;
  void *v6;
  char v7;
  uint64_t v9;
  char v10;
  uint64_t v11;

  uint64_t v11 = v1;
  uint64_t v2 = type metadata accessor for DataFrame(0);
  uint64_t v3 = *(void *)(v2 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  int64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  int64_t v7 = *(unsigned char *)(a1 + 8);
  uint64_t v9 = *(void *)a1;
  Swift::OpaquePointer v10 = v7;
  outlined copy of Result<_DataTable, Error>(v9, v7);
  DataFrame.init(_:)((uint64_t)&v9);
  MLLogisticRegressionClassifier.evaluation(on:)((uint64_t)&v9);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v3 + 8))(&v9, v2);
}

uint64_t MLLogisticRegressionClassifier.write(to:metadata:)(uint64_t a1, uint64_t *a2)
{
  uint64_t v63 = v2;
  uint64_t v62 = v3;
  uint64_t v61 = a1;
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for MLLogisticRegressionClassifier.Model(0) - 8) + 64);
  int64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  v45 = &v40;
  uint64_t v54 = type metadata accessor for Model(0);
  uint64_t v53 = *(void *)(v54 - 8);
  int64_t v7 = *(void *)(v53 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  v42 = &v40;
  uint64_t v10 = type metadata accessor for URL(0);
  uint64_t v11 = *(void *)(v10 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v47 = *a2;
  uint64_t v43 = a2[1];
  unint64_t v48 = a2[2];
  v49 = (char *)a2[3];
  uint64_t v50 = a2[4];
  uint64_t v51 = a2[5];
  uint64_t v46 = a2[6];
  unint64_t v52 = a2[7];
  uint64_t v15 = a2[8];
  uint64_t v16 = v63;
  uint64_t result = static _ValidationUtilities.validateWriteLocation(atURL:defaultName:fileExtension:)(v61, 0xD00000000000001CLL, (unint64_t)("Algorithm type: " + 0x8000000000000000), 0x6C65646F6D6C6DLL, (void *)0xE700000000000000);
  if (!v16)
  {
    uint64_t v63 = 0;
    v56 = &v40;
    uint64_t v57 = v10;
    uint64_t v55 = v11;
    outlined init with copy of MLTrainingSessionParameters(v62, (uint64_t)v45, type metadata accessor for MLLogisticRegressionClassifier.Model);
    uint64_t v18 = v43;
    uint64_t v44 = v15;
    if (v43)
    {
      uint64_t v19 = v47;
      uint64_t v61 = v43;
      uint64_t v20 = v48;
      unint64_t v21 = v48;
      uint64_t v22 = (uint64_t)v49;
      v60 = v49;
      uint64_t v23 = v50;
      uint64_t v24 = v50;
      uint64_t v25 = v51;
      uint64_t v58 = v51;
      uint64_t v26 = v46;
      uint64_t v27 = v46;
      uint64_t v28 = v52;
      unint64_t v59 = v52;
      uint64_t v62 = v15;
      uint64_t v29 = v47;
    }
    else
    {
      v30 = NSFullUserName();
      v31 = v30;
      uint64_t v29 = static String._unconditionallyBridgeFromObjectiveC(_:)(v31);
      uint64_t v61 = v32;

      v60 = "RandomForestRegressor" + 0x8000000000000000;
      unint64_t v21 = 0xD000000000000033;
      unint64_t v59 = 0xE100000000000000;
      uint64_t v27 = 49;
      uint64_t v24 = 0;
      uint64_t v58 = 0;
      uint64_t v62 = 0;
      uint64_t v26 = v46;
      uint64_t v19 = v47;
      uint64_t v20 = v48;
      uint64_t v22 = (uint64_t)v49;
      uint64_t v23 = v50;
      uint64_t v25 = v51;
      uint64_t v28 = v52;
    }
    v41[0] = v29;
    v41[1] = v61;
    v41[2] = v21;
    v41[3] = v60;
    v41[4] = v24;
    v41[5] = v58;
    v41[6] = v27;
    v41[7] = v59;
    v41[8] = v62;
    outlined copy of MLModelMetadata?(v19, v18, v20, v22, v23, v25, v26, v28, v44);
    v33 = v42;
    uint64_t v34 = (uint64_t)v45;
    uint64_t v35 = v63;
    specialized CoreMLExportable.export(metadata:)((uint64_t)v41);
    if (v35)
    {
      uint64_t v63 = v35;
      swift_bridgeObjectRelease(v59);
      swift_bridgeObjectRelease((_BYTE)v60);
      swift_bridgeObjectRelease(v61);
      swift_bridgeObjectRelease(v58);
      swift_bridgeObjectRelease(v62);
      outlined destroy of MLActivityClassifier.ModelParameters(v34, type metadata accessor for MLLogisticRegressionClassifier.Model);
      uint64_t v36 = v55;
      uint64_t v37 = v57;
      v39 = v56;
    }
    else
    {
      swift_bridgeObjectRelease(v59);
      swift_bridgeObjectRelease((_BYTE)v60);
      swift_bridgeObjectRelease(v61);
      swift_bridgeObjectRelease(v58);
      swift_bridgeObjectRelease(v62);
      outlined destroy of MLActivityClassifier.ModelParameters(v34, type metadata accessor for MLLogisticRegressionClassifier.Model);
      v38 = v56;
      Model.write(to:)(v56);
      uint64_t v63 = 0;
      uint64_t v36 = v55;
      (*(void (**)(uint64_t *, uint64_t))(v53 + 8))(v33, v54);
      v39 = v38;
      uint64_t v37 = v57;
    }
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v36 + 8))(v39, v37);
  }
  return result;
}

uint64_t MLLogisticRegressionClassifier.write(toFile:metadata:)(uint64_t a1, uint64_t a2, long long *a3)
{
  uint64_t v23 = v3;
  uint64_t v25 = a2;
  uint64_t v24 = a1;
  uint64_t v26 = type metadata accessor for URL.DirectoryHint(0);
  uint64_t v27 = *(void *)(v26 - 8);
  int64_t v5 = *(void *)(v27 + 64);
  int64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v11 = type metadata accessor for URL(0);
  uint64_t v29 = *(void *)(v11 - 8);
  int64_t v12 = *(void *)(v29 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v28 = *((void *)a3 + 8);
  long long v19 = *a3;
  long long v20 = a3[1];
  long long v21 = a3[2];
  long long v22 = a3[3];
  uint64_t v30 = v11;
  __swift_storeEnumTagSinglePayload((uint64_t)v17, 1, 1, v11);
  (*(void (**)(_OWORD *, void, uint64_t))(v27 + 104))(v17, enum case for URL.DirectoryHint.inferFromPath(_:), v26);
  uint64_t v15 = v25;
  swift_bridgeObjectRetain(v25);
  URL.init(filePath:directoryHint:relativeTo:)(v24, v15, v17, v17);
  v17[0] = v19;
  v17[1] = v20;
  v17[2] = v21;
  v17[3] = v22;
  uint64_t v18 = v28;
  MLLogisticRegressionClassifier.write(to:metadata:)((uint64_t)v17, (uint64_t *)v17);
  return (*(uint64_t (**)(_OWORD *, uint64_t))(v29 + 8))(v17, v30);
}

id MLLogisticRegressionClassifier.model.getter()
{
  uint64_t v1 = type metadata accessor for MLLogisticRegressionClassifier(0);
  return *(id *)(v0 + *(int *)(v1 + 20));
}

unint64_t MLLogisticRegressionClassifier.description.getter()
{
  return MLLogisticRegressionClassifier.debugDescription.getter();
}

unint64_t MLLogisticRegressionClassifier.debugDescription.getter()
{
  uint64_t v1 = v0;
  v25._char object = (void *)type metadata accessor for MLClassifierMetrics.Contents(0);
  int64_t v2 = *(void *)(*((void *)v25._object - 1) + 64);
  uint64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  uint64_t v5 = type metadata accessor for MLLogisticRegressionClassifier(0);
  v25._countAndFlagsBits = MLLogisticRegressionClassifier.ModelParameters.description.getter();
  int64_t v7 = v6;
  v22._countAndFlagsBits = MLClassifierMetrics.description.getter();
  v22._char object = v8;
  uint64_t v9 = *(int *)(v5 + 40);
  uint64_t v10 = v7;
  outlined init with copy of MLTrainingSessionParameters(v1 + v9, (uint64_t)&v20, type metadata accessor for MLClassifierMetrics.Contents);
  LODWORD(v7) = swift_getEnumCaseMultiPayload(&v20, v25._object);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v20, type metadata accessor for MLClassifierMetrics.Contents);
  v25._char object = (void *)MLClassifierMetrics.description.getter();
  int64_t v12 = v11;
  unint64_t v23 = 0xD000000000000029;
  uint64_t v24 = "LogisticRegressionClassifier" + 0x8000000000000000;
  v13._countAndFlagsBits = v25._countAndFlagsBits;
  v25._countAndFlagsBits = (uint64_t)v10;
  v13._char object = v10;
  String.append(_:)(v13);
  v21._countAndFlagsBits = 0xD00000000000001ELL;
  v21._char object = "ActivityClassifier\n\nParameters\n" + 0x8000000000000000;
  char object = (char)v22._object;
  String.append(_:)(v22);
  char v15 = (char)v21._object;
  String.append(_:)(v21);
  swift_bridgeObjectRelease(v15);
  if (v7 > 1)
  {
    char v18 = object;
  }
  else
  {
    v21._countAndFlagsBits = 0xD000000000000020;
    v21._char object = "\nPerformance on Training Data\n" + 0x8000000000000000;
    v16._countAndFlagsBits = (uint64_t)v25._object;
    v16._char object = v12;
    String.append(_:)(v16);
    char v17 = (char)v21._object;
    String.append(_:)(v21);
    swift_bridgeObjectRelease(object);
    char v18 = (char)v12;
    LOBYTE(v12) = v17;
  }
  swift_bridgeObjectRelease(v18);
  swift_bridgeObjectRelease((_BYTE)v12);
  swift_bridgeObjectRelease(v25._countAndFlagsBits);
  return v23;
}

NSAttributedString MLLogisticRegressionClassifier.playgroundDescription.getter()
{
  uint64_t v1 = v0;
  uint64_t v2 = type metadata accessor for NSAttributedString();
  v3._countAndFlagsBits = MLLogisticRegressionClassifier.debugDescription.getter();
  v3._char object = v4;
  result.super.isa = NSAttributedString.__allocating_init(string:)(v3).super.isa;
  v1[3].super.isa = (Class)v2;
  v1->super.isa = result.super.isa;
  return result;
}

void key path setter for MLLogisticRegressionClassifier.model : MLLogisticRegressionClassifier(id *a1)
{
  id v1 = *a1;
  MLLogisticRegressionClassifier.model.setter((uint64_t)v1);
}

void MLLogisticRegressionClassifier.model.setter(uint64_t a1)
{
  uint64_t v2 = *(int *)(type metadata accessor for MLLogisticRegressionClassifier(0) + 20);

  *(void *)(v1 + v2) = a1;
}

void (*MLLogisticRegressionClassifier.model.modify(uint64_t a1))(uint64_t a1, char a2)
{
  *(void *)(a1 + 8) = v1;
  uint64_t v3 = *(int *)(type metadata accessor for MLLogisticRegressionClassifier(0) + 20);
  *(_DWORD *)(a1 + 16) = v3;
  int64_t v4 = *(void **)(v1 + v3);
  *(void *)a1 = v4;
  v4;
  return MLActivityClassifier.model.modify;
}

uint64_t MLLogisticRegressionClassifier.targetColumn.getter()
{
  uint64_t v1 = *(int *)(type metadata accessor for MLLogisticRegressionClassifier(0) + 24);
  uint64_t v2 = *(void *)(v0 + v1);
  swift_bridgeObjectRetain(*(void *)(v0 + v1 + 8));
  return v2;
}

uint64_t MLLogisticRegressionClassifier.targetColumn.setter(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(int *)(type metadata accessor for MLLogisticRegressionClassifier(0) + 24);
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v2 + v3 + 8));
  *(void *)(v2 + v3) = a1;
  *(void *)(v2 + v3 + 8) = a2;
  return result;
}

void (*MLLogisticRegressionClassifier.targetColumn.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLLogisticRegressionClassifier.featureColumns.getter()
{
  uint64_t v1 = type metadata accessor for MLLogisticRegressionClassifier(0);
  return swift_bridgeObjectRetain(*(void *)(v0 + *(int *)(v1 + 28)));
}

uint64_t MLLogisticRegressionClassifier.featureColumns.setter(uint64_t a1)
{
  uint64_t v2 = *(int *)(type metadata accessor for MLLogisticRegressionClassifier(0) + 28);
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v1 + v2));
  *(void *)(v1 + v2) = a1;
  return result;
}

void (*MLLogisticRegressionClassifier.featureColumns.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLLogisticRegressionClassifier.modelParameters.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLLogisticRegressionClassifier(0);
  return outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v1 + *(int *)(v3 + 32), v2);
}

uint64_t MLLogisticRegressionClassifier.trainingMetrics.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLLogisticRegressionClassifier(0);
  return outlined init with copy of MLTrainingSessionParameters(v1 + *(int *)(v3 + 36), v2, type metadata accessor for MLClassifierMetrics);
}

uint64_t MLLogisticRegressionClassifier.validationMetrics.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLLogisticRegressionClassifier(0);
  return outlined init with copy of MLTrainingSessionParameters(v1 + *(int *)(v3 + 40), v2, type metadata accessor for MLClassifierMetrics);
}

uint64_t static MLLogisticRegressionClassifier._defaultSessionParameters.getter()
{
  uint64_t v1 = v0;
  if (one-time initialization token for _defaultSessionParameters != -1) {
    swift_once(&one-time initialization token for _defaultSessionParameters, one-time initialization function for _defaultSessionParameters);
  }
  uint64_t v2 = type metadata accessor for MLTrainingSessionParameters(0);
  uint64_t v3 = __swift_project_value_buffer(v2, (uint64_t)static MLLogisticRegressionClassifier._defaultSessionParameters);
  return outlined init with copy of MLTrainingSessionParameters(v3, v1, type metadata accessor for MLTrainingSessionParameters);
}

uint64_t MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, int *a4, const void *a5)
{
  uint64_t v26 = v6;
  uint64_t v34 = a5;
  uint64_t v37 = a4;
  uint64_t v28 = a3;
  uint64_t v36 = a2;
  uint64_t v35 = a1;
  uint64_t v7 = v5;
  uint64_t v29 = *(void *)(type metadata accessor for MLLogisticRegressionClassifier.Model(0) - 8);
  int64_t v27 = *(void *)(v29 + 64);
  int64_t v8 = alloca(v27);
  uint64_t v9 = alloca(v27);
  uint64_t v30 = &v26;
  uint64_t v10 = (int *)type metadata accessor for MLLogisticRegressionClassifier(0);
  uint64_t v31 = v7 + v10[9];
  MLClassifierMetrics.init()();
  uint64_t v11 = v10[10];
  uint64_t v12 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v13 = swift_allocError(&type metadata for MLCreateError, v12, 0, 0);
  *(void *)uint64_t v14 = 0xD0000000000000C0;
  *(void *)(v14 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v14 + 16) = 0;
  *(_OWORD *)(v14 + 32) = 0;
  *(unsigned char *)(v14 + 48) = 0;
  *(void *)(v7 + v11) = v13;
  uint64_t v15 = type metadata accessor for MLClassifierMetrics.Contents(0);
  uint64_t v32 = v7 + v11;
  swift_storeEnumTagMultiPayload(v7 + v11, v15, 2);
  uint64_t v33 = v10[7];
  *(void *)(v7 + v33) = v37;
  uint64_t v37 = v10;
  uint64_t v16 = v10[6];
  *(void *)(v7 + v16) = v36;
  uint64_t v36 = v16;
  *(void *)(v7 + v16 + 8) = v28;
  uint64_t v17 = (uint64_t)v30;
  outlined init with copy of MLTrainingSessionParameters(v35, (uint64_t)v30, type metadata accessor for MLLogisticRegressionClassifier.Model);
  uint64_t v18 = *(unsigned __int8 *)(v29 + 80);
  uint64_t v19 = ~*(unsigned __int8 *)(v29 + 80) & (v18 + 16);
  uint64_t v20 = swift_allocObject(&unk_398D60, v19 + v27, v18 | 7);
  outlined init with take of MLClassifierMetrics(v17, v20 + v19, type metadata accessor for MLLogisticRegressionClassifier.Model);
  uint64_t v21 = v26;
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:), v20);
  uint64_t v23 = v22;
  swift_release();
  if (v21)
  {
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters((uint64_t)v34);
    outlined destroy of MLActivityClassifier.ModelParameters(v35, type metadata accessor for MLLogisticRegressionClassifier.Model);
    swift_bridgeObjectRelease(*(void *)(v7 + v36 + 8));
    swift_bridgeObjectRelease(*(void *)(v7 + v33));
    outlined destroy of MLActivityClassifier.ModelParameters(v31, type metadata accessor for MLClassifierMetrics);
    return outlined destroy of MLActivityClassifier.ModelParameters(v32, type metadata accessor for MLClassifierMetrics);
  }
  else
  {
    Swift::String v25 = v37;
    *(void *)(v7 + v37[5]) = v23;
    uint64_t result = outlined init with take of MLClassifierMetrics(v35, v7, type metadata accessor for MLLogisticRegressionClassifier.Model);
    qmemcpy((void *)(v7 + v25[8]), v34, 0x49uLL);
  }
  return result;
}

uint64_t closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
  uint64_t v2 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                         + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v3 = (void *)swift_task_alloc(dword_3AE264);
  *(void *)(v1 + 24) = v3;
  *uint64_t v3 = v1;
  v3[1] = closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:);
  return v2();
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;

  int64_t v4 = *v2;
  uint64_t v5 = *(void *)(*v2 + 24);
  uint64_t v6 = *v2;
  swift_task_dealloc(v5);
  if (v1) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v4 + 32) = a1;
  return swift_task_switch(closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:), 0, 0);
}

uint64_t MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(void (*a1)(uint64_t *, uint64_t, uint64_t), uint64_t a2, void *a3, void (*a4)(uint64_t *, uint64_t), uint64_t a5)
{
  v197 = (void (*)(uint64_t *, uint64_t))a4;
  _ = a3;
  uint64_t v7 = v5;
  v190._countAndFlagsBits = a2;
  uint64_t v195 = v6;
  uint64_t v192 = a5;
  v193 = a1;
  int64_t v8 = *(void *)(*(void *)(type metadata accessor for AnyClassificationMetrics(0) - 8) + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  v170 = &v153;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  v166 = &v153;
  int64_t v13 = *(void *)(*(void *)(type metadata accessor for MLClassifierMetrics(0) - 8) + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  v171 = &v153;
  uint64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  v167 = &v153;
  uint64_t v164 = *(void *)(type metadata accessor for MLLogisticRegressionClassifier.Model(0) - 8);
  int64_t v18 = *(void *)(v164 + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  v162 = &v153;
  int64_t v163 = v18;
  uint64_t v21 = alloca(v18);
  uint64_t v22 = alloca(v18);
  v189 = &v153;
  int64_t v23 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                              - 8)
                  + 64);
  uint64_t v24 = alloca(v23);
  Swift::String v25 = alloca(v23);
  v158 = &v153;
  int64_t v26 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?)
                              - 8)
                  + 64);
  int64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  uint64_t v183 = (uint64_t)&v153;
  uint64_t v173 = type metadata accessor for AnyColumn(0);
  int64_t v29 = *(void *)(*(void *)(v173 - 8) + 64);
  uint64_t v30 = alloca(v29);
  uint64_t v31 = alloca(v29);
  v175 = &v153;
  uint64_t v32 = alloca(v29);
  uint64_t v33 = alloca(v29);
  v181 = &v153;
  uint64_t v34 = alloca(v29);
  uint64_t v35 = alloca(v29);
  uint64_t v182 = (uint64_t)&v153;
  int64_t v36 = *(void *)(*(void *)(type metadata accessor for MLLogisticRegressionClassifier.Classifier(0) - 8) + 64);
  uint64_t v37 = alloca(v36);
  v38 = alloca(v36);
  v184 = &v153;
  uint64_t v191 = type metadata accessor for DataFrame(0);
  uint64_t v186 = *(void *)(v191 - 8);
  int64_t v39 = *(void *)(v186 + 64);
  uint64_t v40 = alloca(v39);
  v41 = alloca(v39);
  v169 = &v153;
  v42 = alloca(v39);
  uint64_t v43 = alloca(v39);
  v179 = &v153;
  uint64_t v44 = alloca(v39);
  v45 = alloca(v39);
  v165 = &v153;
  uint64_t v46 = alloca(v39);
  uint64_t v47 = alloca(v39);
  v160 = &v153;
  v187 = (void *)type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData(0);
  int64_t v48 = *(void *)(*(v187 - 1) + 64);
  v49 = alloca(v48);
  uint64_t v50 = alloca(v48);
  uint64_t v185 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
  int64_t v51 = *(void *)(*(void *)(v185 - 8) + 64);
  unint64_t v52 = alloca(v51);
  uint64_t v53 = alloca(v51);
  v168 = &v153;
  uint64_t v54 = alloca(v51);
  uint64_t v55 = alloca(v51);
  v159 = &v153;
  v56 = alloca(v51);
  uint64_t v57 = alloca(v51);
  v178 = &v153;
  uint64_t v58 = alloca(v51);
  unint64_t v59 = alloca(v51);
  v194 = &v153;
  uint64_t v60 = type metadata accessor for MLLogisticRegressionClassifier(0);
  uint64_t v172 = v7 + *(int *)(v60 + 36);
  MLClassifierMetrics.init()();
  uint64_t v174 = v60;
  uint64_t v61 = *(int *)(v60 + 40);
  uint64_t v161 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v62 = swift_allocError(&type metadata for MLCreateError, v161, 0, 0);
  *(void *)uint64_t v63 = 0xD0000000000000C0;
  *(void *)(v63 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  double v64 = 0.0;
  *(_OWORD *)(v63 + 16) = 0;
  *(_OWORD *)(v63 + 32) = 0;
  *(unsigned char *)(v63 + 48) = 0;
  uint64_t v180 = v7;
  *(void *)(v7 + v61) = v62;
  uint64_t v65 = type metadata accessor for MLClassifierMetrics.Contents(0);
  v190._char object = (void *)(v7 + v61);
  uint64_t v176 = v65;
  swift_storeEnumTagMultiPayload(v7 + v61, v65, 2);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v192 + 8, (uint64_t)&v156, &demangling cache variable for type metadata for Any?);
  if (!v157) {
    BUG();
  }
  v66 = v194;
  v67 = (uint64_t *)((char *)v194 + *(int *)(v185 + 48));
  outlined init with take of Any(&v156, v155);
  swift_dynamicCast(&v153, v155, (char *)&type metadata for Any + 8, v187, 7);
  v68 = v193;
  uint64_t v69 = v195;
  MLLogisticRegressionClassifier.ModelParameters.ValidationData.generateDataFrames(trainingData:)((uint64_t)v66, (uint64_t)v67, v193);
  if (v69)
  {
    uint64_t v195 = v69;
    swift_bridgeObjectRelease((_BYTE)_);
    swift_bridgeObjectRelease((_BYTE)v197);
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v192);
    (*(void (**)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))(v186 + 8))(v68, v191);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v153, type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
LABEL_18:
    char object = v190._object;
LABEL_19:
    outlined destroy of MLActivityClassifier.ModelParameters(v172, type metadata accessor for MLClassifierMetrics);
    return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)object, type metadata accessor for MLClassifierMetrics);
  }
  v187 = v67;
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v153, type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
  v70 = v194;
  char v71 = (char)v197;
  v72 = static _FeatureUtilities.selectFeaturesFromTrainingData(trainingData:targetColumn:featureColumns:)((uint64_t)v194, v190._countAndFlagsBits, _, (uint64_t)v197);
  uint64_t v195 = 0;
  v73 = v70;
  v188 = (double *)v72;
  swift_bridgeObjectRelease(v71);
  v74 = v178;
  uint64_t v75 = (uint64_t)v178 + *(int *)(v185 + 48);
  v76 = v73;
  uint64_t v77 = v191;
  v177 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v186 + 16);
  v177(v178, v76, v191);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v187, v75, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload(v75, 1, v77) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v75, &demangling cache variable for type metadata for DataFrame?);
    v197 = *(void (**)(uint64_t *, uint64_t))(v186 + 8);
    v197(v74, v77);
    uint64_t v78 = v77;
  }
  else
  {
    v82 = v160;
    uint64_t v83 = v75;
    uint64_t v84 = v186;
    (*(void (**)(uint64_t *, uint64_t, uint64_t))(v186 + 32))(v160, v83, v77);
    v197 = *(void (**)(uint64_t *, uint64_t))(v84 + 8);
    v197(v74, v77);
    uint64_t v85 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
    inited = (void *)swift_initStackObject(v85, v154);
    inited[2] = 1;
    inited[3] = 2;
    inited[4] = v190._countAndFlagsBits;
    char v87 = (char)_;
    inited[5] = _;
    swift_bridgeObjectRetain(v87);
    DataFrame.validateContainsColumns(_:context:)((Swift::OpaquePointer)inited, (Swift::String)__PAIR128__((unint64_t)("Algorithm type: " + 0x8000000000000000), 0xD00000000000001CLL));
    uint64_t v195 = v88;
    if (v88)
    {
      swift_setDeallocating(inited);
      specialized _ContiguousArrayStorage.__deallocating_deinit();
      swift_bridgeObjectRelease((_BYTE)_);
      swift_bridgeObjectRelease((_BYTE)v188);
      outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v192);
      uint64_t v89 = v191;
      v90 = v197;
      v197((uint64_t *)v193, v191);
      v90(v82, v89);
LABEL_17:
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v194, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      goto LABEL_18;
    }
    swift_setDeallocating(inited);
    specialized _ContiguousArrayStorage.__deallocating_deinit();
    uint64_t v103 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any.Type>);
    v104 = (void *)swift_allocObject(v103, 48, 7);
    v104[2] = 2;
    v104[3] = 4;
    v104[4] = &type metadata for String;
    v104[5] = &type metadata for Int;
    v105._countAndFlagsBits = v190._countAndFlagsBits;
    v105._char object = _;
    DataFrame.validateColumnTypes(_:_:context:)(v105, (Swift::OpaquePointer)v104, (Swift::String)__PAIR128__((unint64_t)("Algorithm type: " + 0x8000000000000000), 0xD00000000000001CLL));
    uint64_t v195 = v106;
    if (v106)
    {
      swift_bridgeObjectRelease((_BYTE)_);
      swift_bridgeObjectRelease((_BYTE)v188);
      swift_bridgeObjectRelease((_BYTE)v104);
      outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v192);
      uint64_t v107 = v191;
      v108 = v197;
      v197((uint64_t *)v193, v191);
      v108(v82, v107);
      goto LABEL_17;
    }
    uint64_t v117 = v191;
    v197(v82, v191);
    char v118 = (char)v104;
    uint64_t v78 = v117;
    swift_bridgeObjectRelease(v118);
  }
  DataFrame.subscript.getter(v190._countAndFlagsBits, _);
  v79 = v159;
  uint64_t v80 = (uint64_t)v159 + *(int *)(v185 + 48);
  v177(v159, v194, v78);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v187, v80, &demangling cache variable for type metadata for DataFrame?);
  uint64_t v81 = (uint64_t)v158;
  outlined init with take of DataFrame?(v80, (uint64_t)v158, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload(v81, 1, v78) == 1)
  {
    v197(v79, v78);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v81, &demangling cache variable for type metadata for DataFrame?);
    __swift_storeEnumTagSinglePayload(v183, 1, 1, v173);
  }
  else
  {
    uint64_t v91 = v183;
    DataFrame.subscript.getter(v190._countAndFlagsBits, _);
    uint64_t v92 = v191;
    uint64_t v93 = v81;
    v94 = v197;
    v197((uint64_t *)v93, v191);
    __swift_storeEnumTagSinglePayload(v91, 0, 1, v173);
    v94(v79, v92);
  }
  uint64_t v95 = v192;
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v192, (uint64_t)v155);
  uint64_t v96 = (uint64_t)_;
  swift_bridgeObjectRetain((_BYTE)_);
  v97 = v188;
  swift_bridgeObjectRetain((_BYTE)v188);
  uint64_t v98 = (uint64_t)v184;
  uint64_t v99 = v195;
  MLLogisticRegressionClassifier.Classifier.init(trainingLabelsColumn:validationLabelsColumn:annotationColumnName:featureColumnNames:parameters:)(v182, v183, v190._countAndFlagsBits, v96, v97, (uint64_t)v155);
  uint64_t v195 = v99;
  if (v99)
  {
    char v100 = v96;
    v101 = v193;
    swift_bridgeObjectRelease(v100);
    swift_bridgeObjectRelease((_BYTE)v97);
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v95);
    v197((uint64_t *)v101, v191);
    goto LABEL_17;
  }
  v102 = (void (*)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))v197;
  if (*(void *)(*(void *)(v98 + 104) + 16) <= 1uLL)
  {
    swift_bridgeObjectRelease((_BYTE)v188);
    swift_bridgeObjectRelease((_BYTE)_);
    uint64_t v111 = v161;
    uint64_t v112 = swift_allocError(&type metadata for MLCreateError, v161, 0, 0);
    *(void *)uint64_t v113 = 0xD000000000000027;
    *(void *)(v113 + 8) = "onClassifier\n\nParameters\n" + 0x8000000000000000;
    *(_OWORD *)(v113 + 16) = 0;
    *(_OWORD *)(v113 + 32) = 0;
    *(unsigned char *)(v113 + 48) = 0;
    uint64_t v195 = v112;
    swift_willThrow(&type metadata for MLCreateError, v111, v113, v114, v115, v116);
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v95);
    v102(v193, v191);
    outlined destroy of MLActivityClassifier.ModelParameters(v98, type metadata accessor for MLLogisticRegressionClassifier.Classifier);
    goto LABEL_17;
  }
  MLLogisticRegressionClassifier.Classifier.fitted(to:validateOn:eventHandler:)(v194, v187, 0, 0, v64);
  uint64_t v119 = v174;
  uint64_t v120 = *(int *)(v174 + 24);
  uint64_t v121 = v180;
  *(void *)(v180 + v120) = v190._countAndFlagsBits;
  v190._countAndFlagsBits = v120;
  *(void *)(v121 + v120 + 8) = _;
  _ = (void *)(v121 + *(int *)(v119 + 32));
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v192, (uint64_t)_);
  uint64_t v182 = *(int *)(v119 + 28);
  *(void *)(v121 + v182) = v188;
  uint64_t v122 = (uint64_t)v162;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v189, (uint64_t)v162, type metadata accessor for MLLogisticRegressionClassifier.Model);
  uint64_t v123 = *(unsigned __int8 *)(v164 + 80);
  uint64_t v124 = ~*(unsigned __int8 *)(v164 + 80) & (v123 + 16);
  uint64_t v125 = swift_allocObject(&unk_398D00, v124 + v163, v123 | 7);
  outlined init with take of MLClassifierMetrics(v122, v125 + v124, type metadata accessor for MLLogisticRegressionClassifier.Model);
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:), v125);
  uint64_t v127 = v126;
  swift_release();
  uint64_t v183 = *(int *)(v174 + 20);
  uint64_t v128 = v180;
  *(void *)(v180 + v183) = v127;
  v129 = (uint64_t **)v189;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v189, v128, type metadata accessor for MLLogisticRegressionClassifier.Model);
  v130 = v165;
  MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)((uint64_t)v194, 0, 0);
  uint64_t v195 = 0;
  v178 = *v129;
  v134 = v129[1];
  DataFrame.subscript.getter(v178, v134);
  uint64_t v135 = (uint64_t)v175;
  DataFrame.subscript.getter(v178, v134);
  v136 = v166;
  AnyClassificationMetrics.init(_:_:)((uint64_t)v181, v135);
  uint64_t v137 = v191;
  v197(v130, v191);
  uint64_t v138 = (uint64_t)v136;
  uint64_t v139 = (uint64_t)v167;
  outlined init with take of MLClassifierMetrics(v138, (uint64_t)v167, type metadata accessor for AnyClassificationMetrics);
  swift_storeEnumTagMultiPayload(v139, v176, 0);
  outlined assign with take of MLClassifierMetrics(v139, v172);
  v140 = v168;
  uint64_t v141 = (uint64_t)v168 + *(int *)(v185 + 48);
  v177(v168, v194, v137);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v187, v141, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload(v141, 1, v137) == 1)
  {
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v192);
    v142 = (uint64_t (*)(uint64_t *, uint64_t))v197;
    v197((uint64_t *)v193, v137);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v189, type metadata accessor for MLLogisticRegressionClassifier.Model);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v184, type metadata accessor for MLLogisticRegressionClassifier.Classifier);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v194, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v141, &demangling cache variable for type metadata for DataFrame?);
    return v142(v140, v137);
  }
  else
  {
    uint64_t v143 = v141;
    uint64_t v144 = (uint64_t)v179;
    (*(void (**)(uint64_t *, uint64_t, uint64_t))(v186 + 32))(v179, v143, v137);
    v197(v140, v137);
    v145 = v169;
    v146 = v189;
    uint64_t v147 = v195;
    MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)(v144, 0, 0);
    uint64_t v195 = v147;
    if (v147)
    {
      outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v192);
      v148 = (void (*)(uint64_t, uint64_t))v197;
      v197((uint64_t *)v193, v137);
      v148(v144, v137);
      char object = v190._object;
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v189, type metadata accessor for MLLogisticRegressionClassifier.Model);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v184, type metadata accessor for MLLogisticRegressionClassifier.Classifier);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v194, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      uint64_t v131 = v180;
      outlined destroy of MLActivityClassifier.ModelParameters(v180, type metadata accessor for MLLogisticRegressionClassifier.Model);

      uint64_t v132 = (uint64_t)_;
      uint64_t v133 = v182;
      swift_bridgeObjectRelease(*(void *)(v131 + v190._countAndFlagsBits + 8));
      swift_bridgeObjectRelease(*(void *)(v131 + v133));
      outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v132);
      goto LABEL_19;
    }
    uint64_t v185 = *v146;
    _ = (void *)v146[1];
    DataFrame.subscript.getter(v185, _);
    uint64_t v149 = (uint64_t)v175;
    DataFrame.subscript.getter(v185, _);
    uint64_t v150 = (uint64_t)v170;
    AnyClassificationMetrics.init(_:_:)((uint64_t)v181, v149);
    v151 = (void (*)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))v197;
    v197(v145, v137);
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v192);
    v151(v193, v137);
    v151((void (*)(uint64_t *, uint64_t, uint64_t))v179, v137);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v189, type metadata accessor for MLLogisticRegressionClassifier.Model);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v184, type metadata accessor for MLLogisticRegressionClassifier.Classifier);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v194, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    uint64_t v152 = (uint64_t)v171;
    outlined init with take of MLClassifierMetrics(v150, (uint64_t)v171, type metadata accessor for AnyClassificationMetrics);
    swift_storeEnumTagMultiPayload(v152, v176, 0);
    return outlined assign with take of MLClassifierMetrics(v152, (uint64_t)v190._object);
  }
}

uint64_t closure #1 in MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
  uint64_t v2 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                         + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v3 = (void *)swift_task_alloc(dword_3AE264);
  *(void *)(v1 + 24) = v3;
  *uint64_t v3 = v1;
  v3[1] = closure #1 in MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:);
  return v2();
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;

  int64_t v4 = *v2;
  uint64_t v5 = *(void *)(*v2 + 24);
  uint64_t v6 = *v2;
  swift_task_dealloc(v5);
  if (v1) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v4 + 32) = a1;
  return swift_task_switch(closure #1 in MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:), 0, 0);
}

uint64_t MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t *a1, uint64_t a2, void *a3, void (*a4)(uint64_t *, uint64_t), uint64_t a5)
{
  int64_t v13 = a4;
  uint64_t v14 = a3;
  uint64_t v15 = a2;
  int64_t v6 = *(void *)(*(void *)(type metadata accessor for DataFrame(0) - 8) + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  char v9 = *((unsigned char *)a1 + 8);
  uint64_t v11 = *a1;
  char v12 = v9;
  DataFrame.init(_:)((uint64_t)&v11);
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(a5, (uint64_t)&v11);
  MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v11, v15, v14, v13, (uint64_t)&v11);
  return outlined destroy of MLLogisticRegressionClassifier.ModelParameters(a5);
}

uint64_t MLLogisticRegressionClassifier.init(checkpoint:)(uint64_t a1)
{
  uint64_t v57 = v2;
  uint64_t v3 = v1;
  uint64_t v66 = type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData(0);
  int64_t v4 = *(void *)(*(void *)(v66 - 8) + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  double v64 = v55;
  uint64_t v7 = alloca(v4);
  int64_t v8 = alloca(v4);
  uint64_t v63 = v55;
  uint64_t v62 = *(void *)(type metadata accessor for MLLogisticRegressionClassifier.Model(0) - 8);
  int64_t v9 = *(void *)(v62 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v60 = v55;
  int64_t v61 = v9;
  char v12 = alloca(v9);
  int64_t v13 = alloca(v9);
  char v71 = v55;
  uint64_t v58 = type metadata accessor for MLLogisticRegressionClassifier.Classifier(0);
  int64_t v14 = *(void *)(*(void *)(v58 - 8) + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v69 = v55;
  uint64_t v17 = type metadata accessor for MLLogisticRegressionClassifier(0);
  uint64_t v68 = v3 + *(int *)(v17 + 36);
  MLClassifierMetrics.init()();
  uint64_t v67 = v17;
  uint64_t v18 = *(int *)(v17 + 40);
  uint64_t v59 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v19 = swift_allocError(&type metadata for MLCreateError, v59, 0, 0);
  *(void *)uint64_t v20 = 0xD0000000000000C0;
  *(void *)(v20 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v20 + 16) = 0;
  *(_OWORD *)(v20 + 32) = 0;
  *(unsigned char *)(v20 + 48) = 0;
  uint64_t v65 = v3;
  *(void *)(v3 + v18) = v19;
  uint64_t v21 = type metadata accessor for MLClassifierMetrics.Contents(0);
  uint64_t v56 = v18 + v3;
  swift_storeEnumTagMultiPayload(v18 + v3, v21, 2);
  uint64_t v22 = *(int *)(type metadata accessor for MLCheckpoint(0) + 20);
  uint64_t v70 = a1;
  switch(*(unsigned char *)(a1 + v22))
  {
    case 0:
      uint64_t v23 = 0x696C616974696E69;
      unint64_t v24 = 0xEB0000000064657ALL;
      break;
    case 1:
      uint64_t v23 = 0x6974636172747865;
      goto LABEL_6;
    case 2:
      swift_bridgeObjectRelease(0);
      goto LABEL_9;
    case 3:
      uint64_t v23 = 0x697461756C617665;
LABEL_6:
      unint64_t v24 = 0xEA0000000000676ELL;
      break;
    case 4:
      unint64_t v24 = 0xEB00000000676E69;
      uint64_t v23 = 0x636E657265666E69;
      break;
  }
  char v25 = _stringCompareWithSmolCheck(_:_:expecting:)(v23, v24, 0x676E696E69617274, 0xE800000000000000, 0);
  swift_bridgeObjectRelease(v24);
  if (v25)
  {
LABEL_9:
    uint64_t v26 = (uint64_t)v69;
    MLLogisticRegressionClassifier.Classifier.init(labels:annotationColumnName:featureColumnNames:)((uint64_t)_swiftEmptyArrayStorage, 1, 0, 0xE000000000000000, (uint64_t)_swiftEmptyArrayStorage);
    uint64_t v27 = lazy protocol witness table accessor for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier();
    uint64_t v28 = (uint64_t)v71;
    uint64_t v29 = v70;
    uint64_t v30 = v57;
    UpdatableSupervisedTabularEstimator.readWithOptimizer(from:)(v70, v58, v27);
    if (!v30)
    {
      uint64_t v38 = (uint64_t)v60;
      outlined init with copy of MLTrainingSessionParameters(v28, (uint64_t)v60, type metadata accessor for MLLogisticRegressionClassifier.Model);
      uint64_t v39 = *(unsigned __int8 *)(v62 + 80);
      uint64_t v40 = ~*(unsigned __int8 *)(v62 + 80) & (v39 + 16);
      uint64_t v41 = swift_allocObject(&unk_398D28, v40 + v61, v39 | 7);
      outlined init with take of MLClassifierMetrics(v38, v41 + v40, type metadata accessor for MLLogisticRegressionClassifier.Model);
      specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLLogisticRegressionClassifier.init(checkpoint:), v41);
      uint64_t v43 = v42;
      swift_release();
      uint64_t v44 = v67;
      uint64_t v45 = v65;
      *(void *)(v65 + *(int *)(v67 + 20)) = v43;
      outlined init with copy of MLTrainingSessionParameters((uint64_t)v71, v45, type metadata accessor for MLLogisticRegressionClassifier.Model);
      uint64_t v46 = (uint64_t)v63;
      *uint64_t v63 = 0;
      *(_WORD *)(v46 + 16) = 256;
      swift_storeEnumTagMultiPayload(v46, v66, 0);
      uint64_t v47 = v45 + *(int *)(v44 + 32) + 8;
      *(_OWORD *)(v47 + 16) = 0;
      *(_OWORD *)uint64_t v47 = 0;
      *(void *)(v47 - 8) = 10;
      *(__m128 *)(v47 + 32) = _mm_loadh_ps((const double *)&qword_349108);
      *(_OWORD *)(v47 + 48) = xmmword_349110;
      *(unsigned char *)(v47 + 64) = 1;
      uint64_t v48 = (uint64_t)v64;
      outlined init with copy of MLTrainingSessionParameters(v46, (uint64_t)v64, type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
      v55[3] = v66;
      boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v55);
      outlined init with take of MLClassifierMetrics(v48, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
      outlined assign with take of Any?((uint64_t)v55, v47);
      outlined destroy of MLActivityClassifier.ModelParameters(v46, type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
      uint64_t v50 = v67;
      uint64_t v51 = *(int *)(v67 + 24);
      uint64_t v52 = v65;
      *(void *)(v65 + v51) = 0;
      *(void *)(v52 + v51 + 8) = 0xE000000000000000;
      uint64_t v53 = v52;
      outlined destroy of MLActivityClassifier.ModelParameters(v70, type metadata accessor for MLCheckpoint);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v71, type metadata accessor for MLLogisticRegressionClassifier.Model);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v69, type metadata accessor for MLLogisticRegressionClassifier.Classifier);
      uint64_t result = *(int *)(v50 + 28);
      *(void *)(v53 + result) = _swiftEmptyArrayStorage;
      return result;
    }
    outlined destroy of MLActivityClassifier.ModelParameters(v29, type metadata accessor for MLCheckpoint);
    uint64_t v31 = type metadata accessor for MLLogisticRegressionClassifier.Classifier;
    uint64_t v32 = v26;
  }
  else
  {
    uint64_t v33 = v59;
    swift_allocError(&type metadata for MLCreateError, v59, 0, 0);
    *(void *)uint64_t v34 = 0xD000000000000049;
    *(void *)(v34 + 8) = "ds at least two labels." + 0x8000000000000000;
    *(_OWORD *)(v34 + 16) = 0;
    *(_OWORD *)(v34 + 32) = 0;
    *(unsigned char *)(v34 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v33, v34, v35, v36, v37);
    uint64_t v31 = type metadata accessor for MLCheckpoint;
    uint64_t v32 = v70;
  }
  outlined destroy of MLActivityClassifier.ModelParameters(v32, v31);
  outlined destroy of MLActivityClassifier.ModelParameters(v68, type metadata accessor for MLClassifierMetrics);
  return outlined destroy of MLActivityClassifier.ModelParameters(v56, type metadata accessor for MLClassifierMetrics);
}

uint64_t closure #1 in MLLogisticRegressionClassifier.init(checkpoint:)(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
  uint64_t v2 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                         + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v3 = (void *)swift_task_alloc(dword_3AE264);
  *(void *)(v1 + 24) = v3;
  *uint64_t v3 = v1;
  v3[1] = closure #1 in MLRandomForestRegressor.init(checkpoint:);
  return v2();
}

void *static MLLogisticRegressionClassifier.train(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, void *a3, char *a4, uint64_t a5, uint64_t a6)
{
  uint64_t v21 = a6;
  uint64_t v22 = a5;
  uint64_t v23 = a4;
  unint64_t v24 = a3;
  uint64_t v25 = a2;
  uint64_t v7 = type metadata accessor for DataFrame(0);
  uint64_t v8 = *(void *)(v7 - 8);
  int64_t v9 = *(void *)(v8 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  char v12 = *(unsigned char *)(a1 + 8);
  uint64_t v19 = *(void *)a1;
  char v20 = v12;
  outlined copy of Result<_DataTable, Error>(v19, v12);
  DataFrame.init(_:)((uint64_t)&v19);
  uint64_t v13 = static MLLogisticRegressionClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v19, v25, v24, v23, v22, v21);
  uint64_t v14 = v7;
  if (v6) {
    return (void *)(*(uint64_t (**)(uint64_t *, uint64_t))(v8 + 8))(&v19, v7);
  }
  uint64_t v16 = v13;
  (*(void (**)(uint64_t *, uint64_t))(v8 + 8))(&v19, v14);
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLLogisticRegressionClassifier>);
  uint64_t v18 = (void *)swift_allocObject(v17, *(unsigned int *)(v17 + 48), *(unsigned __int16 *)(v17 + 52));
  return specialized MLJob.init(_:)(v18, v16);
}

uint64_t static MLLogisticRegressionClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, void *a3, char *a4, uint64_t a5, uint64_t a6)
{
  uint64_t v16 = a6;
  uint64_t v17 = a5;
  uint64_t v18 = a4;
  uint64_t v19 = a3;
  uint64_t v7 = type metadata accessor for DataFrame(0);
  uint64_t v20 = *(void *)(v7 - 8);
  int64_t v8 = *(void *)(v20 + 64);
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  char v11 = *(unsigned char *)(a1 + 8);
  uint64_t v14 = *(void *)a1;
  char v15 = v11;
  outlined copy of Result<_DataTable, Error>(v14, v11);
  DataFrame.init(_:)((uint64_t)&v14);
  uint64_t v12 = static MLLogisticRegressionClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v14, a2, v19, v18, v17, v16);
  (*(void (**)(uint64_t *, uint64_t))(v20 + 8))(&v14, v7);
  return v12;
}

void *static MLLogisticRegressionClassifier.resume(_:)(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLLogisticRegressionClassifier>);
  uint64_t v2 = (void *)swift_allocObject(v1, *(unsigned int *)(v1 + 48), *(unsigned __int16 *)(v1 + 52));
  swift_retain();
  return specialized MLJob.init(_:)(v2, a1);
}

void *static MLLogisticRegressionClassifier.train(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(void (*a1)(uint64_t *, uint64_t, uint64_t), uint64_t a2, void *a3, char *a4, uint64_t a5, uint64_t a6)
{
  uint64_t result = (void *)static MLLogisticRegressionClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(a1, a2, a3, a4, a5, a6);
  if (!v6)
  {
    uint64_t v8 = (uint64_t)result;
    uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLLogisticRegressionClassifier>);
    uint64_t v10 = (void *)swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
    return specialized MLJob.init(_:)(v10, v8);
  }
  return result;
}

uint64_t static MLLogisticRegressionClassifier.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(void (*a1)(uint64_t *, uint64_t, uint64_t), uint64_t a2, void *a3, char *a4, uint64_t a5, uint64_t a6)
{
  uint64_t v60 = v6;
  uint64_t v52 = a6;
  uint64_t v46 = a4;
  uint64_t v47 = a3;
  uint64_t v48 = a2;
  uint64_t v56 = a1;
  int64_t v8 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v50 = &v40;
  char v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v51 = &v40;
  uint64_t v57 = type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData(0);
  int64_t v13 = *(void *)(*(void *)(v57 - 8) + 64);
  uint64_t v14 = alloca(v13);
  char v15 = alloca(v13);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
  int64_t v17 = *(void *)(*(void *)(v16 - 8) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v55 = &v40;
  uint64_t v20 = alloca(v17);
  uint64_t v21 = alloca(v17);
  uint64_t v54 = &v40;
  uint64_t v22 = alloca(v17);
  uint64_t v23 = alloca(v17);
  uint64_t v59 = &v40;
  uint64_t v49 = a5;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a5 + 8, (uint64_t)&v44, &demangling cache variable for type metadata for Any?);
  if (!v45) {
    BUG();
  }
  uint64_t v58 = v16;
  uint64_t v24 = (uint64_t)v59;
  uint64_t v25 = (uint64_t)v59 + *(int *)(v16 + 48);
  outlined init with take of Any(&v44, &v41);
  swift_dynamicCast(&v40, &v41, (char *)&type metadata for Any + 8, v57, 7);
  uint64_t v26 = v60;
  MLLogisticRegressionClassifier.ModelParameters.ValidationData.generateDataFrames(trainingData:)(v24, v25, v56);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v40, type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData);
  uint64_t v60 = v26;
  if (!v26)
  {
    uint64_t v27 = (void (*)(uint64_t *, uint64_t, uint64_t))((char *)v54 + *(int *)(v58 + 48));
    uint64_t v28 = type metadata accessor for DataFrame(0);
    uint64_t v53 = *(void *)(v28 - 8);
    uint64_t v29 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v53 + 16);
    v29(v54, v59, v28);
    uint64_t v56 = v27;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v25, (uint64_t)v27, &demangling cache variable for type metadata for DataFrame?);
    uint64_t v30 = (uint64_t)v55 + *(int *)(v58 + 48);
    uint64_t v57 = v28;
    v29(v55, v59, v28);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v25, v30, &demangling cache variable for type metadata for DataFrame?);
    outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v49, (uint64_t)&v41);
    outlined init with copy of MLTrainingSessionParameters(v52, (uint64_t)v51, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v25 = type metadata accessor for LogisticRegressionClassifierTrainingSessionDelegate(0);
    uint64_t v58 = swift_allocObject(v25, *(unsigned int *)(v25 + 48), *(unsigned __int16 *)(v25 + 52));
    uint64_t v31 = v46;
    swift_bridgeObjectRetain((_BYTE)v46);
    uint64_t v32 = v47;
    swift_bridgeObjectRetain((_BYTE)v47);
    uint64_t v33 = v60;
    uint64_t v34 = LogisticRegressionClassifierTrainingSessionDelegate.init(trainingData:validationData:targetColumn:featureColumns:modelParameters:sessionParameters:)((uint64_t)v54, v30, v48, v32, v31, (uint64_t)&v41, (uint64_t)v51);
    uint64_t v60 = v33;
    if (v33)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v59, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      (*(void (**)(uint64_t *, uint64_t))(v53 + 8))(v55, v57);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v56, &demangling cache variable for type metadata for DataFrame?);
    }
    else
    {
      uint64_t v35 = v34;
      (*(void (**)(uint64_t *, uint64_t))(v53 + 8))(v55, v57);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v56, &demangling cache variable for type metadata for DataFrame?);
      uint64_t v42 = v25;
      uint64_t v43 = &protocol witness table for LogisticRegressionClassifierTrainingSessionDelegate;
      *(void *)&long long v41 = v35;
      uint64_t v36 = (uint64_t)v50;
      outlined init with copy of MLTrainingSessionParameters(v52, (uint64_t)v50, type metadata accessor for MLTrainingSessionParameters);
      uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>);
      swift_allocObject(v37, *(unsigned int *)(v37 + 48), *(unsigned __int16 *)(v37 + 52));
      swift_retain();
      uint64_t v38 = v60;
      uint64_t v25 = specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)&v41, v36, 8);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v59, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      swift_release();
      uint64_t v60 = v38;
    }
  }
  return v25;
}

uint64_t static MLLogisticRegressionClassifier.restoreTrainingSession(sessionParameters:)(uint64_t a1)
{
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  uint64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  uint64_t v12 = v11;
  uint64_t v5 = alloca(v2);
  uint64_t v6 = alloca(v2);
  outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v11, type metadata accessor for MLTrainingSessionParameters);
  uint64_t v7 = type metadata accessor for LogisticRegressionClassifierTrainingSessionDelegate(0);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  uint64_t result = LogisticRegressionClassifierTrainingSessionDelegate.init(sessionParameters:)((uint64_t)v11);
  if (!v1)
  {
    v11[3] = v7;
    v11[4] = &protocol witness table for LogisticRegressionClassifierTrainingSessionDelegate;
    v11[0] = result;
    uint64_t v9 = (uint64_t)v12;
    outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v12, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLLogisticRegressionClassifier>);
    swift_allocObject(v10, *(unsigned int *)(v10 + 48), *(unsigned __int16 *)(v10 + 52));
    return specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)v11, v9, 8);
  }
  return result;
}

uint64_t closure #1 in closure #1 in static MLLogisticRegressionClassifier.resume(_:)(uint64_t a1, char a2, uint64_t a3, void (*a4)(void *))
{
  uint64_t v16 = a4;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLLogisticRegressionClassifier, Error>);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  if (a2)
  {
    v14[0] = a1;
    swift_storeEnumTagMultiPayload(v14, v6, 1);
    swift_errorRetain(a1);
    v16(v14);
  }
  else
  {
    outlined init with copy of TabularRegressionTask(direct field offset for MLTrainingSession.delegate + a3, (uint64_t)v14);
    uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingSessionDelegate);
    uint64_t v11 = type metadata accessor for LogisticRegressionClassifierTrainingSessionDelegate(0);
    swift_dynamicCast(&v15, v14, v10, v11, 7);
    uint64_t v12 = v15;
    swift_retain();
    _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML30MLLogisticRegressionClassifierV_s5Error_pTgm503_s8c4ML30efg80V12handleResult33_66687B25F10324110578427E448BFE6CLL_7session7fulfillys0G0Oyyts5H55_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZACyKXEfU_AE08Logisticfg8TrainingW8DelegateCTf1nc_n(v12);
    v16(v14);
    swift_release();
  }
  return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v14, &demangling cache variable for type metadata for Result<MLLogisticRegressionClassifier, Error>);
}

uint64_t MLLogisticRegressionClassifier.init(delegate:)(uint64_t a1)
{
  uint64_t v62 = a1;
  uint64_t v60 = v1;
  uint64_t v59 = type metadata accessor for MLClassifierMetrics(0);
  int64_t v3 = *(void *)(*(void *)(v59 - 8) + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v57 = v46;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLClassifierMetrics?)
                             - 8)
                 + 64);
  int64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v56 = v46;
  uint64_t v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  uint64_t v55 = v46;
  int64_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLLogisticRegressionClassifier.Model?)
                              - 8)
                  + 64);
  uint64_t v12 = alloca(v11);
  int64_t v13 = alloca(v11);
  uint64_t v52 = v46;
  uint64_t v61 = type metadata accessor for MLLogisticRegressionClassifier(0);
  int64_t v14 = *(void *)(*(void *)(v61 - 8) + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v53 = v46;
  int64_t v17 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLLogisticRegressionClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v20 = (int *)type metadata accessor for MLLogisticRegressionClassifier.PersistentParameters(0);
  int64_t v21 = *(void *)(*((void *)v20 - 1) + 64);
  uint64_t v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  uint64_t v24 = v62 + OBJC_IVAR____TtC8CreateML51LogisticRegressionClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v62 + OBJC_IVAR____TtC8CreateML51LogisticRegressionClassifierTrainingSessionDelegate_trainingParameters, v48, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v24, (uint64_t)v46, &demangling cache variable for type metadata for MLLogisticRegressionClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload((uint64_t)v46, 1, (uint64_t)v20) == 1) {
    BUG();
  }
  outlined init with take of MLClassifierMetrics((uint64_t)v46, (uint64_t)v46, type metadata accessor for MLLogisticRegressionClassifier.PersistentParameters);
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters((uint64_t)&v46[v20[8]], (uint64_t)v51);
  uint64_t v25 = v20[6];
  uint64_t v54 = *(void *)&v46[v25];
  uint64_t v26 = *(void *)&v46[v25 + 8];
  uint64_t v27 = v20[7];
  uint64_t v58 = v46;
  uint64_t v28 = *(int **)&v46[v27];
  uint64_t v29 = v62 + OBJC_IVAR____TtC8CreateML51LogisticRegressionClassifierTrainingSessionDelegate_model;
  swift_beginAccess(v62 + OBJC_IVAR____TtC8CreateML51LogisticRegressionClassifierTrainingSessionDelegate_model, v49, 0, 0);
  uint64_t v30 = (uint64_t)v52;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v29, (uint64_t)v52, &demangling cache variable for type metadata for MLLogisticRegressionClassifier.Model?);
  uint64_t v31 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  if (__swift_getEnumTagSinglePayload(v30, 1, v31) == 1) {
    BUG();
  }
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters((uint64_t)v51, (uint64_t)v47);
  swift_bridgeObjectRetain(v26);
  swift_bridgeObjectRetain((_BYTE)v28);
  uint64_t v32 = v26;
  uint64_t v33 = v53;
  MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:)(v30, v54, v32, v28, v47);
  if (v2)
  {
    swift_release();
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters((uint64_t)v51);
    return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v58, type metadata accessor for MLLogisticRegressionClassifier.PersistentParameters);
  }
  else
  {
    uint64_t v35 = (uint64_t)v33;
    uint64_t v36 = v60;
    outlined init with take of MLClassifierMetrics(v35, v60, type metadata accessor for MLLogisticRegressionClassifier);
    uint64_t v37 = v62;
    uint64_t v38 = v62 + OBJC_IVAR____TtC8CreateML51LogisticRegressionClassifierTrainingSessionDelegate_trainingMetrics;
    swift_beginAccess(v62 + OBJC_IVAR____TtC8CreateML51LogisticRegressionClassifierTrainingSessionDelegate_trainingMetrics, v47, 0, 0);
    uint64_t v39 = v38;
    uint64_t v40 = (uint64_t)v55;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v39, (uint64_t)v55, &demangling cache variable for type metadata for MLClassifierMetrics?);
    if (__swift_getEnumTagSinglePayload(v40, 1, v59) == 1) {
      BUG();
    }
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters((uint64_t)v51);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v58, type metadata accessor for MLLogisticRegressionClassifier.PersistentParameters);
    outlined assign with take of MLClassifierMetrics(v40, v36 + *(int *)(v61 + 36));
    uint64_t v41 = v37 + OBJC_IVAR____TtC8CreateML51LogisticRegressionClassifierTrainingSessionDelegate_validationMetrics;
    swift_beginAccess(v37 + OBJC_IVAR____TtC8CreateML51LogisticRegressionClassifierTrainingSessionDelegate_validationMetrics, v50, 0, 0);
    uint64_t v42 = v41;
    uint64_t v43 = (uint64_t)v56;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v42, (uint64_t)v56, &demangling cache variable for type metadata for MLClassifierMetrics?);
    swift_release();
    if (__swift_getEnumTagSinglePayload(v43, 1, v59) == 1)
    {
      return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v43, &demangling cache variable for type metadata for MLClassifierMetrics?);
    }
    else
    {
      uint64_t v44 = v43;
      uint64_t v45 = (uint64_t)v57;
      outlined init with take of MLClassifierMetrics(v44, (uint64_t)v57, type metadata accessor for MLClassifierMetrics);
      return outlined assign with take of MLClassifierMetrics(v45, *(int *)(v61 + 40) + v60);
    }
  }
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLLogisticRegressionClassifier()
{
  return MLLogisticRegressionClassifier.description.getter();
}

unint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLLogisticRegressionClassifier()
{
  return MLLogisticRegressionClassifier.debugDescription.getter();
}

NSAttributedString protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLLogisticRegressionClassifier()
{
  return MLLogisticRegressionClassifier.playgroundDescription.getter();
}

uint64_t protocol witness for TabularClassificationTask.validationMetrics.getter in conformance MLLogisticRegressionClassifier()
{
  return MLLogisticRegressionClassifier.validationMetrics.getter();
}

uint64_t sub_DE967()
{
  return objectdestroyTm_0();
}

uint64_t partial apply for closure #1 in MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  uint64_t v2 = (void *)swift_task_alloc(dword_3A6DD4);
  *(void *)(v1 + 16) = v2;
  *uint64_t v2 = v1;
  v2[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:)(a1);
}

uint64_t lazy protocol witness table accessor for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier()
{
  uint64_t result = lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier;
  if (!lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier)
  {
    uint64_t v1 = type metadata accessor for MLLogisticRegressionClassifier.Classifier(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLLogisticRegressionClassifier.Classifier, v1);
    lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier = result;
  }
  return result;
}

{
  uint64_t result;
  uint64_t v1;

  uint64_t result = lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier;
  if (!lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier)
  {
    uint64_t v1 = type metadata accessor for MLLogisticRegressionClassifier.Classifier(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLLogisticRegressionClassifier.Classifier, v1);
    lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier = result;
  }
  return result;
}

uint64_t sub_DEA25()
{
  return objectdestroyTm_0();
}

uint64_t partial apply for closure #1 in MLLogisticRegressionClassifier.init(checkpoint:)(uint64_t a1)
{
  type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  uint64_t v2 = (void *)swift_task_alloc(dword_3A6DEC);
  *(void *)(v1 + 16) = v2;
  *uint64_t v2 = v1;
  v2[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLLogisticRegressionClassifier.init(checkpoint:)(a1);
}

id sub_DEAB0()
{
  uint64_t v1 = v0;
  id result = MLLogisticRegressionClassifier.model.getter();
  *uint64_t v1 = result;
  return result;
}

void sub_DEACA(id *a1)
{
}

void *initializeBufferWithCopyOfBuffer for MLLogisticRegressionClassifier(void *a1, void *a2, int *a3)
{
  int64_t v4 = a1;
  int v5 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v5 & 0x20000) == 0)
  {
    *a1 = *a2;
    uint64_t v6 = a2[1];
    v4[1] = v6;
    uint64_t v7 = a2[2];
    swift_bridgeObjectRetain(v6);
    if (v7)
    {
      v4[2] = v7;
      v4[3] = a2[3];
      uint64_t v8 = a2[4];
      v4[4] = v8;
      swift_bridgeObjectRetain(v7);
      swift_bridgeObjectRetain(v8);
    }
    else
    {
      v4[4] = a2[4];
      *((_OWORD *)v4 + 1) = *((_OWORD *)a2 + 1);
    }
    uint64_t v10 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
    uint64_t v11 = *(int *)(v10 + 24);
    uint64_t v12 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 16))((char *)v4 + v11, (char *)a2 + v11, v12);
    uint64_t v13 = *(int *)(v10 + 28);
    uint64_t v14 = *(void *)((char *)a2 + v13);
    char v15 = *((unsigned char *)a2 + v13 + 8);
    *(void *)((char *)v4 + v13) = v14;
    *((unsigned char *)v4 + v13 + 8) = v15;
    uint64_t v16 = a3[5];
    id v57 = *(id *)((char *)a2 + v16);
    *(void *)((char *)v4 + v16) = v57;
    uint64_t v17 = a3[6];
    *(void *)((char *)v4 + v17) = *(void *)((char *)a2 + v17);
    uint64_t v18 = *(void *)((char *)a2 + v17 + 8);
    *(void *)((char *)v4 + v17 + 8) = v18;
    uint64_t v19 = a3[7];
    uint64_t v59 = *(void *)((char *)a2 + v19);
    *(void *)((char *)v4 + v19) = v59;
    uint64_t v20 = a3[8];
    uint64_t v68 = (char *)v4 + v20;
    uint64_t v63 = (char *)a2 + v20;
    int64_t v21 = (long long *)((char *)a2 + v20 + 8);
    uint64_t v65 = (_OWORD *)((char *)v4 + v20 + 8);
    *(void *)((char *)v4 + v20) = *(void *)((char *)a2 + v20);
    uint64_t v22 = *(void *)((char *)a2 + v20 + 32);
    swift_bridgeObjectRetain(v14);
    v57;
    swift_bridgeObjectRetain(v18);
    swift_bridgeObjectRetain(v59);
    if (v22)
    {
      *((void *)v68 + 4) = v22;
      (**(void (***)(_OWORD *, long long *, uint64_t))(v22 - 8))(v65, v21, v22);
    }
    else
    {
      long long v23 = *v21;
      v65[1] = v21[1];
      *uint64_t v65 = v23;
    }
    *(_OWORD *)(v68 + 40) = *(_OWORD *)(v63 + 40);
    *(_OWORD *)(v68 + 56) = *(_OWORD *)(v63 + 56);
    v68[72] = v63[72];
    uint64_t v24 = a3[9];
    uint64_t v25 = (void *)((char *)v4 + v24);
    uint64_t v26 = (char *)a2 + v24;
    uint64_t v64 = type metadata accessor for MLClassifierMetrics.Contents(0);
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v26, v64);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v32 = v25;
      uint64_t v33 = *(void *)v26;
      swift_errorRetain(*(void *)v26);
      *uint64_t v32 = v33;
      uint64_t v25 = v32;
      unsigned int EnumCaseMultiPayload = 2;
    }
    else if (EnumCaseMultiPayload == 1)
    {
      *uint64_t v25 = *(void *)v26;
      uint64_t v58 = (int *)type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v66 = v25;
      uint64_t v28 = v58[5];
      uint64_t v56 = (char *)v66 + v28;
      uint64_t v29 = type metadata accessor for DataFrame(0);
      uint64_t v60 = *(void (**)(char *, char *, uint64_t))(*(void *)(v29 - 8) + 16);
      uint64_t v30 = &v26[v28];
      uint64_t v25 = v66;
      v60(v56, v30, v29);
      uint64_t v31 = v29;
      unsigned int EnumCaseMultiPayload = 1;
      v60((char *)v66 + v58[6], &v26[v58[6]], v31);
    }
    else
    {
      uint64_t v69 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      int v34 = swift_getEnumCaseMultiPayload(v26, v69);
      BOOL v67 = v34 == 1;
      uint64_t v35 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      if (v34 == 1) {
        uint64_t v35 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      uint64_t v36 = __swift_instantiateConcreteTypeFromMangledName(v35);
      (*(void (**)(void *, char *, uint64_t))(*(void *)(v36 - 8) + 16))(v25, v26, v36);
      swift_storeEnumTagMultiPayload(v25, v69, v67);
    }
    swift_storeEnumTagMultiPayload(v25, v64, EnumCaseMultiPayload);
    uint64_t v37 = a3[10];
    uint64_t v38 = (void *)((char *)v4 + v37);
    uint64_t v39 = (void *)((char *)a2 + v37);
    int v40 = swift_getEnumCaseMultiPayload(v39, v64);
    if (v40 == 2)
    {
      uint64_t v45 = *v39;
      swift_errorRetain(v45);
      uint64_t *v38 = v45;
      uint64_t v55 = 2;
    }
    else
    {
      if (v40 != 1)
      {
        uint64_t v49 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
        int v50 = swift_getEnumCaseMultiPayload(v39, v49);
        BOOL v51 = v50 == 1;
        uint64_t v52 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
        if (v50 == 1) {
          uint64_t v52 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
        }
        uint64_t v53 = __swift_instantiateConcreteTypeFromMangledName(v52);
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v53 - 8) + 16))(v38, v39, v53);
        swift_storeEnumTagMultiPayload(v38, v49, v51);
        uint64_t v47 = v38;
        uint64_t v48 = v64;
        uint64_t v46 = 0;
        goto LABEL_24;
      }
      uint64_t *v38 = *v39;
      uint64_t v62 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v41 = *(int *)(v62 + 20);
      uint64_t v70 = (char *)v38 + v41;
      uint64_t v42 = type metadata accessor for DataFrame(0);
      uint64_t v43 = (char *)v39 + v41;
      uint64_t v44 = *(void (**)(char *, char *, uint64_t))(*(void *)(v42 - 8) + 16);
      v44(v70, v43, v42);
      v44((char *)v38 + *(int *)(v62 + 24), (char *)v39 + *(int *)(v62 + 24), v42);
      uint64_t v55 = 1;
    }
    uint64_t v46 = v55;
    uint64_t v47 = v38;
    uint64_t v48 = v64;
LABEL_24:
    swift_storeEnumTagMultiPayload(v47, v48, v46);
    return v4;
  }
  uint64_t v9 = *a2;
  void *v4 = *a2;
  int64_t v4 = (void *)(v9 + ((v5 + 16) & ~v5));
  swift_retain();
  return v4;
}

uint64_t destroy for MLLogisticRegressionClassifier(void *a1, int *a2)
{
  swift_bridgeObjectRelease(a1[1]);
  uint64_t v4 = a1[2];
  if (v4)
  {
    swift_bridgeObjectRelease(v4);
    swift_bridgeObjectRelease(a1[4]);
  }
  uint64_t v5 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  uint64_t v6 = (char *)a1 + *(int *)(v5 + 24);
  uint64_t v7 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  (*(void (**)(char *, uint64_t))(*(void *)(v7 - 8) + 8))(v6, v7);
  swift_bridgeObjectRelease(*(void *)((char *)a1 + *(int *)(v5 + 28)));

  swift_bridgeObjectRelease(*(void *)((char *)a1 + a2[6] + 8));
  swift_bridgeObjectRelease(*(void *)((char *)a1 + a2[7]));
  uint64_t v8 = a2[8];
  if (*(void *)((char *)a1 + v8 + 32)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)((char *)a1 + v8 + 8));
  }
  uint64_t v9 = (char *)a1 + a2[9];
  uint64_t v10 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v9, v10);
  switch(EnumCaseMultiPayload)
  {
    case 2:
      swift_errorRelease(*(void *)v9);
      break;
    case 1:
      uint64_t v30 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v14 = &v9[*(int *)(v30 + 20)];
      uint64_t v29 = v10;
      uint64_t v15 = type metadata accessor for DataFrame(0);
      uint64_t v16 = v14;
      uint64_t v17 = *(void (**)(char *, uint64_t))(*(void *)(v15 - 8) + 8);
      v17(v16, v15);
      uint64_t v18 = v15;
      uint64_t v10 = v29;
      v17(&v9[*(int *)(v30 + 24)], v18);
      break;
    case 0:
      uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload(v9, v12) == 1) {
        uint64_t v13 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        uint64_t v13 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(v13);
      (*(void (**)(char *, uint64_t))(*(void *)(v19 - 8) + 8))(v9, v19);
      break;
  }
  uint64_t v20 = (void *)((char *)a1 + a2[10]);
  uint64_t result = swift_getEnumCaseMultiPayload(v20, v10);
  switch(result)
  {
    case 2:
      return swift_errorRelease(*v20);
    case 1:
      uint64_t v24 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v25 = (char *)v20 + *(int *)(v24 + 20);
      uint64_t v26 = type metadata accessor for DataFrame(0);
      uint64_t v27 = *(void (**)(char *, uint64_t))(*(void *)(v26 - 8) + 8);
      v27(v25, v26);
      return ((uint64_t (*)(char *, uint64_t))v27)((char *)v20 + *(int *)(v24 + 24), v26);
    case 0:
      uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload(v20, v22) == 1) {
        long long v23 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        long long v23 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(v23);
      return (*(uint64_t (**)(void *, uint64_t))(*(void *)(v28 - 8) + 8))(v20, v28);
  }
  return result;
}

void *initializeWithCopy for MLLogisticRegressionClassifier(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v4 = a2[1];
  a1[1] = v4;
  uint64_t v5 = a2[2];
  swift_bridgeObjectRetain(v4);
  if (v5)
  {
    a1[2] = v5;
    a1[3] = a2[3];
    uint64_t v6 = a2[4];
    a1[4] = v6;
    swift_bridgeObjectRetain(v5);
    swift_bridgeObjectRetain(v6);
  }
  else
  {
    a1[4] = a2[4];
    *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
  }
  uint64_t v7 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  uint64_t v8 = *(int *)(v7 + 24);
  uint64_t v9 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))((char *)a1 + v8, (char *)a2 + v8, v9);
  uint64_t v10 = *(int *)(v7 + 28);
  uint64_t v11 = *(void *)((char *)a2 + v10);
  char v12 = *((unsigned char *)a2 + v10 + 8);
  *(void *)((char *)a1 + v10) = v11;
  *((unsigned char *)a1 + v10 + 8) = v12;
  uint64_t v13 = a3[5];
  id v53 = *(id *)((char *)a2 + v13);
  *(void *)((char *)a1 + v13) = v53;
  uint64_t v14 = a3[6];
  *(void *)((char *)a1 + v14) = *(void *)((char *)a2 + v14);
  uint64_t v15 = a1;
  uint64_t v16 = *(void *)((char *)a2 + v14 + 8);
  *(void *)((char *)a1 + v14 + 8) = v16;
  uint64_t v17 = a3[7];
  uint64_t v59 = *(void *)((char *)a2 + v17);
  *(void *)((char *)a1 + v17) = v59;
  uint64_t v18 = a3[8];
  uint64_t v19 = (char *)a1 + v18;
  id v57 = (char *)a2 + v18;
  uint64_t v20 = (long long *)((char *)a2 + v18 + 8);
  uint64_t v52 = v15;
  int64_t v21 = (_OWORD *)((char *)v15 + v18 + 8);
  *(void *)((char *)v15 + v18) = *(void *)((char *)a2 + v18);
  uint64_t v22 = *(void *)((char *)a2 + v18 + 32);
  swift_bridgeObjectRetain(v11);
  v53;
  swift_bridgeObjectRetain(v16);
  swift_bridgeObjectRetain(v59);
  if (v22)
  {
    *((void *)v19 + 4) = v22;
    (**(void (***)(_OWORD *, long long *, uint64_t))(v22 - 8))(v21, v20, v22);
  }
  else
  {
    long long v23 = *v20;
    v21[1] = v20[1];
    *int64_t v21 = v23;
  }
  *(_OWORD *)(v19 + 40) = *(_OWORD *)(v57 + 40);
  *(_OWORD *)(v19 + 56) = *(_OWORD *)(v57 + 56);
  v19[72] = v57[72];
  uint64_t v24 = a3[9];
  uint64_t v25 = (char *)v52 + v24;
  uint64_t v26 = (char *)a2 + v24;
  uint64_t v58 = type metadata accessor for MLClassifierMetrics.Contents(0);
  unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v26, v58);
  if (EnumCaseMultiPayload == 2)
  {
    uint64_t v32 = *(void *)v26;
    swift_errorRetain(*(void *)v26);
    *(void *)uint64_t v25 = v32;
  }
  else if (EnumCaseMultiPayload == 1)
  {
    *(void *)uint64_t v25 = *(void *)v26;
    uint64_t v60 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v28 = *(int *)(v60 + 20);
    uint64_t v54 = &v25[v28];
    uint64_t v29 = type metadata accessor for DataFrame(0);
    uint64_t v30 = &v26[v28];
    uint64_t v31 = *(void (**)(char *, char *, uint64_t))(*(void *)(v29 - 8) + 16);
    v31(v54, v30, v29);
    v31(&v25[*(int *)(v60 + 24)], &v26[*(int *)(v60 + 24)], v29);
  }
  else
  {
    uint64_t v61 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v33 = swift_getEnumCaseMultiPayload(v26, v61);
    BOOL v34 = v33 == 1;
    uint64_t v35 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v33 == 1) {
      uint64_t v35 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v36 = __swift_instantiateConcreteTypeFromMangledName(v35);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v36 - 8) + 16))(v25, v26, v36);
    swift_storeEnumTagMultiPayload(v25, v61, v34);
  }
  swift_storeEnumTagMultiPayload(v25, v58, EnumCaseMultiPayload);
  uint64_t v37 = a3[10];
  uint64_t v38 = (char *)v52 + v37;
  uint64_t v39 = (char *)a2 + v37;
  unsigned int v40 = swift_getEnumCaseMultiPayload((char *)a2 + v37, v58);
  if (v40 == 2)
  {
    uint64_t v45 = *(void *)v39;
    swift_errorRetain(v45);
    *(void *)uint64_t v38 = v45;
  }
  else if (v40 == 1)
  {
    *(void *)uint64_t v38 = *(void *)v39;
    uint64_t v63 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v41 = *(int *)(v63 + 20);
    uint64_t v56 = &v38[v41];
    uint64_t v42 = type metadata accessor for DataFrame(0);
    uint64_t v43 = &v39[v41];
    uint64_t v44 = *(void (**)(char *, char *, uint64_t))(*(void *)(v42 - 8) + 16);
    v44(v56, v43, v42);
    v44(&v38[*(int *)(v63 + 24)], &v39[*(int *)(v63 + 24)], v42);
  }
  else
  {
    uint64_t v64 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    uint64_t v46 = v39;
    int v47 = swift_getEnumCaseMultiPayload(v39, v64);
    BOOL v48 = v47 == 1;
    uint64_t v49 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v47 == 1) {
      uint64_t v49 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v50 = __swift_instantiateConcreteTypeFromMangledName(v49);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v50 - 8) + 16))(v38, v46, v50);
    swift_storeEnumTagMultiPayload(v38, v64, v48);
  }
  swift_storeEnumTagMultiPayload(v38, v58, v40);
  return v52;
}

void *assignWithCopy for MLLogisticRegressionClassifier(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v4 = a2[1];
  uint64_t v5 = a1[1];
  a1[1] = v4;
  swift_bridgeObjectRetain(v4);
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = a1 + 2;
  uint64_t v7 = a2 + 2;
  uint64_t v8 = a1[2];
  uint64_t v9 = a2[2];
  if (v8)
  {
    if (v9)
    {
      a1[2] = v9;
      swift_bridgeObjectRetain(v9);
      swift_bridgeObjectRelease(v8);
      uint64_t v10 = (char *)a2;
      a1[3] = a2[3];
      uint64_t v11 = a2[4];
      uint64_t v12 = a1[4];
      a1[4] = v11;
      swift_bridgeObjectRetain(v11);
      swift_bridgeObjectRelease(v12);
      goto LABEL_9;
    }
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)(a1 + 2), &demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
    _OWORD *v6 = *v7;
    a1[4] = a2[4];
  }
  else
  {
    if (v9)
    {
      a1[2] = v9;
      uint64_t v10 = (char *)a2;
      a1[3] = a2[3];
      uint64_t v13 = a2[4];
      a1[4] = v13;
      swift_bridgeObjectRetain(v9);
      swift_bridgeObjectRetain(v13);
      goto LABEL_9;
    }
    a1[4] = a2[4];
    _OWORD *v6 = *v7;
  }
  uint64_t v10 = (char *)a2;
LABEL_9:
  uint64_t v14 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  uint64_t v15 = *(int *)(v14 + 24);
  uint64_t v16 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 24))((char *)a1 + v15, &v10[v15], v16);
  uint64_t v17 = *(int *)(v14 + 28);
  uint64_t v18 = *(void *)&v10[v17];
  char v19 = v10[v17 + 8];
  uint64_t v20 = *(void *)((char *)a1 + v17);
  *(void *)((char *)a1 + v17) = v18;
  *((unsigned char *)a1 + v17 + 8) = v19;
  swift_bridgeObjectRetain(v18);
  swift_bridgeObjectRelease(v20);
  uint64_t v21 = a3[5];
  uint64_t v22 = *(void **)&v10[v21];
  long long v23 = *(void **)((char *)a1 + v21);
  *(void *)((char *)a1 + v21) = v22;
  v22;

  uint64_t v24 = a3[6];
  *(void *)((char *)a1 + v24) = *(void *)&v10[v24];
  uint64_t v25 = *(void *)&v10[v24 + 8];
  uint64_t v26 = *(void *)((char *)a1 + v24 + 8);
  *(void *)((char *)a1 + v24 + 8) = v25;
  swift_bridgeObjectRetain(v25);
  swift_bridgeObjectRelease(v26);
  uint64_t v27 = a3[7];
  uint64_t v28 = *(void *)&v10[v27];
  uint64_t v29 = *(void *)((char *)a1 + v27);
  *(void *)((char *)a1 + v27) = v28;
  swift_bridgeObjectRetain(v28);
  swift_bridgeObjectRelease(v29);
  uint64_t v30 = a3[8];
  uint64_t v31 = (char *)a1 + v30;
  uint64_t v32 = v10;
  int v33 = &v10[v30];
  uint64_t v34 = (uint64_t)v32 + v30 + 8;
  uint64_t v35 = (_OWORD *)((char *)a1 + v30 + 8);
  *(void *)((char *)a1 + v30) = *(void *)((char *)v32 + v30);
  uint64_t v36 = *(void *)((char *)v32 + v30 + 32);
  if (*(void *)((char *)a1 + v30 + 32))
  {
    if (v36)
    {
      __swift_assign_boxed_opaque_existential_0((void *)((char *)a1 + v30 + 8), (uint64_t *)v34);
      goto LABEL_16;
    }
    __swift_destroy_boxed_opaque_existential_1Tm((void *)((char *)a1 + v30 + 8));
  }
  else if (v36)
  {
    *((void *)v31 + 4) = v36;
    (**(void (***)(_OWORD *, uint64_t))(v36 - 8))(v35, v34);
    goto LABEL_16;
  }
  long long v37 = *(_OWORD *)v34;
  v35[1] = *(_OWORD *)(v34 + 16);
  *uint64_t v35 = v37;
LABEL_16:
  *((void *)v31 + 5) = *((void *)v33 + 5);
  *((void *)v31 + 6) = *((void *)v33 + 6);
  *((void *)v31 + 7) = *((void *)v33 + 7);
  *((void *)v31 + 8) = *((void *)v33 + 8);
  v31[72] = v33[72];
  uint64_t v38 = a2;
  if (a1 != a2)
  {
    uint64_t v39 = a3[9];
    unsigned int v40 = (void *)((char *)a1 + v39);
    uint64_t v41 = (void *)((char *)a2 + v39);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v40, type metadata accessor for MLClassifierMetrics.Contents);
    uint64_t v42 = type metadata accessor for MLClassifierMetrics.Contents(0);
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v41, v42);
    unsigned int v68 = EnumCaseMultiPayload;
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v48 = *v41;
      swift_errorRetain(v48);
      uint64_t v47 = 2;
      *unsigned int v40 = v48;
    }
    else if (EnumCaseMultiPayload == 1)
    {
      *unsigned int v40 = *v41;
      uint64_t v73 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v70 = v42;
      uint64_t v44 = *(int *)(v73 + 20);
      uint64_t v66 = (char *)v40 + v44;
      uint64_t v67 = type metadata accessor for DataFrame(0);
      uint64_t v45 = *(void (**)(char *, char *, uint64_t))(*(void *)(v67 - 8) + 16);
      uint64_t v46 = (char *)v41 + v44;
      uint64_t v42 = v70;
      v45(v66, v46, v67);
      v45((char *)v40 + *(int *)(v73 + 24), (char *)v41 + *(int *)(v73 + 24), v67);
      uint64_t v47 = v68;
      uint64_t v38 = a2;
    }
    else
    {
      uint64_t v71 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      int v49 = swift_getEnumCaseMultiPayload(v41, v71);
      BOOL v74 = v49 == 1;
      uint64_t v50 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      if (v49 == 1) {
        uint64_t v50 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      uint64_t v51 = __swift_instantiateConcreteTypeFromMangledName(v50);
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v51 - 8) + 16))(v40, v41, v51);
      swift_storeEnumTagMultiPayload(v40, v71, v74);
      uint64_t v47 = v68;
    }
    swift_storeEnumTagMultiPayload(v40, v42, v47);
    uint64_t v52 = a3[10];
    id v53 = (void *)((char *)a1 + v52);
    uint64_t v54 = (void *)((char *)v38 + v52);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)a1 + v52, type metadata accessor for MLClassifierMetrics.Contents);
    unsigned int v55 = swift_getEnumCaseMultiPayload(v54, v42);
    if (v55 == 2)
    {
      uint64_t v60 = *v54;
      swift_errorRetain(v60);
      *id v53 = v60;
    }
    else
    {
      unsigned int v77 = v55;
      if (v55 == 1)
      {
        *id v53 = *v54;
        uint64_t v69 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
        uint64_t v56 = *(int *)(v69 + 20);
        uint64_t v75 = (char *)v53 + v56;
        uint64_t v72 = v42;
        uint64_t v57 = type metadata accessor for DataFrame(0);
        v79 = *(void (**)(char *, char *, uint64_t))(*(void *)(v57 - 8) + 16);
        uint64_t v58 = (char *)v54 + v56;
        unsigned int v55 = 1;
        v79(v75, v58, v57);
        uint64_t v59 = v57;
        uint64_t v42 = v72;
        v79((char *)v53 + *(int *)(v69 + 24), (char *)v54 + *(int *)(v69 + 24), v59);
      }
      else
      {
        uint64_t v80 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
        int v61 = swift_getEnumCaseMultiPayload(v54, v80);
        BOOL v62 = v61 == 1;
        uint64_t v63 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
        if (v61 == 1) {
          uint64_t v63 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
        }
        uint64_t v64 = __swift_instantiateConcreteTypeFromMangledName(v63);
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v64 - 8) + 16))(v53, v54, v64);
        swift_storeEnumTagMultiPayload(v53, v80, v62);
        unsigned int v55 = v77;
      }
    }
    swift_storeEnumTagMultiPayload(v53, v42, v55);
  }
  return a1;
}

uint64_t initializeWithTake for MLLogisticRegressionClassifier(uint64_t a1, uint64_t a2, int *a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = *(_OWORD *)(a2 + 16);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v5 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  uint64_t v6 = *(int *)(v5 + 24);
  uint64_t v7 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v7 - 8) + 32))(a1 + v6, a2 + v6, v7);
  uint64_t v8 = *(int *)(v5 + 28);
  *(unsigned char *)(a1 + v8 + 8) = *(unsigned char *)(a2 + v8 + 8);
  *(void *)(a1 + v8) = *(void *)(a2 + v8);
  *(void *)(a1 + a3[5]) = *(void *)(a2 + a3[5]);
  *(_OWORD *)(a1 + a3[6]) = *(_OWORD *)(a2 + a3[6]);
  *(void *)(a1 + a3[7]) = *(void *)(a2 + a3[7]);
  qmemcpy((void *)(a1 + a3[8]), (const void *)(a2 + a3[8]), 0x49uLL);
  uint64_t v47 = a3;
  uint64_t v9 = a3[9];
  uint64_t v10 = (char *)(v9 + a1);
  uint64_t v11 = (char *)(a2 + v9);
  uint64_t v12 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v11, v12);
  if (EnumCaseMultiPayload == 1)
  {
    *(void *)uint64_t v10 = *(void *)v11;
    uint64_t v45 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v21 = *(int *)(v45 + 20);
    uint64_t v46 = &v10[v21];
    uint64_t v51 = v12;
    uint64_t v22 = type metadata accessor for DataFrame(0);
    long long v23 = &v11[v21];
    uint64_t v24 = *(void (**)(char *, char *, uint64_t))(*(void *)(v22 - 8) + 32);
    v24(v46, v23, v22);
    uint64_t v25 = v22;
    uint64_t v12 = v51;
    v24(&v10[*(int *)(v45 + 24)], &v11[*(int *)(v45 + 24)], v25);
    uint64_t v20 = 1;
    uint64_t v18 = v10;
    uint64_t v19 = v51;
LABEL_7:
    swift_storeEnumTagMultiPayload(v18, v19, v20);
    goto LABEL_9;
  }
  if (!EnumCaseMultiPayload)
  {
    uint64_t v50 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v14 = swift_getEnumCaseMultiPayload(v11, v50);
    BOOL v15 = v14 == 1;
    uint64_t v16 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v14 == 1) {
      uint64_t v16 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(v16);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 32))(v10, v11, v17);
    swift_storeEnumTagMultiPayload(v10, v50, v15);
    uint64_t v18 = v10;
    uint64_t v19 = v12;
    uint64_t v20 = 0;
    goto LABEL_7;
  }
  memcpy(v10, v11, *(void *)(*(void *)(v12 - 8) + 64));
LABEL_9:
  uint64_t v26 = v47[10];
  uint64_t v27 = (char *)(a1 + v26);
  uint64_t v28 = (char *)(v26 + a2);
  int v29 = swift_getEnumCaseMultiPayload(v28, v12);
  if (v29 == 1)
  {
    *(void *)uint64_t v27 = *(void *)v28;
    uint64_t v39 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v52 = v12;
    uint64_t v40 = *(int *)(v39 + 20);
    uint64_t v48 = &v27[v40];
    uint64_t v41 = type metadata accessor for DataFrame(0);
    uint64_t v42 = &v28[v40];
    uint64_t v43 = *(void (**)(char *, char *, uint64_t))(*(void *)(v41 - 8) + 32);
    v43(v48, v42, v41);
    v43(&v27[*(int *)(v39 + 24)], &v28[*(int *)(v39 + 24)], v41);
    uint64_t v38 = 1;
    uint64_t v36 = v27;
    uint64_t v37 = v52;
  }
  else
  {
    if (v29)
    {
      memcpy(v27, v28, *(void *)(*(void *)(v12 - 8) + 64));
      return a1;
    }
    uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v31 = swift_getEnumCaseMultiPayload(v28, v30);
    uint64_t v32 = v12;
    BOOL v33 = v31 == 1;
    uint64_t v34 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v31 == 1) {
      uint64_t v34 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(v34);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v35 - 8) + 32))(v27, v28, v35);
    swift_storeEnumTagMultiPayload(v27, v30, v33);
    uint64_t v36 = v27;
    uint64_t v37 = v32;
    uint64_t v38 = 0;
  }
  swift_storeEnumTagMultiPayload(v36, v37, v38);
  return a1;
}

void *assignWithTake for MLLogisticRegressionClassifier(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v4 = a1[1];
  a1[1] = a2[1];
  swift_bridgeObjectRelease(v4);
  uint64_t v5 = a1 + 2;
  uint64_t v6 = a2 + 2;
  uint64_t v7 = a1[2];
  if (v7)
  {
    uint64_t v8 = a2[2];
    if (v8)
    {
      a1[2] = v8;
      swift_bridgeObjectRelease(v7);
      a1[3] = a2[3];
      uint64_t v9 = a1[4];
      a1[4] = a2[4];
      swift_bridgeObjectRelease(v9);
    }
    else
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)(a1 + 2), &demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
      _OWORD *v5 = *v6;
      a1[4] = a2[4];
    }
  }
  else
  {
    a1[4] = a2[4];
    _OWORD *v5 = *v6;
  }
  uint64_t v10 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  uint64_t v11 = *(int *)(v10 + 24);
  uint64_t v12 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 40))((char *)a1 + v11, (char *)a2 + v11, v12);
  uint64_t v13 = *(int *)(v10 + 28);
  char v14 = *((unsigned char *)a2 + v13 + 8);
  uint64_t v15 = *(void *)((char *)a1 + v13);
  *(void *)((char *)a1 + v13) = *(void *)((char *)a2 + v13);
  *((unsigned char *)a1 + v13 + 8) = v14;
  swift_bridgeObjectRelease(v15);
  uint64_t v16 = a3[5];
  uint64_t v17 = *(void **)((char *)a1 + v16);
  *(void *)((char *)a1 + v16) = *(void *)((char *)a2 + v16);

  uint64_t v18 = a3[6];
  *(void *)((char *)a1 + v18) = *(void *)((char *)a2 + v18);
  uint64_t v19 = *(void *)((char *)a1 + v18 + 8);
  *(void *)((char *)a1 + v18 + 8) = *(void *)((char *)a2 + v18 + 8);
  swift_bridgeObjectRelease(v19);
  uint64_t v20 = a3[7];
  uint64_t v21 = *(void *)((char *)a1 + v20);
  *(void *)((char *)a1 + v20) = *(void *)((char *)a2 + v20);
  swift_bridgeObjectRelease(v21);
  uint64_t v22 = a3[8];
  long long v23 = (char *)a1 + v22;
  uint64_t v24 = (char *)a2 + v22;
  uint64_t v25 = (long long *)((char *)a2 + v22 + 8);
  uint64_t v26 = (_OWORD *)((char *)a1 + v22 + 8);
  *(void *)((char *)a1 + v22) = *(void *)((char *)a2 + v22);
  if (*(void *)((char *)a1 + v22 + 32)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)((char *)a1 + v22 + 8));
  }
  long long v27 = *v25;
  v26[1] = v25[1];
  *uint64_t v26 = v27;
  *(_OWORD *)(v23 + 40) = *(_OWORD *)(v24 + 40);
  *(_OWORD *)(v23 + 56) = *(_OWORD *)(v24 + 56);
  v23[72] = v24[72];
  uint64_t v28 = a2;
  if (a1 == a2) {
    return a1;
  }
  uint64_t v29 = a3[9];
  uint64_t v30 = (void *)((char *)a1 + v29);
  int v31 = (void *)((char *)a2 + v29);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v30, type metadata accessor for MLClassifierMetrics.Contents);
  uint64_t v71 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v31, v71);
  if (EnumCaseMultiPayload == 1)
  {
    void *v30 = *v31;
    uint64_t v66 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v41 = *(int *)(v66 + 20);
    uint64_t v64 = (char *)v30 + v41;
    uint64_t v42 = type metadata accessor for DataFrame(0);
    uint64_t v43 = *(void (**)(char *, char *))(*(void *)(v42 - 8) + 32);
    uint64_t v44 = (char *)v31 + v41;
    uint64_t v45 = v42;
    v43(v64, v44);
    ((void (*)(char *, char *, uint64_t))v43)((char *)v30 + *(int *)(v66 + 24), (char *)v31 + *(int *)(v66 + 24), v45);
    uint64_t v28 = a2;
    uint64_t v40 = 1;
    uint64_t v37 = v30;
    uint64_t v38 = v71;
    uint64_t v39 = v71;
  }
  else
  {
    if (EnumCaseMultiPayload)
    {
      uint64_t v46 = v31;
      uint64_t v38 = v71;
      memcpy(v30, v46, *(void *)(*(void *)(v71 - 8) + 64));
      goto LABEL_17;
    }
    uint64_t v65 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v33 = swift_getEnumCaseMultiPayload(v31, v65);
    BOOL v34 = v33 == 1;
    uint64_t v35 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v33 == 1) {
      uint64_t v35 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v36 = __swift_instantiateConcreteTypeFromMangledName(v35);
    (*(void (**)(void *, void *, uint64_t))(*(void *)(v36 - 8) + 32))(v30, v31, v36);
    swift_storeEnumTagMultiPayload(v30, v65, v34);
    uint64_t v37 = v30;
    uint64_t v38 = v71;
    uint64_t v39 = v71;
    uint64_t v40 = 0;
  }
  swift_storeEnumTagMultiPayload(v37, v39, v40);
LABEL_17:
  uint64_t v47 = a3[10];
  uint64_t v48 = (char *)a1 + v47;
  int v49 = (char *)v28 + v47;
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)a1 + v47, type metadata accessor for MLClassifierMetrics.Contents);
  int v50 = swift_getEnumCaseMultiPayload(v49, v38);
  if (v50 == 1)
  {
    *(void *)uint64_t v48 = *(void *)v49;
    uint64_t v70 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v59 = *(int *)(v70 + 20);
    unsigned int v68 = &v48[v59];
    uint64_t v60 = type metadata accessor for DataFrame(0);
    int v61 = &v49[v59];
    BOOL v62 = *(void (**)(char *, char *, uint64_t))(*(void *)(v60 - 8) + 32);
    v62(v68, v61, v60);
    v62(&v48[*(int *)(v70 + 24)], &v49[*(int *)(v70 + 24)], v60);
    uint64_t v58 = 1;
    uint64_t v56 = v48;
    uint64_t v57 = v71;
  }
  else
  {
    if (v50)
    {
      memcpy(v48, v49, *(void *)(*(void *)(v38 - 8) + 64));
      return a1;
    }
    uint64_t v51 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v52 = swift_getEnumCaseMultiPayload(v49, v51);
    BOOL v53 = v52 == 1;
    uint64_t v54 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v52 == 1) {
      uint64_t v54 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v55 = __swift_instantiateConcreteTypeFromMangledName(v54);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v55 - 8) + 32))(v48, v49, v55);
    swift_storeEnumTagMultiPayload(v48, v51, v53);
    uint64_t v56 = v48;
    uint64_t v57 = v71;
    uint64_t v58 = 0;
  }
  swift_storeEnumTagMultiPayload(v56, v57, v58);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLogisticRegressionClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_E00B3);
}

uint64_t sub_E00B3(uint64_t a1, unsigned int a2, uint64_t a3)
{
  uint64_t v4 = a1;
  uint64_t v5 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(v4, a2, v5);
  }
  if (a2 != 0x7FFFFFFF)
  {
    uint64_t v5 = type metadata accessor for MLClassifierMetrics(0);
    uint64_t v4 = *(int *)(a3 + 36) + a1;
    return __swift_getEnumTagSinglePayload(v4, a2, v5);
  }
  uint64_t result = 0;
  if ((*(void *)(a1 + *(int *)(a3 + 20)) & 0xFFFFFFFF00000001) == 0) {
    return (*(void *)(a1 + *(int *)(a3 + 20)) >> 1) + 1;
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLLogisticRegressionClassifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_E0140);
}

uint64_t sub_E0140(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = a1;
  uint64_t v7 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  if (*(_DWORD *)(*(void *)(v7 - 8) + 84) != a3)
  {
    if (a3 == 0x7FFFFFFF)
    {
      uint64_t result = *(int *)(a4 + 20);
      *(void *)(a1 + result) = 2 * (a2 - 1);
      return result;
    }
    uint64_t v7 = type metadata accessor for MLClassifierMetrics(0);
    uint64_t v6 = *(int *)(a4 + 36) + a1;
  }
  return __swift_storeEnumTagSinglePayload(v6, a2, a2, v7);
}

uint64_t type metadata completion function for MLLogisticRegressionClassifier(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLLogisticRegressionClassifier.Model(319);
  if (v2 <= 0x3F)
  {
    v4[0] = *(void *)(result - 8) + 64;
    v4[1] = (char *)&value witness table for Builtin.UnknownObject + 64;
    v4[2] = &unk_349B50;
    v4[3] = (char *)&value witness table for Builtin.BridgeObject + 64;
    v4[4] = &unk_349B68;
    uint64_t result = type metadata accessor for MLClassifierMetrics.Contents(319);
    if (v3 <= 0x3F)
    {
      uint64_t v5 = *(void *)(result - 8) + 64;
      uint64_t v6 = v5;
      swift_initStructMetadata(a1, 256, 7, v4, a1 + 16);
      return 0;
    }
  }
  return result;
}

uint64_t sub_E0264()
{
  return objectdestroyTm_0();
}

uint64_t objectdestroyTm_0()
{
  uint64_t v11 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  uint64_t v1 = *(void *)(v11 - 8);
  uint64_t v2 = *(unsigned __int8 *)(v1 + 80);
  uint64_t v3 = ~*(unsigned __int8 *)(v1 + 80) & (v2 + 16);
  uint64_t v4 = *(void *)(v1 + 64);
  uint64_t v5 = v3 + v0;
  swift_bridgeObjectRelease(*(void *)(v0 + v3 + 8));
  uint64_t v6 = *(void *)(v0 + v3 + 16);
  if (v6)
  {
    swift_bridgeObjectRelease(v6);
    swift_bridgeObjectRelease(*(void *)(v5 + 32));
  }
  uint64_t v7 = v4 + v3;
  uint64_t v8 = v5 + *(int *)(v11 + 24);
  uint64_t v9 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(v8, v9);
  swift_bridgeObjectRelease(*(void *)(v5 + *(int *)(v11 + 28)));
  return swift_deallocObject(v0, v7, v2 | 7);
}

uint64_t partial apply for closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  uint64_t v2 = (void *)swift_task_alloc(dword_3A6ED4);
  *(void *)(v1 + 16) = v2;
  *uint64_t v2 = v1;
  v2[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:)(a1);
}

uint64_t closure #1 in MLLogisticRegressionClassifier.init(_:targetColumn:featureColumns:parameters:)()
{
  return closure #1 in MLRandomForestRegressor.init(checkpoint:)();
}

uint64_t closure #1 in MLLogisticRegressionClassifier.init(trainingData:targetColumn:featureColumns:parameters:)()
{
  return closure #1 in MLRandomForestRegressor.init(checkpoint:)();
}

Class static MLWordTagger.buildOptions(_:)(uint64_t a1)
{
  uint64_t v25 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for AnyHashable, (char *)&type metadata for Any + 8, &protocol witness table for AnyHashable);
  if (!*(unsigned char *)(a1 + 104))
  {
    if (!kNLPMaximumIterationsKey) {
      BUG();
    }
    uint64_t v24 = *(void *)(a1 + 96);
    uint64_t v21 = (uint64_t)kNLPMaximumIterationsKey;
    uint64_t v1 = type metadata accessor for CFStringRef(0);
    uint64_t v2 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type CFStringRef and conformance CFStringRef, type metadata accessor for CFStringRef, (uint64_t)&protocol conformance descriptor for CFStringRef);
    AnyHashable.init<A>(_:)(&v21, v1, v2);
    long long v23 = &type metadata for Int;
    uint64_t v21 = v24;
    specialized Dictionary.subscript.setter((uint64_t)&v21, (uint64_t)v20);
  }
  uint64_t v3 = *(void **)(a1 + 24);
  if (v3)
  {
    uint64_t v4 = (void *)NLModelConfigurationOptionsKeyLanguage;
    uint64_t v21 = NLModelConfigurationOptionsKeyLanguage;
    uint64_t v24 = type metadata accessor for NLModelConfigurationOptionsKey(0);
    uint64_t v26 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type NLModelConfigurationOptionsKey and conformance NLModelConfigurationOptionsKey, type metadata accessor for NLModelConfigurationOptionsKey, (uint64_t)&protocol conformance descriptor for NLModelConfigurationOptionsKey);
    id v5 = v3;
    v4;
    AnyHashable.init<A>(_:)(&v21, v24, v26);
    long long v23 = (void *)type metadata accessor for NLLanguage(0);
    uint64_t v21 = (uint64_t)v5;
    specialized Dictionary.subscript.setter((uint64_t)&v21, (uint64_t)v20);
  }
  uint64_t v6 = *(void *)(a1 + 8);
  BOOL v7 = *(unsigned char *)(a1 + 16) == 0;
  uint64_t v24 = *(void *)a1;
  uint64_t v8 = (void *)NLModelConfigurationOptionsKeyRevision;
  if (v7)
  {
    uint64_t v21 = NLModelConfigurationOptionsKeyRevision;
    uint64_t v13 = type metadata accessor for NLModelConfigurationOptionsKey(0);
    uint64_t v14 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type NLModelConfigurationOptionsKey and conformance NLModelConfigurationOptionsKey, type metadata accessor for NLModelConfigurationOptionsKey, (uint64_t)&protocol conformance descriptor for NLModelConfigurationOptionsKey);
    v8;
    uint64_t v26 = v13;
    AnyHashable.init<A>(_:)(&v21, v13, v14);
    if (v6)
    {
      long long v22 = 0;
      long long v23 = 0;
      uint64_t v15 = 0;
    }
    else
    {
      long long v23 = &type metadata for Int;
      uint64_t v15 = v24;
    }
    uint64_t v21 = v15;
    specialized Dictionary.subscript.setter((uint64_t)&v21, (uint64_t)v20);
    uint64_t v21 = (uint64_t)NLModelConfigurationOptionsKeyUseCRF;
    NLModelConfigurationOptionsKeyUseCRF;
    AnyHashable.init<A>(_:)(&v21, v26, v14);
    long long v23 = &type metadata for Bool;
    LOBYTE(v21) = 1;
  }
  else
  {
    uint64_t v21 = NLModelConfigurationOptionsKeyRevision;
    uint64_t v9 = type metadata accessor for NLModelConfigurationOptionsKey(0);
    uint64_t v26 = v6;
    uint64_t v10 = v9;
    uint64_t v11 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type NLModelConfigurationOptionsKey and conformance NLModelConfigurationOptionsKey, type metadata accessor for NLModelConfigurationOptionsKey, (uint64_t)&protocol conformance descriptor for NLModelConfigurationOptionsKey);
    v8;
    AnyHashable.init<A>(_:)(&v21, v10, v11);
    long long v23 = &type metadata for Int;
    uint64_t v21 = v26;
    specialized Dictionary.subscript.setter((uint64_t)&v21, (uint64_t)v20);
    uint64_t v21 = (uint64_t)NLModelConfigurationOptionsKeyUseTransfer;
    NLModelConfigurationOptionsKeyUseTransfer;
    uint64_t v26 = v10;
    AnyHashable.init<A>(_:)(&v21, v10, v11);
    long long v23 = &type metadata for Bool;
    LOBYTE(v21) = 1;
    specialized Dictionary.subscript.setter((uint64_t)&v21, (uint64_t)v20);
    uint64_t v21 = (uint64_t)NLModelConfigurationOptionsKeyEmbeddingType;
    if ((v24 & 0xFE) != 0)
    {
      NLModelConfigurationOptionsKeyEmbeddingType;
      AnyHashable.init<A>(_:)(&v21, v26, v11);
      uint64_t v12 = (void **)&NLModelEmbeddingTypeContextual;
    }
    else
    {
      NLModelConfigurationOptionsKeyEmbeddingType;
      AnyHashable.init<A>(_:)(&v21, v26, v11);
      uint64_t v12 = (void **)&NLModelEmbeddingTypeDynamic;
    }
    uint64_t v16 = *v12;
    long long v23 = (void *)type metadata accessor for NLModelEmbeddingType(0);
    uint64_t v21 = (uint64_t)v16;
    v16;
  }
  specialized Dictionary.subscript.setter((uint64_t)&v21, (uint64_t)v20);
  char v17 = v25;
  Class isa = Dictionary._bridgeToObjectiveC()().super.isa;
  swift_bridgeObjectRelease(v17);
  return isa;
}

void *implicit closure #1 in closure #1 in closure #3 in static MLWordTagger.createWordTaggerModel<A, B>(trainingExamples:validatingExamples:modelParameters:)(uint64_t a1, uint64_t a2)
{
  if (!a1) {
    return 0;
  }
  uint64_t v2 = *(void **)(a1 + 8 * a2);
  v2;
  return v2;
}

uint64_t closure #1 in FeatureMatrixBuilder.fillArray(from:size:column:)(id *a1)
{
  uint64_t v2 = v1;
  id v3 = *a1;
  MLShapedArray.init(_:)(v3, &type metadata for Double, &protocol witness table for Double);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  return __swift_storeEnumTagSinglePayload(v2, 0, 1, v4);
}

uint64_t FeatureMatrixBuilder.fillArray<A, B>(_:descriptor:size:row:column:)(long long *a1, uint64_t a2, void *a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, uint64_t a13)
{
  uint64_t v77 = v13;
  uint64_t v66 = v14;
  uint64_t v83 = a6;
  uint64_t v71 = a3;
  v72._countAndFlagsBits = a2;
  uint64_t v84 = a1;
  uint64_t v67 = *(void *)(a11 - 8);
  int64_t v15 = *(void *)(v67 + 64);
  uint64_t v16 = alloca(v15);
  char v17 = alloca(v15);
  unsigned int v68 = &v63;
  uint64_t v69 = *(void *)(a9 + 16);
  int64_t v18 = *(void *)(*(void *)(v69 - 8) + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  *(void *)&long long v79 = &v63;
  TupleTypeMetadata2 = swift_getTupleTypeMetadata2(255, &type metadata for Int, a11, 0, 0);
  int64_t v21 = *(void *)(*(void *)(type metadata accessor for Optional(0, TupleTypeMetadata2) - 8) + 64);
  long long v22 = alloca(v21);
  long long v23 = alloca(v21);
  v82 = &v63;
  uint64_t v24 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for PartialRangeFrom<Int>);
  uint64_t v25 = (void *)lazy protocol witness table accessor for type PartialRangeFrom<Int> and conformance <> PartialRangeFrom<A>();
  uint64_t v26 = *(void *)(a12 + 8);
  *(void *)&long long v63 = v24;
  *((void *)&v63 + 1) = a10;
  uint64_t v64 = v25;
  uint64_t v65 = v26;
  uint64_t v75 = ((uint64_t (*)(void, long long *))type metadata accessor for Zip2Sequence)(0, &v63);
  int64_t v27 = *(void *)(*(void *)(v75 - 8) + 64);
  uint64_t v28 = alloca(v27);
  uint64_t v29 = alloca(v27);
  v76 = &v63;
  uint64_t v74 = v24;
  *(void *)&long long v63 = v24;
  *((void *)&v63 + 1) = a10;
  v72._char object = v25;
  uint64_t v64 = v25;
  uint64_t v73 = v26;
  uint64_t v65 = v26;
  uint64_t v30 = ((uint64_t (*)(void, long long *))type metadata accessor for Zip2Sequence.Iterator)(0, &v63);
  uint64_t v78 = *(void *)(v30 - 8);
  int64_t v31 = *(void *)(v78 + 64);
  uint64_t v32 = alloca(v31);
  int v33 = alloca(v31);
  uint64_t v34 = dispatch thunk of Collection.count.getter(a10, a12);
  if (v34 == v83)
  {
    *(void *)&long long v63 = 0;
    ((void (*)(long long *, long long *, uint64_t, uint64_t, void *, uint64_t))zip<A, B>(_:_:))(&v63, v84, v74, a10, v72._object, v73);
    Zip2Sequence.makeIterator()(v75);
    uint64_t v35 = v82;
    uint64_t v84 = &v63;
    Zip2Sequence.Iterator.next()(v30);
    uint64_t v36 = TupleTypeMetadata2;
    if (__swift_getEnumTagSinglePayload((uint64_t)v35, 1, TupleTypeMetadata2) != 1)
    {
      uint64_t v70 = v30;
      do
      {
        uint64_t v37 = a8 + *(void *)v35;
        if (__OFADD__(a8, *(void *)v35)) {
          BUG();
        }
        uint64_t v38 = (char *)v35 + *(int *)(v36 + 48);
        uint64_t v39 = v68;
        (*(void (**)(long long *, char *, uint64_t))(v67 + 32))(v68, v38, a11);
        uint64_t v40 = *(void *)(a9 + 24);
        uint64_t v41 = v39;
        uint64_t v42 = v69;
        dispatch thunk of FloatingPoint.init<A>(_:)(v41, a11, a13, v69, *(void *)(v40 + 16));
        uint64_t v43 = v40;
        uint64_t v35 = v82;
        uint64_t v47 = type metadata accessor for DenseMatrix(0, v42, v43, v44, v45, v46);
        uint64_t v36 = TupleTypeMetadata2;
        DenseMatrix.subscript.setter(v79, a7, v37, v47);
        uint64_t v30 = v70;
        Zip2Sequence.Iterator.next()(v70);
      }
      while (__swift_getEnumTagSinglePayload((uint64_t)v35, 1, v36) != 1);
    }
    return (*(uint64_t (**)(long long *, uint64_t))(v78 + 8))(v84, v30);
  }
  else
  {
    *(void *)&long long v63 = 0;
    *((void *)&v63 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(73);
    v49._countAndFlagsBits = 0xD00000000000001ALL;
    v49._char object = "es a training checkpoint." + 0x8000000000000000;
    String.append(_:)(v49);
    uint64_t v80 = v83;
    uint64_t v50 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char v52 = (char)v51;
    v49._countAndFlagsBits = v50;
    v49._char object = v51;
    String.append(_:)(v49);
    swift_bridgeObjectRelease(v52);
    v49._countAndFlagsBits = 0x61656620726F6620;
    v49._char object = (void *)0xEE00272065727574;
    String.append(_:)(v49);
    BOOL v53 = v71;
    swift_bridgeObjectRetain((_BYTE)v71);
    v49._countAndFlagsBits = v72._countAndFlagsBits;
    v49._char object = v53;
    String.append(_:)(v49);
    swift_bridgeObjectRelease((_BYTE)v53);
    v49._char object = "Expected arrays with size " + 0x8000000000000000;
    v49._countAndFlagsBits = 0xD000000000000010;
    String.append(_:)(v49);
    uint64_t v80 = dispatch thunk of Collection.count.getter(a10, a12);
    uint64_t v54 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    char v56 = (char)v55;
    v49._countAndFlagsBits = v54;
    v49._char object = v55;
    String.append(_:)(v49);
    swift_bridgeObjectRelease(v56);
    v49._countAndFlagsBits = 0x20776F7220746120;
    v49._char object = (void *)0xE800000000000000;
    String.append(_:)(v49);
    uint64_t v80 = a7;
    uint64_t v57 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    LOBYTE(v53) = (_BYTE)v58;
    v49._countAndFlagsBits = v57;
    v49._char object = v58;
    String.append(_:)(v49);
    swift_bridgeObjectRelease((_BYTE)v53);
    v49._countAndFlagsBits = 46;
    v49._char object = (void *)0xE100000000000000;
    String.append(_:)(v49);
    long long v79 = v63;
    v49._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v49._object, 0, 0);
    *(_OWORD *)uint64_t v59 = v79;
    *(_OWORD *)(v59 + 16) = 0;
    *(_OWORD *)(v59 + 32) = 0;
    *(unsigned char *)(v59 + 48) = 0;
    return swift_willThrow(&type metadata for MLCreateError, v49._object, v59, v60, v61, v62);
  }
}

{
  uint64_t v13;
  uint64_t v14;
  int64_t v15;
  void *v16;
  void *v17;
  int64_t v18;
  void *v19;
  void *v20;
  int64_t v21;
  void *v22;
  void *v23;
  uint64_t v24;
  void *v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  int64_t v31;
  void *v32;
  void *v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  int64_t v39;
  void *v40;
  void *v41;
  uint64_t v42;
  long long *v43;
  uint64_t v44;
  uint64_t v45;
  char *v46;
  long long *v47;
  uint64_t v48;
  long long *v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  Swift::String v57;
  uint64_t v58;
  void *v59;
  char v60;
  void *v61;
  uint64_t v62;
  void *v63;
  char v64;
  uint64_t v65;
  void *v66;
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  long long v71;
  void *v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  long long *v76;
  uint64_t v77;
  uint64_t v78;
  void *v79;
  Swift::String v80;
  uint64_t v81;
  uint64_t v82;
  uint64_t v83;
  long long *v84;
  uint64_t v85;
  uint64_t v86;
  long long v87;
  uint64_t v88;
  uint64_t TupleTypeMetadata2;
  long long *v90;
  uint64_t v91;
  long long *v92;

  uint64_t v85 = v13;
  uint64_t v74 = v14;
  uint64_t v91 = a6;
  long long v79 = a3;
  v80._countAndFlagsBits = a2;
  uint64_t v92 = a1;
  uint64_t v75 = *(void *)(a11 - 8);
  int64_t v15 = *(void *)(v75 + 64);
  uint64_t v16 = alloca(v15);
  char v17 = alloca(v15);
  v76 = &v71;
  uint64_t v77 = *(void *)(a9 + 16);
  int64_t v18 = *(void *)(*(void *)(v77 - 8) + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  *(void *)&char v87 = &v71;
  TupleTypeMetadata2 = swift_getTupleTypeMetadata2(255, &type metadata for Int, a11, 0, 0);
  int64_t v21 = *(void *)(*(void *)(type metadata accessor for Optional(0, TupleTypeMetadata2) - 8) + 64);
  long long v22 = alloca(v21);
  long long v23 = alloca(v21);
  v90 = &v71;
  uint64_t v24 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for PartialRangeFrom<Int>);
  uint64_t v25 = (void *)lazy protocol witness table accessor for type PartialRangeFrom<Int> and conformance <> PartialRangeFrom<A>();
  uint64_t v26 = *(void *)(a12 + 8);
  *(void *)&uint64_t v71 = v24;
  *((void *)&v71 + 1) = a10;
  Swift::String v72 = v25;
  uint64_t v73 = v26;
  uint64_t v83 = ((uint64_t (*)(void, long long *, uint64_t, uint64_t, uint64_t, uint64_t))type metadata accessor for Zip2Sequence)(0, &v71, v27, v28, v29, v30);
  int64_t v31 = *(void *)(*(void *)(v83 - 8) + 64);
  uint64_t v32 = alloca(v31);
  int v33 = alloca(v31);
  uint64_t v84 = &v71;
  v82 = v24;
  *(void *)&uint64_t v71 = v24;
  *((void *)&v71 + 1) = a10;
  v80._char object = v25;
  Swift::String v72 = v25;
  uint64_t v81 = v26;
  uint64_t v73 = v26;
  uint64_t v38 = ((uint64_t (*)(void, long long *, uint64_t, uint64_t, uint64_t, uint64_t))type metadata accessor for Zip2Sequence.Iterator)(0, &v71, v34, v35, v36, v37);
  v86 = *(void *)(v38 - 8);
  uint64_t v39 = *(void *)(v86 + 64);
  uint64_t v40 = alloca(v39);
  uint64_t v41 = alloca(v39);
  uint64_t v42 = dispatch thunk of Collection.count.getter(a10, a12);
  if (v42 == v91)
  {
    *(void *)&uint64_t v71 = 0;
    ((void (*)(long long *, long long *, uint64_t, uint64_t, void *, uint64_t))zip<A, B>(_:_:))(&v71, v92, v82, a10, v80._object, v81);
    Zip2Sequence.makeIterator()(v83);
    uint64_t v43 = v90;
    uint64_t v92 = &v71;
    Zip2Sequence.Iterator.next()(v38);
    uint64_t v44 = TupleTypeMetadata2;
    if (__swift_getEnumTagSinglePayload((uint64_t)v43, 1, TupleTypeMetadata2) != 1)
    {
      uint64_t v78 = v38;
      do
      {
        uint64_t v45 = a8 + *(void *)v43;
        if (__OFADD__(a8, *(void *)v43)) {
          BUG();
        }
        uint64_t v46 = (char *)v43 + *(int *)(v44 + 48);
        uint64_t v47 = v76;
        (*(void (**)(long long *, char *, uint64_t))(v75 + 32))(v76, v46, a11);
        uint64_t v48 = *(void *)(a9 + 24);
        Swift::String v49 = v47;
        uint64_t v50 = v77;
        dispatch thunk of BinaryFloatingPoint.init<A>(_:)(v49, a11, a13, v77, v48);
        uint64_t v51 = v48;
        uint64_t v43 = v90;
        uint64_t v55 = type metadata accessor for DenseMatrix(0, v50, v51, v52, v53, v54);
        uint64_t v44 = TupleTypeMetadata2;
        DenseMatrix.subscript.setter(v87, a7, v45, v55);
        uint64_t v38 = v78;
        Zip2Sequence.Iterator.next()(v78);
      }
      while (__swift_getEnumTagSinglePayload((uint64_t)v43, 1, v44) != 1);
    }
    return (*(uint64_t (**)(long long *, uint64_t))(v86 + 8))(v92, v38);
  }
  else
  {
    *(void *)&uint64_t v71 = 0;
    *((void *)&v71 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(73);
    v57._countAndFlagsBits = 0xD00000000000001ALL;
    v57._char object = "es a training checkpoint." + 0x8000000000000000;
    String.append(_:)(v57);
    uint64_t v88 = v91;
    uint64_t v58 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    uint64_t v60 = (char)v59;
    v57._countAndFlagsBits = v58;
    v57._char object = v59;
    String.append(_:)(v57);
    swift_bridgeObjectRelease(v60);
    v57._countAndFlagsBits = 0x61656620726F6620;
    v57._char object = (void *)0xEE00272065727574;
    String.append(_:)(v57);
    uint64_t v61 = v79;
    swift_bridgeObjectRetain((_BYTE)v79);
    v57._countAndFlagsBits = v80._countAndFlagsBits;
    v57._char object = v61;
    String.append(_:)(v57);
    swift_bridgeObjectRelease((_BYTE)v61);
    v57._char object = "Expected arrays with size " + 0x8000000000000000;
    v57._countAndFlagsBits = 0xD000000000000010;
    String.append(_:)(v57);
    uint64_t v88 = dispatch thunk of Collection.count.getter(a10, a12);
    uint64_t v62 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    uint64_t v64 = (char)v63;
    v57._countAndFlagsBits = v62;
    v57._char object = v63;
    String.append(_:)(v57);
    swift_bridgeObjectRelease(v64);
    v57._countAndFlagsBits = 0x20776F7220746120;
    v57._char object = (void *)0xE800000000000000;
    String.append(_:)(v57);
    uint64_t v88 = a7;
    uint64_t v65 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    LOBYTE(v61) = (_BYTE)v66;
    v57._countAndFlagsBits = v65;
    v57._char object = v66;
    String.append(_:)(v57);
    swift_bridgeObjectRelease((_BYTE)v61);
    v57._countAndFlagsBits = 46;
    v57._char object = (void *)0xE100000000000000;
    String.append(_:)(v57);
    char v87 = v71;
    v57._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v57._object, 0, 0);
    *(_OWORD *)uint64_t v67 = v87;
    *(_OWORD *)(v67 + 16) = 0;
    *(_OWORD *)(v67 + 32) = 0;
    *(unsigned char *)(v67 + 48) = 0;
    return swift_willThrow(&type metadata for MLCreateError, v57._object, v67, v68, v69, v70);
  }
}

uint64_t lazy protocol witness table accessor for type PartialRangeFrom<Int> and conformance <> PartialRangeFrom<A>()
{
  uint64_t result = lazy protocol witness table cache variable for type PartialRangeFrom<Int> and conformance <> PartialRangeFrom<A>;
  if (!lazy protocol witness table cache variable for type PartialRangeFrom<Int> and conformance <> PartialRangeFrom<A>)
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for PartialRangeFrom<Int>);
    lazy protocol witness table accessor for type Int and conformance Int();
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for <> PartialRangeFrom<A>, v1);
    lazy protocol witness table cache variable for type PartialRangeFrom<Int> and conformance <> PartialRangeFrom<A> = result;
  }
  return result;
}

uint64_t type metadata completion function for FeatureMatrixBuilder(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v6 = type metadata accessor for DenseMatrix(319, *(void *)(a1 + 16), *(void *)(a1 + 24), a4, a5, a6, (char *)&value witness table for Builtin.BridgeObject + 64, (char *)&value witness table for Builtin.BridgeObject + 64, &unk_349B98);
  if (v7 <= 0x3F)
  {
    v9[3] = *(void *)(v6 - 8) + 64;
    uint64_t v6 = 0;
    swift_initStructMetadata(a1, 0, 4, v9, a1 + 32);
  }
  return v6;
}

uint64_t initializeBufferWithCopyOfBuffer for FeatureMatrixBuilder(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  int v6 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  uint64_t v7 = *a2;
  *(void *)a1 = *a2;
  if ((v6 & 0x20000) != 0)
  {
    uint64_t v8 = v7 + ((v6 + 16) & ~v6);
    swift_retain(v7);
  }
  else
  {
    uint64_t v8 = a1;
    uint64_t v9 = a2[1];
    *(void *)(a1 + 8) = v9;
    *(unsigned char *)(a1 + 16) = *((unsigned char *)a2 + 16);
    uint64_t v10 = *(int *)(a3 + 44);
    uint64_t v14 = a1 + v10;
    uint64_t v11 = (uint64_t)a2 + v10;
    uint64_t v12 = type metadata accessor for DenseMatrix(0, *(void *)(a3 + 16), *(void *)(a3 + 24), a1 + v10, a5, a6);
    int64_t v15 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v12 - 8) + 16);
    swift_bridgeObjectRetain(v7);
    swift_bridgeObjectRetain(v9);
    v15(v14, v11, v12);
  }
  return v8;
}

uint64_t destroy for FeatureMatrixBuilder(void *a1, uint64_t a2)
{
  swift_bridgeObjectRelease(*a1);
  swift_bridgeObjectRelease(a1[1]);
  uint64_t v2 = (char *)a1 + *(int *)(a2 + 44);
  uint64_t v6 = type metadata accessor for DenseMatrix(0, *(void *)(a2 + 16), *(void *)(a2 + 24), v3, v4, v5);
  return (*(uint64_t (**)(char *, uint64_t))(*(void *)(v6 - 8) + 8))(v2, v6);
}

uint64_t initializeWithCopy for FeatureMatrixBuilder(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v6 = *a2;
  *(void *)a1 = *a2;
  uint64_t v7 = a2[1];
  *(void *)(a1 + 8) = v7;
  *(unsigned char *)(a1 + 16) = *((unsigned char *)a2 + 16);
  uint64_t v8 = *(int *)(a3 + 44);
  uint64_t v12 = a1 + v8;
  uint64_t v9 = (uint64_t)a2 + v8;
  uint64_t v10 = type metadata accessor for DenseMatrix(0, *(void *)(a3 + 16), *(void *)(a3 + 24), a1 + v8, a5, a6);
  uint64_t v13 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v10 - 8) + 16);
  swift_bridgeObjectRetain(v6);
  swift_bridgeObjectRetain(v7);
  v13(v12, v9, v10);
  return a1;
}

uint64_t *assignWithCopy for FeatureMatrixBuilder(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v5 = *a2;
  uint64_t v6 = *a1;
  *a1 = *a2;
  swift_bridgeObjectRetain(v5);
  swift_bridgeObjectRelease(v6);
  uint64_t v7 = a2[1];
  uint64_t v8 = a1[1];
  a1[1] = v7;
  swift_bridgeObjectRetain(v7);
  swift_bridgeObjectRelease(v8);
  *((unsigned char *)a1 + 16) = *((unsigned char *)a2 + 16);
  uint64_t v9 = *(int *)(a3 + 44);
  uint64_t v10 = (uint64_t)a1 + v9;
  uint64_t v11 = (uint64_t)a2 + v9;
  uint64_t v15 = type metadata accessor for DenseMatrix(0, *(void *)(a3 + 16), *(void *)(a3 + 24), v12, v13, v14);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v15 - 8) + 24))(v10, v11, v15);
  return a1;
}

uint64_t initializeWithTake for FeatureMatrixBuilder(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  uint64_t v6 = *(int *)(a3 + 44);
  uint64_t v7 = a1 + v6;
  uint64_t v8 = v6 + a2;
  uint64_t v9 = type metadata accessor for DenseMatrix(0, *(void *)(a3 + 16), *(void *)(a3 + 24), a4, a5, a6);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v9 - 8) + 32))(v7, v8, v9);
  return a1;
}

uint64_t *assignWithTake for FeatureMatrixBuilder(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v5 = *a1;
  *a1 = *a2;
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = a1[1];
  a1[1] = a2[1];
  swift_bridgeObjectRelease(v6);
  *((unsigned char *)a1 + 16) = *((unsigned char *)a2 + 16);
  uint64_t v7 = *(int *)(a3 + 44);
  uint64_t v8 = (uint64_t)a1 + v7;
  uint64_t v9 = (uint64_t)a2 + v7;
  uint64_t v13 = type metadata accessor for DenseMatrix(0, *(void *)(a3 + 16), *(void *)(a3 + 24), v10, v11, v12);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v13 - 8) + 40))(v8, v9, v13);
  return a1;
}

uint64_t getEnumTagSinglePayload for FeatureMatrixBuilder(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_E15D6);
}

uint64_t sub_E15D6(void *a1, unsigned int a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t result = 0;
    if ((*a1 & 0xFFFFFFFF00000001) == 0) {
      return (*a1 >> 1) + 1;
    }
  }
  else
  {
    uint64_t v8 = type metadata accessor for DenseMatrix(0, *(void *)(a3 + 16), *(void *)(a3 + 24), a4, a5, a6);
    return __swift_getEnumTagSinglePayload((uint64_t)a1 + *(int *)(a3 + 44), a2, v8);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for FeatureMatrixBuilder(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_E1656);
}

uint64_t sub_E1656(void *a1, unsigned int a2, int a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  if (a3 == 0x7FFFFFFF)
  {
    *a1 = 2 * (a2 - 1);
  }
  else
  {
    uint64_t v7 = type metadata accessor for DenseMatrix(0, *(void *)(a4 + 16), *(void *)(a4 + 24), a4, a5, a6);
    return __swift_storeEnumTagSinglePayload((uint64_t)a1 + *(int *)(a4 + 44), a2, a2, v7);
  }
  return result;
}

uint64_t type metadata accessor for FeatureMatrixBuilder(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for FeatureMatrixBuilder);
}

_UNKNOWN **one-time initialization function for predictor()
{
  static JaccardSimilarity.predictor = (uint64_t)&type metadata for JaccardSimilarityPredictor;
  uint64_t result = &protocol witness table for JaccardSimilarityPredictor;
  qword_3C6D20 = (uint64_t)&protocol witness table for JaccardSimilarityPredictor;
  return result;
}

{
  _UNKNOWN **result;

  static PearsonSimilarity.predictor = (uint64_t)&type metadata for PearsonSimilarityPredictor;
  uint64_t result = &protocol witness table for PearsonSimilarityPredictor;
  qword_3C7058 = (uint64_t)&protocol witness table for PearsonSimilarityPredictor;
  return result;
}

void *static JaccardSimilarity.buildItemStatistics(ratings:count:)(void *a1, uint64_t a2)
{
  uint64_t v2 = specialized Array.init(repeating:count:)(0, a2, 0.0);
  uint64_t v30 = a1[3];
  uint64_t v31 = a1[4];
  uint64_t v32 = a1[5];
  outlined retain of [Int](&v30);
  outlined retain of [Int](&v31);
  outlined retain of ContiguousArray<Double>(&v32);
  specialized SparseMatrix.IndexedSequence.Iterator.init(base:)((uint64_t)a1);
  specialized SparseMatrix.IndexedSequence.Iterator.next()(a1, a2, v3, v4, v5, v6);
  if ((v9 & 1) == 0)
  {
    uint64_t v10 = v7;
    uint64_t v11 = v8;
    do
    {
      uint64_t v12 = v2;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v2);
      double v17 = 0.0;
      if ((v11 & 0x7FFFFFFFFFFFFFFFLL) != 0) {
        double v17 = 1.0;
      }
      if (!isUniquelyReferenced_nonNull_native)
      {
        uint64_t v12 = v2;
        double v33 = v17;
        uint64_t v26 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v2);
        double v17 = v33;
        uint64_t v2 = v26;
      }
      if (v10 < 0) {
        BUG();
      }
      if ((unint64_t)v10 >= v2[2]) {
        BUG();
      }
      uint64_t v18 = 2 * v10;
      *(double *)&v2[v18 + 5] = v17 + *(double *)&v2[v18 + 5];
      uint64_t v19 = v2[v18 + 4];
      BOOL v20 = __OFADD__(1, v19);
      uint64_t v21 = v19 + 1;
      if (v20) {
        BUG();
      }
      long long v22 = &v2[v18 + 4];
      *long long v22 = v21;
      specialized SparseMatrix.IndexedSequence.Iterator.next()(v12, a2, v14, v22, v15, v16);
      uint64_t v10 = v23;
      uint64_t v11 = v24;
    }
    while ((v25 & 1) == 0);
  }
  swift_release();
  swift_bridgeObjectRelease(v29);
  swift_bridgeObjectRelease(v28);
  return v2;
}

void static JaccardSimilarityPredictor.updatePrediction(_:itemScore:neighborScore:)(double *a1, double a2, double a3)
{
  if (a2 != 0.0) {
    *a1 = a3 + *a1;
  }
}

double static JaccardSimilarityPredictor.finalizePrediction(_:userRatingCount:)(uint64_t a1, double a2)
{
  int v2 = 1;
  if (a1 >= 2) {
    int v2 = a1;
  }
  return a2 / (double)v2;
}

double protocol witness for static ItemSimilarityPredictor.interactionScoreRange.getter in conformance JaccardSimilarityPredictor()
{
  return 0.0;
}

void protocol witness for static ItemSimilarityPredictor.updatePrediction(_:itemScore:neighborScore:) in conformance JaccardSimilarityPredictor(double *a1, double a2, double a3)
{
}

double protocol witness for static ItemSimilarityPredictor.finalizePrediction(_:userRatingCount:) in conformance JaccardSimilarityPredictor(uint64_t a1, double a2)
{
  return static JaccardSimilarityPredictor.finalizePrediction(_:userRatingCount:)(a1, a2);
}

ValueMetadata *type metadata accessor for JaccardSimilarityPredictor()
{
  return &type metadata for JaccardSimilarityPredictor;
}

uint64_t static MLDataColumn.== infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.== infix(_:_:));
}

uint64_t static MLDataColumn.!= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.!= infix(_:_:));
}

uint64_t static MLDataColumn.> infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.> infix(_:_:));
}

uint64_t static MLDataColumn.< infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.< infix(_:_:));
}

uint64_t static MLDataColumn.>= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.>= infix(_:_:));
}

uint64_t static MLDataColumn.<= infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.<= infix(_:_:));
}

uint64_t static MLDataColumn.== infix(_:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void (*a5)(uint64_t *a1, uint64_t *a2))
{
  uint64_t v6 = v5;
  char v7 = *(unsigned char *)(a1 + 8);
  uint64_t v8 = *(void *)a2;
  char v9 = *(unsigned char *)(a2 + 8);
  uint64_t v13 = *(void *)a1;
  char v14 = v7;
  uint64_t v15 = v8;
  char v16 = v9;
  a5(&v13, &v15);
  uint64_t result = v11;
  *(void *)uint64_t v6 = v11;
  *(unsigned char *)(v6 + 8) = v12;
  return result;
}

uint64_t static MLDataColumn.== infix(_:_:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(uint64_t *, void *))static MLUntypedColumn.== infix(_:_:));
}

uint64_t static MLDataColumn.!= infix(_:_:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(uint64_t *, void *))static MLUntypedColumn.!= infix(_:_:));
}

uint64_t static MLDataColumn.> infix(_:_:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(uint64_t *, void *))static MLUntypedColumn.> infix(_:_:));
}

uint64_t static MLDataColumn.< infix(_:_:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(uint64_t *, void *))static MLUntypedColumn.< infix(_:_:));
}

uint64_t static MLDataColumn.>= infix(_:_:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(uint64_t *, void *))static MLUntypedColumn.>= infix(_:_:));
}

uint64_t static MLDataColumn.<= infix(_:_:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(uint64_t *, void *))static MLUntypedColumn.<= infix(_:_:));
}

uint64_t static MLDataColumn.== infix(_:_:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, void (*a5)(uint64_t *, void *))
{
  uint64_t v7 = v5;
  double v17 = a5;
  char v8 = *((unsigned char *)a1 + 8);
  uint64_t v15 = *a1;
  char v16 = v8;
  v12[3] = a3;
  v12[4] = a4;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v12);
  (*(void (**)(void *, uint64_t, uint64_t))(*(void *)(a3 - 8) + 16))(boxed_opaque_existential_1, a2, a3);
  v17(&v15, v12);
  __swift_destroy_boxed_opaque_existential_1Tm(v12);
  uint64_t result = v13;
  char v11 = v14;
  *(void *)uint64_t v7 = v13;
  *(unsigned char *)(v7 + 8) = v11;
  return result;
}

uint64_t static MLDataColumn.== infix(_:_:)(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(void *))static MLUntypedColumn.== infix(_:_:));
}

uint64_t static MLDataColumn.!= infix(_:_:)(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(void *))static MLUntypedColumn.!= infix(_:_:));
}

uint64_t static MLDataColumn.> infix(_:_:)(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(void *))static MLUntypedColumn.> infix(_:_:));
}

uint64_t static MLDataColumn.< infix(_:_:)(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(void *))static MLUntypedColumn.< infix(_:_:));
}

uint64_t static MLDataColumn.>= infix(_:_:)(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(void *))static MLUntypedColumn.>= infix(_:_:));
}

uint64_t static MLDataColumn.<= infix(_:_:)(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4)
{
  return static MLDataColumn.== infix(_:_:)(a1, a2, a3, a4, (void (*)(void *))static MLUntypedColumn.<= infix(_:_:));
}

uint64_t static MLDataColumn.== infix(_:_:)(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4, void (*a5)(void *))
{
  uint64_t v7 = v5;
  double v17 = a5;
  uint64_t v8 = *a2;
  char v18 = *((unsigned char *)a2 + 8);
  v12[3] = a3;
  v12[4] = a4;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v12);
  (*(void (**)(void *, uint64_t, uint64_t))(*(void *)(a3 - 8) + 16))(boxed_opaque_existential_1, a1, a3);
  uint64_t v15 = v8;
  char v16 = v18;
  v17(v12);
  __swift_destroy_boxed_opaque_existential_1Tm(v12);
  uint64_t result = v13;
  char v11 = v14;
  *(void *)uint64_t v7 = v13;
  *(unsigned char *)(v7 + 8) = v11;
  return result;
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t a1, uint64_t a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.+ infix(_:_:));
}

{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.+ infix(_:_:));
}

uint64_t static MLDataColumn<>.- infix(_:_:)(uint64_t a1, uint64_t a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.- infix(_:_:));
}

{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.- infix(_:_:));
}

uint64_t static MLDataColumn<>.* infix(_:_:)(uint64_t a1, uint64_t a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.* infix(_:_:));
}

{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.* infix(_:_:));
}

uint64_t static MLDataColumn<>./ infix(_:_:)(uint64_t a1, uint64_t a2)
{
  char v2 = *(unsigned char *)(a1 + 8);
  uint64_t v3 = *(void *)a2;
  char v4 = *(unsigned char *)(a2 + 8);
  uint64_t v8 = *(void *)a1;
  char v9 = v2;
  uint64_t v10 = v3;
  char v11 = v4;
  static MLUntypedColumn./ infix(_:_:)(&v8, &v10);
  specialized MLUntypedColumn.map<A>(to:)(v6, v7);
  return outlined consume of Result<_DataTable, Error>(v6, v7);
}

{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn./ infix(_:_:));
}

uint64_t specialized MLUntypedColumn.map<A>(to:)(uint64_t a1, char a2)
{
  v20[0] = 0;
  uint64_t v3 = v2;
  v20[1] = 0xE000000000000000;
  _StringGuts.grow(_:)(25);
  swift_bridgeObjectRelease(0);
  uint64_t v4 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v5 = swift_allocError(&type metadata for MLCreateError, v4, 0, 0);
  *(void *)uint64_t v6 = 0xD00000000000001ALL;
  *(void *)(v6 + 8) = "', but got size " + 0x8000000000000000;
  *(_OWORD *)(v6 + 16) = 0;
  *(_OWORD *)(v6 + 32) = 0;
  *(unsigned char *)(v6 + 48) = 1;
  if (a2)
  {
    long long v22 = v3;
    v20[0] = a1;
    swift_errorRetain(a1);
    outlined copy of Result<_DataTable, Error>(a1, 1);
    uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v10 = _getErrorEmbeddedNSError<A>(_:)(v20, v9, &protocol self-conformance witness table for Error);
    if (v10)
    {
      uint64_t v11 = v10;
      outlined consume of Result<_DataTable, Error>(a1, 1);
    }
    else
    {
      uint64_t v11 = swift_allocError(v9, &protocol self-conformance witness table for Error, 0, 0);
      *char v18 = v20[0];
    }
    char v23 = 1;
    swift_errorRelease(v5);
    uint64_t result = outlined consume of Result<_DataTable, Error>(a1, 1);
    char v13 = v23;
  }
  else
  {
    uint64_t v7 = *(void *)(*(void *)(a1 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(a1, 0);
    uint64_t v8 = specialized handling<A, B, C, D>(_:_:_:_:)(v7, 0, 0);
    uint64_t v12 = v8;
    uint64_t v21 = v5;
    long long v22 = v3;
    if (!v8) {
      BUG();
    }
    char v13 = 0;
    uint64_t v14 = type metadata accessor for CMLColumn();
    uint64_t v15 = swift_allocObject(v14, 24, 7);
    *(void *)(v15 + 16) = v12;
    uint64_t v16 = type metadata accessor for _UntypedColumn();
    uint64_t v11 = swift_allocObject(v16, 24, 7);
    *(void *)(v11 + 16) = v15;
    swift_errorRelease(v21);
    uint64_t result = outlined consume of Result<_DataTable, Error>(a1, 0);
  }
  uint64_t v19 = v22;
  *long long v22 = v11;
  *((unsigned char *)v19 + 8) = v13 & 1;
  return result;
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t a1, uint64_t *a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(void *, uint64_t))static MLUntypedColumn.+ infix(_:_:));
}

uint64_t static MLDataColumn<>.- infix(_:_:)(uint64_t a1, uint64_t *a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(void *, uint64_t))static MLUntypedColumn.- infix(_:_:));
}

uint64_t static MLDataColumn<>.* infix(_:_:)(uint64_t a1, uint64_t *a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(void *, uint64_t))static MLUntypedColumn.* infix(_:_:));
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t a1, uint64_t *a2, void (*a3)(void *a1, uint64_t a2))
{
  uint64_t v4 = v3;
  uint64_t v5 = *a2;
  char v6 = *((unsigned char *)a2 + 8);
  v9[3] = &type metadata for Int;
  v9[4] = &protocol witness table for Int;
  v9[0] = a1;
  uint64_t v12 = v5;
  char v13 = v6;
  a3(v9, (uint64_t)&v12);
  __swift_destroy_boxed_opaque_existential_1Tm(v9);
  uint64_t result = v10;
  char v8 = v11;
  *(void *)uint64_t v4 = v10;
  *(unsigned char *)(v4 + 8) = v8;
  return result;
}

uint64_t static MLDataColumn<>./ infix(_:_:)(uint64_t a1, uint64_t *a2)
{
  uint64_t v2 = *a2;
  char v3 = *((unsigned char *)a2 + 8);
  v7[3] = &type metadata for Int;
  v7[4] = &protocol witness table for Int;
  v7[0] = a1;
  uint64_t v10 = v2;
  char v11 = v3;
  static MLUntypedColumn./ infix(_:_:)(v7, (uint64_t)&v10);
  __swift_destroy_boxed_opaque_existential_1Tm(v7);
  uint64_t v4 = v8;
  char v5 = v9;
  specialized MLUntypedColumn.map<A>(to:)(v8, v9);
  return outlined consume of Result<_DataTable, Error>(v4, v5);
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t *a1, uint64_t a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(uint64_t, void *))static MLUntypedColumn.+ infix(_:_:));
}

uint64_t static MLDataColumn<>.- infix(_:_:)(uint64_t *a1, uint64_t a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(uint64_t, void *))static MLUntypedColumn.- infix(_:_:));
}

uint64_t static MLDataColumn<>.* infix(_:_:)(uint64_t *a1, uint64_t a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(uint64_t, void *))static MLUntypedColumn.* infix(_:_:));
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t *a1, uint64_t a2, void (*a3)(uint64_t a1, void *a2))
{
  uint64_t v4 = v3;
  char v5 = *((unsigned char *)a1 + 8);
  uint64_t v11 = *a1;
  char v12 = v5;
  v8[3] = &type metadata for Int;
  v8[4] = &protocol witness table for Int;
  v8[0] = a2;
  a3((uint64_t)&v11, v8);
  __swift_destroy_boxed_opaque_existential_1Tm(v8);
  uint64_t result = v9;
  char v7 = v10;
  *(void *)uint64_t v4 = v9;
  *(unsigned char *)(v4 + 8) = v7;
  return result;
}

uint64_t static MLDataColumn<>./ infix(_:_:)(uint64_t *a1, uint64_t a2)
{
  char v2 = *((unsigned char *)a1 + 8);
  uint64_t v9 = *a1;
  char v10 = v2;
  v6[3] = &type metadata for Int;
  v6[4] = &protocol witness table for Int;
  v6[0] = a2;
  static MLUntypedColumn./ infix(_:_:)((uint64_t)&v9, v6);
  __swift_destroy_boxed_opaque_existential_1Tm(v6);
  uint64_t v3 = v7;
  char v4 = v8;
  specialized MLUntypedColumn.map<A>(to:)(v7, v8);
  return outlined consume of Result<_DataTable, Error>(v3, v4);
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t *a1, double a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (void (*)(double *))static MLUntypedColumn.+ infix(_:_:), a2);
}

{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (void (*)(uint64_t *, double *))static MLUntypedColumn.+ infix(_:_:), a2);
}

uint64_t static MLDataColumn<>.- infix(_:_:)(uint64_t *a1, double a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (void (*)(double *))static MLUntypedColumn.- infix(_:_:), a2);
}

{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (void (*)(uint64_t *, double *))static MLUntypedColumn.- infix(_:_:), a2);
}

uint64_t static MLDataColumn<>.* infix(_:_:)(uint64_t *a1, double a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (void (*)(double *))static MLUntypedColumn.* infix(_:_:), a2);
}

{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (void (*)(uint64_t *, double *))static MLUntypedColumn.* infix(_:_:), a2);
}

uint64_t static MLDataColumn<>./ infix(_:_:)(uint64_t *a1, double a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (void (*)(double *))static MLUntypedColumn./ infix(_:_:), a2);
}

{
  return static MLDataColumn<>.+ infix(_:_:)(a1, (void (*)(uint64_t *, double *))static MLUntypedColumn./ infix(_:_:), a2);
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t *a1, void (*a2)(double *), double a3)
{
  uint64_t v4 = v3;
  uint64_t v5 = *a1;
  char v6 = *((unsigned char *)a1 + 8);
  *(void *)&v9[3] = &type metadata for Double;
  *(void *)&v9[4] = &protocol witness table for Double;
  v9[0] = a3;
  uint64_t v12 = v5;
  char v13 = v6;
  a2(v9);
  __swift_destroy_boxed_opaque_existential_1Tm(v9);
  uint64_t result = v10;
  char v8 = v11;
  *(void *)uint64_t v4 = v10;
  *(unsigned char *)(v4 + 8) = v8;
  return result;
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t *a1, void (*a2)(uint64_t *, double *), double a3)
{
  uint64_t v4 = v3;
  char v5 = *((unsigned char *)a1 + 8);
  uint64_t v11 = *a1;
  char v12 = v5;
  *(void *)&v8[3] = &type metadata for Double;
  *(void *)&v8[4] = &protocol witness table for Double;
  v8[0] = a3;
  a2(&v11, v8);
  __swift_destroy_boxed_opaque_existential_1Tm(v8);
  uint64_t result = v9;
  char v7 = v10;
  *(void *)uint64_t v4 = v9;
  *(unsigned char *)(v4 + 8) = v7;
  return result;
}

uint64_t static MLDataColumn<>.|| infix(_:_:)(uint64_t a1, uint64_t a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.|| infix(_:_:));
}

uint64_t static MLDataColumn<>.&& infix(_:_:)(uint64_t a1, uint64_t a2)
{
  return static MLDataColumn<>.+ infix(_:_:)(a1, a2, (void (*)(uint64_t *, uint64_t *))static MLUntypedColumn.&& infix(_:_:));
}

uint64_t static MLDataColumn<>.+ infix(_:_:)(uint64_t a1, uint64_t a2, void (*a3)(uint64_t *a1, uint64_t *a2))
{
  uint64_t v4 = v3;
  char v5 = *(unsigned char *)(a1 + 8);
  uint64_t v6 = *(void *)a2;
  char v7 = *(unsigned char *)(a2 + 8);
  uint64_t v11 = *(void *)a1;
  char v12 = v5;
  uint64_t v13 = v6;
  char v14 = v7;
  a3(&v11, &v13);
  uint64_t result = v9;
  *(void *)uint64_t v4 = v9;
  *(unsigned char *)(v4 + 8) = v10;
  return result;
}

uint64_t specialized RandomAccessCollection<>.index(after:)(uint64_t a1)
{
  uint64_t v1 = CMLSequence.size.getter();
  if (a1 < 0 || v1 <= a1) {
    BUG();
  }
  return a1 + 1;
}

{
  return specialized RandomAccessCollection<>.index(after:)(a1);
}

{
  return specialized RandomAccessCollection<>.index(after:)(a1, CMLDictionary.size.getter);
}

{
  Swift::Int v1;

  uint64_t v1 = MLDataTable.size.getter();
  if (a1 < 0 || v1 <= a1) {
    BUG();
  }
  return a1 + 1;
}

{
  uint64_t v1;
  uint64_t v2;

  swift_retain();
  uint64_t v1 = CMLSequence.size.getter();
  char v2 = specialized RandomAccessCollection<>.distance(from:to:)(0, v1);
  swift_release();
  if (a1 < 0 || v2 <= a1) {
    BUG();
  }
  return a1 + 1;
}

{
  return specialized RandomAccessCollection<>.index(after:)(a1, CMLSequence.size.getter);
}

uint64_t specialized RandomAccessCollection<>.index(after:)(uint64_t a1, uint64_t (__cdecl *a2)())
{
  uint64_t v2 = a2();
  if (a1 < 0 || v2 <= a1) {
    BUG();
  }
  return a1 + 1;
}

uint64_t MLActivityClassifier.DataSource.gatherAnnotatedFeatures(featureColumns:labelColumn:recordingFileColumn:)(uint64_t a1, uint64_t a2, uint64_t *a3, void *a4, void *a5)
{
  char v14 = a4;
  uint64_t v15 = a3;
  uint64_t v17 = v5;
  uint64_t v16 = v7;
  int64_t v9 = *(void *)(*(void *)(type metadata accessor for MLActivityClassifier.DataSource.Columns(0) - 8) + 64);
  char v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t result = MLActivityClassifier.DataSource.gatherData(featureColumns:labelColumn:recordingFileColumn:)(a1, a2, v15, v14, a5);
  if (!v6)
  {
    MLActivityClassifier.DataSource.Columns.buildDataFrame()(a1, a2);
    return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v13, type metadata accessor for MLActivityClassifier.DataSource.Columns);
  }
  return result;
}

uint64_t MLActivityClassifier.DataSource.labeledSensorData(featureColumns:labelColumn:recordingFileColumn:)(uint64_t a1, uint64_t a2, uint64_t *a3, void *a4, void *a5, __m128 a6)
{
  char v23 = a4;
  uint64_t v28 = v6;
  uint64_t v24 = v7;
  uint64_t v25 = v8;
  uint64_t v26 = a5;
  uint64_t v27 = a1;
  int64_t v11 = *(void *)(*(void *)(type metadata accessor for DataFrame(0) - 8) + 64);
  char v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  char v29 = &v23;
  int64_t v14 = *(void *)(*(void *)(type metadata accessor for MLActivityClassifier.DataSource.Columns(0) - 8) + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  if (!a3) {
    a2 = 0x6C6562616CLL;
  }
  uint64_t v17 = (uint64_t *)0xE500000000000000;
  if (a3) {
    uint64_t v17 = a3;
  }
  swift_bridgeObjectRetain((_BYTE)a3);
  uint64_t v30 = &v23;
  uint64_t v18 = a2;
  uint64_t v19 = v24;
  MLActivityClassifier.DataSource.gatherData(featureColumns:labelColumn:recordingFileColumn:)(v27, a2, v17, v23, v26);
  uint64_t result = swift_bridgeObjectRelease((_BYTE)v17);
  if (!v19)
  {
    uint64_t v21 = (uint64_t)v29;
    uint64_t v22 = (uint64_t)v30;
    MLActivityClassifier.DataSource.Columns.buildDataFrame()((uint64_t)v17, v18);
    MLDataTable.init(_:convertArraysToShapedArrays:)(v21, 0, a6);
    return outlined destroy of MLActivityClassifier.ModelParameters(v22, type metadata accessor for MLActivityClassifier.DataSource.Columns);
  }
  return result;
}

uint64_t MLActivityClassifier.DataSource.stratifiedSplit(proportions:seed:featureColumns:labelColumn:recordingFileColumn:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void *a5, uint64_t a6, __m128 a7, unint64_t a8)
{
  v166 = v8;
  uint64_t v165 = a2;
  uint64_t v164 = a1;
  int64_t v14 = (uint64_t *)(((unint64_t)a5 >> 56) & 0xF);
  uint64_t v15 = a4 & 0xFFFFFFFFFFFFLL;
  if (((unint64_t)a5 & 0x2000000000000000) == 0) {
    int64_t v14 = (uint64_t *)v15;
  }
  uint64_t v16 = a4;
  if (v14) {
    int64_t v14 = (uint64_t *)a5;
  }
  else {
    uint64_t v16 = 0;
  }
  uint64_t v17 = (void *)(HIBYTE(a8) & 0xF);
  if ((a8 & 0x2000000000000000) == 0) {
    uint64_t v17 = (void *)(a6 & 0xFFFFFFFFFFFFLL);
  }
  uint64_t v18 = (void *)a6;
  if (v17) {
    uint64_t v17 = (void *)a8;
  }
  else {
    uint64_t v18 = 0;
  }
  uint64_t result = MLActivityClassifier.DataSource.labeledSensorData(featureColumns:labelColumn:recordingFileColumn:)(a3, v16, v14, v18, v17, a7);
  if (v9) {
    return result;
  }
  v173._unsigned __int8 object = a5;
  v173._uint64_t countAndFlagsBits = a4;
  uint64_t v172 = a6;
  unsigned __int8 v189 = v177;
  v181 = v176;
  if ((_BYTE)v177)
  {
    outlined copy of Result<_DataTable, Error>((uint64_t)v176, 1);
    uint64_t v20 = tc_v1_flex_list_create(0);
    if (!v20) {
      BUG();
    }
    uint64_t v21 = v176;
    uint64_t v22 = v20;
    uint64_t v23 = type metadata accessor for CMLSequence();
    uint64_t v24 = (void *)swift_allocObject(v23, 25, 7);
    v24[2] = v22;
    *((unsigned char *)v24 + 24) = 1;
    outlined consume of Result<_DataTable, Error>((uint64_t)v21, 1);
  }
  else
  {
    outlined copy of Result<_DataTable, Error>((uint64_t)v176, 0);
    _DataTable.columnNames.getter(v176);
    outlined consume of Result<_DataTable, Error>((uint64_t)v176, 0);
    uint64_t v24 = v185;
  }
  v187._uint64_t countAndFlagsBits = v172;
  v187._unsigned __int8 object = (void *)a8;
  uint64_t v25 = alloca(24);
  uint64_t v26 = alloca(32);
  v160 = &v187;
  char v27 = specialized Sequence.contains(where:)((uint64_t (*)(unint64_t *))partial apply for specialized closure #1 in Sequence<>.contains(_:), (uint64_t)&v158, (uint64_t)v24);
  v183._uint64_t countAndFlagsBits = 0;
  swift_release();
  if ((v27 & 1) == 0)
  {
    uint64_t v33 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v33, 0, 0);
    *(void *)uint64_t v34 = 0xD00000000000001CLL;
    uint64_t v38 = "Unable to map to type Int.";
LABEL_50:
    *(void *)(v34 + 8) = (unint64_t)v38 | 0x8000000000000000;
    *(_OWORD *)(v34 + 16) = 0;
    *(_OWORD *)(v34 + 32) = 0;
    *(unsigned char *)(v34 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v33, v34, v35, v36, v37);
    return outlined consume of Result<_DataTable, Error>((uint64_t)v176, v177);
  }
  if (v189)
  {
    uint64_t v28 = v181;
    outlined copy of Result<_DataTable, Error>((uint64_t)v181, 1);
    uint64_t v29 = tc_v1_flex_list_create(0);
    if (!v29) {
      BUG();
    }
    uint64_t v30 = v29;
    uint64_t v31 = type metadata accessor for CMLSequence();
    uint64_t v32 = (void *)swift_allocObject(v31, 25, 7);
    v32[2] = v30;
    *((unsigned char *)v32 + 24) = 1;
    outlined consume of Result<_DataTable, Error>((uint64_t)v28, 1);
  }
  else
  {
    uint64_t v39 = v181;
    uint64_t v40 = v181;
    outlined copy of Result<_DataTable, Error>((uint64_t)v181, 0);
    _DataTable.columnNames.getter(v40);
    outlined consume of Result<_DataTable, Error>((uint64_t)v39, 0);
    uint64_t v32 = v185;
  }
  Swift::String v187 = v173;
  uint64_t v41 = alloca(24);
  uint64_t v42 = alloca(32);
  v160 = &v187;
  uint64_t countAndFlagsBits = v183._countAndFlagsBits;
  char v44 = specialized Sequence.contains(where:)((uint64_t (*)(unint64_t *))closure #1 in Sequence<>.contains(_:)specialized partial apply, (uint64_t)&v158, (uint64_t)v32);
  swift_release();
  if ((v44 & 1) == 0)
  {
    uint64_t v33 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v33, 0, 0);
    *(void *)uint64_t v34 = 0xD000000000000014;
    uint64_t v38 = "Invalid recordingFileColumn.";
    goto LABEL_50;
  }
  uint64_t v167 = countAndFlagsBits;
  v187._uint64_t countAndFlagsBits = (uint64_t)v181;
  LOBYTE(v187._object) = v189;
  v45._uint64_t countAndFlagsBits = v172;
  v45._unsigned __int8 object = (void *)a8;
  MLDataTable.subscript.getter(v45);
  uint64_t v46 = v185;
  char v47 = object;
  uint64_t v161 = v185;
  unsigned __int8 v162 = object;
  MLUntypedColumn.dropDuplicates()(v45._countAndFlagsBits, a8);
  outlined consume of Result<_DataTable, Error>((uint64_t)v46, v47);
  uint64_t v185 = (void *)v187._countAndFlagsBits;
  unsigned __int8 object = v187._object;
  uint64_t v48 = Array<A>.init(_:)((uint64_t)&v185, *(double *)a7.i64);
  uint64_t v49 = v48[2];
  swift_bridgeObjectRetain((_BYTE)v48);
  v169 = v48;
  uint64_t v174 = specialized Dictionary.init<A>(uniqueKeysWithValues:)((uint64_t)v48, 0, v49);
  v179 = specialized Array.init(repeating:count:)((uint64_t)_swiftEmptyArrayStorage, v49);
  uint64_t v182 = specialized Array.init(repeating:count:)((uint64_t)_swiftEmptyArrayStorage, v49);
  uint64_t v185 = v181;
  unsigned __int8 object = v189;
  v45._uint64_t countAndFlagsBits = v172;
  v45._unsigned __int8 object = (void *)a8;
  MLDataTable.subscript.getter(v45);
  uint64_t v185 = (void *)v187._countAndFlagsBits;
  unsigned __int8 object = v187._object;
  uint64_t v50 = Array<A>.init(_:)((uint64_t)&v185, *(double *)a7.i64);
  int64_t v163 = (char *)v50[2];
  if (v163)
  {
    v168 = v50;
    uint64_t v51 = v50 + 6;
    char v52 = 0;
    do
    {
      v184 = v52;
      BOOL v53 = (void *)*((void *)v51 - 2);
      uint64_t v54 = (void *)*((void *)v51 - 1);
      uint64_t v55 = v174;
      v183._uint64_t countAndFlagsBits = v174[2];
      v175 = v51;
      int v56 = *v51;
      outlined copy of MLDataValue(v53, v54, *v51);
      if (!v183._countAndFlagsBits) {
        goto LABEL_100;
      }
      outlined copy of MLDataValue(v53, v54, v56);
      v183._uint64_t countAndFlagsBits = (uint64_t)v53;
      *(void *)&long long v57 = v53;
      *((void *)&v57 + 1) = v54;
      uint64_t v58 = v55;
      unint64_t v59 = specialized __RawDictionaryStorage.find<A>(_:)(v57, v56);
      uint64_t v61 = v179;
      uint64_t v62 = v54;
      if ((v60 & 1) == 0)
      {
        outlined consume of MLDataValue((void *)v183._countAndFlagsBits, v54, v56);
LABEL_100:
        swift_bridgeObjectRelease((_BYTE)v169);
        BUG();
      }
      uint64_t v63 = *(void *)(v58[7] + 8 * v59);
      v170 = v62;
      outlined consume of MLDataValue((void *)v183._countAndFlagsBits, v62, v56);
      if (!swift_isUniquelyReferenced_nonNull_native(v61)) {
        uint64_t v61 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v61);
      }
      if (v63 < 0) {
        BUG();
      }
      if ((unint64_t)v63 >= v61[2]) {
        BUG();
      }
      LODWORD(v171) = v56;
      uint64_t v64 = v61;
      uint64_t v65 = (char *)v61[v63 + 4];
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v65);
      v64[v63 + 4] = v65;
      v179 = v64;
      if (!isUniquelyReferenced_nonNull_native)
      {
        uint64_t v65 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v65 + 2) + 1, 1, (uint64_t)v65);
        v64[v63 + 4] = v65;
      }
      unint64_t v69 = *((void *)v65 + 2);
      if (*((void *)v65 + 3) >> 1 <= v69)
      {
        uint64_t v65 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v65 + 3) >= 2uLL, v69 + 1, 1, (uint64_t)v65);
        v179[v63 + 4] = v65;
      }
      *((void *)v65 + 2) = v69 + 1;
      uint64_t v70 = v184;
      *(void *)&v65[8 * v69 + 32] = v184;
      uint64_t v71 = (uint64_t)v70;
      specialized MLDataTable.subscript.getter(v173, (uint64_t)v181, v189, v67, v68);
      Swift::String v72 = v185;
      char v73 = object;
      if (object)
      {
        uint64_t v180 = 0;
        unint64_t v178 = 0xE000000000000000;
        uint64_t v74 = v182;
      }
      else
      {
        outlined copy of Result<_DataTable, Error>((uint64_t)v185, 0);
        _UntypedColumn.valueAtIndex(index:)(v71, *(double *)a7.i64);
        outlined consume of Result<_DataTable, Error>((uint64_t)v72, 0);
        uint64_t v74 = v182;
        if (v188 == 2)
        {
          unint64_t v178 = (unint64_t)v187._object;
          uint64_t v180 = (void *)v187._countAndFlagsBits;
          char v73 = 0;
        }
        else
        {
          outlined consume of MLDataValue((void *)v187._countAndFlagsBits, v187._object, v188);
          uint64_t v180 = 0;
          unint64_t v178 = 0xE000000000000000;
        }
      }
      outlined consume of Result<_DataTable, Error>((uint64_t)v72, v73);
      if (!swift_isUniquelyReferenced_nonNull_native(v74)) {
        uint64_t v74 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v74);
      }
      if ((unint64_t)v63 >= v74[2]) {
        BUG();
      }
      uint64_t v75 = (void *)v74[v63 + 4];
      char v76 = swift_isUniquelyReferenced_nonNull_native(v75);
      v74[v63 + 4] = v75;
      uint64_t v182 = v74;
      if (!v76)
      {
        uint64_t v75 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v75[2] + 1, 1, (uint64_t)v75);
        v74[v63 + 4] = v75;
      }
      unint64_t v77 = v75[2];
      if (v75[3] >> 1 <= v77)
      {
        uint64_t v75 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v75[3] >= 2uLL, v77 + 1, 1, (uint64_t)v75);
        v182[v63 + 4] = v75;
      }
      uint64_t v78 = v184 + 1;
      v75[2] = v77 + 1;
      uint64_t v79 = 2 * v77;
      v75[v79 + 4] = v180;
      v75[v79 + 5] = v178;
      char v52 = v78;
      outlined consume of MLDataValue((void *)v183._countAndFlagsBits, v170, v171);
      uint64_t v51 = v175 + 24;
    }
    while (v163 != v52);
    swift_bridgeObjectRelease((_BYTE)v174);
    LOBYTE(v50) = (_BYTE)v168;
  }
  else
  {
    swift_bridgeObjectRelease((_BYTE)v174);
  }
  swift_bridgeObjectRelease((_BYTE)v50);
  uint64_t v80 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MLUntypedColumn)>);
  uint64_t inited = swift_initStackObject(v80, v159);
  *(void *)(inited + 16) = 3;
  *(void *)(inited + 24) = 6;
  *(void *)(inited + 32) = 0x73656369646E69;
  *(void *)(inited + 40) = 0xE700000000000000;
  v187._uint64_t countAndFlagsBits = (uint64_t)v179;
  v82 = alloca(24);
  uint64_t v83 = alloca(32);
  v160 = &v187;
  swift_bridgeObjectRetain((_BYTE)v179);
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
  char v86 = v85;
  swift_bridgeObjectRelease(v187._countAndFlagsBits);
  v183._uint64_t countAndFlagsBits = (uint64_t)&v158;
  *(void *)(inited + 48) = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(inited + 56) = v86 & 1;
  *(void *)(inited + 64) = 0x6C6562616CLL;
  *(void *)(inited + 72) = 0xE500000000000000;
  v187._uint64_t countAndFlagsBits = (uint64_t)v182;
  char v87 = alloca(24);
  uint64_t v88 = alloca(32);
  v160 = &v187;
  swift_bridgeObjectRetain((_BYTE)v182);
  uint64_t v89 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))_s8CreateML15MLUntypedColumnVyACxcSTRzAA22MLDataValueConvertible7ElementRpzlufcAA08_UntypedD0CyKXEfU_SaySaySSGG_TG5TA_0);
  char v91 = v90;
  swift_bridgeObjectRelease(v187._countAndFlagsBits);
  *(void *)(inited + 80) = v89;
  *(unsigned char *)(inited + 88) = v91 & 1;
  strcpy((char *)(inited + 96), "recordingFile");
  *(_WORD *)(inited + 110) = -4864;
  v187._uint64_t countAndFlagsBits = (uint64_t)v169;
  uint64_t v92 = alloca(24);
  uint64_t v93 = alloca(32);
  v160 = &v187;
  uint64_t v94 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
  char v96 = v95;
  swift_bridgeObjectRelease(v187._countAndFlagsBits);
  *(void *)(inited + 112) = v94;
  *(unsigned char *)(inited + 120) = v96 & 1;
  uint64_t v97 = Dictionary.init(dictionaryLiteral:)(inited, &type metadata for String, &type metadata for MLUntypedColumn, &protocol witness table for String);
  uint64_t v98 = v167;
  specialized MLDataTable.init<A>(uniqueKeysWithValues:)(v97);
  if (v98)
  {
    swift_bridgeObjectRelease((_BYTE)v179);
    swift_bridgeObjectRelease((_BYTE)v182);
    return outlined consume of Result<_DataTable, Error>((uint64_t)v176, v177);
  }
  v183._uint64_t countAndFlagsBits = 0;
  uint64_t v99 = v165;
  if (v165 < 0)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, "Negative value is not representable", 35, 2, "Swift/Integers.swift", 20, 2, 3451, 1);
    BUG();
  }
  char v100 = (void *)v187._countAndFlagsBits;
  unsigned __int8 v101 = v187._object;
  uint64_t v102 = type metadata accessor for MersenneTwisterGenerator();
  swift_allocObject(v102, 136, 7);
  uint64_t v185 = MersenneTwisterGenerator.init(seed:)(v99);
  uint64_t v103 = v183._countAndFlagsBits;
  specialized stratifiedSplitGenerator<A>(proportions:generator:dataTable:on:)(v164, (uint64_t)&v185, v100, v101, 0x6C6562616CLL, (void *)0xE500000000000000, *(double *)a7.i64);
  if (v103)
  {
    swift_bridgeObjectRelease((_BYTE)v179);
    swift_bridgeObjectRelease((_BYTE)v182);
    swift_release();
    outlined consume of Result<_DataTable, Error>((uint64_t)v100, v101);
    return outlined consume of Result<_DataTable, Error>((uint64_t)v176, v177);
  }
  LODWORD(v174) = v101;
  v173._unsigned __int8 object = v100;
  v183._uint64_t countAndFlagsBits = 0;
  swift_release();
  uint64_t v180 = (void *)v187._countAndFlagsBits;
  unsigned __int8 v189 = v187._object;
  uint64_t v185 = v176;
  unsigned __int8 object = v177;
  v104._uint64_t countAndFlagsBits = v172;
  v104._unsigned __int8 object = (void *)a8;
  MLDataTable.subscript.getter(v104);
  uint64_t v105 = v187._countAndFlagsBits;
  char v106 = (char)v187._object;
  if (LOBYTE(v187._object))
  {
    uint64_t v107 = -1;
  }
  else
  {
    swift_retain();
    uint64_t v107 = CMLColumn.size.getter();
    outlined consume of Result<_DataTable, Error>(v105, 0);
  }
  outlined consume of Result<_DataTable, Error>(v105, v106);
  v184 = (char *)specialized Array.init(repeating:count:)(0, v107);
  v108 = v180;
  uint64_t v185 = v180;
  unsigned __int8 object = v189;
  int v109 = v189;
  outlined copy of Result<_DataTable, Error>((uint64_t)v180, v189);
  v110._uint64_t countAndFlagsBits = 0x73656369646E69;
  v110._unsigned __int8 object = (void *)0xE700000000000000;
  MLDataTable.subscript.getter(v110);
  LODWORD(v178) = v109;
  outlined consume of Result<_DataTable, Error>((uint64_t)v108, v109);
  uint64_t v111 = v187._countAndFlagsBits;
  if (LOBYTE(v187._object) == 1)
  {
    outlined consume of Result<_DataTable, Error>(v187._countAndFlagsBits, 1);
LABEL_108:
    BUG();
  }
  swift_retain();
  uint64_t v112 = CMLColumn.size.getter();
  outlined consume of Result<_DataTable, Error>(v111, 0);
  outlined consume of Result<_DataTable, Error>(v111, 0);
  if (v112 < 0) {
    goto LABEL_108;
  }
  uint64_t v113 = v112;
  char v114 = (char)v182;
  uint64_t v115 = v184;
  if (v112)
  {
    uint64_t v116 = 0;
    v173._uint64_t countAndFlagsBits = v112;
    while (1)
    {
      if (v116 == (void *)v113) {
        BUG();
      }
      v181 = v116;
      uint64_t v117 = v183._countAndFlagsBits;
      if (v189) {
        break;
      }
      v184 = v115;
      uint64_t v118 = v108[2];
      outlined copy of Result<_DataTable, Error>((uint64_t)v108, 0);
      swift_retain();
      uint64_t v119 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.column(name:), v118, 0x73656369646E69, 0xE700000000000000);
      v183._uint64_t countAndFlagsBits = v117;
      if (v117)
      {
        swift_errorRelease(v183._countAndFlagsBits);
        swift_release();
        goto LABEL_104;
      }
      uint64_t v120 = v119;
      swift_release();
      outlined consume of Result<_DataTable, Error>((uint64_t)v108, 0);
      uint64_t v121 = type metadata accessor for _UntypedColumn();
      uint64_t v122 = swift_allocObject(v121, 24, 7);
      *(void *)(v122 + 16) = v120;
      swift_retain();
      _UntypedColumn.valueAtIndex(index:)((uint64_t)v181, *(double *)a7.i64);
      outlined consume of Result<_DataTable, Error>(v122, 0);
      outlined consume of Result<_DataTable, Error>(v122, 0);
      if (v188 != 3) {
        goto LABEL_105;
      }
      v175 = (char *)v187._object;
      uint64_t v123 = (void *)v187._countAndFlagsBits;
      swift_retain();
      if (CMLSequence.size.getter())
      {
        uint64_t v124 = 0;
        while (1)
        {
          swift_retain();
          uint64_t v125 = v183._countAndFlagsBits;
          uint64_t v126 = CMLSequence.value(at:)(v124);
          v183._uint64_t countAndFlagsBits = v125;
          if (v125)
          {
            outlined consume of MLDataValue(v123, v175, 3);
            swift_unexpectedError(v183._countAndFlagsBits, "CreateML/SequenceType.swift", 27, 1, 36);
            BUG();
          }
          uint64_t v127 = v126;
          uint64_t v128 = v123;
          outlined consume of MLDataValue(v123, v175, 3);
          MLDataValue.init(_:)(v127, *(double *)a7.i64);
          uint64_t v171 = v187._countAndFlagsBits;
          char v129 = v188;
          swift_retain();
          v170 = (void *)CMLSequence.size.getter();
          v130 = v128;
          outlined consume of MLDataValue(v128, v175, 3);
          if (v124 >= (uint64_t)v170) {
            BUG();
          }
          if (v129) {
            BUG();
          }
          uint64_t v131 = v180;
          outlined copy of Result<_DataTable, Error>((uint64_t)v180, 0);
          v132._uint64_t countAndFlagsBits = 0x6F69746974726170;
          v132._unsigned __int8 object = (void *)0xE90000000000006ELL;
          specialized MLDataTable.subscript.getter(v132, (uint64_t)v131, v178);
          outlined consume of Result<_DataTable, Error>((uint64_t)v131, 0);
          uint64_t v133 = v185;
          uint64_t v123 = v130;
          if (object) {
            break;
          }
          outlined copy of Result<_DataTable, Error>((uint64_t)v185, 0);
          _UntypedColumn.valueAtIndex(index:)((uint64_t)v181, *(double *)a7.i64);
          outlined consume of Result<_DataTable, Error>((uint64_t)v133, 0);
          uint64_t v136 = v187._countAndFlagsBits;
          if (v188)
          {
            outlined consume of MLDataValue((void *)v187._countAndFlagsBits, v187._object, v188);
            v134 = v133;
            char v135 = 0;
            goto LABEL_79;
          }
          outlined consume of Result<_DataTable, Error>((uint64_t)v133, 0);
          uint64_t v137 = v184;
          if (!swift_isUniquelyReferenced_nonNull_native(v184)) {
LABEL_86:
          }
            uint64_t v137 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v137);
LABEL_81:
          if (v171 < 0) {
            BUG();
          }
          if ((unint64_t)v171 >= *((void *)v137 + 2)) {
            BUG();
          }
          ++v124;
          v184 = v137;
          *(void *)&v137[8 * v171 + 32] = v136;
          if (v124 == CMLSequence.size.getter()) {
            goto LABEL_87;
          }
        }
        v134 = v185;
        char v135 = 1;
LABEL_79:
        outlined consume of Result<_DataTable, Error>((uint64_t)v134, v135);
        uint64_t v137 = v184;
        uint64_t v136 = 0;
        if (!swift_isUniquelyReferenced_nonNull_native(v184)) {
          goto LABEL_86;
        }
        uint64_t v136 = 0;
        goto LABEL_81;
      }
LABEL_87:
      uint64_t v138 = (void *)((char *)v181 + 1);
      uint64_t v139 = v175;
      outlined consume of MLDataValue(v123, v175, 3);
      outlined consume of MLDataValue(v123, v139, 3);
      uint64_t v116 = v138;
      uint64_t v113 = v173._countAndFlagsBits;
      BOOL v140 = v138 == (void *)v173._countAndFlagsBits;
      char v114 = (char)v182;
      uint64_t v115 = v184;
      v108 = v180;
      if (v140) {
        goto LABEL_88;
      }
    }
    outlined copy of Result<_DataTable, Error>((uint64_t)v108, 1);
    swift_willThrow(v108, 1, v150, v151, v152, v153);
LABEL_104:
    v187._uint64_t countAndFlagsBits = 0;
    v187._unsigned __int8 object = (void *)0xE000000000000000;
    _StringGuts.grow(_:)(34);
    swift_bridgeObjectRelease(v187._object);
    v187._uint64_t countAndFlagsBits = 0xD00000000000001FLL;
    v187._unsigned __int8 object = "ml.activityclassifier" + 0x8000000000000000;
    v154._uint64_t countAndFlagsBits = 0x73656369646E69;
    v154._unsigned __int8 object = (void *)0xE700000000000000;
    String.append(_:)(v154);
    v154._unsigned __int8 object = (void *)0xE100000000000000;
    v154._uint64_t countAndFlagsBits = 34;
    String.append(_:)(v154);
    Swift::String v183 = v187;
    uint64_t v155 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v156 = swift_allocError(&type metadata for MLCreateError, v155, 0, 0);
    *(Swift::String *)uint64_t v157 = v183;
    *(_OWORD *)(v157 + 16) = 0;
    *(_OWORD *)(v157 + 32) = 0;
    *(unsigned char *)(v157 + 48) = 1;
    outlined consume of Result<_DataTable, Error>((uint64_t)v180, v178);
    outlined consume of Result<_DataTable, Error>(v156, 1);
LABEL_105:
    BUG();
  }
LABEL_88:
  swift_bridgeObjectRelease((_BYTE)v179);
  swift_bridgeObjectRelease(v114);
  v187._uint64_t countAndFlagsBits = (uint64_t)v115;
  uint64_t v141 = alloca(24);
  v142 = alloca(24);
  v160 = &v187;
  uint64_t v143 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
  char v145 = v144;
  swift_bridgeObjectRelease(v187._countAndFlagsBits);
  MLDataTable.willMutate()();
  v187._uint64_t countAndFlagsBits = v143;
  char v146 = v145;
  char v147 = v145 & 1;
  LOBYTE(v187._object) = v147;
  outlined copy of Result<_DataTable, Error>(v143, v146);
  MLDataTable.addImpl(newColumn:named:)((uint64_t)&v187, 0x6F69746974726170, (void *)0xE90000000000006ELL);
  outlined consume of Result<_DataTable, Error>(v143, v146);
  v148 = v176;
  char v149 = v177;
  if (!(_BYTE)v177)
  {
    outlined copy of Result<_DataTable, Error>((uint64_t)v176, 0);
    LOBYTE(v184) = 0;
    _DataTable.columnNamesDidChange()();
    char v149 = (char)v184;
    outlined consume of Result<_DataTable, Error>((uint64_t)v148, 0);
  }
  outlined consume of Result<_DataTable, Error>((uint64_t)v173._object, (char)v174);
  outlined consume of Result<_DataTable, Error>((uint64_t)v180, v178);
  outlined consume of Result<_DataTable, Error>(v143, v147);
  uint64_t result = (uint64_t)v166;
  void *v166 = v148;
  *(unsigned char *)(result + 8) = v149;
  return result;
}

uint64_t specialized _UntypedColumn.init<A>(_:)(uint64_t a1)
{
  uint64_t v54 = v1;
  uint64_t v3 = tc_v1_flex_list_create(0);
  if (!v3) {
    BUG();
  }
  uint64_t v4 = v3;
  uint64_t v5 = type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject(v5, v44);
  *(void *)(inited + 16) = v4;
  uint64_t v51 = inited;
  *(unsigned char *)(inited + 24) = 1;
  uint64_t v8 = *(void *)(a1 + 16);
  uint64_t v48 = v2;
  uint64_t v49 = a1;
  if (v8)
  {
    uint64_t v9 = (unsigned __int8 *)(a1 + 48);
    LOBYTE(v7) = 6;
    uint64_t v53 = v7;
    uint64_t v10 = v54;
    while (1)
    {
      uint64_t v45 = v8;
      int64_t v11 = (void *)*((void *)v9 - 2);
      char v12 = (void *)*((void *)v9 - 1);
      uint64_t v13 = *v9;
      uint64_t v50 = v12;
      uint64_t v47 = v13;
      switch(v13)
      {
        case 0:
        case 1:
          goto LABEL_10;
        case 2:
          goto LABEL_9;
        case 3:
          swift_retain(v11);
          goto LABEL_10;
        case 4:
          char v12 = v11;
LABEL_9:
          swift_bridgeObjectRetain(v12);
          goto LABEL_10;
        case 5:
          v11;
LABEL_10:
          if ((_BYTE)v53 == 6)
          {
            switch((int)v13)
            {
              case 0:
                goto LABEL_14;
              case 1:
                goto LABEL_24;
              case 2:
                goto LABEL_20;
            }
          }
          break;
        case 6:
          uint64_t v54 = v10;
          type metadata accessor for CMLFeatureValue();
          uint64_t v14 = CMLFeatureValue.__allocating_init()(0);
          goto LABEL_17;
      }
      switch((int)v13)
      {
        case 0:
          if ((_BYTE)v53) {
            goto LABEL_39;
          }
LABEL_14:
          uint64_t v15 = v10;
          uint64_t v16 = specialized handling<A, B>(_:_:)((uint64_t)v11);
          if (v10)
          {
            uint64_t v42 = 100;
LABEL_50:
            uint64_t v43 = v15;
LABEL_51:
            swift_unexpectedError(v43, "CreateML/MLDataValueConvertible.swift", 37, 1, v42);
            BUG();
          }
          uint64_t v17 = v16;
          uint64_t v54 = 0;
          if (!v16) {
            BUG();
          }
          uint64_t v53 = 0;
          uint64_t v18 = type metadata accessor for CMLFeatureValue();
          swift_allocObject(v18, 25, 7);
          uint64_t v14 = CMLFeatureValue.init(rawValue:ownsValue:)(v17, 1);
LABEL_17:
          uint64_t v19 = v14;
          goto LABEL_30;
        case 1:
          if ((_BYTE)v53 != 1) {
            goto LABEL_39;
          }
LABEL_24:
          uint64_t v15 = v10;
          uint64_t v23 = specialized handling<A, B>(_:_:)();
          if (v10)
          {
            uint64_t v42 = 153;
            goto LABEL_50;
          }
          uint64_t v24 = v23;
          uint64_t v54 = 0;
          if (!v23) {
            BUG();
          }
          uint64_t v25 = type metadata accessor for CMLFeatureValue();
          swift_allocObject(v25, 25, 7);
          uint64_t v26 = CMLFeatureValue.init(rawValue:ownsValue:)(v24, 1);
          uint64_t v19 = v26;
          LOBYTE(v26) = 1;
          goto LABEL_29;
        case 2:
          if ((_BYTE)v53 != 2) {
            goto LABEL_39;
          }
LABEL_20:
          type metadata accessor for CMLFeatureValue();
          uint64_t v54 = v10;
          uint64_t v20 = (uint64_t)v11;
          uint64_t v21 = (uint64_t)v50;
          swift_bridgeObjectRetain_n(v50, 2);
          uint64_t v46 = v20;
          uint64_t v22 = v54;
          CMLFeatureValue.__allocating_init(_:)(v20, v21);
          uint64_t v54 = v22;
          if (!v22) {
            JUMPOUT(0xE3890);
          }
          uint64_t v42 = 170;
          uint64_t v43 = v54;
          goto LABEL_51;
        case 3:
          JUMPOUT(0xE38B0);
        case 4:
          JUMPOUT(0xE381FLL);
        case 5:
          if ((_BYTE)v53 != 5)
          {
LABEL_39:
            uint64_t v37 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            swift_allocError(&type metadata for MLCreateError, v37, 0, 0);
            *(void *)uint64_t v38 = 0xD000000000000027;
            *(void *)(v38 + 8) = "Invalid labelColumn." + 0x8000000000000000;
            *(_OWORD *)(v38 + 16) = 0;
            *(_OWORD *)(v38 + 32) = 0;
            *(unsigned char *)(v38 + 48) = 1;
            swift_willThrow();
            swift_setDeallocating(v51);
            uint64_t v39 = CMLFeatureValue.deinit();
            swift_deallocClassInstance(v39, 25, 7);
            outlined consume of MLDataValue(v11, v50, v13);
            swift_bridgeObjectRelease(v49);
LABEL_40:
            uint64_t v30 = v48;
LABEL_41:
            uint64_t v40 = type metadata accessor for _UntypedColumn();
            swift_deallocPartialClassInstance(v30, v40, 24, 7);
            return v30;
          }
          uint64_t v54 = v10;
          char v52 = v11;
          uint64_t v26 = MLDataValue.MultiArrayType.featureValue.getter();
          uint64_t v19 = v26;
          LOBYTE(v26) = 5;
LABEL_29:
          uint64_t v53 = v26;
LABEL_30:
          uint64_t v27 = v54;
          CMLSequence.append(_:)(v19);
          uint64_t v10 = v27;
          if (v27)
          {
            swift_bridgeObjectRelease(v49);
            swift_setDeallocating(v51);
            uint64_t v32 = CMLFeatureValue.deinit();
            swift_deallocClassInstance(v32, 25, 7);
            outlined consume of MLDataValue(v11, v50, v47);
            swift_release(v19);
            goto LABEL_40;
          }
          swift_release(v19);
          outlined consume of MLDataValue(v11, v50, v47);
          v9 += 24;
          uint64_t v8 = v45 - 1;
          if (v45 == 1) {
            goto LABEL_34;
          }
          break;
      }
    }
  }
  uint64_t v10 = v54;
LABEL_34:
  swift_bridgeObjectRelease(v49);
  uint64_t v28 = v51;
  uint64_t v29 = specialized handling<A, B>(_:_:)(*(void *)(v51 + 16));
  uint64_t v30 = v48;
  if (v10)
  {
    swift_setDeallocating(v28);
    uint64_t v31 = CMLFeatureValue.deinit();
    swift_deallocClassInstance(v31, 25, 7);
    goto LABEL_41;
  }
  uint64_t v33 = v29;
  uint64_t v54 = 0;
  if (!v29) {
    BUG();
  }
  swift_setDeallocating(v28);
  uint64_t v34 = CMLFeatureValue.deinit();
  swift_deallocClassInstance(v34, 25, 7);
  uint64_t v35 = type metadata accessor for CMLColumn();
  uint64_t v36 = swift_allocObject(v35, 24, 7);
  *(void *)(v36 + 16) = v33;
  *(void *)(v30 + 16) = v36;
  return v30;
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t inited;
  uint64_t i;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  unsigned char v17[32];
  unsigned char v18[32];
  void v19[5];
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;

  uint64_t v3 = tc_v1_flex_list_create(0);
  if (!v3) {
    BUG();
  }
  uint64_t v4 = v3;
  uint64_t v23 = v2;
  uint64_t v5 = type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject(v5, v17);
  *(void *)(inited + 16) = v4;
  uint64_t v22 = inited;
  *(unsigned char *)(inited + 24) = 1;
  uint64_t v21 = a1;
  uint64_t v20 = *(void *)(a1 + 16);
  if (v20)
  {
    for (i = 0; i != v20; ++i)
    {
      uint64_t v8 = *(void *)(v21 + 8 * i + 32);
      v19[3] = &type metadata for Double;
      v19[4] = &protocol witness table for Double;
      v19[0] = v8;
      __swift_project_boxed_opaque_existential_0Tm(v19, (uint64_t)&type metadata for Double);
      uint64_t v9 = specialized handling<A, B>(_:_:)();
      if (v1)
      {
        swift_unexpectedError(v1, "CreateML/MLDataValueConvertible.swift", 37, 1, 153);
        BUG();
      }
      uint64_t v10 = v9;
      if (!v9) {
        BUG();
      }
      int64_t v11 = type metadata accessor for CMLFeatureValue();
      swift_initStackObject(v11, v18);
      char v12 = CMLFeatureValue.init(rawValue:ownsValue:)(v10, 1);
      __swift_destroy_boxed_opaque_existential_1Tm(v19);
      CMLSequence.append(_:)(v12);
      swift_release();
    }
  }
  swift_bridgeObjectRelease(v21);
  type metadata accessor for CMLColumn();
  uint64_t v13 = CMLColumn.__allocating_init(_:type:)(v22, 1);
  uint64_t v14 = v23;
  if (v1)
  {
    uint64_t v15 = type metadata accessor for _UntypedColumn();
    swift_deallocPartialClassInstance(v14, v15, 24, 7);
  }
  else
  {
    *(void *)(v23 + 16) = v13;
  }
  return v14;
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t inited;
  uint64_t i;
  uint64_t v8;
  uint64_t *v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  unsigned char v18[32];
  unsigned char v19[32];
  void v20[5];
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;

  uint64_t v3 = tc_v1_flex_list_create(0);
  if (!v3) {
    BUG();
  }
  uint64_t v4 = v3;
  uint64_t v24 = v2;
  uint64_t v5 = type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject(v5, v18);
  *(void *)(inited + 16) = v4;
  uint64_t v23 = inited;
  *(unsigned char *)(inited + 24) = 1;
  uint64_t v22 = a1;
  uint64_t v21 = *(void *)(a1 + 16);
  if (v21)
  {
    for (i = 0; i != v21; ++i)
    {
      uint64_t v8 = *(void *)(v22 + 8 * i + 32);
      v20[3] = &type metadata for Int;
      v20[4] = &protocol witness table for Int;
      v20[0] = v8;
      uint64_t v9 = __swift_project_boxed_opaque_existential_0Tm(v20, (uint64_t)&type metadata for Int);
      uint64_t v10 = specialized handling<A, B>(_:_:)(*v9);
      if (v1)
      {
        swift_unexpectedError(v1, "CreateML/MLDataValueConvertible.swift", 37, 1, 100);
        BUG();
      }
      int64_t v11 = v10;
      if (!v10) {
        BUG();
      }
      char v12 = type metadata accessor for CMLFeatureValue();
      swift_initStackObject(v12, v19);
      uint64_t v13 = CMLFeatureValue.init(rawValue:ownsValue:)(v11, 1);
      __swift_destroy_boxed_opaque_existential_1Tm(v20);
      CMLSequence.append(_:)(v13);
      swift_release();
    }
  }
  swift_bridgeObjectRelease(v22);
  type metadata accessor for CMLColumn();
  uint64_t v14 = CMLColumn.__allocating_init(_:type:)(v23, 0);
  uint64_t v15 = v24;
  if (v1)
  {
    uint64_t v16 = type metadata accessor for _UntypedColumn();
    swift_deallocPartialClassInstance(v15, v16, 24, 7);
  }
  else
  {
    *(void *)(v24 + 16) = v14;
  }
  return v15;
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t inited;
  uint64_t v8;
  void *v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t *v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  unsigned char v22[32];
  void v23[5];
  uint64_t v24;
  uint64_t v25;
  void *v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;

  uint64_t v3 = v1;
  uint64_t v4 = tc_v1_flex_list_create(0);
  if (!v4) {
    BUG();
  }
  uint64_t v5 = v4;
  uint64_t v31 = v2;
  uint64_t v6 = type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject(v6, v22);
  *(void *)(inited + 16) = v5;
  uint64_t v30 = inited;
  *(unsigned char *)(inited + 24) = 1;
  uint64_t v8 = *(void *)(a1 + 16);
  uint64_t v29 = a1;
  if (v8)
  {
    uint64_t v27 = type metadata accessor for CMLFeatureValue();
    uint64_t v9 = (void *)(a1 + 40);
    do
    {
      uint64_t v24 = v3;
      uint64_t v25 = v8;
      uint64_t v10 = *(v9 - 1);
      uint64_t v26 = v9;
      int64_t v11 = *v9;
      v23[3] = &type metadata for String;
      v23[4] = &protocol witness table for String;
      v23[0] = v10;
      v23[1] = v11;
      char v12 = __swift_project_boxed_opaque_existential_0Tm(v23, (uint64_t)&type metadata for String);
      uint64_t v13 = *v12;
      uint64_t v14 = v12[1];
      uint64_t v28 = v11;
      swift_bridgeObjectRetain_n(v11, 2);
      swift_bridgeObjectRetain(v14);
      uint64_t v15 = v24;
      uint64_t v16 = CMLFeatureValue.__allocating_init(_:)(v13, v14);
      uint64_t v3 = v15;
      if (v15)
      {
        swift_unexpectedError(v15, "CreateML/MLDataValueConvertible.swift", 37, 1, 170);
        BUG();
      }
      uint64_t v17 = v16;
      __swift_destroy_boxed_opaque_existential_1Tm(v23);
      CMLSequence.append(_:)(v17);
      swift_release();
      swift_bridgeObjectRelease(v28);
      uint64_t v9 = v26 + 2;
      uint64_t v8 = v25 - 1;
    }
    while (v25 != 1);
  }
  swift_bridgeObjectRelease(v29);
  type metadata accessor for CMLColumn();
  uint64_t v18 = CMLColumn.__allocating_init(_:type:)(v30, 2);
  uint64_t v19 = v31;
  if (v3)
  {
    uint64_t v20 = type metadata accessor for _UntypedColumn();
    swift_deallocPartialClassInstance(v19, v20, 24, 7);
  }
  else
  {
    *(void *)(v31 + 16) = v18;
  }
  return v19;
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t inited;
  unint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v25;
  uint64_t v26;
  const char *v27;
  uint64_t v28;
  uint64_t v29;
  unsigned char v30[32];
  unsigned char v31[32];
  unsigned char v32[32];
  void v33[5];
  void v34[5];
  uint64_t v35;
  unint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;

  char v44 = v2;
  uint64_t v3 = a1;
  uint64_t v4 = tc_v1_flex_list_create(0);
  if (!v4) {
    BUG();
  }
  uint64_t v5 = v4;
  uint64_t v37 = type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject(v37, v30);
  *(void *)(inited + 16) = v5;
  uint64_t v45 = inited;
  *(unsigned char *)(inited + 24) = 1;
  uint64_t v38 = *(void *)(a1 + 16);
  if (v38)
  {
    uint64_t v7 = 0;
    uint64_t v42 = type metadata accessor for CMLFeatureValue();
    uint64_t v39 = a1;
    while (1)
    {
      if (v7 >= *(void *)(v3 + 16)) {
        BUG();
      }
      uint64_t v36 = v7;
      uint64_t v8 = *(void *)(v3 + 8 * v7 + 32);
      uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int]);
      v33[3] = v9;
      v33[4] = lazy protocol witness table accessor for type [String : Double] and conformance <> [A : B](&lazy protocol witness table cache variable for type [Int] and conformance <A> [A], &demangling cache variable for type metadata for [Int], (uint64_t)&protocol witness table for Int, (uint64_t)&protocol conformance descriptor for <A> [A]);
      v33[0] = v8;
      uint64_t v10 = *__swift_project_boxed_opaque_existential_0Tm(v33, v9);
      uint64_t v43 = v8;
      swift_bridgeObjectRetain_n(v8, 2);
      int64_t v11 = tc_v1_flex_list_create(0);
      if (!v11) {
        BUG();
      }
      char v12 = v11;
      uint64_t v13 = swift_initStackObject(v37, v31);
      *(void *)(v13 + 16) = v12;
      uint64_t v40 = v13;
      *(unsigned char *)(v13 + 24) = 1;
      uint64_t v35 = *(void *)(v10 + 16);
      if (v35) {
        break;
      }
LABEL_12:
      uint64_t v20 = CMLFeatureValue.__allocating_init(_:)(v40);
      uint64_t v3 = v39;
      if (v1)
      {
        uint64_t v27 = "CreateML/SequenceType.swift";
        uint64_t v28 = 27;
        uint64_t v29 = 151;
        goto LABEL_22;
      }
      uint64_t v21 = v20;
      __swift_destroy_boxed_opaque_existential_1Tm(v33);
      CMLSequence.append(_:)(v21);
      uint64_t v7 = v36 + 1;
      swift_release();
      swift_bridgeObjectRelease(v43);
      if (v7 == v38) {
        goto LABEL_14;
      }
    }
    uint64_t v41 = v10;
    swift_bridgeObjectRetain(v10);
    uint64_t v14 = 0;
    while (1)
    {
      uint64_t v15 = *(void *)(v41 + 8 * v14 + 32);
      v34[3] = &type metadata for Int;
      v34[4] = &protocol witness table for Int;
      v34[0] = v15;
      uint64_t v16 = __swift_project_boxed_opaque_existential_0Tm(v34, (uint64_t)&type metadata for Int);
      uint64_t v17 = specialized handling<A, B>(_:_:)(*v16);
      if (v1) {
        break;
      }
      uint64_t v18 = v17;
      if (!v17) {
        BUG();
      }
      swift_initStackObject(v42, v32);
      uint64_t v19 = CMLFeatureValue.init(rawValue:ownsValue:)(v18, 1);
      __swift_destroy_boxed_opaque_existential_1Tm(v34);
      CMLSequence.append(_:)(v19);
      ++v14;
      swift_release();
      if (v35 == v14)
      {
        swift_bridgeObjectRelease(v41);
        goto LABEL_12;
      }
    }
    uint64_t v27 = "CreateML/MLDataValueConvertible.swift";
    uint64_t v28 = 37;
    uint64_t v29 = 100;
LABEL_22:
    swift_unexpectedError(v1, v27, v28, 1, v29);
    BUG();
  }
LABEL_14:
  swift_bridgeObjectRelease(v3);
  type metadata accessor for CMLColumn();
  uint64_t v22 = CMLColumn.__allocating_init(_:type:)(v45, 3);
  if (v1)
  {
    uint64_t v25 = type metadata accessor for _UntypedColumn();
    uint64_t v26 = v44;
    swift_deallocPartialClassInstance(v44, v25, 24, 7);
    return v26;
  }
  else
  {
    uint64_t v23 = v44;
    *(void *)(v44 + 16) = v22;
    return v23;
  }
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t inited;
  unint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t *v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v31;
  uint64_t v32;
  const char *v33;
  uint64_t v34;
  uint64_t v35;
  unsigned char v36[32];
  unsigned char v37[32];
  void v38[5];
  void v39[5];
  uint64_t v40;
  void *v41;
  uint64_t v42;
  unint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  uint64_t v53;

  uint64_t v3 = v1;
  uint64_t v51 = v2;
  uint64_t v4 = a1;
  uint64_t v5 = tc_v1_flex_list_create(0);
  if (!v5) {
    BUG();
  }
  uint64_t v6 = v5;
  uint64_t v45 = type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject(v45, v36);
  *(void *)(inited + 16) = v6;
  char v52 = inited;
  *(unsigned char *)(inited + 24) = 1;
  uint64_t v46 = *(void *)(a1 + 16);
  if (v46)
  {
    uint64_t v8 = 0;
    uint64_t v48 = type metadata accessor for CMLFeatureValue();
    uint64_t v50 = a1;
    while (1)
    {
      if (v8 >= *(void *)(v4 + 16)) {
        BUG();
      }
      uint64_t v53 = v3;
      uint64_t v9 = *(void *)(v4 + 8 * v8 + 32);
      uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
      v38[3] = v10;
      v38[4] = lazy protocol witness table accessor for type [String : Double] and conformance <> [A : B](&lazy protocol witness table cache variable for type [String] and conformance <A> [A], &demangling cache variable for type metadata for [String], (uint64_t)&protocol witness table for String, (uint64_t)&protocol conformance descriptor for <A> [A]);
      v38[0] = v9;
      int64_t v11 = *__swift_project_boxed_opaque_existential_0Tm(v38, v10);
      uint64_t v49 = v9;
      swift_bridgeObjectRetain_n(v9, 2);
      char v12 = tc_v1_flex_list_create(0);
      if (!v12) {
        BUG();
      }
      uint64_t v13 = v12;
      uint64_t v43 = v8;
      uint64_t v14 = swift_initStackObject(v45, v37);
      *(void *)(v14 + 16) = v13;
      uint64_t v47 = v14;
      *(unsigned char *)(v14 + 24) = 1;
      uint64_t v15 = *(void *)(v11 + 16);
      if (v15) {
        break;
      }
LABEL_11:
      uint64_t v4 = v50;
      uint64_t v25 = v53;
      uint64_t v26 = CMLFeatureValue.__allocating_init(_:)(v47);
      uint64_t v3 = v25;
      if (v25)
      {
        uint64_t v33 = "CreateML/SequenceType.swift";
        uint64_t v34 = 27;
        uint64_t v35 = 151;
        goto LABEL_20;
      }
      uint64_t v27 = v26;
      __swift_destroy_boxed_opaque_existential_1Tm(v38);
      CMLSequence.append(_:)(v27);
      uint64_t v8 = v43 + 1;
      swift_release();
      swift_bridgeObjectRelease(v49);
      if (v8 == v46) {
        goto LABEL_13;
      }
    }
    swift_bridgeObjectRetain(v11);
    char v44 = v11;
    uint64_t v16 = (void *)(v11 + 40);
    while (1)
    {
      uint64_t v40 = v15;
      uint64_t v17 = *(v16 - 1);
      uint64_t v41 = v16;
      uint64_t v18 = *v16;
      v39[3] = &type metadata for String;
      v39[4] = &protocol witness table for String;
      v39[0] = v17;
      v39[1] = v18;
      uint64_t v19 = __swift_project_boxed_opaque_existential_0Tm(v39, (uint64_t)&type metadata for String);
      uint64_t v20 = *v19;
      uint64_t v21 = v19[1];
      uint64_t v42 = v18;
      swift_bridgeObjectRetain_n(v18, 2);
      swift_bridgeObjectRetain(v21);
      uint64_t v22 = v53;
      uint64_t v23 = CMLFeatureValue.__allocating_init(_:)(v20, v21);
      uint64_t v3 = v22;
      if (v22) {
        break;
      }
      uint64_t v24 = v23;
      __swift_destroy_boxed_opaque_existential_1Tm(v39);
      CMLSequence.append(_:)(v24);
      uint64_t v53 = 0;
      swift_release();
      swift_bridgeObjectRelease(v42);
      uint64_t v16 = v41 + 2;
      uint64_t v15 = v40 - 1;
      if (v40 == 1)
      {
        swift_bridgeObjectRelease(v44);
        goto LABEL_11;
      }
    }
    uint64_t v33 = "CreateML/MLDataValueConvertible.swift";
    uint64_t v34 = 37;
    uint64_t v35 = 170;
LABEL_20:
    swift_unexpectedError(v3, v33, v34, 1, v35);
    BUG();
  }
LABEL_13:
  swift_bridgeObjectRelease(v4);
  type metadata accessor for CMLColumn();
  uint64_t v28 = CMLColumn.__allocating_init(_:type:)(v52, 3);
  if (v3)
  {
    uint64_t v31 = type metadata accessor for _UntypedColumn();
    uint64_t v32 = v51;
    swift_deallocPartialClassInstance(v51, v31, 24, 7);
    return v32;
  }
  else
  {
    uint64_t v29 = v51;
    *(void *)(v51 + 16) = v28;
    return v29;
  }
}

void *protocol witness for MLDataValueConvertible.init() in conformance String()
{
  *uint64_t result = 0;
  result[1] = 0xE000000000000000;
  return result;
}

uint64_t specialized closure #1 in MLUntypedColumn.init<A>(_:)(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for _UntypedColumn();
  swift_allocObject(v1, 24, 7);
  swift_bridgeObjectRetain(a1);
  return specialized _UntypedColumn.init<A>(_:)(a1);
}

{
  return specialized closure #1 in MLUntypedColumn.init<A>(_:)(a1, specialized _UntypedColumn.init<A>(_:));
}

{
  return specialized closure #1 in MLUntypedColumn.init<A>(_:)(a1, specialized _UntypedColumn.init<A>(_:));
}

{
  return specialized closure #1 in MLUntypedColumn.init<A>(_:)(a1, specialized _UntypedColumn.init<A>(_:));
}

{
  return specialized closure #1 in MLUntypedColumn.init<A>(_:)(a1, specialized _UntypedColumn.init<A>(_:));
}

{
  return specialized closure #1 in MLUntypedColumn.init<A>(_:)(a1, (uint64_t (*)(uint64_t))specialized _UntypedColumn.init<A>(_:));
}

{
  return specialized closure #1 in MLUntypedColumn.init<A>(_:)(a1, specialized _UntypedColumn.init<A>(_:));
}

{
  return specialized closure #1 in MLUntypedColumn.init<A>(_:)(a1, (uint64_t (*)(uint64_t))specialized _UntypedColumn.init<A>(_:));
}

uint64_t specialized _ArrayBuffer._consumeAndCreateNew()(uint64_t a1)
{
  return specialized _ArrayBuffer._consumeAndCreateNew()(a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  uint64_t v1;
  uint64_t v2;

  uint64_t v1 = a1 & 0xFFFFFFFFFFFFF8;
  if ((a1 & 0x4000000000000001) != 0)
  {
    if (a1) {
      uint64_t v1 = a1;
    }
    swift_bridgeObjectRetain(a1);
    uint64_t v2 = _CocoaArrayWrapper.endIndex.getter(v1);
    swift_bridgeObjectRelease(a1);
  }
  else
  {
    uint64_t v2 = *(void *)((char *)&dword_10 + (a1 & 0xFFFFFFFFFFFFF8));
  }
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0, a1);
}

void *specialized _ArrayBuffer._consumeAndCreateNew()(uint64_t a1)
{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

{
  return specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(a1 + 16), 0, a1);
}

uint64_t specialized closure #1 in MLUntypedColumn.init<A>(_:)(void *a1, void *a2)
{
  return specialized closure #1 in MLUntypedColumn.init<A>(_:)(a1, a2, specialized closure #1 in MLUntypedColumn.init<A>(_:));
}

{
  return specialized closure #1 in MLUntypedColumn.init<A>(_:)(a1, a2, specialized closure #1 in MLUntypedColumn.init<A>(_:));
}

{
  return specialized closure #1 in MLUntypedColumn.init<A>(_:)(a1, a2, specialized closure #1 in MLUntypedColumn.init<A>(_:));
}

uint64_t specialized closure #1 in MLUntypedColumn.init<A>(_:)(void *a1, void *a2, uint64_t (*a3)(void))
{
  uint64_t v5 = v3;
  uint64_t result = a3(*a1);
  if (v4) {
    *a2 = v4;
  }
  else {
    uint64_t *v5 = result;
  }
  return result;
}

uint64_t _s8CreateML15MLUntypedColumnVyACxcSTRzAA22MLDataValueConvertible7ElementRpzlufcAA08_UntypedD0CyKXEfU_SaySaySSGG_TG5TA_0(void *a1)
{
  return specialized closure #1 in MLUntypedColumn.init<A>(_:)(*(void **)(v1 + 16), a1, specialized closure #1 in MLUntypedColumn.init<A>(_:));
}

uint64_t *initializeBufferWithCopyOfBuffer for MLActivityClassifier.DataSource(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) == 0)
  {
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, a3);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v18 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v18 - 8) + 16))(a1, a2, v18);
      uint64_t v23 = 2;
    }
    else
    {
      if (EnumCaseMultiPayload != 1)
      {
        uint64_t v21 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v21 - 8) + 16))(a1, a2, v21);
        uint64_t v20 = a3;
        uint64_t v19 = 0;
        goto LABEL_9;
      }
      uint64_t v7 = type metadata accessor for URL(0);
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v7 - 8) + 16))(a1, a2, v7);
      uint64_t v8 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
      uint64_t v9 = v8[12];
      *(uint64_t *)((char *)a1 + v9) = *(uint64_t *)((char *)a2 + v9);
      uint64_t v10 = *(uint64_t *)((char *)a2 + v9 + 8);
      *(uint64_t *)((char *)v3 + v9 + 8) = v10;
      uint64_t v11 = v8[16];
      *(uint64_t *)((char *)v3 + v11) = *(uint64_t *)((char *)a2 + v11);
      uint64_t v12 = *(uint64_t *)((char *)a2 + v11 + 8);
      *(uint64_t *)((char *)v3 + v11 + 8) = v12;
      uint64_t v13 = v8[20];
      *(uint64_t *)((char *)v3 + v13) = *(uint64_t *)((char *)a2 + v13);
      uint64_t v14 = *(uint64_t *)((char *)a2 + v13 + 8);
      *(uint64_t *)((char *)v3 + v13 + 8) = v14;
      uint64_t v15 = v8[24];
      *(uint64_t *)((char *)v3 + v15) = *(uint64_t *)((char *)a2 + v15);
      uint64_t v16 = *(uint64_t *)((char *)a2 + v15 + 8);
      *(uint64_t *)((char *)v3 + v15 + 8) = v16;
      swift_bridgeObjectRetain(v10);
      swift_bridgeObjectRetain(v12);
      swift_bridgeObjectRetain(v14);
      swift_bridgeObjectRetain(v16);
      uint64_t v23 = 1;
    }
    uint64_t v19 = v23;
    a1 = v3;
    uint64_t v20 = a3;
LABEL_9:
    swift_storeEnumTagMultiPayload(a1, v20, v19);
    return v3;
  }
  uint64_t v17 = *a2;
  *uint64_t v3 = *a2;
  uint64_t v3 = (uint64_t *)(v17 + ((v4 + 16) & ~v4));
  swift_retain();
  return v3;
}

uint64_t destroy for MLActivityClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t result = swift_getEnumCaseMultiPayload(a1, a2);
  if (result == 2)
  {
    uint64_t v3 = type metadata accessor for DataFrame(0);
    return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8))(a1, v3);
  }
  if (result != 1)
  {
    if (result) {
      return result;
    }
    uint64_t v3 = type metadata accessor for URL(0);
    return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8))(a1, v3);
  }
  uint64_t v4 = type metadata accessor for URL(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
  uint64_t v5 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
  swift_bridgeObjectRelease(*(void *)(a1 + v5[12] + 8));
  swift_bridgeObjectRelease(*(void *)(a1 + v5[16] + 8));
  swift_bridgeObjectRelease(*(void *)(a1 + v5[20] + 8));
  return swift_bridgeObjectRelease(*(void *)(a1 + v5[24] + 8));
}

uint64_t initializeWithCopy for MLActivityClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = a3;
  unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, a3);
  if (EnumCaseMultiPayload == 2)
  {
    uint64_t v16 = type metadata accessor for DataFrame(0);
LABEL_6:
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v16 - 8) + 16))(a1, a2, v16);
    goto LABEL_7;
  }
  if (EnumCaseMultiPayload != 1)
  {
    uint64_t v16 = type metadata accessor for URL(0);
    goto LABEL_6;
  }
  uint64_t v6 = type metadata accessor for URL(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
  uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
  uint64_t v8 = v7[12];
  *(void *)(a1 + v8) = *(void *)(a2 + v8);
  uint64_t v9 = *(void *)(a2 + v8 + 8);
  *(void *)(a1 + v8 + 8) = v9;
  uint64_t v10 = v7[16];
  *(void *)(a1 + v10) = *(void *)(a2 + v10);
  uint64_t v11 = *(void *)(a2 + v10 + 8);
  *(void *)(a1 + v10 + 8) = v11;
  uint64_t v12 = v7[20];
  *(void *)(a1 + v12) = *(void *)(a2 + v12);
  uint64_t v18 = v3;
  uint64_t v13 = *(void *)(a2 + v12 + 8);
  *(void *)(a1 + v12 + 8) = v13;
  uint64_t v14 = v7[24];
  *(void *)(a1 + v14) = *(void *)(a2 + v14);
  uint64_t v15 = *(void *)(a2 + v14 + 8);
  *(void *)(a1 + v14 + 8) = v15;
  swift_bridgeObjectRetain(v9);
  swift_bridgeObjectRetain(v11);
  LOBYTE(v9) = v13;
  uint64_t v3 = v18;
  swift_bridgeObjectRetain(v9);
  swift_bridgeObjectRetain(v15);
LABEL_7:
  swift_storeEnumTagMultiPayload(a1, v3, EnumCaseMultiPayload);
  return a1;
}

uint64_t assignWithCopy for MLActivityClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(a1, type metadata accessor for MLActivityClassifier.DataSource);
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, a3);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v15 = type metadata accessor for DataFrame(0);
    }
    else
    {
      if (EnumCaseMultiPayload == 1)
      {
        uint64_t v6 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
        uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
        uint64_t v8 = v7[12];
        *(void *)(a1 + v8) = *(void *)(a2 + v8);
        uint64_t v9 = *(void *)(a2 + v8 + 8);
        *(void *)(a1 + v8 + 8) = v9;
        uint64_t v10 = v7[16];
        *(void *)(a1 + v10) = *(void *)(a2 + v10);
        uint64_t v17 = *(void *)(a2 + v10 + 8);
        *(void *)(a1 + v10 + 8) = v17;
        uint64_t v11 = v7[20];
        *(void *)(a1 + v11) = *(void *)(a2 + v11);
        uint64_t v12 = *(void *)(a2 + v11 + 8);
        *(void *)(a1 + v11 + 8) = v12;
        uint64_t v13 = v7[24];
        *(void *)(a1 + v13) = *(void *)(a2 + v13);
        uint64_t v14 = *(void *)(a2 + v13 + 8);
        *(void *)(a1 + v13 + 8) = v14;
        swift_bridgeObjectRetain(v9);
        swift_bridgeObjectRetain(v17);
        swift_bridgeObjectRetain(v12);
        swift_bridgeObjectRetain(v14);
LABEL_8:
        swift_storeEnumTagMultiPayload(a1, a3, EnumCaseMultiPayload);
        return a1;
      }
      uint64_t v15 = type metadata accessor for URL(0);
    }
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v15 - 8) + 16))(a1, a2, v15);
    goto LABEL_8;
  }
  return a1;
}

uint64_t type metadata accessor for MLActivityClassifier.DataSource(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLActivityClassifier.DataSource;
  if (!type metadata singleton initialization cache for MLActivityClassifier.DataSource) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLActivityClassifier.DataSource);
  }
  return result;
}

uint64_t initializeWithTake for MLActivityClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, a3);
  if (EnumCaseMultiPayload == 2)
  {
    uint64_t v7 = type metadata accessor for DataFrame(0);
LABEL_6:
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v7 - 8) + 32))(a1, a2, v7);
    goto LABEL_7;
  }
  if (EnumCaseMultiPayload != 1)
  {
    uint64_t v7 = type metadata accessor for URL(0);
    goto LABEL_6;
  }
  uint64_t v5 = type metadata accessor for URL(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 32))(a1, a2, v5);
  uint64_t v6 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
  *(_OWORD *)(a1 + v6[12]) = *(_OWORD *)(a2 + v6[12]);
  *(_OWORD *)(a1 + v6[16]) = *(_OWORD *)(a2 + v6[16]);
  *(_OWORD *)(a1 + v6[20]) = *(_OWORD *)(a2 + v6[20]);
  *(_OWORD *)(a1 + v6[24]) = *(_OWORD *)(a2 + v6[24]);
LABEL_7:
  swift_storeEnumTagMultiPayload(a1, a3, EnumCaseMultiPayload);
  return a1;
}

uint64_t assignWithTake for MLActivityClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(a1, type metadata accessor for MLActivityClassifier.DataSource);
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, a3);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v7 = type metadata accessor for DataFrame(0);
    }
    else
    {
      if (EnumCaseMultiPayload == 1)
      {
        uint64_t v5 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 32))(a1, a2, v5);
        uint64_t v6 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
        *(_OWORD *)(a1 + v6[12]) = *(_OWORD *)(a2 + v6[12]);
        *(_OWORD *)(a1 + v6[16]) = *(_OWORD *)(a2 + v6[16]);
        *(_OWORD *)(a1 + v6[20]) = *(_OWORD *)(a2 + v6[20]);
        *(_OWORD *)(a1 + v6[24]) = *(_OWORD *)(a2 + v6[24]);
LABEL_8:
        swift_storeEnumTagMultiPayload(a1, a3, EnumCaseMultiPayload);
        return a1;
      }
      uint64_t v7 = type metadata accessor for URL(0);
    }
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v7 - 8) + 32))(a1, a2, v7);
    goto LABEL_8;
  }
  return a1;
}

uint64_t type metadata completion function for MLActivityClassifier.DataSource(uint64_t a1)
{
  uint64_t result = type metadata accessor for URL(319);
  if (v2 <= 0x3F)
  {
    v7[0] = *(void *)(result - 8) + 64;
    swift_getTupleTypeLayout(v6, 0, 5);
    v7[1] = v6;
    uint64_t result = type metadata accessor for DataFrame(319);
    if (v5 <= 0x3F)
    {
      v7[2] = *(void *)(result - 8) + 64;
      swift_initEnumMetadataMultiPayload(a1, 256, 3, v7, v3, v4);
      return 0;
    }
  }
  return result;
}

uint64_t static MLModel.compile(_:)(uint64_t a1)
{
  *(void *)(v1 + 128) = a1;
  return swift_task_switch(static MLModel.compile(_:), 0, 0);
}

uint64_t static MLModel.compile(_:)()
{
  uint64_t v1 = Model.serialized()();
  v0[17] = v1;
  v0[18] = v2;
  uint64_t v3 = v1;
  unint64_t v4 = v2;
  type metadata accessor for MLModelAsset();
  outlined copy of Data._Representation(v3, v4);
  id v5 = @nonobjc MLModelAsset.__allocating_init(specification:)(v3, v4);
  v0[19] = v5;
  id v6 = v5;
  uint64_t v10 = objc_opt_self(MLModel);
  id v7 = objc_allocWithZone((Class)MLModelConfiguration);
  id v8 = [v7 init];
  v0[20] = v8;
  v0[2] = v0;
  v0[7] = v0 + 15;
  v0[3] = static MLModel.compile(_:);
  v0[14] = swift_continuation_init(v0 + 2, 1);
  v0[10] = _NSConcreteStackBlock;
  v0[11] = 0x40000000;
  v0[12] = @objc completion handler block implementation for @escaping @callee_unowned @convention(block) (@unowned MLModel?, @unowned NSError?) -> () with result type MLModel;
  v0[13] = &block_descriptor_3;
  [v10 loadModelAsset:v6 configuration:v8 completionHandler:v0 + 10];
  return swift_continuation_await(v0 + 2);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t (*v2)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);

  uint64_t v1 = *(void *)(*(void *)v0 + 48);
  *(void *)(*(void *)v0 + 168) = v1;
  if (v1) {
    unint64_t v2 = static MLModel.compile(_:);
  }
  else {
    unint64_t v2 = (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))static MLModel.compile(_:);
  }
  return swift_task_switch(v2, 0, 0);
}

{
  uint64_t v0;
  void *v1;
  void *v2;
  uint64_t v3;

  uint64_t v1 = *(void **)(v0 + 160);
  unint64_t v2 = *(void **)(v0 + 152);
  outlined consume of Data._Representation(*(void *)(v0 + 136), *(void *)(v0 + 144));

  uint64_t v3 = *(void *)(v0 + 120);
  return (*(uint64_t (**)(uint64_t))(v0 + 8))(v3);
}

uint64_t static MLModel.compile(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v11 = *(void **)(v6 + 160);
  id v7 = *(void **)(v6 + 152);
  uint64_t v8 = *(void *)(v6 + 136);
  unint64_t v9 = *(void *)(v6 + 144);
  swift_willThrow(a1, a2, a3, a4, a5, a6);
  outlined consume of Data._Representation(v8, v9);

  return (*(uint64_t (**)(void))(v6 + 8))();
}

id @nonobjc MLModelAsset.__allocating_init(specification:)(uint64_t a1, unint64_t a2)
{
  Class isa = Data._bridgeToObjectiveC()().super.isa;
  ObjCClassFromMetadata = (void *)swift_getObjCClassFromMetadata();
  id v13 = 0;
  id v4 = [ObjCClassFromMetadata modelAssetWithSpecificationData:isa error:&v13];
  id v5 = v4;

  id v6 = v13;
  if (v5)
  {
    v13;
  }
  else
  {
    id v7 = v13;
    _convertNSErrorToError(_:)(v6);

    swift_willThrow(v7, "modelAssetWithSpecificationData:error:", v8, v9, v10, v11);
  }
  outlined consume of Data._Representation(a1, a2);
  return v5;
}

uint64_t @objc completion handler block implementation for @escaping @callee_unowned @convention(block) (@unowned MLModel?, @unowned NSError?) -> () with result type MLModel(uint64_t a1, void *a2, void *a3)
{
  uint64_t v3 = *(void *)(a1 + 32);
  if (a3)
  {
    id v4 = a3;
    return specialized _resumeUnsafeThrowingContinuationWithError<A>(_:_:)(v3, (uint64_t)v4);
  }
  else
  {
    if (!a2) {
      BUG();
    }
    id v6 = a2;
    return specialized _resumeUnsafeThrowingContinuation<A>(_:_:)(v3, (uint64_t)v6);
  }
}

uint64_t specialized _resumeUnsafeThrowingContinuationWithError<A>(_:_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
  uint64_t v3 = swift_allocError(v2, &protocol self-conformance witness table for Error, 0, 0);
  void *v4 = a2;
  return swift_continuation_throwingResumeWithError(a1, v3);
}

uint64_t specialized _resumeUnsafeThrowingContinuation<A>(_:_:)(uint64_t a1, uint64_t a2)
{
  **(void **)(*(void *)(a1 + 64) + 40) = a2;
  return swift_continuation_throwingResume();
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML23MLDecisionTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML23ijk3V15lm75V13configuration10validationAE0A12MLComponents07BoostedD13ConfigurationV_11c7Data0N5e12VSgtcfcAE010N21N0OAMcAPmcfu_ApMcfu0_AOXMtTf1ncn_n(uint64_t a1)
{
  uint64_t v21 = v1;
  uint64_t v2 = type metadata accessor for DataFrame(0);
  uint64_t v18 = *(void *)(v2 - 8);
  int64_t v3 = *(void *)(v18 + 64);
  id v4 = alloca(v3);
  id v5 = alloca(v3);
  uint64_t v19 = &v17;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                             - 8)
                 + 64);
  id v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, (uint64_t)&v17, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v17, 1, v2) == 1)
  {
    uint64_t v9 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData(0);
    uint64_t v10 = v21;
    uint64_t v11 = 1;
    uint64_t v12 = v9;
  }
  else
  {
    id v13 = v19;
    uint64_t v14 = v18;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v18 + 32))(v19, &v17, v2);
    uint64_t v15 = v21;
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v14 + 16))(v21, v13, v2);
    uint64_t v20 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData(0);
    swift_storeEnumTagMultiPayload(v15, v20, 2);
    (*(void (**)(uint64_t *, uint64_t))(v14 + 8))(v13, v2);
    uint64_t v10 = v15;
    uint64_t v11 = 0;
    uint64_t v12 = v20;
  }
  return __swift_storeEnumTagSinglePayload(v10, v11, 1, v12);
}

void MLDecisionTreeRegressor.predictions(from:)(uint64_t a1)
{
  int64_t v3 = v2;
  uint64_t v14 = v1;
  uint64_t v5 = type metadata accessor for DataFrame(0);
  uint64_t v13 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v13 + 64);
  id v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v15 = &v12;
  uint64_t v9 = type metadata accessor for MLDecisionTreeRegressor(0);
  DataFrame.validateContainsColumns(_:context:)(*(Swift::OpaquePointer *)((char *)v3 + *(int *)(v9 + 28)), (Swift::String)__PAIR128__(0xE700000000000000, 0x65727574616546));
  if (!v10)
  {
    TreeRegressorModel.applied(to:eventHandler:)(a1, 0, 0);
    uint64_t v11 = v15;
    DataFrame.subscript.getter(*v3, v3[1]);
    (*(void (**)(uint64_t *, uint64_t))(v13 + 8))(v11, v5);
  }
}

uint64_t type metadata accessor for MLDecisionTreeRegressor(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLDecisionTreeRegressor;
  if (!type metadata singleton initialization cache for MLDecisionTreeRegressor) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLDecisionTreeRegressor);
  }
  return result;
}

uint64_t MLDecisionTreeRegressor.predictions(from:)(uint64_t a1, __m128 a2)
{
  uint64_t v15 = v3;
  uint64_t v16 = v2;
  uint64_t v17 = type metadata accessor for DataFrame(0);
  uint64_t v18 = *(void *)(v17 - 8);
  int64_t v4 = *(void *)(v18 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  int64_t v7 = *(void *)(*(void *)(type metadata accessor for AnyColumn(0) - 8) + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  char v10 = *(unsigned char *)(a1 + 8);
  uint64_t v13 = *(void *)a1;
  char v14 = v10;
  outlined copy of Result<_DataTable, Error>(v13, v10);
  DataFrame.init(_:)((uint64_t)&v13);
  uint64_t v11 = v15;
  MLDecisionTreeRegressor.predictions(from:)((uint64_t)&v13);
  if (v11) {
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v18 + 8))(&v13, v17);
  }
  *(double *)a2.i64 = (*(double (**)(uint64_t *, uint64_t))(v18 + 8))(&v13, v17);
  return MLUntypedColumn.init(_:convertArraysToShapedArrays:)((uint64_t)&v13, 1, a2);
}

void MLDecisionTreeRegressor.evaluation(on:)(uint64_t a1)
{
  uint64_t v3 = v2;
  uint64_t v5 = v1;
  uint64_t v6 = type metadata accessor for MLDecisionTreeRegressor(0);
  v7._rawValue = *(void **)(v3 + *(int *)(v6 + 28));
  uint64_t v15 = a1;
  DataFrame.validateContainsColumns(_:context:)(v7, (Swift::String)__PAIR128__(0xE700000000000000, 0x65727574616546));
  if (v8) {
    goto LABEL_4;
  }
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t inited = swift_initStackObject(v9, v14);
  uint64_t v16 = v3;
  v11._rawValue = (void *)inited;
  *(void *)(inited + 16) = 1;
  *(void *)(inited + 24) = 2;
  uint64_t v12 = *(int *)(v6 + 24);
  uint64_t v13 = *(void *)(v16 + v12 + 8);
  *((void *)v11._rawValue + 4) = *(void *)(v16 + v12);
  *((void *)v11._rawValue + 5) = v13;
  swift_bridgeObjectRetain(v13);
  DataFrame.validateContainsColumns(_:context:)(v11, (Swift::String)__PAIR128__(0xE500000000000000, 0x6C6562614CLL));
  swift_setDeallocating(v11._rawValue);
  specialized _ContiguousArrayStorage.__deallocating_deinit();
  if (v8)
  {
LABEL_4:
    *(void *)uint64_t v5 = v8;
    *(void *)(v5 + 8) = 0;
    *(unsigned char *)(v5 + 16) = 1;
  }
  else
  {
    TreeRegressorModel.computeMetrics(on:)(v15);
  }
}

uint64_t MLDecisionTreeRegressor.evaluation(on:)(uint64_t a1)
{
  uint64_t v11 = v1;
  uint64_t v2 = type metadata accessor for DataFrame(0);
  uint64_t v3 = *(void *)(v2 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  char v7 = *(unsigned char *)(a1 + 8);
  uint64_t v9 = *(void *)a1;
  char v10 = v7;
  outlined copy of Result<_DataTable, Error>(v9, v7);
  DataFrame.init(_:)((uint64_t)&v9);
  MLDecisionTreeRegressor.evaluation(on:)((uint64_t)&v9);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v3 + 8))(&v9, v2);
}

uint64_t MLDecisionTreeRegressor.write(to:metadata:)(uint64_t a1, uint64_t *a2)
{
  uint64_t v63 = v2;
  uint64_t v62 = v3;
  uint64_t v61 = a1;
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for TreeRegressorModel(0) - 8) + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v45 = &v40;
  uint64_t v54 = type metadata accessor for Model(0);
  uint64_t v53 = *(void *)(v54 - 8);
  int64_t v7 = *(void *)(v53 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v42 = &v40;
  uint64_t v10 = type metadata accessor for URL(0);
  uint64_t v11 = *(void *)(v10 - 8);
  int64_t v12 = *(void *)(v11 + 64);
  uint64_t v13 = alloca(v12);
  char v14 = alloca(v12);
  uint64_t v47 = *a2;
  uint64_t v43 = a2[1];
  unint64_t v48 = a2[2];
  uint64_t v49 = (char *)a2[3];
  uint64_t v50 = a2[4];
  uint64_t v51 = a2[5];
  uint64_t v46 = a2[6];
  unint64_t v52 = a2[7];
  uint64_t v15 = a2[8];
  uint64_t v16 = v63;
  uint64_t result = static _ValidationUtilities.validateWriteLocation(atURL:defaultName:fileExtension:)(v61, 0xD000000000000015, (unint64_t)("v24@?0@\"MLModel\"8@\"NSError\"16" + 0x8000000000000000), 0x6C65646F6D6C6DLL, (void *)0xE700000000000000);
  if (!v16)
  {
    uint64_t v63 = 0;
    int v56 = &v40;
    uint64_t v57 = v10;
    uint64_t v55 = v11;
    outlined init with copy of MLTrainingSessionParameters(v62, (uint64_t)v45, type metadata accessor for TreeRegressorModel);
    uint64_t v18 = v43;
    uint64_t v44 = v15;
    if (v43)
    {
      uint64_t v19 = v47;
      uint64_t v61 = v43;
      uint64_t v20 = v48;
      unint64_t v21 = v48;
      uint64_t v22 = (uint64_t)v49;
      char v60 = v49;
      uint64_t v23 = v50;
      uint64_t v24 = v50;
      uint64_t v25 = v51;
      uint64_t v58 = v51;
      uint64_t v26 = v46;
      uint64_t v27 = v46;
      uint64_t v28 = v52;
      unint64_t v59 = v52;
      uint64_t v62 = v15;
      uint64_t v29 = v47;
    }
    else
    {
      uint64_t v30 = NSFullUserName();
      uint64_t v31 = v30;
      uint64_t v29 = static String._unconditionallyBridgeFromObjectiveC(_:)(v31);
      uint64_t v61 = v32;

      char v60 = "RandomForestRegressor" + 0x8000000000000000;
      unint64_t v21 = 0xD000000000000033;
      unint64_t v59 = 0xE100000000000000;
      uint64_t v27 = 49;
      uint64_t v24 = 0;
      uint64_t v58 = 0;
      uint64_t v62 = 0;
      uint64_t v26 = v46;
      uint64_t v19 = v47;
      uint64_t v20 = v48;
      uint64_t v22 = (uint64_t)v49;
      uint64_t v23 = v50;
      uint64_t v25 = v51;
      uint64_t v28 = v52;
    }
    v41[0] = v29;
    v41[1] = v61;
    v41[2] = v21;
    v41[3] = v60;
    v41[4] = v24;
    v41[5] = v58;
    v41[6] = v27;
    v41[7] = v59;
    v41[8] = v62;
    outlined copy of MLModelMetadata?(v19, v18, v20, v22, v23, v25, v26, v28, v44);
    uint64_t v33 = v42;
    uint64_t v34 = (uint64_t)v45;
    uint64_t v35 = v63;
    specialized CoreMLExportable.export(metadata:)((uint64_t)v41);
    if (v35)
    {
      uint64_t v63 = v35;
      swift_bridgeObjectRelease(v59);
      swift_bridgeObjectRelease((_BYTE)v60);
      swift_bridgeObjectRelease(v61);
      swift_bridgeObjectRelease(v58);
      swift_bridgeObjectRelease(v62);
      outlined destroy of MLActivityClassifier.ModelParameters(v34, type metadata accessor for TreeRegressorModel);
      uint64_t v36 = v55;
      uint64_t v37 = v57;
      uint64_t v39 = v56;
    }
    else
    {
      swift_bridgeObjectRelease(v59);
      swift_bridgeObjectRelease((_BYTE)v60);
      swift_bridgeObjectRelease(v61);
      swift_bridgeObjectRelease(v58);
      swift_bridgeObjectRelease(v62);
      outlined destroy of MLActivityClassifier.ModelParameters(v34, type metadata accessor for TreeRegressorModel);
      uint64_t v38 = v56;
      Model.write(to:)(v56);
      uint64_t v63 = 0;
      uint64_t v36 = v55;
      (*(void (**)(uint64_t *, uint64_t))(v53 + 8))(v33, v54);
      uint64_t v39 = v38;
      uint64_t v37 = v57;
    }
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v36 + 8))(v39, v37);
  }
  return result;
}

uint64_t MLDecisionTreeRegressor.write(toFile:metadata:)(uint64_t a1, uint64_t a2, long long *a3)
{
  uint64_t v23 = v3;
  uint64_t v25 = a2;
  uint64_t v24 = a1;
  uint64_t v26 = type metadata accessor for URL.DirectoryHint(0);
  uint64_t v27 = *(void *)(v26 - 8);
  int64_t v5 = *(void *)(v27 + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v11 = type metadata accessor for URL(0);
  uint64_t v29 = *(void *)(v11 - 8);
  int64_t v12 = *(void *)(v29 + 64);
  uint64_t v13 = alloca(v12);
  char v14 = alloca(v12);
  uint64_t v28 = *((void *)a3 + 8);
  long long v19 = *a3;
  long long v20 = a3[1];
  long long v21 = a3[2];
  long long v22 = a3[3];
  uint64_t v30 = v11;
  __swift_storeEnumTagSinglePayload((uint64_t)v17, 1, 1, v11);
  (*(void (**)(_OWORD *, void, uint64_t))(v27 + 104))(v17, enum case for URL.DirectoryHint.inferFromPath(_:), v26);
  uint64_t v15 = v25;
  swift_bridgeObjectRetain(v25);
  URL.init(filePath:directoryHint:relativeTo:)(v24, v15, v17, v17);
  v17[0] = v19;
  v17[1] = v20;
  v17[2] = v21;
  v17[3] = v22;
  uint64_t v18 = v28;
  MLDecisionTreeRegressor.write(to:metadata:)((uint64_t)v17, (uint64_t *)v17);
  return (*(uint64_t (**)(_OWORD *, uint64_t))(v29 + 8))(v17, v30);
}

id MLDecisionTreeRegressor.model.getter()
{
  uint64_t v1 = type metadata accessor for MLDecisionTreeRegressor(0);
  return *(id *)(v0 + *(int *)(v1 + 20));
}

unint64_t MLDecisionTreeRegressor.description.getter()
{
  uint64_t v1 = type metadata accessor for MLDecisionTreeRegressor(0);
  uint64_t v14 = MLDecisionTreeRegressor.ModelParameters.description.getter();
  uint64_t v3 = v2;
  unint64_t v16 = MLRegressorMetrics.description.getter();
  int64_t v5 = v4;
  char v13 = *(unsigned char *)(v0 + *(int *)(v1 + 40) + 16);
  v12._uint64_t countAndFlagsBits = MLRegressorMetrics.description.getter();
  v12._unsigned __int8 object = v6;
  v7._uint64_t countAndFlagsBits = v14;
  char v15 = (char)v3;
  v7._unsigned __int8 object = v3;
  String.append(_:)(v7);
  v7._uint64_t countAndFlagsBits = v16;
  v7._unsigned __int8 object = v5;
  String.append(_:)(v7);
  v7._uint64_t countAndFlagsBits = 0xD00000000000001ELL;
  v7._unsigned __int8 object = "ActivityClassifier\n\nParameters\n" + 0x8000000000000000;
  String.append(_:)(v7);
  swift_bridgeObjectRelease(("ActivityClassifier\n\nParameters\n" + 0x8000000000000000));
  if (v13)
  {
    char v8 = (char)v5;
    unsigned __int8 object = v12._object;
  }
  else
  {
    String.append(_:)(v12);
    v10._uint64_t countAndFlagsBits = 0xD000000000000020;
    unsigned __int8 object = ("\nPerformance on Training Data\n" + 0x8000000000000000);
    v10._unsigned __int8 object = "\nPerformance on Training Data\n" + 0x8000000000000000;
    String.append(_:)(v10);
    swift_bridgeObjectRelease((_BYTE)v5);
    char v8 = (char)v12._object;
  }
  swift_bridgeObjectRelease(v8);
  swift_bridgeObjectRelease(object);
  swift_bridgeObjectRelease(v15);
  return 0xD000000000000022;
}

unint64_t MLDecisionTreeRegressor.debugDescription.getter()
{
  return MLDecisionTreeRegressor.description.getter();
}

NSAttributedString MLDecisionTreeRegressor.playgroundDescription.getter()
{
  uint64_t v1 = v0;
  uint64_t v2 = type metadata accessor for NSAttributedString();
  v3._uint64_t countAndFlagsBits = MLDecisionTreeRegressor.description.getter();
  v3._unsigned __int8 object = v4;
  result.super.Class isa = NSAttributedString.__allocating_init(string:)(v3).super.isa;
  v1[3].super.Class isa = (Class)v2;
  v1->super.Class isa = result.super.isa;
  return result;
}

void key path setter for MLDecisionTreeRegressor.model : MLDecisionTreeRegressor(id *a1)
{
  id v1 = *a1;
  MLDecisionTreeRegressor.model.setter((uint64_t)v1);
}

void MLDecisionTreeRegressor.model.setter(uint64_t a1)
{
  uint64_t v2 = *(int *)(type metadata accessor for MLDecisionTreeRegressor(0) + 20);

  *(void *)(v1 + v2) = a1;
}

void (*MLDecisionTreeRegressor.model.modify(uint64_t a1))(uint64_t a1, char a2)
{
  *(void *)(a1 + 8) = v1;
  uint64_t v3 = *(int *)(type metadata accessor for MLDecisionTreeRegressor(0) + 20);
  *(_DWORD *)(a1 + 16) = v3;
  int64_t v4 = *(void **)(v1 + v3);
  *(void *)a1 = v4;
  v4;
  return MLActivityClassifier.model.modify;
}

uint64_t MLDecisionTreeRegressor.targetColumn.getter()
{
  uint64_t v1 = *(int *)(type metadata accessor for MLDecisionTreeRegressor(0) + 24);
  uint64_t v2 = *(void *)(v0 + v1);
  swift_bridgeObjectRetain(*(void *)(v0 + v1 + 8));
  return v2;
}

uint64_t MLDecisionTreeRegressor.targetColumn.setter(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(int *)(type metadata accessor for MLDecisionTreeRegressor(0) + 24);
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v2 + v3 + 8));
  *(void *)(v2 + v3) = a1;
  *(void *)(v2 + v3 + 8) = a2;
  return result;
}

void (*MLDecisionTreeRegressor.targetColumn.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLDecisionTreeRegressor.featureColumns.getter()
{
  uint64_t v1 = type metadata accessor for MLDecisionTreeRegressor(0);
  return swift_bridgeObjectRetain(*(void *)(v0 + *(int *)(v1 + 28)));
}

uint64_t MLDecisionTreeRegressor.featureColumns.setter(uint64_t a1)
{
  uint64_t v2 = *(int *)(type metadata accessor for MLDecisionTreeRegressor(0) + 28);
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v1 + v2));
  *(void *)(v1 + v2) = a1;
  return result;
}

void (*MLDecisionTreeRegressor.featureColumns.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLDecisionTreeRegressor.modelParameters.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLDecisionTreeRegressor(0);
  return outlined init with copy of MLDecisionTreeRegressor.ModelParameters(v1 + *(int *)(v3 + 32), v2);
}

uint64_t MLDecisionTreeRegressor.trainingMetrics.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = *(int *)(type metadata accessor for MLDecisionTreeRegressor(0) + 36);
  uint64_t v4 = *(void *)(v1 + v3);
  uint64_t v5 = *(void *)(v1 + v3 + 8);
  char v6 = *(unsigned char *)(v1 + v3 + 16);
  *(void *)uint64_t v2 = v4;
  *(void *)(v2 + 8) = v5;
  *(unsigned char *)(v2 + 16) = v6;
  return outlined copy of Result<_RegressorMetrics, Error>(v4, v5, v6);
}

uint64_t MLDecisionTreeRegressor.validationMetrics.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = *(int *)(type metadata accessor for MLDecisionTreeRegressor(0) + 40);
  uint64_t v4 = *(void *)(v1 + v3);
  uint64_t v5 = *(void *)(v1 + v3 + 8);
  char v6 = *(unsigned char *)(v1 + v3 + 16);
  *(void *)uint64_t v2 = v4;
  *(void *)(v2 + 8) = v5;
  *(unsigned char *)(v2 + 16) = v6;
  return outlined copy of Result<_RegressorMetrics, Error>(v4, v5, v6);
}

uint64_t static MLDecisionTreeRegressor._defaultSessionParameters.getter()
{
  uint64_t v1 = v0;
  if (one-time initialization token for _defaultSessionParameters != -1) {
    swift_once(&one-time initialization token for _defaultSessionParameters, one-time initialization function for _defaultSessionParameters);
  }
  uint64_t v2 = type metadata accessor for MLTrainingSessionParameters(0);
  uint64_t v3 = __swift_project_value_buffer(v2, (uint64_t)static MLDecisionTreeRegressor._defaultSessionParameters);
  return outlined init with copy of MLTrainingSessionParameters(v3, v1, type metadata accessor for MLTrainingSessionParameters);
}

uint64_t MLDecisionTreeRegressor.init(_:targetColumn:featureColumns:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v6[7] = a6;
  v6[6] = a5;
  void v6[5] = a4;
  v6[4] = a3;
  v6[3] = a2;
  v6[2] = a1;
  return swift_task_switch(MLDecisionTreeRegressor.init(_:targetColumn:featureColumns:parameters:), 0, 0);
}

uint64_t MLDecisionTreeRegressor.init(_:targetColumn:featureColumns:parameters:)()
{
  uint64_t v1 = *(void *)(v0 + 48);
  long long v13 = *(_OWORD *)(v0 + 32);
  uint64_t v2 = *(void *)(v0 + 16);
  uint64_t v3 = (int *)type metadata accessor for MLDecisionTreeRegressor(0);
  *(void *)(v0 + 64) = v3;
  uint64_t v4 = v3[9];
  *(_DWORD *)(v0 + 96) = v4;
  *(unsigned char *)(v2 + v4 + 16) = 0;
  *(_OWORD *)(v2 + v4) = 0;
  uint64_t v5 = v3[10];
  *(_DWORD *)(v0 + 100) = v5;
  uint64_t v6 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v7 = swift_allocError(&type metadata for MLCreateError, v6, 0, 0);
  *(void *)uint64_t v8 = 0xD0000000000000C0;
  *(void *)(v8 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v8 + 16) = 0;
  *(_OWORD *)(v8 + 32) = 0;
  *(unsigned char *)(v8 + 48) = 0;
  *(void *)(v2 + v5) = v7;
  *(void *)(v2 + v5 + 8) = 0;
  *(unsigned char *)(v2 + v5 + 16) = 1;
  uint64_t v9 = v3[7];
  *(_DWORD *)(v0 + 104) = v9;
  *(void *)(v2 + v9) = v1;
  *(_OWORD *)(v2 + v3[6]) = v13;
  Swift::String v10 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                          + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v11 = (void *)swift_task_alloc(dword_3AE25C);
  *(void *)(v0 + 72) = v11;
  void *v11 = v0;
  v11[1] = MLDecisionTreeRegressor.init(_:targetColumn:featureColumns:parameters:);
  return v10();
}

{
  uint64_t v0;
  uint64_t v1;
  long long *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  long long v6;
  long long v7;
  long long v8;

  uint64_t v1 = *(void *)(v0 + 64);
  uint64_t v2 = *(long long **)(v0 + 56);
  uint64_t v3 = *(void *)(v0 + 16);
  uint64_t v4 = *(void *)(v0 + 24);
  *(void *)(v3 + *(int *)(v1 + 20)) = *(void *)(v0 + 88);
  outlined init with take of MLClassifierMetrics(v4, v3, type metadata accessor for TreeRegressorModel);
  uint64_t v5 = *(int *)(v1 + 32);
  uint64_t v6 = *v2;
  uint64_t v7 = v2[1];
  uint64_t v8 = v2[2];
  *(_OWORD *)(v3 + v5 + 48) = v2[3];
  *(_OWORD *)(v3 + v5 + 32) = v8;
  *(_OWORD *)(v3 + v5 + 16) = v7;
  *(_OWORD *)(v3 + v5) = v6;
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;

  uint64_t v6 = *(int *)(v0 + 104);
  uint64_t v1 = *(int *)(v0 + 100);
  uint64_t v2 = *(int *)(v0 + 96);
  uint64_t v7 = *(void *)(v0 + 40);
  uint64_t v3 = *(void *)(v0 + 16);
  uint64_t v4 = *(void *)(v0 + 24);
  outlined destroy of MLDecisionTreeRegressor.ModelParameters(*(void *)(v0 + 56));
  outlined destroy of MLActivityClassifier.ModelParameters(v4, type metadata accessor for TreeRegressorModel);
  swift_bridgeObjectRelease(v7);
  swift_bridgeObjectRelease(*(void *)(v3 + v6));
  outlined consume of Result<(Int, Int), Error>(*(void *)(v3 + v2), *(void *)(v3 + v2 + 8), *(_DWORD *)(v3 + v2 + 16));
  outlined consume of Result<(Int, Int), Error>(*(void *)(v3 + v1), *(void *)(v3 + v1 + 8), *(_DWORD *)(v3 + v1 + 16));
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLDecisionTreeRegressor.init(_:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  uint64_t v5 = *(void *)(*v2 + 72);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 80) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = MLDecisionTreeRegressor.init(_:targetColumn:featureColumns:parameters:);
  }
  else
  {
    *(void *)(v4 + 88) = a1;
    uint64_t v6 = MLDecisionTreeRegressor.init(_:targetColumn:featureColumns:parameters:);
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(void (*a1)(uint64_t *, uint64_t, uint64_t), uint64_t a2, void *a3, Swift::Int a4, uint64_t a5)
{
  Swift::Int quantity = a4;
  uint64_t v137 = a3;
  uint64_t v7 = v5;
  uint64_t v126 = a2;
  uint64_t v125 = v6;
  uint64_t v139 = a5;
  v134 = a1;
  uint64_t v135 = type metadata accessor for DataFrame(0);
  uint64_t v133 = *(void *)(v135 - 8);
  int64_t v8 = *(void *)(v133 + 64);
  uint64_t v9 = alloca(v8);
  Swift::String v10 = alloca(v8);
  uint64_t v120 = &v103;
  uint64_t v118 = *(void *)(type metadata accessor for TreeRegressorModel(0) - 8);
  int64_t v11 = *(void *)(v118 + 64);
  Swift::String v12 = alloca(v11);
  long long v13 = alloca(v11);
  uint64_t v116 = &v103;
  int64_t v117 = v11;
  uint64_t v14 = alloca(v11);
  char v15 = alloca(v11);
  uint64_t v136 = &v103;
  uint64_t v111 = type metadata accessor for BaseTreeRegressor(0);
  uint64_t v112 = *(void *)(v111 - 8);
  int64_t v16 = *(void *)(v112 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v113 = &v103;
  uint64_t v114 = type metadata accessor for TreeRegressor(0);
  int64_t v19 = *(void *)(*(void *)(v114 - 8) + 64);
  long long v20 = alloca(v19);
  long long v21 = alloca(v19);
  uint64_t v131 = &v103;
  uint64_t v128 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData(0);
  int64_t v22 = *(void *)(*(void *)(v128 - 8) + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  uint64_t v143 = &v103;
  uint64_t v124 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
  int64_t v25 = *(void *)(*(void *)(v124 - 8) + 64);
  uint64_t v26 = alloca(v25);
  uint64_t v27 = alloca(v25);
  uint64_t v123 = &v103;
  uint64_t v28 = alloca(v25);
  uint64_t v29 = alloca(v25);
  uint64_t v119 = &v103;
  uint64_t v30 = alloca(v25);
  uint64_t v31 = alloca(v25);
  v142 = &v103;
  uint64_t v140 = type metadata accessor for BoostedTreeConfiguration(0);
  uint64_t v141 = *(void (**)(long long *, uint64_t))(v140 - 8);
  int64_t v32 = *((void *)v141 + 8);
  uint64_t v33 = alloca(v32);
  uint64_t v34 = alloca(v32);
  uint64_t v115 = &v103;
  uint64_t v35 = alloca(v32);
  uint64_t v36 = alloca(v32);
  uint64_t v121 = &v103;
  uint64_t v37 = alloca(v32);
  uint64_t v38 = alloca(v32);
  uint64_t v39 = type metadata accessor for MLDecisionTreeRegressor(0);
  uint64_t v40 = *(int *)(v39 + 36);
  *(unsigned char *)(v7 + v40 + 16) = 0;
  uint64_t v132 = v40;
  *(_OWORD *)(v7 + v40) = 0;
  uint64_t v122 = v39;
  uint64_t v41 = *(int *)(v39 + 40);
  uint64_t v42 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v43 = swift_allocError(&type metadata for MLCreateError, v42, 0, 0);
  *(void *)uint64_t v44 = 0xD0000000000000C0;
  *(void *)(v44 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v44 + 16) = 0;
  *(_OWORD *)(v44 + 32) = 0;
  *(unsigned char *)(v44 + 48) = 0;
  *(void *)(v7 + v41) = v43;
  *(void *)(v7 + v41 + 8) = 0;
  uint64_t v130 = v41;
  uint64_t v127 = v7;
  *(unsigned char *)(v7 + v41 + 16) = 1;
  uint64_t v45 = v139;
  outlined init with copy of MLDecisionTreeRegressor.ModelParameters(v139, (uint64_t)&v105);
  BoostedTreeConfiguration.init()();
  BoostedTreeConfiguration.maximumIterations.setter(1);
  BoostedTreeConfiguration.learningRate.setter(1.0);
  BoostedTreeConfiguration.maximumDepth.setter(v107);
  BoostedTreeConfiguration.minimumLossReduction.setter(v108);
  BoostedTreeConfiguration.minimumChildWeight.setter(v109);
  uint64_t v138 = &v103;
  BoostedTreeConfiguration.randomSeed.setter(v110);
  outlined destroy of MLDecisionTreeRegressor.ModelParameters((uint64_t)&v105);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v45, (uint64_t)&v103, &demangling cache variable for type metadata for Any?);
  if (!v104) {
    BUG();
  }
  v132 += v127;
  uint64_t v46 = (uint64_t)v142;
  uint64_t v47 = (uint64_t)v142 + *(int *)(v124 + 48);
  outlined init with take of Any(&v103, &v105);
  swift_dynamicCast(v143, &v105, (char *)&type metadata for Any + 8, v128, 7);
  uint64_t v48 = v46;
  uint64_t v49 = v134;
  uint64_t v50 = v125;
  MLDecisionTreeRegressor.ModelParameters.ValidationData.generateDataFrames(trainingData:)(v48, v47, v134);
  uint64_t v51 = v132;
  if (v50)
  {
    swift_bridgeObjectRelease((_BYTE)v137);
    swift_bridgeObjectRelease(quantity);
    outlined destroy of MLDecisionTreeRegressor.ModelParameters(v139);
    (*(void (**)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))(v133 + 8))(v49, v135);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v143, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
    (*((void (**)(long long *, uint64_t))v141 + 1))(v138, v140);
    uint64_t v52 = v127;
    uint64_t v53 = v130;
LABEL_6:
    outlined consume of Result<(Int, Int), Error>(*(void *)v51, *(void *)(v51 + 8), *(_DWORD *)(v51 + 16));
    return outlined consume of Result<(Int, Int), Error>(*(void *)(v52 + v53), *(void *)(v52 + v53 + 8), *(_DWORD *)(v52 + v53 + 16));
  }
  uint64_t v125 = v47;
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v143, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  uint64_t v54 = v126;
  char v55 = quantity;
  int v56 = static _FeatureUtilities.selectFeaturesFromTrainingData(trainingData:targetColumn:featureColumns:)((uint64_t)v142, v126, v137, quantity);
  uint64_t v143 = 0;
  char v57 = v55;
  uint64_t v58 = v56;
  swift_bridgeObjectRelease(v57);
  unint64_t v59 = (void (*)(long long *, long long *, uint64_t))*((void *)v141 + 2);
  char v60 = v121;
  v59(v121, v138, v140);
  uint64_t v61 = v59;
  uint64_t v62 = v131;
  *(void *)uint64_t v131 = v54;
  *((void *)v62 + 1) = v137;
  *((void *)v62 + 2) = v58;
  *((void *)v62 + 3) = v58;
  *((void *)v62 + 4) = 0xD000000000000013;
  *((void *)v62 + 5) = "raining samples." + 0x8000000000000000;
  uint64_t v63 = v115;
  uint64_t v64 = v60;
  uint64_t v65 = v140;
  v61(v115, v64, v140);
  uint64_t v128 = (uint64_t)v58;
  swift_bridgeObjectRetain_n(v58, 2);
  swift_bridgeObjectRetain((_BYTE)v137);
  uint64_t v66 = v113;
  BaseTreeRegressor.init(configuration:)(v63);
  uint64_t v67 = v65;
  uint64_t v68 = (void (*)(long long *, uint64_t))*((void *)v141 + 1);
  v68(v121, v67);
  (*(void (**)(char *, long long *, uint64_t))(v112 + 32))((char *)v62 + *(int *)(v114 + 28), v66, v111);
  unint64_t v69 = v138;
  uint64_t v70 = (uint64_t)v143;
  TreeRegressor.fitted(to:validateOn:eventHandler:)((uint64_t)v142, v125, 0, 0);
  uint64_t v143 = (long long *)v70;
  if (v70)
  {
    swift_bridgeObjectRelease((_BYTE)v137);
    swift_bridgeObjectRelease(v128);
    outlined destroy of MLDecisionTreeRegressor.ModelParameters(v139);
    (*(void (**)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))(v133 + 8))(v134, v135);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v62, type metadata accessor for TreeRegressor);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v142, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    v68(v69, v140);
    uint64_t v52 = v127;
    uint64_t v53 = v130;
    uint64_t v51 = v132;
    goto LABEL_6;
  }
  uint64_t v141 = v68;
  if (!AnalyticsReporter.init()())
  {
    Swift::String v72 = v119;
    uint64_t v73 = (uint64_t)v119 + *(int *)(v124 + 48);
    uint64_t v74 = v133;
    (*(void (**)(long long *, long long *, uint64_t))(v133 + 16))(v119, v142, v135);
    uint64_t v75 = v125;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v125, v73, &demangling cache variable for type metadata for DataFrame?);
    Swift::Int quantity = DataFrame.shape.getter(v75);
    (*(void (**)(long long *, uint64_t))(v74 + 8))(v72, v135);
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_decisionTreeRegressor, (Swift::String)__PAIR128__((unint64_t)("vectorized_features" + 0x8000000000000000), 0xD000000000000015), quantity);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v73, &demangling cache variable for type metadata for DataFrame?);
  }
  uint64_t v76 = v122;
  Swift::Int v77 = *(int *)(v122 + 24);
  uint64_t v78 = v127;
  *(void *)(v127 + v77) = v126;
  Swift::Int quantity = v77;
  *(void *)(v78 + v77 + 8) = v137;
  uint64_t v126 = v78 + *(int *)(v76 + 32);
  outlined init with copy of MLDecisionTreeRegressor.ModelParameters(v139, v126);
  uint64_t v137 = (void *)*(int *)(v76 + 28);
  *(void *)((char *)v137 + v78) = v128;
  uint64_t v79 = (uint64_t)v116;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v136, (uint64_t)v116, type metadata accessor for TreeRegressorModel);
  uint64_t v80 = *(unsigned __int8 *)(v118 + 80);
  uint64_t v81 = ~*(unsigned __int8 *)(v118 + 80) & (v80 + 16);
  uint64_t v82 = swift_allocObject(&unk_398E38, v81 + v117, v80 | 7);
  outlined init with take of MLClassifierMetrics(v79, v82 + v81, type metadata accessor for TreeRegressorModel);
  uint64_t v83 = (uint64_t)v143;
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:), v82);
  if (v83)
  {
    swift_release();
    outlined destroy of MLDecisionTreeRegressor.ModelParameters(v139);
    (*(void (**)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))(v133 + 8))(v134, v135);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v136, type metadata accessor for TreeRegressorModel);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v131, type metadata accessor for TreeRegressor);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v142, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    v141(v138, v140);
    uint64_t v52 = v78;
    uint64_t v53 = v130;
    uint64_t v85 = v126;
LABEL_12:
    swift_bridgeObjectRelease(*(void *)(v52 + quantity + 8));
    swift_bridgeObjectRelease(*(void *)((char *)v137 + v52));
    outlined destroy of MLDecisionTreeRegressor.ModelParameters(v85);
    uint64_t v51 = v132;
    goto LABEL_6;
  }
  uint64_t v86 = v84;
  swift_release();
  uint64_t v128 = *(int *)(v122 + 20);
  *(void *)(v78 + v128) = v86;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v136, v78, type metadata accessor for TreeRegressorModel);
  uint64_t v87 = (uint64_t)v142;
  TreeRegressorModel.computeMetrics(on:)((uint64_t)v142);
  uint64_t v143 = 0;
  uint64_t v88 = v87;
  char v89 = v106;
  uint64_t v90 = v132;
  outlined consume of Result<(Int, Int), Error>(*(void *)v132, *(void *)(v132 + 8), *(_DWORD *)(v132 + 16));
  *(_OWORD *)uint64_t v90 = v105;
  *(unsigned char *)(v90 + 16) = v89;
  char v91 = v123;
  uint64_t v92 = (uint64_t)v123 + *(int *)(v124 + 48);
  uint64_t v93 = v88;
  uint64_t v94 = v135;
  uint64_t v95 = v133;
  (*(void (**)(long long *, uint64_t, uint64_t))(v133 + 16))(v123, v93, v135);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v125, v92, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload(v92, 1, v94) == 1)
  {
    outlined destroy of MLDecisionTreeRegressor.ModelParameters(v139);
    char v96 = *(void (**)(void (*)(uint64_t *, uint64_t, uint64_t), uint64_t))(v95 + 8);
    v96(v134, v94);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v136, type metadata accessor for TreeRegressorModel);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v131, type metadata accessor for TreeRegressor);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v142, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    v141(v138, v140);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v92, &demangling cache variable for type metadata for DataFrame?);
    return ((uint64_t (*)(long long *, uint64_t))v96)(v91, v94);
  }
  else
  {
    uint64_t v97 = (uint64_t)v120;
    (*(void (**)(long long *, uint64_t, uint64_t))(v95 + 32))(v120, v92, v94);
    uint64_t v98 = *(void (**)(long long *, uint64_t))(v95 + 8);
    v98(v123, v94);
    uint64_t v99 = v127;
    uint64_t v100 = (uint64_t)v143;
    TreeRegressorModel.computeMetrics(on:)(v97);
    uint64_t v143 = (long long *)v100;
    if (v100)
    {
      outlined destroy of MLDecisionTreeRegressor.ModelParameters(v139);
      v98((long long *)v134, v94);
      v98((long long *)v97, v94);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v136, type metadata accessor for TreeRegressorModel);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v131, type metadata accessor for TreeRegressor);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v142, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      v141(v138, v140);
      uint64_t v52 = v99;
      outlined destroy of MLActivityClassifier.ModelParameters(v99, type metadata accessor for TreeRegressorModel);

      uint64_t v53 = v130;
      uint64_t v85 = v126;
      goto LABEL_12;
    }
    outlined destroy of MLDecisionTreeRegressor.ModelParameters(v139);
    v98((long long *)v134, v94);
    v98((long long *)v97, v94);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v136, type metadata accessor for TreeRegressorModel);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v131, type metadata accessor for TreeRegressor);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v142, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
    v141(v138, v140);
    char v101 = v106;
    uint64_t v102 = v130;
    uint64_t result = outlined consume of Result<(Int, Int), Error>(*(void *)(v99 + v130), *(void *)(v99 + v130 + 8), *(_DWORD *)(v99 + v130 + 16));
    *(_OWORD *)(v99 + v102) = v105;
    *(unsigned char *)(v99 + v102 + 16) = v101;
  }
  return result;
}

uint64_t closure #1 in MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
  uint64_t v2 = (uint64_t (*)(void))((char *)&async function pointer to specialized CoreMLExportable.exportAsCoreMLModel()
                         + async function pointer to specialized CoreMLExportable.exportAsCoreMLModel());
  uint64_t v3 = (void *)swift_task_alloc(dword_3AE25C);
  *(void *)(v1 + 24) = v3;
  *uint64_t v3 = v1;
  v3[1] = closure #1 in MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:);
  return v2();
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;

  uint64_t v4 = *v2;
  uint64_t v5 = *(void *)(*v2 + 24);
  uint64_t v6 = *v2;
  swift_task_dealloc(v5);
  if (v1) {
    return (*(uint64_t (**)(void))(v6 + 8))();
  }
  *(void *)(v4 + 32) = a1;
  return swift_task_switch(closure #1 in MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:), 0, 0);
}

uint64_t MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t *a1, uint64_t a2, void *a3, Swift::Int a4, uint64_t a5)
{
  Swift::Int v13 = a4;
  uint64_t v14 = a3;
  uint64_t v15 = a2;
  int64_t v6 = *(void *)(*(void *)(type metadata accessor for DataFrame(0) - 8) + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  char v9 = *((unsigned char *)a1 + 8);
  uint64_t v11 = *a1;
  char v12 = v9;
  DataFrame.init(_:)((uint64_t)&v11);
  outlined init with copy of MLDecisionTreeRegressor.ModelParameters(a5, (uint64_t)&v11);
  MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v11, v15, v14, v13, (uint64_t)&v11);
  return outlined destroy of MLDecisionTreeRegressor.ModelParameters(a5);
}

uint64_t MLDecisionTreeRegressor.init(checkpoint:)(uint64_t a1)
{
  uint64_t v66 = v2;
  uint64_t v86 = a1;
  uint64_t v3 = v1;
  uint64_t v79 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData(0);
  int64_t v4 = *(void *)(*(void *)(v79 - 8) + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  Swift::Int v77 = v65;
  uint64_t v7 = alloca(v4);
  int64_t v8 = alloca(v4);
  uint64_t v76 = v65;
  uint64_t v75 = *(void *)(type metadata accessor for TreeRegressorModel(0) - 8);
  int64_t v9 = *(void *)(v75 + 64);
  Swift::String v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v73 = v65;
  int64_t v74 = v9;
  char v12 = alloca(v9);
  Swift::Int v13 = alloca(v9);
  uint64_t v84 = v65;
  uint64_t v67 = type metadata accessor for BaseTreeRegressor(0);
  uint64_t v68 = *(void *)(v67 - 8);
  int64_t v14 = *(void *)(v68 + 64);
  uint64_t v15 = alloca(v14);
  int64_t v16 = alloca(v14);
  uint64_t v81 = v65;
  uint64_t v69 = type metadata accessor for BoostedTreeConfiguration(0);
  uint64_t v70 = *(void *)(v69 - 8);
  int64_t v17 = *(void *)(v70 + 64);
  uint64_t v18 = alloca(v17);
  int64_t v19 = alloca(v17);
  Swift::String v72 = v65;
  long long v20 = alloca(v17);
  long long v21 = alloca(v17);
  uint64_t v82 = v65;
  uint64_t v71 = type metadata accessor for TreeRegressor(0);
  int64_t v22 = *(void *)(*(void *)(v71 - 8) + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  uint64_t v87 = (char *)v65;
  uint64_t v25 = type metadata accessor for MLDecisionTreeRegressor(0);
  uint64_t v26 = *(int *)(v25 + 36);
  *(unsigned char *)(v3 + v26 + 16) = 0;
  *(_OWORD *)(v3 + v26) = 0;
  uint64_t v78 = (int *)v25;
  uint64_t v27 = *(int *)(v25 + 40);
  uint64_t v85 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v28 = swift_allocError(&type metadata for MLCreateError, v85, 0, 0);
  *(void *)uint64_t v29 = 0xD0000000000000C0;
  *(void *)(v29 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v29 + 16) = 0;
  *(_OWORD *)(v29 + 32) = 0;
  *(unsigned char *)(v29 + 48) = 0;
  *(void *)(v3 + v27) = v28;
  *(void *)(v3 + v27 + 8) = 0;
  uint64_t v83 = v3;
  uint64_t v80 = v27;
  *(unsigned char *)(v3 + v27 + 16) = 1;
  switch(*(unsigned char *)(v86 + *(int *)(type metadata accessor for MLCheckpoint(0) + 20)))
  {
    case 0:
      uint64_t v30 = 0x696C616974696E69;
      uint64_t v31 = v87;
      unint64_t v32 = 0xEB0000000064657ALL;
      goto LABEL_9;
    case 1:
      uint64_t v30 = 0x6974636172747865;
      goto LABEL_6;
    case 2:
      swift_bridgeObjectRelease(0);
      uint64_t v31 = v87;
      goto LABEL_10;
    case 3:
      uint64_t v30 = 0x697461756C617665;
LABEL_6:
      unint64_t v32 = 0xEA0000000000676ELL;
      break;
    case 4:
      unint64_t v32 = 0xEB00000000676E69;
      uint64_t v30 = 0x636E657265666E69;
      break;
    case 5:
      JUMPOUT(0xE6F30);
  }
  uint64_t v31 = v87;
LABEL_9:
  char v33 = _stringCompareWithSmolCheck(_:_:expecting:)(v30, v32, 0x676E696E69617274, 0xE800000000000000, 0);
  swift_bridgeObjectRelease(v32);
  if (v33)
  {
LABEL_10:
    uint64_t v85 = v26;
    uint64_t v34 = (uint64_t)v82;
    BoostedTreeConfiguration.init()();
    *(void *)uint64_t v31 = 0;
    *((void *)v31 + 1) = 0xE000000000000000;
    *((void *)v31 + 2) = _swiftEmptyArrayStorage;
    *((void *)v31 + 3) = _swiftEmptyArrayStorage;
    *((void *)v31 + 4) = 0xD000000000000013;
    *((void *)v31 + 5) = "raining samples." + 0x8000000000000000;
    uint64_t v35 = v72;
    uint64_t v36 = v34;
    uint64_t v37 = v69;
    uint64_t v38 = v70;
    (*(void (**)(void *, uint64_t, uint64_t))(v70 + 16))(v72, v36, v69);
    BaseTreeRegressor.init(configuration:)(v35);
    (*(void (**)(void *, uint64_t))(v38 + 8))(v82, v37);
    uint64_t v39 = v71;
    (*(void (**)(char *, void *, uint64_t))(v68 + 32))(&v31[*(int *)(v71 + 28)], v81, v67);
    uint64_t v40 = lazy protocol witness table accessor for type TreeRegressor and conformance TreeRegressor();
    uint64_t v41 = (uint64_t)v84;
    uint64_t v42 = v86;
    uint64_t v43 = v66;
    UpdatableSupervisedTabularEstimator.readWithOptimizer(from:)(v86, v39, v40);
    if (!v43)
    {
      uint64_t v51 = (uint64_t)v73;
      outlined init with copy of MLTrainingSessionParameters(v41, (uint64_t)v73, type metadata accessor for TreeRegressorModel);
      uint64_t v52 = *(unsigned __int8 *)(v75 + 80);
      uint64_t v53 = ~*(unsigned __int8 *)(v75 + 80) & (v52 + 16);
      uint64_t v54 = swift_allocObject(&unk_398E60, v53 + v74, v52 | 7);
      outlined init with take of MLClassifierMetrics(v51, v54 + v53, type metadata accessor for TreeRegressorModel);
      specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLDecisionTreeRegressor.init(checkpoint:), v54);
      uint64_t v56 = v55;
      swift_release();
      uint64_t v81 = 0;
      char v57 = v78;
      uint64_t v58 = v83;
      *(void *)(v83 + v78[5]) = v56;
      outlined init with copy of MLTrainingSessionParameters((uint64_t)v84, v58, type metadata accessor for TreeRegressorModel);
      uint64_t v59 = (uint64_t)v76;
      _OWORD *v76 = 0;
      *(_WORD *)(v59 + 16) = 256;
      swift_storeEnumTagMultiPayload(v59, v79, 0);
      uint64_t v60 = v57[8];
      uint64_t v82 = (void *)(v58 + v60);
      *(_OWORD *)(v58 + v60 + 16) = 0;
      *(_OWORD *)(v58 + v60) = 0;
      *(void *)(v58 + v60 + 32) = 6;
      *(__m128 *)(v58 + v60 + 40) = _mm_loadh_ps((const double *)&qword_346D50);
      *(void *)(v58 + v60 + 56) = 42;
      uint64_t v61 = (uint64_t)v77;
      outlined init with copy of MLTrainingSessionParameters(v59, (uint64_t)v77, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
      v65[3] = v79;
      boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v65);
      outlined init with take of MLClassifierMetrics(v61, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
      outlined assign with take of Any?((uint64_t)v65, (uint64_t)v82);
      outlined destroy of MLActivityClassifier.ModelParameters(v59, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
      uint64_t v63 = v57[6];
      *(void *)(v58 + v63) = 0;
      *(void *)(v58 + v63 + 8) = 0xE000000000000000;
      outlined destroy of MLActivityClassifier.ModelParameters(v86, type metadata accessor for MLCheckpoint);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v84, type metadata accessor for TreeRegressorModel);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v87, type metadata accessor for TreeRegressor);
      uint64_t result = v57[7];
      *(void *)(v58 + result) = _swiftEmptyArrayStorage;
      return result;
    }
    outlined destroy of MLActivityClassifier.ModelParameters(v42, type metadata accessor for MLCheckpoint);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v31, type metadata accessor for TreeRegressor);
    uint64_t v44 = v83;
    uint64_t v45 = v80;
    uint64_t v26 = v85;
  }
  else
  {
    uint64_t v46 = v85;
    swift_allocError(&type metadata for MLCreateError, v85, 0, 0);
    *(void *)uint64_t v47 = 0xD000000000000042;
    *(void *)(v47 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
    *(_OWORD *)(v47 + 16) = 0;
    *(_OWORD *)(v47 + 32) = 0;
    *(unsigned char *)(v47 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v46, v47, v48, v49, v50);
    outlined destroy of MLActivityClassifier.ModelParameters(v86, type metadata accessor for MLCheckpoint);
    uint64_t v44 = v83;
    uint64_t v45 = v80;
  }
  outlined consume of Result<(Int, Int), Error>(*(void *)(v44 + v26), *(void *)(v44 + v26 + 8), *(_DWORD *)(v44 + v26 + 16));
  return outlined consume of Result<(Int, Int), Error>(*(void *)(v44 + v45), *(void *)(v44 + v45 + 8), *(_DWORD *)(v44 + v45 + 16));
}

void *static MLDecisionTreeRegressor.train(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v21 = a6;
  uint64_t v22 = a5;
  uint64_t v23 = a4;
  uint64_t v24 = a3;
  uint64_t v25 = a2;
  uint64_t v7 = type metadata accessor for DataFrame(0);
  uint64_t v8 = *(void *)(v7 - 8);
  int64_t v9 = *(void *)(v8 + 64);
  Swift::String v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  char v12 = *(unsigned char *)(a1 + 8);
  uint64_t v19 = *(void *)a1;
  char v20 = v12;
  outlined copy of Result<_DataTable, Error>(v19, v12);
  DataFrame.init(_:)((uint64_t)&v19);
  uint64_t v13 = static MLDecisionTreeRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v19, v25, v24, v23, v22, v21);
  uint64_t v14 = v7;
  if (v6) {
    return (void *)(*(uint64_t (**)(uint64_t *, uint64_t))(v8 + 8))(&v19, v7);
  }
  uint64_t v16 = v13;
  (*(void (**)(uint64_t *, uint64_t))(v8 + 8))(&v19, v14);
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLDecisionTreeRegressor>);
  uint64_t v18 = (void *)swift_allocObject(v17, *(unsigned int *)(v17 + 48), *(unsigned __int16 *)(v17 + 52));
  return specialized MLJob.init(_:)(v18, v16);
}

uint64_t static MLDecisionTreeRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v16 = a6;
  uint64_t v17 = a5;
  uint64_t v18 = a4;
  uint64_t v19 = a3;
  uint64_t v7 = type metadata accessor for DataFrame(0);
  uint64_t v20 = *(void *)(v7 - 8);
  int64_t v8 = *(void *)(v20 + 64);
  int64_t v9 = alloca(v8);
  Swift::String v10 = alloca(v8);
  char v11 = *(unsigned char *)(a1 + 8);
  uint64_t v14 = *(void *)a1;
  char v15 = v11;
  outlined copy of Result<_DataTable, Error>(v14, v11);
  DataFrame.init(_:)((uint64_t)&v14);
  uint64_t v12 = static MLDecisionTreeRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)((void (*)(uint64_t *, uint64_t, uint64_t))&v14, a2, v19, v18, v17, v16);
  (*(void (**)(uint64_t *, uint64_t))(v20 + 8))(&v14, v7);
  return v12;
}

void *static MLDecisionTreeRegressor.resume(_:)(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLDecisionTreeRegressor>);
  uint64_t v2 = (void *)swift_allocObject(v1, *(unsigned int *)(v1 + 48), *(unsigned __int16 *)(v1 + 52));
  swift_retain();
  return specialized MLJob.init(_:)(v2, a1);
}

void *static MLDecisionTreeRegressor.train(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(void (*a1)(uint64_t *, uint64_t, uint64_t), uint64_t a2, void *a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t result = (void *)static MLDecisionTreeRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(a1, a2, a3, a4, a5, a6);
  if (!v6)
  {
    uint64_t v8 = (uint64_t)result;
    uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLJob<MLDecisionTreeRegressor>);
    Swift::String v10 = (void *)swift_allocObject(v9, *(unsigned int *)(v9 + 48), *(unsigned __int16 *)(v9 + 52));
    return specialized MLJob.init(_:)(v10, v8);
  }
  return result;
}

uint64_t static MLDecisionTreeRegressor.makeTrainingSession(trainingData:targetColumn:featureColumns:parameters:sessionParameters:)(void (*a1)(uint64_t *, uint64_t, uint64_t), uint64_t a2, void *a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v62 = v6;
  uint64_t v59 = a6;
  uint64_t v56 = a4;
  char v57 = a3;
  uint64_t v50 = a2;
  uint64_t v63 = a1;
  int64_t v8 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  uint64_t v9 = alloca(v8);
  Swift::String v10 = alloca(v8);
  uint64_t v54 = &v42;
  char v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v51 = &v42;
  int64_t v13 = *(void *)(*(void *)(type metadata accessor for BoostedTreeConfiguration(0) - 8) + 64);
  uint64_t v14 = alloca(v13);
  char v15 = alloca(v13);
  uint64_t v52 = &v42;
  uint64_t v64 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData(0);
  int64_t v16 = *(void *)(*(void *)(v64 - 8) + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
  int64_t v20 = *(void *)(*(void *)(v19 - 8) + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v61 = &v42;
  uint64_t v23 = alloca(v20);
  uint64_t v24 = alloca(v20);
  uint64_t v60 = &v42;
  uint64_t v25 = alloca(v20);
  uint64_t v26 = alloca(v20);
  uint64_t v65 = &v42;
  uint64_t v53 = a5;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a5, (uint64_t)&v42, &demangling cache variable for type metadata for Any?);
  if (!v43) {
    BUG();
  }
  uint64_t v58 = v19;
  uint64_t v27 = (uint64_t)v65;
  uint64_t v28 = (uint64_t)v65 + *(int *)(v19 + 48);
  outlined init with take of Any(&v42, &v44);
  swift_dynamicCast(&v42, &v44, (char *)&type metadata for Any + 8, v64, 7);
  uint64_t v29 = v62;
  MLDecisionTreeRegressor.ModelParameters.ValidationData.generateDataFrames(trainingData:)(v27, v28, v63);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v42, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  if (!v29)
  {
    uint64_t v55 = 0;
    uint64_t v30 = (uint64_t)v60 + *(int *)(v58 + 48);
    uint64_t v31 = (void (*)(uint64_t *, uint64_t, uint64_t))type metadata accessor for DataFrame(0);
    uint64_t v64 = *((void *)v31 - 1);
    unint64_t v32 = *(void (**)(long long *, long long *, void))(v64 + 16);
    v32(v60, v65, v31);
    uint64_t v62 = v30;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v28, v30, &demangling cache variable for type metadata for DataFrame?);
    uint64_t v33 = (uint64_t)v61 + *(int *)(v58 + 48);
    uint64_t v63 = v31;
    v32(v61, v65, v31);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v28, v33, &demangling cache variable for type metadata for DataFrame?);
    outlined init with copy of MLDecisionTreeRegressor.ModelParameters(v53, (uint64_t)&v44);
    swift_bridgeObjectRetain(v56);
    swift_bridgeObjectRetain((_BYTE)v57);
    uint64_t v34 = (uint64_t)v52;
    BoostedTreeConfiguration.init()();
    BoostedTreeConfiguration.maximumIterations.setter(1);
    BoostedTreeConfiguration.learningRate.setter(1.0);
    BoostedTreeConfiguration.maximumDepth.setter(v46);
    BoostedTreeConfiguration.minimumLossReduction.setter(v47);
    BoostedTreeConfiguration.minimumChildWeight.setter(v48);
    BoostedTreeConfiguration.randomSeed.setter(v49);
    outlined destroy of MLDecisionTreeRegressor.ModelParameters((uint64_t)&v44);
    uint64_t v35 = (uint64_t)v51;
    outlined init with copy of MLTrainingSessionParameters(v59, (uint64_t)v51, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v28 = type metadata accessor for TreeRegressorTrainingSessionDelegate(0);
    swift_allocObject(v28, *(unsigned int *)(v28 + 48), *(unsigned __int16 *)(v28 + 52));
    uint64_t v36 = v55;
    uint64_t v37 = TreeRegressorTrainingSessionDelegate.init(trainingData:validationData:targetColumn:featureColumns:configuration:sessionParameters:)((uint64_t)v60, v33, v50, v57, v56, v34, v35);
    if (v36)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v65, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      (*(void (**)(long long *, void (*)(uint64_t *, uint64_t, uint64_t)))(v64 + 8))(v61, v63);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for DataFrame?);
    }
    else
    {
      uint64_t v38 = v37;
      (*(void (**)(long long *, void (*)(uint64_t *, uint64_t, uint64_t)))(v64 + 8))(v61, v63);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v62, &demangling cache variable for type metadata for DataFrame?);
      uint64_t v45 = v28;
      uint64_t v46 = &protocol witness table for TreeRegressorTrainingSessionDelegate;
      *(void *)&long long v44 = v38;
      uint64_t v39 = (uint64_t)v54;
      outlined init with copy of MLTrainingSessionParameters(v59, (uint64_t)v54, type metadata accessor for MLTrainingSessionParameters);
      uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>);
      swift_allocObject(v40, *(unsigned int *)(v40 + 48), *(unsigned __int16 *)(v40 + 52));
      swift_retain();
      uint64_t v28 = specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)&v44, v39, 2);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v65, &demangling cache variable for type metadata for (training: DataFrame, validation: DataFrame?));
      swift_release();
    }
  }
  return v28;
}

uint64_t static MLDecisionTreeRegressor.restoreTrainingSession(sessionParameters:)(uint64_t a1)
{
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  uint64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  uint64_t v12 = v11;
  uint64_t v5 = alloca(v2);
  uint64_t v6 = alloca(v2);
  outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v11, type metadata accessor for MLTrainingSessionParameters);
  uint64_t v7 = type metadata accessor for TreeRegressorTrainingSessionDelegate(0);
  swift_allocObject(v7, *(unsigned int *)(v7 + 48), *(unsigned __int16 *)(v7 + 52));
  uint64_t result = TreeRegressorTrainingSessionDelegate.init(sessionParameters:)((uint64_t)v11);
  if (!v1)
  {
    v11[3] = v7;
    v11[4] = &protocol witness table for TreeRegressorTrainingSessionDelegate;
    v11[0] = result;
    uint64_t v9 = (uint64_t)v12;
    outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v12, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLTrainingSession<MLDecisionTreeRegressor>);
    swift_allocObject(v10, *(unsigned int *)(v10 + 48), *(unsigned __int16 *)(v10 + 52));
    return specialized MLTrainingSession.init(delegate:parameters:modelType:)((uint64_t)v11, v9, 2);
  }
  return result;
}

uint64_t closure #1 in closure #1 in static MLDecisionTreeRegressor.resume(_:)(uint64_t a1, char a2, uint64_t a3, void (*a4)(uint64_t *), uint64_t a5)
{
  uint64_t v22 = a5;
  uint64_t v23 = a4;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLDecisionTreeRegressor, Error>);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TaskPriority?)
                              - 8)
                  + 64);
  char v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  if (a2)
  {
    uint64_t v19 = a1;
    swift_storeEnumTagMultiPayload(&v19, v6, 1);
    swift_errorRetain(a1);
    v23(&v19);
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v19, &demangling cache variable for type metadata for Result<MLDecisionTreeRegressor, Error>);
  }
  else
  {
    outlined init with copy of TabularRegressionTask(direct field offset for MLTrainingSession.delegate + a3, (uint64_t)v20);
    uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingSessionDelegate);
    uint64_t v14 = type metadata accessor for TreeRegressorTrainingSessionDelegate(0);
    swift_dynamicCast(&v21, v20, v13, v14, 7);
    uint64_t v15 = v21;
    uint64_t v16 = type metadata accessor for TaskPriority(0);
    __swift_storeEnumTagSinglePayload((uint64_t)&v19, 1, 1, v16);
    uint64_t v17 = swift_allocObject(&unk_398E98, 56, 7);
    *(_OWORD *)(v17 + 16) = 0;
    *(void *)(v17 + 32) = v15;
    *(void *)(v17 + 40) = v23;
    *(void *)(v17 + 48) = v22;
    swift_retain();
    _sScTss5NeverORs_rlE8priority9operationScTyxABGScPSg_xyYaYAcntcfCyt_Tgm5((uint64_t)&v19, (uint64_t)&async function pointer to partial apply for closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:), v17);
    return swift_release();
  }
}

uint64_t closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  v6[4] = a6;
  v6[3] = a5;
  v6[2] = a4;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLDecisionTreeRegressor, Error>);
  void v6[5] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:), 0, 0);
}

uint64_t closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:)()
{
  uint64_t v1 = (char *)&async function pointer to specialized Result<>.init(catching:)
     + async function pointer to specialized Result<>.init(catching:);
  uint64_t v2 = dword_3AE66C;
  swift_retain();
  uint64_t v3 = (void *)swift_task_alloc(v2);
  v0[6] = v3;
  *uint64_t v3 = v0;
  v3[1] = closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:);
  return ((uint64_t (*)(void, void))v1)(v0[5], v0[2]);
}

{
  uint64_t v0;

  swift_task_dealloc(*(void *)(*(void *)v0 + 48));
  return swift_task_switch(closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:), 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;

  uint64_t v1 = *(void *)(v0 + 40);
  (*(void (**)(uint64_t))(v0 + 24))(v1);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, &demangling cache variable for type metadata for Result<MLDecisionTreeRegressor, Error>);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLDecisionTreeRegressor.init(delegate:)(uint64_t a1, uint64_t a2)
{
  v2[30] = a2;
  v2[29] = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TreeRegressorModel?);
  v2[31] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLDecisionTreeRegressor(0);
  v2[32] = v4;
  v2[33] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLDecisionTreeRegressor.ModelParameters.ValidationData?);
  v2[34] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData(0);
  v2[35] = v6;
  v2[36] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  v2[37] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = type metadata accessor for BoostedTreeConfiguration(0);
  v2[38] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v2[39] = v9;
  v2[40] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  v2[41] = swift_task_alloc((*(void *)(*(void *)(v10 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = type metadata accessor for PersistentParametersForTreeBasedMethods(0);
  v2[42] = v11;
  v2[43] = swift_task_alloc((*(void *)(*(void *)(v11 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLDecisionTreeRegressor.init(delegate:), 0, 0);
}

uint64_t MLDecisionTreeRegressor.init(delegate:)()
{
  uint64_t v1 = *(void *)(v0 + 336);
  uint64_t v2 = *(void *)(v0 + 328);
  uint64_t v3 = OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_trainingParameters + *(void *)(v0 + 240);
  swift_beginAccess(v3, v0 + 176, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v3, v2, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1) {
    BUG();
  }
  uint64_t v22 = v0 + 16;
  uint64_t v23 = (void *)(v0 + 144);
  uint64_t v4 = *(void *)(v0 + 344);
  uint64_t v5 = *(void *)(v0 + 336);
  uint64_t v6 = *(void *)(v0 + 320);
  uint64_t v32 = *(void *)(v0 + 312);
  uint64_t v7 = *(void *)(v0 + 304);
  uint64_t v30 = *(void *)(v0 + 296);
  uint64_t v28 = *(void *)(v0 + 272);
  uint64_t v26 = *(void *)(v0 + 280);
  outlined init with take of MLClassifierMetrics(*(void *)(v0 + 328), v4, type metadata accessor for PersistentParametersForTreeBasedMethods);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v32 + 16))(v6, v4 + *(int *)(v5 + 32), v7);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v4 + *(int *)(v5 + 20), v30, &demangling cache variable for type metadata for DataFrame?);
  *(_OWORD *)(v0 + 16) = 0;
  *(_OWORD *)(v0 + 32) = 0;
  *(void *)(v0 + 48) = BoostedTreeConfiguration.maximumDepth.getter();
  *(double *)(v0 + 56) = BoostedTreeConfiguration.minimumLossReduction.getter();
  *(double *)(v0 + 64) = BoostedTreeConfiguration.minimumChildWeight.getter();
  *(void *)(v0 + 72) = BoostedTreeConfiguration.randomSeed.getter();
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML23MLDecisionTreeRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML23ijk3V15lm75V13configuration10validationAE0A12MLComponents07BoostedD13ConfigurationV_11c7Data0N5e12VSgtcfcAE010N21N0OAMcAPmcfu_ApMcfu0_AOXMtTf1ncn_n(v30);
  if (__swift_getEnumTagSinglePayload(v28, 1, v26) == 1)
  {
    uint64_t v8 = *(void *)(v0 + 272);
    swift_storeEnumTagMultiPayload(*(void *)(v0 + 288), *(void *)(v0 + 280), 3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v8, &demangling cache variable for type metadata for MLDecisionTreeRegressor.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 272), *(void *)(v0 + 288), type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  }
  uint64_t v9 = *(void *)(v0 + 344);
  uint64_t v27 = *(void *)(v0 + 336);
  uint64_t v31 = *(void *)(v0 + 320);
  uint64_t v29 = *(void *)(v0 + 312);
  uint64_t v33 = *(void *)(v0 + 304);
  uint64_t v21 = *(void *)(v0 + 296);
  uint64_t v10 = *(void *)(v0 + 288);
  uint64_t v11 = *(void *)(v0 + 240);
  uint64_t v25 = *(void *)(v0 + 248);
  *(void *)(v0 + 168) = *(void *)(v0 + 280);
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v23);
  outlined init with take of MLClassifierMetrics(v10, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  outlined assign with take of Any?((uint64_t)v23, v22);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v21, &demangling cache variable for type metadata for DataFrame?);
  (*(void (**)(uint64_t, uint64_t))(v29 + 8))(v31, v33);
  uint64_t v13 = *(int *)(v27 + 24);
  uint64_t v24 = *(void *)(v9 + v13);
  uint64_t v14 = *(void *)(v9 + v13 + 8);
  uint64_t v15 = *(void *)(v9 + *(int *)(v27 + 28));
  uint64_t v16 = OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_model + v11;
  swift_beginAccess(v16, v0 + 200, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v16, v25, &demangling cache variable for type metadata for TreeRegressorModel?);
  uint64_t v17 = type metadata accessor for TreeRegressorModel(0);
  if (__swift_getEnumTagSinglePayload(v25, 1, v17) == 1) {
    BUG();
  }
  outlined init with copy of MLDecisionTreeRegressor.ModelParameters(v22, v0 + 80);
  uint64_t v18 = dword_3A7144;
  swift_bridgeObjectRetain(v14);
  swift_bridgeObjectRetain(v15);
  uint64_t v19 = (void *)swift_task_alloc(v18);
  *(void *)(v0 + 352) = v19;
  *uint64_t v19 = v0;
  v19[1] = MLDecisionTreeRegressor.init(delegate:);
  return MLDecisionTreeRegressor.init(_:targetColumn:featureColumns:parameters:)(*(void *)(v0 + 264), *(void *)(v0 + 248), v24, v14, v15, v0 + 80);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 352);
  *(void *)(*(void *)v1 + 360) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLDecisionTreeRegressor.init(delegate:);
  }
  else {
    uint64_t v3 = MLDecisionTreeRegressor.init(delegate:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  char v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;

  uint64_t v1 = *(void *)(v0 + 240);
  outlined init with take of MLClassifierMetrics(*(void *)(v0 + 264), *(void *)(v0 + 232), type metadata accessor for MLDecisionTreeRegressor);
  uint64_t v2 = *(unsigned char *)(v1 + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_trainingMetrics + 16);
  if (v2 == -1) {
    BUG();
  }
  uint64_t v15 = *(void *)(v0 + 344);
  uint64_t v18 = *(void *)(v0 + 256);
  uint64_t v3 = *(void *)(v0 + 232);
  uint64_t v4 = *(void *)(v0 + 240);
  int64_t v20 = *(void *)(v1 + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_trainingMetrics);
  uint64_t v16 = *(void *)(v1 + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_trainingMetrics + 8);
  outlined copy of Result<_RegressorMetrics, Error>(v20, v16, v2);
  outlined destroy of MLDecisionTreeRegressor.ModelParameters(v0 + 16);
  outlined destroy of MLActivityClassifier.ModelParameters(v15, type metadata accessor for PersistentParametersForTreeBasedMethods);
  uint64_t v5 = *(int *)(v18 + 36);
  outlined consume of Result<(Int, Int), Error>(*(void *)(v3 + v5), *(void *)(v3 + v5 + 8), *(_DWORD *)(v3 + v5 + 16));
  *(void *)(v3 + v5) = v20;
  *(void *)(v3 + v5 + 8) = v16;
  *(unsigned char *)(v3 + v5 + 16) = v2 & 1;
  uint64_t v6 = *(void *)(v4 + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_validationMetrics + 8);
  uint64_t v7 = *(unsigned char *)(v4 + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_validationMetrics + 16);
  uint64_t v21 = *(void *)(v4 + OBJC_IVAR____TtC8CreateML36TreeRegressorTrainingSessionDelegate_validationMetrics);
  outlined copy of MLRegressorMetrics?(v21, v6, v7);
  swift_release();
  if (v7 != -1)
  {
    uint64_t v8 = *(void *)(v0 + 232);
    uint64_t v9 = *(int *)(*(void *)(v0 + 256) + 40);
    outlined consume of Result<(Int, Int), Error>(*(void *)(v8 + v9), *(void *)(v8 + v9 + 8), *(_DWORD *)(v8 + v9 + 16));
    *(void *)(v8 + v9) = v21;
    *(void *)(v8 + v9 + 8) = v6;
    *(unsigned char *)(v8 + v9 + 16) = v7 & 1;
  }
  uint64_t v10 = *(void *)(v0 + 328);
  uint64_t v11 = *(void *)(v0 + 320);
  uint64_t v12 = *(void *)(v0 + 296);
  uint64_t v13 = *(void *)(v0 + 288);
  uint64_t v19 = *(void *)(v0 + 272);
  uint64_t v22 = *(void *)(v0 + 248);
  uint64_t v17 = *(void *)(v0 + 264);
  swift_task_dealloc(*(void *)(v0 + 344));
  swift_task_dealloc(v10);
  swift_task_dealloc(v11);
  swift_task_dealloc(v12);
  swift_task_dealloc(v13);
  swift_task_dealloc(v19);
  swift_task_dealloc(v17);
  swift_task_dealloc(v22);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;

  uint64_t v1 = *(void *)(v0 + 344);
  uint64_t v2 = *(void *)(v0 + 328);
  uint64_t v3 = *(void *)(v0 + 320);
  uint64_t v9 = *(void *)(v0 + 296);
  uint64_t v8 = *(void *)(v0 + 288);
  uint64_t v7 = *(void *)(v0 + 272);
  uint64_t v6 = *(void *)(v0 + 264);
  uint64_t v5 = *(void *)(v0 + 248);
  swift_release();
  outlined destroy of MLDecisionTreeRegressor.ModelParameters(v0 + 16);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for PersistentParametersForTreeBasedMethods);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  swift_task_dealloc(v5);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLDecisionTreeRegressor()
{
  return MLDecisionTreeRegressor.description.getter();
}

unint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLDecisionTreeRegressor()
{
  return MLDecisionTreeRegressor.debugDescription.getter();
}

NSAttributedString protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLDecisionTreeRegressor()
{
  return MLDecisionTreeRegressor.playgroundDescription.getter();
}

uint64_t protocol witness for TabularRegressionTask.validationMetrics.getter in conformance MLDecisionTreeRegressor()
{
  return MLDecisionTreeRegressor.validationMetrics.getter();
}

uint64_t type metadata accessor for NSAttributedString()
{
  uint64_t result = lazy cache variable for type metadata for NSAttributedString;
  if (!lazy cache variable for type metadata for NSAttributedString)
  {
    uint64_t v1 = objc_opt_self(NSAttributedString);
    uint64_t result = swift_getObjCClassMetadata(v1);
    lazy cache variable for type metadata for NSAttributedString = result;
  }
  return result;
}

uint64_t outlined init with copy of MLDecisionTreeRegressor.ModelParameters(uint64_t a1, uint64_t a2)
{
  (*(void (**)(uint64_t, uint64_t))(*((void *)&type metadata for MLDecisionTreeRegressor.ModelParameters - 1)
                                           + 16))(a2, a1);
  return a2;
}

uint64_t outlined destroy of MLDecisionTreeRegressor.ModelParameters(uint64_t a1)
{
  return a1;
}

uint64_t sub_E8292()
{
  return objectdestroyTm();
}

uint64_t partial apply for closure #1 in MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(uint64_t a1)
{
  type metadata accessor for TreeRegressorModel(0);
  uint64_t v2 = (void *)swift_task_alloc(dword_3A7044);
  *(void *)(v1 + 16) = v2;
  *uint64_t v2 = v1;
  v2[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)(a1);
}

uint64_t sub_E8313()
{
  return objectdestroyTm();
}

uint64_t partial apply for closure #1 in MLDecisionTreeRegressor.init(checkpoint:)(uint64_t a1)
{
  type metadata accessor for TreeRegressorModel(0);
  uint64_t v2 = (void *)swift_task_alloc(dword_3A7054);
  *(void *)(v1 + 16) = v2;
  *uint64_t v2 = v1;
  v2[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLRandomForestRegressor.init(checkpoint:)(a1);
}

id sub_E83A6()
{
  uint64_t v1 = v0;
  id result = MLDecisionTreeRegressor.model.getter();
  *uint64_t v1 = result;
  return result;
}

void sub_E83C0(id *a1)
{
}

void *initializeBufferWithCopyOfBuffer for MLDecisionTreeRegressor(void *a1, void *a2, int *a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v8 = *a2;
    *uint64_t v3 = *a2;
    uint64_t v3 = (void *)(v8 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    *a1 = *a2;
    uint64_t v5 = a2[1];
    v3[1] = v5;
    uint64_t v6 = a2[2];
    swift_bridgeObjectRetain(v5);
    if (v6)
    {
      v3[2] = v6;
      v3[3] = a2[3];
      uint64_t v7 = a2[4];
      v3[4] = v7;
      swift_bridgeObjectRetain(v6);
      swift_bridgeObjectRetain(v7);
    }
    else
    {
      v3[4] = a2[4];
      *((_OWORD *)v3 + 1) = *((_OWORD *)a2 + 1);
    }
    uint64_t v9 = *(int *)(type metadata accessor for TreeRegressorModel(0) + 24);
    uint64_t v10 = type metadata accessor for BaseTreeRegressorModel(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 16))((char *)v3 + v9, (char *)a2 + v9, v10);
    uint64_t v11 = a3[5];
    uint64_t v12 = *(void **)((char *)a2 + v11);
    *(void *)((char *)v3 + v11) = v12;
    uint64_t v13 = a3[6];
    *(void *)((char *)v3 + v13) = *(void *)((char *)a2 + v13);
    uint64_t v14 = *(void *)((char *)a2 + v13 + 8);
    *(void *)((char *)v3 + v13 + 8) = v14;
    uint64_t v15 = a3[7];
    uint64_t v29 = *(void *)((char *)a2 + v15);
    *(void *)((char *)v3 + v15) = v29;
    uint64_t v16 = a3[8];
    uint64_t v17 = (char *)v3 + v16;
    uint64_t v31 = (_OWORD *)((char *)a2 + v16);
    uint64_t v18 = *(void *)((char *)a2 + v16 + 24);
    v12;
    swift_bridgeObjectRetain(v14);
    swift_bridgeObjectRetain(v29);
    if (v18)
    {
      *((void *)v17 + 3) = v18;
      uint64_t v19 = v31;
      (**(void (***)(char *, _OWORD *, uint64_t))(v18 - 8))(v17, v31, v18);
    }
    else
    {
      uint64_t v19 = v31;
      long long v20 = *v31;
      *((_OWORD *)v17 + 1) = v31[1];
      *(_OWORD *)uint64_t v17 = v20;
    }
    *((_OWORD *)v17 + 2) = v19[2];
    *((_OWORD *)v17 + 3) = v19[3];
    uint64_t v21 = a3[9];
    uint64_t v22 = *(void *)((char *)a2 + v21);
    uint64_t v23 = *(void *)((char *)a2 + v21 + 8);
    char v32 = *((unsigned char *)a2 + v21 + 16);
    outlined copy of Result<_RegressorMetrics, Error>(v22, v23, v32);
    *(void *)((char *)v3 + v21) = v22;
    *(void *)((char *)v3 + v21 + 8) = v23;
    *((unsigned char *)v3 + v21 + 16) = v32;
    uint64_t v24 = a3[10];
    uint64_t v25 = *(void *)((char *)a2 + v24);
    uint64_t v26 = *(void *)((char *)a2 + v24 + 8);
    char v27 = *((unsigned char *)a2 + v24 + 16);
    outlined copy of Result<_RegressorMetrics, Error>(v25, v26, v27);
    *(void *)((char *)v3 + v24) = v25;
    *(void *)((char *)v3 + v24 + 8) = v26;
    *((unsigned char *)v3 + v24 + 16) = v27;
  }
  return v3;
}

void *initializeWithCopy for MLDecisionTreeRegressor(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v4 = a2[1];
  a1[1] = v4;
  uint64_t v5 = a2[2];
  swift_bridgeObjectRetain(v4);
  if (v5)
  {
    a1[2] = v5;
    a1[3] = a2[3];
    uint64_t v6 = a2[4];
    a1[4] = v6;
    swift_bridgeObjectRetain(v5);
    swift_bridgeObjectRetain(v6);
  }
  else
  {
    a1[4] = a2[4];
    *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
  }
  uint64_t v7 = *(int *)(type metadata accessor for TreeRegressorModel(0) + 24);
  uint64_t v8 = type metadata accessor for BaseTreeRegressorModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 16))((char *)a1 + v7, (char *)a2 + v7, v8);
  uint64_t v9 = a3[5];
  uint64_t v10 = *(void **)((char *)a2 + v9);
  *(void *)((char *)a1 + v9) = v10;
  uint64_t v11 = a3[6];
  *(void *)((char *)a1 + v11) = *(void *)((char *)a2 + v11);
  uint64_t v12 = *(void *)((char *)a2 + v11 + 8);
  *(void *)((char *)a1 + v11 + 8) = v12;
  uint64_t v13 = a3[7];
  uint64_t v27 = *(void *)((char *)a2 + v13);
  *(void *)((char *)a1 + v13) = v27;
  uint64_t v14 = a3[8];
  uint64_t v15 = (char *)a1 + v14;
  uint64_t v29 = (_OWORD *)((char *)a2 + v14);
  uint64_t v16 = *(void *)((char *)a2 + v14 + 24);
  v10;
  swift_bridgeObjectRetain(v12);
  swift_bridgeObjectRetain(v27);
  if (v16)
  {
    *((void *)v15 + 3) = v16;
    uint64_t v17 = v29;
    (**(void (***)(char *, _OWORD *, uint64_t))(v16 - 8))(v15, v29, v16);
  }
  else
  {
    uint64_t v17 = v29;
    long long v18 = *v29;
    *((_OWORD *)v15 + 1) = v29[1];
    *(_OWORD *)uint64_t v15 = v18;
  }
  *((_OWORD *)v15 + 2) = v17[2];
  *((_OWORD *)v15 + 3) = v17[3];
  uint64_t v19 = a3[9];
  uint64_t v20 = *(void *)((char *)a2 + v19);
  uint64_t v21 = *(void *)((char *)a2 + v19 + 8);
  char v30 = *((unsigned char *)a2 + v19 + 16);
  outlined copy of Result<_RegressorMetrics, Error>(v20, v21, v30);
  *(void *)((char *)a1 + v19) = v20;
  *(void *)((char *)a1 + v19 + 8) = v21;
  *((unsigned char *)a1 + v19 + 16) = v30;
  uint64_t v22 = a3[10];
  uint64_t v23 = *(void *)((char *)a2 + v22);
  uint64_t v24 = *(void *)((char *)a2 + v22 + 8);
  char v25 = *((unsigned char *)a2 + v22 + 16);
  outlined copy of Result<_RegressorMetrics, Error>(v23, v24, v25);
  *(void *)((char *)a1 + v22) = v23;
  *(void *)((char *)a1 + v22 + 8) = v24;
  *((unsigned char *)a1 + v22 + 16) = v25;
  return a1;
}

void *assignWithCopy for MLDecisionTreeRegressor(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v4 = a2[1];
  uint64_t v5 = a1[1];
  a1[1] = v4;
  swift_bridgeObjectRetain(v4);
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = a1 + 2;
  uint64_t v7 = a2 + 2;
  uint64_t v8 = a1[2];
  uint64_t v9 = a2[2];
  if (v8)
  {
    if (v9)
    {
      a1[2] = v9;
      swift_bridgeObjectRetain(v9);
      swift_bridgeObjectRelease(v8);
      a1[3] = a2[3];
      uint64_t v10 = a2[4];
      uint64_t v11 = a1[4];
      a1[4] = v10;
      swift_bridgeObjectRetain(v10);
      swift_bridgeObjectRelease(v11);
    }
    else
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)(a1 + 2), &demangling cache variable for type metadata for FeatureVectorizer<Float>.Transformer);
      _OWORD *v6 = *v7;
      a1[4] = a2[4];
    }
  }
  else if (v9)
  {
    a1[2] = v9;
    a1[3] = a2[3];
    uint64_t v12 = a2[4];
    a1[4] = v12;
    swift_bridgeObjectRetain(v9);
    swift_bridgeObjectRetain(v12);
  }
  else
  {
    a1[4] = a2[4];
    _OWORD *v6 = *v7;
  }
  uint64_t v13 = *(int *)(type metadata accessor for TreeRegressorModel(0) + 24);
  uint64_t v14 = type metadata accessor for BaseTreeRegressorModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 24))((char *)a1 + v13, (char *)a2 + v13, v14);
  uint64_t v15 = a3[5];
  uint64_t v16 = *(void **)((char *)a2 + v15);
  uint64_t v17 = *(void **)((char *)a1 + v15);
  *(void *)((char *)a1 + v15) = v16;
  v16;

  uint64_t v18 = a3[6];
  *(void *)((char *)a1 + v18) = *(void *)((char *)a2 + v18);
  uint64_t v19 = *(void *)((char *)a2 + v18 + 8);
  uint64_t v20 = *(void *)((char *)a1 + v18 + 8);
  *(void *)((char *)a1 + v18 + 8) = v19;
  swift_bridgeObjectRetain(v19);
  swift_bridgeObjectRelease(v20);
  uint64_t v21 = a3[7];
  uint64_t v22 = *(void *)((char *)a2 + v21);
  uint64_t v23 = *(void *)((char *)a1 + v21);
  *(void *)((char *)a1 + v21) = v22;
  swift_bridgeObjectRetain(v22);
  swift_bridgeObjectRelease(v23);
  uint64_t v24 = a3[8];
  char v25 = (char *)a1 + v24;
  uint64_t v26 = (char *)a2 + v24;
  uint64_t v27 = *(void *)((char *)a2 + v24 + 24);
  if (!*(void *)((char *)a1 + v24 + 24))
  {
    if (v27)
    {
      *((void *)v25 + 3) = v27;
      (**(void (***)(char *, char *))(v27 - 8))(v25, v26);
      goto LABEL_15;
    }
LABEL_14:
    long long v30 = *(_OWORD *)v26;
    *((_OWORD *)v25 + 1) = *((_OWORD *)v26 + 1);
    *(_OWORD *)char v25 = v30;
    goto LABEL_15;
  }
  uint64_t v29 = (void *)((char *)a1 + v24);
  if (!v27)
  {
    __swift_destroy_boxed_opaque_existential_1Tm(v29);
    goto LABEL_14;
  }
  __swift_assign_boxed_opaque_existential_0(v29, (void *)((char *)a2 + v24));
LABEL_15:
  *((void *)v25 + 4) = *((void *)v26 + 4);
  *((void *)v25 + 5) = *((void *)v26 + 5);
  *((void *)v25 + 6) = *((void *)v26 + 6);
  *((void *)v25 + 7) = *((void *)v26 + 7);
  uint64_t v31 = a3[9];
  uint64_t v32 = *(void *)((char *)a2 + v31);
  uint64_t v33 = *(void *)((char *)a2 + v31 + 8);
  char v45 = *((unsigned char *)a2 + v31 + 16);
  outlined copy of Result<_RegressorMetrics, Error>(v32, v33, v45);
  uint64_t v34 = *(void *)((char *)a1 + v31);
  uint64_t v35 = *(void *)((char *)a1 + v31 + 8);
  *(void *)((char *)a1 + v31) = v32;
  *(void *)((char *)a1 + v31 + 8) = v33;
  int v36 = *(_DWORD *)((char *)a1 + v31 + 16);
  *((unsigned char *)a1 + v31 + 16) = v45;
  outlined consume of Result<(Int, Int), Error>(v34, v35, v36);
  uint64_t v37 = a3[10];
  uint64_t v38 = *(void *)((char *)a2 + v37);
  uint64_t v39 = *(void *)((char *)a2 + v37 + 8);
  char v40 = *((unsigned char *)a2 + v37 + 16);
  outlined copy of Result<_RegressorMetrics, Error>(v38, v39, v40);
  uint64_t v41 = *(void *)((char *)a1 + v37);
  uint64_t v42 = *(void *)((char *)a1 + v37 + 8);
  *(void *)((char *)a1 + v37) = v38;
  *(void *)((char *)a1 + v37 + 8) = v39;
  int v43 = *(_DWORD *)((char *)a1 + v37 + 16);
  *((unsigned char *)a1 + v37 + 16) = v40;
  outlined consume of Result<(Int, Int), Error>(v41, v42, v43);
  return a1;
}

uint64_t initializeWithTake for MLDecisionTreeRegressor(uint64_t a1, uint64_t a2, int *a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = *(_OWORD *)(a2 + 16);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v4 = *(int *)(type metadata accessor for TreeRegressorModel(0) + 24);
  uint64_t v5 = type metadata accessor for BaseTreeRegressorModel(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 32))(a1 + v4, a2 + v4, v5);
  *(void *)(a1 + a3[5]) = *(void *)(a2 + a3[5]);
  *(_OWORD *)(a1 + a3[6]) = *(_OWORD *)(a2 + a3[6]);
  *(void *)(a1 + a3[7]) = *(void *)(a2 + a3[7]);
  uint64_t v6 = a3[8];
  long long v7 = *(_OWORD *)(a2 + v6);
  long long v8 = *(_OWORD *)(a2 + v6 + 16);
  long long v9 = *(_OWORD *)(a2 + v6 + 32);
  *(_OWORD *)(a1 + v6 + 48) = *(_OWORD *)(a2 + v6 + 48);
  *(_OWORD *)(a1 + v6 + 32) = v9;
  *(_OWORD *)(a1 + v6 + 16) = v8;
  *(_OWORD *)(a1 + v6) = v7;
  uint64_t v10 = a3[9];
  *(_OWORD *)(a1 + v10) = *(_OWORD *)(a2 + v10);
  *(unsigned char *)(a1 + v10 + 16) = *(unsigned char *)(a2 + v10 + 16);
  uint64_t v11 = a3[10];
  *(_OWORD *)(a1 + v11) = *(_OWORD *)(a2 + v11);
  *(unsigned char *)(a1 + v11 + 16) = *(unsigned char *)(a2 + v11 + 16);
  return a1;
}

void *assignWithTake for MLDecisionTreeRegressor(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  uint64_t v6 = a1[1];
  a1[1] = a2[1];
  swift_bridgeObjectRelease(v6);
  long long v7 = a1 + 2;
  long long v8 = a2 + 2;
  uint64_t v9 = a1[2];
  if (v9)
  {
    uint64_t v10 = a2[2];
    if (v10)
    {
      a1[2] = v10;
      swift_bridgeObjectRelease(v9);
      a1[3] = a2[3];
      uint64_t v11 = a1[4];
      a1[4] = a2[4];
      swift_bridgeObjectRelease(v11);
    }
    else
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)(a1 + 2), &demangling cache variable for type metadata for FeatureVectorizer<Float>.Transformer);
      _OWORD *v7 = *v8;
      a1[4] = a2[4];
    }
  }
  else
  {
    a1[4] = a2[4];
    _OWORD *v7 = *v8;
  }
  uint64_t v12 = *(int *)(type metadata accessor for TreeRegressorModel(0) + 24);
  uint64_t v13 = type metadata accessor for BaseTreeRegressorModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v13 - 8) + 40))((char *)a1 + v12, (char *)a2 + v12, v13);
  uint64_t v14 = a3[5];
  uint64_t v15 = *(void **)((char *)a1 + v14);
  *(void *)((char *)a1 + v14) = *(void *)((char *)a2 + v14);

  uint64_t v16 = a3[6];
  *(void *)((char *)a1 + v16) = *(void *)((char *)a2 + v16);
  uint64_t v17 = *(void *)((char *)a1 + v16 + 8);
  *(void *)((char *)a1 + v16 + 8) = *(void *)((char *)a2 + v16 + 8);
  swift_bridgeObjectRelease(v17);
  uint64_t v18 = a3[7];
  uint64_t v19 = *(void *)((char *)a1 + v18);
  *(void *)((char *)a1 + v18) = *(void *)((char *)a2 + v18);
  swift_bridgeObjectRelease(v19);
  uint64_t v20 = a3[8];
  uint64_t v21 = (_OWORD *)((char *)a1 + v20);
  if (*(void *)((char *)a1 + v20 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)((char *)a1 + v20));
  }
  long long v22 = *(_OWORD *)((char *)a2 + v20);
  v21[1] = *(_OWORD *)((char *)a2 + v20 + 16);
  *uint64_t v21 = v22;
  *(void *)((char *)a1 + v20 + 32) = *(void *)((char *)a2 + v20 + 32);
  *(_OWORD *)((char *)a1 + v20 + 40) = *(_OWORD *)((char *)a2 + v20 + 40);
  *(void *)((char *)a1 + v20 + 56) = *(void *)((char *)a2 + v20 + 56);
  uint64_t v23 = a3[9];
  char v24 = *((unsigned char *)a2 + v23 + 16);
  uint64_t v25 = *(void *)((char *)a1 + v23);
  uint64_t v26 = *(void *)((char *)a1 + v23 + 8);
  *(_OWORD *)((char *)a1 + v23) = *(_OWORD *)((char *)a2 + v23);
  int v27 = *(_DWORD *)((char *)a1 + v23 + 16);
  *((unsigned char *)a1 + v23 + 16) = v24;
  outlined consume of Result<(Int, Int), Error>(v25, v26, v27);
  uint64_t v28 = a3[10];
  char v29 = *((unsigned char *)a2 + v28 + 16);
  uint64_t v30 = *(void *)((char *)a1 + v28);
  uint64_t v31 = *(void *)((char *)a1 + v28 + 8);
  *(_OWORD *)((char *)a1 + v28) = *(_OWORD *)((char *)a2 + v28);
  int v32 = *(_DWORD *)((char *)a1 + v28 + 16);
  *((unsigned char *)a1 + v28 + 16) = v29;
  outlined consume of Result<(Int, Int), Error>(v30, v31, v32);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLDecisionTreeRegressor(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_E8CF0);
}

uint64_t sub_E8CF0(uint64_t a1, unsigned int a2, uint64_t a3)
{
  unsigned int v4 = 0;
  uint64_t v5 = type metadata accessor for TreeRegressorModel(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(a1, a2, v5);
  }
  if ((*(void *)(a1 + *(int *)(a3 + 20)) & 0xFFFFFFFF00000001) == 0) {
    return (*(void *)(a1 + *(int *)(a3 + 20)) >> 1) + 1;
  }
  return v4;
}

uint64_t storeEnumTagSinglePayload for MLDecisionTreeRegressor(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_E8D6A);
}

uint64_t sub_E8D6A(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = type metadata accessor for TreeRegressorModel(0);
  if (*(_DWORD *)(*(void *)(v6 - 8) + 84) == a3) {
    return __swift_storeEnumTagSinglePayload(a1, a2, a2, v6);
  }
  uint64_t result = *(int *)(a4 + 20);
  *(void *)(a1 + result) = 2 * (a2 - 1);
  return result;
}

uint64_t type metadata completion function for MLDecisionTreeRegressor(uint64_t a1)
{
  uint64_t result = type metadata accessor for TreeRegressorModel(319);
  if (v2 <= 0x3F)
  {
    v3[0] = *(void *)(result - 8) + 64;
    v3[1] = (char *)&value witness table for Builtin.UnknownObject + 64;
    v3[2] = &unk_349D18;
    v3[3] = (char *)&value witness table for Builtin.BridgeObject + 64;
    v3[4] = &unk_349D30;
    v3[5] = &unk_349D48;
    v3[6] = &unk_349D48;
    swift_initStructMetadata(a1, 256, 7, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t sub_E8E5F()
{
  swift_unknownObjectRelease(v0[2]);
  swift_release(v0[4]);
  swift_release(v0[6]);
  return swift_deallocObject(v0, 56, 7);
}

uint64_t partial apply for closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:)(uint64_t a1)
{
  uint64_t v3 = v1[2];
  uint64_t v4 = v1[3];
  uint64_t v8 = v1[4];
  uint64_t v9 = v1[5];
  uint64_t v5 = v1[6];
  uint64_t v6 = (void *)swift_task_alloc(dword_3A7124);
  *(void *)(v2 + 16) = v6;
  void *v6 = v2;
  v6[1] = partial apply for specialized closure #1 in blockAwait<A>(_:);
  return closure #1 in static MLDecisionTreeRegressor.handleResult(_:session:fulfill:)(a1, v3, v4, v8, v9, v5);
}

uint64_t __swift_allocate_value_buffer(uint64_t a1, uint64_t *a2)
{
  uint64_t v2 = a2;
  uint64_t v3 = *(void *)(a1 - 8);
  int v4 = *(_DWORD *)(v3 + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v5 = swift_slowAlloc(*(void *)(v3 + 64), v4);
    *a2 = v5;
    return v5;
  }
  return (uint64_t)v2;
}

uint64_t closure #1 in MLDecisionTreeRegressor.init(trainingData:targetColumn:featureColumns:parameters:)()
{
  return closure #1 in MLRandomForestRegressor.init(checkpoint:)();
}

uint64_t SortedSet.init(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  *(void *)&long long v32 = a1;
  uint64_t v36 = a4;
  uint64_t v6 = type metadata accessor for Set(0, a2, a4);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for Set<A>, v6);
  *(void *)&long long v32 = Array.init<A>(_:)(&v32, a2, v6, WitnessTable);
  uint64_t v37 = a2;
  uint64_t v23 = a2;
  uint64_t v24 = a3;
  uint64_t v25 = a4;
  uint64_t v26 = a2;
  uint64_t v8 = type metadata accessor for Array(0, a2);
  uint64_t v38 = swift_getWitnessTable(&protocol conformance descriptor for [A], v8);
  uint64_t v9 = Sequence.sorted(by:)(partial apply for implicit closure #1 in SortedSet.init(_:), v22, v8, v38);
  swift_bridgeObjectRelease(v32);
  uint64_t v39 = v9;
  uint64_t v35 = v9;
  uint64_t v29 = v9;
  swift_bridgeObjectRetain(v9);
  uint64_t v10 = swift_getWitnessTable(&protocol conformance descriptor for [A], v8);
  RandomAccessCollection<>.indices.getter(v8, v10, &protocol witness table for Int);
  *(_OWORD *)uint64_t v31 = v32;
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Range<Int>);
  uint64_t v12 = lazy protocol witness table accessor for type Int and conformance Int();
  int v27 = &protocol witness table for Int;
  uint64_t v28 = v12;
  uint64_t v13 = swift_getWitnessTable(&protocol conformance descriptor for <> Range<A>, v11);
  uint64_t v14 = v38;
  zip<A, B>(_:_:)(&v35, v31, v8, v11, v38, v13);
  swift_bridgeObjectRelease(v39);
  *(void *)uint64_t v31 = v29;
  *(_OWORD *)&v31[8] = v30;
  *(void *)&long long v32 = v8;
  *((void *)&v32 + 1) = v11;
  uint64_t v33 = v14;
  uint64_t v34 = v13;
  uint64_t v18 = type metadata accessor for Zip2Sequence(0, &v32, v15, v31, v16, v17, v21);
  uint64_t v19 = swift_getWitnessTable(&protocol conformance descriptor for Zip2Sequence<A, B>, v18);
  Dictionary.init<A>(uniqueKeysWithValues:)(v31, v37, &type metadata for Int, v18, v36, v19);
  return v39;
}

uint64_t partial apply for implicit closure #1 in SortedSet.init(_:)(uint64_t a1, uint64_t a2)
{
  return dispatch thunk of static Comparable.< infix(_:_:)(a1, a2, *(void *)(v2 + 16), *(void *)(v2 + 24));
}

uint64_t type metadata accessor for SortedSet(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for SortedSet);
}

void *initializeBufferWithCopyOfBuffer for TreeRegressorModel(void *a1, void *a2, uint64_t a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v9 = *a2;
    *uint64_t v3 = *a2;
    uint64_t v3 = (void *)(v9 + ((v4 + 16) & ~v4));
    swift_retain(v9);
  }
  else
  {
    *a1 = *a2;
    uint64_t v6 = a2[1];
    v3[1] = v6;
    uint64_t v7 = a2[2];
    swift_bridgeObjectRetain(v6);
    if (v7)
    {
      v3[2] = v7;
      v3[3] = a2[3];
      uint64_t v8 = a2[4];
      v3[4] = v8;
      swift_bridgeObjectRetain(v7);
      swift_bridgeObjectRetain(v8);
    }
    else
    {
      v3[4] = a2[4];
      *((_OWORD *)v3 + 1) = *((_OWORD *)a2 + 1);
    }
    uint64_t v10 = *(int *)(a3 + 24);
    uint64_t v11 = (char *)v3 + v10;
    uint64_t v12 = (char *)a2 + v10;
    uint64_t v13 = type metadata accessor for BaseTreeRegressorModel(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v13 - 8) + 16))(v11, v12, v13);
  }
  return v3;
}

uint64_t destroy for TreeRegressorModel(void *a1, uint64_t a2)
{
  swift_bridgeObjectRelease(a1[1]);
  uint64_t v3 = a1[2];
  if (v3)
  {
    swift_bridgeObjectRelease(v3);
    swift_bridgeObjectRelease(a1[4]);
  }
  int v4 = (char *)a1 + *(int *)(a2 + 24);
  uint64_t v5 = type metadata accessor for BaseTreeRegressorModel(0);
  return (*(uint64_t (**)(char *, uint64_t))(*(void *)(v5 - 8) + 8))(v4, v5);
}

void *initializeWithCopy for TreeRegressorModel(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v5 = a2[1];
  a1[1] = v5;
  uint64_t v6 = a2[2];
  swift_bridgeObjectRetain(v5);
  if (v6)
  {
    a1[2] = v6;
    a1[3] = a2[3];
    uint64_t v7 = a2[4];
    a1[4] = v7;
    swift_bridgeObjectRetain(v6);
    swift_bridgeObjectRetain(v7);
  }
  else
  {
    a1[4] = a2[4];
    *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
  }
  uint64_t v8 = *(int *)(a3 + 24);
  uint64_t v9 = (char *)a1 + v8;
  uint64_t v10 = (char *)a2 + v8;
  uint64_t v11 = type metadata accessor for BaseTreeRegressorModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 16))(v9, v10, v11);
  return a1;
}

void *assignWithCopy for TreeRegressorModel(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v4 = a2[1];
  uint64_t v5 = a1[1];
  a1[1] = v4;
  swift_bridgeObjectRetain(v4);
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = a1 + 2;
  uint64_t v7 = a2 + 2;
  uint64_t v8 = a1[2];
  uint64_t v9 = a2[2];
  if (v8)
  {
    if (v9)
    {
      a1[2] = v9;
      swift_bridgeObjectRetain(v9);
      swift_bridgeObjectRelease(v8);
      a1[3] = a2[3];
      uint64_t v10 = a2[4];
      uint64_t v11 = a1[4];
      a1[4] = v10;
      swift_bridgeObjectRetain(v10);
      swift_bridgeObjectRelease(v11);
    }
    else
    {
      outlined destroy of FeatureVectorizer<Float>.Transformer((uint64_t)(a1 + 2));
      _OWORD *v6 = *v7;
      a1[4] = a2[4];
    }
  }
  else if (v9)
  {
    a1[2] = v9;
    a1[3] = a2[3];
    uint64_t v12 = a2[4];
    a1[4] = v12;
    swift_bridgeObjectRetain(v9);
    swift_bridgeObjectRetain(v12);
  }
  else
  {
    a1[4] = a2[4];
    _OWORD *v6 = *v7;
  }
  uint64_t v13 = *(int *)(a3 + 24);
  uint64_t v14 = (char *)a1 + v13;
  uint64_t v15 = (char *)a2 + v13;
  uint64_t v16 = type metadata accessor for BaseTreeRegressorModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 24))(v14, v15, v16);
  return a1;
}

uint64_t initializeWithTake for TreeRegressorModel(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = *(_OWORD *)(a2 + 16);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v3 = *(int *)(a3 + 24);
  uint64_t v4 = a1 + v3;
  uint64_t v5 = v3 + a2;
  uint64_t v6 = type metadata accessor for BaseTreeRegressorModel(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 32))(v4, v5, v6);
  return a1;
}

void *assignWithTake for TreeRegressorModel(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v5 = a1[1];
  a1[1] = a2[1];
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = a1 + 2;
  uint64_t v7 = a2 + 2;
  uint64_t v8 = a1[2];
  if (v8)
  {
    uint64_t v9 = a2[2];
    if (v9)
    {
      a1[2] = v9;
      swift_bridgeObjectRelease(v8);
      a1[3] = a2[3];
      uint64_t v10 = a1[4];
      a1[4] = a2[4];
      swift_bridgeObjectRelease(v10);
    }
    else
    {
      outlined destroy of FeatureVectorizer<Float>.Transformer((uint64_t)(a1 + 2));
      _OWORD *v6 = *v7;
      a1[4] = a2[4];
    }
  }
  else
  {
    a1[4] = a2[4];
    _OWORD *v6 = *v7;
  }
  uint64_t v11 = *(int *)(a3 + 24);
  uint64_t v12 = (char *)a1 + v11;
  uint64_t v13 = (char *)a2 + v11;
  uint64_t v14 = type metadata accessor for BaseTreeRegressorModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 40))(v12, v13, v14);
  return a1;
}

uint64_t getEnumTagSinglePayload for TreeRegressorModel(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_E95B8);
}

uint64_t sub_E95B8(uint64_t a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t result = 0;
    if ((*(void *)(a1 + 8) & 0xFFFFFFFF00000001) == 0) {
      return (*(void *)(a1 + 8) >> 1) + 1;
    }
  }
  else
  {
    uint64_t v5 = type metadata accessor for BaseTreeRegressorModel(0);
    return __swift_getEnumTagSinglePayload(*(int *)(a3 + 24) + a1, a2, v5);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for TreeRegressorModel(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_E9640);
}

uint64_t sub_E9640(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(a1 + 8) = 2 * (a2 - 1);
  }
  else
  {
    uint64_t v5 = type metadata accessor for BaseTreeRegressorModel(0);
    return __swift_storeEnumTagSinglePayload(*(int *)(a4 + 24) + a1, a2, a2, v5);
  }
  return result;
}

uint64_t type metadata accessor for TreeRegressorModel(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for TreeRegressorModel;
  if (!type metadata singleton initialization cache for TreeRegressorModel) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for TreeRegressorModel);
  }
  return result;
}

uint64_t type metadata completion function for TreeRegressorModel(uint64_t a1)
{
  v3[0] = &unk_349DB8;
  v3[1] = &unk_349DD0;
  uint64_t result = type metadata accessor for BaseTreeRegressorModel(319);
  if (v2 <= 0x3F)
  {
    v3[2] = *(void *)(result - 8) + 64;
    swift_initStructMetadata(a1, 256, 3, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t TreeRegressorModel.computeMetrics(on:)(uint64_t a1)
{
  uint64_t v49 = v3;
  uint64_t v36 = v1;
  uint64_t v45 = type metadata accessor for AnyColumn(0);
  uint64_t v46 = *(void *)(v45 - 8);
  int64_t v4 = *(void *)(v46 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v32 = (uint64_t)&v32;
  uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  uint64_t v34 = *(void *)(v33 - 8);
  int64_t v7 = *(void *)(v34 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v35 = &v32;
  uint64_t v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<Double>>);
  uint64_t v10 = *(void *)(v37 - 8);
  int64_t v11 = *(void *)(v10 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v41 = &v32;
  uint64_t v14 = type metadata accessor for DataFrame(0);
  uint64_t v15 = *(void *)(v14 - 8);
  int64_t v16 = *(void *)(v15 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v42 = &v32;
  uint64_t v47 = a1;
  uint64_t result = TreeRegressorModel.applied(to:eventHandler:)(a1, 0, 0);
  if (!v2)
  {
    uint64_t v40 = 0;
    uint64_t v39 = v15;
    uint64_t v38 = v14;
    uint64_t v44 = v10;
    uint64_t v20 = v49;
    uint64_t v21 = v35;
    DataFrame.subscript.getter(*v49, v49[1], &type metadata for Double);
    uint64_t v48 = 0;
    uint64_t v22 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Double> and conformance Column<A>, &demangling cache variable for type metadata for Column<Double>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v23 = v33;
    OptionalColumnProtocol.filled(with:)(&v48, v33, v22);
    (*(void (**)(uint64_t *, uint64_t))(v34 + 8))(v21, v23);
    uint64_t v24 = v32;
    DataFrame.subscript.getter(*v20, v20[1]);
    uint64_t v25 = AnyColumn.convertedToDoubles()();
    (*(void (**)(uint64_t, uint64_t))(v46 + 8))(v24, v45);
    if (!v25) {
      BUG();
    }
    uint64_t v43 = v25;
    uint64_t v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ContiguousArray<Double>);
    uint64_t v46 = v26;
    uint64_t v27 = lazy protocol witness table accessor for type Double and conformance Double();
    uint64_t v49 = (void *)lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<Double>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<Double>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
    uint64_t v47 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type ContiguousArray<Double> and conformance ContiguousArray<A>, &demangling cache variable for type metadata for ContiguousArray<Double>, (uint64_t)&protocol conformance descriptor for ContiguousArray<A>);
    uint64_t v28 = v41;
    uint64_t v29 = v26;
    uint64_t v30 = v37;
    maximumAbsoluteError<A, B, C>(_:_:)(v41, &v43, &type metadata for Double, v37, v29, v27, v49, v47);
    uint64_t v45 = v48;
    uint64_t v43 = v25;
    rootMeanSquaredError<A, B, C>(_:_:)(v28, &v43, &type metadata for Double, v30, v46, v27, v49, v47);
    (*(void (**)(uint64_t *, uint64_t))(v44 + 8))(v28, v30);
    (*(void (**)(uint64_t *, uint64_t))(v39 + 8))(v42, v38);
    swift_release();
    uint64_t result = v48;
    uint64_t v31 = v36;
    *uint64_t v36 = v45;
    v31[1] = result;
    *((unsigned char *)v31 + 16) = 0;
  }
  return result;
}

uint64_t TreeRegressorModel.applied(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v52 = v4;
  uint64_t v6 = v5;
  uint64_t v48 = a3;
  uint64_t v49 = a2;
  uint64_t v7 = v3;
  uint64_t v38 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  uint64_t v37 = *(void *)(v38 - 8);
  int64_t v8 = *(void *)(v37 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v39 = &v37;
  uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Float>);
  uint64_t v45 = *(void *)(v46 - 8);
  int64_t v11 = *(void *)(v45 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v14 = v6[2];
  if (!v14)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000001CLL, "ressorModel.swift" + 0x8000000000000000, "CreateML/TreeRegressorModel.swift", 33, 2, 16, 0);
    BUG();
  }
  uint64_t v15 = v52;
  uint64_t result = specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(a1, 0, v14, v6[3], v6[4]);
  if (!v15)
  {
    uint64_t v52 = v7;
    type metadata accessor for TreeRegressorModel(0);
    uint64_t v17 = v49;
    uint64_t v18 = BaseTreeRegressorModel.applied(features:eventHandler:)(&v37, v49, v48);
    uint64_t v49 = 0;
    uint64_t v48 = &v37;
    uint64_t v19 = v18;
    DataFrame.init()(&v37, v17, v20, v18);
    uint64_t v40 = *v6;
    uint64_t v21 = v6[1];
    int64_t v22 = *(void *)(v19 + 16);
    uint64_t v41 = v21;
    if (v22)
    {
      uint64_t v51 = _swiftEmptyArrayStorage;
      int64_t v50 = v22;
      swift_bridgeObjectRetain(v21);
      uint64_t v23 = 0;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v50, 0);
      int64_t v24 = v50;
      uint64_t v25 = v51;
      uint64_t v26 = *(void *)(v19 + 16);
      int v27 = 1;
      uint64_t v28 = v19;
      do
      {
        if (v26 == v23) {
          BUG();
        }
        float v29 = *(float *)(v28 + 4 * v23 + 32);
        uint64_t v51 = v25;
        unint64_t v30 = v25[2];
        unint64_t v31 = v25[3];
        int64_t v32 = v30 + 1;
        if (v31 >> 1 <= v30)
        {
          uint64_t v42 = v28;
          uint64_t v43 = v26;
          int v33 = v27;
          float v47 = v29;
          int64_t v44 = v30 + 1;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v31 >= 2, v32, v27);
          int64_t v32 = v44;
          float v29 = v47;
          int v27 = v33;
          uint64_t v26 = v43;
          int64_t v24 = v50;
          uint64_t v28 = v42;
          uint64_t v25 = v51;
        }
        ++v23;
        v25[2] = v32;
        *(double *)&v25[v30 + 4] = v29;
      }
      while (v24 != v23);
      swift_release();
    }
    else
    {
      swift_bridgeObjectRetain(v21);
      swift_release();
      uint64_t v25 = _swiftEmptyArrayStorage;
    }
    uint64_t v51 = v25;
    uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
    uint64_t v35 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Double] and conformance [A], &demangling cache variable for type metadata for [Double], (uint64_t)&protocol conformance descriptor for [A]);
    uint64_t v36 = v39;
    Column.init<A>(name:contents:)(v40, v41, &v51, &type metadata for Double, v34, v35);
    DataFrame.append<A>(column:)(v36, &type metadata for Double);
    (*(void (**)(uint64_t *, uint64_t))(v37 + 8))(v36, v38);
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v45 + 8))(v48, v46);
  }
  return result;
}

uint64_t protocol witness for Transformer.applied(to:eventHandler:) in conformance TreeRegressorModel(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4)
{
  TreeRegressorModel.applied(to:eventHandler:)(a2, a3, a4);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(*(uint64_t (**)(void))(v4 + 8));
}

uint64_t base witness table accessor for Transformer in TreeRegressorModel()
{
  return lazy protocol witness table accessor for type TreeRegressorModel and conformance TreeRegressorModel();
}

uint64_t lazy protocol witness table accessor for type TreeRegressorModel and conformance TreeRegressorModel()
{
  uint64_t result = lazy protocol witness table cache variable for type TreeRegressorModel and conformance TreeRegressorModel;
  if (!lazy protocol witness table cache variable for type TreeRegressorModel and conformance TreeRegressorModel)
  {
    uint64_t v1 = type metadata accessor for TreeRegressorModel(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for TreeRegressorModel, v1);
    lazy protocol witness table cache variable for type TreeRegressorModel and conformance TreeRegressorModel = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type Double and conformance Double()
{
  uint64_t result = lazy protocol witness table cache variable for type Double and conformance Double;
  if (!lazy protocol witness table cache variable for type Double and conformance Double)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for Double, &type metadata for Double);
    lazy protocol witness table cache variable for type Double and conformance Double = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type Double and conformance Double;
  if (!lazy protocol witness table cache variable for type Double and conformance Double)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for Double, &type metadata for Double);
    lazy protocol witness table cache variable for type Double and conformance Double = result;
  }
  return result;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D4LL10parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t a4)
{
  int64_t v4 = *(void *)(a1 + 16);
  if (v4)
  {
    uint64_t v16 = *(void *)(a1 + 16);
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v4, 0);
    uint64_t v6 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(a3) - 8);
    uint64_t v7 = ((*(unsigned __int8 *)(v6 + 80) + 32) & ~*(unsigned __int8 *)(v6 + 80)) + a1;
    uint64_t v17 = *(void *)(v6 + 72);
    do
    {
      uint64_t KeyPath = swift_getKeyPath(a4);
      swift_getAtKeyPath(v7, KeyPath);
      swift_release();
      if (!swift_isUniquelyReferenced_nonNull_native(_swiftEmptyArrayStorage)) {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, _swiftEmptyArrayStorage[2] + 1, 1);
      }
      unint64_t v9 = _swiftEmptyArrayStorage[2];
      unint64_t v10 = v9 + 1;
      if (_swiftEmptyArrayStorage[3] >> 1 <= v9)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v9 + 1, 1);
        unint64_t v10 = v9 + 1;
      }
      _swiftEmptyArrayStorage[2] = v10;
      uint64_t v11 = 2 * v9;
      _swiftEmptyArrayStorage[v11 + 4] = v13;
      _swiftEmptyArrayStorage[v11 + 5] = v14;
      v7 += v17;
      --v16;
    }
    while (v16);
  }
  return _swiftEmptyArrayStorage;
}

void *specialized Array.init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4)
{
  return specialized Array.init<A>(_:)(a1, a2, a3, a4, specialized _copyCollectionToContiguousArray<A>(_:));
}

{
  return specialized Array.init<A>(_:)(a1, a2, a3, a4, specialized _copyCollectionToContiguousArray<A>(_:));
}

{
  return specialized Array.init<A>(_:)(a1, a2, a3, a4, (void *(*)(uint64_t, uint64_t, uint64_t, unint64_t))specialized _copyCollectionToContiguousArray<A>(_:));
}

{
  return specialized Array.init<A>(_:)(a1, a2, a3, a4, (void *(*)(uint64_t, uint64_t, uint64_t, unint64_t))specialized _copyCollectionToContiguousArray<A>(_:));
}

void *specialized Array.init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, void *(*a5)(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4))
{
  if ((a4 & 1) == 0)
  {
    uint64_t v7 = a5(a1, a2, a3, a4);
LABEL_3:
    int64_t v8 = v7;
    goto LABEL_10;
  }
  uint64_t v9 = type metadata accessor for __ContiguousArrayStorageBase(0);
  swift_unknownObjectRetain_n(a1, 2);
  unint64_t v10 = (void *)swift_dynamicCastClass(a1, v9);
  if (!v10)
  {
    swift_unknownObjectRelease(a1);
    unint64_t v10 = _swiftEmptyArrayStorage;
  }
  uint64_t v11 = v10[2];
  swift_release();
  if (__OFSUB__(a4 >> 1, a3)) {
    BUG();
  }
  if (v11 != (a4 >> 1) - a3)
  {
    swift_unknownObjectRelease(a1);
    uint64_t v7 = a5(a1, a2, a3, a4);
    goto LABEL_3;
  }
  int64_t v8 = (void *)swift_dynamicCastClass(a1, v9);
  if (!v8)
  {
    swift_unknownObjectRelease(a1);
    int64_t v8 = _swiftEmptyArrayStorage;
  }
LABEL_10:
  swift_unknownObjectRelease(a1);
  return v8;
}

char *_sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVy11TabularData12FilledColumnVyAH0I0VySSGGAJyALySaySfGGGG_18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGs5NeverOTg5012_sSSSaySfG18j14MLComponents16lm3Vy6n4ML13pq2Vyu20GSSGIgggr_SS_AAtAIs5r68OIegnrzr_TR03_s8a80ML38SoundClassifierTrainingSessionDelegateC13loadg44FrameySay0A12MLComponents16cd4Vy04e4B013gh36zu7GSSGG07F37I00iJ0VKFZALSS_SayZ7GtXEfU_Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  uint64_t v91 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  int64_t v1 = *(void *)(*(void *)(v91 - 8) + 64);
  uint64_t v2 = alloca(v1);
  uint64_t v3 = alloca(v1);
  uint64_t v92 = &v90;
  uint64_t v93 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
  uint64_t v94 = *(void *)(v93 - 8);
  int64_t v4 = *(void *)(v94 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  char v106 = &v90;
  uint64_t v7 = alloca(v4);
  int64_t v8 = alloca(v4);
  uint64_t v95 = &v90;
  uint64_t v109 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<[Float]>>);
  uint64_t v100 = *(void *)(v109 - 8);
  int64_t v9 = *(void *)(v100 + 64);
  unint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v99 = &v90;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  uint64_t v13 = *(void *)(v12 - 8);
  uint64_t v108 = v12;
  uint64_t v102 = v13;
  int64_t v14 = *(void *)(v13 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v98 = &v90;
  uint64_t v113 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<FilledColumn<Column<String>>, FilledColumn<Column<[Float]>>>);
  int64_t v17 = *(void *)(*(void *)(v113 - 8) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  char v96 = &v90;
  uint64_t v114 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<FilledColumn<Column<String>>, FilledColumn<Column<[Float]>>>.Iterator);
  int64_t v20 = *(void *)(*(void *)(v114 - 8) + 64);
  uint64_t v21 = alloca(v20);
  int64_t v22 = alloca(v20);
  uint64_t v111 = &v90;
  uint64_t v107 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<String>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<String>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
  uint64_t v101 = a1;
  uint64_t v23 = dispatch thunk of Sequence.underestimatedCount.getter(v12, v107);
  uint64_t v110 = (uint64_t *)lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<[Float]>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<[Float]>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
  uint64_t v24 = dispatch thunk of Sequence.underestimatedCount.getter(v109, v110);
  if (v24 < v23) {
    uint64_t v23 = v24;
  }
  uint64_t v112 = (char *)_swiftEmptyArrayStorage;
  int64_t v25 = 0;
  if (v23 > 0) {
    int64_t v25 = v23;
  }
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v25, 0);
  uint64_t v26 = (uint64_t)v96;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v101, (uint64_t)v96, &demangling cache variable for type metadata for Zip2Sequence<FilledColumn<Column<String>>, FilledColumn<Column<[Float]>>>);
  uint64_t v27 = v108;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v102 + 32))(v98, v26, v108);
  uint64_t v28 = v27;
  uint64_t v29 = v109;
  dispatch thunk of Sequence.makeIterator()(v28, v107);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v100 + 32))(v99, v26 + *(int *)(v113 + 52), v29);
  unint64_t v30 = (char *)v111 + *(int *)(v114 + 52);
  dispatch thunk of Sequence.makeIterator()(v29, v110);
  unint64_t v31 = v111;
  uint64_t v103 = *(int *)(v114 + 56);
  *((unsigned char *)v111 + v103) = 0;
  if (v23 < 0) {
    BUG();
  }
  uint64_t v32 = v108;
  uint64_t v97 = v30;
  uint64_t v33 = (uint64_t)v31;
  if (!v23) {
    goto LABEL_18;
  }
  uint64_t v34 = v31;
  uint64_t v35 = (uint64_t *)((char *)v31
                  + *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<String>>>)
                           + 36));
  uint64_t v36 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[Float]>>>)
               + 36);
  uint64_t v37 = v108;
  uint64_t v114 = (uint64_t)v35;
  uint64_t v110 = (uint64_t *)&v30[v36];
  do
  {
    BOOL v38 = v23 == 0;
    uint64_t v39 = v23 - 1;
    if (v38) {
      BUG();
    }
    if (*((unsigned char *)v34 + v103)) {
      BUG();
    }
    uint64_t v107 = v39;
    uint64_t v113 = *v35;
    uint64_t v40 = v37;
    uint64_t v41 = v34;
    uint64_t v42 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<String>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<String>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
    dispatch thunk of Collection.endIndex.getter(v37, v42);
    if (v113 == v104) {
      BUG();
    }
    uint64_t v43 = (void (*)(void, void))dispatch thunk of Collection.subscript.read(&v104, v114, v37, v42);
    char v96 = (uint64_t *)*v44;
    uint64_t v101 = v44[1];
    swift_bridgeObjectRetain(v101);
    v43(&v104, 0);
    uint64_t v45 = v98;
    uint64_t v46 = v41;
    uint64_t v47 = v102;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v102 + 16))(v98, v46, v40);
    dispatch thunk of Collection.formIndex(after:)(v114, v40, v42);
    (*(void (**)(uint64_t *, uint64_t))(v47 + 8))(v45, v40);
    uint64_t v48 = v110;
    uint64_t v113 = *v110;
    uint64_t v49 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<[Float]>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<[Float]>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
    int64_t v50 = v97;
    uint64_t v51 = v109;
    dispatch thunk of Collection.endIndex.getter(v109, v49);
    if (v113 == v104)
    {
      swift_bridgeObjectRelease(v101);
      BUG();
    }
    uint64_t v52 = (void (*)(void, void))dispatch thunk of Collection.subscript.read(&v104, v48, v51, v49);
    uint64_t v113 = *v53;
    swift_bridgeObjectRetain(v113);
    v52(&v104, 0);
    uint64_t v54 = v99;
    uint64_t v55 = v109;
    (*(void (**)(uint64_t *, char *, uint64_t))(v100 + 16))(v99, v50, v109);
    dispatch thunk of Collection.formIndex(after:)(v110, v55, v49);
    (*(void (**)(uint64_t *, uint64_t))(v100 + 8))(v54, v55);
    uint64_t v56 = v113;
    uint64_t v104 = v113;
    uint64_t v57 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
    uint64_t v58 = (void *)swift_allocObject(v57, 40, 7);
    v58[2] = 1;
    v58[3] = 2;
    v58[4] = *(void *)(v56 + 16);
    swift_bridgeObjectRetain(v56);
    uint64_t v59 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
    uint64_t v60 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float], (uint64_t)&protocol conformance descriptor for [A]);
    uint64_t v61 = v92;
    MLShapedArray.init<A>(scalars:shape:)(&v104, v58, &type metadata for Float, v59, &protocol witness table for Float, v60);
    uint64_t v104 = (uint64_t)v96;
    uint64_t v105 = v101;
    AnnotatedFeature.init(feature:annotation:)(v61, &v104, v91, &type metadata for String);
    swift_bridgeObjectRelease(v113);
    uint64_t v62 = v112;
    if (!swift_isUniquelyReferenced_nonNull_native(v112))
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v62 + 2) + 1, 1);
      uint64_t v62 = v112;
    }
    uint64_t v34 = v111;
    unint64_t v63 = *((void *)v62 + 2);
    if (*((void *)v62 + 3) >> 1 <= v63)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v62 + 3) >= 2uLL, v63 + 1, 1);
      uint64_t v34 = v111;
      uint64_t v62 = v112;
    }
    *((void *)v62 + 2) = v63 + 1;
    (*(void (**)(char *, uint64_t *, uint64_t))(v94 + 32))(&v62[((*(unsigned __int8 *)(v94 + 80) + 32) & ~*(unsigned __int8 *)(v94 + 80)) + *(void *)(v94 + 72) * v63], v106, v93);
    uint64_t v23 = v107;
    uint64_t v37 = v108;
    uint64_t v35 = (uint64_t *)v114;
  }
  while (v107);
  uint64_t v32 = v108;
  uint64_t v33 = (uint64_t)v34;
  if (!*((unsigned char *)v34 + v103))
  {
LABEL_18:
    uint64_t v113 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<String>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<String>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
    while (1)
    {
      uint64_t v64 = v32;
      uint64_t v65 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<String>>>)
                   + 36);
      uint64_t v114 = *(void *)(v33 + v65);
      uint64_t v66 = (void *)v33;
      uint64_t v67 = v113;
      dispatch thunk of Collection.endIndex.getter(v64, v113);
      if (v114 == v104) {
        break;
      }
      uint64_t v68 = v33 + v65;
      uint64_t v114 = dispatch thunk of Collection.subscript.read(&v104, v68, v64, v67);
      uint64_t v110 = *v69;
      char v106 = v69[1];
      swift_bridgeObjectRetain((_BYTE)v106);
      ((void (*)(uint64_t *, void))v114)(&v104, 0);
      uint64_t v70 = v98;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v102 + 16))(v98, v33, v64);
      dispatch thunk of Collection.formIndex(after:)(v68, v64, v113);
      (*(void (**)(uint64_t *, uint64_t))(v102 + 8))(v70, v64);
      uint64_t v71 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<[Float]>>>)
                   + 36);
      Swift::String v72 = v97;
      uint64_t v114 = *(void *)&v97[v71];
      uint64_t v73 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<[Float]>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<[Float]>>, (uint64_t)&protocol conformance descriptor for FilledColumn<A>);
      dispatch thunk of Collection.endIndex.getter(v109, v73);
      if (v114 == v104)
      {
        swift_bridgeObjectRelease((_BYTE)v106);
        uint64_t v66 = v111;
        break;
      }
      int64_t v74 = &v72[v71];
      uint64_t v75 = v109;
      uint64_t v107 = v73;
      uint64_t v76 = (void (*)(void, void))dispatch thunk of Collection.subscript.read(&v104, v74, v109, v73);
      uint64_t v114 = *v77;
      swift_bridgeObjectRetain(v114);
      v76(&v104, 0);
      uint64_t v78 = v99;
      uint64_t v79 = v100;
      (*(void (**)(uint64_t *, char *, uint64_t))(v100 + 16))(v99, v97, v75);
      dispatch thunk of Collection.formIndex(after:)(v74, v75, v107);
      (*(void (**)(uint64_t *, uint64_t))(v79 + 8))(v78, v75);
      uint64_t v80 = v114;
      uint64_t v104 = v114;
      uint64_t v81 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
      uint64_t v82 = (void *)swift_allocObject(v81, 40, 7);
      v82[2] = 1;
      v82[3] = 2;
      v82[4] = *(void *)(v80 + 16);
      swift_bridgeObjectRetain(v80);
      uint64_t v83 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
      uint64_t v84 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float], (uint64_t)&protocol conformance descriptor for [A]);
      uint64_t v85 = v92;
      MLShapedArray.init<A>(scalars:shape:)(&v104, v82, &type metadata for Float, v83, &protocol witness table for Float, v84);
      uint64_t v104 = (uint64_t)v110;
      uint64_t v105 = (uint64_t)v106;
      AnnotatedFeature.init(feature:annotation:)(v85, &v104, v91, &type metadata for String);
      swift_bridgeObjectRelease(v114);
      uint64_t v86 = v112;
      if (!swift_isUniquelyReferenced_nonNull_native(v112))
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v86 + 2) + 1, 1);
        uint64_t v86 = v112;
      }
      uint64_t v87 = v111;
      unint64_t v88 = *((void *)v86 + 2);
      if (*((void *)v86 + 3) >> 1 <= v88)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v86 + 3) >= 2uLL, v88 + 1, 1);
        uint64_t v87 = v111;
        uint64_t v86 = v112;
      }
      *((void *)v86 + 2) = v88 + 1;
      (*(void (**)(char *, uint64_t *, uint64_t))(v94 + 32))(&v86[((*(unsigned __int8 *)(v94 + 80) + 32) & ~*(unsigned __int8 *)(v94 + 80)) + *(void *)(v94 + 72) * v88], v95, v93);
      uint64_t v32 = v108;
      uint64_t v33 = (uint64_t)v87;
      if (*((unsigned char *)v87 + v103)) {
        goto LABEL_29;
      }
    }
    *((unsigned char *)v66 + v103) = 1;
    uint64_t v33 = (uint64_t)v66;
  }
LABEL_29:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v33, &demangling cache variable for type metadata for Zip2Sequence<FilledColumn<Column<String>>, FilledColumn<Column<[Float]>>>.Iterator);
  return v112;
}

uint64_t key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
}

uint64_t key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, a4, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
}

uint64_t SoundClassifierTrainingSessionDelegate.init(sessionParameters:)(uint64_t a1)
{
  *(void *)(v1 + 16) = 0xD000000000000010;
  *(void *)(v1 + 24) = "rt a new session" + 0x8000000000000000;
  uint64_t v2 = v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
  uint64_t v3 = type metadata accessor for MLSoundClassifier.PersistentParameters(0);
  __swift_storeEnumTagSinglePayload(v2, 1, 1, v3);
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles) = _swiftEmptyArrayStorage;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles) = _swiftEmptyArrayStorage;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures) = _swiftEmptyArrayStorage;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures) = _swiftEmptyArrayStorage;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels) = &_swiftEmptySetSingleton;
  *(unsigned char *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_featureExtractionOnly) = 0;
  uint64_t v4 = v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier;
  uint64_t v5 = type metadata accessor for MLSoundClassifier.Classifier(0);
  __swift_storeEnumTagSinglePayload(v4, 1, 1, v5);
  uint64_t v6 = v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model;
  uint64_t v7 = type metadata accessor for MLSoundClassifier.Model(0);
  __swift_storeEnumTagSinglePayload(v6, 1, 1, v7);
  uint64_t v8 = v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_parameters;
  uint64_t v9 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  __swift_storeEnumTagSinglePayload(v8, 1, 1, v9);
  uint64_t v10 = v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingMetrics;
  uint64_t v11 = type metadata accessor for MLClassifierMetrics(0);
  __swift_storeEnumTagSinglePayload(v10, 1, 1, v11);
  __swift_storeEnumTagSinglePayload(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationMetrics, 1, 1, v11);
  uint64_t v12 = v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_tablePrinter;
  uint64_t v13 = type metadata accessor for TrainingTablePrinter(0);
  __swift_storeEnumTagSinglePayload(v12, 1, 1, v13);
  outlined init with take of MLClassifierMetrics(a1, v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  return v1;
}

void *SoundClassifierTrainingSessionDelegate.init(trainingData:featureExtractionOnly:modelParameters:sessionParameters:)(uint64_t a1, int a2, uint64_t a3, uint64_t a4)
{
  uint64_t v45 = v4;
  uint64_t v42 = a4;
  uint64_t v44 = a3;
  int v43 = a2;
  uint64_t v35 = a1;
  uint64_t v38 = *v5;
  uint64_t v6 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v36 = &v33;
  int64_t v10 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.DataSource(0) - 8) + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v37 = &v33;
  int64_t v13 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  int64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v41 = &v33;
  v5[2] = 0xD000000000000010;
  v5[3] = "rt a new session" + 0x8000000000000000;
  uint64_t v16 = (uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
  uint64_t v17 = type metadata accessor for MLSoundClassifier.PersistentParameters(0);
  uint64_t v39 = v16;
  uint64_t v40 = v17;
  __swift_storeEnumTagSinglePayload(v16, 1, 1, v17);
  *(void *)((char *)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles) = _swiftEmptyArrayStorage;
  *(void *)((char *)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles) = _swiftEmptyArrayStorage;
  *(void *)((char *)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures) = _swiftEmptyArrayStorage;
  *(void *)((char *)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures) = _swiftEmptyArrayStorage;
  *(void *)((char *)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels) = &_swiftEmptySetSingleton;
  *((unsigned char *)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_featureExtractionOnly) = 0;
  uint64_t v18 = (uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier;
  uint64_t v19 = type metadata accessor for MLSoundClassifier.Classifier(0);
  __swift_storeEnumTagSinglePayload(v18, 1, 1, v19);
  uint64_t v20 = (uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model;
  uint64_t v21 = type metadata accessor for MLSoundClassifier.Model(0);
  __swift_storeEnumTagSinglePayload(v20, 1, 1, v21);
  __swift_storeEnumTagSinglePayload((uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_parameters, 1, 1, v6);
  uint64_t v22 = (uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingMetrics;
  uint64_t v23 = type metadata accessor for MLClassifierMetrics(0);
  __swift_storeEnumTagSinglePayload(v22, 1, 1, v23);
  __swift_storeEnumTagSinglePayload((uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationMetrics, 1, 1, v23);
  uint64_t v24 = (uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_tablePrinter;
  uint64_t v25 = type metadata accessor for TrainingTablePrinter(0);
  uint64_t v26 = v35;
  __swift_storeEnumTagSinglePayload(v24, 1, 1, v25);
  uint64_t v27 = (uint64_t)v37;
  outlined init with copy of MLTrainingSessionParameters(v26, (uint64_t)v37, type metadata accessor for MLSoundClassifier.DataSource);
  uint64_t v28 = (uint64_t)v36;
  outlined init with copy of MLTrainingSessionParameters(v44, (uint64_t)v36, type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v29 = v45;
  MLSoundClassifier.PersistentParameters.init(trainingData:modelParameters:)(v27, v28);
  uint64_t v45 = v29;
  if (v29)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(v42, type metadata accessor for MLTrainingSessionParameters);
    outlined destroy of MLActivityClassifier.ModelParameters(v44, type metadata accessor for MLSoundClassifier.ModelParameters);
    outlined destroy of MLActivityClassifier.ModelParameters(v26, type metadata accessor for MLSoundClassifier.DataSource);
    swift_bridgeObjectRelease(v5[3]);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    swift_bridgeObjectRelease(*(void *)((char *)v5
                                        + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles));
    swift_bridgeObjectRelease(*(void *)((char *)v5
                                        + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles));
    swift_bridgeObjectRelease(*(void *)((char *)v5
                                        + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures));
    swift_bridgeObjectRelease(*(void *)((char *)v5
                                        + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures));
    swift_bridgeObjectRelease(*(void *)((char *)v5
                                        + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels));
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_parameters, &demangling cache variable for type metadata for MLSoundClassifier.ModelParameters?);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingMetrics, &demangling cache variable for type metadata for MLClassifierMetrics?);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationMetrics, &demangling cache variable for type metadata for MLClassifierMetrics?);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_tablePrinter, &demangling cache variable for type metadata for TrainingTablePrinter?);
    swift_deallocPartialClassInstance(v5, v38, *(unsigned int *)(*v5 + 48), *(unsigned __int16 *)(*v5 + 52));
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters(v44, type metadata accessor for MLSoundClassifier.ModelParameters);
    outlined destroy of MLActivityClassifier.ModelParameters(v26, type metadata accessor for MLSoundClassifier.DataSource);
    uint64_t v30 = (uint64_t)v41;
    __swift_storeEnumTagSinglePayload((uint64_t)v41, 0, 1, v40);
    uint64_t v31 = v39;
    swift_beginAccess(v39, v34, 33, 0);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v30, v31, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    swift_endAccess(v34);
    outlined init with take of MLClassifierMetrics(v42, (uint64_t)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
    *((unsigned char *)v5 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_featureExtractionOnly) = v43 & 1;
  }
  return v5;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> SoundClassifierTrainingSessionDelegate.setUp()()
{
  uint64_t v60 = v0;
  uint64_t v61 = v1;
  int64_t v2 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?)
                             - 8)
                 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v53 = v43;
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0) - 8)
                 + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v59 = v43;
  uint64_t v52 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  int64_t v8 = *(void *)(*(void *)(v52 - 8) + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  int64_t v50 = v43;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v51 = v43;
  int64_t v13 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Classifier?)
                              - 8)
                  + 64);
  int64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v48 = v43;
  uint64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v49 = v43;
  int64_t v18 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v21 = (int *)type metadata accessor for MLSoundClassifier.PersistentParameters(0);
  int64_t v22 = *(void *)(*((void *)v21 - 1) + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  uint64_t v25 = v61 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v61 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters, v43, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v25, (uint64_t)v43, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload((uint64_t)v43, 1, (uint64_t)v21) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v43, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    BUG();
  }
  outlined init with take of MLClassifierMetrics((uint64_t)v43, (uint64_t)v43, type metadata accessor for MLSoundClassifier.PersistentParameters);
  uint64_t v26 = v60;
  SoundClassifierTrainingSessionDelegate.populateFiles(parameters:)((uint64_t)v43);
  if (v26)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v43, type metadata accessor for MLSoundClassifier.PersistentParameters);
  }
  else
  {
    uint64_t v58 = 0;
    uint64_t v60 = *(void *)(v61 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels);
    outlined init with copy of MLTrainingSessionParameters((uint64_t)&v43[v21[5]], (uint64_t)v59, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v56 = *(void *)&v43[v21[8]];
    uint64_t v57 = *(void *)&v43[v21[6]];
    uint64_t v27 = v21[9];
    uint64_t v55 = *(void *)&v43[v27];
    char v62 = v43[v27 + 8];
    uint64_t v28 = (int *)v52;
    uint64_t v29 = *(int *)(v52 + 28);
    uint64_t v30 = (uint64_t)v50;
    uint64_t v54 = &v50[v29];
    *(_OWORD *)&v50[v29] = 0;
    *(_OWORD *)(v30 + v29 + 16) = 0;
    uint64_t v31 = v28[8];
    *(void *)(v30 + v31) = 0;
    uint64_t v32 = *(void *)&v43[v27 + 16];
    *(unsigned char *)(v30 + v31 + 8) = 1;
    *(void *)(v30 + v28[9]) = 32;
    outlined init with copy of MLTrainingSessionParameters((uint64_t)v59, v30, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    *(void *)(v30 + v28[5]) = v56;
    *(void *)(v30 + v28[6]) = v57;
    uint64_t v47 = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
    uint64_t v44 = v55;
    char v45 = v62;
    uint64_t v46 = v32;
    swift_bridgeObjectRetain(v32);
    swift_bridgeObjectRetain(v60);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)&v44, (uint64_t)v54, &demangling cache variable for type metadata for Any?);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v59, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
    uint64_t v33 = v30;
    uint64_t v34 = (uint64_t)v51;
    outlined init with take of MLClassifierMetrics(v33, (uint64_t)v51, type metadata accessor for MLSoundClassifier.ModelParameters);
    uint64_t v35 = (uint64_t)v49;
    MLSoundClassifier.Classifier.init(labels:parameters:)(v60, v34);
    uint64_t v36 = type metadata accessor for MLSoundClassifier.Classifier(0);
    __swift_storeEnumTagSinglePayload(v35, 0, 1, v36);
    uint64_t v37 = v61 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier;
    swift_beginAccess(v61 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier, &v44, 33, 0);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v35, v37, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
    swift_endAccess(&v44);
    uint64_t v38 = v37;
    uint64_t v39 = (uint64_t)v48;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v38, (uint64_t)v48, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
    if (__swift_getEnumTagSinglePayload(v39, 1, v36) == 1) {
      BUG();
    }
    uint64_t v40 = (uint64_t)v53;
    MLSoundClassifier.Classifier.makeTransformer()();
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v43, type metadata accessor for MLSoundClassifier.PersistentParameters);
    outlined destroy of MLActivityClassifier.ModelParameters(v39, type metadata accessor for MLSoundClassifier.Classifier);
    uint64_t v41 = type metadata accessor for MLSoundClassifier.Model(0);
    __swift_storeEnumTagSinglePayload(v40, 0, 1, v41);
    uint64_t v42 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model + v61;
    swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model + v61, &v44, 33, 0);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v40, v42, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
    swift_endAccess(&v44);
  }
}

uint64_t SoundClassifierTrainingSessionDelegate.populateFiles(parameters:)(uint64_t a1)
{
  uint64_t v77 = v1;
  int64_t v3 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0) - 8)
                 + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  trainingData._rawValue = v69;
  uint64_t v6 = alloca(v3);
  int64_t v7 = alloca(v3);
  v86._rawValue = v69;
  int64_t v8 = alloca(v3);
  uint64_t v9 = alloca(v3);
  unint64_t v88 = v69;
  uint64_t v10 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  int64_t v11 = *(void *)(*(void *)(v10 - 8) + 64);
  uint64_t v12 = alloca(v11);
  int64_t v13 = alloca(v11);
  uint64_t v85 = v69;
  int64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  *(Swift::OpaquePointer_optional *)&long long v16 = MLSoundClassifier.DataSource.annotatedFeatures()();
  if (!v19)
  {
    uint64_t v79 = v69;
    uint64_t v20 = v85;
    uint64_t v78 = (int *)v10;
    uint64_t v87 = a1;
    if ((void)v16)
    {
      trainingData._rawValue = (void *)v16;
      uint64_t v21 = (int *)type metadata accessor for MLSoundClassifier.PersistentParameters(0);
      uint64_t v22 = v87;
      uint64_t v23 = (uint64_t)v88;
      outlined init with copy of MLTrainingSessionParameters(v87 + v21[5], (uint64_t)v88, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      uint64_t v82 = *(void *)(v22 + v21[8]);
      uint64_t v83 = *(void *)(v22 + v21[6]);
      uint64_t v24 = v21[9];
      uint64_t v80 = *(_OWORD **)(v22 + v24);
      LOBYTE(v81) = *(unsigned char *)(v22 + v24 + 8);
      uint64_t v87 = *(void *)(v22 + v24 + 16);
      uint64_t v25 = v78;
      uint64_t v26 = v78[7];
      uint64_t v85 = 0;
      uint64_t v27 = (uint64_t)v79;
      uint64_t v28 = v79;
      *(_OWORD *)&v79[v26] = 0;
      *(_OWORD *)&v28[v26 + 16] = 0;
      uint64_t v29 = v25[8];
      *(void *)&v28[v29] = 0;
      uint64_t v30 = (uint64_t)&v28[v26];
      *(unsigned char *)(v27 + v29 + 8) = 1;
      *(void *)(v27 + v25[9]) = 32;
      outlined init with copy of MLTrainingSessionParameters(v23, v27, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      *(void *)(v27 + v25[5]) = v82;
      *(void *)(v27 + v25[6]) = v83;
      uint64_t v73 = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
      uint64_t v70 = (uint64_t)v80;
      char v71 = v81;
      uint64_t v72 = v87;
      swift_bridgeObjectRetain(v87);
      rawValue = (int *)trainingData._rawValue;
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)&v70, v30, &demangling cache variable for type metadata for Any?);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v88, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      uint64_t v32 = v86._rawValue;
      outlined init with copy of MLTrainingSessionParameters(v27, (uint64_t)v86._rawValue, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      outlined destroy of MLActivityClassifier.ModelParameters(v27, type metadata accessor for MLSoundClassifier.ModelParameters);
      unsigned long long v33 = (unsigned __int128)MLSoundClassifier.ModelParameters.ValidationData.splitFeatures(trainingData:)((Swift::OpaquePointer)rawValue);
      if (v34)
      {
        uint64_t v35 = (uint64_t)v32;
LABEL_5:
        outlined destroy of MLActivityClassifier.ModelParameters(v35, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
        *(void *)&long long v16 = swift_bridgeObjectRelease((_BYTE)rawValue);
        return v16;
      }
      uint64_t v49 = (void *)*((void *)&v33 + 1);
      uint64_t v85 = 0;
      uint64_t v50 = v33;
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v32, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      uint64_t v51 = v49;
      uint64_t v52 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures;
      uint64_t v53 = v77;
      swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures + v77, &v70, 1, 0);
      uint64_t v54 = *(void *)(v53 + v52);
      *(void *)(v53 + v52) = v50;
      swift_bridgeObjectRelease(v54);
      if (!v51) {
        uint64_t v51 = _swiftEmptyArrayStorage;
      }
      uint64_t v55 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures;
      swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures + v53, v69, 1, 0);
      uint64_t v56 = *(void *)(v53 + v55);
      *(void *)(v53 + v55) = v51;
      swift_bridgeObjectRelease(v56);
      uint64_t v57 = &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>;
      uint64_t v58 = &unk_349ED8;
      uint64_t v59 = &v75;
      char v60 = (char)trainingData._rawValue;
      uint64_t v61 = trainingData._rawValue;
    }
    else
    {
      uint64_t v36 = v87;
      uint64_t v37 = MLSoundClassifier.DataSource.labeledSounds()(v17, v18, *((void *)&v16 + 1));
      uint64_t v38 = (uint64_t)v20;
      rawValue = v78;
      char v39 = v37;
      v86._rawValue = specialized Sequence.flatMap<A>(_:)(v37);
      uint64_t v79 = 0;
      swift_bridgeObjectRelease(v39);
      uint64_t v40 = (int *)type metadata accessor for MLSoundClassifier.PersistentParameters(0);
      outlined init with copy of MLTrainingSessionParameters(v36 + v40[5], (uint64_t)v88, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      uint64_t v83 = *(void *)(v36 + v40[8]);
      uint64_t v76 = *(void *)(v36 + v40[6]);
      uint64_t v41 = v40[9];
      uint64_t v81 = *(void *)(v36 + v41);
      LOBYTE(v82) = *(unsigned char *)(v36 + v41 + 8);
      uint64_t v42 = (_OWORD *)(rawValue[7] + v38);
      uint64_t v80 = v42;
      _OWORD *v42 = 0;
      v42[1] = 0;
      uint64_t v43 = rawValue[8];
      *(void *)(v38 + v43) = 0;
      uint64_t v44 = *(void *)(v36 + v41 + 16);
      *(unsigned char *)(v38 + v43 + 8) = 1;
      *(void *)(v38 + rawValue[9]) = 32;
      outlined init with copy of MLTrainingSessionParameters((uint64_t)v88, v38, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      *(void *)(v38 + rawValue[5]) = v83;
      *(void *)(v38 + rawValue[6]) = v76;
      uint64_t v73 = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
      uint64_t v70 = v81;
      char v71 = v82;
      uint64_t v72 = v44;
      swift_bridgeObjectRetain(v44);
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)&v70, (uint64_t)v80, &demangling cache variable for type metadata for Any?);
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v88, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      char v45 = trainingData._rawValue;
      outlined init with copy of MLTrainingSessionParameters(v38, (uint64_t)trainingData._rawValue, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      outlined destroy of MLActivityClassifier.ModelParameters(v38, type metadata accessor for MLSoundClassifier.ModelParameters);
      LOBYTE(rawValue) = v86._rawValue;
      uint64_t v46 = (uint64_t)v45;
      unsigned long long v47 = (unsigned __int128)MLSoundClassifier.ModelParameters.ValidationData.splitFiles(trainingData:)(v86);
      if (v48)
      {
        uint64_t v35 = (uint64_t)v45;
        goto LABEL_5;
      }
      uint64_t v65 = (void *)*((void *)&v47 + 1);
      uint64_t v66 = v47;
      outlined destroy of MLActivityClassifier.ModelParameters(v46, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      if (!v65) {
        uint64_t v65 = _swiftEmptyArrayStorage;
      }
      unint64_t v88 = v65;
      uint64_t v67 = (uint64_t)v65;
      uint64_t v53 = v77;
      specialized SoundClassifierTrainingSessionDelegate.populateFiles<A, B>(training:validation:parameters:)(v66, v67, v87);
      swift_bridgeObjectRelease(v66);
      swift_bridgeObjectRelease((_BYTE)v88);
      uint64_t v57 = &demangling cache variable for type metadata for AnnotatedFeature<URL, String>;
      uint64_t v58 = &unk_349F70;
      uint64_t v59 = &v74;
      char v60 = (char)v86._rawValue;
      uint64_t v61 = v86._rawValue;
    }
    MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm((uint64_t)v61, (uint64_t)v59, v57, (uint64_t)v58);
    swift_bridgeObjectRelease(v60);
    uint64_t v63 = specialized Set.init<A>(_:)((uint64_t)MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm);
    uint64_t v64 = *(void *)(v53 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels);
    *(void *)(v53 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels) = v63;
    *(void *)&long long v16 = swift_bridgeObjectRelease(v64);
  }
  return v16;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> SoundClassifierTrainingSessionDelegate.resume(from:)(Swift::OpaquePointer from)
{
  uint64_t v100 = v1;
  uint64_t v98 = v2;
  rawValue = (uint64_t *)from._rawValue;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Classifier?)
                             - 8)
                 + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  Swift::OpaquePointer v86 = &v79;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?)
                             - 8)
                 + 64);
  int64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v93 = &v79;
  uint64_t v96 = type metadata accessor for URL(0);
  uint64_t v88 = *(void *)(v96 - 8);
  int64_t v9 = *(void *)(v88 + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  char v89 = &v79;
  uint64_t v12 = alloca(v9);
  int64_t v13 = alloca(v9);
  uint64_t v87 = &v79;
  int64_t v14 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  uint64_t v15 = alloca(v14);
  long long v16 = alloca(v14);
  uint64_t v95 = (uint64_t)&v79;
  uint64_t v17 = type metadata accessor for MLSoundClassifier.PersistentParameters(0);
  int64_t v18 = *(void *)(*(void *)(v17 - 8) + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v97 = &v79;
  int64_t v21 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                              - 8)
                  + 64);
  uint64_t v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  uint64_t v85 = &v79;
  uint64_t v24 = alloca(v21);
  uint64_t v25 = alloca(v21);
  uint64_t v26 = type metadata accessor for MLCheckpoint(0);
  uint64_t v90 = *(void *)(v26 - 8);
  int64_t v27 = *(void *)(v90 + 64);
  uint64_t v28 = alloca(v27);
  uint64_t v29 = alloca(v27);
  uint64_t v92 = &v79;
  uint64_t v30 = alloca(v27);
  uint64_t v31 = alloca(v27);
  uint64_t v91 = &v79;
  uint64_t v32 = alloca(v27);
  unsigned long long v33 = alloca(v27);
  specialized BidirectionalCollection.last.getter((uint64_t)rawValue);
  uint64_t v94 = v26;
  if (__swift_getEnumTagSinglePayload((uint64_t)&v79, 1, v26) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v79, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v34 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v34, 0, 0);
    *(void *)uint64_t v35 = 0xD00000000000001DLL;
    *(void *)(v35 + 8) = "reated." + 0x8000000000000000;
    *(_OWORD *)(v35 + 16) = 0;
    *(_OWORD *)(v35 + 32) = 0;
    *(unsigned char *)(v35 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v34, v35, v36, v37, v38);
    return;
  }
  uint64_t v99 = &v79;
  outlined init with take of MLClassifierMetrics((uint64_t)&v79, (uint64_t)&v79, type metadata accessor for MLCheckpoint);
  uint64_t v39 = v98 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v98 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters, v80, 0, 0);
  uint64_t v40 = v95;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v39, v95, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload(v40, 1, v17) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v40, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    BUG();
  }
  uint64_t v41 = (uint64_t)v97;
  outlined init with take of MLClassifierMetrics(v40, (uint64_t)v97, type metadata accessor for MLSoundClassifier.PersistentParameters);
  uint64_t v42 = v100;
  SoundClassifierTrainingSessionDelegate.populateFiles(parameters:)(v41);
  uint64_t v43 = (uint64_t)v93;
  if (v42) {
    goto LABEL_5;
  }
  uint64_t v100 = 0;
  int v45 = *((unsigned __int8 *)v99 + *(int *)(v94 + 20));
  if (v45 != 2)
  {
    if (v45 == 1)
    {
      uint64_t v46 = (uint64_t)v99;
      SoundClassifierTrainingSessionDelegate.resumeFeatureExtraction(from:)((uint64_t)v99);
      outlined destroy of MLActivityClassifier.ModelParameters(v41, type metadata accessor for MLSoundClassifier.PersistentParameters);
      outlined destroy of MLActivityClassifier.ModelParameters(v46, type metadata accessor for MLCheckpoint);
      return;
    }
    uint64_t v58 = (uint64_t)v99;
    uint64_t v59 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v59, 0, 0);
    *(void *)uint64_t v60 = 0xD00000000000003ELL;
    *(void *)(v60 + 8) = "No checkpoints to be resumed." + 0x8000000000000000;
    *(_OWORD *)(v60 + 16) = 0;
    *(_OWORD *)(v60 + 32) = 0;
    *(unsigned char *)(v60 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v59, v60, v61, v62, v63);
    outlined destroy of MLActivityClassifier.ModelParameters(v41, type metadata accessor for MLSoundClassifier.PersistentParameters);
    uint64_t v44 = v58;
LABEL_6:
    outlined destroy of MLActivityClassifier.ModelParameters(v44, type metadata accessor for MLCheckpoint);
    return;
  }
  v84[0] = rawValue;
  uint64_t v47 = rawValue[2];
  char v48 = 1;
  if (!v47)
  {
    uint64_t v57 = 0;
    goto LABEL_25;
  }
  uint64_t v49 = v47 - 1;
  uint64_t v50 = (uint64_t)rawValue
      + ((*(unsigned __int8 *)(v90 + 80) + 32) & ~*(unsigned __int8 *)(v90 + 80))
      + v49 * *(void *)(v90 + 72);
  uint64_t v95 = -*(void *)(v90 + 72);
  while (2)
  {
    rawValue = (uint64_t *)v49;
    uint64_t v51 = v41;
    uint64_t v52 = v43;
    uint64_t v53 = (uint64_t)v92;
    outlined init with copy of MLTrainingSessionParameters(v50, (uint64_t)v92, type metadata accessor for MLCheckpoint);
    switch(*(unsigned char *)(v53 + *(int *)(v94 + 20)))
    {
      case 0:
        unint64_t v54 = 0xEB0000000064657ALL;
        uint64_t v55 = 0x696C616974696E69;
        goto LABEL_17;
      case 1:
        swift_bridgeObjectRelease(110);
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v92, type metadata accessor for MLCheckpoint);
        char v48 = 0;
        uint64_t v43 = v52;
        uint64_t v41 = v51;
        goto LABEL_24;
      case 2:
        unint64_t v54 = 0xE800000000000000;
        uint64_t v55 = 0x676E696E69617274;
        goto LABEL_17;
      case 3:
        unint64_t v54 = 0xEA0000000000676ELL;
        uint64_t v55 = 0x697461756C617665;
        goto LABEL_17;
      case 4:
        unint64_t v54 = 0xEB00000000676E69;
        uint64_t v55 = 0x636E657265666E69;
LABEL_17:
        char v56 = _stringCompareWithSmolCheck(_:_:expecting:)(v55, v54, 0x6974636172747865, 0xEA0000000000676ELL, 0);
        swift_bridgeObjectRelease(v54);
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v92, type metadata accessor for MLCheckpoint);
        if ((v56 & 1) == 0)
        {
          v50 += v95;
          uint64_t v49 = (uint64_t)rawValue - 1;
          uint64_t v43 = (uint64_t)v93;
          uint64_t v41 = (uint64_t)v97;
          if (!rawValue)
          {
            uint64_t v57 = 0;
            char v48 = 1;
            goto LABEL_25;
          }
          continue;
        }
        char v48 = 0;
        uint64_t v43 = (uint64_t)v93;
        uint64_t v41 = (uint64_t)v97;
LABEL_24:
        uint64_t v57 = (uint64_t)rawValue;
LABEL_25:
        rawValue = &v79;
        uint64_t v64 = alloca(24);
        uint64_t v65 = alloca(32);
        uint64_t v81 = v84;
        uint64_t v66 = (uint64_t)v85;
        uint64_t v67 = v100;
        _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))partial apply for specialized closure #1 in BidirectionalCollection.last(where:), (uint64_t)&v79, v57, v48, (uint64_t)v83);
        if (__swift_getEnumTagSinglePayload(v66, 1, v94) == 1)
        {
          uint64_t v100 = v67;
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v66, &demangling cache variable for type metadata for MLCheckpoint?);
          goto LABEL_29;
        }
        uint64_t v68 = v66;
        uint64_t v69 = (uint64_t)v91;
        outlined init with take of MLClassifierMetrics(v68, (uint64_t)v91, type metadata accessor for MLCheckpoint);
        SoundClassifierTrainingSessionDelegate.resumeFeatureExtraction(from:)(v69);
        outlined destroy of MLActivityClassifier.ModelParameters(v69, type metadata accessor for MLCheckpoint);
        if (v67)
        {
LABEL_5:
          outlined destroy of MLActivityClassifier.ModelParameters(v41, type metadata accessor for MLSoundClassifier.PersistentParameters);
          uint64_t v44 = (uint64_t)v99;
          goto LABEL_6;
        }
        uint64_t v100 = 0;
LABEL_29:
        uint64_t v70 = v89;
        URL.appendingPathComponent(_:)(0x6C65646F6DLL, 0xE500000000000000);
        char v71 = v87;
        URL.appendingPathExtension(_:)(6777712, 0xE300000000000000);
        rawValue = *(uint64_t **)(v88 + 8);
        ((void (*)(uint64_t *, uint64_t))rawValue)(v70, v96);
        uint64_t v72 = v98 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier;
        swift_beginAccess(v98 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier, v84, 0, 0);
        uint64_t v73 = (uint64_t)v86;
        outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v72, (uint64_t)v86, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
        uint64_t v74 = type metadata accessor for MLSoundClassifier.Classifier(0);
        if (__swift_getEnumTagSinglePayload(v73, 1, v74) == 1) {
          BUG();
        }
        uint64_t v75 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier, type metadata accessor for MLSoundClassifier.Classifier, (uint64_t)&protocol conformance descriptor for MLSoundClassifier.Classifier);
        uint64_t v76 = v100;
        UpdatableSupervisedEstimator.readWithOptimizer(from:)(v71, v74, v75);
        ((void (*)(uint64_t *, uint64_t))rawValue)(v71, v96);
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v97, type metadata accessor for MLSoundClassifier.PersistentParameters);
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v99, type metadata accessor for MLCheckpoint);
        outlined destroy of MLActivityClassifier.ModelParameters(v73, type metadata accessor for MLSoundClassifier.Classifier);
        if (!v76)
        {
          uint64_t v77 = type metadata accessor for MLSoundClassifier.Model(0);
          __swift_storeEnumTagSinglePayload(v43, 0, 1, v77);
          uint64_t v78 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model + v98;
          swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model + v98, v82, 33, 0);
          outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v43, v78, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
          swift_endAccess(v82);
        }
        return;
    }
  }
}

uint64_t SoundClassifierTrainingSessionDelegate.resumeFeatureExtraction(from:)(uint64_t a1)
{
  uint64_t v200 = v1;
  uint64_t v199 = v2;
  uint64_t v201 = a1;
  uint64_t v192 = type metadata accessor for CSVType(0);
  uint64_t v182 = *(void **)(v192 - 8);
  int64_t v3 = v182[8];
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  uint64_t v176 = &v152;
  int64_t v6 = *(void *)(*(void *)(type metadata accessor for CSVReadingOptions(0) - 8) + 64);
  int64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v161 = &v152;
  int64_t v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  v181 = &v152;
  int64_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?)
                              - 8)
                  + 64);
  uint64_t v12 = alloca(v11);
  int64_t v13 = alloca(v11);
  v170 = &v152;
  int64_t v14 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0) - 8)
                  + 64);
  uint64_t v15 = alloca(v14);
  long long v16 = alloca(v14);
  Swift::String v183 = &v152;
  uint64_t v168 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  int64_t v17 = *(void *)(*(void *)(v168 - 8) + 64);
  int64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  v166 = &v152;
  uint64_t v20 = alloca(v17);
  int64_t v21 = alloca(v17);
  uint64_t v167 = &v152;
  int64_t v22 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Classifier?)
                              - 8)
                  + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  uint64_t v164 = &v152;
  uint64_t v25 = alloca(v22);
  uint64_t v26 = alloca(v22);
  uint64_t v165 = &v152;
  int64_t v27 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                              - 8)
                  + 64);
  uint64_t v28 = alloca(v27);
  uint64_t v29 = alloca(v27);
  unsigned __int8 v162 = &v152;
  uint64_t v30 = alloca(v27);
  uint64_t v31 = alloca(v27);
  int64_t v163 = &v152;
  uint64_t v32 = alloca(v27);
  unsigned long long v33 = alloca(v27);
  v184 = &v152;
  uint64_t v34 = alloca(v27);
  uint64_t v35 = alloca(v27);
  uint64_t v195 = &v152;
  uint64_t v197 = type metadata accessor for DataFrame(0);
  v193 = *(void **)(v197 - 8);
  int64_t v36 = v193[8];
  uint64_t v37 = alloca(v36);
  uint64_t v38 = alloca(v36);
  v160 = &v152;
  uint64_t v39 = alloca(v36);
  uint64_t v40 = alloca(v36);
  uint64_t v171 = &v152;
  uint64_t v41 = alloca(v36);
  uint64_t v42 = alloca(v36);
  v194 = &v152;
  uint64_t v43 = alloca(v36);
  uint64_t v44 = alloca(v36);
  char v188 = &v152;
  uint64_t v191 = type metadata accessor for URL(0);
  uint64_t v202 = *(void *)(v191 - 8);
  int64_t v45 = *(void *)(v202 + 64);
  uint64_t v46 = alloca(v45);
  uint64_t v47 = alloca(v45);
  int v177 = &v152;
  char v48 = alloca(v45);
  uint64_t v49 = alloca(v45);
  v198 = &v152;
  uint64_t v50 = alloca(v45);
  uint64_t v51 = alloca(v45);
  uint64_t v185 = &v152;
  uint64_t v52 = alloca(v45);
  uint64_t v53 = alloca(v45);
  Swift::String v190 = &v152;
  unint64_t v54 = alloca(v45);
  uint64_t v55 = alloca(v45);
  v196 = &v152;
  char v56 = alloca(v45);
  uint64_t v57 = alloca(v45);
  Swift::String v187 = &v152;
  uint64_t v58 = alloca(v45);
  uint64_t v59 = alloca(v45);
  uint64_t v186 = &v152;
  int64_t v60 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  uint64_t v61 = alloca(v60);
  uint64_t v62 = alloca(v60);
  uint64_t v63 = type metadata accessor for MLSoundClassifier.PersistentParameters(0);
  int64_t v64 = *(void *)(*(void *)(v63 - 8) + 64);
  uint64_t v65 = alloca(v64);
  uint64_t v66 = alloca(v64);
  uint64_t v67 = v199 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v199 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters, v153, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v67, (uint64_t)&v152, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  v169 = (int *)v63;
  if (__swift_getEnumTagSinglePayload((uint64_t)&v152, 1, v63) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v152, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    BUG();
  }
  unsigned __int8 v189 = &v152;
  outlined init with take of MLClassifierMetrics((uint64_t)&v152, (uint64_t)&v152, type metadata accessor for MLSoundClassifier.PersistentParameters);
  uint64_t v68 = v187;
  URL.appendingPathComponent(_:)(0x676E696E69617274, 0xE800000000000000);
  URL.appendingPathExtension(_:)(7762787, 0xE300000000000000);
  uint64_t v69 = *(void (**)(uint64_t *, uint64_t))(v202 + 8);
  uint64_t v70 = v191;
  v69(v68, v191);
  URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEA00000000006E6FLL);
  URL.appendingPathExtension(_:)(7762787, 0xE300000000000000);
  Swift::String v187 = (uint64_t *)v69;
  v69(v68, v70);
  char v71 = v190;
  uint64_t v72 = v186;
  uint64_t v202 = *(void *)(v202 + 16);
  ((void (*)(uint64_t *, uint64_t *, uint64_t))v202)(v190, v186, v70);
  uint64_t v73 = v194;
  uint64_t v74 = (uint64_t *)v200;
  DataFrame.init(contentsOfSFrameDirectory:columns:rows:)(v71, 0, 0, 0, 1);
  if (v74)
  {
    v194 = v74;
    ((void (*)(uint64_t *, uint64_t *, uint64_t))v202)(v198, v72, v70);
    uint64_t v75 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, CSVType)>);
    uint64_t v200 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, CSVType));
    uint64_t v76 = *(void *)(v200 - 8);
    uint64_t v77 = *(uint64_t **)(v76 + 72);
    uint64_t v78 = *(unsigned __int8 *)(v76 + 80);
    uint64_t v79 = ((int)v78 + 32) & ~*(unsigned __int8 *)(v76 + 80);
    uint64_t v172 = v75;
    uint64_t v175 = v79 + 2 * (void)v77;
    uint64_t v174 = v78 | 7;
    uint64_t v80 = swift_allocObject(v75, v175, v78 | 7);
    *(void *)(v80 + 16) = 2;
    *(void *)(v80 + 24) = 4;
    uint64_t v81 = v80 + v79;
    uint64_t v82 = v80 + v79 + *(int *)(v200 + 48);
    *(void *)(v80 + v79) = 0x7365727574616566;
    uint64_t v173 = v79;
    *(void *)(v80 + v79 + 8) = 0xE800000000000000;
    uint64_t v83 = (void *)v182[13];
    unsigned int v178 = enum case for CSVType.data(_:);
    ((void (*)(uint64_t, void, uint64_t))v83)(v82, enum case for CSVType.data(_:), v192);
    uint64_t v84 = v83;
    uint64_t v85 = (char *)v77 + *(int *)(v200 + 48) + v81;
    *(uint64_t *)((char *)v77 + v81) = 0x62614C7373616C63;
    uint64_t v185 = v77;
    *(uint64_t *)((char *)v77 + v81 + 8) = 0xEA00000000006C65;
    unsigned int v179 = enum case for CSVType.string(_:);
    uint64_t v86 = v192;
    uint64_t v87 = v84;
    ((void (*)(char *, void, uint64_t))v84)(v85, enum case for CSVType.string(_:), v192);
    uint64_t v201 = Dictionary.init(dictionaryLiteral:)(v80, &type metadata for String, v86, &protocol witness table for String);
    uint64_t v88 = default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
    Swift::String v190 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 2 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
    uint64_t v182 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 3 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
    char v89 = v176;
    unsigned int v180 = enum case for CSVType.double(_:);
    v184 = v87;
    ((void (*)(uint64_t *, void, uint64_t))v87)(v176, enum case for CSVType.double(_:), v86);
    uint64_t v90 = v181;
    CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)(1, v88, v190, v182, v89, 1, 1, 0, 44, 0xE100000000000000, 92, 0xE100000000000000);
    uint64_t v91 = v160;
    DataFrame.init(contentsOfCSVFile:columns:rows:types:options:)(v198, 0, 0, 0, 1, v201, v90);
    uint64_t v201 = 0;
    v198 = (uint64_t *)v193[4];
    ((void (*)(uint64_t *, uint64_t *, uint64_t))v198)(v188, v91, v197);
    ((void (*)(uint64_t *, uint64_t *, uint64_t))v202)(v177, v196, v191);
    uint64_t v95 = swift_allocObject(v172, v175, v174);
    *(void *)(v95 + 16) = 2;
    *(void *)(v95 + 24) = 4;
    uint64_t v96 = v173;
    uint64_t v97 = v95 + v173;
    uint64_t v98 = v200;
    uint64_t v99 = v95 + v173 + *(int *)(v200 + 48);
    *(void *)(v95 + v173) = 0x7365727574616566;
    *(void *)(v95 + v96 + 8) = 0xE800000000000000;
    uint64_t v100 = v184;
    ((void (*)(uint64_t, void, uint64_t))v184)(v99, v178, v192);
    uint64_t v101 = v185;
    uint64_t v102 = (char *)v185 + *(int *)(v98 + 48) + v97;
    *(uint64_t *)((char *)v185 + v97) = 0x62614C7373616C63;
    *(uint64_t *)((char *)v101 + v97 + 8) = 0xEA00000000006C65;
    uint64_t v103 = v192;
    uint64_t v104 = v100;
    ((void (*)(char *, void, uint64_t))v100)(v102, v179, v192);
    uint64_t v105 = v103;
    uint64_t v202 = Dictionary.init(dictionaryLiteral:)(v95, &type metadata for String, v103, &protocol witness table for String);
    uint64_t v200 = (uint64_t)default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
    Swift::String v190 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 2 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
    v181 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 3 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
    char v106 = v176;
    ((void (*)(uint64_t *, void, uint64_t))v104)(v176, v180, v105);
    unsigned int v107 = 1;
    uint64_t v108 = v161;
    CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)(1, v200, v190, v181, v106, 1, 1, 0, 44, 0xE100000000000000, 92, 0xE100000000000000);
    uint64_t v109 = (uint64_t)v162;
    uint64_t v110 = v201;
    DataFrame.init(contentsOfCSVFile:columns:rows:types:options:)(v177, 0, 0, 0, 1, v202, v108);
    if (v110) {
      swift_errorRelease(v110);
    }
    else {
      unsigned int v107 = 0;
    }
    uint64_t v111 = (uint64_t)v195;
    swift_errorRelease(v194);
  }
  else
  {
    uint64_t v92 = v73;
    uint64_t v93 = v70;
    v198 = (uint64_t *)v193[4];
    ((void (*)(uint64_t *, uint64_t *, uint64_t))v198)(v188, v92, v197);
    uint64_t v94 = v185;
    ((void (*)(uint64_t *, uint64_t *, uint64_t))v202)(v185, v196, v93);
    uint64_t v109 = (uint64_t)v184;
    DataFrame.init(contentsOfSFrameDirectory:columns:rows:)(v94, 0, 0, 0, 1);
    unsigned int v107 = 0;
    uint64_t v111 = (uint64_t)v195;
  }
  __swift_storeEnumTagSinglePayload(v109, v107, 1, v197);
  outlined init with take of DataFrame?(v109, v111);
  uint64_t v112 = static SoundClassifierTrainingSessionDelegate.loadDataFrame(_:)(v188);
  uint64_t v201 = 0;
  uint64_t v115 = v112;
  uint64_t v116 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures;
  uint64_t v117 = v199;
  swift_beginAccess(v199 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures, v154, 1, 0);
  uint64_t v118 = *(void *)(v117 + v116);
  *(void *)(v117 + v116) = v115;
  uint64_t v119 = (uint64_t)v195;
  swift_bridgeObjectRelease(v118);
  uint64_t v120 = (uint64_t)v163;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v119, (uint64_t)v163, &demangling cache variable for type metadata for DataFrame?);
  uint64_t v121 = v197;
  if (__swift_getEnumTagSinglePayload(v120, 1, v197) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v120, &demangling cache variable for type metadata for DataFrame?);
    uint64_t v122 = (uint64_t)v189;
  }
  else
  {
    uint64_t v123 = v171;
    ((void (*)(uint64_t *, uint64_t, uint64_t))v198)(v171, v120, v121);
    uint64_t v124 = v201;
    uint64_t v125 = static SoundClassifierTrainingSessionDelegate.loadDataFrame(_:)(v123);
    uint64_t v201 = v124;
    uint64_t v126 = v121;
    uint64_t v122 = (uint64_t)v189;
    if (v124)
    {
      uint64_t v127 = v123;
      uint64_t v128 = (void (*)(uint64_t *, uint64_t))v193[1];
      v128(v127, v126);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v119, &demangling cache variable for type metadata for DataFrame?);
      v128(v188, v126);
      uint64_t v129 = v191;
      uint64_t v113 = v187;
      ((void (*)(uint64_t *, uint64_t))v187)(v196, v191);
      ((void (*)(uint64_t *, uint64_t))v113)(v186, v129);
      return outlined destroy of MLActivityClassifier.ModelParameters(v122, type metadata accessor for MLSoundClassifier.PersistentParameters);
    }
    uint64_t v130 = v126;
    uint64_t v131 = v125;
    ((void (*)(uint64_t *, uint64_t))v193[1])(v123, v130);
    uint64_t v132 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures;
    swift_beginAccess(v199 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures, v155, 1, 0);
    uint64_t v133 = *(void *)(v199 + v132);
    *(void *)(v199 + v132) = v131;
    uint64_t v117 = v199;
    swift_bridgeObjectRelease(v133);
  }
  uint64_t v202 = *(void *)(v117 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels);
  v134 = v169;
  outlined init with copy of MLTrainingSessionParameters(v169[5] + v122, (uint64_t)v183, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
  uint64_t v200 = *(void *)(v122 + v134[8]);
  v194 = *(uint64_t **)(v122 + v134[6]);
  uint64_t v135 = v134[9];
  uint64_t v192 = *(void *)(v122 + v135);
  LOBYTE(v198) = *(unsigned char *)(v122 + v135 + 8);
  uint64_t v136 = (int *)v168;
  uint64_t v137 = *(int *)(v168 + 28);
  uint64_t v138 = (uint64_t)v166;
  uint64_t v139 = (uint64_t)v166 + v137;
  *(_OWORD *)((char *)v166 + v137) = 0;
  *(_OWORD *)(v138 + v137 + 16) = 0;
  uint64_t v140 = v136[8];
  *(void *)(v138 + v140) = 0;
  uint64_t v141 = *(void *)(v122 + v135 + 16);
  *(unsigned char *)(v138 + v140 + 8) = 1;
  *(void *)(v138 + v136[9]) = 32;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v183, v138, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
  *(void *)(v138 + v136[5]) = v200;
  *(void *)(v138 + v136[6]) = v194;
  v159 = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
  uint64_t v156 = v192;
  char v157 = (char)v198;
  uint64_t v158 = v141;
  swift_bridgeObjectRetain(v141);
  swift_bridgeObjectRetain(v202);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)&v156, v139, &demangling cache variable for type metadata for Any?);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v183, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
  uint64_t v142 = (uint64_t)v167;
  outlined init with take of MLClassifierMetrics(v138, (uint64_t)v167, type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v143 = (uint64_t)v165;
  MLSoundClassifier.Classifier.init(labels:parameters:)(v202, v142);
  uint64_t v144 = type metadata accessor for MLSoundClassifier.Classifier(0);
  __swift_storeEnumTagSinglePayload(v143, 0, 1, v144);
  uint64_t v145 = v199 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier;
  swift_beginAccess(v199 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier, &v156, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v143, v145, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
  swift_endAccess(&v156);
  uint64_t v146 = (uint64_t)v164;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v145, (uint64_t)v164, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
  if (__swift_getEnumTagSinglePayload(v146, 1, v144) == 1) {
    BUG();
  }
  uint64_t v147 = (uint64_t)v170;
  MLSoundClassifier.Classifier.makeTransformer()();
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v195, &demangling cache variable for type metadata for DataFrame?);
  ((void (*)(uint64_t *, uint64_t))v193[1])(v188, v197);
  uint64_t v148 = v191;
  char v149 = v187;
  ((void (*)(uint64_t *, uint64_t))v187)(v196, v191);
  ((void (*)(uint64_t *, uint64_t))v149)(v186, v148);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v189, type metadata accessor for MLSoundClassifier.PersistentParameters);
  outlined destroy of MLActivityClassifier.ModelParameters(v146, type metadata accessor for MLSoundClassifier.Classifier);
  uint64_t v150 = type metadata accessor for MLSoundClassifier.Model(0);
  __swift_storeEnumTagSinglePayload(v147, 0, 1, v150);
  uint64_t v151 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model + v199;
  swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model + v199, &v156, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v147, v151, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
  return swift_endAccess(&v156);
}

uint64_t static SoundClassifierTrainingSessionDelegate.loadDataFrame(_:)()
{
  uint64_t v35 = v0;
  uint64_t v38 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<FilledColumn<Column<String>>, FilledColumn<Column<[Float]>>>);
  int64_t v1 = *(void *)(*(void *)(v38 - 8) + 64);
  uint64_t v2 = alloca(v1);
  int64_t v3 = alloca(v1);
  uint64_t v37 = &v33;
  uint64_t v42 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Float]>);
  uint64_t v41 = *(void *)(v42 - 8);
  int64_t v4 = *(void *)(v41 + 64);
  int64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGs5NeverOTg5012_sSSSaySfG18j14MLComponents16lm3Vy6n4ML13pq2Vyu20GSSGIgggr_SS_AAtAIs5r68OIegnrzr_TR03_s8a80ML38SoundClassifierTrainingSessionDelegateC13loadg44FrameySay0A12MLComponents16cd4Vy04e4B013gh36zu7GSSGG07F37I00iJ0VKFZALSS_SayZ7GtXEfU_Tf3nnnpf_nTf1cn_n = (char *)&v33;
  uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<[Float]>>);
  uint64_t v39 = *(void *)(v40 - 8);
  int64_t v7 = *(void *)(v39 + 64);
  int64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  uint64_t v49 = &v33;
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v36 = *(void *)(v10 - 8);
  int64_t v11 = *(void *)(v36 + 64);
  uint64_t v12 = alloca(v11);
  int64_t v13 = alloca(v11);
  uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  uint64_t v47 = *(void *)(v46 - 8);
  int64_t v14 = *(void *)(v47 + 64);
  uint64_t v15 = alloca(v14);
  long long v16 = alloca(v14);
  uint64_t v44 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Data>);
  uint64_t v43 = *(void *)(v44 - 8);
  int64_t v17 = *(void *)(v43 + 64);
  int64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  int64_t v45 = &v33;
  DataFrame.subscript.getter(0x7365727574616566, 0xE800000000000000, &type metadata for Data);
  DataFrame.subscript.getter(0x62614C7373616C63, 0xEA00000000006C65, &type metadata for String);
  v34[0] = 0;
  v34[1] = 0xE000000000000000;
  uint64_t v20 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>, (uint64_t)&protocol conformance descriptor for Column<A>);
  char v48 = &v33;
  OptionalColumnProtocol.filled(with:)(v34, v10, v20);
  (*(void (**)(uint64_t *, uint64_t))(v36 + 8))(&v33, v10);
  uint64_t v21 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
  uint64_t v22 = type metadata accessor for JSONDecoder(0);
  swift_allocObject(v22, *(unsigned int *)(v22 + 48), *(unsigned __int16 *)(v22 + 52));
  v34[0] = JSONDecoder.init()();
  uint64_t v23 = lazy protocol witness table accessor for type [Float] and conformance <A> [A](&lazy protocol witness table cache variable for type [Float] and conformance <A> [A], (uint64_t)&protocol witness table for Float, (uint64_t)&protocol conformance descriptor for <A> [A]);
  uint64_t v24 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type JSONDecoder and conformance JSONDecoder, (uint64_t (*)(uint64_t))&type metadata accessor for JSONDecoder, (uint64_t)&protocol conformance descriptor for JSONDecoder);
  uint64_t v25 = v35;
  Column.decoded<A, B>(_:using:)(v21, v34, v44, v21, v22, v23, v24);
  swift_release();
  if (v25)
  {
    (*(void (**)(uint64_t *, uint64_t))(v47 + 8))(v48, v46);
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v43 + 8))(v45, v44);
  }
  else
  {
    v34[0] = _swiftEmptyArrayStorage;
    uint64_t v27 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Float]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Float]>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v28 = v42;
    uint64_t v29 = MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGs5NeverOTg5012_sSSSaySfG18j14MLComponents16lm3Vy6n4ML13pq2Vyu20GSSGIgggr_SS_AAtAIs5r68OIegnrzr_TR03_s8a80ML38SoundClassifierTrainingSessionDelegateC13loadg44FrameySay0A12MLComponents16cd4Vy04e4B013gh36zu7GSSGG07F37I00iJ0VKFZALSS_SayZ7GtXEfU_Tf3nnnpf_nTf1cn_n;
    OptionalColumnProtocol.filled(with:)(v34, v42, v27);
    (*(void (**)(char *, uint64_t))(v41 + 8))(v29, v28);
    uint64_t v30 = (uint64_t)v37;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v47 + 16))(v37, v48, v46);
    uint64_t v31 = v40;
    uint64_t v32 = v39;
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v39 + 16))(v30 + *(int *)(v38 + 52), v49, v40);
    MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGs5NeverOTg5012_sSSSaySfG18j14MLComponents16lm3Vy6n4ML13pq2Vyu20GSSGIgggr_SS_AAtAIs5r68OIegnrzr_TR03_s8a80ML38SoundClassifierTrainingSessionDelegateC13loadg44FrameySay0A12MLComponents16cd4Vy04e4B013gh36zu7GSSGG07F37I00iJ0VKFZALSS_SayZ7GtXEfU_Tf3nnnpf_nTf1cn_n = _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVy11TabularData12FilledColumnVyAH0I0VySSGGAJyALySaySfGGGG_18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGs5NeverOTg5012_sSSSaySfG18j14MLComponents16lm3Vy6n4ML13pq2Vyu20GSSGIgggr_SS_AAtAIs5r68OIegnrzr_TR03_s8a80ML38SoundClassifierTrainingSessionDelegateC13loadg44FrameySay0A12MLComponents16cd4Vy04e4B013gh36zu7GSSGG07F37I00iJ0VKFZALSS_SayZ7GtXEfU_Tf3nnnpf_nTf1cn_n(v30);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v30, &demangling cache variable for type metadata for Zip2Sequence<FilledColumn<Column<String>>, FilledColumn<Column<[Float]>>>);
    (*(void (**)(uint64_t *, uint64_t))(v32 + 8))(v49, v31);
    (*(void (**)(uint64_t *, uint64_t))(v47 + 8))(v48, v46);
    (*(void (**)(uint64_t *, uint64_t))(v43 + 8))(v45, v44);
    return (uint64_t)MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGs5NeverOTg5012_sSSSaySfG18j14MLComponents16lm3Vy6n4ML13pq2Vyu20GSSGIgggr_SS_AAtAIs5r68OIegnrzr_TR03_s8a80ML38SoundClassifierTrainingSessionDelegateC13loadg44FrameySay0A12MLComponents16cd4Vy04e4B013gh36zu7GSSGG07F37I00iJ0VKFZALSS_SayZ7GtXEfU_Tf3nnnpf_nTf1cn_n;
  }
}

uint64_t specialized SoundClassifierTrainingSessionDelegate.populateFiles<A, B>(training:validation:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  double v12 = *(double *)(a3 + *(int *)(type metadata accessor for MLSoundClassifier.PersistentParameters(0) + 28));
  int64_t v5 = specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)(a1, v12);
  char v6 = (char)v5;
  v13[0] = v5;
  swift_bridgeObjectRetain((_BYTE)v5);
  specialized MutableCollection<>.sort(by:)(v13);
  if (v3)
  {
    swift_release();
    BUG();
  }
  swift_bridgeObjectRelease(v6);
  uint64_t v7 = *(void *)(v4 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles);
  *(void *)(v4 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles) = v13[0];
  swift_bridgeObjectRelease(v7);
  int64_t v8 = specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)(a2, v12);
  char v9 = (char)v8;
  v13[0] = v8;
  swift_bridgeObjectRetain((_BYTE)v8);
  specialized MutableCollection<>.sort(by:)(v13);
  swift_bridgeObjectRelease(v9);
  uint64_t v10 = *(void *)(v4 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles);
  *(void *)(v4 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles) = v13[0];
  return swift_bridgeObjectRelease(v10);
}

uint64_t key path getter for AnnotatedFeature.annotation : AnnotatedFeature<URL, String>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, &demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
}

uint64_t key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4)
{
  int64_t v5 = v4;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(a4);
  uint64_t result = AnnotatedFeature.annotation.getter(v6);
  _OWORD *v5 = v8;
  return result;
}

uint64_t key path setter for AnnotatedFeature.annotation : AnnotatedFeature<URL, String>(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, a4, &demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
}

uint64_t key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t *a5)
{
  uint64_t v6 = *a1;
  uint64_t v7 = a1[1];
  v10[0] = v6;
  v10[1] = v7;
  swift_bridgeObjectRetain(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(a5);
  return AnnotatedFeature.annotation.setter(v10, v8);
}

double *specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)(uint64_t a1, double a2)
{
  double v39 = a2;
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for URL(0) - 8) + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v31 = v29;
  uint64_t v44 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v40 = *(void *)(v44 - 8);
  int64_t v5 = *(void *)(v40 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v37 = v29;
  uint64_t v8 = alloca(v5);
  char v9 = alloca(v5);
  uint64_t v42 = v29;
  uint64_t v30 = a1;
  swift_bridgeObjectRetain(a1);
  specialized MutableCollection<>.sort(by:)(&v30);
  uint64_t v10 = *(void *)(v30 + 16);
  if (v10)
  {
    double v39 = v39 * 1000.0;
    uint64_t v11 = (*(unsigned __int8 *)(v40 + 80) + 32) & ~*(unsigned __int8 *)(v40 + 80);
    uint64_t v34 = v30;
    uint64_t v33 = v11;
    uint64_t v12 = v30 + v11;
    uint64_t v35 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v40 + 16);
    uint64_t v36 = *(void *)(v40 + 72);
    uint64_t v43 = (double *)_swiftEmptyArrayStorage;
    do
    {
      uint64_t v38 = v10;
      uint64_t v13 = v44;
      v35(v42, v12, v44);
      uint64_t v14 = (uint64_t)v31;
      AnnotatedFeature.feature.getter(v13);
      objc_allocWithZone((Class)AVAudioFile);
      id v15 = @nonobjc AVAudioFile.init(forReading:)(v14);
      int64_t v17 = v15;
      if (v15)
      {
        double v18 = (double)(int)[v15 length] * 1000.0;
        double v41 = v18;
        id v19 = [v17 fileFormat];
        id v20 = v19;
        [v20 sampleRate];
        double v32 = v18;

        uint64_t v16 = v38;
        if (v41 / v32 >= v39)
        {
          v35(v37, (uint64_t)v42, v44);
          if (swift_isUniquelyReferenced_nonNull_native(v43)) {
            uint64_t v21 = v43;
          }
          else {
            uint64_t v21 = (double *)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v43 + 2) + 1, 1, (uint64_t)v43);
          }
          unint64_t v22 = *((void *)v21 + 2);
          unint64_t v23 = *((void *)v21 + 3);
          *(void *)&double v24 = v22 + 1;
          if (v23 >> 1 <= v22)
          {
            *(void *)&double v41 = v22 + 1;
            uint64_t v27 = (double *)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v23 >= 2, v22 + 1, 1, (uint64_t)v21);
            double v24 = v41;
            uint64_t v21 = v27;
          }
          v21[2] = v24;
          uint64_t v43 = v21;
          uint64_t v25 = (char *)v21 + v33 + v36 * v22;
          uint64_t v26 = v40;
          (*(void (**)(char *, unsigned char *, uint64_t))(v40 + 32))(v25, v37, v44);

          (*(void (**)(unsigned char *, uint64_t))(v26 + 8))(v42, v44);
        }
        else
        {
          (*(void (**)(unsigned char *, uint64_t))(v40 + 8))(v42, v44);
        }
      }
      else
      {
        uint64_t v16 = v38;
        (*(void (**)(unsigned char *, uint64_t))(v40 + 8))(v42, v44);
      }
      v12 += v36;
      uint64_t v10 = v16 - 1;
    }
    while (v10);
    swift_release();
    return v43;
  }
  else
  {
    swift_release();
    return (double *)_swiftEmptyArrayStorage;
  }
}

Swift::Int_optional __swiftcall SoundClassifierTrainingSessionDelegate.itemCount(phase:)(CreateML::MLPhase phase)
{
  switch(*(unsigned char *)phase)
  {
    case 0:
    case 4:
      v2.is_nil = 1;
      v2.value = 0;
      return v2;
    case 1:
      uint64_t v3 = *(void *)(*(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles)
                     + 16);
      uint64_t v4 = *(void *)(v1 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles);
      BOOL v5 = __OFADD__(*(void *)(v4 + 16), v3);
      v2.value = *(void *)(v4 + 16) + v3;
      if (v5) {
        BUG();
      }
      goto LABEL_7;
    case 2:
      v2.value = 1;
      goto LABEL_7;
    case 3:
      v2.value = 0;
LABEL_7:
      v2.is_nil = 0;
      return v2;
  }
}

Swift::tuple_Int_finished_Bool __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> SoundClassifierTrainingSessionDelegate.extractFeatures(from:)(Swift::Int from)
{
  uint64_t v50 = v1;
  uint64_t v51 = v2;
  Swift::Int v52 = from;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  uint64_t v4 = alloca(v3);
  BOOL v5 = alloca(v3);
  uint64_t v6 = (int *)type metadata accessor for MLSoundClassifier.PersistentParameters(0);
  int64_t v7 = *(void *)(*((void *)v6 - 1) + 64);
  uint64_t v8 = alloca(v7);
  char v9 = alloca(v7);
  uint64_t v10 = v51 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v51 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters, v43, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, (uint64_t)&v33, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v33, 1, (uint64_t)v6) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v33, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    BUG();
  }
  char v56 = &v33;
  outlined init with take of MLClassifierMetrics((uint64_t)&v33, (uint64_t)&v33, type metadata accessor for MLSoundClassifier.PersistentParameters);
  uint64_t v11 = *(void *)(v51 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles);
  Swift::Int v12 = *(void *)(v11 + 16);
  uint64_t v13 = *(void *)(*(void *)(v51 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles)
                  + 16);
  if (__OFADD__(v13, v12)) {
    BUG();
  }
  if (v13 + v12 <= v52)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v56, type metadata accessor for MLSoundClassifier.PersistentParameters);
    v24.finished = 1;
    v24._0 = 0;
  }
  else
  {
    uint64_t v45 = *(void *)(v51 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles);
    Swift::Int v53 = v13 + v12;
    unint64_t v55 = *(void *)((char *)v56 + v6[6]);
    unint64_t v48 = *(void *)((char *)v56 + v6[7]);
    uint64_t v14 = v6[9];
    uint64_t v47 = *(void *)((char *)v56 + v14);
    LOBYTE(v54) = *((unsigned char *)v56 + v14 + 8);
    uint64_t v15 = v51 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_sessionParameters;
    uint64_t v16 = *(void *)(*(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 20) + v15);
    BOOL v17 = __OFADD__(v52, v16);
    Swift::Int v18 = v52 + v16;
    uint64_t v19 = v52 - v12;
    if (v52 >= v12)
    {
      if (v17) {
        BUG();
      }
      if (v53 < v18) {
        Swift::Int v18 = v53;
      }
      Swift::Int v49 = v18;
      BOOL v17 = __OFSUB__(v18, v12);
      uint64_t v25 = v18 - v12;
      if (v17) {
        BUG();
      }
      if (v25 < v19) {
        BUG();
      }
      if (v13 < v19) {
        BUG();
      }
      if (v19 < 0) {
        BUG();
      }
      if (v13 < v25) {
        BUG();
      }
      uint64_t v46 = v52 - v12;
      int v26 = *(unsigned __int8 *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>)
                                           - 8)
                               + 80);
      uint64_t v27 = v45;
      uint64_t v28 = v45 + ((v26 + 32) & ~v26);
      *(void *)&long long v33 = v55;
      *((void *)&v33 + 1) = v48;
      Swift::Int v34 = v12;
      Swift::Int v35 = v53;
      uint64_t v36 = v47;
      char v37 = v54;
      uint64_t v29 = type metadata accessor for MLSoundClassifier.FeatureExtractor();
      uint64_t v54 = swift_allocObject(v29, 88, 7);
      swift_bridgeObjectRetain(v27);
      swift_unknownObjectRetain(v27);
      uint64_t v30 = v50;
      specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(v27, v28, v46, 2 * v25 + 1, &v33);
      if (v30)
      {
        char v23 = v27;
        goto LABEL_23;
      }
      uint64_t v32 = MLSoundClassifier.FeatureExtractor.extractFeatures()();
      swift_bridgeObjectRelease(v27);
      swift_release();
      swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures + v51, v44, 33, 0);
      specialized Array.append<A>(contentsOf:)(v32);
    }
    else
    {
      if (v17) {
        BUG();
      }
      if (v12 < v18) {
        Swift::Int v18 = v12;
      }
      if (v18 < v52) {
        BUG();
      }
      if (v52 < 0) {
        BUG();
      }
      int v20 = *(unsigned __int8 *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>)
                                           - 8)
                               + 80);
      unint64_t v38 = v55;
      long long v39 = v48;
      unint64_t v55 = 2 * v18 + 1;
      Swift::Int v40 = v53;
      uint64_t v41 = v47;
      char v42 = v54;
      uint64_t v21 = type metadata accessor for MLSoundClassifier.FeatureExtractor();
      swift_allocObject(v21, 88, 7);
      Swift::Int v49 = v18;
      swift_bridgeObjectRetain(v11);
      swift_unknownObjectRetain(v11);
      uint64_t v22 = v50;
      specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(v11, v11 + ((v20 + 32) & ~v20), v52, v55, &v38);
      if (v22)
      {
        char v23 = v11;
LABEL_23:
        swift_bridgeObjectRelease(v23);
        v24._0 = outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v56, type metadata accessor for MLSoundClassifier.PersistentParameters);
        return v24;
      }
      uint64_t v31 = MLSoundClassifier.FeatureExtractor.extractFeatures()();
      swift_bridgeObjectRelease(v11);
      swift_release();
      swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures + v51, v44, 33, 0);
      specialized Array.append<A>(contentsOf:)(v31);
    }
    swift_endAccess(v44);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v56, type metadata accessor for MLSoundClassifier.PersistentParameters);
    v24._0 = v49 - v52;
    if (__OFSUB__(v49, v52)) {
      BUG();
    }
    v24.finished = v49 >= v53;
  }
  return v24;
}

uint64_t SoundClassifierTrainingSessionDelegate.train(from:)(uint64_t a1)
{
  v2[40] = v1;
  v2[39] = a1;
  unint64_t v3 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Classifier?)
                              - 8)
                  + 64)
      + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[41] = swift_task_alloc(v3);
  v2[42] = swift_task_alloc(v3);
  unint64_t v4 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?)
                              - 8)
                  + 64)
      + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[43] = swift_task_alloc(v4);
  v2[44] = swift_task_alloc(v4);
  uint64_t v5 = type metadata accessor for TrainingTablePrinter(0);
  v2[45] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[46] = v6;
  uint64_t v7 = *(void *)(v6 + 64);
  v2[47] = v7;
  unint64_t v8 = (v7 + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[48] = swift_task_alloc(v8);
  v2[49] = swift_task_alloc(v8);
  v2[50] = swift_task_alloc(v8);
  unint64_t v9 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TrainingTablePrinter?)
                              - 8)
                  + 64)
      + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[51] = swift_task_alloc(v9);
  v2[52] = swift_task_alloc(v9);
  v2[53] = swift_task_alloc(v9);
  v2[54] = swift_task_alloc(v9);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  v2[55] = swift_task_alloc((*(void *)(*(void *)(v10 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(SoundClassifierTrainingSessionDelegate.train(from:), 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;

  uint64_t v2 = *(void *)(*(void *)v1 + 560);
  *(void *)(*(void *)v1 + 568) = a1;
  swift_task_dealloc(v2);
  return swift_task_switch(SoundClassifierTrainingSessionDelegate.train(from:), 0, 0);
}

uint64_t SoundClassifierTrainingSessionDelegate.train(from:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v8 = *(void *)(v7 + 440);
  uint64_t v9 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters + *(void *)(v7 + 320);
  swift_beginAccess(v9, v7 + 16, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v9, v8, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  uint64_t v10 = type metadata accessor for MLSoundClassifier.PersistentParameters(0);
  LODWORD(v9) = __swift_getEnumTagSinglePayload(v8, 1, v10);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v8, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  if (v9 == 1) {
    BUG();
  }
  uint64_t v11 = *(void *)(v7 + 312);
  uint64_t v12 = *(void *)(v7 + 320);
  uint64_t v13 = v12 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_sessionParameters;
  uint64_t v14 = type metadata accessor for MLTrainingSessionParameters(0);
  uint64_t v15 = *(void *)(*(int *)(v14 + 20) + v13);
  *(void *)(v7 + 448) = v15;
  *(void *)(v7 + 280) = v11 + v15;
  *(unsigned char *)(v7 + 288) = __OFADD__(v11, v15);
  if (__OFADD__(v11, v15)) {
    BUG();
  }
  uint64_t v16 = *(void *)(v13 + *(int *)(v14 + 28));
  *(void *)(v7 + 456) = v16;
  *(void *)(v7 + 296) = v16 - v11;
  *(unsigned char *)(v7 + 304) = __OFSUB__(v16, v11);
  if (__OFSUB__(v16, v11)) {
    BUG();
  }
  uint64_t v65 = *(void *)(v7 + 360);
  uint64_t v17 = *(void *)(v7 + 432);
  uint64_t v18 = type metadata accessor for EventCollector();
  swift_allocObject(v18, 32, 7);
  uint64_t v61 = EventCollector.init()();
  *(void *)(v7 + 464) = v61;
  uint64_t v19 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_tablePrinter + v12;
  swift_beginAccess(v19, v7 + 40, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v19, v17, &demangling cache variable for type metadata for TrainingTablePrinter?);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v17, 1, v65);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v17, &demangling cache variable for type metadata for TrainingTablePrinter?);
  if (EnumTagSinglePayload == 1)
  {
    uint64_t v21 = *(void *)(v7 + 424);
    uint64_t v66 = *(void *)(v7 + 416);
    uint64_t v22 = *(void *)(v7 + 320);
    uint64_t v62 = *(void *)(v7 + 360);
    uint64_t v23 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures;
    swift_beginAccess(v22 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures, v7 + 64, 0, 0);
    static MLSoundClassifier.createTablePrinter(hasValidation:)(*(void *)(*(void *)(v22 + v23) + 16) != 0);
    __swift_storeEnumTagSinglePayload(v21, 0, 1, v62);
    swift_beginAccess(v19, v7 + 88, 33, 0);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v21, v19, &demangling cache variable for type metadata for TrainingTablePrinter?);
    swift_endAccess(v7 + 88);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v19, v66, &demangling cache variable for type metadata for TrainingTablePrinter?);
    if (__swift_getEnumTagSinglePayload(v66, 1, v62) == 1) {
      BUG();
    }
    uint64_t v24 = *(void *)(v7 + 416);
    TrainingTablePrinter.beginTable()();
    outlined destroy of MLActivityClassifier.ModelParameters(v24, type metadata accessor for TrainingTablePrinter);
  }
  uint64_t v25 = *(void *)(v7 + 360);
  uint64_t v26 = *(void *)(v7 + 408);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v19, v26, &demangling cache variable for type metadata for TrainingTablePrinter?);
  int v27 = __swift_getEnumTagSinglePayload(v26, 1, v25);
  uint64_t v28 = *(void *)(v7 + 408);
  if (v27 == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v28, &demangling cache variable for type metadata for TrainingTablePrinter?);
    return _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000027, "range [0.0, 1.0), but got " + 0x8000000000000000, "CreateML/_SoundClassifierTrainingSessionDelegate.swift", 54, 2, 296, 0);
  }
  else
  {
    uint64_t v30 = *(void *)(v7 + 320);
    outlined init with take of MLClassifierMetrics(v28, *(void *)(v7 + 400), type metadata accessor for TrainingTablePrinter);
    uint64_t v31 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures;
    swift_beginAccess(v30 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures, v7 + 112, 0, 0);
    uint64_t v32 = *(void *)(v30 + v31);
    *(void *)(v7 + 472) = v32;
    uint64_t v33 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier + v30;
    if (*(void *)(v32 + 16))
    {
      uint64_t v67 = v32;
      uint64_t v34 = *(void *)(v7 + 328);
      swift_beginAccess(v33, v7 + 136, 0, 0);
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v33, v34, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
      uint64_t v35 = type metadata accessor for MLSoundClassifier.Classifier(0);
      if (__swift_getEnumTagSinglePayload(v34, 1, v35) == 1) {
        BUG();
      }
      uint64_t v60 = *(void *)(v7 + 400);
      uint64_t v36 = *(void *)(v7 + 384);
      uint64_t v69 = v36;
      uint64_t v37 = *(void *)(v7 + 376);
      uint64_t v38 = *(void *)(v7 + 320);
      uint64_t v63 = *(void *)(v7 + 368);
      uint64_t v39 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures;
      swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures + v38, v7 + 160, 0, 0);
      uint64_t v40 = *(void *)(v38 + v39);
      *(void *)(v7 + 512) = v40;
      outlined init with copy of MLTrainingSessionParameters(v60, v36, type metadata accessor for TrainingTablePrinter);
      uint64_t v41 = *(unsigned __int8 *)(v63 + 80);
      uint64_t v42 = ~*(unsigned __int8 *)(v63 + 80) & (v41 + 24);
      uint64_t v43 = swift_allocObject(&unk_398FA0, v42 + v37, v41 | 7);
      *(void *)(v7 + 520) = v43;
      *(void *)(v43 + 16) = v61;
      outlined init with take of MLClassifierMetrics(v69, v43 + v42, type metadata accessor for TrainingTablePrinter);
      uint64_t v70 = (char *)&async function pointer to specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)
          + async function pointer to specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
      uint64_t v44 = dword_3A745C;
      swift_retain();
      swift_bridgeObjectRetain(v40);
      swift_bridgeObjectRetain(v67);
      uint64_t v45 = (void *)swift_task_alloc(v44);
      *(void *)(v7 + 528) = v45;
      void *v45 = v7;
      v45[1] = SoundClassifierTrainingSessionDelegate.train(from:);
      return ((uint64_t (*)(void, uint64_t, uint64_t, uint64_t (*)(uint64_t), uint64_t, uint64_t))v70)(*(void *)(v7 + 344), v40, v67, partial apply for closure #2 in SoundClassifierTrainingSessionDelegate.train(from:), v43, v46);
    }
    else
    {
      uint64_t v47 = *(void *)(v7 + 336);
      swift_beginAccess(v33, v7 + 208, 0, 0);
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v33, v47, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
      uint64_t v48 = type metadata accessor for MLSoundClassifier.Classifier(0);
      if (__swift_getEnumTagSinglePayload(v47, 1, v48) == 1) {
        BUG();
      }
      uint64_t v64 = *(void *)(v7 + 400);
      uint64_t v49 = *(void *)(v7 + 392);
      uint64_t v50 = *(void *)(v7 + 376);
      uint64_t v51 = *(void *)(v7 + 320);
      uint64_t v71 = *(void *)(v7 + 368);
      uint64_t v52 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures;
      swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures + v51, v7 + 232, 0, 0);
      uint64_t v68 = *(void *)(v51 + v52);
      *(void *)(v7 + 480) = v68;
      uint64_t v53 = v49;
      outlined init with copy of MLTrainingSessionParameters(v64, v49, type metadata accessor for TrainingTablePrinter);
      uint64_t v54 = *(unsigned __int8 *)(v71 + 80);
      uint64_t v55 = ~*(unsigned __int8 *)(v71 + 80) & (v54 + 24);
      uint64_t v56 = swift_allocObject(&unk_398FC8, v55 + v50, v54 | 7);
      *(void *)(v7 + 488) = v56;
      *(void *)(v56 + 16) = v61;
      outlined init with take of MLClassifierMetrics(v53, v56 + v55, type metadata accessor for TrainingTablePrinter);
      uint64_t v72 = (char *)&async function pointer to specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:)
          + async function pointer to specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
      uint64_t v57 = dword_3A746C;
      swift_bridgeObjectRetain(v68);
      swift_retain();
      uint64_t v58 = (void *)swift_task_alloc(v57);
      *(void *)(v7 + 496) = v58;
      *uint64_t v58 = v7;
      v58[1] = SoundClassifierTrainingSessionDelegate.train(from:);
      return ((uint64_t (*)(void, uint64_t, uint64_t (*)(uint64_t), uint64_t, uint64_t))v72)(*(void *)(v7 + 352), v68, partial apply for closure #1 in SoundClassifierTrainingSessionDelegate.train(from:), v56, v59);
    }
  }
}

uint64_t SoundClassifierTrainingSessionDelegate.train(from:)()
{
  uint64_t v3 = *(void *)(*v1 + 496);
  uint64_t v4 = *(void *)(*v1 + 480);
  uint64_t v2 = *v1;
  *(void *)(*v1 + 504) = v0;
  swift_task_dealloc(v3);
  swift_release();
  swift_bridgeObjectRelease(v4);
  if (v0)
  {
    uint64_t v5 = SoundClassifierTrainingSessionDelegate.train(from:);
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v2 + 336), type metadata accessor for MLSoundClassifier.Classifier);
    uint64_t v5 = SoundClassifierTrainingSessionDelegate.train(from:);
  }
  return swift_task_switch(v5, 0, 0);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  void *v8;
  void *v9;

  uint64_t v1 = v0[40];
  uint64_t v2 = v0[44];
  uint64_t v3 = type metadata accessor for MLSoundClassifier.Model(0);
  __swift_storeEnumTagSinglePayload(v2, 0, 1, v3);
  uint64_t v4 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model + v1;
  swift_beginAccess(v4, v0 + 32, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v2, v4, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
  swift_endAccess(v0 + 32);
  uint64_t v5 = v0[35];
  uint64_t v6 = v0[37];
  if (v0[56] < v6) {
    uint64_t v6 = v0[56];
  }
  v0[68] = v6;
  v0[69] = v5;
  static os_log_type_t.info.getter();
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v8 = (void *)swift_allocObject(v7, 72, 7);
  v8[2] = 1;
  v8[3] = 2;
  v8[7] = &type metadata for Int;
  v8[8] = &protocol witness table for Int;
  v8[4] = 3;
  os_log(_:dso:log:type:_:)("event: %lu", 10);
  swift_bridgeObjectRelease((_BYTE)v8);
  uint64_t v9 = (void *)swift_task_alloc(dword_3A7464);
  v0[70] = v9;
  *uint64_t v9 = v0;
  v9[1] = SoundClassifierTrainingSessionDelegate.train(from:);
  return SoundClassifierTrainingSessionDelegate.buildMetrics(eventCollector:)(v0[58]);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t (*v5)();
  uint64_t v7;

  uint64_t v3 = *(void *)(*v1 + 528);
  uint64_t v4 = *(void *)(*v1 + 472);
  uint64_t v7 = *(void *)(*v1 + 512);
  uint64_t v2 = *v1;
  *(void *)(*v1 + 536) = v0;
  swift_task_dealloc(v3);
  swift_release();
  swift_bridgeObjectRelease(v4);
  swift_bridgeObjectRelease(v7);
  if (v0)
  {
    uint64_t v5 = SoundClassifierTrainingSessionDelegate.train(from:);
  }
  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v2 + 328), type metadata accessor for MLSoundClassifier.Classifier);
    uint64_t v5 = SoundClassifierTrainingSessionDelegate.train(from:);
  }
  return swift_task_switch(v5, 0, 0);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  void *v8;
  void *v9;

  uint64_t v1 = v0[40];
  uint64_t v2 = v0[43];
  uint64_t v3 = type metadata accessor for MLSoundClassifier.Model(0);
  __swift_storeEnumTagSinglePayload(v2, 0, 1, v3);
  uint64_t v4 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model + v1;
  swift_beginAccess(v4, v0 + 23, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v2, v4, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
  swift_endAccess(v0 + 23);
  uint64_t v5 = v0[35];
  uint64_t v6 = v0[37];
  if (v0[56] < v6) {
    uint64_t v6 = v0[56];
  }
  v0[68] = v6;
  v0[69] = v5;
  static os_log_type_t.info.getter();
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v8 = (void *)swift_allocObject(v7, 72, 7);
  v8[2] = 1;
  v8[3] = 2;
  v8[7] = &type metadata for Int;
  v8[8] = &protocol witness table for Int;
  v8[4] = 3;
  os_log(_:dso:log:type:_:)("event: %lu", 10);
  swift_bridgeObjectRelease((_BYTE)v8);
  uint64_t v9 = (void *)swift_task_alloc(dword_3A7464);
  v0[70] = v9;
  *uint64_t v9 = v0;
  v9[1] = SoundClassifierTrainingSessionDelegate.train(from:);
  return SoundClassifierTrainingSessionDelegate.buildMetrics(eventCollector:)(v0[58]);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;

  uint64_t v1 = *(void *)(v0 + 568);
  uint64_t v2 = *(void *)(v0 + 440);
  uint64_t v15 = *(void *)(v0 + 432);
  uint64_t v14 = *(void *)(v0 + 424);
  uint64_t v13 = *(void *)(v0 + 416);
  uint64_t v12 = *(void *)(v0 + 408);
  uint64_t v3 = *(void *)(v0 + 400);
  uint64_t v11 = *(void *)(v0 + 392);
  uint64_t v10 = *(void *)(v0 + 384);
  uint64_t v9 = *(void *)(v0 + 352);
  uint64_t v8 = *(void *)(v0 + 344);
  uint64_t v6 = *(void *)(v0 + 328);
  uint64_t v7 = *(void *)(v0 + 336);
  uint64_t v5 = specialized _dictionaryUpCast<A, B, C, D>(_:)(v1);
  swift_bridgeObjectRelease(v1);
  swift_release();
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for TrainingTablePrinter);
  swift_task_dealloc(v2);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v3);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void, void *, BOOL))(v0 + 8))(*(void *)(v0 + 544), v5, *(void *)(v0 + 552) >= *(void *)(v0 + 456));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v6 = *(void *)(v0 + 328);
  uint64_t v1 = *(void *)(v0 + 336);
  uint64_t v2 = *(void *)(v0 + 440);
  uint64_t v3 = *(void *)(v0 + 432);
  uint64_t v13 = *(void *)(v0 + 424);
  uint64_t v12 = *(void *)(v0 + 416);
  uint64_t v11 = *(void *)(v0 + 408);
  uint64_t v4 = *(void *)(v0 + 400);
  uint64_t v10 = *(void *)(v0 + 392);
  uint64_t v9 = *(void *)(v0 + 384);
  uint64_t v8 = *(void *)(v0 + 352);
  uint64_t v7 = *(void *)(v0 + 344);
  swift_release();
  outlined destroy of MLActivityClassifier.ModelParameters(v4, type metadata accessor for TrainingTablePrinter);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLSoundClassifier.Classifier);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v4);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v1);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;

  uint64_t v1 = *(void *)(v0 + 440);
  uint64_t v2 = *(void *)(v0 + 432);
  uint64_t v13 = *(void *)(v0 + 424);
  uint64_t v12 = *(void *)(v0 + 416);
  uint64_t v11 = *(void *)(v0 + 408);
  uint64_t v3 = *(void *)(v0 + 400);
  uint64_t v10 = *(void *)(v0 + 392);
  uint64_t v9 = *(void *)(v0 + 384);
  uint64_t v8 = *(void *)(v0 + 352);
  uint64_t v7 = *(void *)(v0 + 344);
  uint64_t v4 = *(void *)(v0 + 328);
  uint64_t v6 = *(void *)(v0 + 336);
  swift_release();
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for TrainingTablePrinter);
  outlined destroy of MLActivityClassifier.ModelParameters(v4, type metadata accessor for MLSoundClassifier.Classifier);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v3);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  swift_task_dealloc(v4);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v5[6] = v4;
  v5[5] = a4;
  v5[4] = a3;
  v5[3] = a1;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v5[7] = v6;
  uint64_t v7 = *(void *)(v6 - 8);
  v5[8] = v7;
  v5[9] = swift_task_alloc((*(void *)(v7 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  v5[10] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v5[11] = v9;
  v5[12] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v5[13] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v5[14] = v11;
  v5[15] = swift_task_alloc((*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  v5[16] = v12;
  uint64_t v13 = *(void *)(v12 - 8);
  v5[17] = v13;
  v5[18] = swift_task_alloc((*(void *)(v13 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  v5[19] = v14;
  v5[20] = swift_task_alloc((*(void *)(*(void *)(v14 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  v5[2] = a2;
  return swift_task_switch(specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:), 0, 0);
}

uint64_t specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:)()
{
  uint64_t v14 = v0 + 2;
  uint64_t v1 = v0[20];
  uint64_t v2 = v0[6];
  uint64_t v3 = v0[19];
  uint64_t v4 = type metadata accessor for MLSoundClassifier.Classifier(0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v2 + *(int *)(v4 + 20), v1, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v1, v3);
  uint64_t v6 = v0[20];
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(v0[11] + 32))(v0[12], v6, v0[10]);
    uint64_t v7 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifier.fitted<A>(to:eventHandler:)[1]);
    v0[23] = v7;
    uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    uint64_t v9 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>], (uint64_t)&protocol conformance descriptor for [A]);
    void *v7 = v0;
    v7[1] = specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
    return FullyConnectedNetworkClassifier.fitted<A>(to:eventHandler:)(v0[9], v14, v0[4], v0[5], v0[10], v8, v9);
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(v0[17] + 32))(v0[18], v6, v0[16]);
    uint64_t v11 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifier.fitted<A>(to:eventHandler:)[1]);
    v0[21] = v11;
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    uint64_t v13 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>], (uint64_t)&protocol conformance descriptor for [A]);
    void *v11 = v0;
    v11[1] = specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
    return LogisticRegressionClassifier.fitted<A>(to:eventHandler:)(v0[15], v14, v0[4], v0[5], v0[16], v12, v13);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 168);
  *(void *)(*(void *)v1 + 176) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
  }
  else {
    uint64_t v3 = specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 184);
  *(void *)(*(void *)v1 + 192) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
  }
  else {
    uint64_t v3 = specialized MLSoundClassifier.Classifier.fitted<A>(to:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;

  uint64_t v1 = *(void *)(v0 + 144);
  uint64_t v2 = *(void *)(v0 + 120);
  uint64_t v11 = *(void *)(v0 + 112);
  uint64_t v12 = *(void *)(v0 + 104);
  uint64_t v10 = *(void *)(v0 + 160);
  uint64_t v9 = *(void *)(v0 + 96);
  uint64_t v8 = *(void *)(v0 + 72);
  uint64_t v3 = *(void *)(v0 + 24);
  uint64_t v4 = *(void *)(v0 + 48);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 136) + 8))(v1, *(void *)(v0 + 128));
  outlined init with copy of MLTrainingSessionParameters(v4, v3, type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v5 = v3 + *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v11 + 32))(v5, v2, v12);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload(v5, v6, 0);
  swift_task_dealloc(v10);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;

  uint64_t v1 = *(void *)(v0 + 144);
  uint64_t v2 = *(void *)(v0 + 160);
  uint64_t v3 = *(void *)(v0 + 120);
  uint64_t v6 = *(void *)(v0 + 72);
  uint64_t v4 = *(void *)(v0 + 96);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 136) + 8))(v1, *(void *)(v0 + 128));
  swift_task_dealloc(v2);
  swift_task_dealloc(v1);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;

  uint64_t v9 = *(void *)(v0 + 96);
  uint64_t v1 = *(void *)(v0 + 72);
  uint64_t v12 = *(void *)(v0 + 64);
  uint64_t v2 = *(void *)(v0 + 56);
  uint64_t v11 = *(void *)(v0 + 160);
  uint64_t v10 = *(void *)(v0 + 144);
  uint64_t v8 = *(void *)(v0 + 120);
  uint64_t v3 = *(void *)(v0 + 24);
  uint64_t v4 = *(void *)(v0 + 48);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 88) + 8))(v9, *(void *)(v0 + 80));
  outlined init with copy of MLTrainingSessionParameters(v4, v3, type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v5 = v3 + *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v12 + 32))(v5, v1, v2);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload(v5, v6, 1);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;

  uint64_t v1 = *(void *)(v0 + 96);
  uint64_t v6 = *(void *)(v0 + 72);
  uint64_t v2 = *(void *)(v0 + 160);
  uint64_t v3 = *(void *)(v0 + 144);
  uint64_t v4 = *(void *)(v0 + 120);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 88) + 8))(v1, *(void *)(v0 + 80));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v1);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t closure #2 in SoundClassifierTrainingSessionDelegate.train(from:)(uint64_t a1, __m128 a2)
{
  return TrainingTablePrinter.print(_:)(a1, a2);
}

uint64_t specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  v6[7] = v5;
  v6[6] = a5;
  void v6[5] = a4;
  v6[4] = a1;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v6[8] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v6[9] = v9;
  v6[10] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifier<Float, String>);
  v6[11] = v10;
  uint64_t v11 = *(void *)(v10 - 8);
  v6[12] = v11;
  v6[13] = swift_task_alloc((*(void *)(v11 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v6[14] = v12;
  uint64_t v13 = *(void *)(v12 - 8);
  v6[15] = v13;
  v6[16] = swift_task_alloc((*(void *)(v13 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Float, String>);
  v6[17] = v14;
  uint64_t v15 = *(void *)(v14 - 8);
  v6[18] = v15;
  v6[19] = swift_task_alloc((*(void *)(v15 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  v6[20] = v16;
  v6[21] = swift_task_alloc((*(void *)(*(void *)(v16 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  v6[2] = a2;
  v6[3] = a3;
  return swift_task_switch(specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:), 0, 0);
}

uint64_t specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)()
{
  uint64_t v13 = v0 + 2;
  uint64_t v12 = v0 + 3;
  uint64_t v1 = v0[21];
  uint64_t v2 = v0[7];
  uint64_t v3 = v0[20];
  uint64_t v4 = type metadata accessor for MLSoundClassifier.Classifier(0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v2 + *(int *)(v4 + 20), v1, &demangling cache variable for type metadata for Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v1, v3);
  uint64_t v6 = v0[21];
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(v0[12] + 32))(v0[13], v6, v0[11]);
    uint64_t v7 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifier.fitted<A, B>(to:validateOn:eventHandler:)[1]);
    v0[24] = v7;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    uint64_t v8 = (void *)lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>], (uint64_t)&protocol conformance descriptor for [A]);
    void *v7 = v0;
    v7[1] = specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
    retaddr = v8;
    return FullyConnectedNetworkClassifier.fitted<A, B>(to:validateOn:eventHandler:)(v0[10], v13, v12, v0[5], v0[6], v0[11]);
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(v0[18] + 32))(v0[19], v6, v0[17]);
    uint64_t v10 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifier.fitted<A, B>(to:validateOn:eventHandler:)[1]);
    v0[22] = v10;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>]);
    uint64_t v11 = (void *)lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Float>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Float>, String>], (uint64_t)&protocol conformance descriptor for [A]);
    *uint64_t v10 = v0;
    v10[1] = specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
    retaddr = v11;
    return LogisticRegressionClassifier.fitted<A, B>(to:validateOn:eventHandler:)(v0[16], v13, v12, v0[5], v0[6], v0[17]);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 176);
  *(void *)(*(void *)v1 + 184) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  }
  else {
    uint64_t v3 = specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 192);
  *(void *)(*(void *)v1 + 200) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  }
  else {
    uint64_t v3 = specialized MLSoundClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;

  uint64_t v1 = *(void *)(v0 + 152);
  uint64_t v2 = *(void *)(v0 + 128);
  uint64_t v11 = *(void *)(v0 + 120);
  uint64_t v12 = *(void *)(v0 + 112);
  uint64_t v10 = *(void *)(v0 + 168);
  uint64_t v9 = *(void *)(v0 + 104);
  uint64_t v8 = *(void *)(v0 + 80);
  uint64_t v3 = *(void *)(v0 + 32);
  uint64_t v4 = *(void *)(v0 + 56);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 144) + 8))(v1, *(void *)(v0 + 136));
  outlined init with copy of MLTrainingSessionParameters(v4, v3, type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v5 = v3 + *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v11 + 32))(v5, v2, v12);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload(v5, v6, 0);
  swift_task_dealloc(v10);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;

  uint64_t v1 = *(void *)(v0 + 152);
  uint64_t v2 = *(void *)(v0 + 168);
  uint64_t v3 = *(void *)(v0 + 128);
  uint64_t v6 = *(void *)(v0 + 80);
  uint64_t v4 = *(void *)(v0 + 104);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 144) + 8))(v1, *(void *)(v0 + 136));
  swift_task_dealloc(v2);
  swift_task_dealloc(v1);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;

  uint64_t v9 = *(void *)(v0 + 104);
  uint64_t v1 = *(void *)(v0 + 80);
  uint64_t v12 = *(void *)(v0 + 72);
  uint64_t v2 = *(void *)(v0 + 64);
  uint64_t v11 = *(void *)(v0 + 168);
  uint64_t v10 = *(void *)(v0 + 152);
  uint64_t v8 = *(void *)(v0 + 128);
  uint64_t v3 = *(void *)(v0 + 32);
  uint64_t v4 = *(void *)(v0 + 56);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 96) + 8))(v9, *(void *)(v0 + 88));
  outlined init with copy of MLTrainingSessionParameters(v4, v3, type metadata accessor for MLSoundClassifier.ModelParameters);
  uint64_t v5 = v3 + *(int *)(type metadata accessor for MLSoundClassifier.Model(0) + 20);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v12 + 32))(v5, v1, v2);
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  swift_storeEnumTagMultiPayload(v5, v6, 1);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;

  uint64_t v1 = *(void *)(v0 + 104);
  uint64_t v6 = *(void *)(v0 + 80);
  uint64_t v2 = *(void *)(v0 + 168);
  uint64_t v3 = *(void *)(v0 + 152);
  uint64_t v4 = *(void *)(v0 + 128);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 96) + 8))(v1, *(void *)(v0 + 88));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v1);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t SoundClassifierTrainingSessionDelegate.buildMetrics(eventCollector:)(uint64_t a1)
{
  v1[2] = a1;
  uint64_t v2 = type metadata accessor for MetricsKey(0);
  v1[3] = v2;
  uint64_t v3 = *(void *)(v2 - 8);
  v1[4] = v3;
  v1[5] = swift_task_alloc((*(void *)(v3 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(SoundClassifierTrainingSessionDelegate.buildMetrics(eventCollector:), 0, 0);
}

uint64_t SoundClassifierTrainingSessionDelegate.buildMetrics(eventCollector:)()
{
  unint64_t v1 = *(void *)(v0 + 40);
  uint64_t v2 = *(void *)(v0 + 32);
  uint64_t v28 = *(void *)(v0 + 24);
  static MetricsKey.trainingAccuracy.getter();
  id v3 = specialized EventCollector.getLast<A>(metric:type:)();
  char v5 = v4;
  uint64_t v6 = v28;
  uint64_t v29 = *(void (**)(unint64_t, uint64_t))(v2 + 8);
  v29(v1, v6);
  if ((v5 & 1) == 0)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)(3, isUniquelyReferenced_nonNull_native, *(double *)&v3);
    swift_bridgeObjectRelease(0);
  }
  unint64_t v8 = *(void *)(v0 + 40);
  uint64_t v9 = *(void *)(v0 + 24);
  static MetricsKey.validationAccuracy.getter();
  id v10 = specialized EventCollector.getLast<A>(metric:type:)();
  char v12 = v11;
  unint64_t v13 = v8;
  v29(v8, v9);
  if ((v12 & 1) == 0)
  {
    char v14 = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)(5, v14, *(double *)&v10);
    unint64_t v13 = 0x8000000000000000;
    swift_bridgeObjectRelease(0);
  }
  unint64_t v15 = *(void *)(v0 + 40);
  uint64_t v16 = *(void *)(v0 + 24);
  static MetricsKey.trainingLoss.getter(v13);
  id v17 = specialized EventCollector.getLast<A>(metric:type:)();
  char v19 = v18;
  v29(v15, v16);
  if ((v19 & 1) == 0)
  {
    char v20 = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)(0, v20, *(double *)&v17);
    swift_bridgeObjectRelease(0);
  }
  unint64_t v21 = *(void *)(v0 + 40);
  uint64_t v22 = *(void *)(v0 + 24);
  static MetricsKey.validationLoss.getter();
  id v23 = specialized EventCollector.getLast<A>(metric:type:)();
  char v25 = v24;
  v29(v21, v22);
  if ((v25 & 1) == 0)
  {
    char v26 = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)(4, v26, *(double *)&v23);
    swift_bridgeObjectRelease(0);
  }
  swift_task_dealloc(*(void *)(v0 + 40));
  return (*(uint64_t (**)(void *))(v0 + 8))(_swiftEmptyDictionarySingleton);
}

uint64_t SoundClassifierTrainingSessionDelegate.evaluate(from:)()
{
  v1[51] = v0;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationMetrics<String>);
  v1[52] = v2;
  uint64_t v3 = *(void *)(v2 - 8);
  v1[53] = v3;
  v1[54] = swift_task_alloc((*(void *)(v3 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  v1[55] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for MLSoundClassifier.ModelParameters(0);
  v1[56] = v5;
  unint64_t v6 = (*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v1[57] = swift_task_alloc(v6);
  v1[58] = swift_task_alloc(v6);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  v1[59] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLClassifierMetrics?);
  v1[60] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?);
  v1[61] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = type metadata accessor for MLSoundClassifier.Model(0);
  v1[62] = v10;
  v1[63] = swift_task_alloc((*(void *)(*(void *)(v10 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(SoundClassifierTrainingSessionDelegate.evaluate(from:), 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char *v12;
  uint64_t v13;
  void *v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;

  unint64_t v1 = *(void *)(v0 + 496);
  uint64_t v2 = *(void *)(v0 + 488);
  uint64_t v3 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model + *(void *)(v0 + 408);
  swift_beginAccess(v3, v0 + 128, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v3, v2, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 488), &demangling cache variable for type metadata for MLSoundClassifier.Model?);
    uint64_t v4 = *(void *)(v0 + 488);
    uint64_t v5 = *(void *)(v0 + 480);
    unint64_t v6 = *(void *)(v0 + 472);
    uint64_t v7 = *(void *)(v0 + 464);
    id v17 = *(void *)(v0 + 456);
    unint64_t v15 = *(void *)(v0 + 432);
    uint64_t v16 = *(void *)(v0 + 440);
    swift_task_dealloc(*(void *)(v0 + 504));
    swift_task_dealloc(v4);
    swift_task_dealloc(v5);
    swift_task_dealloc(v6);
    swift_task_dealloc(v7);
    swift_task_dealloc(v17);
    swift_task_dealloc(v16);
    swift_task_dealloc(v15);
    return (*(uint64_t (**)(void, uint64_t))(v0 + 8))(0, 1);
  }
  else
  {
    uint64_t v9 = *(void *)(v0 + 408);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 488), *(void *)(v0 + 504), type metadata accessor for MLSoundClassifier.Model);
    uint64_t v10 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures;
    *(void *)(v0 + 512) = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures;
    swift_beginAccess(v9 + v10, v0 + 152, 0, 0);
    char v11 = *(void *)(v9 + v10);
    *(void *)(v0 + 520) = v11;
    char v12 = (char *)&async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:)
        + async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:);
    unint64_t v13 = dword_3A743C;
    swift_bridgeObjectRetain(v11);
    char v14 = (void *)swift_task_alloc(v13);
    *(void *)(v0 + 528) = v14;
    *char v14 = v0;
    v14[1] = SoundClassifierTrainingSessionDelegate.evaluate(from:);
    return ((uint64_t (*)(uint64_t, void, void))v12)(v11, 0, 0);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  void *MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
  uint64_t v5;
  void *v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t *v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  char *v20;
  uint64_t v21;
  void *v22;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t (*v31)(uint64_t, uint64_t (*)(uint64_t));
  uint64_t v32;
  uint64_t (*v33)(uint64_t);
  uint64_t v34;
  uint64_t v35;
  int *v36;
  uint64_t v37;
  uint64_t v38;
  int *v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;
  char v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  uint64_t v56;
  uint64_t v57;
  uint64_t v58;
  uint64_t *v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;
  uint64_t v70;
  uint64_t v71;
  uint64_t v72;
  uint64_t v73;
  uint64_t v74;
  uint64_t v75;
  double v76;
  uint64_t v77;
  char v78;

  unint64_t v1 = *(void *)(v0 + 544);
  uint64_t v2 = *(void *)(v0 + 536);
  uint64_t v60 = *(void *)(v0 + 512);
  uint64_t v3 = *(void *)(v0 + 408);
  uint64_t v64 = *(void *)(v0 + 480);
  MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v1, v0 + 344, &demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>, (uint64_t)&unk_349F10);
  swift_bridgeObjectRelease(v1);
  *(void *)(v0 + 352) = MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
  uint64_t v5 = *(void *)(v3 + v60);
  swift_bridgeObjectRetain(v5);
  unint64_t v6 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v5, v0 + 360, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>, (uint64_t)&unk_349ED8);
  uint64_t v62 = v2;
  swift_bridgeObjectRelease(v5);
  *(void *)(v0 + 368) = v6;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  *(void *)(v0 + 552) = v7;
  uint64_t v8 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [String] and conformance [A], &demangling cache variable for type metadata for [String], (uint64_t)&protocol conformance descriptor for [A]);
  *(void *)(v0 + 560) = v8;
  ClassificationMetrics.init<A, B>(_:_:)(v0 + 352, v0 + 368, &type metadata for String, v7, v7, &protocol witness table for String, v8, v8);
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
  *(void *)(v0 + 568) = v9;
  swift_storeEnumTagMultiPayload(v64, v9, 0);
  uint64_t v10 = type metadata accessor for MLClassifierMetrics.Contents(0);
  *(void *)(v0 + 576) = v10;
  swift_storeEnumTagMultiPayload(v64, v10, 0);
  char v11 = type metadata accessor for MLClassifierMetrics(0);
  *(void *)(v0 + 584) = v11;
  uint64_t v67 = v11;
  __swift_storeEnumTagSinglePayload(v64, 0, 1, v11);
  char v12 = v3 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingMetrics;
  swift_beginAccess(v3 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingMetrics, v0 + 176, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v64, v12, &demangling cache variable for type metadata for MLClassifierMetrics?);
  swift_endAccess(v0 + 176);
  uint64_t v70 = v3;
  uint64_t v74 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles;
  unint64_t v13 = *(void *)(v3 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles);
  if (*(void *)(v13 + 16))
  {
    char v14 = *(void *)(v0 + 408);
    unint64_t v15 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures;
    uint64_t v16 = (uint64_t *)(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures + v14);
    swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures + v14, v0 + 200, 1, 0);
    if (!*(void *)(*(void *)(v14 + v15) + 16))
    {
      uint64_t v59 = v16;
      uint64_t v65 = v13;
      uint64_t v34 = *(void *)(v0 + 472);
      uint64_t v35 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters + *(void *)(v0 + 408);
      swift_beginAccess(v35, v0 + 296, 0, 0);
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v35, v34, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
      uint64_t v36 = (int *)type metadata accessor for MLSoundClassifier.PersistentParameters(0);
      if (__swift_getEnumTagSinglePayload(v34, 1, (uint64_t)v36) == 1) {
        BUG();
      }
      uint64_t v37 = *(void *)(v0 + 472);
      uint64_t v54 = *(void *)(v0 + 464);
      uint64_t v38 = *(void *)(v0 + 456);
      uint64_t v61 = *(void *)(v0 + 440);
      uint64_t v39 = *(int **)(v0 + 448);
      outlined init with copy of MLTrainingSessionParameters(v37 + v36[5], v61, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      uint64_t v57 = *(void *)(v37 + v36[8]);
      uint64_t v58 = *(void *)(v37 + v36[6]);
      uint64_t v40 = v36[9];
      uint64_t v56 = *(void *)(v37 + v40);
      uint64_t v78 = *(unsigned char *)(v37 + v40 + 8);
      uint64_t v41 = *(void *)(v37 + v40 + 16);
      uint64_t v42 = v39[7];
      *(_OWORD *)(v38 + v42) = 0;
      *(_OWORD *)(v38 + v42 + 16) = 0;
      uint64_t v43 = v39[8];
      *(void *)(v38 + v43) = 0;
      uint64_t v55 = v38 + v42;
      *(unsigned char *)(v38 + v43 + 8) = 1;
      *(void *)(v38 + v39[9]) = 32;
      outlined init with copy of MLTrainingSessionParameters(v61, v38, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      *(void *)(v38 + v39[5]) = v57;
      *(void *)(v38 + v39[6]) = v58;
      *(void *)(v0 + 88) = &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType;
      *(void *)(v0 + 64) = v56;
      *(unsigned char *)(v0 + 72) = v78;
      *(void *)(v0 + 80) = v41;
      swift_bridgeObjectRetain(v41);
      swift_bridgeObjectRetain(v65);
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v0 + 64, v55, &demangling cache variable for type metadata for Any?);
      outlined destroy of MLActivityClassifier.ModelParameters(v61, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      outlined init with take of MLClassifierMetrics(v38, v54, type metadata accessor for MLSoundClassifier.ModelParameters);
      outlined destroy of MLActivityClassifier.ModelParameters(v37, type metadata accessor for MLSoundClassifier.PersistentParameters);
      uint64_t v44 = *(void *)(*(void *)(v70 + v74) + 16);
      uint64_t v72 = *(void *)(v54 + v39[6]);
      uint64_t v45 = v0 + 96;
      uint64_t v76 = MLSoundClassifier.ModelParameters.featureExtractionTimeWindowSize.getter();
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v54 + v39[7], v0 + 96, &demangling cache variable for type metadata for Any?);
      if (*(void *)(v0 + 120))
      {
        uint64_t v46 = 1;
        if (swift_dynamicCast(v0 + 320, v45, (char *)&type metadata for Any + 8, &type metadata for MLSoundClassifier.ModelParameters.ModelAlgorithmType, 6))
        {
          uint64_t v46 = *(void *)(v0 + 320);
          uint64_t v47 = *(unsigned char *)(v0 + 328);
          uint64_t v45 = *(void *)(v0 + 336);
        }
        else
        {
          uint64_t v47 = 1;
          LOBYTE(v45) = 0;
        }
      }
      else
      {
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v45, &demangling cache variable for type metadata for Any?);
        uint64_t v47 = 1;
        LOBYTE(v45) = 0;
        uint64_t v46 = 1;
      }
      outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 464), type metadata accessor for MLSoundClassifier.ModelParameters);
      swift_bridgeObjectRelease(v45);
      *(void *)(v0 + 16) = v72;
      *(_OWORD *)(v0 + 24) = *(unint64_t *)&v76;
      *(void *)(v0 + 40) = v44;
      *(void *)(v0 + 48) = v46;
      *(unsigned char *)(v0 + 56) = v47;
      uint64_t v48 = type metadata accessor for MLSoundClassifier.FeatureExtractor();
      swift_allocObject(v48, 88, 7);
      swift_bridgeObjectRetain(v65);
      specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(v65, (_OWORD *)(v0 + 16));
      if (v62)
      {
        swift_bridgeObjectRelease(v65);
        uint64_t v50 = *(void *)(v0 + 504);
        uint64_t v51 = *(void *)(v0 + 488);
        uint64_t v52 = *(void *)(v0 + 480);
        uint64_t v63 = *(void *)(v0 + 472);
        uint64_t v66 = *(void *)(v0 + 464);
        uint64_t v77 = *(void *)(v0 + 456);
        uint64_t v73 = *(void *)(v0 + 432);
        uint64_t v69 = *(void *)(v0 + 440);
        uint64_t v33 = type metadata accessor for MLSoundClassifier.Model;
        outlined destroy of MLActivityClassifier.ModelParameters(v50, type metadata accessor for MLSoundClassifier.Model);
        swift_task_dealloc(v50);
        swift_task_dealloc(v51);
        swift_task_dealloc(v52);
        swift_task_dealloc(v63);
        swift_task_dealloc(v66);
        swift_task_dealloc(v77);
        swift_task_dealloc(v69);
        uint64_t v32 = v73;
        swift_task_dealloc(v73);
        uint64_t v31 = *(uint64_t (**)(uint64_t, uint64_t (*)(uint64_t)))(v0 + 8);
        return v31(v32, v33);
      }
      uint64_t v49 = MLSoundClassifier.FeatureExtractor.extractFeatures()();
      swift_release();
      swift_bridgeObjectRelease(v65);
      uint64_t v53 = *v59;
      *uint64_t v59 = v49;
      swift_bridgeObjectRelease(v53);
    }
  }
  id v17 = *(void *)(v0 + 408);
  char v18 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures;
  *(void *)(v0 + 592) = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures;
  swift_beginAccess(v18 + v17, v0 + 224, 0, 0);
  char v19 = *(void *)(v17 + v18);
  *(void *)(v0 + 600) = v19;
  if (*(void *)(v19 + 16))
  {
    char v20 = (char *)&async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:)
        + async function pointer to specialized Transformer.prediction<A, B>(from:eventHandler:);
    unint64_t v21 = dword_3A743C;
    swift_bridgeObjectRetain(v19);
    uint64_t v22 = (void *)swift_task_alloc(v21);
    *(void *)(v0 + 608) = v22;
    *uint64_t v22 = v0;
    v22[1] = SoundClassifierTrainingSessionDelegate.evaluate(from:);
    return ((uint64_t (*)(uint64_t, void, void))v20)(v19, 0, 0);
  }
  char v24 = *(void *)(v0 + 408);
  char v25 = *(void *)(v0 + 480);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 504), type metadata accessor for MLSoundClassifier.Model);
  __swift_storeEnumTagSinglePayload(v25, 1, 1, v67);
  char v26 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationMetrics + v24;
  swift_beginAccess(v26, v0 + 272, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v25, v26, &demangling cache variable for type metadata for MLClassifierMetrics?);
  swift_endAccess(v0 + 272);
  int v27 = *(void *)(v0 + 488);
  uint64_t v28 = *(void *)(v0 + 480);
  uint64_t v29 = *(void *)(v0 + 472);
  uint64_t v30 = *(void *)(v0 + 464);
  uint64_t v75 = *(void *)(v0 + 456);
  uint64_t v71 = *(void *)(v0 + 432);
  uint64_t v68 = *(void *)(v0 + 440);
  swift_task_dealloc(*(void *)(v0 + 504));
  swift_task_dealloc(v27);
  swift_task_dealloc(v28);
  swift_task_dealloc(v29);
  swift_task_dealloc(v30);
  swift_task_dealloc(v75);
  swift_task_dealloc(v68);
  swift_task_dealloc(v71);
  uint64_t v31 = *(uint64_t (**)(uint64_t, uint64_t (*)(uint64_t)))(v0 + 8);
  uint64_t v32 = 1;
  uint64_t v33 = (uint64_t (*)(uint64_t))(&dword_0 + 1);
  return v31(v32, v33);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  void *MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;

  unint64_t v1 = *(void *)(v0 + 624);
  char v20 = *(void *)(v0 + 592);
  uint64_t v22 = *(void *)(v0 + 584);
  char v24 = *(void *)(v0 + 576);
  char v12 = *(void *)(v0 + 568);
  id v17 = *(void *)(v0 + 560);
  char v18 = *(void *)(v0 + 552);
  uint64_t v16 = *(void *)(v0 + 504);
  char v14 = *(void *)(v0 + 480);
  char v19 = *(void *)(v0 + 432);
  unint64_t v13 = *(void *)(v0 + 424);
  uint64_t v2 = *(void *)(v0 + 408);
  unint64_t v15 = *(void *)(v0 + 416);
  MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v1, v0 + 376, &demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>, (uint64_t)&unk_349F10);
  swift_bridgeObjectRelease(v1);
  *(void *)(v0 + 384) = MLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm;
  uint64_t v4 = *(void *)(v2 + v20);
  swift_bridgeObjectRetain(v4);
  uint64_t v5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVy6CoreML13MLShapedArrayVySfGSSGG_SSs5NeverOTg503_s8d169ML38SoundClassifierTrainingSessionDelegateC13populateFiles33_6DADCD271D509E5C075FB900187437D410parametersyAA07MLSoundD0V20PersistentParametersV_tKFSS0A12MLComponents16fg4Vy04h4B013jK61VySfGSSGcfu0_32c7cfd4b680d8003eade90301c2a1b770ARSSTf3nnnpk_nTf1cn_nTm(v4, v0 + 392, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>, (uint64_t)&unk_349ED8);
  swift_bridgeObjectRelease(v4);
  *(void *)(v0 + 400) = v5;
  ClassificationMetrics.init<A, B>(_:_:)(v0 + 384, v0 + 400, &type metadata for String, v18, v18, &protocol witness table for String, v17, v17);
  outlined destroy of MLActivityClassifier.ModelParameters(v16, type metadata accessor for MLSoundClassifier.Model);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v13 + 32))(v14, v19, v15);
  swift_storeEnumTagMultiPayload(v14, v12, 0);
  swift_storeEnumTagMultiPayload(v14, v24, 0);
  __swift_storeEnumTagSinglePayload(v14, 0, 1, v22);
  unint64_t v6 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationMetrics + v2;
  swift_beginAccess(v6, v0 + 248, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v14, v6, &demangling cache variable for type metadata for MLClassifierMetrics?);
  swift_endAccess(v0 + 248);
  uint64_t v7 = *(void *)(v0 + 488);
  uint64_t v8 = *(void *)(v0 + 480);
  uint64_t v9 = *(void *)(v0 + 472);
  uint64_t v10 = *(void *)(v0 + 464);
  char v25 = *(void *)(v0 + 456);
  unint64_t v21 = *(void *)(v0 + 432);
  id v23 = *(void *)(v0 + 440);
  swift_task_dealloc(*(void *)(v0 + 504));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v10);
  swift_task_dealloc(v25);
  swift_task_dealloc(v23);
  swift_task_dealloc(v21);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v0 + 8))(1, 1);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;

  unint64_t v1 = *(void *)(v0 + 504);
  uint64_t v2 = *(void *)(v0 + 488);
  uint64_t v3 = *(void *)(v0 + 480);
  uint64_t v4 = *(void *)(v0 + 472);
  uint64_t v9 = *(void *)(v0 + 464);
  uint64_t v8 = *(void *)(v0 + 456);
  unint64_t v6 = *(void *)(v0 + 432);
  uint64_t v7 = *(void *)(v0 + 440);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLSoundClassifier.Model);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;

  unint64_t v1 = *(void *)(v0 + 504);
  uint64_t v2 = *(void *)(v0 + 488);
  uint64_t v3 = *(void *)(v0 + 480);
  uint64_t v4 = *(void *)(v0 + 472);
  uint64_t v9 = *(void *)(v0 + 464);
  uint64_t v8 = *(void *)(v0 + 456);
  unint64_t v6 = *(void *)(v0 + 432);
  uint64_t v7 = *(void *)(v0 + 440);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLSoundClassifier.Model);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v4);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t SoundClassifierTrainingSessionDelegate.evaluate(from:)(uint64_t a1)
{
  uint64_t v5 = *(void *)(*(void *)v2 + 528);
  uint64_t v4 = *(void **)v2;
  v4[67] = v1;
  swift_task_dealloc(v5);
  swift_bridgeObjectRelease(v4[65]);
  if (v1)
  {
    unint64_t v6 = SoundClassifierTrainingSessionDelegate.evaluate(from:);
  }
  else
  {
    v4[68] = a1;
    unint64_t v6 = SoundClassifierTrainingSessionDelegate.evaluate(from:);
  }
  return swift_task_switch(v6, 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;
  void *v4;
  uint64_t v5;
  uint64_t (*v6)();

  uint64_t v5 = *(void *)(*(void *)v2 + 608);
  uint64_t v4 = *(void **)v2;
  v4[77] = v1;
  swift_task_dealloc(v5);
  swift_bridgeObjectRelease(v4[75]);
  if (v1)
  {
    unint64_t v6 = SoundClassifierTrainingSessionDelegate.evaluate(from:);
  }
  else
  {
    v4[78] = a1;
    unint64_t v6 = SoundClassifierTrainingSessionDelegate.evaluate(from:);
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t specialized Transformer.prediction<A, B>(from:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v4[7] = v3;
  v4[6] = a3;
  void v4[5] = a2;
  v4[4] = a1;
  uint64_t v5 = type metadata accessor for MLSoundClassifier.Model(0);
  v4[8] = v5;
  v4[9] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for Event(0, a2, v6);
  v4[10] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  v4[11] = v8;
  v4[12] = swift_task_alloc((*(void *)(v8 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>);
  v4[13] = v9;
  uint64_t v10 = *(void *)(v9 - 8);
  v4[14] = v10;
  v4[15] = swift_task_alloc((*(void *)(v10 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v4[16] = v11;
  uint64_t v12 = *(void *)(v11 - 8);
  v4[17] = v12;
  v4[18] = swift_task_alloc((*(void *)(v12 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v4[19] = v13;
  uint64_t v14 = *(void *)(v13 - 8);
  v4[20] = v14;
  v4[21] = swift_task_alloc((*(void *)(v14 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  v4[22] = v15;
  v4[23] = swift_task_alloc((*(void *)(*(void *)(v15 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  v4[24] = v16;
  uint64_t v17 = *(void *)(v16 - 8);
  v4[25] = v17;
  v4[26] = swift_task_alloc((*(void *)(v17 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  v4[27] = v18;
  uint64_t v19 = *(void *)(v18 - 8);
  v4[28] = v19;
  unint64_t v20 = (*(void *)(v19 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[29] = swift_task_alloc(v20);
  v4[30] = swift_task_alloc(v20);
  uint64_t v21 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
  v4[31] = v21;
  uint64_t v22 = *(void *)(v21 - 8);
  v4[32] = v22;
  v4[33] = swift_task_alloc((*(void *)(v22 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized Transformer.prediction<A, B>(from:eventHandler:), 0, 0);
}

{
  uint64_t v3;
  void *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  unint64_t v20;
  uint64_t v21;
  uint64_t v22;

  v4[7] = v3;
  v4[6] = a3;
  void v4[5] = a2;
  v4[4] = a1;
  uint64_t v5 = type metadata accessor for MLImageClassifier.Model(0);
  v4[8] = v5;
  v4[9] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for Event(0, a2, v6);
  v4[10] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  v4[11] = v8;
  v4[12] = swift_task_alloc((*(void *)(v8 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>);
  v4[13] = v9;
  uint64_t v10 = *(void *)(v9 - 8);
  v4[14] = v10;
  v4[15] = swift_task_alloc((*(void *)(v10 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v4[16] = v11;
  uint64_t v12 = *(void *)(v11 - 8);
  v4[17] = v12;
  v4[18] = swift_task_alloc((*(void *)(v12 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v4[19] = v13;
  uint64_t v14 = *(void *)(v13 - 8);
  v4[20] = v14;
  v4[21] = swift_task_alloc((*(void *)(v14 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  v4[22] = v15;
  v4[23] = swift_task_alloc((*(void *)(*(void *)(v15 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  v4[24] = v16;
  uint64_t v17 = *(void *)(v16 - 8);
  v4[25] = v17;
  v4[26] = swift_task_alloc((*(void *)(v17 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  v4[27] = v18;
  uint64_t v19 = *(void *)(v18 - 8);
  v4[28] = v19;
  unint64_t v20 = (*(void *)(v19 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[29] = swift_task_alloc(v20);
  v4[30] = swift_task_alloc(v20);
  uint64_t v21 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
  v4[31] = v21;
  uint64_t v22 = *(void *)(v21 - 8);
  v4[32] = v22;
  v4[33] = swift_task_alloc((*(void *)(v22 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(specialized Transformer.prediction<A, B>(from:eventHandler:), 0, 0);
}

uint64_t specialized Transformer.prediction<A, B>(from:eventHandler:)()
{
  int64_t v1 = *(void *)(*(void *)(v0 + 32) + 16);
  *(void *)(v0 + 272) = v1;
  uint64_t v2 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0, (uint64_t)_swiftEmptyArrayStorage);
  if (v1)
  {
    uint64_t v3 = *(void *)(v0 + 256);
    int v4 = *(_DWORD *)(v3 + 80);
    *(_DWORD *)(v0 + 344) = v4;
    uint64_t v5 = *(void (**)(uint64_t, uint64_t, uint64_t))(v3 + 16);
    *(void *)(v0 + 280) = *(void *)(v3 + 72);
    *(void *)(v0 + 288) = v5;
    *(void *)(v0 + 304) = v2;
    *(void *)(v0 + 296) = 0;
    uint64_t v6 = *(void *)(v0 + 264);
    uint64_t v7 = *(void *)(v0 + 32);
    uint64_t v8 = *(void *)(v0 + 248);
    uint64_t v9 = v7 + ((v4 + 32) & ~v4);
    swift_bridgeObjectRetain(v7);
    v5(v6, v9, v8);
    static Task<>.checkCancellation()();
    uint64_t v14 = *(void *)(v0 + 184);
    uint64_t v27 = *(void *)(v0 + 176);
    uint64_t v15 = *(void *)(v0 + 56);
    uint64_t v16 = *(void *)(v0 + 64);
    AnnotatedFeature.feature.getter(*(void *)(v0 + 248));
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v15 + *(int *)(v16 + 20), v14, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v14, v27);
    uint64_t v18 = *(void *)(v0 + 184);
    if (EnumCaseMultiPayload == 1)
    {
      (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 136) + 32))(*(void *)(v0 + 144), v18, *(void *)(v0 + 128));
      uint64_t v19 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)[1]);
      *(void *)(v0 + 328) = v19;
      *uint64_t v19 = v0;
      v19[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
      return FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 240), *(void *)(v0 + 208), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 128));
    }
    else
    {
      (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 160) + 32))(*(void *)(v0 + 168), v18, *(void *)(v0 + 152));
      unint64_t v20 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifierModel.applied(to:eventHandler:)[1]);
      *(void *)(v0 + 312) = v20;
      void *v20 = v0;
      v20[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
      return LogisticRegressionClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 240), *(void *)(v0 + 208), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 152));
    }
  }
  else
  {
    uint64_t v10 = *(void *)(v0 + 240);
    uint64_t v11 = *(void *)(v0 + 232);
    uint64_t v12 = *(void *)(v0 + 208);
    uint64_t v25 = *(void *)(v0 + 184);
    uint64_t v24 = *(void *)(v0 + 168);
    uint64_t v23 = *(void *)(v0 + 144);
    uint64_t v22 = *(void *)(v0 + 120);
    uint64_t v26 = *(void *)(v0 + 72);
    uint64_t v21 = *(void *)(v0 + 96);
    swift_task_dealloc(*(void *)(v0 + 264));
    swift_task_dealloc(v10);
    swift_task_dealloc(v11);
    swift_task_dealloc(v12);
    swift_task_dealloc(v25);
    swift_task_dealloc(v24);
    swift_task_dealloc(v23);
    swift_task_dealloc(v22);
    swift_task_dealloc(v21);
    swift_task_dealloc(v26);
    return (*(uint64_t (**)(void))(v0 + 8))();
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 312);
  *(void *)(*(void *)v1 + 320) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized Transformer.prediction<A, B>(from:eventHandler:);
  }
  else {
    uint64_t v3 = specialized Transformer.prediction<A, B>(from:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 328);
  *(void *)(*(void *)v1 + 336) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized Transformer.prediction<A, B>(from:eventHandler:);
  }
  else {
    uint64_t v3 = specialized Transformer.prediction<A, B>(from:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  unint64_t v6;
  void *v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char *v12;
  void *v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t (*v31)(void *);
  void *v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  int EnumCaseMultiPayload;
  uint64_t v42;
  void *v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  void *v63;
  void *v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;

  (*(void (**)(void, void))(*(void *)(v0 + 160) + 8))(*(void *)(v0 + 168), *(void *)(v0 + 152));
  uint64_t v49 = *(void *)(v0 + 320);
  uint64_t v62 = *(void *)(v0 + 304);
  uint64_t v55 = *(void *)(v0 + 248);
  int64_t v1 = *(void *)(v0 + 240);
  uint64_t v2 = *(void *)(v0 + 232);
  uint64_t v3 = *(void *)(v0 + 224);
  int v4 = *(void *)(v0 + 216);
  (*(void (**)(void, void))(*(void *)(v0 + 200) + 8))(*(void *)(v0 + 208), *(void *)(v0 + 192));
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v3 + 16))(v2, v1, v4);
  AnnotatedFeature.annotation.getter(v55);
  AnnotatedPrediction.init(prediction:annotation:)(v2, v0 + 16, v4, &type metadata for String);
  uint64_t v5 = *(void *)(v62 + 16);
  uint64_t v6 = *(void *)(v62 + 24);
  uint64_t v7 = *(void **)(v0 + 304);
  if (v6 >> 1 <= v5) {
    uint64_t v7 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v6 >= 2, v5 + 1, 1, *(void *)(v0 + 304));
  }
  uint64_t v8 = *(void *)(v0 + 120);
  uint64_t v9 = *(void *)(v0 + 104);
  uint64_t v10 = *(void *)(v0 + 112);
  uint64_t v11 = *(void *)(v0 + 40);
  v7[2] = v5 + 1;
  uint64_t v12 = (char *)v7
      + ((*(unsigned __int8 *)(v10 + 80) + 32) & ~*(unsigned __int8 *)(v10 + 80))
      + *(void *)(v10 + 72) * v5;
  uint64_t v13 = v7;
  (*(void (**)(char *, uint64_t, uint64_t))(v10 + 32))(v12, v8, v9);
  uint64_t v63 = v13;
  if (v11)
  {
    uint64_t v59 = *(void *)(v0 + 272);
    uint64_t v14 = *(void *)(v0 + 96);
    uint64_t v66 = *(void *)(v0 + 88);
    uint64_t v52 = *(void *)(v0 + 80);
    uint64_t v15 = *(void *)(v0 + 72);
    uint64_t v16 = *(void *)(v0 + 64);
    uint64_t v56 = *(void (**)(uint64_t))(v0 + 40);
    uint64_t v17 = *(void *)(v0 + 48);
    outlined init with copy of MLTrainingSessionParameters(*(void *)(v0 + 56), v15, type metadata accessor for MLSoundClassifier.Model);
    swift_retain();
    uint64_t v47 = String.init<A>(describing:)(v15, v16);
    uint64_t v45 = v18;
    uint64_t v46 = v63[2];
    uint64_t v19 = type metadata accessor for MetricsKey(0);
    unint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    uint64_t v21 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, (uint64_t (*)(uint64_t))&type metadata accessor for MetricsKey, (uint64_t)&protocol conformance descriptor for MetricsKey);
    uint64_t v22 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, v19, v20, v21);
    Event.init(origin:itemCount:totalItemCount:metrics:)(v47, v45, v46, v59, 0, v22);
    v56(v14);
    _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v56, v17);
    (*(void (**)(uint64_t, uint64_t))(v66 + 8))(v14, v52);
  }
  uint64_t v23 = *(void *)(v0 + 264);
  uint64_t v67 = *(void *)(v0 + 256);
  uint64_t v24 = *(void *)(v0 + 248);
  uint64_t v25 = *(void *)(v0 + 296) + 1;
  uint64_t v26 = *(void *)(v0 + 272);
  (*(void (**)(void, void))(*(void *)(v0 + 224) + 8))(*(void *)(v0 + 240), *(void *)(v0 + 216));
  (*(void (**)(uint64_t, uint64_t))(v67 + 8))(v23, v24);
  if (v25 == v26)
  {
    swift_bridgeObjectRelease(*(void *)(v0 + 32));
    uint64_t v27 = *(void *)(v0 + 240);
    uint64_t v28 = *(void *)(v0 + 232);
    uint64_t v29 = *(void *)(v0 + 208);
    uint64_t v30 = *(void *)(v0 + 184);
    uint64_t v50 = *(void *)(v0 + 168);
    uint64_t v60 = *(void *)(v0 + 144);
    uint64_t v57 = *(void *)(v0 + 120);
    uint64_t v68 = *(void *)(v0 + 72);
    uint64_t v53 = *(void *)(v0 + 96);
    swift_task_dealloc(*(void *)(v0 + 264));
    swift_task_dealloc(v27);
    swift_task_dealloc(v28);
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v50);
    swift_task_dealloc(v60);
    swift_task_dealloc(v57);
    swift_task_dealloc(v53);
    swift_task_dealloc(v68);
    uint64_t v31 = *(uint64_t (**)(void *))(v0 + 8);
    uint64_t v32 = v63;
    return v31(v32);
  }
  uint64_t v33 = *(void *)(v0 + 296) + 1;
  *(void *)(v0 + 304) = v63;
  *(void *)(v0 + 296) = v33;
  (*(void (**)(void, uint64_t, void))(v0 + 288))(*(void *)(v0 + 264), *(void *)(v0 + 32)+ ((*(unsigned __int8 *)(v0 + 344) + 32) & ~*(unsigned __int8 *)(v0 + 344))+ *(void *)(v0 + 280) * v33, *(void *)(v0 + 248));
  static Task<>.checkCancellation()();
  if (v49)
  {
    (*(void (**)(void, void))(*(void *)(v0 + 256) + 8))(*(void *)(v0 + 264), *(void *)(v0 + 248));
    swift_bridgeObjectRelease((_BYTE)v63);
    uint64_t v34 = *(void *)(v0 + 264);
    uint64_t v35 = *(void *)(v0 + 240);
    uint64_t v36 = *(void *)(v0 + 232);
    uint64_t v48 = *(void *)(v0 + 208);
    uint64_t v51 = *(void *)(v0 + 184);
    uint64_t v61 = *(void *)(v0 + 168);
    uint64_t v58 = *(void *)(v0 + 144);
    uint64_t v54 = *(void *)(v0 + 120);
    uint64_t v69 = *(void *)(v0 + 96);
    uint64_t v64 = *(void **)(v0 + 72);
    swift_bridgeObjectRelease(*(void *)(v0 + 32));
    swift_task_dealloc(v34);
    swift_task_dealloc(v35);
    swift_task_dealloc(v36);
    swift_task_dealloc(v48);
    swift_task_dealloc(v51);
    swift_task_dealloc(v61);
    swift_task_dealloc(v58);
    swift_task_dealloc(v54);
    swift_task_dealloc(v69);
    uint64_t v32 = v64;
    swift_task_dealloc(v64);
    uint64_t v31 = *(uint64_t (**)(void *))(v0 + 8);
    return v31(v32);
  }
  uint64_t v38 = *(void *)(v0 + 184);
  uint64_t v65 = *(void *)(v0 + 176);
  uint64_t v39 = *(void *)(v0 + 56);
  uint64_t v40 = *(void *)(v0 + 64);
  AnnotatedFeature.feature.getter(*(void *)(v0 + 248));
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v39 + *(int *)(v40 + 20), v38, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v38, v65);
  uint64_t v42 = *(void *)(v0 + 184);
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 136) + 32))(*(void *)(v0 + 144), v42, *(void *)(v0 + 128));
    uint64_t v43 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 328) = v43;
    *uint64_t v43 = v0;
    v43[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
    return FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 240), *(void *)(v0 + 208), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 128));
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 160) + 32))(*(void *)(v0 + 168), v42, *(void *)(v0 + 152));
    uint64_t v44 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 312) = v44;
    *uint64_t v44 = v0;
    v44[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
    return LogisticRegressionClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 240), *(void *)(v0 + 208), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 152));
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  unint64_t v6;
  void *v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char *v12;
  void *v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t (*v31)(void *);
  void *v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  int EnumCaseMultiPayload;
  uint64_t v42;
  void *v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  void (*v56)(uint64_t);
  uint64_t v57;
  uint64_t v58;
  uint64_t v59;
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  void *v63;
  void *v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  uint64_t v68;
  uint64_t v69;

  (*(void (**)(void, void))(*(void *)(v0 + 136) + 8))(*(void *)(v0 + 144), *(void *)(v0 + 128));
  uint64_t v49 = *(void *)(v0 + 336);
  uint64_t v62 = *(void *)(v0 + 304);
  uint64_t v55 = *(void *)(v0 + 248);
  int64_t v1 = *(void *)(v0 + 240);
  uint64_t v2 = *(void *)(v0 + 232);
  uint64_t v3 = *(void *)(v0 + 224);
  int v4 = *(void *)(v0 + 216);
  (*(void (**)(void, void))(*(void *)(v0 + 200) + 8))(*(void *)(v0 + 208), *(void *)(v0 + 192));
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v3 + 16))(v2, v1, v4);
  AnnotatedFeature.annotation.getter(v55);
  AnnotatedPrediction.init(prediction:annotation:)(v2, v0 + 16, v4, &type metadata for String);
  uint64_t v5 = *(void *)(v62 + 16);
  uint64_t v6 = *(void *)(v62 + 24);
  uint64_t v7 = *(void **)(v0 + 304);
  if (v6 >> 1 <= v5) {
    uint64_t v7 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v6 >= 2, v5 + 1, 1, *(void *)(v0 + 304));
  }
  uint64_t v8 = *(void *)(v0 + 120);
  uint64_t v9 = *(void *)(v0 + 104);
  uint64_t v10 = *(void *)(v0 + 112);
  uint64_t v11 = *(void *)(v0 + 40);
  v7[2] = v5 + 1;
  uint64_t v12 = (char *)v7
      + ((*(unsigned __int8 *)(v10 + 80) + 32) & ~*(unsigned __int8 *)(v10 + 80))
      + *(void *)(v10 + 72) * v5;
  uint64_t v13 = v7;
  (*(void (**)(char *, uint64_t, uint64_t))(v10 + 32))(v12, v8, v9);
  uint64_t v63 = v13;
  if (v11)
  {
    uint64_t v59 = *(void *)(v0 + 272);
    uint64_t v14 = *(void *)(v0 + 96);
    uint64_t v66 = *(void *)(v0 + 88);
    uint64_t v52 = *(void *)(v0 + 80);
    uint64_t v15 = *(void *)(v0 + 72);
    uint64_t v16 = *(void *)(v0 + 64);
    uint64_t v56 = *(void (**)(uint64_t))(v0 + 40);
    uint64_t v17 = *(void *)(v0 + 48);
    outlined init with copy of MLTrainingSessionParameters(*(void *)(v0 + 56), v15, type metadata accessor for MLSoundClassifier.Model);
    swift_retain();
    uint64_t v47 = String.init<A>(describing:)(v15, v16);
    uint64_t v45 = v18;
    uint64_t v46 = v63[2];
    uint64_t v19 = type metadata accessor for MetricsKey(0);
    unint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    uint64_t v21 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, (uint64_t (*)(uint64_t))&type metadata accessor for MetricsKey, (uint64_t)&protocol conformance descriptor for MetricsKey);
    uint64_t v22 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, v19, v20, v21);
    Event.init(origin:itemCount:totalItemCount:metrics:)(v47, v45, v46, v59, 0, v22);
    v56(v14);
    _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v56, v17);
    (*(void (**)(uint64_t, uint64_t))(v66 + 8))(v14, v52);
  }
  uint64_t v23 = *(void *)(v0 + 264);
  uint64_t v67 = *(void *)(v0 + 256);
  uint64_t v24 = *(void *)(v0 + 248);
  uint64_t v25 = *(void *)(v0 + 296) + 1;
  uint64_t v26 = *(void *)(v0 + 272);
  (*(void (**)(void, void))(*(void *)(v0 + 224) + 8))(*(void *)(v0 + 240), *(void *)(v0 + 216));
  (*(void (**)(uint64_t, uint64_t))(v67 + 8))(v23, v24);
  if (v25 == v26)
  {
    swift_bridgeObjectRelease(*(void *)(v0 + 32));
    uint64_t v27 = *(void *)(v0 + 240);
    uint64_t v28 = *(void *)(v0 + 232);
    uint64_t v29 = *(void *)(v0 + 208);
    uint64_t v30 = *(void *)(v0 + 184);
    uint64_t v50 = *(void *)(v0 + 168);
    uint64_t v60 = *(void *)(v0 + 144);
    uint64_t v57 = *(void *)(v0 + 120);
    uint64_t v68 = *(void *)(v0 + 72);
    uint64_t v53 = *(void *)(v0 + 96);
    swift_task_dealloc(*(void *)(v0 + 264));
    swift_task_dealloc(v27);
    swift_task_dealloc(v28);
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v50);
    swift_task_dealloc(v60);
    swift_task_dealloc(v57);
    swift_task_dealloc(v53);
    swift_task_dealloc(v68);
    uint64_t v31 = *(uint64_t (**)(void *))(v0 + 8);
    uint64_t v32 = v63;
    return v31(v32);
  }
  uint64_t v33 = *(void *)(v0 + 296) + 1;
  *(void *)(v0 + 304) = v63;
  *(void *)(v0 + 296) = v33;
  (*(void (**)(void, uint64_t, void))(v0 + 288))(*(void *)(v0 + 264), *(void *)(v0 + 32)+ ((*(unsigned __int8 *)(v0 + 344) + 32) & ~*(unsigned __int8 *)(v0 + 344))+ *(void *)(v0 + 280) * v33, *(void *)(v0 + 248));
  static Task<>.checkCancellation()();
  if (v49)
  {
    (*(void (**)(void, void))(*(void *)(v0 + 256) + 8))(*(void *)(v0 + 264), *(void *)(v0 + 248));
    swift_bridgeObjectRelease((_BYTE)v63);
    uint64_t v34 = *(void *)(v0 + 264);
    uint64_t v35 = *(void *)(v0 + 240);
    uint64_t v36 = *(void *)(v0 + 232);
    uint64_t v48 = *(void *)(v0 + 208);
    uint64_t v51 = *(void *)(v0 + 184);
    uint64_t v61 = *(void *)(v0 + 168);
    uint64_t v58 = *(void *)(v0 + 144);
    uint64_t v54 = *(void *)(v0 + 120);
    uint64_t v69 = *(void *)(v0 + 96);
    uint64_t v64 = *(void **)(v0 + 72);
    swift_bridgeObjectRelease(*(void *)(v0 + 32));
    swift_task_dealloc(v34);
    swift_task_dealloc(v35);
    swift_task_dealloc(v36);
    swift_task_dealloc(v48);
    swift_task_dealloc(v51);
    swift_task_dealloc(v61);
    swift_task_dealloc(v58);
    swift_task_dealloc(v54);
    swift_task_dealloc(v69);
    uint64_t v32 = v64;
    swift_task_dealloc(v64);
    uint64_t v31 = *(uint64_t (**)(void *))(v0 + 8);
    return v31(v32);
  }
  uint64_t v38 = *(void *)(v0 + 184);
  uint64_t v65 = *(void *)(v0 + 176);
  uint64_t v39 = *(void *)(v0 + 56);
  uint64_t v40 = *(void *)(v0 + 64);
  AnnotatedFeature.feature.getter(*(void *)(v0 + 248));
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v39 + *(int *)(v40 + 20), v38, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v38, v65);
  uint64_t v42 = *(void *)(v0 + 184);
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 136) + 32))(*(void *)(v0 + 144), v42, *(void *)(v0 + 128));
    uint64_t v43 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 328) = v43;
    *uint64_t v43 = v0;
    v43[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
    return FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 240), *(void *)(v0 + 208), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 128));
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 160) + 32))(*(void *)(v0 + 168), v42, *(void *)(v0 + 152));
    uint64_t v44 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 312) = v44;
    *uint64_t v44 = v0;
    v44[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
    return LogisticRegressionClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 240), *(void *)(v0 + 208), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 152));
  }
}

{
  uint64_t v0;
  int64_t v1;
  void *v2;
  uint64_t v3;
  int v4;
  void (*v5)(uint64_t, uint64_t, uint64_t);
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  int EnumCaseMultiPayload;
  uint64_t v18;
  void *v19;
  void *v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;

  int64_t v1 = *(void *)(*(void *)(v0 + 32) + 16);
  *(void *)(v0 + 272) = v1;
  uint64_t v2 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0, (uint64_t)_swiftEmptyArrayStorage);
  if (v1)
  {
    uint64_t v3 = *(void *)(v0 + 256);
    int v4 = *(_DWORD *)(v3 + 80);
    *(_DWORD *)(v0 + 344) = v4;
    uint64_t v5 = *(void (**)(uint64_t, uint64_t, uint64_t))(v3 + 16);
    *(void *)(v0 + 280) = *(void *)(v3 + 72);
    *(void *)(v0 + 288) = v5;
    *(void *)(v0 + 304) = v2;
    *(void *)(v0 + 296) = 0;
    uint64_t v6 = *(void *)(v0 + 264);
    uint64_t v7 = *(void *)(v0 + 32);
    uint64_t v8 = *(void *)(v0 + 248);
    uint64_t v9 = v7 + ((v4 + 32) & ~v4);
    swift_bridgeObjectRetain(v7);
    v5(v6, v9, v8);
    static Task<>.checkCancellation()();
    uint64_t v14 = *(void *)(v0 + 184);
    uint64_t v15 = *(void *)(v0 + 56);
    uint64_t v16 = *(void *)(v0 + 176);
    AnnotatedFeature.feature.getter(*(void *)(v0 + 248));
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v15, v14, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v14, v16);
    uint64_t v18 = *(void *)(v0 + 184);
    if (EnumCaseMultiPayload == 1)
    {
      (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 136) + 32))(*(void *)(v0 + 144), v18, *(void *)(v0 + 128));
      uint64_t v19 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)[1]);
      *(void *)(v0 + 328) = v19;
      *uint64_t v19 = v0;
      v19[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
      return FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 240), *(void *)(v0 + 208), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 128));
    }
    else
    {
      (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 160) + 32))(*(void *)(v0 + 168), v18, *(void *)(v0 + 152));
      unint64_t v20 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifierModel.applied(to:eventHandler:)[1]);
      *(void *)(v0 + 312) = v20;
      void *v20 = v0;
      v20[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
      return LogisticRegressionClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 240), *(void *)(v0 + 208), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 152));
    }
  }
  else
  {
    uint64_t v10 = *(void *)(v0 + 240);
    uint64_t v11 = *(void *)(v0 + 232);
    uint64_t v12 = *(void *)(v0 + 208);
    uint64_t v25 = *(void *)(v0 + 184);
    uint64_t v24 = *(void *)(v0 + 168);
    uint64_t v23 = *(void *)(v0 + 144);
    uint64_t v22 = *(void *)(v0 + 120);
    uint64_t v26 = *(void *)(v0 + 72);
    uint64_t v21 = *(void *)(v0 + 96);
    swift_task_dealloc(*(void *)(v0 + 264));
    swift_task_dealloc(v10);
    swift_task_dealloc(v11);
    swift_task_dealloc(v12);
    swift_task_dealloc(v25);
    swift_task_dealloc(v24);
    swift_task_dealloc(v23);
    swift_task_dealloc(v22);
    swift_task_dealloc(v21);
    swift_task_dealloc(v26);
    return (*(uint64_t (**)(void))(v0 + 8))();
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)(void);

  uint64_t v2 = *(void *)(*(void *)v1 + 312);
  *(void *)(*(void *)v1 + 320) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized Transformer.prediction<A, B>(from:eventHandler:);
  }
  else {
    uint64_t v3 = specialized Transformer.prediction<A, B>(from:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)(void);

  uint64_t v2 = *(void *)(*(void *)v1 + 328);
  *(void *)(*(void *)v1 + 336) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = specialized Transformer.prediction<A, B>(from:eventHandler:);
  }
  else {
    uint64_t v3 = specialized Transformer.prediction<A, B>(from:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  unint64_t v6;
  void *v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char *v12;
  void *v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t (*v31)(void *);
  void *v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  int EnumCaseMultiPayload;
  uint64_t v42;
  void *v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  void *v53;
  void *v54;
  uint64_t v55;
  uint64_t v56;
  uint64_t v57;
  uint64_t v58;
  void (*v59)(uint64_t);
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  uint64_t v68;

  (*(void (**)(void, void))(*(void *)(v0 + 160) + 8))(*(void *)(v0 + 168), *(void *)(v0 + 152));
  uint64_t v49 = *(void *)(v0 + 320);
  uint64_t v52 = *(void *)(v0 + 304);
  uint64_t v58 = *(void *)(v0 + 248);
  int64_t v1 = *(void *)(v0 + 240);
  uint64_t v2 = *(void *)(v0 + 232);
  uint64_t v3 = *(void *)(v0 + 224);
  int v4 = *(void *)(v0 + 216);
  (*(void (**)(void, void))(*(void *)(v0 + 200) + 8))(*(void *)(v0 + 208), *(void *)(v0 + 192));
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v3 + 16))(v2, v1, v4);
  AnnotatedFeature.annotation.getter(v58);
  AnnotatedPrediction.init(prediction:annotation:)(v2, v0 + 16, v4, &type metadata for String);
  uint64_t v5 = *(void *)(v52 + 16);
  uint64_t v6 = *(void *)(v52 + 24);
  uint64_t v7 = *(void **)(v0 + 304);
  if (v6 >> 1 <= v5) {
    uint64_t v7 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v6 >= 2, v5 + 1, 1, *(void *)(v0 + 304));
  }
  uint64_t v8 = *(void *)(v0 + 120);
  uint64_t v9 = *(void *)(v0 + 104);
  uint64_t v10 = *(void *)(v0 + 112);
  uint64_t v11 = *(void *)(v0 + 40);
  v7[2] = v5 + 1;
  uint64_t v12 = (char *)v7
      + ((*(unsigned __int8 *)(v10 + 80) + 32) & ~*(unsigned __int8 *)(v10 + 80))
      + *(void *)(v10 + 72) * v5;
  uint64_t v13 = v7;
  (*(void (**)(char *, uint64_t, uint64_t))(v10 + 32))(v12, v8, v9);
  uint64_t v53 = v13;
  if (v11)
  {
    uint64_t v62 = *(void *)(v0 + 272);
    uint64_t v14 = *(void *)(v0 + 96);
    uint64_t v65 = *(void *)(v0 + 88);
    uint64_t v55 = *(void *)(v0 + 80);
    uint64_t v15 = *(void *)(v0 + 72);
    uint64_t v16 = *(void *)(v0 + 64);
    uint64_t v59 = *(void (**)(uint64_t))(v0 + 40);
    uint64_t v17 = *(void *)(v0 + 48);
    outlined init with copy of MLTrainingSessionParameters(*(void *)(v0 + 56), v15, type metadata accessor for MLImageClassifier.Model);
    swift_retain();
    uint64_t v47 = String.init<A>(describing:)(v15, v16);
    uint64_t v45 = v18;
    uint64_t v46 = v53[2];
    uint64_t v19 = type metadata accessor for MetricsKey(0);
    unint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    uint64_t v21 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, (uint64_t (*)(uint64_t))&type metadata accessor for MetricsKey, (uint64_t)&protocol conformance descriptor for MetricsKey);
    uint64_t v22 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, v19, v20, v21);
    Event.init(origin:itemCount:totalItemCount:metrics:)(v47, v45, v46, v62, 0, v22);
    v59(v14);
    _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v59, v17);
    (*(void (**)(uint64_t, uint64_t))(v65 + 8))(v14, v55);
  }
  uint64_t v23 = *(void *)(v0 + 264);
  uint64_t v66 = *(void *)(v0 + 256);
  uint64_t v24 = *(void *)(v0 + 248);
  uint64_t v25 = *(void *)(v0 + 296) + 1;
  uint64_t v26 = *(void *)(v0 + 272);
  (*(void (**)(void, void))(*(void *)(v0 + 224) + 8))(*(void *)(v0 + 240), *(void *)(v0 + 216));
  (*(void (**)(uint64_t, uint64_t))(v66 + 8))(v23, v24);
  if (v25 == v26)
  {
    swift_bridgeObjectRelease(*(void *)(v0 + 32));
    uint64_t v27 = *(void *)(v0 + 240);
    uint64_t v28 = *(void *)(v0 + 232);
    uint64_t v29 = *(void *)(v0 + 208);
    uint64_t v30 = *(void *)(v0 + 184);
    uint64_t v50 = *(void *)(v0 + 168);
    uint64_t v63 = *(void *)(v0 + 144);
    uint64_t v60 = *(void *)(v0 + 120);
    uint64_t v67 = *(void *)(v0 + 72);
    uint64_t v56 = *(void *)(v0 + 96);
    swift_task_dealloc(*(void *)(v0 + 264));
    swift_task_dealloc(v27);
    swift_task_dealloc(v28);
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v50);
    swift_task_dealloc(v63);
    swift_task_dealloc(v60);
    swift_task_dealloc(v56);
    swift_task_dealloc(v67);
    uint64_t v31 = *(uint64_t (**)(void *))(v0 + 8);
    uint64_t v32 = v53;
    return v31(v32);
  }
  uint64_t v33 = *(void *)(v0 + 296) + 1;
  *(void *)(v0 + 304) = v53;
  *(void *)(v0 + 296) = v33;
  (*(void (**)(void, uint64_t, void))(v0 + 288))(*(void *)(v0 + 264), *(void *)(v0 + 32)+ ((*(unsigned __int8 *)(v0 + 344) + 32) & ~*(unsigned __int8 *)(v0 + 344))+ *(void *)(v0 + 280) * v33, *(void *)(v0 + 248));
  static Task<>.checkCancellation()();
  if (v49)
  {
    (*(void (**)(void, void))(*(void *)(v0 + 256) + 8))(*(void *)(v0 + 264), *(void *)(v0 + 248));
    swift_bridgeObjectRelease((_BYTE)v53);
    uint64_t v34 = *(void *)(v0 + 264);
    uint64_t v35 = *(void *)(v0 + 240);
    uint64_t v36 = *(void *)(v0 + 232);
    uint64_t v48 = *(void *)(v0 + 208);
    uint64_t v51 = *(void *)(v0 + 184);
    uint64_t v64 = *(void *)(v0 + 168);
    uint64_t v61 = *(void *)(v0 + 144);
    uint64_t v57 = *(void *)(v0 + 120);
    uint64_t v68 = *(void *)(v0 + 96);
    uint64_t v54 = *(void **)(v0 + 72);
    swift_bridgeObjectRelease(*(void *)(v0 + 32));
    swift_task_dealloc(v34);
    swift_task_dealloc(v35);
    swift_task_dealloc(v36);
    swift_task_dealloc(v48);
    swift_task_dealloc(v51);
    swift_task_dealloc(v64);
    swift_task_dealloc(v61);
    swift_task_dealloc(v57);
    swift_task_dealloc(v68);
    uint64_t v32 = v54;
    swift_task_dealloc(v54);
    uint64_t v31 = *(uint64_t (**)(void *))(v0 + 8);
    return v31(v32);
  }
  uint64_t v38 = *(void *)(v0 + 184);
  uint64_t v39 = *(void *)(v0 + 56);
  uint64_t v40 = *(void *)(v0 + 176);
  AnnotatedFeature.feature.getter(*(void *)(v0 + 248));
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v39, v38, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v38, v40);
  uint64_t v42 = *(void *)(v0 + 184);
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 136) + 32))(*(void *)(v0 + 144), v42, *(void *)(v0 + 128));
    uint64_t v43 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 328) = v43;
    *uint64_t v43 = v0;
    v43[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
    return FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 240), *(void *)(v0 + 208), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 128));
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 160) + 32))(*(void *)(v0 + 168), v42, *(void *)(v0 + 152));
    uint64_t v44 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 312) = v44;
    *uint64_t v44 = v0;
    v44[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
    return LogisticRegressionClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 240), *(void *)(v0 + 208), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 152));
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;

  int64_t v1 = *(void *)(v0 + 304);
  uint64_t v15 = *(void *)(v0 + 264);
  uint64_t v13 = *(void *)(v0 + 256);
  uint64_t v17 = *(void *)(v0 + 248);
  uint64_t v2 = *(void *)(v0 + 208);
  uint64_t v3 = *(void *)(v0 + 200);
  int v4 = *(void *)(v0 + 192);
  (*(void (**)(void, void))(*(void *)(v0 + 160) + 8))(*(void *)(v0 + 168), *(void *)(v0 + 152));
  (*(void (**)(uint64_t, uint64_t))(v3 + 8))(v2, v4);
  swift_bridgeObjectRelease(v1);
  (*(void (**)(uint64_t, uint64_t))(v13 + 8))(v15, v17);
  uint64_t v5 = *(void *)(v0 + 264);
  uint64_t v6 = *(void *)(v0 + 240);
  uint64_t v7 = *(void *)(v0 + 232);
  uint64_t v8 = *(void *)(v0 + 208);
  uint64_t v12 = *(void *)(v0 + 184);
  uint64_t v11 = *(void *)(v0 + 168);
  uint64_t v10 = *(void *)(v0 + 144);
  uint64_t v18 = *(void *)(v0 + 120);
  uint64_t v16 = *(void *)(v0 + 96);
  uint64_t v14 = *(void *)(v0 + 72);
  swift_bridgeObjectRelease(*(void *)(v0 + 32));
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v18);
  swift_task_dealloc(v16);
  swift_task_dealloc(v14);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  unint64_t v6;
  void *v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  char *v12;
  void *v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t (*v31)(void *);
  void *v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  int EnumCaseMultiPayload;
  uint64_t v42;
  void *v43;
  void *v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  void *v53;
  void *v54;
  uint64_t v55;
  uint64_t v56;
  uint64_t v57;
  uint64_t v58;
  void (*v59)(uint64_t);
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  uint64_t v63;
  uint64_t v64;
  uint64_t v65;
  uint64_t v66;
  uint64_t v67;
  uint64_t v68;

  (*(void (**)(void, void))(*(void *)(v0 + 136) + 8))(*(void *)(v0 + 144), *(void *)(v0 + 128));
  uint64_t v49 = *(void *)(v0 + 336);
  uint64_t v52 = *(void *)(v0 + 304);
  uint64_t v58 = *(void *)(v0 + 248);
  int64_t v1 = *(void *)(v0 + 240);
  uint64_t v2 = *(void *)(v0 + 232);
  uint64_t v3 = *(void *)(v0 + 224);
  int v4 = *(void *)(v0 + 216);
  (*(void (**)(void, void))(*(void *)(v0 + 200) + 8))(*(void *)(v0 + 208), *(void *)(v0 + 192));
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v3 + 16))(v2, v1, v4);
  AnnotatedFeature.annotation.getter(v58);
  AnnotatedPrediction.init(prediction:annotation:)(v2, v0 + 16, v4, &type metadata for String);
  uint64_t v5 = *(void *)(v52 + 16);
  uint64_t v6 = *(void *)(v52 + 24);
  uint64_t v7 = *(void **)(v0 + 304);
  if (v6 >> 1 <= v5) {
    uint64_t v7 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v6 >= 2, v5 + 1, 1, *(void *)(v0 + 304));
  }
  uint64_t v8 = *(void *)(v0 + 120);
  uint64_t v9 = *(void *)(v0 + 104);
  uint64_t v10 = *(void *)(v0 + 112);
  uint64_t v11 = *(void *)(v0 + 40);
  v7[2] = v5 + 1;
  uint64_t v12 = (char *)v7
      + ((*(unsigned __int8 *)(v10 + 80) + 32) & ~*(unsigned __int8 *)(v10 + 80))
      + *(void *)(v10 + 72) * v5;
  uint64_t v13 = v7;
  (*(void (**)(char *, uint64_t, uint64_t))(v10 + 32))(v12, v8, v9);
  uint64_t v53 = v13;
  if (v11)
  {
    uint64_t v62 = *(void *)(v0 + 272);
    uint64_t v14 = *(void *)(v0 + 96);
    uint64_t v65 = *(void *)(v0 + 88);
    uint64_t v55 = *(void *)(v0 + 80);
    uint64_t v15 = *(void *)(v0 + 72);
    uint64_t v16 = *(void *)(v0 + 64);
    uint64_t v59 = *(void (**)(uint64_t))(v0 + 40);
    uint64_t v17 = *(void *)(v0 + 48);
    outlined init with copy of MLTrainingSessionParameters(*(void *)(v0 + 56), v15, type metadata accessor for MLImageClassifier.Model);
    swift_retain();
    uint64_t v47 = String.init<A>(describing:)(v15, v16);
    uint64_t v45 = v18;
    uint64_t v46 = v53[2];
    uint64_t v19 = type metadata accessor for MetricsKey(0);
    unint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    uint64_t v21 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, (uint64_t (*)(uint64_t))&type metadata accessor for MetricsKey, (uint64_t)&protocol conformance descriptor for MetricsKey);
    uint64_t v22 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, v19, v20, v21);
    Event.init(origin:itemCount:totalItemCount:metrics:)(v47, v45, v46, v62, 0, v22);
    v59(v14);
    _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v59, v17);
    (*(void (**)(uint64_t, uint64_t))(v65 + 8))(v14, v55);
  }
  uint64_t v23 = *(void *)(v0 + 264);
  uint64_t v66 = *(void *)(v0 + 256);
  uint64_t v24 = *(void *)(v0 + 248);
  uint64_t v25 = *(void *)(v0 + 296) + 1;
  uint64_t v26 = *(void *)(v0 + 272);
  (*(void (**)(void, void))(*(void *)(v0 + 224) + 8))(*(void *)(v0 + 240), *(void *)(v0 + 216));
  (*(void (**)(uint64_t, uint64_t))(v66 + 8))(v23, v24);
  if (v25 == v26)
  {
    swift_bridgeObjectRelease(*(void *)(v0 + 32));
    uint64_t v27 = *(void *)(v0 + 240);
    uint64_t v28 = *(void *)(v0 + 232);
    uint64_t v29 = *(void *)(v0 + 208);
    uint64_t v30 = *(void *)(v0 + 184);
    uint64_t v50 = *(void *)(v0 + 168);
    uint64_t v63 = *(void *)(v0 + 144);
    uint64_t v60 = *(void *)(v0 + 120);
    uint64_t v67 = *(void *)(v0 + 72);
    uint64_t v56 = *(void *)(v0 + 96);
    swift_task_dealloc(*(void *)(v0 + 264));
    swift_task_dealloc(v27);
    swift_task_dealloc(v28);
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v50);
    swift_task_dealloc(v63);
    swift_task_dealloc(v60);
    swift_task_dealloc(v56);
    swift_task_dealloc(v67);
    uint64_t v31 = *(uint64_t (**)(void *))(v0 + 8);
    uint64_t v32 = v53;
    return v31(v32);
  }
  uint64_t v33 = *(void *)(v0 + 296) + 1;
  *(void *)(v0 + 304) = v53;
  *(void *)(v0 + 296) = v33;
  (*(void (**)(void, uint64_t, void))(v0 + 288))(*(void *)(v0 + 264), *(void *)(v0 + 32)+ ((*(unsigned __int8 *)(v0 + 344) + 32) & ~*(unsigned __int8 *)(v0 + 344))+ *(void *)(v0 + 280) * v33, *(void *)(v0 + 248));
  static Task<>.checkCancellation()();
  if (v49)
  {
    (*(void (**)(void, void))(*(void *)(v0 + 256) + 8))(*(void *)(v0 + 264), *(void *)(v0 + 248));
    swift_bridgeObjectRelease((_BYTE)v53);
    uint64_t v34 = *(void *)(v0 + 264);
    uint64_t v35 = *(void *)(v0 + 240);
    uint64_t v36 = *(void *)(v0 + 232);
    uint64_t v48 = *(void *)(v0 + 208);
    uint64_t v51 = *(void *)(v0 + 184);
    uint64_t v64 = *(void *)(v0 + 168);
    uint64_t v61 = *(void *)(v0 + 144);
    uint64_t v57 = *(void *)(v0 + 120);
    uint64_t v68 = *(void *)(v0 + 96);
    uint64_t v54 = *(void **)(v0 + 72);
    swift_bridgeObjectRelease(*(void *)(v0 + 32));
    swift_task_dealloc(v34);
    swift_task_dealloc(v35);
    swift_task_dealloc(v36);
    swift_task_dealloc(v48);
    swift_task_dealloc(v51);
    swift_task_dealloc(v64);
    swift_task_dealloc(v61);
    swift_task_dealloc(v57);
    swift_task_dealloc(v68);
    uint64_t v32 = v54;
    swift_task_dealloc(v54);
    uint64_t v31 = *(uint64_t (**)(void *))(v0 + 8);
    return v31(v32);
  }
  uint64_t v38 = *(void *)(v0 + 184);
  uint64_t v39 = *(void *)(v0 + 56);
  uint64_t v40 = *(void *)(v0 + 176);
  AnnotatedFeature.feature.getter(*(void *)(v0 + 248));
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v39, v38, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v38, v40);
  uint64_t v42 = *(void *)(v0 + 184);
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 136) + 32))(*(void *)(v0 + 144), v42, *(void *)(v0 + 128));
    uint64_t v43 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 328) = v43;
    *uint64_t v43 = v0;
    v43[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
    return FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 240), *(void *)(v0 + 208), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 128));
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 160) + 32))(*(void *)(v0 + 168), v42, *(void *)(v0 + 152));
    uint64_t v44 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifierModel.applied(to:eventHandler:)[1]);
    *(void *)(v0 + 312) = v44;
    *uint64_t v44 = v0;
    v44[1] = specialized Transformer.prediction<A, B>(from:eventHandler:);
    return LogisticRegressionClassifierModel.applied(to:eventHandler:)(*(void *)(v0 + 240), *(void *)(v0 + 208), *(void *)(v0 + 40), *(void *)(v0 + 48), *(void *)(v0 + 152));
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;

  int64_t v1 = *(void *)(v0 + 304);
  uint64_t v15 = *(void *)(v0 + 264);
  uint64_t v13 = *(void *)(v0 + 256);
  uint64_t v17 = *(void *)(v0 + 248);
  uint64_t v2 = *(void *)(v0 + 208);
  uint64_t v3 = *(void *)(v0 + 200);
  int v4 = *(void *)(v0 + 192);
  (*(void (**)(void, void))(*(void *)(v0 + 136) + 8))(*(void *)(v0 + 144), *(void *)(v0 + 128));
  (*(void (**)(uint64_t, uint64_t))(v3 + 8))(v2, v4);
  swift_bridgeObjectRelease(v1);
  (*(void (**)(uint64_t, uint64_t))(v13 + 8))(v15, v17);
  uint64_t v5 = *(void *)(v0 + 264);
  uint64_t v6 = *(void *)(v0 + 240);
  uint64_t v7 = *(void *)(v0 + 232);
  uint64_t v8 = *(void *)(v0 + 208);
  uint64_t v12 = *(void *)(v0 + 184);
  uint64_t v11 = *(void *)(v0 + 168);
  uint64_t v10 = *(void *)(v0 + 144);
  uint64_t v18 = *(void *)(v0 + 120);
  uint64_t v16 = *(void *)(v0 + 96);
  uint64_t v14 = *(void *)(v0 + 72);
  swift_bridgeObjectRelease(*(void *)(v0 + 32));
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v18);
  swift_task_dealloc(v16);
  swift_task_dealloc(v14);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  return specialized Transformer.prediction<A, B>(from:eventHandler:)();
}

{
  return specialized Transformer.prediction<A, B>(from:eventHandler:)();
}

uint64_t key path getter for AnnotatedPrediction.prediction : AnnotatedPrediction<ClassificationDistribution<String>, String>()
{
  uint64_t v0 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>);
  return AnnotatedPrediction.prediction.getter(v0);
}

uint64_t key path setter for AnnotatedPrediction.prediction : AnnotatedPrediction<ClassificationDistribution<String>, String>(uint64_t a1)
{
  v9[0] = v1;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  uint64_t v3 = *(void *)(v2 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  (*(void (**)(void *, uint64_t, uint64_t))(v3 + 16))(v9, a1, v2);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedPrediction<ClassificationDistribution<String>, String>);
  return AnnotatedPrediction.prediction.setter(v9, v7);
}

uint64_t key path getter for ClassificationDistribution.mostLikelyLabel : ClassificationDistribution<String>()
{
  uint64_t v1 = v0;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  uint64_t result = ClassificationDistribution.mostLikelyLabel.getter(v2);
  *uint64_t v1 = v4;
  return result;
}

Swift::Bool __swiftcall SoundClassifierTrainingSessionDelegate.shouldTransition(from:to:)(CreateML::MLPhase from, CreateML::MLPhase to)
{
  Swift::Bool result = 1;
  if (*(unsigned char *)from == 1 && *(unsigned char *)to == 2) {
    return *(unsigned char *)(v2 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_featureExtractionOnly) ^ 1;
  }
  return result;
}

uint64_t SoundClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)(uint64_t *a1, unsigned __int8 *a2)
{
  uint64_t v80 = v2;
  uint64_t v81 = v3;
  uint64_t v90 = a1;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Model?)
                             - 8)
                 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v87 = &v76;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.Classifier?)
                             - 8)
                 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  char v89 = &v76;
  LODWORD(v10) = 0;
  uint64_t v84 = type metadata accessor for CSVWritingOptions(0);
  uint64_t v79 = *(void *)(v84 - 8);
  int64_t v11 = *(void *)(v79 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v77 = &v76;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  uint64_t v76 = (uint64_t)&v76;
  uint64_t v86 = (void (*)(uint64_t *, uint64_t))type metadata accessor for DataFrame(0);
  uint64_t v83 = *((void *)v86 - 1);
  int64_t v16 = *(void *)(v83 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v78 = &v76;
  uint64_t v19 = alloca(v16);
  unint64_t v20 = alloca(v16);
  uint64_t v82 = &v76;
  uint64_t v88 = type metadata accessor for URL(0);
  uint64_t v21 = *(void *)(v88 - 8);
  int64_t v22 = *(void *)(v21 + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  uint64_t v25 = alloca(v22);
  uint64_t v26 = alloca(v22);
  uint64_t v27 = alloca(v22);
  uint64_t v28 = alloca(v22);
  uint64_t v29 = alloca(v22);
  uint64_t v30 = alloca(v22);
  int v31 = *a2;
  if (v31 == 2)
  {
    URL.appendingPathComponent(_:)(0x6C65646F6DLL, 0xE500000000000000);
    uint64_t v90 = &v76;
    URL.appendingPathExtension(_:)(6777712, 0xE300000000000000);
    uint64_t v48 = *(void (**)(uint64_t *, uint64_t))(v21 + 8);
    v48(&v76, v88);
    uint64_t v49 = v81;
    uint64_t v50 = v81 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier;
    swift_beginAccess(v81 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier, v92, 0, 0);
    uint64_t v51 = (uint64_t)v89;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v50, (uint64_t)v89, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
    uint64_t v10 = (void (*)(uint64_t *, uint64_t))type metadata accessor for MLSoundClassifier.Classifier(0);
    if (__swift_getEnumTagSinglePayload(v51, 1, (uint64_t)v10) == 1) {
      BUG();
    }
    uint64_t v86 = v48;
    uint64_t v52 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model + v49;
    swift_beginAccess(v52, v91, 0, 0);
    uint64_t v53 = v52;
    uint64_t v54 = (uint64_t)v87;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v53, (uint64_t)v87, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
    uint64_t v55 = type metadata accessor for MLSoundClassifier.Model(0);
    if (__swift_getEnumTagSinglePayload(v54, 1, v55) == 1) {
      BUG();
    }
    uint64_t v56 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLSoundClassifier.Classifier and conformance MLSoundClassifier.Classifier, type metadata accessor for MLSoundClassifier.Classifier, (uint64_t)&protocol conformance descriptor for MLSoundClassifier.Classifier);
    uint64_t v57 = v90;
    uint64_t v58 = v80;
    UpdatableSupervisedEstimator.writeWithOptimizer(_:to:overwrite:)(v54, v90, 1, v10, v56);
    LODWORD(v10) = v54;
    if (v58)
    {
      v86(v57, v88);
      outlined destroy of MLActivityClassifier.ModelParameters(v54, type metadata accessor for MLSoundClassifier.Model);
      outlined destroy of MLActivityClassifier.ModelParameters(v51, type metadata accessor for MLSoundClassifier.Classifier);
      return v10;
    }
    v86(v57, v88);
    outlined destroy of MLActivityClassifier.ModelParameters(v54, type metadata accessor for MLSoundClassifier.Model);
    outlined destroy of MLActivityClassifier.ModelParameters(v51, type metadata accessor for MLSoundClassifier.Classifier);
LABEL_13:
    LOBYTE(v10) = 1;
    return v10;
  }
  if (v31 != 1) {
    return v10;
  }
  char v89 = &v76;
  URL.appendingPathComponent(_:)(0x676E696E69617274, 0xE800000000000000);
  uint64_t v87 = &v76;
  URL.appendingPathExtension(_:)(7762787, 0xE300000000000000);
  uint64_t v32 = *(void (**)(uint64_t *, uint64_t))(v21 + 8);
  uint64_t v33 = v88;
  v32(&v76, v88);
  URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEA00000000006E6FLL);
  URL.appendingPathExtension(_:)(7762787, 0xE300000000000000);
  uint64_t v85 = v32;
  v32(&v76, v33);
  uint64_t v34 = objc_opt_self(NSFileManager);
  id v35 = [v34 defaultManager];
  uint64_t v36 = (NSURL *)v35;
  URL._bridgeToObjectiveC()(v36);
  uint64_t v38 = v37;
  v92[0] = 0;
  unsigned __int8 v39 = [(NSURL *)v36 createDirectoryAtURL:v37 withIntermediateDirectories:1 attributes:0 error:v92];

  id v40 = v92[0];
  if (!v39)
  {
    id v59 = v92[0];
    _convertNSErrorToError(_:)(v40);

    swift_willThrow(v59, "createDirectoryAtURL:withIntermediateDirectories:attributes:error:", v60, v61, v62, v63);
    uint64_t v10 = (void (*)(uint64_t *, uint64_t))v88;
    uint64_t v64 = v85;
    v85(v89, v88);
    v64(v87, v10);
    return v10;
  }
  uint64_t v41 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures;
  uint64_t v42 = v81;
  swift_beginAccess(v81 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures, v92, 0, 0);
  uint64_t v43 = *(void *)(v42 + v41);
  v40;
  swift_bridgeObjectRetain(v43);
  uint64_t v44 = v82;
  static SoundClassifierTrainingSessionDelegate.createJSONEncodedDataFrame(from:)(v43);
  swift_bridgeObjectRelease(v43);
  uint64_t v45 = v76;
  CSVWritingOptions.init(includesHeader:dateFormat:nilEncoding:trueEncoding:falseEncoding:newline:delimiter:)(1, 0, 0, 0, 0xE000000000000000, 1702195828, 0xE400000000000000, 0x65736C6166, 0xE500000000000000, 10, 0xE100000000000000, 44, 0xE100000000000000);
  uint64_t v46 = v86;
  uint64_t v47 = v80;
  DataFrameProtocol.writeCSV(to:options:)(v87, v45, v86, &protocol witness table for DataFrame);
  if (!v47)
  {
    uint64_t v90 = *(uint64_t **)(v79 + 8);
    ((void (*)(uint64_t, uint64_t))v90)(v45, v84);
    uint64_t v65 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures;
    uint64_t v66 = v81;
    swift_beginAccess(v81 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures, v91, 0, 0);
    uint64_t v67 = *(void *)(v66 + v65);
    swift_bridgeObjectRetain(v67);
    uint64_t v68 = v78;
    static SoundClassifierTrainingSessionDelegate.createJSONEncodedDataFrame(from:)(v67);
    char v69 = v67;
    uint64_t v70 = v86;
    swift_bridgeObjectRelease(v69);
    uint64_t v71 = v77;
    CSVWritingOptions.init(includesHeader:dateFormat:nilEncoding:trueEncoding:falseEncoding:newline:delimiter:)(1, 0, 0, 0, 0xE000000000000000, 1702195828, 0xE400000000000000, 0x65736C6166, 0xE500000000000000, 10, 0xE100000000000000, 44, 0xE100000000000000);
    DataFrameProtocol.writeCSV(to:options:)(v89, v71, v70, &protocol witness table for DataFrame);
    ((void (*)(uint64_t *, uint64_t))v90)(v71, v84);
    uint64_t v74 = *(void (**)(uint64_t *, void *))(v83 + 8);
    v74(v68, v70);
    v74(v82, v70);
    uint64_t v75 = v88;
    uint64_t v10 = v85;
    v85(v89, v88);
    v10(v87, v75);
    goto LABEL_13;
  }
  (*(void (**)(uint64_t, uint64_t))(v79 + 8))(v45, v84);
  (*(void (**)(uint64_t *, void *))(v83 + 8))(v44, v46);
  uint64_t v72 = v88;
  uint64_t v10 = v85;
  v85(v89, v88);
  v10(v87, v72);
  return v10;
}

uint64_t static SoundClassifierTrainingSessionDelegate.createJSONEncodedDataFrame(from:)(uint64_t a1)
{
  uint64_t v60 = v1;
  uint64_t v3 = 0;
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for String.Encoding(0) - 8) + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v53 = &v49;
  uint64_t v54 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  uint64_t v55 = *(void *)(v54 - 8);
  int64_t v7 = *(void *)(v55 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v56 = &v49;
  uint64_t v71 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
  uint64_t v67 = *(void *)(v71 - 8);
  int64_t v10 = *(void *)(v67 + 64);
  int64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v68 = &v49;
  uint64_t v64 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v61 = *(void *)(v64 - 8);
  int64_t v13 = *(void *)(v61 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  int64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v18 = type metadata accessor for JSONEncoder(0);
  swift_allocObject(v18, *(unsigned int *)(v18 + 48), *(unsigned __int16 *)(v18 + 52));
  uint64_t v19 = a1;
  uint64_t v66 = JSONEncoder.init()();
  uint64_t v20 = *(void *)(a1 + 16);
  uint64_t v72 = &v49;
  Column.init(name:capacity:)(0x7365727574616566, 0xE800000000000000, v20, &type metadata for String);
  uint64_t v65 = &v49;
  Column.init(name:capacity:)(0x62614C7373616C63, 0xEA00000000006C65, v20, &type metadata for String);
  uint64_t v57 = v20;
  if (v20)
  {
    uint64_t v21 = v19 + ((*(unsigned __int8 *)(v67 + 80) + 32) & ~*(unsigned __int8 *)(v67 + 80));
    uint64_t v58 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v67 + 16);
    uint64_t v59 = *(void *)(v67 + 72);
    uint64_t v62 = v19;
    swift_bridgeObjectRetain(v19);
    uint64_t v22 = v71;
    uint64_t v23 = v68;
    do
    {
      uint64_t v51 = v21;
      v58(v23, v21, v22);
      uint64_t v24 = v56;
      AnnotatedFeature.feature.getter(v22);
      uint64_t v25 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
      uint64_t v26 = v54;
      uint64_t v27 = MLShapedArrayProtocol.scalars.getter(v54, v25);
      (*(void (**)(uint64_t *, uint64_t))(v55 + 8))(v24, v26);
      uint64_t v69 = v27;
      uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
      uint64_t v29 = lazy protocol witness table accessor for type [Float] and conformance <A> [A](&lazy protocol witness table cache variable for type [Float] and conformance <A> [A], (uint64_t)&protocol witness table for Float, (uint64_t)&protocol conformance descriptor for <A> [A]);
      uint64_t v30 = dispatch thunk of JSONEncoder.encode<A>(_:)(&v69, v28, v29);
      uint64_t v63 = v3;
      if (v3)
      {
        swift_bridgeObjectRelease(v27);
        swift_unexpectedError(v63, "CreateML/_SoundClassifierTrainingSessionDelegate.swift", 54, 1, 430);
        BUG();
      }
      uint64_t v32 = v30;
      unint64_t v33 = v31;
      swift_bridgeObjectRelease(v27);
      uint64_t v34 = v53;
      static String.Encoding.utf8.getter();
      uint64_t v35 = String.init(data:encoding:)(v32, v33, v34);
      LOBYTE(v34) = v36;
      uint64_t v69 = v35;
      uint64_t v70 = v36;
      unint64_t v52 = v33;
      uint64_t v37 = v64;
      Column.append(_:)(&v69, v64);
      swift_bridgeObjectRelease((_BYTE)v34);
      uint64_t v38 = v68;
      AnnotatedFeature.annotation.getter(v71);
      LOBYTE(v34) = v70;
      v50[0] = v69;
      v50[1] = v70;
      Column.append(_:)(v50, v37);
      outlined consume of Data._Representation(v32, v52);
      swift_bridgeObjectRelease((_BYTE)v34);
      uint64_t v22 = v71;
      (*(void (**)(uint64_t *, uint64_t))(v67 + 8))(v38, v71);
      uint64_t v21 = v59 + v51;
      BOOL v39 = v57-- == 1;
      uint64_t v23 = v38;
      uint64_t v3 = v63;
    }
    while (!v39);
    swift_bridgeObjectRelease(v62);
  }
  uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  uint64_t v41 = *(void *)(type metadata accessor for AnyColumn(0) - 8);
  uint64_t v42 = swift_allocObject(v40, ((*(unsigned __int8 *)(v41 + 80) + 32) & ~*(unsigned __int8 *)(v41 + 80)) + 2 * *(void *)(v41 + 72), *(unsigned __int8 *)(v41 + 80) | 7);
  *(void *)(v42 + 16) = 2;
  *(void *)(v42 + 24) = 4;
  uint64_t v43 = v64;
  Column.eraseToAnyColumn()(v64);
  uint64_t v44 = v65;
  Column.eraseToAnyColumn()(v43);
  uint64_t v69 = v42;
  uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  uint64_t v46 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn], (uint64_t)&protocol conformance descriptor for [A]);
  DataFrame.init<A>(columns:)(&v69, v45, v46);
  swift_release();
  uint64_t v47 = *(void (**)(uint64_t *, uint64_t))(v61 + 8);
  v47(v44, v43);
  return ((uint64_t (*)(uint64_t *, uint64_t))v47)(v72, v43);
}

uint64_t static SoundClassifierTrainingSessionDelegate.createDataFrame(from:)(uint64_t a1)
{
  uint64_t v33 = v1;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  uint64_t v29 = *(void *)(v2 - 8);
  int64_t v3 = *(void *)(v29 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v36 = v26;
  uint64_t v38 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v34 = *(void *)(v38 - 8);
  int64_t v6 = *(void *)(v34 + 64);
  int64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLShapedArray<Float>>);
  uint64_t v35 = *(void *)(v9 - 8);
  int64_t v10 = *(void *)(v35 + 64);
  int64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v13 = *(void *)(a1 + 16);
  uint64_t v40 = v26;
  Column.init(name:capacity:)(0x7365727574616566, 0xE800000000000000, v13, v2);
  BOOL v39 = v26;
  Column.init(name:capacity:)(0x62614C7373616C63, 0xEA00000000006C65, v13, &type metadata for String);
  uint64_t v41 = v9;
  if (v13)
  {
    uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
    uint64_t v14 = *(void *)(v30 - 8);
    uint64_t v31 = v2;
    uint64_t v15 = a1 + ((*(unsigned __int8 *)(v14 + 80) + 32) & ~*(unsigned __int8 *)(v14 + 80));
    uint64_t v32 = *(void *)(v14 + 72);
    uint64_t v37 = a1;
    swift_bridgeObjectRetain(a1);
    int64_t v16 = v36;
    do
    {
      uint64_t v17 = v30;
      AnnotatedFeature.feature.getter(v30);
      Column.append(_:)(v16, v41);
      (*(void (**)(void *, uint64_t))(v29 + 8))(v16, v31);
      AnnotatedFeature.annotation.getter(v17);
      LOBYTE(v17) = v28;
      v26[0] = v27;
      v26[1] = v28;
      Column.append(_:)(v26, v38);
      swift_bridgeObjectRelease(v17);
      v15 += v32;
      --v13;
    }
    while (v13);
    swift_bridgeObjectRelease(v37);
    uint64_t v9 = v41;
  }
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  uint64_t v19 = *(void *)(type metadata accessor for AnyColumn(0) - 8);
  uint64_t v20 = swift_allocObject(v18, ((*(unsigned __int8 *)(v19 + 80) + 32) & ~*(unsigned __int8 *)(v19 + 80)) + 2 * *(void *)(v19 + 72), *(unsigned __int8 *)(v19 + 80) | 7);
  *(void *)(v20 + 16) = 2;
  *(void *)(v20 + 24) = 4;
  Column.eraseToAnyColumn()(v9);
  uint64_t v21 = v38;
  uint64_t v22 = v39;
  Column.eraseToAnyColumn()(v38);
  uint64_t v27 = v20;
  uint64_t v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  uint64_t v24 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn], (uint64_t)&protocol conformance descriptor for [A]);
  DataFrame.init<A>(columns:)(&v27, v23, v24);
  (*(void (**)(void *, uint64_t))(v34 + 8))(v22, v21);
  return (*(uint64_t (**)(void *, uint64_t))(v35 + 8))(v40, v41);
}

uint64_t SoundClassifierTrainingSessionDelegate.save(to:)(uint64_t a1)
{
  uint64_t v19 = v1;
  uint64_t v20 = a1;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v6 = type metadata accessor for MLSoundClassifier.PersistentParameters(0);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters + v2;
  swift_beginAccess(v10, v18, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, (uint64_t)&v17, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v17, 1, v6) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v17, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    uint64_t v11 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v11, 0, 0);
    *(void *)uint64_t v12 = 0xD000000000000030;
    *(void *)(v12 + 8) = "Feature Extractor" + 0x8000000000000000;
    *(_OWORD *)(v12 + 16) = 0;
    *(_OWORD *)(v12 + 32) = 0;
    *(unsigned char *)(v12 + 48) = 2;
    return swift_willThrow(&type metadata for MLCreateError, v11, v12, v13, v14, v15);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)&v17, (uint64_t)&v17, type metadata accessor for MLSoundClassifier.PersistentParameters);
    MLSoundClassifier.PersistentParameters.save(toSessionDirectory:)(v20);
    return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v17, type metadata accessor for MLSoundClassifier.PersistentParameters);
  }
}

NSURL *SoundClassifierTrainingSessionDelegate.restore(from:phase:)(uint64_t a1, unsigned char *a2)
{
  uint64_t v28 = v2;
  uint64_t v30 = v3;
  uint64_t v35 = a2;
  uint64_t v29 = a1;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v32 = v26;
  int64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  uint64_t v31 = v26;
  uint64_t v9 = type metadata accessor for URL(0);
  uint64_t v10 = *(void *)(v9 - 8);
  int64_t v11 = *(void *)(v10 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v34 = type metadata accessor for MLSoundClassifier.PersistentParameters(0);
  int64_t v14 = *(void *)(*(void *)(v34 - 8) + 64);
  uint64_t v15 = alloca(v14);
  int64_t v16 = alloca(v14);
  uint64_t v33 = v26;
  uint64_t v17 = alloca(v14);
  uint64_t v18 = alloca(v14);
  LOBYTE(v35) = *v35;
  (*(void (**)(unsigned char *, uint64_t, uint64_t))(v10 + 16))(v26, v29, v9);
  uint64_t v19 = v28;
  Swift::Bool result = MLSoundClassifier.PersistentParameters.init(sessionDirectory:)((uint64_t)v26);
  if (!v19)
  {
    uint64_t v21 = OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters + v30;
    swift_beginAccess(OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters + v30, v26, 0, 0);
    uint64_t v22 = (uint64_t)v31;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v21, (uint64_t)v31, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
    if (__swift_getEnumTagSinglePayload(v22, 1, v34) == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v22, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
      uint64_t v23 = (uint64_t)v32;
      outlined init with take of MLClassifierMetrics((uint64_t)v26, (uint64_t)v32, type metadata accessor for MLSoundClassifier.PersistentParameters);
      __swift_storeEnumTagSinglePayload(v23, 0, 1, v34);
      swift_beginAccess(v21, v27, 33, 0);
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v23, v21, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
      return (NSURL *)swift_endAccess(v27);
    }
    else
    {
      uint64_t v24 = v22;
      uint64_t v25 = (uint64_t)v33;
      outlined init with take of MLClassifierMetrics(v24, (uint64_t)v33, type metadata accessor for MLSoundClassifier.PersistentParameters);
      v27[0] = v35;
      SoundClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:phase:)((uint64_t)v26, v25, v27);
      outlined destroy of MLActivityClassifier.ModelParameters(v25, type metadata accessor for MLSoundClassifier.PersistentParameters);
      return (NSURL *)outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v26, type metadata accessor for MLSoundClassifier.PersistentParameters);
    }
  }
  return result;
}

char SoundClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:phase:)(uint64_t a1, uint64_t a2, unsigned __int8 *a3)
{
  *(void *)&long long v159 = a2;
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for MLSoundClassifier.DataSource(0) - 8) + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v150 = &v145;
  uint64_t v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v161 = (char *)&v145;
  uint64_t v155 = type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData(0);
  int64_t v10 = *(void *)(*(void *)(v155 - 8) + 64);
  int64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v158 = (char *)&v145;
  uint64_t v13 = alloca(v10);
  int64_t v14 = alloca(v10);
  char v157 = (char *)&v145;
  uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLSoundClassifier.ModelParameters.ValidationData, MLSoundClassifier.ModelParameters.ValidationData));
  int64_t v16 = *(void *)(*(void *)(v15 - 8) + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  v160 = &v145;
  int v19 = *a3;
  *(void *)&long long v156 = a1;
  uint64_t v21 = MLSoundClassifier.DataSource.labeledSounds()(&demangling cache variable for type metadata for (MLSoundClassifier.ModelParameters.ValidationData, MLSoundClassifier.ModelParameters.ValidationData), a2, v20);
  if (!v3)
  {
    char v22 = v21;
    uint64_t v145 = v15;
    int v152 = v19;
    uint64_t v23 = specialized Sequence.flatMap<A>(_:)(v21);
    swift_bridgeObjectRelease(v22);
    uint64_t v24 = (int *)type metadata accessor for MLSoundClassifier.PersistentParameters(0);
    uint64_t v25 = v24[7];
    double v146 = *(double *)(v156 + v25);
    uint64_t v153 = (int *)specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)((uint64_t)v23, v146);
    swift_bridgeObjectRelease((_BYTE)v23);
    uint64_t v27 = MLSoundClassifier.DataSource.labeledSounds()(v23, a2, v26);
    LOBYTE(v23) = v27;
    uint64_t v147 = v25;
    uint64_t v28 = (uint64_t)specialized Sequence.flatMap<A>(_:)(v27);
    uint64_t v154 = 0;
    swift_bridgeObjectRelease((_BYTE)v23);
    uint64_t v148 = v24[7];
    double v149 = *(double *)(v159 + v148);
    uint64_t v29 = specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)(v28, v149);
    swift_bridgeObjectRelease(v28);
    LOBYTE(v25) = (_BYTE)v153;
    LOBYTE(v28) = specialized static Array<A>.== infix(_:_:)((uint64_t)v153, (uint64_t)v29);
    swift_bridgeObjectRelease(v25);
    swift_bridgeObjectRelease((_BYTE)v29);
    if (v28)
    {
      uint64_t v153 = v24;
      uint64_t v30 = v24[5];
      uint64_t v31 = v156 + v30;
      uint64_t v32 = v159;
      uint64_t v33 = v159 + v30;
      uint64_t v34 = (uint64_t)v160;
      uint64_t v35 = (void *)((char *)v160 + *(int *)(v145 + 48));
      outlined init with copy of MLTrainingSessionParameters(v31, (uint64_t)v160, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      uint64_t v36 = v33;
      uint64_t v37 = v34;
      outlined init with copy of MLTrainingSessionParameters(v36, (uint64_t)v35, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
      uint64_t v38 = v34;
      uint64_t v39 = v155;
      switch(swift_getEnumCaseMultiPayload(v38, v155))
      {
        case 0u:
        case 3u:
          outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v35, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
          goto LABEL_5;
        case 1u:
          uint64_t v67 = (uint64_t)v157;
          outlined init with copy of MLTrainingSessionParameters(v37, (uint64_t)v157, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
          if (swift_getEnumCaseMultiPayload(v35, v39) != 1)
          {
            outlined destroy of MLActivityClassifier.ModelParameters(v67, type metadata accessor for MLSoundClassifier.DataSource);
LABEL_34:
            uint64_t v96 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            swift_allocError(&type metadata for MLCreateError, v96, 0, 0);
            *(void *)uint64_t v97 = 1;
            *(_OWORD *)(v97 + 8) = 0;
            *(_OWORD *)(v97 + 24) = 0;
            *(void *)(v97 + 40) = 0;
            *(unsigned char *)(v97 + 48) = 4;
            swift_willThrow(&type metadata for MLCreateError, v96, v97, v98, v99, v100);
            LOBYTE(v21) = outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v37, &demangling cache variable for type metadata for (MLSoundClassifier.ModelParameters.ValidationData, MLSoundClassifier.ModelParameters.ValidationData));
            return v21;
          }
          uint64_t v68 = v67;
          uint64_t v69 = (uint64_t)v161;
          uint64_t v70 = v154;
          outlined init with take of MLClassifierMetrics(v68, (uint64_t)v161, type metadata accessor for MLSoundClassifier.DataSource);
          uint64_t v71 = (uint64_t)v35;
          uint64_t v72 = (uint64_t)v150;
          uint64_t v73 = (uint64_t)v150;
          outlined init with take of MLClassifierMetrics(v71, (uint64_t)v150, type metadata accessor for MLSoundClassifier.DataSource);
          uint64_t v75 = MLSoundClassifier.DataSource.labeledSounds()(v71, v73, v74);
          if (v70)
          {
            outlined destroy of MLActivityClassifier.ModelParameters(v72, type metadata accessor for MLSoundClassifier.DataSource);
            uint64_t v76 = v69;
LABEL_22:
            outlined destroy of MLActivityClassifier.ModelParameters(v76, type metadata accessor for MLSoundClassifier.DataSource);
            uint64_t v77 = (uint64_t)v160;
            goto LABEL_26;
          }
          char v103 = v75;
          uint64_t v104 = specialized Sequence.flatMap<A>(_:)(v75);
          swift_bridgeObjectRelease(v103);
          uint64_t v105 = specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)((uint64_t)v104, v146);
          swift_bridgeObjectRelease((_BYTE)v104);
          uint64_t v107 = MLSoundClassifier.DataSource.labeledSounds()(v104, v73, v106);
          char v123 = v107;
          uint64_t v124 = (uint64_t)specialized Sequence.flatMap<A>(_:)(v107);
          uint64_t v154 = 0;
          swift_bridgeObjectRelease(v123);
          uint64_t v125 = specialized static MLSoundClassifier.filterFilesForFeatureExtractor<A>(labeledFiles:featureExtractionTimeWindowSize:)(v124, v149);
          swift_bridgeObjectRelease(v124);
          LOBYTE(v124) = specialized static Array<A>.== infix(_:_:)((uint64_t)v105, (uint64_t)v125);
          swift_bridgeObjectRelease((_BYTE)v105);
          swift_bridgeObjectRelease((_BYTE)v125);
          if ((v124 & 1) == 0)
          {
            uint64_t v128 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            swift_allocError(&type metadata for MLCreateError, v128, 0, 0);
            *(void *)uint64_t v129 = 1;
            *(_OWORD *)(v129 + 8) = 0;
            *(_OWORD *)(v129 + 24) = 0;
            *(void *)(v129 + 40) = 0;
            *(unsigned char *)(v129 + 48) = 4;
            swift_willThrow(&type metadata for MLCreateError, v128, v129, v130, v131, v132);
            outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v150, type metadata accessor for MLSoundClassifier.DataSource);
            uint64_t v76 = (uint64_t)v161;
            goto LABEL_22;
          }
          outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v150, type metadata accessor for MLSoundClassifier.DataSource);
          outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v161, type metadata accessor for MLSoundClassifier.DataSource);
          uint64_t v32 = v159;
          uint64_t v37 = (uint64_t)v160;
LABEL_5:
          outlined destroy of MLActivityClassifier.ModelParameters(v37, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
          uint64_t v40 = v153[6];
          double v41 = *(double *)(v156 + v40);
          if (v41 == *(double *)(v32 + v40))
          {
            double v42 = *(double *)(v156 + v147);
            if (v42 == *(double *)(v32 + v148))
            {
              uint64_t v43 = v153[9];
              uint64_t v44 = *(void *)(v156 + v43);
              char v45 = *(unsigned char *)(v156 + v43 + 8);
              uint64_t v46 = *(void *)(v156 + v43 + 16);
              uint64_t v47 = *(void *)(v32 + v43);
              unsigned __int8 v48 = *(unsigned char *)(v32 + v43 + 8);
              *(void *)&long long v159 = *(void *)(v32 + v43 + 16);
              LOBYTE(v155) = v48;
              v160 = (void *)v46;
              if (v45)
              {
                int v49 = v152;
                if (((v44 == v47) & v48) == 0)
                {
LABEL_9:
                  *(void *)&long long v151 = v44;
                  BYTE8(v151) = v45;
                  char v157 = (char *)v47;
                  swift_bridgeObjectRetain(v46);
                  *(void *)&long long v50 = MLSoundClassifier.ModelParameters.FeatureExtractorType.description.getter();
                  uint64_t v51 = 0xD000000000000015;
                  uint64_t v158 = (char *)0xD000000000000015;
                  uint64_t v161 = "Feature Extractor: " + 0x8000000000000000;
                  unint64_t v52 = "Multilayer Perceptron" + 0x8000000000000000;
                  if (!v160) {
                    uint64_t v51 = 0xD000000000000012;
                  }
                  uint64_t v53 = "Feature Extractor: " + 0x8000000000000000;
                  if (!v160) {
                    uint64_t v53 = "Multilayer Perceptron" + 0x8000000000000000;
                  }
                  long long v151 = v50;
                  *(void *)&long long v156 = *((void *)&v50 + 1);
                  swift_bridgeObjectRetain(BYTE8(v50));
                  v54._uint64_t countAndFlagsBits = v51;
                  v54._unsigned __int8 object = v53;
                  String.append(_:)(v54);
                  swift_bridgeObjectRelease((_BYTE)v160);
                  swift_bridgeObjectRelease(v156);
                  swift_bridgeObjectRelease((_BYTE)v53);
                  long long v156 = v151;
                  *(void *)&long long v151 = v157;
                  BYTE8(v151) = v155 & 1;
                  uint64_t v55 = v159;
                  swift_bridgeObjectRetain(v159);
                  *(void *)&long long v56 = MLSoundClassifier.ModelParameters.FeatureExtractorType.description.getter();
                  char v57 = BYTE8(v56);
                  BOOL v58 = v55 == 0;
                  uint64_t v59 = (uint64_t)v158;
                  if (v58) {
                    uint64_t v59 = 0xD000000000000012;
                  }
                  else {
                    unint64_t v52 = v161;
                  }
                  long long v151 = v56;
                  swift_bridgeObjectRetain(BYTE8(v56));
                  v60._uint64_t countAndFlagsBits = v59;
                  v60._unsigned __int8 object = v52;
                  String.append(_:)(v60);
                  swift_bridgeObjectRelease(v159);
                  swift_bridgeObjectRelease(v57);
                  swift_bridgeObjectRelease((_BYTE)v52);
                  long long v159 = v151;
                  uint64_t v61 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
                  swift_allocError(&type metadata for MLCreateError, v61, 0, 0);
                  *(void *)uint64_t v62 = 0xD000000000000011;
                  uint64_t v66 = "on time window size" + 0x8000000000000000;
LABEL_17:
                  *(void *)(v62 + 8) = v66;
                  *(_OWORD *)(v62 + 16) = v156;
                  *(_OWORD *)(v62 + 32) = v159;
                  *(unsigned char *)(v62 + 48) = 3;
                  break;
                }
              }
              else
              {
                int v49 = v152;
                if (v48 & 1 | (v44 != v47)) {
                  goto LABEL_9;
                }
              }
              unint64_t v101 = 0xEB0000000064657ALL;
              switch(v49)
              {
                case 0:
                  uint64_t v161 = (char *)v44;
                  LOBYTE(v158) = v45;
                  char v157 = (char *)v47;
                  uint64_t v102 = 0x696C616974696E69;
                  goto LABEL_45;
                case 1:
                  LOBYTE(v21) = swift_bridgeObjectRelease(110);
                  return v21;
                case 2:
                  uint64_t v161 = (char *)v44;
                  LOBYTE(v158) = v45;
                  char v157 = (char *)v47;
                  JUMPOUT(0xF52B1);
                case 3:
                  uint64_t v161 = (char *)v44;
                  LOBYTE(v158) = v45;
                  JUMPOUT(0xF52CFLL);
                case 4:
                  uint64_t v161 = (char *)v44;
                  LOBYTE(v158) = v45;
                  char v157 = (char *)v47;
                  unint64_t v101 = 0xEB00000000676E69;
                  uint64_t v102 = 0x636E657265666E69;
LABEL_45:
                  char v108 = _stringCompareWithSmolCheck(_:_:expecting:)(v102, v101, 0x6974636172747865, 0xEA0000000000676ELL, 0);
                  LOBYTE(v21) = swift_bridgeObjectRelease(v101);
                  if (v108) {
                    return v21;
                  }
                  uint64_t v110 = v153[8];
                  uint64_t v111 = *(void *)(v32 + v110);
                  if (*(void *)(v156 + v110) != v111)
                  {
                    *(void *)&long long v151 = *(void *)(v156 + v110);
                    uint64_t v113 = lazy protocol witness table accessor for type Int and conformance Int();
                    *(void *)&long long v159 = BinaryInteger.description.getter(&type metadata for Int, v113);
                    *(void *)&long long v156 = v114;
                    *(void *)&long long v151 = v111;
                    uint64_t v115 = BinaryInteger.description.getter(&type metadata for Int, v113);
                    uint64_t v117 = v116;
                    uint64_t v118 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
                    swift_allocError(&type metadata for MLCreateError, v118, 0, 0);
                    *(void *)uint64_t v119 = 0x657449202E78614DLL;
                    *(void *)(v119 + 8) = 0xEF736E6F69746172;
                    *(void *)(v119 + 16) = v159;
                    *(void *)(v119 + 24) = v156;
                    *(void *)(v119 + 32) = v115;
                    *(void *)(v119 + 40) = v117;
                    *(unsigned char *)(v119 + 48) = 3;
                    LOBYTE(v21) = swift_willThrow(&type metadata for MLCreateError, v118, v119, v120, v121, v122);
                    return v21;
                  }
                  LOBYTE(v109) = (_BYTE)v158;
                  if ((_BYTE)v158)
                  {
                    uint64_t v112 = (uint64_t)v161;
                    if ((v155 & (v161 == v157)) != 1) {
                      goto LABEL_60;
                    }
                  }
                  else
                  {
                    uint64_t v112 = (uint64_t)v161;
                    if (v155 & 1 | (v161 != v157)) {
                      goto LABEL_60;
                    }
                  }
                  if (v160)
                  {
                    if ((void)v159)
                    {
                      char v126 = (char)v158;
                      uint64_t v127 = v112;
                      LOBYTE(v21) = specialized static Array<A>.== infix(_:_:)((uint64_t)v160, v159);
                      uint64_t v112 = v127;
                      LOBYTE(v109) = v126;
                      if (v21) {
                        return v21;
                      }
                    }
                  }
                  else if (!(void)v159)
                  {
                    LOBYTE(v21) = swift_bridgeObjectRelease_n(0, 2, v109, v154, v112);
                    return v21;
                  }
LABEL_60:
                  *(void *)&long long v151 = v112;
                  BYTE8(v151) = v109;
                  uint64_t v133 = (uint64_t)v160;
                  swift_bridgeObjectRetain((_BYTE)v160);
                  *(void *)&long long v134 = MLSoundClassifier.ModelParameters.FeatureExtractorType.description.getter();
                  uint64_t v161 = (char *)0xD000000000000015;
                  uint64_t v135 = "Feature Extractor: " + 0x8000000000000000;
                  uint64_t v158 = "Feature Extractor: " + 0x8000000000000000;
                  uint64_t v136 = "Multilayer Perceptron" + 0x8000000000000000;
                  BOOL v58 = v133 == 0;
                  uint64_t v137 = 0xD000000000000015;
                  if (v58)
                  {
                    uint64_t v137 = 0xD000000000000012;
                    uint64_t v135 = "Multilayer Perceptron" + 0x8000000000000000;
                  }
                  long long v151 = v134;
                  *(void *)&long long v156 = *((void *)&v134 + 1);
                  swift_bridgeObjectRetain(BYTE8(v134));
                  v138._uint64_t countAndFlagsBits = v137;
                  v138._unsigned __int8 object = v135;
                  String.append(_:)(v138);
                  swift_bridgeObjectRelease((_BYTE)v160);
                  swift_bridgeObjectRelease(v156);
                  swift_bridgeObjectRelease((_BYTE)v135);
                  long long v156 = v151;
                  *(void *)&long long v151 = v157;
                  BYTE8(v151) = v155 & 1;
                  uint64_t v139 = v159;
                  swift_bridgeObjectRetain(v159);
                  *(void *)&long long v140 = MLSoundClassifier.ModelParameters.FeatureExtractorType.description.getter();
                  char v141 = BYTE8(v140);
                  BOOL v58 = v139 == 0;
                  uint64_t v142 = (uint64_t)v161;
                  if (v58) {
                    uint64_t v142 = 0xD000000000000012;
                  }
                  else {
                    uint64_t v136 = v158;
                  }
                  long long v151 = v140;
                  swift_bridgeObjectRetain(BYTE8(v140));
                  v143._uint64_t countAndFlagsBits = v142;
                  v143._unsigned __int8 object = v136;
                  String.append(_:)(v143);
                  swift_bridgeObjectRelease(v159);
                  swift_bridgeObjectRelease(v141);
                  swift_bridgeObjectRelease((_BYTE)v136);
                  long long v159 = v151;
                  uint64_t v61 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
                  swift_allocError(&type metadata for MLCreateError, v61, 0, 0);
                  *(void *)uint64_t v62 = 0x687469726F676C41;
                  uint64_t v66 = (char *)0xE90000000000006DLL;
                  break;
              }
              goto LABEL_17;
            }
            *(void *)&long long v159 = *(void *)(v32 + v148);
            uint64_t v88 = Double.description.getter(v42);
            uint64_t v90 = v94;
            uint64_t v91 = Double.description.getter(*(double *)&v159);
            uint64_t v93 = v95;
            uint64_t v61 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            swift_allocError(&type metadata for MLCreateError, v61, 0, 0);
            *(void *)uint64_t v62 = 0xD000000000000023;
            uint64_t v63 = "ning checkpoints are supported" + 0x8000000000000000;
          }
          else
          {
            *(void *)&long long v159 = *(void *)(v32 + v40);
            uint64_t v88 = Double.description.getter(v41);
            uint64_t v90 = v89;
            uint64_t v91 = Double.description.getter(*(double *)&v159);
            uint64_t v93 = v92;
            uint64_t v61 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
            swift_allocError(&type metadata for MLCreateError, v61, 0, 0);
            *(void *)uint64_t v62 = 0x2070616C7265764FLL;
            uint64_t v63 = (char *)0xEE00726F74636146;
          }
          *(void *)(v62 + 8) = v63;
          *(void *)(v62 + 16) = v88;
          *(void *)(v62 + 24) = v90;
          *(void *)(v62 + 32) = v91;
          *(void *)(v62 + 40) = v93;
          *(unsigned char *)(v62 + 48) = 3;
          break;
        case 2u:
          uint64_t v78 = v37;
          uint64_t v79 = (uint64_t *)v158;
          outlined init with copy of MLTrainingSessionParameters(v78, (uint64_t)v158, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
          uint64_t v80 = *v79;
          if (swift_getEnumCaseMultiPayload(v35, v39) != 2)
          {
            swift_bridgeObjectRelease(v80);
            uint64_t v37 = (uint64_t)v160;
            goto LABEL_34;
          }
          uint64_t v81 = *v35;
          char v82 = specialized static Dictionary<>.== infix(_:_:)(v80, *v35);
          swift_bridgeObjectRelease(v80);
          swift_bridgeObjectRelease(v81);
          uint64_t v37 = (uint64_t)v160;
          if (v82) {
            goto LABEL_5;
          }
          uint64_t v83 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          swift_allocError(&type metadata for MLCreateError, v83, 0, 0);
          *(void *)uint64_t v84 = 1;
          *(_OWORD *)(v84 + 8) = 0;
          *(_OWORD *)(v84 + 24) = 0;
          *(void *)(v84 + 40) = 0;
          *(unsigned char *)(v84 + 48) = 4;
          swift_willThrow(&type metadata for MLCreateError, v83, v84, v85, v86, v87);
          uint64_t v77 = v37;
LABEL_26:
          LOBYTE(v21) = outlined destroy of MLActivityClassifier.ModelParameters(v77, type metadata accessor for MLSoundClassifier.ModelParameters.ValidationData);
          return v21;
      }
    }
    else
    {
      uint64_t v61 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v61, 0, 0);
      *(void *)uint64_t v62 = 1;
      *(_OWORD *)(v62 + 8) = 0;
      *(_OWORD *)(v62 + 24) = 0;
      *(void *)(v62 + 40) = 0;
      *(unsigned char *)(v62 + 48) = 4;
    }
    LOBYTE(v21) = swift_willThrow(&type metadata for MLCreateError, v61, v62, v63, v64, v65);
  }
  return v21;
}

uint64_t SoundClassifierTrainingSessionDelegate.deinit()
{
  swift_bridgeObjectRelease(*(void *)(v0 + 24));
  outlined destroy of MLActivityClassifier.ModelParameters(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for MLSoundClassifier.PersistentParameters?);
  swift_bridgeObjectRelease(*(void *)(v0
                                      + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFiles));
  swift_bridgeObjectRelease(*(void *)(v0
                                      + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFiles));
  swift_bridgeObjectRelease(*(void *)(v0
                                      + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingFeatures));
  swift_bridgeObjectRelease(*(void *)(v0
                                      + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationFeatures));
  swift_bridgeObjectRelease(*(void *)(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_labels));
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_classifier, &demangling cache variable for type metadata for MLSoundClassifier.Classifier?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_model, &demangling cache variable for type metadata for MLSoundClassifier.Model?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_parameters, &demangling cache variable for type metadata for MLSoundClassifier.ModelParameters?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_trainingMetrics, &demangling cache variable for type metadata for MLClassifierMetrics?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_validationMetrics, &demangling cache variable for type metadata for MLClassifierMetrics?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML38SoundClassifierTrainingSessionDelegate_tablePrinter, &demangling cache variable for type metadata for TrainingTablePrinter?);
  return v0;
}

uint64_t SoundClassifierTrainingSessionDelegate.__deallocating_deinit()
{
  SoundClassifierTrainingSessionDelegate.deinit();
  return swift_deallocClassInstance(v0, *(unsigned int *)(*(void *)v0 + 48), *(unsigned __int16 *)(*(void *)v0 + 52));
}

uint64_t ObjC metadata update function for SoundClassifierTrainingSessionDelegate()
{
  return type metadata accessor for SoundClassifierTrainingSessionDelegate(0);
}

uint64_t type metadata accessor for SoundClassifierTrainingSessionDelegate(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for SoundClassifierTrainingSessionDelegate;
  if (!type metadata singleton initialization cache for SoundClassifierTrainingSessionDelegate) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for SoundClassifierTrainingSessionDelegate);
  }
  return result;
}

uint64_t type metadata completion function for SoundClassifierTrainingSessionDelegate(uint64_t a1)
{
  v9[0] = &unk_349E88;
  uint64_t result = type metadata accessor for MLTrainingSessionParameters(319);
  if (v2 <= 0x3F)
  {
    v9[1] = *(void *)(result - 8) + 64;
    uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLSoundClassifier.PersistentParameters?, type metadata accessor for MLSoundClassifier.PersistentParameters);
    if (v3 <= 0x3F)
    {
      v9[2] = *(void *)(result - 8) + 64;
      v9[3] = (char *)&value witness table for Builtin.BridgeObject + 64;
      void v9[4] = (char *)&value witness table for Builtin.BridgeObject + 64;
      double v9[5] = (char *)&value witness table for Builtin.BridgeObject + 64;
      void v9[6] = (char *)&value witness table for Builtin.BridgeObject + 64;
      v9[7] = (char *)&value witness table for Builtin.BridgeObject + 64;
      v9[8] = &unk_349EA0;
      uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLSoundClassifier.Classifier?, type metadata accessor for MLSoundClassifier.Classifier);
      if (v4 <= 0x3F)
      {
        v9[9] = *(void *)(result - 8) + 64;
        uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLSoundClassifier.Model?, type metadata accessor for MLSoundClassifier.Model);
        if (v5 <= 0x3F)
        {
          v9[10] = *(void *)(result - 8) + 64;
          uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLSoundClassifier.ModelParameters?, type metadata accessor for MLSoundClassifier.ModelParameters);
          if (v6 <= 0x3F)
          {
            v9[11] = *(void *)(result - 8) + 64;
            uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for MLClassifierMetrics?, type metadata accessor for MLClassifierMetrics);
            if (v7 <= 0x3F)
            {
              uint64_t v10 = *(void *)(result - 8) + 64;
              uint64_t v11 = v10;
              uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for TrainingTablePrinter?, type metadata accessor for TrainingTablePrinter);
              if (v8 <= 0x3F)
              {
                uint64_t v12 = *(void *)(result - 8) + 64;
                uint64_t result = swift_updateClassMetadata2(a1, 256, 15, v9, a1 + 80);
                if (!result) {
                  return 0;
                }
              }
            }
          }
        }
      }
    }
  }
  return result;
}

uint64_t type metadata accessor for MLSoundClassifier.PersistentParameters?(uint64_t a1, uint64_t *a2, uint64_t (*a3)(uint64_t))
{
  uint64_t result = *a2;
  if (!*a2)
  {
    uint64_t v4 = a3(255);
    uint64_t result = type metadata accessor for Optional(a1, v4);
    if (!v5) {
      *a2 = result;
    }
  }
  return result;
}

void protocol witness for TrainingSessionDelegate.setUp() in conformance SoundClassifierTrainingSessionDelegate()
{
}

void protocol witness for TrainingSessionDelegate.resume(from:) in conformance SoundClassifierTrainingSessionDelegate(Swift::OpaquePointer a1)
{
}

unint64_t protocol witness for TrainingSessionDelegate.itemCount(phase:) in conformance SoundClassifierTrainingSessionDelegate(CreateML::MLPhase a1)
{
  return (unint64_t)SoundClassifierTrainingSessionDelegate.itemCount(phase:)(a1);
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(Swift::Int a1)
{
  *(Swift::tuple_Int_finished_Bool *)&long long v2 = SoundClassifierTrainingSessionDelegate.extractFeatures(from:)(a1);
  if (v4)
  {
    uint64_t v5 = v1;
  }
  else
  {
    unsigned int v3 = BYTE8(v2);
    uint64_t v5 = v1;
    *((void *)&v2 + 1) = v2;
  }
  return protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(*(uint64_t (**)(uint64_t, void))(v1 + 8), v5, *((uint64_t *)&v2 + 1), v3);
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance SoundClassifierTrainingSessionDelegate(uint64_t a1)
{
  long long v2 = (void *)swift_task_alloc(dword_3A744C);
  *(void *)(v1 + 16) = v2;
  *long long v2 = v1;
  v2[1] = protocol witness for TrainingSessionDelegate.train(from:) in conformance SoundClassifierTrainingSessionDelegate;
  return SoundClassifierTrainingSessionDelegate.train(from:)(a1);
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance SoundClassifierTrainingSessionDelegate(uint64_t a1, uint64_t a2, unsigned __int8 a3)
{
  uint64_t v7 = *(void *)(*v4 + 16);
  uint64_t v8 = *v4;
  swift_task_dealloc(v7);
  if (!v3)
  {
    uint64_t v9 = a3;
    uint64_t v7 = a1;
  }
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(v8 + 8))(v7, a2, v9);
}

uint64_t protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance SoundClassifierTrainingSessionDelegate()
{
  uint64_t v1 = (void *)swift_task_alloc(dword_3A742C);
  *(void *)(v0 + 16) = v1;
  *uint64_t v1 = v0;
  v1[1] = protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance SoundClassifierTrainingSessionDelegate;
  return SoundClassifierTrainingSessionDelegate.evaluate(from:)();
}

uint64_t protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance SoundClassifierTrainingSessionDelegate(uint64_t a1)
{
  uint64_t v4 = *(void *)(*v2 + 16);
  uint64_t v5 = *v2;
  swift_task_dealloc(v4);
  if (!v1) {
    uint64_t v4 = a1;
  }
  return (*(uint64_t (**)(uint64_t))(v5 + 8))(v4);
}

uint64_t protocol witness for TrainingSessionDelegate.saveCheckpoint(to:phase:iteration:) in conformance SoundClassifierTrainingSessionDelegate(uint64_t *a1, unsigned __int8 *a2)
{
  return SoundClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)(a1, a2);
}

Swift::Bool protocol witness for TrainingSessionDelegate.shouldTransition(from:to:) in conformance SoundClassifierTrainingSessionDelegate(CreateML::MLPhase a1, CreateML::MLPhase a2)
{
  return SoundClassifierTrainingSessionDelegate.shouldTransition(from:to:)(a1, a2);
}

uint64_t protocol witness for TrainingSessionCodable.save(to:) in conformance SoundClassifierTrainingSessionDelegate(uint64_t a1)
{
  return SoundClassifierTrainingSessionDelegate.save(to:)(a1);
}

NSURL *protocol witness for TrainingSessionCodable.restore(from:phase:) in conformance SoundClassifierTrainingSessionDelegate(uint64_t a1, unsigned char *a2)
{
  return SoundClassifierTrainingSessionDelegate.restore(from:phase:)(a1, a2);
}

Swift::Int specialized MutableCollection<>.sort(by:)(void *a1)
{
  uint64_t v1 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>)
                 - 8);
  long long v2 = (void *)*a1;
  if (!swift_isUniquelyReferenced_nonNull_native(*a1)) {
    long long v2 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)v2);
  }
  uint64_t v3 = v2[2];
  v5[0] = (uint64_t)v2 + ((*(unsigned __int8 *)(v1 + 80) + 32) & ~*(unsigned __int8 *)(v1 + 80));
  v5[1] = v3;
  Swift::Int result = specialized UnsafeMutableBufferPointer._stableSortImpl(by:)(v5);
  *a1 = v2;
  return result;
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  Swift::Int result;
  uint64_t v5[6];

  uint64_t v1 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>)
                 - 8);
  long long v2 = (void *)*a1;
  if (!swift_isUniquelyReferenced_nonNull_native(*a1)) {
    long long v2 = specialized _ContiguousArrayBuffer._consumeAndCreateNew()((uint64_t)v2);
  }
  uint64_t v3 = v2[2];
  v5[0] = (uint64_t)v2 + ((*(unsigned __int8 *)(v1 + 80) + 32) & ~*(unsigned __int8 *)(v1 + 80));
  v5[1] = v3;
  Swift::Int result = specialized UnsafeMutableBufferPointer._stableSortImpl(by:)(v5);
  *a1 = v2;
  return result;
}

uint64_t specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(uint64_t a1, uint64_t a2, uint64_t a3, unint64_t a4, _OWORD *a5)
{
  uint64_t v25 = v5;
  uint64_t v7 = v6;
  unint64_t v27 = a4;
  uint64_t v24 = a3;
  *(void *)(v7 + 72) = &_swiftEmptySetSingleton;
  id v9 = objc_allocWithZone((Class)NSLock);
  *(void *)(v7 + 80) = [v9 init];
  long long v10 = a5[1];
  long long v11 = *(_OWORD *)((char *)a5 + 25);
  *(_OWORD *)(v7 + 16) = *a5;
  *(_OWORD *)(v7 + 32) = v10;
  *(_OWORD *)(v7 + 41) = v11;
  swift_unknownObjectRetain(a1);
  uint64_t v26 = a1;
  *(void *)(v7 + 64) = specialized Array.init<A>(_:)(a1, a2, v24, v27, specialized _copyCollectionToContiguousArray<A>(_:));
  if (*(double *)a5 < 0.0 || *(double *)a5 >= 1.0)
  {
    unint64_t v27 = *(void *)a5;
    swift_release();
    uint64_t v22 = 0;
    unint64_t v23 = 0xE000000000000000;
    _StringGuts.grow(_:)(61);
    v12._unsigned __int8 object = "gSessionDelegate.swift" + 0x8000000000000000;
    v12._uint64_t countAndFlagsBits = 0xD00000000000003ALL;
    String.append(_:)(v12);
    Double.write<A>(to:)(&v22, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    v12._uint64_t countAndFlagsBits = 46;
    v12._unsigned __int8 object = (void *)0xE100000000000000;
    String.append(_:)(v12);
    uint64_t v13 = v22;
    unint64_t v14 = v23;
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
    int64_t v16 = (void *)swift_allocObject(v15, 64, 7);
    v16[2] = 1;
    v16[3] = 2;
    v16[7] = &type metadata for String;
    v16[4] = v13;
    v16[5] = v14;
    swift_bridgeObjectRetain(v14);
    print(_:separator:terminator:)(v16, 32, 0xE100000000000000, 10, 0xE100000000000000);
    swift_bridgeObjectRelease((_BYTE)v16);
    v12._unsigned __int8 object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v12._object, 0, 0);
    *(void *)uint64_t v17 = v13;
    *(void *)(v17 + 8) = v14;
    *(_OWORD *)(v17 + 16) = 0;
    *(_OWORD *)(v17 + 32) = 0;
    *(unsigned char *)(v17 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v12._object, v17, v18, v19, v20);
    swift_unknownObjectRelease(v26);
  }
  else
  {
    swift_unknownObjectRelease(v26);
  }
  return v7;
}

uint64_t specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)(uint64_t a1, _OWORD *a2)
{
  uint64_t v3 = v2;
  *(void *)(v2 + 72) = &_swiftEmptySetSingleton;
  id v5 = objc_allocWithZone((Class)NSLock);
  *(void *)(v2 + 80) = [v5 init];
  long long v6 = a2[1];
  long long v7 = *(_OWORD *)((char *)a2 + 25);
  *(_OWORD *)(v2 + 16) = *a2;
  *(_OWORD *)(v2 + 32) = v6;
  *(_OWORD *)(v2 + 41) = v7;
  *(void *)(v2 + 64) = a1;
  if (*(double *)a2 < 0.0 || *(double *)a2 >= 1.0)
  {
    uint64_t v20 = *(void *)a2;
    swift_bridgeObjectRetain(a1);
    swift_release();
    uint64_t v18 = 0;
    unint64_t v19 = 0xE000000000000000;
    _StringGuts.grow(_:)(61);
    v8._unsigned __int8 object = "gSessionDelegate.swift" + 0x8000000000000000;
    v8._uint64_t countAndFlagsBits = 0xD00000000000003ALL;
    String.append(_:)(v8);
    Double.write<A>(to:)(&v18, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    v8._uint64_t countAndFlagsBits = 46;
    v8._unsigned __int8 object = (void *)0xE100000000000000;
    String.append(_:)(v8);
    uint64_t v20 = a1;
    uint64_t v9 = v18;
    unint64_t v10 = v19;
    uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
    Swift::String v12 = (void *)swift_allocObject(v11, 64, 7);
    v12[2] = 1;
    v12[3] = 2;
    v12[7] = &type metadata for String;
    v12[4] = v9;
    void v12[5] = v10;
    swift_bridgeObjectRetain(v10);
    print(_:separator:terminator:)(v12, 32, 0xE100000000000000, 10, 0xE100000000000000);
    swift_bridgeObjectRelease((_BYTE)v12);
    v8._unsigned __int8 object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v8._object, 0, 0);
    *(void *)uint64_t v13 = v9;
    *(void *)(v13 + 8) = v10;
    *(_OWORD *)(v13 + 16) = 0;
    *(_OWORD *)(v13 + 32) = 0;
    *(unsigned char *)(v13 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v8._object, v13, v14, v15, v16);
    swift_bridgeObjectRelease(v20);
  }
  return v3;
}

uint64_t specialized Sequence<>.lexicographicallyPrecedes<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, void *a4)
{
  unsigned int v4 = a2;
  swift_bridgeObjectRetain(a4);
  swift_bridgeObjectRetain(a2);
  Swift::String_optional v5 = String.Iterator.next()();
  if (!v5.value._object)
  {
LABEL_10:
    swift_bridgeObjectRelease(a4);
    unsigned __int8 object = String.Iterator.next()().value._object;
    swift_bridgeObjectRelease(a2);
    LOBYTE(v4) = object != 0;
    goto LABEL_15;
  }
  uint64_t countAndFlagsBits = v5.value._countAndFlagsBits;
  long long v7 = v5.value._object;
  unsigned int v4 = 1;
  while (1)
  {
    Swift::String_optional v8 = String.Iterator.next()();
    if (!v8.value._object)
    {
      swift_bridgeObjectRelease(v7);
LABEL_12:
      swift_bridgeObjectRelease(a2);
      unsigned int v4 = 0;
      goto LABEL_14;
    }
    uint64_t v9 = v8.value._countAndFlagsBits;
    unint64_t v10 = v8.value._object;
    if (countAndFlagsBits == v8.value._countAndFlagsBits && v7 == v8.value._object)
    {
      swift_bridgeObjectRelease(v7);
      swift_bridgeObjectRelease(v10);
      goto LABEL_9;
    }
    if (_stringCompareWithSmolCheck(_:_:expecting:)(countAndFlagsBits, v7, v8.value._countAndFlagsBits, v8.value._object, 1))break; {
    char v11 = _stringCompareWithSmolCheck(_:_:expecting:)(v9, v10, countAndFlagsBits, v7, 1);
    }
    swift_bridgeObjectRelease(v7);
    swift_bridgeObjectRelease(v10);
    if (v11) {
      goto LABEL_12;
    }
LABEL_9:
    Swift::String_optional v12 = String.Iterator.next()();
    uint64_t countAndFlagsBits = v12.value._countAndFlagsBits;
    long long v7 = v12.value._object;
    if (!v12.value._object) {
      goto LABEL_10;
    }
  }
  swift_bridgeObjectRelease(v7);
  swift_bridgeObjectRelease(v10);
  swift_bridgeObjectRelease(a2);
  LOBYTE(v4) = 1;
LABEL_14:
  unsigned __int8 object = a4;
LABEL_15:
  swift_bridgeObjectRelease(object);
  return v4;
}

id @nonobjc AVAudioFile.init(forReading:)(uint64_t a1)
{
  URL._bridgeToObjectiveC()(__stack_chk_guard);
  uint64_t v3 = v2;
  id v12 = 0;
  id v4 = [v1 initForReading:v2 error:&v12];

  id v5 = v12;
  id v11 = v4;
  if (v4)
  {
    uint64_t v6 = type metadata accessor for URL(0);
    long long v7 = *(void (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8);
    v5;
    v7(a1, v6);
  }
  else
  {
    id v8 = v12;
    _convertNSErrorToError(_:)(v5);

    swift_willThrow();
    uint64_t v9 = type metadata accessor for URL(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(a1, v9);
  }
  return v11;
}

uint64_t sub_F642E(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
}

uint64_t sub_F6440(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, a4, &demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Float>, String>);
}

uint64_t sub_F6452()
{
  return key path getter for AnnotatedPrediction.prediction : AnnotatedPrediction<ClassificationDistribution<String>, String>();
}

uint64_t sub_F645C(uint64_t a1)
{
  return key path setter for AnnotatedPrediction.prediction : AnnotatedPrediction<ClassificationDistribution<String>, String>(a1);
}

void *sub_F6466()
{
  return &protocol witness table for String;
}

uint64_t sub_F6473()
{
  return key path getter for ClassificationDistribution.mostLikelyLabel : ClassificationDistribution<String>();
}

uint64_t sub_F6481()
{
  return objectdestroyTm_1();
}

uint64_t partial apply for closure #2 in SoundClassifierTrainingSessionDelegate.train(from:)(uint64_t a1)
{
  return partial apply for closure #2 in SoundClassifierTrainingSessionDelegate.train(from:)(a1, (uint64_t (*)(uint64_t, void, uint64_t))closure #2 in SoundClassifierTrainingSessionDelegate.train(from:));
}

uint64_t sub_F649C()
{
  return objectdestroyTm_1();
}

uint64_t objectdestroyTm_1()
{
  uint64_t v1 = type metadata accessor for TrainingTablePrinter(0);
  uint64_t v2 = *(void *)(v1 - 8);
  uint64_t v3 = *(unsigned __int8 *)(v2 + 80);
  uint64_t v4 = ~*(unsigned __int8 *)(v2 + 80) & (v3 + 24);
  uint64_t v5 = v4 + *(void *)(v2 + 64);
  swift_release();
  uint64_t v6 = v0 + v4;
  uint64_t v7 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v7 - 8) + 8))(v6, v7);

  swift_bridgeObjectRelease(*(void *)(*(int *)(v1 + 24) + v6));
  return swift_deallocObject(v0, v5, v3 | 7);
}

uint64_t partial apply for closure #1 in SoundClassifierTrainingSessionDelegate.train(from:)(uint64_t a1)
{
  return partial apply for closure #2 in SoundClassifierTrainingSessionDelegate.train(from:)(a1, (uint64_t (*)(uint64_t, void, uint64_t))closure #1 in SoundClassifierTrainingSessionDelegate.train(from:));
}

uint64_t partial apply for closure #2 in SoundClassifierTrainingSessionDelegate.train(from:)(uint64_t a1, uint64_t (*a2)(uint64_t, void, uint64_t))
{
  uint64_t v3 = type metadata accessor for TrainingTablePrinter(0);
  return a2(a1, *(void *)(v2 + 16), v2+ (~*(unsigned __int8 *)(*(void *)(v3 - 8) + 80) & (*(unsigned __int8 *)(*(void *)(v3 - 8)+ 80)+ 24)));
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(uint64_t (*a1)(uint64_t, void), uint64_t a2, uint64_t a3, unsigned int a4)
{
  return a1(a3, a4);
}

Swift::Int specialized UnsafeMutableBufferPointer._stableSortImpl(by:)(uint64_t *a1)
{
  uint64_t v139 = type metadata accessor for URL(0);
  uint64_t v134 = *(void *)(v139 - 8);
  int64_t v2 = *(void *)(v134 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  long long v140 = &v131;
  uint64_t v159 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  long long v151 = *(void **)(v159 - 8);
  int64_t v5 = v151[8];
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v136 = &v131;
  id v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v133 = &v131;
  unint64_t v10 = alloca(v5);
  id v11 = alloca(v5);
  long long v156 = &v131;
  id v12 = alloca(v5);
  uint64_t v13 = alloca(v5);
  uint64_t v153 = &v131;
  Swift::Int v14 = a1[1];
  Swift::Int result = _minimumMergeRunLength(_:)(v14);
  if (result >= v14)
  {
    if (v14 < 0) {
      BUG();
    }
    if (v14) {
      return specialized MutableCollection<>._insertionSort(within:sortedEnd:by:)(0, v14, 1uLL, a1);
    }
  }
  else
  {
    Swift::Int v16 = result;
    int v152 = a1;
    uint64_t v145 = v1;
    Swift::String v138 = specialized static Array._allocateUninitialized(_:)(v14 / 2);
    unint64_t v135 = v18;
    uint64_t v137 = v14;
    if (v14 > 0)
    {
      Swift::Int v132 = v16;
      unint64_t v19 = (char *)_swiftEmptyArrayStorage;
      uint64_t v20 = 0;
      Swift::Int v21 = v14;
      uint64_t v22 = v159;
      while (1)
      {
        uint64_t v158 = v19;
        uint64_t v23 = (uint64_t)v20;
        Swift::Int v24 = (Swift::Int)(v20 + 1);
        uint64_t v144 = v20;
        if ((uint64_t)(v20 + 1) >= v21)
        {
          uint64_t v47 = v152;
        }
        else
        {
          uint64_t v147 = *v152;
          uint64_t v25 = (char *)v151[2];
          uint64_t v149 = v151[9];
          uint64_t v154 = (char *)(v147 + v149 * v24);
          ((void (*)(void (**)(void, uint64_t), char *, uint64_t))v25)(v153, v154, v22);
          uint64_t v150 = v23 * v149;
          char v141 = v25;
          ((void (*)(void (**)(void, uint64_t), uint64_t, uint64_t))v25)(v156, v147 + v23 * v149, v22);
          Swift::Int v146 = v21;
          uint64_t v26 = v140;
          AnnotatedFeature.feature.getter(v22);
          Swift::String v148 = URL.path(percentEncoded:)(1);
          char v157 = *(char **)(v134 + 8);
          uint64_t v27 = v139;
          ((void (*)(void, uint64_t))v157)(v26, v139);
          AnnotatedFeature.feature.getter(v22);
          Swift::String v28 = URL.path(percentEncoded:)(1);
          uint64_t countAndFlagsBits = v28._countAndFlagsBits;
          unsigned __int8 object = v28._object;
          Swift::String v143 = (char *)v28._object;
          uint64_t v31 = v26;
          Swift::Int v21 = v146;
          uint64_t v32 = v27;
          uint64_t v23 = (uint64_t)v144;
          ((void (*)(void, uint64_t))v157)(v31, v32);
          uint64_t v33 = countAndFlagsBits;
          uint64_t v22 = v159;
          uint64_t v34 = (uint64_t)object;
          LOBYTE(object) = v148._object;
          LOBYTE(v142) = specialized Sequence<>.lexicographicallyPrecedes<A>(_:)(v33, v34, v148._countAndFlagsBits, v148._object);
          swift_bridgeObjectRelease((_BYTE)object);
          swift_bridgeObjectRelease((_BYTE)v143);
          uint64_t v35 = (void (*)(void, uint64_t))v151[1];
          v35(v156, v22);
          uint64_t v131 = v35;
          v35(v153, v22);
          Swift::Int v24 = v23 + 2;
          if (v23 + 2 >= v21)
          {
            uint64_t v46 = v149;
          }
          else
          {
            uint64_t v36 = (char *)(v147 + v24 * v149);
            uint64_t v37 = v154;
            while (1)
            {
              uint64_t v154 = v37;
              uint64_t v155 = (char *)v24;
              Swift::String v143 = v36;
              uint64_t v38 = (void (*)(void (**)(void, uint64_t), char *, uint64_t))v141;
              ((void (*)(void (**)(void, uint64_t), char *, uint64_t))v141)(v153, v36, v22);
              v38(v156, v37, v22);
              uint64_t v39 = v140;
              AnnotatedFeature.feature.getter(v22);
              Swift::String v148 = URL.path(percentEncoded:)(1);
              uint64_t v40 = v139;
              ((void (*)(void, uint64_t))v157)(v39, v139);
              AnnotatedFeature.feature.getter(v22);
              Swift::String v41 = URL.path(percentEncoded:)(1);
              uint64_t v42 = v41._countAndFlagsBits;
              uint64_t v43 = v41._object;
              ((void (*)(void, uint64_t))v157)(v39, v40);
              LOBYTE(v39) = v148._object;
              LOBYTE(v42) = specialized Sequence<>.lexicographicallyPrecedes<A>(_:)(v42, (uint64_t)v43, v148._countAndFlagsBits, v148._object);
              swift_bridgeObjectRelease((_BYTE)v39);
              char v44 = (char)v43;
              uint64_t v22 = v159;
              swift_bridgeObjectRelease(v44);
              char v45 = v131;
              v131(v156, v22);
              v45(v153, v22);
              if ((v142 ^ v42)) {
                break;
              }
              Swift::Int v24 = (Swift::Int)(v155 + 1);
              uint64_t v46 = v149;
              uint64_t v37 = &v154[v149];
              uint64_t v36 = &v143[v149];
              Swift::Int v21 = v146;
              if ((uint64_t)(v155 + 1) >= v146)
              {
                Swift::Int v24 = v146;
                uint64_t v23 = (uint64_t)v144;
                goto LABEL_13;
              }
            }
            Swift::Int v24 = (Swift::Int)v155;
            uint64_t v23 = (uint64_t)v144;
            Swift::Int v21 = v146;
            uint64_t v46 = v149;
          }
LABEL_13:
          uint64_t v47 = v152;
          uint64_t v17 = v150;
          if (v142)
          {
            if (v24 < v23) {
              BUG();
            }
            if (v24 > v23)
            {
              uint64_t v48 = v46 * (v24 - 1);
              uint64_t v49 = v46 * v24;
              long long v50 = (char *)v23;
              uint64_t v51 = 0;
              uint64_t v155 = (char *)v24;
              while (1)
              {
                unint64_t v52 = (char *)(v24 + v51 - 1);
                if (v50 != v52) {
                  break;
                }
LABEL_26:
                ++v50;
                --v51;
                v48 -= v46;
                v49 -= v46;
                v17 += v46;
                if ((uint64_t)v50 >= (uint64_t)v52)
                {
                  uint64_t v47 = v152;
                  uint64_t v22 = v159;
                  uint64_t v23 = (uint64_t)v144;
                  Swift::Int v21 = v146;
                  goto LABEL_28;
                }
              }
              uint64_t v154 = (char *)(v24 + v51 - 1);
              if (!v147) {
                BUG();
              }
              v148._unsigned __int8 object = (void *)(v147 + v17);
              char v157 = (char *)(v147 + v48);
              uint64_t v53 = (void (*)(void (**)(void, uint64_t), uint64_t, uint64_t))v151[4];
              uint64_t v150 = v17;
              v148._uint64_t countAndFlagsBits = (uint64_t)v53;
              v53(v136, v147 + v17, v159);
              if (v150 < v48 || v148._object >= (void *)(v49 + v147))
              {
                swift_arrayInitWithTakeFrontToBack(v148._object, v157, 1, v159);
LABEL_24:
                uint64_t v55 = v157;
                uint64_t v54 = v159;
              }
              else
              {
                uint64_t v54 = v159;
                uint64_t v55 = v157;
                if (v150 != v48)
                {
                  swift_arrayInitWithTakeBackToFront(v148._object, v157, 1, v159);
                  goto LABEL_24;
                }
              }
              ((void (*)(char *, void (**)(void, uint64_t), uint64_t))v148._countAndFlagsBits)(v55, v136, v54);
              Swift::Int v24 = (Swift::Int)v155;
              uint64_t v46 = v149;
              uint64_t v17 = v150;
              unint64_t v52 = v154;
              goto LABEL_26;
            }
          }
        }
LABEL_28:
        if (v24 < v21)
        {
          if (__OFSUB__(v24, v23)) {
            BUG();
          }
          if (v24 - v23 < v132)
          {
            if (__OFADD__(v132, v23)) {
              BUG();
            }
            if (v132 + v23 < v21) {
              Swift::Int v21 = v132 + v23;
            }
            if (v21 < v23) {
              BUG();
            }
            if (v24 != v21)
            {
              long long v56 = (void (*)(void (**)(void, void), uint64_t, uint64_t))v151[2];
              uint64_t v142 = v56;
              uint64_t v57 = v151[9];
              uint64_t v58 = v57 * (v24 - 1);
              uint64_t v150 = v57;
              uint64_t v59 = (char *)(v57 * v24);
              Swift::Int v146 = v21;
              do
              {
                char v141 = v59;
                uint64_t v147 = v58;
                uint64_t v155 = (char *)v24;
                while (1)
                {
                  Swift::String v143 = (char *)v23;
                  uint64_t v60 = *v47;
                  char v157 = v59;
                  uint64_t v61 = v142;
                  ((void (*)(void (**)(void, uint64_t), char *, uint64_t, void (*)(void (**)(void, void), uint64_t, uint64_t), uint64_t))v142)(v153, &v59[v60], v22, v56, v17);
                  uint64_t v149 = v58;
                  v61(v156, v58 + v60, v22);
                  uint64_t v62 = v22;
                  uint64_t v63 = v140;
                  AnnotatedFeature.feature.getter(v62);
                  Swift::String v64 = URL.path(percentEncoded:)(1);
                  uint64_t v154 = (char *)v64._countAndFlagsBits;
                  v148._uint64_t countAndFlagsBits = (uint64_t)v64._object;
                  v148._unsigned __int8 object = *(void **)(v134 + 8);
                  uint64_t v65 = v139;
                  ((void (*)(void, uint64_t))v148._object)(v63, v139);
                  AnnotatedFeature.feature.getter(v159);
                  Swift::String v66 = URL.path(percentEncoded:)(1);
                  uint64_t v67 = v66._countAndFlagsBits;
                  uint64_t v68 = v66._object;
                  ((void (*)(void, uint64_t))v148._object)(v63, v65);
                  LOBYTE(v65) = v148._countAndFlagsBits;
                  LOBYTE(v63) = specialized Sequence<>.lexicographicallyPrecedes<A>(_:)(v67, (uint64_t)v68, (uint64_t)v154, (void *)v148._countAndFlagsBits);
                  swift_bridgeObjectRelease(v65);
                  swift_bridgeObjectRelease((_BYTE)v68);
                  uint64_t v69 = (void (*)(void, uint64_t))v151[1];
                  uint64_t v70 = v159;
                  v69(v156, v159);
                  v69(v153, v70);
                  if ((v63 & 1) == 0) {
                    break;
                  }
                  uint64_t v71 = *v152;
                  if (!*v152) {
                    BUG();
                  }
                  uint64_t v72 = &v157[v71];
                  uint64_t v73 = v149;
                  uint64_t v74 = v149 + v71;
                  uint64_t v154 = (char *)v151[4];
                  ((void (*)(void (**)(void, uint64_t), char *, uint64_t))v154)(v133, v72, v159);
                  swift_arrayInitWithTakeFrontToBack(v72, v74, 1, v159);
                  uint64_t v22 = v159;
                  ((void (*)(uint64_t, void (**)(void, uint64_t), uint64_t))v154)(v74, v133, v159);
                  uint64_t v58 = v73 - v150;
                  uint64_t v59 = &v157[-v150];
                  uint64_t v23 = (uint64_t)(v143 + 1);
                  uint64_t v75 = v155;
                  uint64_t v47 = v152;
                  if (v155 == v143 + 1) {
                    goto LABEL_43;
                  }
                }
                uint64_t v47 = v152;
                uint64_t v22 = v159;
                uint64_t v75 = v155;
LABEL_43:
                Swift::Int v24 = (Swift::Int)(v75 + 1);
                uint64_t v58 = v150 + v147;
                uint64_t v59 = &v141[v150];
                uint64_t v23 = (uint64_t)v144;
              }
              while (v24 != v146);
              Swift::Int v24 = v146;
            }
          }
        }
        if (v24 < v23) {
          BUG();
        }
        uint64_t v155 = (char *)v24;
        if (!swift_isUniquelyReferenced_nonNull_native(v158)) {
          uint64_t v158 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v158 + 2) + 1, 1, v158);
        }
        unint64_t v76 = *((void *)v158 + 2);
        unint64_t v77 = v76 + 1;
        uint64_t v20 = v155;
        if (*((void *)v158 + 3) >> 1 <= v76)
        {
          uint64_t v118 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v158 + 3) >= 2uLL, v76 + 1, 1, v158);
          uint64_t v20 = v155;
          uint64_t v158 = v118;
        }
        uint64_t v78 = v158;
        *((void *)v158 + 2) = v77;
        uint64_t v79 = 16 * v76;
        *(void *)&v78[v79 + 32] = v23;
        unint64_t v19 = v78;
        *(void *)&v78[v79 + 40] = v20;
        if (v76) {
          break;
        }
        unint64_t v77 = 1;
LABEL_86:
        Swift::Int v21 = v152[1];
        if ((uint64_t)v20 >= v21) {
          goto LABEL_92;
        }
      }
      uint64_t v80 = v78 + 32;
      uint64_t v158 = v78;
      char v157 = v78 + 32;
      while (1)
      {
        unint64_t v81 = v77 - 1;
        if (v77 >= 4) {
          break;
        }
        if (v77 == 3)
        {
          uint64_t v82 = *((void *)v19 + 5);
          BOOL v83 = __OFSUB__(v82, *((void *)v19 + 4));
          uint64_t v84 = v82 - *((void *)v19 + 4);
          BOOL v85 = v83;
LABEL_60:
          if (v85) {
            BUG();
          }
          unint64_t v95 = v77 - 2;
          uint64_t v96 = 16 * (v77 - 2);
          uint64_t v97 = *(void *)&v80[v96 + 8];
          BOOL v83 = __OFSUB__(v97, *(void *)&v80[v96]);
          uint64_t v98 = v97 - *(void *)&v80[v96];
          BOOL v99 = v83;
          if (v83) {
            BUG();
          }
          uint64_t v100 = *(void *)&v80[16 * v81 + 8];
          BOOL v83 = __OFSUB__(v100, *(void *)&v80[16 * v81]);
          uint64_t v101 = v100 - *(void *)&v80[16 * v81];
          if (v83) {
            BUG();
          }
          uint64_t v17 = v101 + v98;
          if (__OFADD__(v101, v98)) {
            BUG();
          }
          if (v17 >= v84)
          {
            if (v84 >= v101) {
              unint64_t v95 = v77 - 1;
            }
            unint64_t v81 = v95;
            goto LABEL_77;
          }
          goto LABEL_69;
        }
        uint64_t v102 = *((void *)v19 + 5);
        BOOL v83 = __OFSUB__(v102, *((void *)v19 + 4));
        uint64_t v98 = v102 - *((void *)v19 + 4);
        BOOL v99 = v83;
LABEL_69:
        if (v99) {
          BUG();
        }
        uint64_t v103 = *(void *)&v80[16 * v81 + 8];
        BOOL v83 = __OFSUB__(v103, *(void *)&v80[16 * v81]);
        uint64_t v104 = v103 - *(void *)&v80[16 * v81];
        if (v83) {
          BUG();
        }
        if (v104 < v98) {
          goto LABEL_86;
        }
LABEL_77:
        if (v81 - 1 >= v77) {
          BUG();
        }
        uint64_t v107 = *v152;
        if (!*v152) {
          BUG();
        }
        uint64_t v108 = 16 * (v81 - 1);
        uint64_t v109 = *(void *)&v80[v108];
        uint64_t v154 = (char *)v81;
        uint64_t v110 = &v80[16 * v81];
        uint64_t v111 = *((void *)v110 + 1);
        uint64_t v112 = v145;
        specialized _merge<A>(low:mid:high:buffer:by:)(v107 + v109 * v151[9], v107 + v151[9] * *(void *)v110, v107 + v111 * v151[9], v135);
        uint64_t v145 = v112;
        if (v112) {
          goto LABEL_104;
        }
        if (v111 < v109) {
          BUG();
        }
        uint64_t v113 = v158;
        uint64_t v114 = (void (*)(void, void, void))v154;
        if ((unint64_t)v154 > *((void *)v158 + 2)) {
          BUG();
        }
        uint64_t v115 = &v157[v108];
        *(void *)uint64_t v115 = v109;
        *((void *)v115 + 1) = v111;
        unint64_t v116 = *((void *)v113 + 2);
        if ((unint64_t)v114 >= v116) {
          BUG();
        }
        unint64_t v19 = v113;
        unint64_t v77 = v116 - 1;
        memmove(v110, v110 + 16, 16 * (v116 - 1 - (void)v114));
        uint64_t v80 = v157;
        *((void *)v19 + 2) = v116 - 1;
        BOOL v117 = v116 <= 2;
        uint64_t v22 = v159;
        uint64_t v20 = v155;
        if (v117) {
          goto LABEL_86;
        }
      }
      uint64_t v86 = 16 * v77;
      uint64_t v87 = *(void *)&v80[16 * v77 - 56];
      BOOL v83 = __OFSUB__(v87, *(void *)&v80[16 * v77 - 64]);
      uint64_t v88 = v87 - *(void *)&v80[16 * v77 - 64];
      if (v83) {
        BUG();
      }
      uint64_t v89 = *(void *)&v80[v86 - 40];
      BOOL v83 = __OFSUB__(v89, *(void *)&v80[v86 - 48]);
      uint64_t v84 = v89 - *(void *)&v80[v86 - 48];
      BOOL v85 = v83;
      if (v83) {
        BUG();
      }
      unint64_t v90 = v77 - 2;
      uint64_t v91 = 16 * (v77 - 2);
      uint64_t v92 = *(void *)&v80[v91 + 8];
      BOOL v83 = __OFSUB__(v92, *(void *)&v80[v91]);
      uint64_t v93 = v92 - *(void *)&v80[v91];
      if (v83) {
        BUG();
      }
      BOOL v83 = __OFADD__(v84, v93);
      uint64_t v94 = v84 + v93;
      if (v83) {
        BUG();
      }
      if (v94 >= v88)
      {
        uint64_t v105 = *(void *)&v80[16 * v81 + 8];
        BOOL v83 = __OFSUB__(v105, *(void *)&v80[16 * v81]);
        uint64_t v106 = v105 - *(void *)&v80[16 * v81];
        if (v83) {
          BUG();
        }
        if (v84 >= v106) {
          unint64_t v90 = v77 - 1;
        }
        unint64_t v81 = v90;
        goto LABEL_77;
      }
      goto LABEL_60;
    }
    unint64_t v19 = (char *)_swiftEmptyArrayStorage;
    unint64_t v77 = _swiftEmptyArrayStorage[2];
LABEL_92:
    uint64_t v158 = v19;
    if (v77 < 2)
    {
LABEL_106:
      swift_bridgeObjectRelease((_BYTE)v158);
      if (v137 < -1) {
        BUG();
      }
      char v130 = (char)v138;
      v138[2] = 0;
      return swift_bridgeObjectRelease(v130);
    }
    else
    {
      uint64_t v119 = (char *)*v152;
      char v157 = (char *)*v152;
      while (1)
      {
        unint64_t v120 = v77 - 2;
        if (v77 < 2) {
          BUG();
        }
        if (!v119) {
          BUG();
        }
        uint64_t v121 = 16 * v120;
        uint64_t v153 = (void (**)(void, uint64_t))(v77 - 1);
        uint64_t v122 = 16 * (v77 - 1);
        char v123 = *(void (***)(void, uint64_t))&v158[v122 + 40];
        uint64_t v124 = v151[9];
        uint64_t v159 = *(void *)&v158[16 * v120 + 32];
        unint64_t v125 = (unint64_t)&v119[v124 * *(void *)&v158[v122 + 32]];
        long long v156 = v123;
        uint64_t v126 = v145;
        specialized _merge<A>(low:mid:high:buffer:by:)((unint64_t)&v119[v159 * v124], v125, (unint64_t)&v119[(void)v123 * v124], v135);
        uint64_t v145 = v126;
        if (v126) {
          break;
        }
        if ((uint64_t)v156 < v159) {
          BUG();
        }
        if (!swift_isUniquelyReferenced_nonNull_native(v158)) {
          uint64_t v158 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v158);
        }
        uint64_t v127 = v158;
        if (v120 >= *((void *)v158 + 2)) {
          BUG();
        }
        *(void *)&v158[v121 + 32] = v159;
        *(void *)&v127[v121 + 40] = v156;
        unint64_t v128 = *((void *)v127 + 2);
        if (v77 > v128) {
          BUG();
        }
        uint64_t v158 = v127;
        memmove(&v127[v122 + 32], &v127[16 * v77 + 32], 16 * (v128 - 1 - (void)v153));
        *((void *)v158 + 2) = v128 - 1;
        unint64_t v77 = v128 - 1;
        uint64_t v119 = v157;
        if (v128 <= 2) {
          goto LABEL_106;
        }
      }
LABEL_104:
      swift_bridgeObjectRelease((_BYTE)v158);
      if (v137 < -1) {
        BUG();
      }
      char v129 = (char)v138;
      v138[2] = 0;
      return swift_bridgeObjectRelease(v129);
    }
  }
  return result;
}

{
  uint64_t v1;
  int64_t v2;
  void *v3;
  void *v4;
  uint64_t v5;
  int64_t v6;
  void *v7;
  void *v8;
  void *v9;
  void *v10;
  void *v11;
  void *v12;
  void *v13;
  void *v14;
  void *v15;
  void *v16;
  void *v17;
  void *v18;
  void *v19;
  void *v20;
  void *v21;
  void *v22;
  Swift::Int v23;
  Swift::Int result;
  unint64_t v25;
  char *v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  unint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t *v35;
  void (*v36)(uint64_t *, uint64_t);
  uint64_t v37;
  Swift::String v38;
  uint64_t countAndFlagsBits;
  uint64_t *v40;
  void *object;
  char v42;
  uint64_t v43;
  void (*v44)(uint64_t *, uint64_t);
  uint64_t v45;
  unint64_t v46;
  char *v47;
  void (*v48)(uint64_t *, char *, uint64_t);
  uint64_t *v49;
  uint64_t v50;
  void (*v51)(uint64_t *, uint64_t);
  Swift::String v52;
  void *v53;
  uint64_t v54;
  void *v55;
  char v56;
  unsigned __int8 v57;
  uint64_t v58;
  void (*v59)(uint64_t *, uint64_t);
  uint64_t v60;
  uint64_t v61;
  uint64_t v62;
  unint64_t v63;
  uint64_t v64;
  uint64_t v65;
  void *v66;
  uint64_t v67;
  char *v68;
  uint64_t v69;
  uint64_t v70;
  char *v71;
  unint64_t v72;
  uint64_t v73;
  uint64_t v74;
  char *v75;
  uint64_t v76;
  uint64_t v77;
  void (*v78)(uint64_t *, uint64_t, uint64_t);
  uint64_t *v79;
  Swift::String v80;
  uint64_t v81;
  Swift::String v82;
  uint64_t v83;
  void *v84;
  uint64_t v85;
  uint64_t v86;
  uint64_t v87;
  uint64_t v88;
  uint64_t v89;
  char v90;
  void (*v91)(uint64_t *, uint64_t);
  uint64_t v92;
  uint64_t v93;
  char *v94;
  uint64_t v95;
  uint64_t v96;
  uint64_t v97;
  void (*v98)(uint64_t *, uint64_t);
  char isUniquelyReferenced_nonNull_native;
  unint64_t v100;
  unint64_t v101;
  uint64_t v102;
  char *v103;
  unint64_t v104;
  uint64_t v105;
  BOOL v106;
  uint64_t v107;
  BOOL v108;
  uint64_t v109;
  uint64_t v110;
  uint64_t v111;
  uint64_t v112;
  unint64_t v113;
  uint64_t v114;
  uint64_t v115;
  uint64_t v116;
  uint64_t v117;
  unint64_t v118;
  uint64_t v119;
  uint64_t v120;
  uint64_t v121;
  BOOL v122;
  uint64_t v123;
  uint64_t v124;
  uint64_t v125;
  uint64_t v126;
  uint64_t v127;
  uint64_t v128;
  uint64_t v129;
  uint64_t v130;
  uint64_t v131;
  uint64_t v132;
  char *v133;
  uint64_t v134;
  uint64_t v135;
  char *v136;
  unint64_t v137;
  char *v138;
  unint64_t v139;
  uint64_t *v140;
  unint64_t v141;
  char *v142;
  uint64_t v143;
  uint64_t v144;
  uint64_t v145;
  uint64_t *v146;
  uint64_t v147;
  unint64_t v148;
  unint64_t v149;
  uint64_t v150;
  char *v151;
  unint64_t v152;
  char *v153;
  char *v154;
  char v155;
  char v156;
  uint64_t v157;
  void (*v158)(uint64_t *, uint64_t);
  Swift::Int v159;
  uint64_t *v160;
  uint64_t v161;
  unint64_t v162;
  uint64_t *v163;
  uint64_t *v164;
  uint64_t v165;
  void *v166;
  uint64_t *v167;
  uint64_t v168;
  uint64_t v169;
  uint64_t *v170;
  uint64_t *v171;
  char *v172;
  uint64_t v173;
  uint64_t *v174;
  uint64_t *v175;
  unint64_t v176;
  void (*v177)(uint64_t *, uint64_t, uint64_t);
  uint64_t v178;
  uint64_t v179;
  uint64_t v180;
  uint64_t *v181;
  Swift::String v182;
  uint64_t v183;
  uint64_t v184;
  void *v185;
  uint64_t *v186;
  unint64_t v187;
  uint64_t v188;
  char *v189;
  char *v190;
  uint64_t v191;

  v169 = type metadata accessor for URL(0);
  uint64_t v161 = *(void *)(v169 - 8);
  int64_t v2 = *(void *)(v161 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  v170 = &v157;
  int64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v185 = *(void **)(v5 - 8);
  uint64_t v6 = v185[8];
  uint64_t v7 = alloca(v6);
  id v8 = alloca(v6);
  uint64_t v164 = &v157;
  uint64_t v9 = alloca(v6);
  unint64_t v10 = alloca(v6);
  v160 = &v157;
  id v11 = alloca(v6);
  id v12 = alloca(v6);
  uint64_t v167 = &v157;
  uint64_t v13 = alloca(v6);
  Swift::Int v14 = alloca(v6);
  v181 = &v157;
  uint64_t v15 = alloca(v6);
  Swift::Int v16 = alloca(v6);
  uint64_t v171 = &v157;
  uint64_t v17 = alloca(v6);
  unint64_t v18 = alloca(v6);
  int64_t v163 = &v157;
  unint64_t v19 = alloca(v6);
  uint64_t v20 = alloca(v6);
  uint64_t v174 = &v157;
  Swift::Int v21 = alloca(v6);
  uint64_t v22 = alloca(v6);
  uint64_t v175 = &v157;
  uint64_t v186 = a1;
  uint64_t v23 = a1[1];
  Swift::Int result = _minimumMergeRunLength(_:)(v23);
  if (result >= v23)
  {
    if (v23 < 0) {
      BUG();
    }
    if (v23) {
      return specialized MutableCollection<>._insertionSort(within:sortedEnd:by:)(0, v23, 1uLL, v186);
    }
  }
  else
  {
    uint64_t v159 = result;
    unsigned int v180 = v1;
    v166 = specialized static Array._allocateUninitialized(_:)(v23 / 2);
    unsigned __int8 v162 = v25;
    uint64_t v165 = v23;
    if (v23 > 0)
    {
      uint64_t v191 = v5;
      uint64_t v26 = (char *)_swiftEmptyArrayStorage;
      uint64_t v27 = 0;
      Swift::String v28 = v23;
      while (1)
      {
        uint64_t v29 = v27;
        uint64_t v30 = v27 + 1;
        unsigned __int8 v189 = v26;
        unsigned int v179 = v27;
        if (v27 + 1 >= v28)
        {
          uint64_t v43 = v191;
        }
        else
        {
          v184 = v28;
          uint64_t v31 = *v186;
          int v177 = (void (*)(uint64_t *, uint64_t, uint64_t))v185[2];
          uint64_t v32 = v185[9];
          uint64_t v33 = v31 + v32 * v30;
          Swift::String v190 = (char *)v33;
          uint64_t v34 = v191;
          v177(v175, v33, v191);
          Swift::String v187 = v32;
          uint64_t v173 = v31;
          Swift::String v183 = v29 * v32;
          v177(v174, v31 + v29 * v32, v34);
          uint64_t v35 = v170;
          AnnotatedFeature.feature.getter(v34);
          uint64_t v182 = URL.path(percentEncoded:)(1);
          uint64_t v36 = *(void (**)(uint64_t *, uint64_t))(v161 + 8);
          uint64_t v37 = v169;
          v36(v35, v169);
          AnnotatedFeature.feature.getter(v191);
          uint64_t v38 = URL.path(percentEncoded:)(1);
          uint64_t countAndFlagsBits = v38._countAndFlagsBits;
          uint64_t v40 = v35;
          unsigned __int8 object = v38._object;
          uint64_t v172 = (char *)v36;
          v36(v40, v37);
          uint64_t v42 = (char)v182._object;
          if (v182 == __PAIR128__((unint64_t)object, countAndFlagsBits))
          {
            LODWORD(v178) = 0;
            LOBYTE(object) = v182._object;
          }
          else
          {
            LODWORD(v178) = _stringCompareWithSmolCheck(_:_:expecting:)(v182._countAndFlagsBits, v182._object, countAndFlagsBits, object, 1);
          }
          Swift::String v28 = v184;
          swift_bridgeObjectRelease(v42);
          swift_bridgeObjectRelease((_BYTE)object);
          char v44 = (void (*)(uint64_t *, uint64_t))v185[1];
          uint64_t v43 = v191;
          v44(v174, v191);
          uint64_t v158 = v44;
          v44(v175, v43);
          uint64_t v29 = v179;
          uint64_t v30 = v179 + 2;
          if (v179 + 2 < v28)
          {
            uint64_t v46 = v173 + v30 * v187;
            uint64_t v47 = v190;
            while (1)
            {
              char v188 = v30;
              uint64_t v168 = v46;
              uint64_t v48 = (void (*)(uint64_t *, char *, uint64_t))v177;
              v177(v163, v46, v43);
              Swift::String v190 = v47;
              v48(v171, v47, v43);
              uint64_t v49 = v170;
              AnnotatedFeature.feature.getter(v43);
              uint64_t v182 = URL.path(percentEncoded:)(1);
              long long v50 = v169;
              uint64_t v51 = (void (*)(uint64_t *, uint64_t))v172;
              ((void (*)(uint64_t *, uint64_t))v172)(v49, v169);
              AnnotatedFeature.feature.getter(v191);
              unint64_t v52 = URL.path(percentEncoded:)(1);
              uint64_t v176 = v52._countAndFlagsBits;
              uint64_t v53 = v52._object;
              uint64_t v54 = v50;
              uint64_t v55 = v182._object;
              v51(v49, v54);
              long long v56 = (char)v53;
              if (__PAIR128__((unint64_t)v55, v182._countAndFlagsBits) == __PAIR128__((unint64_t)v53, v176))
              {
                uint64_t v57 = 0;
                long long v56 = (char)v55;
              }
              else
              {
                uint64_t v57 = _stringCompareWithSmolCheck(_:_:expecting:)(v182._countAndFlagsBits, v55, v176, v53, 1);
              }
              swift_bridgeObjectRelease((_BYTE)v55);
              swift_bridgeObjectRelease(v56);
              uint64_t v58 = v191;
              uint64_t v59 = v158;
              v158(v171, v191);
              v59(v163, v58);
              if ((v178 ^ v57)) {
                break;
              }
              uint64_t v30 = v188 + 1;
              uint64_t v47 = &v190[v187];
              uint64_t v46 = v187 + v168;
              Swift::String v28 = v184;
              uint64_t v43 = v191;
              if (v188 + 1 >= v184)
              {
                uint64_t v30 = v184;
                uint64_t v29 = v179;
                goto LABEL_18;
              }
            }
            uint64_t v43 = v191;
            uint64_t v30 = v188;
            uint64_t v29 = v179;
            Swift::String v28 = v184;
          }
LABEL_18:
          uint64_t v26 = v189;
          uint64_t v60 = v183;
          if (v178)
          {
            if (v30 < v29) {
              BUG();
            }
            if (v30 > v29)
            {
              uint64_t v61 = v29;
              uint64_t v62 = v187 * (v30 - 1);
              char v188 = v30;
              uint64_t v63 = v187 * v30;
              Swift::String v64 = 0;
              while (1)
              {
                uint64_t v65 = v188 + v64 - 1;
                if (v61 != v65) {
                  break;
                }
LABEL_31:
                ++v61;
                --v64;
                v62 -= v187;
                v63 -= v187;
                v60 += v187;
                if (v61 >= v65)
                {
                  uint64_t v43 = v191;
                  uint64_t v30 = v188;
                  uint64_t v29 = v179;
                  Swift::String v28 = v184;
                  goto LABEL_33;
                }
              }
              v182._uint64_t countAndFlagsBits = v188 + v64 - 1;
              if (!v173) {
                BUG();
              }
              uint64_t v176 = v173 + v60;
              Swift::String v190 = (char *)(v173 + v62);
              Swift::String v66 = (void *)v185[4];
              Swift::String v183 = v60;
              v182._unsigned __int8 object = v66;
              ((void (*)(uint64_t *, uint64_t, uint64_t, uint64_t, uint64_t, char *))v66)(v164, v173 + v60, v191, v173, v45, v26);
              if (v183 < v62 || v176 >= v63 + v173)
              {
                swift_arrayInitWithTakeFrontToBack(v176, v190, 1, v191);
LABEL_29:
                uint64_t v68 = v190;
                uint64_t v67 = v191;
              }
              else
              {
                uint64_t v67 = v191;
                uint64_t v68 = v190;
                if (v183 != v62)
                {
                  swift_arrayInitWithTakeBackToFront(v176, v190, 1, v191);
                  goto LABEL_29;
                }
              }
              ((void (*)(char *, uint64_t *, uint64_t))v182._object)(v68, v164, v67);
              uint64_t v26 = v189;
              uint64_t v60 = v183;
              uint64_t v65 = v182._countAndFlagsBits;
              goto LABEL_31;
            }
          }
        }
LABEL_33:
        if (v30 < v28)
        {
          if (__OFSUB__(v30, v29)) {
            BUG();
          }
          if (v30 - v29 < v159)
          {
            if (__OFADD__(v159, v29)) {
              BUG();
            }
            if (v159 + v29 < v28) {
              Swift::String v28 = v159 + v29;
            }
            if (v28 < v29) {
              BUG();
            }
            if (v30 != v28)
            {
              int v177 = (void (*)(uint64_t *, uint64_t, uint64_t))v185[2];
              uint64_t v69 = v185[9];
              uint64_t v70 = v69 * (v30 - 1);
              Swift::String v183 = v69;
              uint64_t v71 = (char *)(v69 * v30);
              v184 = v28;
              do
              {
                uint64_t v72 = v29;
                uint64_t v172 = v71;
                unsigned int v178 = v70;
                uint64_t v73 = v70;
                char v188 = v30;
                while (1)
                {
                  uint64_t v176 = v72;
                  uint64_t v74 = *v186;
                  Swift::String v190 = v71;
                  uint64_t v75 = &v71[v74];
                  unint64_t v76 = v43;
                  unint64_t v77 = v43;
                  uint64_t v78 = v177;
                  v177(v181, (uint64_t)v75, v76);
                  uint64_t v168 = v73;
                  v78(v167, v73 + v74, v77);
                  uint64_t v79 = v170;
                  AnnotatedFeature.feature.getter(v77);
                  uint64_t v80 = URL.path(percentEncoded:)(1);
                  Swift::String v187 = v80._countAndFlagsBits;
                  v182._uint64_t countAndFlagsBits = (uint64_t)v80._object;
                  v182._unsigned __int8 object = *(void **)(v161 + 8);
                  unint64_t v81 = v169;
                  ((void (*)(uint64_t *, uint64_t))v182._object)(v79, v169);
                  AnnotatedFeature.feature.getter(v191);
                  uint64_t v82 = URL.path(percentEncoded:)(1);
                  BOOL v83 = v82._countAndFlagsBits;
                  uint64_t v84 = v82._object;
                  BOOL v85 = v81;
                  uint64_t v86 = v182._countAndFlagsBits;
                  ((void (*)(uint64_t *, uint64_t))v182._object)(v79, v85);
                  if (v187 == v83 && (void *)v86 == v84)
                  {
                    swift_bridgeObjectRelease_n(v86, 2, v87, v88, v89);
                    uint64_t v98 = (void (*)(uint64_t *, uint64_t))v185[1];
                    uint64_t v43 = v191;
                    v98(v167, v191);
                    v98(v181, v43);
                    uint64_t v97 = v188;
                    goto LABEL_51;
                  }
                  unint64_t v90 = _stringCompareWithSmolCheck(_:_:expecting:)(v187, v86, v83, v84, 1);
                  swift_bridgeObjectRelease(v86);
                  swift_bridgeObjectRelease((_BYTE)v84);
                  uint64_t v91 = (void (*)(uint64_t *, uint64_t))v185[1];
                  uint64_t v92 = v191;
                  v91(v167, v191);
                  v91(v181, v92);
                  if ((v90 & 1) == 0) {
                    break;
                  }
                  uint64_t v93 = *v186;
                  if (!*v186) {
                    BUG();
                  }
                  uint64_t v94 = &v190[v93];
                  unint64_t v95 = v168;
                  uint64_t v96 = v168 + v93;
                  Swift::String v187 = v185[4];
                  ((void (*)(uint64_t *, char *, uint64_t))v187)(v160, v94, v191);
                  swift_arrayInitWithTakeFrontToBack(v94, v96, 1, v191);
                  uint64_t v43 = v191;
                  ((void (*)(uint64_t, uint64_t *, uint64_t))v187)(v96, v160, v191);
                  uint64_t v73 = v95 - v183;
                  uint64_t v71 = &v190[-v183];
                  uint64_t v72 = v176 + 1;
                  uint64_t v97 = v188;
                  if (v188 == v176 + 1) {
                    goto LABEL_51;
                  }
                }
                uint64_t v97 = v188;
                uint64_t v43 = v191;
LABEL_51:
                uint64_t v30 = v97 + 1;
                uint64_t v70 = v183 + v178;
                uint64_t v71 = &v172[v183];
                uint64_t v29 = v179;
              }
              while (v30 != v184);
              uint64_t v30 = v184;
              uint64_t v26 = v189;
            }
          }
        }
        if (v30 < v29) {
          BUG();
        }
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v26);
        char v188 = v30;
        if (isUniquelyReferenced_nonNull_native) {
          uint64_t v26 = v189;
        }
        else {
          uint64_t v26 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v189 + 2) + 1, 1, v189);
        }
        uint64_t v100 = *((void *)v26 + 2);
        uint64_t v101 = v100 + 1;
        if (*((void *)v26 + 3) >> 1 <= v100) {
          uint64_t v26 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v26 + 3) >= 2uLL, v100 + 1, 1, v26);
        }
        *((void *)v26 + 2) = v101;
        uint64_t v102 = 16 * v100;
        *(void *)&v26[v102 + 32] = v29;
        *(void *)&v26[v102 + 40] = v188;
        if (v100) {
          break;
        }
        uint64_t v101 = 1;
LABEL_94:
        Swift::String v28 = v186[1];
        uint64_t v27 = v188;
        if (v188 >= v28) {
          goto LABEL_101;
        }
      }
      uint64_t v103 = v26 + 32;
      unsigned __int8 v189 = v26;
      Swift::String v190 = v26 + 32;
      while (1)
      {
        uint64_t v104 = v101 - 1;
        if (v101 >= 4) {
          break;
        }
        if (v101 == 3)
        {
          uint64_t v105 = *((void *)v26 + 5);
          uint64_t v106 = __OFSUB__(v105, *((void *)v26 + 4));
          uint64_t v107 = v105 - *((void *)v26 + 4);
          uint64_t v108 = v106;
LABEL_68:
          if (v108) {
            BUG();
          }
          uint64_t v118 = v101 - 2;
          uint64_t v119 = 16 * (v101 - 2);
          unint64_t v120 = *(void *)&v103[v119 + 8];
          uint64_t v106 = __OFSUB__(v120, *(void *)&v103[v119]);
          uint64_t v121 = v120 - *(void *)&v103[v119];
          uint64_t v122 = v106;
          if (v106) {
            BUG();
          }
          char v123 = *(void *)&v103[16 * v104 + 8];
          uint64_t v106 = __OFSUB__(v123, *(void *)&v103[16 * v104]);
          uint64_t v124 = v123 - *(void *)&v103[16 * v104];
          if (v106) {
            BUG();
          }
          if (__OFADD__(v124, v121)) {
            BUG();
          }
          if (v124 + v121 >= v107)
          {
            if (v107 >= v124) {
              uint64_t v118 = v101 - 1;
            }
            uint64_t v104 = v118;
            goto LABEL_85;
          }
          goto LABEL_77;
        }
        unint64_t v125 = *((void *)v26 + 5);
        uint64_t v106 = __OFSUB__(v125, *((void *)v26 + 4));
        uint64_t v121 = v125 - *((void *)v26 + 4);
        uint64_t v122 = v106;
LABEL_77:
        if (v122) {
          BUG();
        }
        uint64_t v126 = *(void *)&v103[16 * v104 + 8];
        uint64_t v106 = __OFSUB__(v126, *(void *)&v103[16 * v104]);
        uint64_t v127 = v126 - *(void *)&v103[16 * v104];
        if (v106) {
          BUG();
        }
        if (v127 < v121) {
          goto LABEL_94;
        }
LABEL_85:
        if (v104 - 1 >= v101) {
          BUG();
        }
        char v130 = *v186;
        if (!*v186) {
          BUG();
        }
        uint64_t v131 = 16 * (v104 - 1);
        Swift::Int v132 = *(void *)&v103[v131];
        Swift::String v187 = v104;
        uint64_t v133 = &v103[16 * v104];
        uint64_t v134 = *((void *)v133 + 1);
        unint64_t v135 = v180;
        specialized _merge<A>(low:mid:high:buffer:by:)(v130 + v132 * v185[9], v130 + v185[9] * *(void *)v133, v130 + v134 * v185[9], v162);
        unsigned int v180 = v135;
        if (v135) {
          goto LABEL_114;
        }
        uint64_t v136 = v189;
        if (v134 < v132) {
          BUG();
        }
        uint64_t v137 = v187;
        if (v187 > *((void *)v189 + 2)) {
          BUG();
        }
        Swift::String v138 = &v190[v131];
        *(void *)Swift::String v138 = v132;
        *((void *)v138 + 1) = v134;
        uint64_t v139 = *((void *)v136 + 2);
        if (v137 >= v139) {
          BUG();
        }
        uint64_t v101 = v139 - 1;
        memmove(v133, v133 + 16, 16 * (v139 - 1 - v137));
        uint64_t v103 = v190;
        uint64_t v26 = v189;
        *((void *)v189 + 2) = v139 - 1;
        if (v139 <= 2) {
          goto LABEL_94;
        }
      }
      uint64_t v109 = 16 * v101;
      uint64_t v110 = *(void *)&v103[16 * v101 - 56];
      uint64_t v106 = __OFSUB__(v110, *(void *)&v103[16 * v101 - 64]);
      uint64_t v111 = v110 - *(void *)&v103[16 * v101 - 64];
      if (v106) {
        BUG();
      }
      uint64_t v112 = *(void *)&v103[v109 - 40];
      uint64_t v106 = __OFSUB__(v112, *(void *)&v103[v109 - 48]);
      uint64_t v107 = v112 - *(void *)&v103[v109 - 48];
      uint64_t v108 = v106;
      if (v106) {
        BUG();
      }
      uint64_t v113 = v101 - 2;
      uint64_t v114 = 16 * (v101 - 2);
      uint64_t v115 = *(void *)&v103[v114 + 8];
      uint64_t v106 = __OFSUB__(v115, *(void *)&v103[v114]);
      unint64_t v116 = v115 - *(void *)&v103[v114];
      if (v106) {
        BUG();
      }
      uint64_t v106 = __OFADD__(v107, v116);
      BOOL v117 = v107 + v116;
      if (v106) {
        BUG();
      }
      if (v117 >= v111)
      {
        unint64_t v128 = *(void *)&v103[16 * v104 + 8];
        uint64_t v106 = __OFSUB__(v128, *(void *)&v103[16 * v104]);
        char v129 = v128 - *(void *)&v103[16 * v104];
        if (v106) {
          BUG();
        }
        if (v107 >= v129) {
          uint64_t v113 = v101 - 1;
        }
        uint64_t v104 = v113;
        goto LABEL_85;
      }
      goto LABEL_68;
    }
    uint64_t v26 = (char *)_swiftEmptyArrayStorage;
    uint64_t v101 = _swiftEmptyArrayStorage[2];
LABEL_101:
    if (v101 < 2)
    {
LABEL_116:
      swift_bridgeObjectRelease((_BYTE)v26);
      if (v165 < -1) {
        BUG();
      }
      long long v156 = (char)v166;
      v166[2] = 0;
      return swift_bridgeObjectRelease(v156);
    }
    else
    {
      long long v140 = (uint64_t *)*v186;
      uint64_t v186 = (uint64_t *)*v186;
      while (1)
      {
        char v141 = v101 - 2;
        if (v101 < 2) {
          BUG();
        }
        if (!v140) {
          BUG();
        }
        uint64_t v142 = v26 + 32;
        Swift::String v143 = 16 * v141;
        Swift::String v190 = (char *)(v101 - 1);
        uint64_t v144 = 16 * (v101 - 1);
        uint64_t v145 = *(void *)&v26[16 * v141 + 32];
        unsigned __int8 v189 = v26;
        Swift::Int v146 = *(uint64_t **)&v26[v144 + 40];
        uint64_t v147 = v185[9];
        uint64_t v191 = v145;
        Swift::String v148 = (unint64_t)v140 + v145 * v147;
        uint64_t v149 = (unint64_t)v140 + v147 * *(void *)&v142[v144];
        v181 = v146;
        uint64_t v150 = v180;
        specialized _merge<A>(low:mid:high:buffer:by:)(v148, v149, (unint64_t)v140 + (void)v146 * v147, v162);
        unsigned int v180 = v150;
        if (v150) {
          break;
        }
        if ((uint64_t)v181 < v191) {
          BUG();
        }
        if (swift_isUniquelyReferenced_nonNull_native(v189)) {
          long long v151 = v189;
        }
        else {
          long long v151 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v189);
        }
        if (v141 >= *((void *)v151 + 2)) {
          BUG();
        }
        *(void *)&v151[v143 + 32] = v191;
        *(void *)&v151[v143 + 40] = v181;
        int v152 = *((void *)v151 + 2);
        if (v101 > v152) {
          BUG();
        }
        uint64_t v153 = &v151[v144 + 32];
        uint64_t v154 = v151;
        memmove(v153, &v151[16 * v101 + 32], 16 * (v152 - 1 - (void)v190));
        uint64_t v26 = v154;
        *((void *)v154 + 2) = v152 - 1;
        uint64_t v101 = v152 - 1;
        long long v140 = v186;
        if (v152 <= 2) {
          goto LABEL_116;
        }
      }
LABEL_114:
      swift_bridgeObjectRelease((_BYTE)v189);
      if (v165 < -1) {
        BUG();
      }
      uint64_t v155 = (char)v166;
      v166[2] = 0;
      return swift_bridgeObjectRelease(v155);
    }
  }
  return result;
}

unint64_t specialized MutableCollection<>._insertionSort(within:sortedEnd:by:)(uint64_t a1, uint64_t a2, unint64_t a3, uint64_t *a4)
{
  long long v50 = a4;
  uint64_t v46 = a1;
  uint64_t v40 = type metadata accessor for URL(0);
  uint64_t v41 = *(void *)(v40 - 8);
  int64_t v5 = *(void *)(v41 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v42 = &v36;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  long long v56 = *(void **)(v8 - 8);
  int64_t v9 = v56[8];
  unint64_t v10 = alloca(v9);
  id v11 = alloca(v9);
  uint64_t v51 = &v36;
  id v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v53 = &v36;
  Swift::Int v14 = alloca(v9);
  unint64_t result = (v9 + 15) & 0xFFFFFFFFFFFFFFF0;
  Swift::Int v16 = alloca(v9);
  uint64_t v54 = &v36;
  unint64_t v57 = a3;
  uint64_t v47 = a2;
  if (a3 != a2)
  {
    uint64_t v43 = (void (*)(uint64_t *, uint64_t, uint64_t))v56[2];
    uint64_t v17 = v56[9];
    uint64_t v18 = v17 * (v57 - 1);
    uint64_t v52 = v17;
    unint64_t v19 = v57 * v17;
    uint64_t v58 = v8;
    do
    {
      uint64_t v49 = v46;
      unint64_t v45 = v19;
      uint64_t v44 = v18;
      do
      {
        uint64_t v37 = v18;
        unint64_t v48 = v19;
        uint64_t v20 = *v50;
        Swift::Int v21 = v43;
        v43(v54, *v50 + v19, v8);
        v21(v53, v18 + v20, v8);
        uint64_t v22 = v42;
        AnnotatedFeature.feature.getter(v58);
        Swift::String v23 = URL.path(percentEncoded:)(1);
        uint64_t countAndFlagsBits = (void (*)(uint64_t *, uint64_t, uint64_t))v23._countAndFlagsBits;
        unsigned __int8 object = v23._object;
        Swift::Int v24 = *(void (**)(uint64_t *, uint64_t))(v41 + 8);
        uint64_t v25 = v40;
        v24(v22, v40);
        AnnotatedFeature.feature.getter(v58);
        Swift::String v26 = URL.path(percentEncoded:)(1);
        uint64_t v39 = v26._countAndFlagsBits;
        uint64_t v27 = v26._object;
        v24(v22, v25);
        LOBYTE(v25) = (_BYTE)object;
        LOBYTE(v22) = specialized Sequence<>.lexicographicallyPrecedes<A>(_:)(v39, (uint64_t)v27, (uint64_t)countAndFlagsBits, object);
        swift_bridgeObjectRelease(v25);
        char v28 = (char)v27;
        uint64_t v29 = v37;
        unint64_t v30 = v48;
        swift_bridgeObjectRelease(v28);
        uint64_t v31 = (void (*)(uint64_t *, uint64_t))v56[1];
        v31(v53, v58);
        v31(v54, v58);
        BOOL v32 = (v22 & 1) == 0;
        uint64_t v8 = v58;
        if (v32) {
          break;
        }
        uint64_t v33 = *v50;
        if (!*v50) {
          BUG();
        }
        uint64_t v34 = v33 + v30;
        uint64_t v35 = (uint64_t *)(v29 + v33);
        uint64_t countAndFlagsBits = (void (*)(uint64_t *, uint64_t, uint64_t))v56[4];
        countAndFlagsBits(v51, v34, v58);
        swift_arrayInitWithTakeFrontToBack(v34, v35, 1, v58);
        uint64_t v8 = v58;
        countAndFlagsBits(v35, (uint64_t)v51, v58);
        uint64_t v18 = v29 - v52;
        unint64_t v19 = v48 - v52;
        ++v49;
      }
      while (v57 != v49);
      unint64_t result = v57 + 1;
      uint64_t v18 = v52 + v44;
      unint64_t v19 = v52 + v45;
      unint64_t v57 = result;
    }
    while (result != v47);
  }
  return result;
}

{
  int64_t v5;
  void *v6;
  void *v7;
  uint64_t v8;
  int64_t v9;
  void *v10;
  void *v11;
  void *v12;
  void *v13;
  void *v14;
  unint64_t result;
  void *v16;
  uint64_t v17;
  uint64_t v18;
  unint64_t v19;
  uint64_t v20;
  void (*v21)(uint64_t *, uint64_t, uint64_t);
  uint64_t *v22;
  Swift::String v23;
  uint64_t v24;
  uint64_t v25;
  Swift::String v26;
  uint64_t v27;
  void *v28;
  uint64_t *v29;
  void *v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  char v34;
  void (*v35)(uint64_t *, uint64_t);
  uint64_t v36;
  uint64_t v37;
  uint64_t *v38;
  void (*v39)(uint64_t *, uint64_t);
  uint64_t v40;
  void *object;
  void (*v42)(uint64_t *, uint64_t);
  uint64_t v43;
  uint64_t v44;
  uint64_t *v45;
  void (*v46)(uint64_t *, uint64_t, uint64_t);
  uint64_t v47;
  unint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t *v52;
  uint64_t *v53;
  uint64_t v54;
  uint64_t v55;
  uint64_t v56;
  uint64_t *v57;
  void (*countAndFlagsBits)(uint64_t *, uint64_t, uint64_t);
  unint64_t v59;
  uint64_t *v60;
  void *v61;
  unint64_t v62;

  uint64_t v52 = a4;
  uint64_t v49 = a1;
  uint64_t v43 = type metadata accessor for URL(0);
  uint64_t v44 = *(void *)(v43 - 8);
  int64_t v5 = *(void *)(v44 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  unint64_t v45 = &v40;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v61 = *(void **)(v8 - 8);
  int64_t v9 = v61[8];
  unint64_t v10 = alloca(v9);
  id v11 = alloca(v9);
  uint64_t v53 = &v40;
  id v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v60 = &v40;
  Swift::Int v14 = alloca(v9);
  unint64_t result = (v9 + 15) & 0xFFFFFFFFFFFFFFF0;
  Swift::Int v16 = alloca(v9);
  unint64_t v57 = &v40;
  uint64_t v62 = a3;
  long long v50 = a2;
  if (a3 != a2)
  {
    uint64_t v46 = (void (*)(uint64_t *, uint64_t, uint64_t))v61[2];
    uint64_t v17 = v61[9];
    uint64_t v18 = v17 * (v62 - 1);
    uint64_t v54 = v17;
    unint64_t v19 = v62 * v17;
    uint64_t v55 = v8;
    do
    {
      uint64_t v51 = v49;
      unint64_t v48 = v19;
      uint64_t v59 = v19;
      uint64_t v47 = v18;
      long long v56 = v18;
      while (1)
      {
        uint64_t v20 = *v52;
        Swift::Int v21 = v46;
        v46(v57, *v52 + v59, v8);
        v21(v60, v56 + v20, v8);
        uint64_t v22 = v45;
        AnnotatedFeature.feature.getter(v8);
        Swift::String v23 = URL.path(percentEncoded:)(1);
        uint64_t countAndFlagsBits = (void (*)(uint64_t *, uint64_t, uint64_t))v23._countAndFlagsBits;
        unsigned __int8 object = v23._object;
        uint64_t v42 = *(void (**)(uint64_t *, uint64_t))(v44 + 8);
        Swift::Int v24 = v8;
        uint64_t v25 = v43;
        v42(v22, v43);
        AnnotatedFeature.feature.getter(v24);
        Swift::String v26 = URL.path(percentEncoded:)(1);
        uint64_t v27 = v26._countAndFlagsBits;
        char v28 = v26._object;
        uint64_t v29 = v22;
        unint64_t v30 = object;
        v42(v29, v25);
        if (countAndFlagsBits == (void (*)(uint64_t *, uint64_t, uint64_t))v27 && v30 == v28) {
          break;
        }
        uint64_t v34 = _stringCompareWithSmolCheck(_:_:expecting:)(countAndFlagsBits, v30, v27, v28, 1);
        swift_bridgeObjectRelease((_BYTE)v30);
        swift_bridgeObjectRelease((_BYTE)v28);
        uint64_t v35 = (void (*)(uint64_t *, uint64_t))v61[1];
        uint64_t v8 = v55;
        v35(v60, v55);
        v35(v57, v8);
        if (v34)
        {
          uint64_t v36 = *v52;
          if (!*v52) {
            BUG();
          }
          uint64_t v37 = v36 + v59;
          uint64_t v38 = (uint64_t *)(v56 + v36);
          uint64_t countAndFlagsBits = (void (*)(uint64_t *, uint64_t, uint64_t))v61[4];
          countAndFlagsBits(v53, v37, v8);
          swift_arrayInitWithTakeFrontToBack(v37, v38, 1, v8);
          countAndFlagsBits(v38, (uint64_t)v53, v8);
          v56 -= v54;
          v59 -= v54;
          if (v62 != ++v51) {
            continue;
          }
        }
        goto LABEL_11;
      }
      swift_bridgeObjectRelease_n(v30, 2, v31, v32, v33);
      uint64_t v39 = (void (*)(uint64_t *, uint64_t))v61[1];
      uint64_t v8 = v55;
      v39(v60, v55);
      v39(v57, v8);
LABEL_11:
      unint64_t result = v62 + 1;
      uint64_t v18 = v54 + v47;
      unint64_t v19 = v54 + v48;
      uint64_t v62 = result;
    }
    while (result != v50);
  }
  return result;
}

char specialized _merge<A>(low:mid:high:buffer:by:)(unint64_t a1, unint64_t a2, unint64_t a3, unint64_t a4)
{
  unint64_t v76 = a4;
  uint64_t v62 = type metadata accessor for URL(0);
  uint64_t v63 = *(void *)(v62 - 8);
  int64_t v5 = *(void *)(v63 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  Swift::String v64 = &v59;
  uint64_t v79 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v8 = *(void *)(v79 - 8);
  int64_t v9 = *(void *)(v8 + 64);
  unint64_t v10 = alloca(v9);
  id v11 = alloca(v9);
  uint64_t v72 = &v59;
  id v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v73 = &v59;
  uint64_t v69 = v8;
  uint64_t v14 = *(void *)(v8 + 72);
  if (!v14) {
    BUG();
  }
  if (a2 - a1 == 0x8000000000000000 && v14 == -1) {
    BUG();
  }
  int64_t v15 = a3 - a2;
  if (a3 - a2 == 0x8000000000000000 && v14 == -1) {
    BUG();
  }
  unint64_t v77 = a3;
  uint64_t v16 = (uint64_t)(a2 - a1) / v14;
  uint64_t v75 = v14;
  unint64_t v80 = a1;
  if (v16 >= v15 / v14)
  {
    uint64_t v34 = v15 / v14;
    unint64_t v33 = a2;
    unint64_t v35 = v76;
    specialized UnsafeMutablePointer.moveInitialize(from:count:)(a2, v15 / v14, v76);
    uint64_t v36 = v14 * v34;
    unint64_t v19 = v35 + v36;
    if (v36 <= 0 || v80 >= a2)
    {
      unint64_t v17 = v76;
      goto LABEL_45;
    }
    uint64_t v60 = -v14;
    uint64_t v61 = *(void (**)(uint64_t *, unint64_t, uint64_t))(v69 + 16);
    uint64_t v37 = (char *)v77;
    while (1)
    {
      unint64_t v78 = v19;
      unint64_t v77 = (unint64_t)v37;
      uint64_t v38 = v60;
      uint64_t v70 = &v37[v60];
      unint64_t v74 = v33;
      unint64_t v68 = v19 + v60;
      uint64_t v39 = v79;
      uint64_t v40 = v61;
      v61(v73, v19 + v60, v79);
      unint64_t v71 = v33 + v38;
      v40(v72, v33 + v38, v39);
      uint64_t v41 = v64;
      AnnotatedFeature.feature.getter(v39);
      Swift::String v65 = URL.path(percentEncoded:)(1);
      Swift::String v66 = *(void (**)(uint64_t *, uint64_t))(v63 + 8);
      uint64_t v42 = v62;
      v66(v41, v62);
      uint64_t v43 = v39;
      uint64_t v44 = v72;
      AnnotatedFeature.feature.getter(v43);
      Swift::String v45 = URL.path(percentEncoded:)(1);
      uint64_t countAndFlagsBits = v45._countAndFlagsBits;
      unsigned __int8 object = v45._object;
      v66(v41, v42);
      LOBYTE(v42) = v65._object;
      LOBYTE(v41) = specialized Sequence<>.lexicographicallyPrecedes<A>(_:)(countAndFlagsBits, (uint64_t)object, v65._countAndFlagsBits, v65._object);
      swift_bridgeObjectRelease(v42);
      swift_bridgeObjectRelease((_BYTE)object);
      uint64_t v47 = *(void (**)(uint64_t *, uint64_t))(v69 + 8);
      unint64_t v48 = v44;
      uint64_t v49 = v79;
      v47(v48, v79);
      v47(v73, v49);
      if ((v41 & 1) == 0)
      {
        unint64_t v52 = v74;
        unint64_t v17 = v76;
        uint64_t v37 = v70;
        if (v77 < v78 || (unint64_t)v70 >= v78)
        {
          unint64_t v56 = v68;
          swift_arrayInitWithTakeFrontToBack(v70, v68, 1, v79);
          unint64_t v51 = v52;
          unint64_t v19 = v56;
          uint64_t v14 = v75;
        }
        else
        {
          uint64_t v14 = v75;
          if (v77 == v78)
          {
            unint64_t v51 = v74;
            unint64_t v19 = v68;
          }
          else
          {
            unint64_t v53 = v68;
            swift_arrayInitWithTakeBackToFront(v70, v68, 1, v79);
            unint64_t v51 = v74;
            unint64_t v19 = v53;
          }
        }
        unint64_t v55 = v80;
        goto LABEL_40;
      }
      unint64_t v50 = v78;
      unint64_t v17 = v76;
      uint64_t v37 = v70;
      if (v77 < v74 || (unint64_t)v70 >= v74) {
        break;
      }
      uint64_t v14 = v75;
      if (v77 != v74)
      {
        swift_arrayInitWithTakeBackToFront(v70, v71, 1, v79);
        unint64_t v51 = v71;
LABEL_35:
        unint64_t v55 = v80;
        unint64_t v19 = v50;
        goto LABEL_40;
      }
      unint64_t v55 = v80;
      unint64_t v19 = v78;
      unint64_t v51 = v71;
LABEL_40:
      if (v19 > v17)
      {
        unint64_t v33 = v51;
        if (v51 > v55) {
          continue;
        }
      }
      unint64_t v33 = v51;
      goto LABEL_45;
    }
    unint64_t v54 = v71;
    swift_arrayInitWithTakeFrontToBack(v70, v71, 1, v79);
    unint64_t v51 = v54;
    uint64_t v14 = v75;
    goto LABEL_35;
  }
  unint64_t v17 = v76;
  specialized UnsafeMutablePointer.moveInitialize(from:count:)(a1, v16, v76);
  uint64_t v18 = v14 * v16;
  unint64_t v19 = v17 + v18;
  if (v18 > 0 && a2 < v77)
  {
    uint64_t v70 = *(char **)(v69 + 16);
    unint64_t v78 = v17 + v18;
    do
    {
      unint64_t v74 = a2;
      unint64_t v20 = v17;
      unint64_t v76 = v17;
      uint64_t v21 = v79;
      uint64_t v22 = v70;
      ((void (*)(uint64_t *, unint64_t, uint64_t))v70)(v73, a2, v79);
      ((void (*)(uint64_t *, unint64_t, uint64_t))v22)(v72, v20, v21);
      Swift::String v23 = v64;
      AnnotatedFeature.feature.getter(v21);
      Swift::String v65 = URL.path(percentEncoded:)(1);
      Swift::String v66 = *(void (**)(uint64_t *, uint64_t))(v63 + 8);
      uint64_t v24 = v62;
      v66(v23, v62);
      AnnotatedFeature.feature.getter(v21);
      Swift::String v25 = URL.path(percentEncoded:)(1);
      uint64_t countAndFlagsBits = v25._countAndFlagsBits;
      Swift::String v26 = v25._object;
      v66(v23, v24);
      LOBYTE(v24) = v65._object;
      LOBYTE(v23) = specialized Sequence<>.lexicographicallyPrecedes<A>(_:)(countAndFlagsBits, (uint64_t)v26, v65._countAndFlagsBits, v65._object);
      swift_bridgeObjectRelease(v24);
      swift_bridgeObjectRelease((_BYTE)v26);
      uint64_t v27 = *(void (**)(uint64_t *, uint64_t))(v69 + 8);
      v27(v72, v21);
      v27(v73, v21);
      if (v23)
      {
        uint64_t v14 = v75;
        unint64_t v28 = v74;
        unint64_t v29 = v74 + v75;
        unint64_t v30 = v80;
        unint64_t v17 = v76;
        if (v80 < v74 || v80 >= v29) {
          goto LABEL_18;
        }
      }
      else
      {
        unint64_t v29 = v74;
        uint64_t v14 = v75;
        unint64_t v28 = v76;
        unint64_t v17 = v76 + v75;
        unint64_t v30 = v80;
        if (v80 < v76 || v80 >= v17)
        {
LABEL_18:
          swift_arrayInitWithTakeFrontToBack(v80, v28, 1, v79);
          unint64_t v30 = v80;
          unint64_t v31 = v77;
          goto LABEL_19;
        }
      }
      unint64_t v31 = v77;
      if (v30 != v28)
      {
        swift_arrayInitWithTakeBackToFront(v80, v28, 1, v79);
        unint64_t v30 = v80;
      }
LABEL_19:
      unint64_t v19 = v78;
      unint64_t v32 = v14 + v30;
      if (v17 >= v78)
      {
        unint64_t v33 = v32;
        goto LABEL_45;
      }
      unint64_t v80 = v32;
      a2 = v29;
    }
    while (v29 < v31);
  }
  unint64_t v33 = v80;
LABEL_45:
  int64_t v57 = v19 - v17;
  if (v14 == -1 && v57 == 0x8000000000000000) {
    BUG();
  }
  specialized UnsafeMutablePointer.moveInitialize(from:count:)(v17, v57 / v14, v33);
  return 1;
}

{
  unint64_t v6;
  int64_t v7;
  void *v8;
  void *v9;
  uint64_t v10;
  int64_t v11;
  void *v12;
  void *v13;
  void *v14;
  void *v15;
  void *v16;
  void *v17;
  void *v18;
  void *v19;
  int64_t v20;
  uint64_t v21;
  uint64_t v22;
  unint64_t v23;
  unint64_t v24;
  uint64_t v25;
  void (*v26)(uint64_t, unint64_t, uint64_t);
  uint64_t *v27;
  uint64_t v28;
  Swift::String v29;
  uint64_t countAndFlagsBits;
  void *object;
  uint64_t v32;
  void *v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  void (*v37)(uint64_t, uint64_t);
  uint64_t v38;
  char v39;
  char v40;
  void (*v41)(uint64_t, uint64_t);
  uint64_t v42;
  unint64_t v43;
  unint64_t v44;
  unint64_t v45;
  unint64_t v46;
  unint64_t v47;
  uint64_t v48;
  unint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  void (*v53)(uint64_t, unint64_t, uint64_t);
  unint64_t v54;
  uint64_t *v55;
  Swift::String v56;
  uint64_t v57;
  Swift::String v58;
  uint64_t v59;
  void (*v60)(uint64_t *, uint64_t);
  uint64_t v61;
  void (*v62)(uint64_t *, uint64_t);
  char v63;
  unint64_t v64;
  void (*v65)(uint64_t, uint64_t);
  unint64_t v66;
  uint64_t v67;
  BOOL v68;
  unint64_t v69;
  unint64_t v70;
  char *v71;
  uint64_t v72;
  int64_t v73;
  uint64_t v75;
  void (*v76)(uint64_t, unint64_t, uint64_t);
  uint64_t v77;
  uint64_t v78;
  uint64_t *v79;
  unint64_t v80;
  void (*v81)(uint64_t *, uint64_t);
  void (*v82)(uint64_t, unint64_t, uint64_t);
  char *v83;
  unint64_t v84;
  unint64_t v85;
  Swift::String v86;
  uint64_t v87;
  uint64_t *v88;
  uint64_t v89;
  unint64_t v90;
  unint64_t v91;
  unint64_t v92;
  uint64_t v93;
  uint64_t v94;

  uint64_t v6 = a1;
  unint64_t v77 = type metadata accessor for URL(0);
  unint64_t v78 = *(void *)(v77 - 8);
  uint64_t v7 = *(void *)(v78 + 64);
  uint64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  uint64_t v79 = &v75;
  uint64_t v93 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  unint64_t v10 = *(void *)(v93 - 8);
  id v11 = *(void *)(v10 + 64);
  id v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  v86._uint64_t countAndFlagsBits = (uint64_t)&v75;
  uint64_t v14 = alloca(v11);
  int64_t v15 = alloca(v11);
  v86._unsigned __int8 object = &v75;
  uint64_t v16 = alloca(v11);
  unint64_t v17 = alloca(v11);
  uint64_t v89 = (uint64_t)&v75;
  uint64_t v18 = alloca(v11);
  unint64_t v19 = alloca(v11);
  uint64_t v88 = &v75;
  uint64_t v87 = v10;
  uint64_t v94 = *(void *)(v10 + 72);
  if (!v94) {
    BUG();
  }
  if (a2 - a1 == 0x8000000000000000 && v94 == -1) {
    BUG();
  }
  unint64_t v20 = a3 - a2;
  if (a3 - a2 == 0x8000000000000000 && v94 == -1) {
    BUG();
  }
  uint64_t v91 = a3;
  unint64_t v90 = a2;
  uint64_t v21 = (uint64_t)(a2 - a1) / v94;
  if (v21 < v20 / v94)
  {
    specialized UnsafeMutablePointer.moveInitialize(from:count:)(a1, v21, a4);
    uint64_t v22 = v94 * v21;
    Swift::String v23 = a4 + v22;
    if (v22 <= 0 || (uint64_t v24 = v90, v90 >= v91))
    {
LABEL_23:
      uint64_t v47 = v6;
      goto LABEL_49;
    }
    uint64_t v82 = *(void (**)(uint64_t, unint64_t, uint64_t))(v87 + 16);
    uint64_t v92 = a4 + v22;
    while (1)
    {
      BOOL v85 = v6;
      unint64_t v90 = v24;
      Swift::String v25 = v93;
      Swift::String v26 = v82;
      v82((uint64_t)v88, v24, v93);
      uint64_t v84 = a4;
      v26(v89, a4, v25);
      uint64_t v27 = v79;
      AnnotatedFeature.feature.getter(v25);
      uint64_t v86 = URL.path(percentEncoded:)(1);
      unint64_t v81 = *(void (**)(uint64_t *, uint64_t))(v78 + 8);
      unint64_t v28 = v77;
      v81(v27, v77);
      AnnotatedFeature.feature.getter(v25);
      unint64_t v29 = URL.path(percentEncoded:)(1);
      uint64_t countAndFlagsBits = v29._countAndFlagsBits;
      unsigned __int8 object = v29._object;
      unint64_t v32 = v28;
      unint64_t v33 = v86._object;
      v81(v27, v32);
      if (__PAIR128__((unint64_t)v33, v86._countAndFlagsBits) == __PAIR128__((unint64_t)object, countAndFlagsBits))break; {
      uint64_t v39 = (char)object;
      }
      uint64_t v40 = _stringCompareWithSmolCheck(_:_:expecting:)(v86._countAndFlagsBits, v33, countAndFlagsBits, object, 1);
      swift_bridgeObjectRelease((_BYTE)v33);
      swift_bridgeObjectRelease(v39);
      uint64_t v41 = *(void (**)(uint64_t, uint64_t))(v87 + 8);
      uint64_t v42 = v93;
      v41(v89, v93);
      v41((uint64_t)v88, v42);
      if ((v40 & 1) == 0) {
        goto LABEL_16;
      }
      uint64_t v43 = v90;
      uint64_t v44 = v90 + v94;
      Swift::String v45 = v85;
      a4 = v84;
      uint64_t v46 = v91;
      if (v85 >= v90 && v85 < v44)
      {
LABEL_18:
        if (v45 != v43) {
          swift_arrayInitWithTakeBackToFront(v45, v43, 1, v93);
        }
        goto LABEL_21;
      }
LABEL_20:
      swift_arrayInitWithTakeFrontToBack(v45, v43, 1, v93);
LABEL_21:
      Swift::String v23 = v92;
      uint64_t v6 = v94 + v45;
      if (a4 < v92)
      {
        uint64_t v24 = v44;
        if (v44 < v46) {
          continue;
        }
      }
      goto LABEL_23;
    }
    swift_bridgeObjectRelease_n(v33, 2, v34, v35, v36);
    uint64_t v37 = *(void (**)(uint64_t, uint64_t))(v87 + 8);
    uint64_t v38 = v93;
    v37(v89, v93);
    v37((uint64_t)v88, v38);
LABEL_16:
    uint64_t v43 = v84;
    a4 = v84 + v94;
    Swift::String v45 = v85;
    uint64_t v44 = v90;
    uint64_t v46 = v91;
    if (v85 >= v84 && v85 < a4) {
      goto LABEL_18;
    }
    goto LABEL_20;
  }
  unint64_t v48 = v20 / v94;
  uint64_t v49 = v90;
  specialized UnsafeMutablePointer.moveInitialize(from:count:)(v90, v20 / v94, a4);
  unint64_t v50 = v94 * v48;
  Swift::String v23 = a4 + v50;
  if (v50 <= 0)
  {
    uint64_t v72 = v94;
    uint64_t v47 = v49;
    goto LABEL_50;
  }
  uint64_t v47 = v49;
  if (a1 >= v49) {
    goto LABEL_49;
  }
  uint64_t v89 = -v94;
  unint64_t v76 = *(void (**)(uint64_t, unint64_t, uint64_t))(v87 + 16);
  uint64_t v84 = a4;
  BOOL v85 = a1;
  do
  {
    uint64_t v92 = v23;
    unint64_t v51 = v89;
    BOOL v83 = (char *)(v23 + v89);
    unint64_t v52 = v93;
    unint64_t v53 = v76;
    unint64_t v54 = v47;
    v76((uint64_t)v86._object, v23 + v89, v93);
    unint64_t v90 = v54;
    unint64_t v80 = v51 + v54;
    v53(v86._countAndFlagsBits, v51 + v54, v52);
    unint64_t v55 = v79;
    AnnotatedFeature.feature.getter(v52);
    unint64_t v56 = URL.path(percentEncoded:)(1);
    uint64_t v88 = (uint64_t *)v56._countAndFlagsBits;
    unint64_t v81 = (void (*)(uint64_t *, uint64_t))v56._object;
    uint64_t v82 = *(void (**)(uint64_t, unint64_t, uint64_t))(v78 + 8);
    int64_t v57 = v77;
    ((void (*)(uint64_t *, uint64_t))v82)(v55, v77);
    AnnotatedFeature.feature.getter(v52);
    uint64_t v58 = URL.path(percentEncoded:)(1);
    uint64_t v59 = v58._countAndFlagsBits;
    uint64_t v60 = (void (*)(uint64_t *, uint64_t))v58._object;
    uint64_t v61 = v57;
    uint64_t v62 = v81;
    ((void (*)(uint64_t *, uint64_t))v82)(v55, v61);
    if (v88 == (uint64_t *)v59 && v62 == v60)
    {
      uint64_t v63 = 0;
      LOBYTE(v60) = (_BYTE)v62;
    }
    else
    {
      uint64_t v63 = _stringCompareWithSmolCheck(_:_:expecting:)(v88, v62, v59, v60, 1);
    }
    Swift::String v64 = v91;
    swift_bridgeObjectRelease((_BYTE)v62);
    swift_bridgeObjectRelease((_BYTE)v60);
    uint64_t v91 = v64 + v89;
    Swift::String v65 = *(void (**)(uint64_t, uint64_t))(v87 + 8);
    Swift::String v66 = v64;
    uint64_t v67 = v93;
    v65(v86._countAndFlagsBits, v93);
    v65((uint64_t)v86._object, v67);
    unint64_t v68 = (v63 & 1) == 0;
    a4 = v84;
    if (v68)
    {
      uint64_t v70 = v90;
      uint64_t v69 = v91;
      if (v66 < v92 || v91 >= v92)
      {
        unint64_t v71 = v83;
        swift_arrayInitWithTakeFrontToBack(v91, v83, 1, v93);
      }
      else
      {
        if (v66 == v92)
        {
          Swift::String v23 = (unint64_t)v83;
          goto LABEL_44;
        }
        unint64_t v71 = v83;
        swift_arrayInitWithTakeBackToFront(v91, v83, 1, v93);
      }
      Swift::String v23 = (unint64_t)v71;
      uint64_t v69 = v91;
    }
    else
    {
      uint64_t v69 = v91;
      if (v66 < v90 || v91 >= v90)
      {
        uint64_t v70 = v80;
        swift_arrayInitWithTakeFrontToBack(v91, v80, 1, v93);
      }
      else
      {
        uint64_t v70 = v80;
        if (v66 != v90) {
          swift_arrayInitWithTakeBackToFront(v91, v80, 1, v93);
        }
      }
      Swift::String v23 = v92;
    }
LABEL_44:
    if (v23 <= a4) {
      break;
    }
    uint64_t v47 = v70;
    uint64_t v91 = v69;
  }
  while (v70 > v85);
  uint64_t v47 = v70;
LABEL_49:
  uint64_t v72 = v94;
LABEL_50:
  uint64_t v73 = v23 - a4;
  if (v72 == -1 && v73 == 0x8000000000000000) {
    BUG();
  }
  specialized UnsafeMutablePointer.moveInitialize(from:count:)(a4, v73 / v72, v47);
  return 1;
}

uint64_t partial apply for specialized closure #1 in BidirectionalCollection.last(where:)(uint64_t *a1)
{
  return specialized closure #1 in BidirectionalCollection.last(where:)(a1, *(uint64_t **)(v1 + 16));
}

{
  uint64_t v1;

  return specialized closure #1 in BidirectionalCollection.last(where:)(a1, *(uint64_t **)(v1 + 16));
}

uint64_t lazy protocol witness table accessor for type [Float] and conformance <A> [A](uint64_t *a1, uint64_t a2, uint64_t a3)
{
  uint64_t result = *a1;
  if (!*a1)
  {
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [Float]);
    uint64_t result = swift_getWitnessTable(a3, v5);
    *a1 = result;
  }
  return result;
}

uint64_t sub_F91D5(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return key path getter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, &demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
}

uint64_t sub_F91E7(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return key path setter for AnnotatedFeature.annotation : AnnotatedFeature<MLShapedArray<Float>, String>(a1, a2, a3, a4, &demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
}

uint64_t closure #1 in SoundClassifierTrainingSessionDelegate.train(from:)(uint64_t a1, __m128 a2)
{
  return closure #2 in SoundClassifierTrainingSessionDelegate.train(from:)(a1, a2);
}

void *initializeBufferWithCopyOfBuffer for MLActivityClassifier.LSTMBlock(uint64_t a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v3 = (void *)a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v9 = *a2;
    *uint64_t v3 = *a2;
    uint64_t v3 = (void *)(v9 + ((v4 + 16) & ~v4));
    swift_retain(v9);
  }
  else
  {
    *(_OWORD *)a1 = *(_OWORD *)a2;
    *(unsigned char *)(a1 + 16) = *((unsigned char *)a2 + 16);
    *(unsigned char *)(a1 + 17) = *((unsigned char *)a2 + 17);
    uint64_t v5 = *(int *)(a3 + 32);
    uint64_t v6 = a1 + v5;
    uint64_t v7 = (uint64_t)a2 + v5;
    uint64_t v8 = type metadata accessor for LSTM(0);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v8 - 8) + 16))(v6, v7, v8);
  }
  return v3;
}

uint64_t destroy for MLActivityClassifier.LSTMBlock(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(int *)(a2 + 32) + a1;
  uint64_t v3 = type metadata accessor for LSTM(0);
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8))(v2, v3);
}

uint64_t initializeWithCopy for MLActivityClassifier.LSTMBlock(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  *(unsigned char *)(a1 + 17) = *(unsigned char *)(a2 + 17);
  uint64_t v3 = *(int *)(a3 + 32);
  uint64_t v4 = a1 + v3;
  uint64_t v5 = v3 + a2;
  uint64_t v6 = type metadata accessor for LSTM(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 16))(v4, v5, v6);
  return a1;
}

uint64_t assignWithCopy for MLActivityClassifier.LSTMBlock(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  *(unsigned char *)(a1 + 17) = *(unsigned char *)(a2 + 17);
  uint64_t v3 = *(int *)(a3 + 32);
  uint64_t v4 = a1 + v3;
  uint64_t v5 = v3 + a2;
  uint64_t v6 = type metadata accessor for LSTM(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 24))(v4, v5, v6);
  return a1;
}

uint64_t initializeWithTake for MLActivityClassifier.LSTMBlock(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  *(unsigned char *)(a1 + 17) = *(unsigned char *)(a2 + 17);
  uint64_t v3 = *(int *)(a3 + 32);
  uint64_t v4 = a1 + v3;
  uint64_t v5 = v3 + a2;
  uint64_t v6 = type metadata accessor for LSTM(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 32))(v4, v5, v6);
  return a1;
}

uint64_t assignWithTake for MLActivityClassifier.LSTMBlock(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(unsigned char *)(a1 + 16) = *(unsigned char *)(a2 + 16);
  *(unsigned char *)(a1 + 17) = *(unsigned char *)(a2 + 17);
  uint64_t v3 = *(int *)(a3 + 32);
  uint64_t v4 = a1 + v3;
  uint64_t v5 = v3 + a2;
  uint64_t v6 = type metadata accessor for LSTM(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v6 - 8) + 40))(v4, v5, v6);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLActivityClassifier.LSTMBlock(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_F945A);
}

uint64_t sub_F945A(uint64_t a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 254)
  {
    unsigned __int8 v3 = *(unsigned char *)(a1 + 16);
    uint64_t result = 0;
    if (v3 >= 2u) {
      return ((v3 + 2147483646) & 0x7FFFFFFFu) + 1;
    }
  }
  else
  {
    uint64_t v6 = type metadata accessor for LSTM(0);
    return __swift_getEnumTagSinglePayload(*(int *)(a3 + 32) + a1, a2, v6);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLActivityClassifier.LSTMBlock(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_F94DE);
}

uint64_t sub_F94DE(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 254)
  {
    *(unsigned char *)(a1 + 16) = a2 + 1;
  }
  else
  {
    uint64_t v5 = type metadata accessor for LSTM(0);
    return __swift_storeEnumTagSinglePayload(*(int *)(a4 + 32) + a1, a2, a2, v5);
  }
  return result;
}

uint64_t type metadata accessor for MLActivityClassifier.LSTMBlock(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLActivityClassifier.LSTMBlock, (uint64_t)&nominal type descriptor for MLActivityClassifier.LSTMBlock);
}

uint64_t type metadata completion function for MLActivityClassifier.LSTMBlock(uint64_t a1)
{
  v3[0] = (char *)&value witness table for Builtin.Int64 + 64;
  v3[1] = (char *)&value witness table for Builtin.Int64 + 64;
  v3[2] = &unk_349FD0;
  v3[3] = &unk_349FD0;
  uint64_t result = type metadata accessor for LSTM(319);
  if (v2 <= 0x3F)
  {
    void v3[4] = *(void *)(result - 8) + 64;
    swift_initStructMetadata(a1, 256, 5, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t *initializeBufferWithCopyOfBuffer for MLActivityClassifier.InputBlock(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  unsigned __int8 v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v9 = *a2;
    *unsigned __int8 v3 = *a2;
    unsigned __int8 v3 = (uint64_t *)(v9 + ((v4 + 16) & ~v4));
    swift_retain(v9);
  }
  else
  {
    *(_OWORD *)a1 = *(_OWORD *)a2;
    uint64_t v5 = *(int *)(a3 + 24);
    uint64_t v6 = (char *)a1 + v5;
    uint64_t v7 = (char *)a2 + v5;
    uint64_t v8 = type metadata accessor for LearningPhase(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 16))(v6, v7, v8);
  }
  return v3;
}

uint64_t destroy for MLActivityClassifier.InputBlock(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(int *)(a2 + 24) + a1;
  uint64_t v3 = type metadata accessor for LearningPhase(0);
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8))(v2, v3);
}

_OWORD *initializeWithCopy for MLActivityClassifier.InputBlock(_OWORD *a1, _OWORD *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v3 = *(int *)(a3 + 24);
  int v4 = (char *)a1 + v3;
  uint64_t v5 = (char *)a2 + v3;
  uint64_t v6 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16))(v4, v5, v6);
  return a1;
}

void *assignWithCopy for MLActivityClassifier.InputBlock(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  a1[1] = a2[1];
  uint64_t v3 = *(int *)(a3 + 24);
  int v4 = (char *)a1 + v3;
  uint64_t v5 = (char *)a2 + v3;
  uint64_t v6 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 24))(v4, v5, v6);
  return a1;
}

_OWORD *initializeWithTake for MLActivityClassifier.InputBlock(_OWORD *a1, _OWORD *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v3 = *(int *)(a3 + 24);
  int v4 = (char *)a1 + v3;
  uint64_t v5 = (char *)a2 + v3;
  uint64_t v6 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 32))(v4, v5, v6);
  return a1;
}

_OWORD *assignWithTake for MLActivityClassifier.InputBlock(_OWORD *a1, _OWORD *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v3 = *(int *)(a3 + 24);
  int v4 = (char *)a1 + v3;
  uint64_t v5 = (char *)a2 + v3;
  uint64_t v6 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 40))(v4, v5, v6);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLActivityClassifier.InputBlock(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_F9790);
}

uint64_t sub_F9790(uint64_t a1, unsigned int a2, uint64_t a3)
{
  uint64_t v3 = *(int *)(a3 + 24) + a1;
  uint64_t v4 = type metadata accessor for LearningPhase(0);
  return __swift_getEnumTagSinglePayload(v3, a2, v4);
}

uint64_t storeEnumTagSinglePayload for MLActivityClassifier.InputBlock(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_F97CC);
}

uint64_t sub_F97CC(uint64_t a1, unsigned int a2, uint64_t a3, uint64_t a4)
{
  uint64_t v4 = *(int *)(a4 + 24) + a1;
  uint64_t v5 = type metadata accessor for LearningPhase(0);
  return __swift_storeEnumTagSinglePayload(v4, a2, a2, v5);
}

uint64_t type metadata accessor for MLActivityClassifier.InputBlock(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLActivityClassifier.InputBlock, (uint64_t)&nominal type descriptor for MLActivityClassifier.InputBlock);
}

uint64_t type metadata completion function for MLActivityClassifier.InputBlock(uint64_t a1)
{
  v3[0] = (char *)&value witness table for Builtin.Int64 + 64;
  v3[1] = (char *)&value witness table for Builtin.Int64 + 64;
  uint64_t result = type metadata accessor for LearningPhase(319);
  if (v2 <= 0x3F)
  {
    v3[2] = *(void *)(result - 8) + 64;
    swift_initStructMetadata(a1, 256, 3, v3, a1 + 16);
    return 0;
  }
  return result;
}

void *initializeBufferWithCopyOfBuffer for MLActivityClassifier.Model(_OWORD *a1, char *a2, int *a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v29 = *(void *)a2;
    *uint64_t v3 = *(void *)a2;
    uint64_t v3 = (void *)(v29 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    *a1 = *(_OWORD *)a2;
    uint64_t v6 = *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
    uint64_t v7 = type metadata accessor for LearningPhase(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 16))((char *)a1 + v6, &a2[v6], v7);
    uint64_t v8 = a3[5];
    uint64_t v53 = type metadata accessor for Conv2D(0);
    unint64_t v55 = *(void (**)(char *, char *, uint64_t))(*(void *)(v53 - 8) + 16);
    v55((char *)a1 + v8, &a2[v8], v53);
    uint64_t v9 = a3[6];
    uint64_t v45 = type metadata accessor for ReLU(0);
    uint64_t v47 = *(void (**)(char *, char *, uint64_t))(*(void *)(v45 - 8) + 16);
    v47((char *)a1 + v9, &a2[v9], v45);
    uint64_t v10 = a3[7];
    uint64_t v49 = type metadata accessor for Dropout(0);
    unint64_t v51 = *(void (**)(char *, char *, uint64_t))(*(void *)(v49 - 8) + 16);
    v51((char *)a1 + v10, &a2[v10], v49);
    uint64_t v11 = a3[8];
    id v12 = (char *)a1 + v11;
    uint64_t v13 = &a2[v11];
    *(_OWORD *)((char *)a1 + v11) = *(_OWORD *)&a2[v11];
    *((unsigned char *)a1 + v11 + 16) = a2[v11 + 16];
    *((unsigned char *)a1 + v11 + 17) = a2[v11 + 17];
    uint64_t v14 = *(int *)(type metadata accessor for MLActivityClassifier.LSTMBlock(0) + 32);
    int64_t v15 = &v12[v14];
    uint64_t v16 = &v13[v14];
    uint64_t v17 = type metadata accessor for LSTM(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 16))(v15, v16, v17);
    v55((char *)a1 + a3[9], &a2[a3[9]], v53);
    uint64_t v18 = a3[10];
    uint64_t v19 = type metadata accessor for BatchNorm(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16))((char *)a1 + v18, &a2[v18], v19);
    v47((char *)a1 + a3[11], &a2[a3[11]], v45);
    v51((char *)a1 + a3[12], &a2[a3[12]], v49);
    v55((char *)a1 + a3[13], &a2[a3[13]], v53);
    *(void *)((char *)a1 + a3[14]) = *(void *)&a2[a3[14]];
    uint64_t v20 = a3[15];
    uint64_t v50 = *(void *)&a2[v20];
    *(void *)((char *)a1 + v20) = v50;
    unint64_t v54 = a3;
    uint64_t v21 = a3[16];
    uint64_t v22 = (char *)a1 + v21;
    Swift::String v23 = &a2[v21];
    *(void *)((char *)a1 + v21) = *(void *)&a2[v21];
    *(void *)((char *)a1 + v21 + 8) = *(void *)&a2[v21 + 8];
    *((unsigned char *)a1 + v21 + 16) = a2[v21 + 16];
    *(_OWORD *)((char *)a1 + v21 + 24) = *(_OWORD *)&a2[v21 + 24];
    uint64_t v52 = *(void *)&a2[v21 + 40];
    *(void *)((char *)a1 + v21 + 40) = v52;
    *(void *)((char *)a1 + v21 + 48) = *(void *)&a2[v21 + 48];
    uint64_t v43 = *(void *)&a2[v21 + 56];
    *(void *)((char *)a1 + v21 + 56) = v43;
    *(void *)((char *)a1 + v21 + 64) = *(void *)&a2[v21 + 64];
    uint64_t v44 = *(void *)&a2[v21 + 72];
    *(void *)((char *)a1 + v21 + 72) = v44;
    uint64_t v48 = type metadata accessor for MLActivityClassifier.Configuration(0);
    uint64_t v24 = *(int *)(v48 + 44);
    unint64_t v56 = v22;
    Swift::String v25 = &v22[v24];
    uint64_t v46 = v23;
    Swift::String v26 = &v23[v24];
    uint64_t v27 = type metadata accessor for DataFrame(0);
    swift_bridgeObjectRetain(v50);
    swift_bridgeObjectRetain(v52);
    swift_bridgeObjectRetain(v43);
    swift_bridgeObjectRetain(v44);
    if (__swift_getEnumTagSinglePayload((uint64_t)v26, 1, v27))
    {
      uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
      memcpy(v25, v26, *(void *)(*(void *)(v28 - 8) + 64));
    }
    else
    {
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v27 - 8) + 16))(v25, v26, v27);
      __swift_storeEnumTagSinglePayload((uint64_t)v25, 0, 1, v27);
    }
    uint64_t v30 = v27;
    uint64_t v31 = *(int *)(v48 + 48);
    unint64_t v32 = &v56[v31];
    unint64_t v33 = &v46[v31];
    if (__swift_getEnumTagSinglePayload((uint64_t)&v46[v31], 1, v30))
    {
      uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
      memcpy(v32, v33, *(void *)(*(void *)(v34 - 8) + 64));
    }
    else
    {
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v30 - 8) + 16))(v32, v33, v30);
      __swift_storeEnumTagSinglePayload((uint64_t)v32, 0, 1, v30);
    }
    uint64_t v35 = v54[17];
    uint64_t v36 = *(void **)&a2[v35];
    *(void *)((char *)v3 + v35) = v36;
    uint64_t v37 = v54[18];
    uint64_t v38 = (void *)((char *)v3 + v37);
    uint64_t v39 = &a2[v37];
    uint64_t v40 = *(void *)&a2[v37];
    v36;
    if (v40)
    {
      void *v38 = v40;
      v38[1] = *((void *)v39 + 1);
      uint64_t v41 = *((void *)v39 + 2);
      v38[2] = v41;
      swift_retain();
      swift_retain();
      swift_bridgeObjectRetain(v41);
    }
    else
    {
      v38[2] = *((void *)v39 + 2);
      *(_OWORD *)uint64_t v38 = *(_OWORD *)v39;
    }
  }
  return v3;
}

void destroy for MLActivityClassifier.Model(uint64_t a1, int *a2)
{
  uint64_t v2 = a1 + *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
  uint64_t v3 = type metadata accessor for LearningPhase(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8))(v2, v3);
  uint64_t v4 = a1 + a2[5];
  uint64_t v20 = type metadata accessor for Conv2D(0);
  uint64_t v21 = *(void (**)(uint64_t, uint64_t))(*(void *)(v20 - 8) + 8);
  v21(v4, v20);
  uint64_t v5 = a1 + a2[6];
  uint64_t v22 = type metadata accessor for ReLU(0);
  uint64_t v17 = *(void (**)(uint64_t, uint64_t))(*(void *)(v22 - 8) + 8);
  v17(v5, v22);
  uint64_t v6 = a1 + a2[7];
  uint64_t v18 = type metadata accessor for Dropout(0);
  uint64_t v19 = *(void (**)(uint64_t, uint64_t))(*(void *)(v18 - 8) + 8);
  v19(v6, v18);
  uint64_t v7 = a1 + a2[8];
  uint64_t v8 = v7 + *(int *)(type metadata accessor for MLActivityClassifier.LSTMBlock(0) + 32);
  uint64_t v9 = type metadata accessor for LSTM(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(v8, v9);
  v21(a1 + a2[9], v20);
  uint64_t v10 = a1 + a2[10];
  uint64_t v11 = type metadata accessor for BatchNorm(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v11 - 8) + 8))(v10, v11);
  v17(a1 + a2[11], v22);
  v19(a1 + a2[12], v18);
  v21(a1 + a2[13], v20);
  swift_bridgeObjectRelease(*(void *)(a1 + a2[15]));
  id v12 = (void *)(a1 + a2[16]);
  swift_bridgeObjectRelease(v12[5]);
  swift_bridgeObjectRelease(v12[7]);
  swift_bridgeObjectRelease(v12[9]);
  uint64_t v23 = type metadata accessor for MLActivityClassifier.Configuration(0);
  uint64_t v13 = (uint64_t)v12 + *(int *)(v23 + 44);
  uint64_t v14 = type metadata accessor for DataFrame(0);
  if (!__swift_getEnumTagSinglePayload(v13, 1, v14)) {
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v14 - 8) + 8))(v13, v14);
  }
  uint64_t v15 = (uint64_t)v12 + *(int *)(v23 + 48);
  if (!__swift_getEnumTagSinglePayload(v15, 1, v14)) {
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v14 - 8) + 8))(v15, v14);
  }

  uint64_t v16 = a2[18];
  if (*(void *)(a1 + v16))
  {
    swift_release();
    swift_release();
    swift_bridgeObjectRelease(*(void *)(a1 + v16 + 16));
  }
}

char *initializeWithCopy for MLActivityClassifier.Model(char *a1, char *a2, int *a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  uint64_t v5 = *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
  uint64_t v6 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16))(&a1[v5], &a2[v5], v6);
  uint64_t v7 = a3[5];
  uint64_t v49 = type metadata accessor for Conv2D(0);
  unint64_t v51 = *(void (**)(char *, char *, uint64_t))(*(void *)(v49 - 8) + 16);
  v51(&a1[v7], &a2[v7], v49);
  uint64_t v8 = a3[6];
  uint64_t v43 = type metadata accessor for ReLU(0);
  uint64_t v45 = *(void (**)(char *, char *, uint64_t))(*(void *)(v43 - 8) + 16);
  v45(&a1[v8], &a2[v8], v43);
  uint64_t v9 = a3[7];
  __dsta = (void *)type metadata accessor for Dropout(0);
  uint64_t v47 = *(void (**)(char *, char *, void *))(*(__dsta - 1) + 16);
  v47(&a1[v9], &a2[v9], __dsta);
  uint64_t v10 = a3[8];
  uint64_t v11 = &a1[v10];
  id v12 = &a2[v10];
  *(_OWORD *)&a1[v10] = *(_OWORD *)&a2[v10];
  a1[v10 + 16] = a2[v10 + 16];
  a1[v10 + 17] = a2[v10 + 17];
  uint64_t v13 = *(int *)(type metadata accessor for MLActivityClassifier.LSTMBlock(0) + 32);
  uint64_t v14 = &v11[v13];
  uint64_t v15 = &v12[v13];
  uint64_t v16 = type metadata accessor for LSTM(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(v14, v15, v16);
  v51(&a1[a3[9]], &a2[a3[9]], v49);
  uint64_t v17 = a3[10];
  uint64_t v18 = type metadata accessor for BatchNorm(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 16))(&a1[v17], &a2[v17], v18);
  v45(&a1[a3[11]], &a2[a3[11]], v43);
  v47(&a1[a3[12]], &a2[a3[12]], __dsta);
  v51(&a1[a3[13]], &a2[a3[13]], v49);
  *(void *)&a1[a3[14]] = *(void *)&a2[a3[14]];
  uint64_t v19 = a3[15];
  uint64_t v48 = *(void *)&a2[v19];
  *(void *)&a1[v19] = v48;
  uint64_t v50 = a3;
  uint64_t v20 = a3[16];
  uint64_t v21 = &a1[v20];
  uint64_t v22 = &a2[v20];
  *(void *)&a1[v20] = *(void *)&a2[v20];
  *(void *)&a1[v20 + 8] = *(void *)&a2[v20 + 8];
  a1[v20 + 16] = a2[v20 + 16];
  *(_OWORD *)&a1[v20 + 24] = *(_OWORD *)&a2[v20 + 24];
  uint64_t v40 = *(void *)&a2[v20 + 40];
  *(void *)&a1[v20 + 40] = v40;
  *(void *)&a1[v20 + 48] = *(void *)&a2[v20 + 48];
  uint64_t v41 = *(void *)&a2[v20 + 56];
  *(void *)&a1[v20 + 56] = v41;
  *(void *)&a1[v20 + 64] = *(void *)&a2[v20 + 64];
  uint64_t v42 = *(void *)&a2[v20 + 72];
  *(void *)&a1[v20 + 72] = v42;
  uint64_t v46 = type metadata accessor for MLActivityClassifier.Configuration(0);
  uint64_t v23 = *(int *)(v46 + 44);
  uint64_t v52 = v21;
  __dst = &v21[v23];
  uint64_t v44 = v22;
  uint64_t v24 = &v22[v23];
  uint64_t v25 = type metadata accessor for DataFrame(0);
  swift_bridgeObjectRetain(v48);
  swift_bridgeObjectRetain(v40);
  swift_bridgeObjectRetain(v41);
  swift_bridgeObjectRetain(v42);
  if (__swift_getEnumTagSinglePayload((uint64_t)v24, 1, v25))
  {
    uint64_t v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(__dst, v24, *(void *)(*(void *)(v26 - 8) + 64));
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v25 - 8) + 16))(__dst, v24, v25);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v25);
  }
  uint64_t v27 = v25;
  uint64_t v28 = *(int *)(v46 + 48);
  uint64_t v29 = &v52[v28];
  uint64_t v30 = &v22[v28];
  if (__swift_getEnumTagSinglePayload((uint64_t)&v44[v28], 1, v27))
  {
    uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(v29, v30, *(void *)(*(void *)(v31 - 8) + 64));
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v27 - 8) + 16))(v29, v30, v27);
    __swift_storeEnumTagSinglePayload((uint64_t)v29, 0, 1, v27);
  }
  uint64_t v32 = v50[17];
  unint64_t v33 = *(void **)&a2[v32];
  *(void *)&a1[v32] = v33;
  uint64_t v34 = v50[18];
  uint64_t v35 = &a1[v34];
  uint64_t v36 = &a2[v34];
  uint64_t v37 = *(void *)&a2[v34];
  v33;
  if (v37)
  {
    *(void *)uint64_t v35 = v37;
    *((void *)v35 + 1) = *((void *)v36 + 1);
    uint64_t v38 = *((void *)v36 + 2);
    *((void *)v35 + 2) = v38;
    swift_retain();
    swift_retain();
    swift_bridgeObjectRetain(v38);
  }
  else
  {
    *((void *)v35 + 2) = *((void *)v36 + 2);
    *(_OWORD *)uint64_t v35 = *(_OWORD *)v36;
  }
  return a1;
}

char *assignWithCopy for MLActivityClassifier.Model(char *a1, char *a2, int *a3)
{
  *(void *)a1 = *(void *)a2;
  *((void *)a1 + 1) = *((void *)a2 + 1);
  uint64_t v5 = *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
  uint64_t v6 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 24))(&a1[v5], &a2[v5], v6);
  uint64_t v7 = a3[5];
  __srca = (void *)type metadata accessor for Conv2D(0);
  Swift::String v65 = *(void (**)(char *, char *, void *))(*(__srca - 1) + 24);
  v65(&a1[v7], &a2[v7], __srca);
  uint64_t v8 = a3[6];
  uint64_t v59 = type metadata accessor for ReLU(0);
  uint64_t v61 = *(void (**)(char *, char *, uint64_t))(*(void *)(v59 - 8) + 24);
  v61(&a1[v8], &a2[v8], v59);
  uint64_t v9 = a3;
  uint64_t v10 = a3[7];
  __dsta = (void *)type metadata accessor for Dropout(0);
  uint64_t v58 = *(void (**)(char *, char *, void *))(*(__dsta - 1) + 24);
  v58(&a1[v10], &a2[v10], __dsta);
  uint64_t v11 = a3[8];
  id v12 = &a1[v11];
  uint64_t v13 = &a2[v11];
  *(void *)&a1[v11] = *(void *)&a2[v11];
  *(void *)&a1[v11 + 8] = *(void *)&a2[v11 + 8];
  a1[v11 + 16] = a2[v11 + 16];
  a1[v11 + 17] = a2[v11 + 17];
  uint64_t v14 = *(int *)(type metadata accessor for MLActivityClassifier.LSTMBlock(0) + 32);
  uint64_t v15 = &v12[v14];
  uint64_t v16 = &v13[v14];
  uint64_t v17 = type metadata accessor for LSTM(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 24))(v15, v16, v17);
  v65(&a1[v9[9]], &a2[v9[9]], __srca);
  uint64_t v18 = v9[10];
  uint64_t v19 = type metadata accessor for BatchNorm(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 24))(&a1[v18], &a2[v18], v19);
  v61(&a1[v9[11]], &a2[v9[11]], v59);
  v58(&a1[v9[12]], &a2[v9[12]], __dsta);
  v65(&a1[v9[13]], &a2[v9[13]], __srca);
  *(void *)&a1[v9[14]] = *(void *)&a2[v9[14]];
  uint64_t v20 = v9[15];
  uint64_t v21 = v9;
  uint64_t v22 = *(void *)&a2[v20];
  uint64_t v23 = *(void *)&a1[v20];
  *(void *)&a1[v20] = v22;
  swift_bridgeObjectRetain(v22);
  swift_bridgeObjectRelease(v23);
  uint64_t v60 = v21;
  uint64_t v24 = v21[16];
  uint64_t v25 = &a1[v24];
  __src = &a2[v24];
  *(void *)&a1[v24] = *(void *)&a2[v24];
  *(void *)&a1[v24 + 8] = *(void *)&a2[v24 + 8];
  a1[v24 + 16] = a2[v24 + 16];
  *(void *)&a1[v24 + 24] = *(void *)&a2[v24 + 24];
  *(void *)&a1[v24 + 32] = *(void *)&a2[v24 + 32];
  uint64_t v26 = *(void *)&a2[v24 + 40];
  uint64_t v27 = *(void *)&a1[v24 + 40];
  *(void *)&a1[v24 + 40] = v26;
  swift_bridgeObjectRetain(v26);
  swift_bridgeObjectRelease(v27);
  *(void *)&a1[v24 + 48] = *(void *)&a2[v24 + 48];
  uint64_t v28 = *(void *)&a2[v24 + 56];
  uint64_t v29 = *(void *)&a1[v24 + 56];
  *(void *)&a1[v24 + 56] = v28;
  swift_bridgeObjectRetain(v28);
  swift_bridgeObjectRelease(v29);
  *(void *)&a1[v24 + 64] = *(void *)&a2[v24 + 64];
  uint64_t v30 = *(void *)&a2[v24 + 72];
  uint64_t v31 = *(void *)&a1[v24 + 72];
  *(void *)&a1[v24 + 72] = v30;
  swift_bridgeObjectRetain(v30);
  swift_bridgeObjectRelease(v31);
  uint64_t v62 = type metadata accessor for MLActivityClassifier.Configuration(0);
  uint64_t v32 = *(int *)(v62 + 44);
  Swift::String v66 = v25;
  uint64_t v33 = (uint64_t)&v25[v32];
  uint64_t v34 = &__src[v32];
  uint64_t v35 = type metadata accessor for DataFrame(0);
  __dst = (void *)v33;
  LODWORD(v33) = __swift_getEnumTagSinglePayload(v33, 1, v35);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v34, 1, v35);
  if (v33)
  {
    if (EnumTagSinglePayload)
    {
      size_t v37 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      uint64_t v38 = __dst;
LABEL_6:
      memcpy(v38, v34, v37);
      goto LABEL_9;
    }
    (*(void (**)(void *, char *, uint64_t))(*(void *)(v35 - 8) + 16))(__dst, v34, v35);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v35);
  }
  else
  {
    uint64_t v39 = *(void *)(v35 - 8);
    if (EnumTagSinglePayload)
    {
      (*(void (**)(void *, uint64_t))(v39 + 8))(__dst, v35);
      size_t v37 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      uint64_t v38 = __dst;
      goto LABEL_6;
    }
    (*(void (**)(void *, char *, uint64_t))(v39 + 24))(__dst, v34, v35);
  }
LABEL_9:
  uint64_t v40 = *(int *)(v62 + 48);
  uint64_t v41 = &__src[v40];
  uint64_t v67 = &v66[v40];
  int v42 = __swift_getEnumTagSinglePayload((uint64_t)v67, 1, v35);
  int v43 = __swift_getEnumTagSinglePayload((uint64_t)v41, 1, v35);
  if (v42)
  {
    if (v43)
    {
      size_t v44 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      uint64_t v45 = v67;
LABEL_14:
      memcpy(v45, v41, v44);
      goto LABEL_17;
    }
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v35 - 8) + 16))(v67, v41, v35);
    __swift_storeEnumTagSinglePayload((uint64_t)v67, 0, 1, v35);
  }
  else
  {
    uint64_t v46 = *(void *)(v35 - 8);
    if (v43)
    {
      (*(void (**)(char *, uint64_t))(v46 + 8))(v67, v35);
      size_t v44 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      uint64_t v45 = v67;
      goto LABEL_14;
    }
    (*(void (**)(char *, char *, uint64_t))(v46 + 24))(v67, v41, v35);
  }
LABEL_17:
  uint64_t v47 = v60[17];
  uint64_t v48 = *(void **)&a1[v47];
  uint64_t v49 = *(void **)&a2[v47];
  *(void *)&a1[v47] = v49;
  v49;

  uint64_t v50 = v60[18];
  unint64_t v51 = &a1[v50];
  uint64_t v52 = &a2[v50];
  uint64_t v53 = *(void *)&a2[v50];
  if (*(void *)&a1[v50])
  {
    if (v53)
    {
      *(void *)unint64_t v51 = v53;
      swift_retain();
      swift_release();
      *((void *)v51 + 1) = *((void *)v52 + 1);
      swift_retain();
      swift_release();
      uint64_t v54 = *((void *)v52 + 2);
      uint64_t v55 = *((void *)v51 + 2);
      *((void *)v51 + 2) = v54;
      swift_bridgeObjectRetain(v54);
      swift_bridgeObjectRelease(v55);
    }
    else
    {
      outlined destroy of ClassificationMetricsContainer((uint64_t)&a1[v50]);
      *(_OWORD *)unint64_t v51 = *(_OWORD *)v52;
      *((void *)v51 + 2) = *((void *)v52 + 2);
    }
  }
  else if (v53)
  {
    *(void *)unint64_t v51 = v53;
    *((void *)v51 + 1) = *((void *)v52 + 1);
    uint64_t v56 = *((void *)v52 + 2);
    *((void *)v51 + 2) = v56;
    swift_retain();
    swift_retain();
    swift_bridgeObjectRetain(v56);
  }
  else
  {
    *((void *)v51 + 2) = *((void *)v52 + 2);
    *(_OWORD *)unint64_t v51 = *(_OWORD *)v52;
  }
  return a1;
}

char *initializeWithTake for MLActivityClassifier.Model(char *a1, char *a2, int *a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  uint64_t v4 = *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
  uint64_t v5 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v5 - 8) + 32))(&a1[v4], &a2[v4], v5);
  uint64_t v6 = a3[5];
  uint64_t v36 = type metadata accessor for Conv2D(0);
  uint64_t v38 = *(void (**)(char *, char *, uint64_t))(*(void *)(v36 - 8) + 32);
  v38(&a1[v6], &a2[v6], v36);
  uint64_t v7 = a3[6];
  uint64_t v32 = type metadata accessor for ReLU(0);
  uint64_t v34 = *(void (**)(char *, char *, uint64_t))(*(void *)(v32 - 8) + 32);
  v34(&a1[v7], &a2[v7], v32);
  uint64_t v8 = a3[7];
  __dsta = (void *)type metadata accessor for Dropout(0);
  uint64_t v31 = *(void (**)(char *, char *, void *))(*(__dsta - 1) + 32);
  v31(&a1[v8], &a2[v8], __dsta);
  uint64_t v9 = a3[8];
  uint64_t v10 = &a1[v9];
  uint64_t v11 = &a2[v9];
  *(_OWORD *)&a1[v9] = *(_OWORD *)&a2[v9];
  a1[v9 + 16] = a2[v9 + 16];
  a1[v9 + 17] = a2[v9 + 17];
  uint64_t v12 = *(int *)(type metadata accessor for MLActivityClassifier.LSTMBlock(0) + 32);
  uint64_t v13 = &v10[v12];
  uint64_t v14 = &v11[v12];
  uint64_t v15 = type metadata accessor for LSTM(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 32))(v13, v14, v15);
  v38(&a1[a3[9]], &a2[a3[9]], v36);
  uint64_t v16 = a3[10];
  uint64_t v17 = type metadata accessor for BatchNorm(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 32))(&a1[v16], &a2[v16], v17);
  v34(&a1[a3[11]], &a2[a3[11]], v32);
  v31(&a1[a3[12]], &a2[a3[12]], __dsta);
  v38(&a1[a3[13]], &a2[a3[13]], v36);
  *(void *)&a1[a3[14]] = *(void *)&a2[a3[14]];
  *(void *)&a1[a3[15]] = *(void *)&a2[a3[15]];
  uint64_t v39 = a3;
  uint64_t v18 = a3[16];
  uint64_t v19 = &a1[v18];
  uint64_t v20 = &a2[v18];
  *(void *)&a1[v18] = *(void *)&a2[v18];
  *(void *)&a1[v18 + 8] = *(void *)&a2[v18 + 8];
  a1[v18 + 16] = a2[v18 + 16];
  *(_OWORD *)&a1[v18 + 24] = *(_OWORD *)&a2[v18 + 24];
  *(void *)&a1[v18 + 40] = *(void *)&a2[v18 + 40];
  *(_OWORD *)&a1[v18 + 48] = *(_OWORD *)&a2[v18 + 48];
  *(_OWORD *)&a1[v18 + 64] = *(_OWORD *)&a2[v18 + 64];
  uint64_t v35 = type metadata accessor for MLActivityClassifier.Configuration(0);
  uint64_t v21 = *(int *)(v35 + 44);
  size_t v37 = v19;
  __dst = &v19[v21];
  uint64_t v33 = v20;
  uint64_t v22 = &v20[v21];
  uint64_t v23 = type metadata accessor for DataFrame(0);
  if (__swift_getEnumTagSinglePayload((uint64_t)v22, 1, v23))
  {
    uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(__dst, v22, *(void *)(*(void *)(v24 - 8) + 64));
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v23 - 8) + 32))(__dst, v22, v23);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v23);
  }
  uint64_t v25 = *(int *)(v35 + 48);
  uint64_t v26 = &v37[v25];
  uint64_t v27 = &v20[v25];
  if (__swift_getEnumTagSinglePayload((uint64_t)&v33[v25], 1, v23))
  {
    uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(v26, v27, *(void *)(*(void *)(v28 - 8) + 64));
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v23 - 8) + 32))(v26, v27, v23);
    __swift_storeEnumTagSinglePayload((uint64_t)v26, 0, 1, v23);
  }
  *(void *)&a1[v39[17]] = *(void *)&a2[v39[17]];
  uint64_t v29 = v39[18];
  *(void *)&a1[v29 + 16] = *(void *)&a2[v29 + 16];
  *(_OWORD *)&a1[v29] = *(_OWORD *)&a2[v29];
  return a1;
}

char *assignWithTake for MLActivityClassifier.Model(char *a1, char *a2, int *a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  uint64_t v5 = *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
  uint64_t v6 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 40))(&a1[v5], &a2[v5], v6);
  uint64_t v7 = a3[5];
  int64_t v57 = (void *)type metadata accessor for Conv2D(0);
  __srca = *(void (**)(char *, char *, void *))(*(v57 - 1) + 40);
  __srca(&a1[v7], &a2[v7], v57);
  uint64_t v8 = a3[6];
  uint64_t v51 = type metadata accessor for ReLU(0);
  uint64_t v53 = *(void (**)(char *, char *, uint64_t))(*(void *)(v51 - 8) + 40);
  v53(&a1[v8], &a2[v8], v51);
  uint64_t v9 = a3[7];
  __dsta = (void *)type metadata accessor for Dropout(0);
  uint64_t v50 = *(void (**)(char *, char *, void *))(*(__dsta - 1) + 40);
  v50(&a1[v9], &a2[v9], __dsta);
  uint64_t v10 = a3[8];
  uint64_t v11 = &a1[v10];
  uint64_t v12 = &a2[v10];
  *(_OWORD *)&a1[v10] = *(_OWORD *)&a2[v10];
  a1[v10 + 16] = a2[v10 + 16];
  a1[v10 + 17] = a2[v10 + 17];
  uint64_t v13 = *(int *)(type metadata accessor for MLActivityClassifier.LSTMBlock(0) + 32);
  uint64_t v14 = &v11[v13];
  uint64_t v15 = &v12[v13];
  uint64_t v16 = type metadata accessor for LSTM(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 40))(v14, v15, v16);
  __srca(&a1[a3[9]], &a2[a3[9]], v57);
  uint64_t v17 = a3[10];
  uint64_t v18 = type metadata accessor for BatchNorm(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 40))(&a1[v17], &a2[v17], v18);
  v53(&a1[a3[11]], &a2[a3[11]], v51);
  v50(&a1[a3[12]], &a2[a3[12]], __dsta);
  __srca(&a1[a3[13]], &a2[a3[13]], v57);
  *(void *)&a1[a3[14]] = *(void *)&a2[a3[14]];
  uint64_t v19 = a3[15];
  uint64_t v20 = *(void *)&a1[v19];
  *(void *)&a1[v19] = *(void *)&a2[v19];
  swift_bridgeObjectRelease(v20);
  uint64_t v52 = a3;
  uint64_t v21 = a3[16];
  uint64_t v22 = &a1[v21];
  uint64_t v23 = &a2[v21];
  *(void *)&a1[v21] = *(void *)&a2[v21];
  *(void *)&a1[v21 + 8] = *(void *)&a2[v21 + 8];
  a1[v21 + 16] = a2[v21 + 16];
  *(_OWORD *)&a1[v21 + 24] = *(_OWORD *)&a2[v21 + 24];
  uint64_t v24 = *(void *)&a1[v21 + 40];
  *(void *)&a1[v21 + 40] = *(void *)&a2[v21 + 40];
  swift_bridgeObjectRelease(v24);
  *(void *)&a1[v21 + 48] = *(void *)&a2[v21 + 48];
  uint64_t v25 = *(void *)&a1[v21 + 56];
  *(void *)&a1[v21 + 56] = *(void *)&a2[v21 + 56];
  swift_bridgeObjectRelease(v25);
  *(void *)&a1[v21 + 64] = *(void *)&a2[v21 + 64];
  uint64_t v26 = *(void *)&a1[v21 + 72];
  *(void *)&a1[v21 + 72] = *(void *)&a2[v21 + 72];
  swift_bridgeObjectRelease(v26);
  uint64_t v54 = type metadata accessor for MLActivityClassifier.Configuration(0);
  uint64_t v27 = *(int *)(v54 + 44);
  uint64_t v58 = v22;
  uint64_t v28 = (uint64_t)&v22[v27];
  __src = v23;
  uint64_t v29 = &v23[v27];
  uint64_t v30 = type metadata accessor for DataFrame(0);
  __dst = (void *)v28;
  LODWORD(v28) = __swift_getEnumTagSinglePayload(v28, 1, v30);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v29, 1, v30);
  if (v28)
  {
    if (EnumTagSinglePayload)
    {
      size_t v32 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      uint64_t v33 = __dst;
LABEL_6:
      memcpy(v33, v29, v32);
      goto LABEL_9;
    }
    (*(void (**)(void *, char *, uint64_t))(*(void *)(v30 - 8) + 32))(__dst, v29, v30);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v30);
  }
  else
  {
    uint64_t v34 = *(void *)(v30 - 8);
    if (EnumTagSinglePayload)
    {
      (*(void (**)(void *, uint64_t))(v34 + 8))(__dst, v30);
      size_t v32 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      uint64_t v33 = __dst;
      goto LABEL_6;
    }
    (*(void (**)(void *, char *, uint64_t))(v34 + 40))(__dst, v29, v30);
  }
LABEL_9:
  uint64_t v35 = *(int *)(v54 + 48);
  uint64_t v36 = &__src[v35];
  uint64_t v59 = &v58[v35];
  int v37 = __swift_getEnumTagSinglePayload((uint64_t)v59, 1, v30);
  int v38 = __swift_getEnumTagSinglePayload((uint64_t)v36, 1, v30);
  if (v37)
  {
    if (v38)
    {
      size_t v39 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      uint64_t v40 = v59;
LABEL_14:
      memcpy(v40, v36, v39);
      goto LABEL_17;
    }
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v30 - 8) + 32))(v59, v36, v30);
    __swift_storeEnumTagSinglePayload((uint64_t)v59, 0, 1, v30);
  }
  else
  {
    uint64_t v41 = *(void *)(v30 - 8);
    if (v38)
    {
      (*(void (**)(char *, uint64_t))(v41 + 8))(v59, v30);
      size_t v39 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      uint64_t v40 = v59;
      goto LABEL_14;
    }
    (*(void (**)(char *, char *, uint64_t))(v41 + 40))(v59, v36, v30);
  }
LABEL_17:
  uint64_t v42 = v52[17];
  int v43 = *(void **)&a1[v42];
  *(void *)&a1[v42] = *(void *)&a2[v42];

  uint64_t v44 = v52[18];
  uint64_t v45 = &a1[v44];
  uint64_t v46 = &a2[v44];
  if (*(void *)&a1[v44])
  {
    uint64_t v47 = *(void *)&a2[v44];
    if (v47)
    {
      *(void *)uint64_t v45 = v47;
      swift_release();
      *((void *)v45 + 1) = *((void *)v46 + 1);
      swift_release();
      uint64_t v48 = *((void *)v45 + 2);
      *((void *)v45 + 2) = *((void *)v46 + 2);
      swift_bridgeObjectRelease(v48);
    }
    else
    {
      outlined destroy of ClassificationMetricsContainer((uint64_t)v45);
      *(_OWORD *)uint64_t v45 = *(_OWORD *)v46;
      *((void *)v45 + 2) = *((void *)v46 + 2);
    }
  }
  else
  {
    *((void *)v45 + 2) = *((void *)v46 + 2);
    *(_OWORD *)uint64_t v45 = *(_OWORD *)v46;
  }
  return a1;
}

uint64_t getEnumTagSinglePayload for MLActivityClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_FAEDB);
}

uint64_t sub_FAEDB(uint64_t a1, unsigned int a2, int *a3)
{
  uint64_t v4 = a1;
  uint64_t v5 = type metadata accessor for MLActivityClassifier.InputBlock(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(v4, a2, v5);
  }
  uint64_t v5 = type metadata accessor for Conv2D(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2)
  {
    uint64_t v6 = a3[5];
LABEL_17:
    uint64_t v4 = v6 + a1;
    return __swift_getEnumTagSinglePayload(v4, a2, v5);
  }
  uint64_t v5 = type metadata accessor for ReLU(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2)
  {
    uint64_t v6 = a3[6];
    goto LABEL_17;
  }
  uint64_t v5 = type metadata accessor for Dropout(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2)
  {
    uint64_t v6 = a3[7];
    goto LABEL_17;
  }
  uint64_t v5 = type metadata accessor for MLActivityClassifier.LSTMBlock(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2)
  {
    uint64_t v6 = a3[8];
    goto LABEL_17;
  }
  uint64_t v5 = type metadata accessor for BatchNorm(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2)
  {
    uint64_t v6 = a3[10];
    goto LABEL_17;
  }
  if (a2 != 0x7FFFFFFF)
  {
    uint64_t v5 = type metadata accessor for MLActivityClassifier.Configuration(0);
    uint64_t v6 = a3[16];
    goto LABEL_17;
  }
  uint64_t result = 0;
  if ((*(void *)(a1 + a3[15]) & 0xFFFFFFFF00000001) == 0) {
    return (*(void *)(a1 + a3[15]) >> 1) + 1;
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLActivityClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_FAFE0);
}

uint64_t sub_FAFE0(uint64_t a1, unsigned int a2, int a3, int *a4)
{
  uint64_t v6 = a1;
  uint64_t v7 = type metadata accessor for MLActivityClassifier.InputBlock(0);
  if (*(_DWORD *)(*(void *)(v7 - 8) + 84) != a3)
  {
    uint64_t v7 = type metadata accessor for Conv2D(0);
    if (*(_DWORD *)(*(void *)(v7 - 8) + 84) == a3)
    {
      uint64_t v8 = a4[5];
    }
    else
    {
      uint64_t v7 = type metadata accessor for ReLU(0);
      if (*(_DWORD *)(*(void *)(v7 - 8) + 84) == a3)
      {
        uint64_t v8 = a4[6];
      }
      else
      {
        uint64_t v7 = type metadata accessor for Dropout(0);
        if (*(_DWORD *)(*(void *)(v7 - 8) + 84) == a3)
        {
          uint64_t v8 = a4[7];
        }
        else
        {
          uint64_t v7 = type metadata accessor for MLActivityClassifier.LSTMBlock(0);
          if (*(_DWORD *)(*(void *)(v7 - 8) + 84) == a3)
          {
            uint64_t v8 = a4[8];
          }
          else
          {
            uint64_t v7 = type metadata accessor for BatchNorm(0);
            if (*(_DWORD *)(*(void *)(v7 - 8) + 84) == a3)
            {
              uint64_t v8 = a4[10];
            }
            else
            {
              if (a3 == 0x7FFFFFFF)
              {
                uint64_t result = a4[15];
                *(void *)(a1 + result) = 2 * (a2 - 1);
                return result;
              }
              uint64_t v7 = type metadata accessor for MLActivityClassifier.Configuration(0);
              uint64_t v8 = a4[16];
            }
          }
        }
      }
    }
    uint64_t v6 = v8 + a1;
  }
  return __swift_storeEnumTagSinglePayload(v6, a2, a2, v7);
}

uint64_t type metadata accessor for MLActivityClassifier.Model(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLActivityClassifier.Model, (uint64_t)&nominal type descriptor for MLActivityClassifier.Model);
}

uint64_t type metadata completion function for MLActivityClassifier.Model(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLActivityClassifier.InputBlock(319);
  if (v2 <= 0x3F)
  {
    v12[0] = *(void *)(result - 8) + 64;
    uint64_t result = type metadata accessor for Conv2D(319);
    if (v3 <= 0x3F)
    {
      uint64_t v4 = *(void *)(result - 8) + 64;
      v12[1] = v4;
      uint64_t result = type metadata accessor for ReLU(319);
      if (v5 <= 0x3F)
      {
        uint64_t v6 = *(void *)(result - 8) + 64;
        v12[2] = v6;
        uint64_t result = type metadata accessor for Dropout(319);
        if (v7 <= 0x3F)
        {
          uint64_t v8 = *(void *)(result - 8) + 64;
          v12[3] = v8;
          uint64_t result = type metadata accessor for MLActivityClassifier.LSTMBlock(319);
          if (v9 <= 0x3F)
          {
            v12[4] = *(void *)(result - 8) + 64;
            void v12[5] = v4;
            uint64_t result = type metadata accessor for BatchNorm(319);
            if (v10 <= 0x3F)
            {
              v12[6] = *(void *)(result - 8) + 64;
              v12[7] = v6;
              v12[8] = v8;
              v12[9] = v4;
              v12[10] = (char *)&value witness table for Builtin.Int64 + 64;
              v12[11] = (char *)&value witness table for Builtin.BridgeObject + 64;
              uint64_t result = type metadata accessor for MLActivityClassifier.Configuration(319);
              if (v11 <= 0x3F)
              {
                v12[12] = *(void *)(result - 8) + 64;
                v12[13] = "\b";
                v12[14] = &unk_34A018;
                swift_initStructMetadata(a1, 256, 15, v12, a1 + 16);
                return 0;
              }
            }
          }
        }
      }
    }
  }
  return result;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDyS2SG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg5077_s8CreateML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG56VG13renamedInputstAN_SDyS2SGtKFAMSS3key_SS5valuet_tXEfU_SDySSAIGTf1cn_n(uint64_t a1, uint64_t a2)
{
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for FeatureType(0) - 8) + 64);
  unint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v48 = &v40;
  uint64_t v7 = type metadata accessor for FeatureDescription(0);
  uint64_t v52 = *(void *)(v7 - 8);
  int64_t v8 = *(void *)(v52 + 64);
  unint64_t v9 = alloca(v8);
  unint64_t v10 = alloca(v8);
  uint64_t v49 = &v40;
  unint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  int64_t v13 = *(void *)(a1 + 16);
  if (v13)
  {
    uint64_t v51 = v2;
    uint64_t v53 = a1;
    uint64_t v54 = v7;
    uint64_t v55 = &v40;
    int64_t v57 = _swiftEmptyArrayStorage;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v13, 0);
    uint64_t v58 = v57;
    uint64_t v14 = v53;
    int64_t v15 = specialized Dictionary.startIndex.getter(v53);
    uint64_t v17 = v52;
    if (v15 < 0 || v15 >= 1 << *(unsigned char *)(v14 + 32)) {
LABEL_27:
    }
      BUG();
    uint64_t v18 = v14 + 64;
    uint64_t v56 = a2;
    uint64_t v50 = v14 + 64;
    while (1)
    {
      uint64_t v19 = *(void *)(v18 + 8 * ((unint64_t)v15 >> 6));
      if (!_bittest64(&v19, v15)) {
        BUG();
      }
      if (v16 != *(_DWORD *)(v14 + 36)) {
        BUG();
      }
      if (!*(void *)(a2 + 16)) {
        BUG();
      }
      uint64_t v43 = 1 << v15;
      unint64_t v42 = (unint64_t)v15 >> 6;
      uint64_t v46 = v16;
      int64_t v47 = v13;
      int64_t v40 = v15;
      uint64_t v20 = 16 * v15;
      uint64_t v21 = *(void *)(v14 + 48);
      uint64_t v22 = *(void *)(v14 + 56);
      uint64_t v41 = *(void *)(v21 + v20);
      uint64_t v23 = *(void *)(v21 + v20 + 8);
      uint64_t v24 = a2;
      uint64_t v25 = *(void *)(v22 + v20 + 8);
      uint64_t v59 = *(void *)(v22 + v20);
      swift_bridgeObjectRetain_n(v23, 2);
      swift_bridgeObjectRetain(v25);
      unint64_t v26 = specialized __RawDictionaryStorage.find<A>(_:)(v59, v25);
      if ((v27 & 1) == 0) {
        BUG();
      }
      uint64_t v59 = *(void *)(v17 + 72);
      uint64_t v28 = *(void *)(v24 + 56) + v59 * v26;
      uint64_t v29 = v49;
      uint64_t v45 = v23;
      uint64_t v30 = v54;
      (*(void (**)(int64_t *, uint64_t, uint64_t))(v17 + 16))(v49, v28, v54);
      uint64_t v44 = v25;
      uint64_t v31 = v48;
      FeatureDescription.type.getter();
      (*(void (**)(int64_t *, uint64_t))(v17 + 8))(v29, v30);
      size_t v32 = v55;
      char v33 = v45;
      FeatureDescription.init(name:type:description:)(v41, v45, v31, 0, 0xE000000000000000);
      swift_bridgeObjectRelease(v44);
      swift_bridgeObjectRelease(v33);
      uint64_t v34 = v30;
      uint64_t v35 = v58;
      int64_t v57 = v58;
      unint64_t v36 = v58[2];
      if (v58[3] >> 1 <= v36)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v58[3] >= 2uLL, v36 + 1, 1);
        size_t v32 = v55;
        uint64_t v34 = v54;
        uint64_t v35 = v57;
      }
      v35[2] = v36 + 1;
      uint64_t v17 = v52;
      int v37 = *(unsigned __int8 *)(v52 + 80);
      uint64_t v58 = v35;
      (*(void (**)(unint64_t, int64_t *, uint64_t))(v52 + 32))((unint64_t)v35 + ((v37 + 32) & ~v37) + v59 * v36, v32, v34);
      uint64_t v14 = v53;
      uint64_t v38 = -1 << *(unsigned char *)(v53 + 32);
      if (v40 >= -v38) {
        BUG();
      }
      uint64_t v18 = v50;
      if ((v43 & *(void *)(v50 + 8 * v42)) == 0) {
        BUG();
      }
      if (v46 != *(_DWORD *)(v53 + 36)) {
        BUG();
      }
      int64_t v15 = _HashTable.occupiedBucket(after:)(v40, v50, ~v38);
      int64_t v13 = v47 - 1;
      if (v47 == 1) {
        break;
      }
      a2 = v56;
      if (v15 >= 0)
      {
        uint64_t v16 = *(unsigned int *)(v14 + 36);
        if (v15 < 1 << *(unsigned char *)(v14 + 32)) {
          continue;
        }
      }
      goto LABEL_27;
    }
    swift_bridgeObjectRelease(v56);
    return v58;
  }
  else
  {
    swift_bridgeObjectRelease(a2);
    return _swiftEmptyArrayStorage;
  }
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSD6ValuesVyS2S_G_20MLModelSpecification18FeatureDescriptionVs5NeverOTg5077_s8CreateML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20ef17ADV5model_SayAI18gH41VG13renamedInputstAN_SDyS2SGtKFAMSSXEfU0_SDySSAKGTf1cn_n(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = a1;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureDescription?)
                             - 8)
                 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v43 = &v33;
  uint64_t v8 = type metadata accessor for FeatureDescription(0);
  uint64_t v9 = *(void *)(v8 - 8);
  int64_t v10 = *(void *)(v9 + 64);
  unint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  int64_t v13 = *(void *)(a1 + 16);
  if (v13)
  {
    unint64_t v42 = &v33;
    uint64_t v45 = v9;
    uint64_t v47 = v8;
    uint64_t v41 = v2;
    uint64_t v48 = a2;
    uint64_t v44 = _swiftEmptyArrayStorage;
    int64_t v14 = v13;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v13, 0);
    uint64_t v46 = v44;
    uint64_t v15 = v48;
    int64_t v16 = specialized Dictionary.Values.startIndex.getter(a1);
    if (v16 < 0 || v16 >= 1 << *(unsigned char *)(a1 + 32)) {
LABEL_22:
    }
      BUG();
    uint64_t v18 = a1 + 64;
    uint64_t v39 = a1;
    uint64_t v40 = a1 + 64;
    while (1)
    {
      uint64_t v19 = *(void *)(v18 + 8 * ((unint64_t)v16 >> 6));
      if (!_bittest64(&v19, v16)) {
        BUG();
      }
      if (v17 != *(_DWORD *)(v4 + 36)) {
        BUG();
      }
      uint64_t v36 = 1 << v16;
      unint64_t v35 = (unint64_t)v16 >> 6;
      uint64_t v37 = v17;
      int64_t v38 = v14;
      uint64_t v20 = *(void *)(v4 + 56);
      uint64_t v21 = *(void *)(v20 + 16 * v16 + 8);
      if (!*(void *)(v15 + 16))
      {
        __swift_storeEnumTagSinglePayload((uint64_t)v43, 1, 1, v47);
        swift_bridgeObjectRetain(v21);
LABEL_29:
        BUG();
      }
      int64_t v33 = v16;
      uint64_t v22 = *(void *)(16 * v16 + v20);
      swift_bridgeObjectRetain_n(v21, 2);
      unint64_t v23 = specialized __RawDictionaryStorage.find<A>(_:)(v22, v21);
      uint64_t v25 = 1;
      uint64_t v26 = (uint64_t)v43;
      if (v24)
      {
        (*(void (**)(int64_t *, unint64_t, uint64_t))(v45 + 16))(v43, *(void *)(v48 + 56) + *(void *)(v45 + 72) * v23, v47);
        uint64_t v25 = 0;
      }
      uint64_t v27 = v47;
      __swift_storeEnumTagSinglePayload(v26, v25, 1, v47);
      swift_bridgeObjectRelease(v21);
      if (__swift_getEnumTagSinglePayload(v26, 1, v27) == 1) {
        goto LABEL_29;
      }
      uint64_t v34 = *(void (**)(int64_t *, uint64_t, uint64_t))(v45 + 32);
      v34(v42, v26, v27);
      swift_bridgeObjectRelease(v21);
      uint64_t v28 = v46;
      uint64_t v44 = v46;
      unint64_t v29 = v46[2];
      uint64_t v15 = v48;
      if (v46[3] >> 1 <= v29)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v46[3] >= 2uLL, v29 + 1, 1);
        uint64_t v15 = v48;
        uint64_t v28 = v44;
      }
      v28[2] = v29 + 1;
      int v30 = *(unsigned __int8 *)(v45 + 80);
      uint64_t v46 = v28;
      v34((void *)((char *)v28 + ((v30 + 32) & ~v30) + *(void *)(v45 + 72) * v29), (uint64_t)v42, v27);
      uint64_t v4 = v39;
      uint64_t v31 = -1 << *(unsigned char *)(v39 + 32);
      if (v33 >= -v31) {
        BUG();
      }
      uint64_t v18 = v40;
      if ((v36 & *(void *)(v40 + 8 * v35)) == 0) {
        BUG();
      }
      if (v37 != *(_DWORD *)(v39 + 36)) {
        BUG();
      }
      int64_t v16 = _HashTable.occupiedBucket(after:)(v33, v40, ~v31);
      int64_t v14 = v38 - 1;
      if (v38 == 1) {
        break;
      }
      if (v16 >= 0)
      {
        uint64_t v17 = *(unsigned int *)(v4 + 36);
        if (v16 < 1 << *(unsigned char *)(v4 + 32)) {
          continue;
        }
      }
      goto LABEL_22;
    }
    swift_bridgeObjectRelease(v15);
    return v46;
  }
  else
  {
    swift_bridgeObjectRelease(a2);
    return _swiftEmptyArrayStorage;
  }
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDyS2SG_20MLModelSpecification13NeuralNetworkV5LayerVs5NeverOTg5077_s8CreateML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de70ADV5model_SayAI18FeatureDescriptionVG13renamedInputstAN_SDyS2SGtKFAI13fgoH25VSS3key_SS5valuet_tXEfU1_Tf1cn_n(uint64_t a1)
{
  uint64_t v2 = a1;
  uint64_t v27 = type metadata accessor for NeuralNetwork.Layer(0);
  uint64_t v28 = *(void *)(v27 - 8);
  int64_t v3 = *(void *)(v28 + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  int64_t v6 = *(void *)(a1 + 16);
  if (!v6) {
    return _swiftEmptyArrayStorage;
  }
  uint64_t v30 = v1;
  uint64_t v34 = _swiftEmptyArrayStorage;
  int64_t v33 = v6;
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v6, 0);
  uint64_t v36 = _swiftEmptyArrayStorage;
  int64_t v7 = specialized Dictionary.startIndex.getter(a1);
  if (v7 < 0 || v7 >= 1 << *(unsigned char *)(a1 + 32)) {
LABEL_24:
  }
    BUG();
  uint64_t v35 = a1 + 64;
  size_t v32 = &v22;
  uint64_t v29 = a1;
  while (1)
  {
    unint64_t v9 = (unint64_t)v7 >> 6;
    uint64_t v10 = *(void *)(v35 + 8 * ((unint64_t)v7 >> 6));
    if (!_bittest64(&v10, v7)) {
      BUG();
    }
    if (v8 != *(_DWORD *)(v2 + 36)) {
      BUG();
    }
    uint64_t v25 = 1 << v7;
    uint64_t v26 = v8;
    uint64_t v11 = *(void *)(v2 + 48);
    uint64_t v12 = *(void *)(v2 + 56);
    uint64_t v23 = *(void *)(v11 + 16 * v7);
    uint64_t v13 = *(void *)(v11 + 16 * v7 + 8);
    uint64_t v24 = *(void *)(v12 + 16 * v7);
    uint64_t v14 = v24;
    uint64_t v15 = *(void **)(v12 + 16 * v7 + 8);
    strcpy((char *)v31, "__activation_");
    HIWORD(v31[1]) = -4864;
    int64_t v22 = v7;
    swift_bridgeObjectRetain(v13);
    swift_bridgeObjectRetain((_BYTE)v15);
    v16._uint64_t countAndFlagsBits = v14;
    v16._unsigned __int8 object = v15;
    String.append(_:)(v16);
    LOBYTE(v14) = v31[1];
    static NeuralNetwork.Layer.linearActivation(name:inputName:outputName:scale:offset:)(v31[0], v31[1], v23, v13, v24, v15, 1.0, 0.0);
    swift_bridgeObjectRelease((_BYTE)v15);
    swift_bridgeObjectRelease(v13);
    uint64_t v17 = v36;
    swift_bridgeObjectRelease(v14);
    uint64_t v34 = v17;
    unint64_t v18 = v17[2];
    uint64_t v36 = v17;
    if (v17[3] >> 1 <= v18)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v17[3] >= 2uLL, v18 + 1, 1);
      uint64_t v36 = v34;
    }
    uint64_t v19 = (char *)v36;
    v36[2] = v18 + 1;
    (*(void (**)(char *, int64_t *, uint64_t))(v28 + 32))(&v19[((*(unsigned __int8 *)(v28 + 80) + 32) & ~*(unsigned __int8 *)(v28 + 80)) + *(void *)(v28 + 72) * v18], v32, v27);
    uint64_t v2 = v29;
    uint64_t v20 = -1 << *(unsigned char *)(v29 + 32);
    if (v22 >= -v20) {
      BUG();
    }
    if ((v25 & *(void *)(v35 + 8 * v9)) == 0) {
      BUG();
    }
    if (v26 != *(_DWORD *)(v29 + 36)) {
      BUG();
    }
    int64_t v7 = _HashTable.occupiedBucket(after:)(v22, v35, ~v20);
    if (v33 == 1) {
      return v36;
    }
    --v33;
    if (v7 >= 0)
    {
      uint64_t v8 = *(unsigned int *)(v2 + 36);
      if (v7 < 1 << *(unsigned char *)(v2 + 32)) {
        continue;
      }
    }
    goto LABEL_24;
  }
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay20MLModelSpecification18FeatureDescriptionVG_AHs5NeverOTg5077_s8CreateML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG40VG13renamedInputstAN_SDyS2SGtKFA2MXEfU2_SDyS2SGSDySSAHGTf1cn_n(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v47 = v3;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureDescription?)
                             - 8)
                 + 64);
  int64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v46 = &v40;
  uint64_t v52 = type metadata accessor for FeatureDescription(0);
  uint64_t v9 = *(void *)(v52 - 8);
  int64_t v10 = *(void *)(v9 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v48 = &v40;
  int64_t v13 = *(void *)(a1 + 16);
  if (v13)
  {
    uint64_t v44 = a2;
    uint64_t v51 = a3;
    uint64_t v53 = _swiftEmptyArrayStorage;
    int64_t v41 = v13;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v13, 0);
    uint64_t v50 = v53;
    uint64_t v42 = (*(unsigned __int8 *)(v9 + 80) + 32) & ~*(unsigned __int8 *)(v9 + 80);
    uint64_t v14 = v42 + a1;
    uint64_t v43 = *(void *)(v9 + 72);
    uint64_t v49 = v9;
    do
    {
      uint64_t v15 = FeatureDescription.name.getter();
      char v17 = v16;
      uint64_t v18 = v44;
      BOOL v19 = *(void *)(v44 + 16) == 0;
      uint64_t v40 = v14;
      if (v19 || (unint64_t v20 = specialized __RawDictionaryStorage.find<A>(_:)(v15, v16), (v21 & 1) == 0))
      {
        swift_bridgeObjectRelease(v17);
        uint64_t v30 = v52;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v49 + 16))(v48, v14, v52);
        size_t v32 = v50;
      }
      else
      {
        uint64_t v22 = *(void *)(v18 + 56);
        uint64_t v23 = 16 * v20;
        uint64_t v24 = *(void *)(v22 + v23);
        uint64_t v45 = *(void *)(v22 + v23 + 8);
        swift_bridgeObjectRetain(v45);
        swift_bridgeObjectRelease(v17);
        uint64_t v25 = 1;
        uint64_t v26 = v49;
        if (*(void *)(v51 + 16))
        {
          unint64_t v27 = specialized __RawDictionaryStorage.find<A>(_:)(v24, v45);
          uint64_t v25 = 1;
          if (v28)
          {
            (*(void (**)(uint64_t *, unint64_t, uint64_t))(v26 + 16))(v46, *(void *)(v51 + 56) + v43 * v27, v52);
            uint64_t v25 = 0;
          }
        }
        uint64_t v29 = (uint64_t)v46;
        uint64_t v30 = v52;
        __swift_storeEnumTagSinglePayload((uint64_t)v46, v25, 1, v52);
        swift_bridgeObjectRelease(v45);
        int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v29, 1, v30);
        size_t v32 = v50;
        if (EnumTagSinglePayload == 1) {
          BUG();
        }
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v26 + 32))(v48, v29, v30);
      }
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v32);
      uint64_t v53 = v32;
      if (!isUniquelyReferenced_nonNull_native)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v32[2] + 1, 1);
        uint64_t v30 = v52;
        size_t v32 = v53;
      }
      unint64_t v34 = v32[2];
      if (v32[3] >> 1 <= v34)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v32[3] >= 2uLL, v34 + 1, 1);
        uint64_t v30 = v52;
        size_t v32 = v53;
      }
      v32[2] = v34 + 1;
      uint64_t v35 = (char *)v32 + v42;
      uint64_t v36 = v32;
      uint64_t v37 = v43;
      (*(void (**)(char *, uint64_t *, uint64_t))(v49 + 32))(&v35[v43 * v34], v48, v30);
      uint64_t v50 = v36;
      uint64_t v53 = v36;
      uint64_t v14 = v37 + v40;
      --v41;
    }
    while (v41);
    swift_bridgeObjectRelease(v44);
    LOBYTE(a3) = v51;
    int64_t v38 = v50;
  }
  else
  {
    swift_bridgeObjectRelease(a2);
    int64_t v38 = _swiftEmptyArrayStorage;
  }
  swift_bridgeObjectRelease(a3);
  return v38;
}

char specialized Sequence.allSatisfy(_:)(uint64_t a1, uint64_t (*a2)(uint64_t, uint64_t, char *), uint64_t a3)
{
  uint64_t v28 = a3;
  uint64_t v29 = a2;
  uint64_t v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: String, value: Tensor));
  int64_t v3 = *(void *)(*(void *)(v30 - 8) + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  uint64_t v31 = v26;
  specialized _NativeDictionary.makeIterator()(a1);
  uint64_t v36 = v26[0];
  uint64_t v35 = v26[1];
  uint64_t v6 = v26[3];
  unint64_t v7 = v26[4];
  int64_t v34 = (unint64_t)(v26[2] + 64) >> 6;
  swift_bridgeObjectRetain(a1);
  while (v7)
  {
    _BitScanForward64(&v8, v7);
    uint64_t v33 = (v7 - 1) & v7;
    int64_t v32 = v6;
    unint64_t v9 = v8 | (v6 << 6);
LABEL_21:
    uint64_t v15 = *(void *)(v36 + 48);
    uint64_t v16 = *(void *)(v36 + 56);
    uint64_t v17 = *(void *)(v15 + 16 * v9);
    uint64_t v27 = *(void *)(v15 + 16 * v9 + 8);
    uint64_t v18 = type metadata accessor for Tensor(0);
    uint64_t v19 = *(void *)(v18 - 8);
    uint64_t v20 = v16 + *(void *)(v19 + 72) * v9;
    uint64_t v21 = v30;
    uint64_t v22 = v31;
    (*(void (**)(char *, uint64_t, uint64_t))(v19 + 16))((char *)v31 + *(int *)(v30 + 48), v20, v18);
    *uint64_t v22 = v17;
    uint64_t v23 = v27;
    v22[1] = v27;
    uint64_t v24 = (char *)v22 + *(int *)(v21 + 48);
    swift_bridgeObjectRetain(v23);
    LOBYTE(v24) = v29(v17, v23, v24);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v22, &demangling cache variable for type metadata for (key: String, value: Tensor));
    uint64_t v6 = v32;
    unint64_t v7 = v33;
    if ((v24 & 1) == 0)
    {
      swift_release();
      return 0;
    }
  }
  int64_t v10 = v6 + 1;
  if (__OFADD__(1, v6)) {
    BUG();
  }
  if (v10 >= v34) {
    goto LABEL_23;
  }
  unint64_t v11 = *(void *)(v35 + 8 * v10);
  if (v11)
  {
    int64_t v12 = v6 + 1;
LABEL_20:
    _BitScanForward64(&v14, v11);
    uint64_t v33 = v11 & (v11 - 1);
    unint64_t v9 = v14 + (v12 << 6);
    int64_t v32 = v12;
    goto LABEL_21;
  }
  int64_t v12 = v6 + 2;
  if (v6 + 2 >= v34) {
    goto LABEL_23;
  }
  unint64_t v11 = *(void *)(v35 + 8 * v10 + 8);
  if (v11) {
    goto LABEL_20;
  }
  int64_t v12 = v6 + 3;
  if (v6 + 3 >= v34) {
    goto LABEL_23;
  }
  unint64_t v11 = *(void *)(v35 + 8 * v10 + 16);
  if (v11) {
    goto LABEL_20;
  }
  int64_t v12 = v6 + 4;
  if (v6 + 4 >= v34) {
    goto LABEL_23;
  }
  unint64_t v11 = *(void *)(v35 + 8 * v10 + 24);
  if (v11) {
    goto LABEL_20;
  }
  int64_t v12 = v6 + 5;
  if (v6 + 5 >= v34) {
    goto LABEL_23;
  }
  unint64_t v11 = *(void *)(v35 + 8 * v10 + 32);
  if (v11) {
    goto LABEL_20;
  }
  int64_t v13 = v6 + 6;
  while (v13 < v34)
  {
    unint64_t v11 = *(void *)(v35 + 8 * v13++);
    if (v11)
    {
      int64_t v12 = v13 - 1;
      goto LABEL_20;
    }
  }
LABEL_23:
  swift_release();
  return 1;
}

uint64_t specialized Sequence.first(where:)(uint64_t a1)
{
  uint64_t v35 = v1;
  uint64_t v36 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: String, value: Tensor));
  int64_t v2 = *(void *)(*(void *)(v36 - 8) + 64);
  int64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v31 = v30;
  int64_t v5 = alloca(v2);
  uint64_t v6 = alloca(v2);
  int64_t v32 = v30;
  specialized _NativeDictionary.makeIterator()(a1);
  uint64_t v37 = v30[1];
  uint64_t v39 = v30[2];
  uint64_t v7 = v30[4];
  unint64_t v8 = v30[5];
  int64_t v38 = (unint64_t)(v30[3] + 64) >> 6;
  swift_bridgeObjectRetain(a1);
  while (1)
  {
    if (v8)
    {
      _BitScanForward64(&v9, v8);
      uint64_t v34 = (v8 - 1) & v8;
      unint64_t v10 = v9 | (v7 << 6);
      int64_t v33 = v7;
    }
    else
    {
      int64_t v11 = v7 + 1;
      if (__OFADD__(1, v7)) {
        BUG();
      }
      if (v11 >= v38) {
        goto LABEL_25;
      }
      unint64_t v12 = *(void *)(v39 + 8 * v11);
      if (v12)
      {
        int64_t v13 = v7 + 1;
      }
      else
      {
        int64_t v13 = v7 + 2;
        if (v7 + 2 >= v38) {
          goto LABEL_25;
        }
        unint64_t v12 = *(void *)(v39 + 8 * v11 + 8);
        if (!v12)
        {
          int64_t v13 = v7 + 3;
          if (v7 + 3 >= v38) {
            goto LABEL_25;
          }
          unint64_t v12 = *(void *)(v39 + 8 * v11 + 16);
          if (!v12)
          {
            int64_t v13 = v7 + 4;
            if (v7 + 4 >= v38) {
              goto LABEL_25;
            }
            unint64_t v12 = *(void *)(v39 + 8 * v11 + 24);
            if (!v12)
            {
              int64_t v13 = v7 + 5;
              if (v7 + 5 >= v38) {
                goto LABEL_25;
              }
              unint64_t v12 = *(void *)(v39 + 8 * v11 + 32);
              if (!v12)
              {
                int64_t v14 = v7 + 6;
                while (v14 < v38)
                {
                  unint64_t v12 = *(void *)(v39 + 8 * v14++);
                  if (v12)
                  {
                    int64_t v13 = v14 - 1;
                    goto LABEL_20;
                  }
                }
LABEL_25:
                swift_release();
                uint64_t v26 = v35;
                uint64_t v27 = 1;
                return __swift_storeEnumTagSinglePayload(v26, v27, 1, v36);
              }
            }
          }
        }
      }
LABEL_20:
      _BitScanForward64(&v15, v12);
      uint64_t v34 = v12 & (v12 - 1);
      int64_t v33 = v13;
      unint64_t v10 = v15 + (v13 << 6);
    }
    uint64_t v16 = *(void *)(v37 + 48);
    uint64_t v17 = *(void *)(v37 + 56);
    uint64_t v18 = *(void *)(v16 + 16 * v10);
    uint64_t v19 = *(void *)(v16 + 16 * v10 + 8);
    uint64_t v20 = type metadata accessor for Tensor(0);
    uint64_t v21 = *(void *)(v20 - 8);
    uint64_t v22 = v17 + *(void *)(v21 + 72) * v10;
    uint64_t v23 = v32;
    (*(void (**)(char *, uint64_t, uint64_t))(v21 + 16))((char *)v32 + *(int *)(v36 + 48), v22, v20);
    *uint64_t v23 = v18;
    v23[1] = v19;
    uint64_t v24 = v31;
    outlined init with take of LSTM.State?((uint64_t)v23, (uint64_t)v31, &demangling cache variable for type metadata for (key: String, value: Tensor));
    uint64_t v25 = v24[1];
    if ((*v24 != 0x6E496574617473 || v25 != 0xE700000000000000)
      && (_stringCompareWithSmolCheck(_:_:expecting:)(*v24, v25, 0x6E496574617473, 0xE700000000000000, 0) & 1) == 0)
    {
      break;
    }
    swift_bridgeObjectRetain(v19);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v24, &demangling cache variable for type metadata for (key: String, value: Tensor));
    uint64_t v7 = v33;
    unint64_t v8 = v34;
  }
  swift_bridgeObjectRetain(v19);
  swift_release();
  uint64_t v28 = v35;
  outlined init with take of LSTM.State?((uint64_t)v24, v35, &demangling cache variable for type metadata for (key: String, value: Tensor));
  uint64_t v26 = v28;
  uint64_t v27 = 0;
  return __swift_storeEnumTagSinglePayload(v26, v27, 1, v36);
}

uint64_t specialized Sequence.contains(where:)(uint64_t a1, uint64_t a2, unint64_t a3)
{
  uint64_t v3 = a1;
  uint64_t v4 = HIBYTE(a3) & 0xF;
  if ((a3 & 0x2000000000000000) == 0) {
    uint64_t v4 = a2 & 0xFFFFFFFFFFFFLL;
  }
  uint64_t v18 = a2;
  unint64_t v19 = a3;
  uint64_t v20 = 0;
  uint64_t v21 = v4;
  swift_bridgeObjectRetain(a3);
  uint64_t v5 = a1 + 1;
  if (__OFADD__(1, a1)) {
LABEL_25:
  }
    BUG();
  while (1)
  {
    uint64_t v22 = v3;
    Swift::String_optional v6 = String.Iterator.next()();
    unsigned __int8 object = v6.value._object;
    if (!v6.value._object) {
      break;
    }
    uint64_t countAndFlagsBits = v6.value._countAndFlagsBits;
    if ((v6.value._countAndFlagsBits != 2573 || v6.value._object != (void *)0xE200000000000000)
      && (_stringCompareWithSmolCheck(_:_:expecting:)(v6.value._countAndFlagsBits, v6.value._object, 2573, 0xE200000000000000, 0) & 1) == 0)
    {
      if ((Character._isSingleScalar.getter(countAndFlagsBits, object, v9, v10, v11, v12, v18, v19, v20, v21) & 1) == 0) {
        goto LABEL_23;
      }
      unint64_t v13 = specialized Collection.first.getter(countAndFlagsBits, (unint64_t)object);
      if ((v13 & 0x100000000) != 0) {
        BUG();
      }
      if ((v13 & 0xFFFFFF80) != 0)
      {
LABEL_23:
        swift_bridgeObjectRelease((_BYTE)object);
        break;
      }
      unint64_t v14 = specialized Collection.first.getter(countAndFlagsBits, (unint64_t)object);
      if ((v14 & 0x100000000) != 0) {
        BUG();
      }
      if ((v14 & 0xFFFFFF00) != 0) {
        BUG();
      }
    }
    if ((Character.isLetter.getter(countAndFlagsBits, object) & 1) != 0
      || v22 > 0 && (Character.isNumber.getter(countAndFlagsBits, object) & 1) != 0
      || countAndFlagsBits == 95 && object == (void *)0xE100000000000000)
    {
      swift_bridgeObjectRelease((_BYTE)object);
    }
    else
    {
      char v16 = _stringCompareWithSmolCheck(_:_:expecting:)(countAndFlagsBits, object, 95, 0xE100000000000000, 0);
      swift_bridgeObjectRelease((_BYTE)object);
      if ((v16 & 1) == 0) {
        break;
      }
    }
    uint64_t v3 = v5;
    if (__OFADD__(1, v5++)) {
      goto LABEL_25;
    }
  }
  LOBYTE(v5) = object != 0;
  swift_bridgeObjectRelease(v19);
  return v5;
}

uint64_t MLActivityClassifier.InputBlock.forward(_:)(uint64_t a1, double a2)
{
  uint64_t v4 = v3;
  uint64_t v32 = v2;
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for MLActivityClassifier.InputBlock(0) - 8) + 64);
  Swift::String_optional v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v28 = type metadata accessor for TensorShape(0);
  uint64_t v29 = *(void *)(v28 - 8);
  int64_t v8 = *(void *)(v29 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v30 = &v28;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v31 = a1;
  Tensor.shape.getter();
  uint64_t v13 = TensorShape.dimensions.getter();
  uint64_t v14 = *(void *)(v13 + 16);
  swift_bridgeObjectRelease(v13);
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v4, (uint64_t)&v28, type metadata accessor for MLActivityClassifier.InputBlock);
  if (v14 != 1)
  {
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v28, type metadata accessor for MLActivityClassifier.InputBlock);
    goto LABEL_9;
  }
  char v15 = LearningPhase.isTraining.getter();
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v28, type metadata accessor for MLActivityClassifier.InputBlock);
  if (v15)
  {
LABEL_9:
    uint64_t v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
    uint64_t v22 = (void *)swift_allocObject(v23, 64, 7);
    v22[2] = 4;
    v22[3] = 8;
    v22[4] = TensorShape.subscript.getter(0);
    v22[5] = TensorShape.subscript.getter(1);
    v22[6] = 1;
    v22[7] = TensorShape.subscript.getter(2);
    goto LABEL_10;
  }
  uint64_t v16 = TensorShape.subscript.getter(0);
  unint64_t v17 = *v4;
  unint64_t v18 = v4[1];
  uint64_t v19 = v18 * *v4;
  if (!is_mul_ok(v18, *v4)) {
    BUG();
  }
  if (!v19) {
    BUG();
  }
  if (v16 == 0x8000000000000000 && v19 == -1) {
    BUG();
  }
  uint64_t v20 = v16 / v19;
  uint64_t v21 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v22 = (void *)swift_allocObject(v21, 64, 7);
  v22[2] = 4;
  v22[3] = 8;
  v22[4] = v20;
  v22[5] = v17;
  v22[6] = 1;
  v22[7] = v18;
LABEL_10:
  uint64_t v24 = v30;
  TensorShape.init(_:)(v22, a2);
  Tensor.reshaped(to:)(v24);
  uint64_t v25 = *(void (**)(uint64_t *, uint64_t))(v29 + 8);
  uint64_t v26 = v28;
  v25(v24, v28);
  return ((uint64_t (*)(uint64_t *, uint64_t))v25)(&v28, v26);
}

uint64_t protocol witness for Layer.isEveryParameterInitialized.getter in conformance MLActivityClassifier.InputBlock()
{
  return Layer.isEveryParameterInitialized.getter();
}

uint64_t protocol witness for Layer.initializeParameters(for:) in conformance MLActivityClassifier.InputBlock()
{
  return Layer.initializeParameters(for:)();
}

uint64_t protocol witness for Layer.forward(_:) in conformance MLActivityClassifier.InputBlock(uint64_t a1, double a2)
{
  return MLActivityClassifier.InputBlock.forward(_:)(a1, a2);
}

uint64_t protocol witness for LearningPhaseSensitive.learningPhase.getter in conformance MLActivityClassifier.InputBlock(uint64_t a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = v2 + *(int *)(a1 + 24);
  uint64_t v5 = type metadata accessor for LearningPhase(0);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16))(v3, v4, v5);
}

uint64_t protocol witness for LearningPhaseSensitive.learningPhase.setter in conformance MLActivityClassifier.InputBlock(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2 + *(int *)(a2 + 24);
  uint64_t v4 = type metadata accessor for LearningPhase(0);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 40))(v3, a1, v4);
}

void (*protocol witness for LearningPhaseSensitive.learningPhase.modify in conformance MLActivityClassifier.InputBlock())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t protocol witness for _ComputeDevicePlaceable.place(on:) in conformance MLActivityClassifier.InputBlock(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.InputBlock and conformance MLActivityClassifier.InputBlock, type metadata accessor for MLActivityClassifier.InputBlock, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.InputBlock);
  return Layer.place(on:)(a1, a2, v2);
}

uint64_t protocol witness for _ComputeDevicePlaceable.placed(on:) in conformance MLActivityClassifier.InputBlock(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.InputBlock and conformance MLActivityClassifier.InputBlock, type metadata accessor for MLActivityClassifier.InputBlock, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.InputBlock);
  return Layer.placed(on:)(a1, a2, v2);
}

uint64_t MLActivityClassifier.LSTMBlock.forward(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v49 = v4;
  uint64_t v48 = a4;
  uint64_t v59 = a3;
  uint64_t v40 = a2;
  uint64_t v41 = a1;
  uint64_t v42 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for RecurrentLayerInput<LSTM.State>);
  uint64_t v43 = *(void *)(v42 - 8);
  int64_t v5 = *(void *)(v43 + 64);
  Swift::String_optional v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v46 = v39;
  uint64_t v54 = type metadata accessor for LSTM(0);
  uint64_t v55 = *(void *)(v54 - 8);
  int64_t v8 = *(void *)(v55 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v50 = v39;
  uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for RecurrentLayerOutput<LSTM.State>);
  uint64_t v44 = *(void *)(v45 - 8);
  int64_t v11 = *(void *)(v44 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v47 = v39;
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (LSTM.State?, Tensor));
  int64_t v15 = *(void *)(*(void *)(v14 - 8) + 64);
  uint64_t v16 = alloca(v15);
  unint64_t v17 = alloca(v15);
  uint64_t v56 = v39;
  unint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  uint64_t v58 = v39;
  uint64_t v20 = alloca(v15);
  uint64_t v21 = alloca(v15);
  int64_t v57 = v39;
  uint64_t v22 = *(int *)(v14 + 48);
  uint64_t v53 = v14;
  uint64_t v23 = &v39[v22];
  uint64_t v51 = v23;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v59, (uint64_t)v39, &demangling cache variable for type metadata for LSTM.State?);
  uint64_t v24 = type metadata accessor for Tensor(0);
  uint64_t v59 = *(void *)(v24 - 8);
  uint64_t v25 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v59 + 16);
  v25(v23, v48, v24);
  uint64_t v26 = (void (*)(unsigned char *, unsigned char *, uint64_t))v25;
  uint64_t v52 = (void (*)(unsigned char *, unsigned char *, uint64_t))v25;
  uint64_t v27 = type metadata accessor for MLActivityClassifier.LSTMBlock(0);
  (*(void (**)(unsigned char *, uint64_t, uint64_t))(v55 + 16))(v39, v49 + *(int *)(v27 + 32), v54);
  uint64_t v28 = &v58[*(int *)(v14 + 48)];
  uint64_t v29 = (uint64_t)v57;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v57, (uint64_t)v58, &demangling cache variable for type metadata for LSTM.State?);
  uint64_t v30 = v51;
  v26(v28, v51, v24);
  uint64_t v31 = &v56[*(int *)(v53 + 48)];
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v29, (uint64_t)v56, &demangling cache variable for type metadata for LSTM.State?);
  v52(v31, v30, v24);
  uint64_t v32 = type metadata accessor for LSTM.State(0);
  int64_t v33 = v46;
  RecurrentLayerInput.init(input:state:)(v28, v56, v32);
  (*(void (**)(unsigned char *, uint64_t))(v59 + 8))(v31, v24);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v58, &demangling cache variable for type metadata for LSTM.State?);
  uint64_t v34 = v47;
  uint64_t v35 = v54;
  uint64_t v36 = v50;
  Layer.callAsFunction(_:)(v33, v54, &protocol witness table for LSTM);
  (*(void (**)(unsigned char *, uint64_t))(v43 + 8))(v33, v42);
  (*(void (**)(unsigned char *, uint64_t))(v55 + 8))(v36, v35);
  uint64_t v37 = v45;
  RecurrentLayerOutput.state.getter(v45);
  RecurrentLayerOutput.output.getter(v37);
  (*(void (**)(unsigned char *, uint64_t))(v44 + 8))(v34, v37);
  return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v57, &demangling cache variable for type metadata for (LSTM.State?, Tensor));
}

uint64_t protocol witness for Layer.forward(_:) in conformance MLActivityClassifier.LSTMBlock(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return protocol witness for Layer.forward(_:) in conformance MLActivityClassifier.LSTMBlock(a1, a2, a3, MLActivityClassifier.LSTMBlock.forward(_:));
}

uint64_t protocol witness for _ComputeDevicePlaceable.place(on:) in conformance MLActivityClassifier.LSTMBlock(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.LSTMBlock and conformance MLActivityClassifier.LSTMBlock, type metadata accessor for MLActivityClassifier.LSTMBlock, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.LSTMBlock);
  return Layer.place(on:)(a1, a2, v2);
}

uint64_t protocol witness for _ComputeDevicePlaceable.placed(on:) in conformance MLActivityClassifier.LSTMBlock(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.LSTMBlock and conformance MLActivityClassifier.LSTMBlock, type metadata accessor for MLActivityClassifier.LSTMBlock, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.LSTMBlock);
  return Layer.placed(on:)(a1, a2, v2);
}

uint64_t MLActivityClassifier.Model.init(windowSize:features:target:classLabels:randomSeed:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, char a7)
{
  uint64_t v19 = a4;
  uint64_t v20 = a3;
  uint64_t v17 = v7;
  uint64_t v21 = a2;
  uint64_t v16 = a6;
  uint64_t v18 = a5;
  uint64_t v22 = a1;
  HIBYTE(v23) = a7 & 1;
  uint64_t v8 = type metadata accessor for MLActivityClassifier.Configuration(0);
  int64_t v9 = *(void *)(*(void *)(v8 - 8) + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v12 = (char *)&v15 + *(int *)(v8 + 44);
  uint64_t v13 = type metadata accessor for DataFrame(0);
  __swift_storeEnumTagSinglePayload((uint64_t)v12, 1, 1, v13);
  __swift_storeEnumTagSinglePayload((uint64_t)&v15 + *(int *)(v8 + 48), 1, 1, v13);
  uint64_t v15 = 10;
  uint64_t v16 = 0;
  LOBYTE(v17) = 0;
  uint64_t v18 = 32;
  uint64_t v19 = v22;
  uint64_t v20 = v21;
  uint64_t v23 = 0x5F6E6F6973736573;
  unint64_t v24 = 0xEA00000000006469;
  return MLActivityClassifier.Model.init(classLabels:randomSeed:trainingConfiguration:)(32, 0, 0x5Fu, (uint64_t)&v15);
}

uint64_t MLActivityClassifier.Model.init(classLabels:randomSeed:trainingConfiguration:)(uint64_t a1, uint64_t a2, unsigned int a3, uint64_t a4)
{
  uint64_t v52 = a2;
  uint64_t v47 = a1;
  Swift::String_optional v6 = v4;
  LOBYTE(a3) = a3 & 1;
  unsigned int v55 = a3;
  uint64_t v44 = type metadata accessor for MLActivityClassifier.LSTMBlock(0);
  int64_t v7 = *(void *)(*(void *)(v44 - 8) + 64);
  uint64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  uint64_t v54 = &v43;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?)
                              - 8)
                  + 64);
  int64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v48 = &v43;
  uint64_t v13 = (int *)type metadata accessor for MLActivityClassifier.Model(0);
  uint64_t v50 = v13;
  *(void *)((char *)v6 + v13[17]) = 0;
  uint64_t v14 = v13[18];
  *(_OWORD *)((char *)v6 + v14) = 0;
  *(void *)((char *)v6 + v14 + 16) = 0;
  *(void *)((char *)v6 + v13[15]) = a1;
  uint64_t v43 = a4;
  uint64_t v51 = *(void *)(a4 + 32);
  uint64_t v15 = v51;
  uint64_t v16 = *(void *)(*(void *)(a4 + 40) + 16);
  uint64_t v17 = (char *)v6 + *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
  unsigned int v18 = enum case for LearningPhase.automatic(_:);
  uint64_t v19 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, void, uint64_t))(*(void *)(v19 - 8) + 104))(v17, v18, v19);
  void *v6 = v16;
  v6[1] = v15;
  uint64_t v20 = type metadata accessor for ParameterInitializer(0);
  uint64_t v49 = type metadata accessor for ComputeDevice(0);
  uint64_t v21 = (uint64_t)v48;
  __swift_storeEnumTagSinglePayload((uint64_t)v48, 1, 1, v49);
  swift_bridgeObjectRetain(v47);
  unsigned int v55 = v55;
  uint64_t v53 = v20;
  uint64_t v22 = static ParameterInitializer.glorotUniform(seed:scalarType:on:)(v52, v55, &type metadata for Float, &protocol witness table for Float, v21);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v21, &demangling cache variable for type metadata for ComputeDevice?);
  uint64_t v23 = static ParameterInitializer.zeros.getter();
  unint64_t v24 = v50;
  uint64_t v45 = v6;
  Conv2D.init(filterCount:kernelSize:stride:padding:dilation:groupCount:weightInitializer:biasInitializer:)(64, 1, v51, 1, v51, 0, 0, 1, 1, 1, v22, v23);
  ReLU.init()();
  uint64_t v25 = v52;
  LODWORD(v17) = v55;
  Dropout.init(probability:seed:)(v52, v55, 0.2);
  uint64_t v51 = (uint64_t)v6 + v24[8];
  uint64_t v26 = v54;
  *uint64_t v54 = 200;
  v26[1] = 64;
  *((_WORD *)v26 + 8) = 256;
  uint64_t v27 = (uint64_t)v48;
  uint64_t v28 = v49;
  __swift_storeEnumTagSinglePayload((uint64_t)v48, 1, 1, v49);
  uint64_t v46 = static ParameterInitializer.glorotUniform(seed:scalarType:on:)(v25, v17, &type metadata for Float, &protocol witness table for Float, v27);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v27, &demangling cache variable for type metadata for ComputeDevice?);
  __swift_storeEnumTagSinglePayload(v27, 1, 1, v28);
  LODWORD(v28) = v17;
  uint64_t v29 = static ParameterInitializer.glorotUniform(seed:scalarType:on:)(v25, v17, &type metadata for Float, &protocol witness table for Float, v27);
  uint64_t v30 = v27;
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v27, &demangling cache variable for type metadata for ComputeDevice?);
  uint64_t v31 = static ParameterInitializer.zeros.getter();
  uint64_t v32 = (uint64_t)v54;
  LSTM.init(unitCount:recurrentWeightInitializer:inputWeightInitializer:biasInitializer:isBidirectional:)(200, v46, v29, v31, 0);
  outlined init with take of MLClassifierMetrics(v32, v51, type metadata accessor for MLActivityClassifier.LSTMBlock);
  __swift_storeEnumTagSinglePayload(v27, 1, 1, v49);
  uint64_t v33 = static ParameterInitializer.glorotUniform(seed:scalarType:on:)(v52, v28, &type metadata for Float, &protocol witness table for Float, v27);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v27, &demangling cache variable for type metadata for ComputeDevice?);
  uint64_t v34 = static ParameterInitializer.zeros.getter();
  uint64_t v35 = v45;
  Conv2D.init(filterCount:kernelSize:stride:padding:dilation:groupCount:weightInitializer:biasInitializer:)(128, 1, 1, 1, 1, 0, 0, 1, 1, 1, v33, v34);
  uint64_t v36 = static ParameterInitializer.zeros.getter();
  uint64_t v37 = static ParameterInitializer.ones.getter();
  BatchNorm.init(offsetInitializer:scaleInitializer:momentum:epsilon:)(v36, v37, 0.89999998, 0.001);
  ReLU.init()();
  uint64_t v38 = v52;
  LODWORD(v28) = v55;
  Dropout.init(probability:seed:)(v52, v55, 0.5);
  uint64_t v54 = *(uint64_t **)(v47 + 16);
  swift_bridgeObjectRelease(v47);
  __swift_storeEnumTagSinglePayload(v30, 1, 1, v49);
  uint64_t v39 = static ParameterInitializer.glorotUniform(seed:scalarType:on:)(v38, v28, &type metadata for Float, &protocol witness table for Float, v30);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v30, &demangling cache variable for type metadata for ComputeDevice?);
  uint64_t v40 = static ParameterInitializer.zeros.getter();
  uint64_t v41 = v50;
  Conv2D.init(filterCount:kernelSize:stride:padding:dilation:groupCount:weightInitializer:biasInitializer:)(v54, 1, 1, 1, 1, 0, 0, 1, 1, 1, v39, v40);
  *(void *)((char *)v35 + v41[14]) = Softmax.init(axis:)(1);
  return outlined init with take of MLClassifierMetrics(v43, (uint64_t)v35 + v41[16], type metadata accessor for MLActivityClassifier.Configuration);
}

uint64_t MLActivityClassifier.Model.forward(_:)(uint64_t a1, uint64_t a2, uint64_t a3, void (*a4)(void, void))
{
  uint64_t v104 = v4;
  uint64_t v106 = a4;
  uint64_t v85 = a2;
  uint64_t v83 = a1;
  uint64_t v94 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (LSTM.State, Tensor));
  int64_t v6 = *(void *)(*(void *)(v94 - 8) + 64);
  int64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v84 = &v82;
  int64_t v9 = alloca(v6);
  int64_t v10 = alloca(v6);
  BOOL v99 = &v82;
  uint64_t v11 = type metadata accessor for Tensor(0);
  uint64_t v12 = *(void **)(v11 - 8);
  uint64_t v105 = v11;
  int64_t v13 = v12[8];
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v98 = &v82;
  uint64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v101 = &v82;
  unsigned int v18 = alloca(v13);
  uint64_t v19 = alloca(v13);
  uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (LSTM.State?, Tensor));
  uint64_t v21 = *(void *)(v20 - 8);
  uint64_t v90 = v20;
  int64_t v22 = *(void *)(v21 + 64);
  uint64_t v23 = alloca(v22);
  unint64_t v24 = alloca(v22);
  uint64_t v88 = &v82;
  uint64_t v25 = alloca(v22);
  uint64_t v26 = alloca(v22);
  uint64_t v89 = &v82;
  uint64_t v27 = alloca(v22);
  uint64_t v28 = alloca(v22);
  unint64_t v95 = &v82;
  uint64_t v29 = (char *)&v82 + *(int *)(v20 + 48);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a3, (uint64_t)&v82, &demangling cache variable for type metadata for LSTM.State?);
  uint64_t v91 = (void (*)(void, void, void))v12[2];
  uint64_t v30 = v29;
  uint64_t v92 = v29;
  v91(v29, (void (*)(uint64_t *, uint64_t))v106, v11);
  uint64_t v31 = type metadata accessor for MLActivityClassifier.InputBlock(0);
  uint64_t v32 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.InputBlock and conformance MLActivityClassifier.InputBlock, type metadata accessor for MLActivityClassifier.InputBlock, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.InputBlock);
  Layer.callAsFunction(_:)(v30, v31, v32);
  uint64_t v102 = type metadata accessor for MLActivityClassifier.Model(0);
  uint64_t v96 = type metadata accessor for Conv2D(0);
  uint64_t v33 = v101;
  Layer.callAsFunction(_:)(&v82, v96, &protocol witness table for Conv2D);
  uint64_t v106 = (void (*)(void, void))v12[1];
  uint64_t v100 = &v82;
  uint64_t v34 = v105;
  v106(&v82, v105);
  uint64_t v103 = (void (*)(void, void, void))v12[4];
  uint64_t v35 = v33;
  v103(&v82, v33, v34);
  uint64_t v86 = type metadata accessor for ReLU(0);
  uint64_t v36 = v100;
  Layer.callAsFunction(_:)(v100, v86, &protocol witness table for ReLU);
  uint64_t v37 = v36;
  uint64_t v38 = v36;
  uint64_t v39 = v105;
  v106(v38, v105);
  uint64_t v40 = v39;
  uint64_t v41 = v103;
  v103(v37, v35, v40);
  uint64_t v87 = type metadata accessor for Dropout(0);
  uint64_t v42 = v35;
  uint64_t v43 = v100;
  Layer.callAsFunction(_:)(v100, v87, &protocol witness table for Dropout);
  uint64_t v44 = v105;
  v106(v43, v105);
  v41(v43, v42, v44);
  uint64_t v45 = v98;
  Tensor.squeezingShape(at:)(&outlined read-only object #0 of MLActivityClassifier.Model.forward(_:));
  Tensor.transposed(permutation:)(&outlined read-only object #1 of MLActivityClassifier.Model.forward(_:));
  uint64_t v46 = v45;
  uint64_t v47 = v105;
  uint64_t v48 = v106;
  v106(v46, v105);
  v48(v43, v47);
  v41(v43, v101, v47);
  uint64_t v97 = (char *)v99 + *(int *)(v94 + 48);
  uint64_t v93 = v104 + *(int *)(v102 + 32);
  uint64_t v49 = v90;
  uint64_t v50 = (uint64_t)v89;
  uint64_t v51 = (char *)v89 + *(int *)(v90 + 48);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v95, (uint64_t)v89, &demangling cache variable for type metadata for LSTM.State?);
  uint64_t v52 = v91;
  v91(v51, v92, v47);
  uint64_t v53 = (char *)v88 + *(int *)(v49 + 48);
  uint64_t v54 = v50;
  uint64_t v55 = (uint64_t)v88;
  outlined init with take of LSTM.State?(v54, (uint64_t)v88, &demangling cache variable for type metadata for LSTM.State?);
  v52(v53, v100, v47);
  uint64_t v56 = type metadata accessor for MLActivityClassifier.LSTMBlock(0);
  uint64_t v57 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.LSTMBlock and conformance MLActivityClassifier.LSTMBlock, type metadata accessor for MLActivityClassifier.LSTMBlock, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.LSTMBlock);
  Layer.callAsFunction(_:)(v55, v56, v57);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v55, &demangling cache variable for type metadata for (LSTM.State?, Tensor));
  uint64_t v58 = v105;
  v106(v51, v105);
  uint64_t v59 = v98;
  Tensor.transposed(permutation:)(&outlined read-only object #2 of MLActivityClassifier.Model.forward(_:));
  uint64_t v60 = v101;
  Tensor.expandingShape(at:)(&outlined read-only object #3 of MLActivityClassifier.Model.forward(_:));
  uint64_t v61 = v59;
  uint64_t v62 = v106;
  v106(v61, v58);
  uint64_t v63 = v100;
  v62(v100, v58);
  v103(v63, v60, v58);
  Layer.callAsFunction(_:)(v63, v96, &protocol witness table for Conv2D);
  uint64_t v64 = v58;
  v106(v63, v58);
  Swift::String v65 = v101;
  v103(v63, v101, v64);
  uint64_t v66 = type metadata accessor for BatchNorm(0);
  Layer.callAsFunction(_:)(v63, v66, &protocol witness table for BatchNorm);
  uint64_t v67 = v64;
  uint64_t v68 = v64;
  uint64_t v69 = v106;
  v106(v63, v68);
  v103(v63, v65, v67);
  uint64_t v70 = v65;
  Layer.callAsFunction(_:)(v63, v86, &protocol witness table for ReLU);
  uint64_t v71 = v105;
  v69(v63, v105);
  uint64_t v72 = v103;
  v103(v63, v70, v71);
  uint64_t v73 = v101;
  Layer.callAsFunction(_:)(v63, v87, &protocol witness table for Dropout);
  uint64_t v74 = v105;
  v106(v63, v105);
  v72(v63, v73, v74);
  Layer.callAsFunction(_:)(v63, v96, &protocol witness table for Conv2D);
  uint64_t v75 = v105;
  unint64_t v76 = v106;
  v106(v63, v105);
  v103(v63, v73, v75);
  uint64_t v82 = *(void *)(v104 + *(int *)(v102 + 56));
  Layer.callAsFunction(_:)(v63, &type metadata for Softmax, &protocol witness table for Softmax);
  v76(v63, v75);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v95, &demangling cache variable for type metadata for (LSTM.State?, Tensor));
  unint64_t v77 = v84;
  unint64_t v78 = (char *)v84 + *(int *)(v94 + 48);
  uint64_t v79 = type metadata accessor for LSTM.State(0);
  unint64_t v80 = *(void (**)(void, void, void))(*(void *)(v79 - 8) + 32);
  v80(v77, v99, v79);
  v103(v78, v97, v75);
  v80(v83, v77, v79);
  return ((uint64_t (*)(char *, uint64_t))v106)(v78, v75);
}

uint64_t protocol witness for Layer.forward(_:) in conformance MLActivityClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return protocol witness for Layer.forward(_:) in conformance MLActivityClassifier.LSTMBlock(a1, a2, a3, (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t))MLActivityClassifier.Model.forward(_:));
}

uint64_t protocol witness for Layer.forward(_:) in conformance MLActivityClassifier.LSTMBlock(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t (*a4)(uint64_t, uint64_t, uint64_t, uint64_t))
{
  uint64_t v6 = v4;
  uint64_t v7 = a1
     + *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (LSTM.State?, Tensor))
              + 48);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (LSTM.State, Tensor));
  return a4(v6, v6 + *(int *)(v8 + 48), a1, v7);
}

uint64_t protocol witness for _ComputeDevicePlaceable.place(on:) in conformance MLActivityClassifier.Model(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model and conformance MLActivityClassifier.Model, type metadata accessor for MLActivityClassifier.Model, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model);
  return Layer.place(on:)(a1, a2, v2);
}

uint64_t protocol witness for _ComputeDevicePlaceable.placed(on:) in conformance MLActivityClassifier.Model(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model and conformance MLActivityClassifier.Model, type metadata accessor for MLActivityClassifier.Model, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model);
  return Layer.placed(on:)(a1, a2, v2);
}

uint64_t base witness table accessor for _BaseLayer in MLActivityClassifier.InputBlock()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.InputBlock and conformance MLActivityClassifier.InputBlock, type metadata accessor for MLActivityClassifier.InputBlock, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.InputBlock);
}

uint64_t base witness table accessor for _ComputeDevicePlaceable in MLActivityClassifier.InputBlock()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.InputBlock and conformance MLActivityClassifier.InputBlock, type metadata accessor for MLActivityClassifier.InputBlock, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.InputBlock);
}

uint64_t base witness table accessor for _Differentiable in MLActivityClassifier.InputBlock()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.InputBlock and conformance MLActivityClassifier.InputBlock, type metadata accessor for MLActivityClassifier.InputBlock, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.InputBlock);
}

uint64_t base witness table accessor for _BaseLayer in MLActivityClassifier.LSTMBlock()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.LSTMBlock and conformance MLActivityClassifier.LSTMBlock, type metadata accessor for MLActivityClassifier.LSTMBlock, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.LSTMBlock);
}

uint64_t base witness table accessor for _ComputeDevicePlaceable in MLActivityClassifier.LSTMBlock()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.LSTMBlock and conformance MLActivityClassifier.LSTMBlock, type metadata accessor for MLActivityClassifier.LSTMBlock, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.LSTMBlock);
}

uint64_t base witness table accessor for _Differentiable in MLActivityClassifier.LSTMBlock()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.LSTMBlock and conformance MLActivityClassifier.LSTMBlock, type metadata accessor for MLActivityClassifier.LSTMBlock, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.LSTMBlock);
}

uint64_t base witness table accessor for _BaseLayer in MLActivityClassifier.Model()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model and conformance MLActivityClassifier.Model, type metadata accessor for MLActivityClassifier.Model, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model);
}

uint64_t base witness table accessor for _ComputeDevicePlaceable in MLActivityClassifier.Model()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model and conformance MLActivityClassifier.Model, type metadata accessor for MLActivityClassifier.Model, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model);
}

uint64_t base witness table accessor for _Differentiable in MLActivityClassifier.Model()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model and conformance MLActivityClassifier.Model, type metadata accessor for MLActivityClassifier.Model, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model);
}

uint64_t MLActivityClassifier.Model.MLPackageRepresentation.forward(_:)(uint64_t a1, double a2)
{
  uint64_t v164 = v2;
  uint64_t v152 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (LSTM.State?, Tensor));
  int64_t v3 = *(void *)(*(void *)(v152 - 8) + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  long long v151 = v138;
  uint64_t v159 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (LSTM.State, Tensor));
  int64_t v6 = *(void *)(*(void *)(v159 - 8) + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v150 = v138;
  int64_t v9 = alloca(v6);
  int64_t v10 = alloca(v6);
  uint64_t v145 = v138;
  uint64_t v11 = alloca(v6);
  uint64_t v12 = alloca(v6);
  uint64_t v158 = v138;
  int64_t v13 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ScalarType?)
                              - 8)
                  + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v144 = v138;
  int64_t v16 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?)
                              - 8)
                  + 64);
  uint64_t v17 = alloca(v16);
  unsigned int v18 = alloca(v16);
  uint64_t v154 = v138;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v171 = v138;
  uint64_t v167 = type metadata accessor for Tensor(0);
  uint64_t v168 = *(void *)(v167 - 8);
  int64_t v21 = *(void *)(v168 + 64);
  int64_t v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  uint64_t v155 = v138;
  unint64_t v24 = alloca(v21);
  uint64_t v25 = alloca(v21);
  uint64_t v149 = v138;
  uint64_t v26 = alloca(v21);
  uint64_t v27 = alloca(v21);
  uint64_t v161 = v138;
  uint64_t v28 = alloca(v21);
  uint64_t v29 = alloca(v21);
  v170 = v138;
  int64_t v30 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LSTM.State?)
                              - 8)
                  + 64);
  uint64_t v31 = alloca(v30);
  uint64_t v32 = alloca(v30);
  long long v156 = v138;
  uint64_t v33 = alloca(v30);
  uint64_t v34 = alloca(v30);
  v160 = v138;
  uint64_t v163 = type metadata accessor for TensorShape(0);
  uint64_t v146 = *(void *)(v163 - 8);
  int64_t v35 = *(void *)(v146 + 64);
  uint64_t v36 = alloca(v35);
  uint64_t v37 = alloca(v35);
  v169 = v138;
  uint64_t v38 = alloca(v35);
  uint64_t v39 = alloca(v35);
  Swift::String v143 = (uint64_t *)v138;
  int64_t v40 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: String, value: Tensor)?)
                              - 8)
                  + 64);
  uint64_t v41 = alloca(v40);
  uint64_t v42 = alloca(v40);
  int64_t v43 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for TensorShape?)
                              - 8)
                  + 64);
  uint64_t v44 = alloca(v43);
  uint64_t v45 = alloca(v43);
  uint64_t v46 = alloca(v43);
  uint64_t v47 = alloca(v43);
  Swift::String v148 = v138;
  uint64_t v162 = a1;
  swift_bridgeObjectRetain(a1);
  specialized Sequence.first(where:)(a1);
  uint64_t v48 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: String, value: Tensor));
  if (__swift_getEnumTagSinglePayload((uint64_t)v138, 1, v48) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v138, &demangling cache variable for type metadata for (key: String, value: Tensor)?);
    uint64_t v49 = 1;
    uint64_t v50 = (uint64_t)v148;
  }
  else
  {
    swift_bridgeObjectRelease(v138[8]);
    uint64_t v51 = &v138[*(int *)(v48 + 48)];
    uint64_t v52 = (uint64_t)v148;
    Tensor.shape.getter();
    (*(void (**)(unsigned char *, uint64_t))(v168 + 8))(v51, v167);
    uint64_t v50 = v52;
    uint64_t v49 = 0;
  }
  uint64_t v53 = v163;
  __swift_storeEnumTagSinglePayload(v50, v49, 1, v163);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v50, (uint64_t)v138, &demangling cache variable for type metadata for TensorShape?);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v138, 1, v53);
  uint64_t v55 = v143;
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v138, &demangling cache variable for type metadata for TensorShape?);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0x7369207475706E49, 0xEE007974706D6520, "CreateML/MLActivityClassifier.Model.swift", 41, 2, 294, 0);
    goto LABEL_24;
  }
  (*(void (**)(uint64_t *, unsigned char *, uint64_t))(v146 + 32))(v143, v138, v53);
  uint64_t v56 = TensorShape.dimensions.getter();
  uint64_t v57 = *(void *)(v56 + 16);
  swift_bridgeObjectRelease(v56);
  if (v57 != 1)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000018, "ActivityClassifer" + 0x8000000000000000, "CreateML/MLActivityClassifier.Model.swift", 41, 2, 297, 0);
    goto LABEL_24;
  }
  uint64_t v58 = v162;
  uint64_t v59 = alloca(24);
  uint64_t v60 = alloca(32);
  uint64_t v139 = v55;
  swift_bridgeObjectRetain(v162);
  char v61 = specialized Sequence.allSatisfy(_:)(v58, (uint64_t (*)(uint64_t, uint64_t, char *))partial apply for closure #2 in MLActivityClassifier.Model.MLPackageRepresentation.forward(_:), (uint64_t)v138);
  swift_bridgeObjectRelease(v58);
  if ((v61 & 1) == 0)
  {
    uint64_t v137 = 302;
    uint64_t v136 = "Inputs should be vectors";
LABEL_23:
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000027, (unint64_t)v136 | 0x8000000000000000, "CreateML/MLActivityClassifier.Model.swift", 41, 2, v137, 0);
LABEL_24:
    BUG();
  }
  uint64_t v153 = 0;
  uint64_t v62 = type metadata accessor for LSTM.State(0);
  __swift_storeEnumTagSinglePayload((uint64_t)v160, 1, 1, v62);
  uint64_t v63 = (uint64_t)v171;
  specialized Dictionary.subscript.getter(0x6E496574617473, 0xE700000000000000, v162);
  uint64_t v64 = v167;
  int v65 = __swift_getEnumTagSinglePayload(v63, 1, v167);
  uint64_t v147 = v62;
  if (v65 == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v63, &demangling cache variable for type metadata for Tensor?);
    goto LABEL_15;
  }
  (*(void (**)(unsigned char *, uint64_t, uint64_t))(v168 + 32))(v170, v63, v64);
  uint64_t v66 = *(void *)&v164[*(int *)(type metadata accessor for MLActivityClassifier.Model(0) + 32)];
  uint64_t v67 = v169;
  Tensor.shape.getter();
  uint64_t v68 = TensorShape.dimensions.getter();
  uint64_t v69 = *(void *)(v68 + 16);
  swift_bridgeObjectRelease(v68);
  uint64_t v70 = *(unsigned char **)(v146 + 8);
  ((void (*)(unsigned char *, uint64_t))v70)(v67, v163);
  if (v69 != 1) {
    goto LABEL_22;
  }
  Tensor.shape.getter();
  uint64_t v71 = TensorShape.subscript.getter(0);
  uint64_t v72 = v169;
  uint64_t v73 = (void (*)(void, void))v71;
  ((void (*)(unsigned char *, uint64_t))v70)(v169, v163);
  if (v66 + 0x4000000000000000 < 0) {
    BUG();
  }
  v166 = v73;
  if (v73 != (void (*)(void, void))(2 * v66))
  {
LABEL_22:
    uint64_t v137 = 311;
    uint64_t v136 = " all have the same size";
    goto LABEL_23;
  }
  uint64_t v165 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Range<Int>>);
  uint64_t v74 = (void *)swift_allocObject(v165, 48, 7);
  v74[2] = 1;
  v74[3] = 2;
  if (v66 < 0) {
    BUG();
  }
  char v75 = (char)v74;
  v74[4] = 0;
  v74[5] = v66;
  uint64_t v171 = v70;
  uint64_t v142 = v74;
  uint64_t v76 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Range<Int>]);
  uint64_t v77 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Range<Int>] and conformance [A], &demangling cache variable for type metadata for [Range<Int>], (uint64_t)&protocol conformance descriptor for [A]);
  uint64_t v157 = v66;
  unint64_t v78 = v149;
  long long v140 = (char *)v76;
  uint64_t v141 = v77;
  Tensor.slice<A>(at:)(&v142, v76);
  swift_bridgeObjectRelease(v75);
  uint64_t v79 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  unint64_t v80 = (void *)swift_allocObject(v79, 48, 7);
  v80[2] = 2;
  v80[3] = 4;
  v80[4] = 1;
  uint64_t v81 = v157;
  v80[5] = v157;
  TensorShape.init(_:)(v80, a2);
  Tensor.reshaped(to:)(v72);
  uint64_t v82 = v163;
  ((void (*)(unsigned char *, uint64_t))v171)(v72, v163);
  uint64_t v83 = *(void (**)(unsigned char *, uint64_t))(v168 + 8);
  v83(v78, v167);
  uint64_t v84 = (void *)swift_allocObject(v165, 48, 7);
  v84[2] = 1;
  void v84[3] = 2;
  uint64_t v85 = v166;
  if ((uint64_t)v166 < v81) {
    BUG();
  }
  uint64_t v165 = v79;
  uint64_t v86 = v81;
  v84[4] = v81;
  v84[5] = v85;
  uint64_t v142 = v84;
  uint64_t v87 = v155;
  v166 = (void (*)(void, void))v83;
  Tensor.slice<A>(at:)(&v142, v140);
  swift_bridgeObjectRelease((_BYTE)v84);
  uint64_t v88 = (void *)swift_allocObject(v165, 48, 7);
  v88[2] = 2;
  v88[3] = 4;
  v88[4] = 1;
  v88[5] = v86;
  uint64_t v89 = v169;
  TensorShape.init(_:)(v88, a2);
  uint64_t v90 = v149;
  Tensor.reshaped(to:)(v89);
  ((void (*)(unsigned char *, uint64_t))v171)(v89, v82);
  uint64_t v91 = v87;
  uint64_t v92 = v167;
  v166(v91, v167);
  uint64_t v93 = (uint64_t)v156;
  LSTM.State.init(hidden:cell:)(v161, v90);
  uint64_t v94 = (uint64_t)v160;
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v160, &demangling cache variable for type metadata for LSTM.State?);
  __swift_storeEnumTagSinglePayload(v93, 0, 1, v147);
  outlined init with take of LSTM.State?(v93, v94, &demangling cache variable for type metadata for LSTM.State?);
  uint64_t v95 = (uint64_t)v154;
  specialized Dictionary._Variant.removeValue(forKey:)(0x6E496574617473, 0xE700000000000000);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v95, &demangling cache variable for type metadata for Tensor?);
  v166(v170, v92);
LABEL_15:
  uint64_t v171 = (unsigned char *)type metadata accessor for MLActivityClassifier.Model(0);
  uint64_t v96 = *(void *)&v164[*((int *)v171 + 16) + 40];
  uint64_t v97 = alloca(32);
  uint64_t v98 = alloca(32);
  uint64_t v139 = &v162;
  long long v140 = v164;
  swift_bridgeObjectRetain(v96);
  BOOL v99 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_14NeuralNetworks6TensorVs5NeverOTg5((void (*)(void *))partial apply for closure #3 in MLActivityClassifier.Model.MLPackageRepresentation.forward(_:), (uint64_t)v138, v96, (uint64_t)&v139);
  swift_bridgeObjectRelease(v96);
  uint64_t v153 = type metadata accessor for ScalarType(0);
  uint64_t v100 = (uint64_t)v144;
  __swift_storeEnumTagSinglePayload((uint64_t)v144, 1, 1, v153);
  uint64_t v101 = v161;
  Tensor.init(concatenating:alongAxis:scalarType:)(v99, 0, v100);
  v169 = &v158[*(int *)(v159 + 48)];
  uint64_t v102 = (uint64_t)v151;
  uint64_t v103 = &v151[*(int *)(v152 + 48)];
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v160, (uint64_t)v151, &demangling cache variable for type metadata for LSTM.State?);
  v170 = *(unsigned char **)(v168 + 16);
  ((void (*)(unsigned char *, unsigned char *, uint64_t))v170)(v103, v101, v167);
  uint64_t v104 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model and conformance MLActivityClassifier.Model, type metadata accessor for MLActivityClassifier.Model, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model);
  Layer.callAsFunction(_:)(v102, v171, v104);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v102, &demangling cache variable for type metadata for (LSTM.State?, Tensor));
  uint64_t v105 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Tensor)>);
  uint64_t v106 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, Tensor));
  uint64_t v107 = *(void *)(v106 - 8);
  uint64_t v108 = v106;
  uint64_t v155 = (unsigned char *)v106;
  uint64_t v152 = *(void *)(v107 + 72);
  uint64_t v109 = *(unsigned __int8 *)(v107 + 80);
  uint64_t v110 = ((int)v109 + 32) & ~*(unsigned __int8 *)(v107 + 80);
  uint64_t v111 = swift_allocObject(v105, v110 + 2 * v152, v109 | 7);
  long long v151 = (unsigned char *)v111;
  *(void *)(v111 + 16) = 2;
  *(void *)(v111 + 24) = 4;
  uint64_t v154 = (unsigned char *)(v111 + v110);
  long long v156 = (unsigned char *)(v111 + v110 + *(int *)(v108 + 48));
  *(void *)(v111 + v110) = 0x74754F6574617473;
  *(void *)(v111 + v110 + 8) = 0xE800000000000000;
  uint64_t v112 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Tensor>);
  uint64_t v157 = *(void *)(v168 + 72);
  uint64_t v113 = swift_allocObject(v112, ((*(unsigned __int8 *)(v168 + 80) + 32) & ~*(unsigned __int8 *)(v168 + 80)) + 2 * v157, *(unsigned __int8 *)(v168 + 80) | 7);
  v166 = (void (*)(void, void))v113;
  *(void *)(v113 + 16) = 2;
  *(void *)(v113 + 24) = 4;
  uint64_t v165 = (uint64_t)&v145[*(int *)(v159 + 48)];
  uint64_t v114 = v165;
  uint64_t v115 = v147;
  uint64_t v116 = *(void *)(v147 - 8);
  uint64_t v164 = *(char **)(v116 + 16);
  BOOL v117 = v145;
  ((void (*)(unsigned char *, unsigned char *, uint64_t))v164)(v145, v158, v147);
  uint64_t v118 = v114;
  uint64_t v119 = v169;
  ((void (*)(uint64_t, unsigned char *, uint64_t))v170)(v118, v169, v167);
  LSTM.State.hidden.getter();
  uint64_t v171 = *(unsigned char **)(v116 + 8);
  ((void (*)(unsigned char *, uint64_t))v171)(v117, v115);
  unint64_t v120 = v150;
  uint64_t v121 = &v150[*(int *)(v159 + 48)];
  ((void (*)(unsigned char *, unsigned char *, uint64_t))v164)(v150, v158, v115);
  uint64_t v122 = v119;
  uint64_t v123 = v167;
  ((void (*)(unsigned char *, unsigned char *, uint64_t))v170)(v121, v122, v167);
  LSTM.State.cell.getter();
  ((void (*)(unsigned char *, uint64_t))v171)(v120, v115);
  uint64_t v124 = *(unsigned char **)(v168 + 8);
  ((void (*)(unsigned char *, uint64_t))v124)(v121, v123);
  uint64_t v125 = v123;
  ((void (*)(uint64_t, uint64_t))v124)(v165, v123);
  uint64_t v150 = v124;
  uint64_t v126 = (uint64_t)v144;
  __swift_storeEnumTagSinglePayload((uint64_t)v144, 1, 1, v153);
  uint64_t v127 = v149;
  Tensor.init(concatenating:alongAxis:scalarType:)(v166, 1, v126);
  Tensor.flattened()();
  ((void (*)(unsigned char *, uint64_t))v124)(v127, v123);
  uint64_t v128 = v152;
  char v129 = v154;
  char v130 = &v154[v152 + *((int *)v155 + 12)];
  *(void *)&v154[v152] = 0xD000000000000013;
  *(void *)&v129[v128 + 8] = " inverted index." + 0x8000000000000000;
  uint64_t v131 = &v145[*(int *)(v159 + 48)];
  uint64_t v132 = (uint64_t)v158;
  uint64_t v133 = v147;
  ((void (*)(unsigned char *, unsigned char *, uint64_t))v164)(v145, v158, v147);
  ((void (*)(unsigned char *, unsigned char *, uint64_t))v170)(v131, v169, v125);
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v168 + 32))(v130, v131, v125);
  ((void (*)(unsigned char *, uint64_t))v171)(v145, v133);
  uint64_t v134 = Dictionary.init(dictionaryLiteral:)(v151, &type metadata for String, v125, &protocol witness table for String);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v132, &demangling cache variable for type metadata for (LSTM.State, Tensor));
  ((void (*)(unsigned char *, uint64_t))v150)(v161, v125);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v160, &demangling cache variable for type metadata for LSTM.State?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v148, &demangling cache variable for type metadata for TensorShape?);
  (*(void (**)(uint64_t *, uint64_t))(v146 + 8))(v143, v163);
  swift_bridgeObjectRelease(v162);
  return v134;
}

uint64_t closure #2 in MLActivityClassifier.Model.MLPackageRepresentation.forward(_:)(uint64_t a1, uint64_t a2, uint64_t a3, void *a4)
{
  uint64_t v31 = a4;
  uint64_t v26 = a3;
  unsigned int v4 = a1;
  uint64_t v28 = type metadata accessor for TensorShape(0);
  uint64_t v5 = *(void *)(v28 - 8);
  int64_t v6 = *(void *)(v5 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v27 = &v25;
  int64_t v9 = alloca(v6);
  int64_t v10 = alloca(v6);
  uint64_t v29 = &v25;
  uint64_t v11 = type metadata accessor for Tensor(0);
  uint64_t v12 = *(void *)(v11 - 8);
  int64_t v13 = *(void *)(v12 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  int64_t v30 = &v25;
  if (a1 == 0x6E496574617473 && a2 == 0xE700000000000000)
  {
    (*(void (**)(uint64_t *, uint64_t, uint64_t))(v12 + 16))(v30, v26, v11);
    uint64_t v16 = v28;
    (*(void (**)(uint64_t *, void *, uint64_t))(v5 + 16))(v29, v31, v28);
  }
  else
  {
    unsigned int v4 = _stringCompareWithSmolCheck(_:_:expecting:)(a1, a2, 0x6E496574617473, 0xE700000000000000, 0);
    (*(void (**)(uint64_t *, uint64_t, uint64_t))(v12 + 16))(v30, v26, v11);
    uint64_t v16 = v28;
    (*(void (**)(uint64_t *, void *, uint64_t))(v5 + 16))(v29, v31, v28);
    if ((v4 & 1) == 0)
    {
      Tensor.shape.getter();
      uint64_t v17 = (void *)TensorShape.dimensions.getter();
      uint64_t v31 = v17;
      unsigned int v18 = (void *)TensorShape.dimensions.getter();
      char v19 = (char)v18;
      LOBYTE(v20) = specialized static Array<A>.== infix(_:_:)(v17, v18);
      unsigned int v4 = v20;
      swift_bridgeObjectRelease((_BYTE)v31);
      char v21 = v19;
      uint64_t v22 = v28;
      swift_bridgeObjectRelease(v21);
      uint64_t v23 = *(void (**)(uint64_t *, uint64_t))(v5 + 8);
      v23(v27, v22);
      v23(v29, v22);
      goto LABEL_7;
    }
  }
  LOBYTE(v4) = 1;
  (*(void (**)(uint64_t *, uint64_t))(v5 + 8))(v29, v16);
LABEL_7:
  (*(void (**)(uint64_t *, uint64_t))(v12 + 8))(v30, v11);
  return v4;
}

uint64_t closure #3 in MLActivityClassifier.Model.MLPackageRepresentation.forward(_:)(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v23 = a2;
  uint64_t v21 = v3;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?)
                             - 8)
                 + 64);
  int64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v22 = &v20;
  uint64_t v8 = *a1;
  uint64_t v9 = a1[1];
  uint64_t v10 = *(void *)(a3
                  + *(int *)(type metadata accessor for MLActivityClassifier.Model.MLPackageRepresentation(0) + 20));
  uint64_t v11 = *(void *)(v10 + 16);
  swift_bridgeObjectRetain(v9);
  if (v11)
  {
    unint64_t v12 = specialized __RawDictionaryStorage.find<A>(_:)(v8, v9);
    if (v13)
    {
      uint64_t v14 = *(void *)(v10 + 56);
      uint64_t v15 = 16 * v12;
      uint64_t v8 = *(void *)(v14 + v15);
      uint64_t v16 = *(void *)(v14 + v15 + 8);
      swift_bridgeObjectRetain(v16);
      swift_bridgeObjectRelease(v9);
      uint64_t v9 = v16;
    }
  }
  uint64_t v17 = (uint64_t)v22;
  specialized Dictionary.subscript.getter(v8, v9, *v23);
  swift_bridgeObjectRelease(v9);
  uint64_t v18 = type metadata accessor for Tensor(0);
  if (__swift_getEnumTagSinglePayload(v17, 1, v18) == 1) {
    BUG();
  }
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v18 - 8) + 32))(v21, v17, v18);
}

uint64_t protocol witness for Layer.forward(_:) in conformance MLActivityClassifier.Model.MLPackageRepresentation(uint64_t *a1, double a2)
{
  uint64_t v3 = v2;
  uint64_t result = MLActivityClassifier.Model.MLPackageRepresentation.forward(_:)(*a1, a2);
  *uint64_t v3 = result;
  return result;
}

uint64_t protocol witness for _ComputeDevicePlaceable.place(on:) in conformance MLActivityClassifier.Model.MLPackageRepresentation(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model.MLPackageRepresentation and conformance MLActivityClassifier.Model.MLPackageRepresentation, type metadata accessor for MLActivityClassifier.Model.MLPackageRepresentation, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model.MLPackageRepresentation);
  return Layer.place(on:)(a1, a2, v2);
}

uint64_t protocol witness for _ComputeDevicePlaceable.placed(on:) in conformance MLActivityClassifier.Model.MLPackageRepresentation(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model.MLPackageRepresentation and conformance MLActivityClassifier.Model.MLPackageRepresentation, type metadata accessor for MLActivityClassifier.Model.MLPackageRepresentation, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model.MLPackageRepresentation);
  return Layer.placed(on:)(a1, a2, v2);
}

uint64_t MLActivityClassifier.Model.makeClassifier(_:_:_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v121 = v4;
  uint64_t v88 = a3;
  uint64_t v112 = a2;
  unint64_t v6 = 0;
  uint64_t v87 = type metadata accessor for Model(0);
  uint64_t v86 = *(void *)(v87 - 8);
  int64_t v7 = *(void *)(v86 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v111 = &v84;
  uint64_t v101 = type metadata accessor for URL(0);
  uint64_t v100 = *(void *)(v101 - 8);
  int64_t v10 = *(void *)(v100 + 64);
  uint64_t v11 = alloca(v10);
  unint64_t v12 = alloca(v10);
  uint64_t v107 = &v84;
  uint64_t v91 = type metadata accessor for ModelKind(0);
  uint64_t v90 = *(void *)(v91 - 8);
  int64_t v13 = *(void *)(v90 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v92 = &v84;
  uint64_t v94 = type metadata accessor for FeatureType.DictionaryParameters.KeyType(0);
  uint64_t v93 = *(void *)(v94 - 8);
  int64_t v16 = *(void *)(v93 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v96 = &v84;
  uint64_t v104 = type metadata accessor for FeatureType(0);
  uint64_t v98 = *(void *)(v104 - 8);
  int64_t v19 = *(void *)(v98 + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  uint64_t v95 = &v84;
  uint64_t v120 = type metadata accessor for FeatureDescription(0);
  uint64_t v115 = *(void *)(v120 - 8);
  int64_t v22 = *(void *)(v115 + 64);
  uint64_t v23 = alloca(v22);
  unint64_t v24 = alloca(v22);
  uint64_t v105 = &v84;
  uint64_t v25 = alloca(v22);
  uint64_t v26 = alloca(v22);
  uint64_t v106 = &v84;
  uint64_t v27 = alloca(v22);
  uint64_t v28 = alloca(v22);
  uint64_t v109 = &v84;
  uint64_t v29 = alloca(v22);
  int64_t v30 = alloca(v22);
  uint64_t v110 = &v84;
  uint64_t v31 = alloca(v22);
  uint64_t v32 = alloca(v22);
  uint64_t v119 = &v84;
  v33._rawValue = *(void **)(v121 + *(int *)(type metadata accessor for MLActivityClassifier.Model(0) + 60));
  unint64_t v103 = 0xD000000000000010;
  uint64_t v102 = " inverted index." + 0x8000000000000000;
  v122._uint64_t countAndFlagsBits = 0x6C6562616CLL;
  uint64_t v89 = a1;
  v122._unsigned __int8 object = (void *)0xE500000000000000;
  MLProgram.addClassifierSpecification(classLabels:probabilityTensorName:outputProbabilityName:outputLabelName:)(v33, (Swift::String)__PAIR128__((unint64_t)(" inverted index." + 0x8000000000000000), 0xD000000000000013), (Swift::String)__PAIR128__((unint64_t)("labelProbabilityRaw" + 0x8000000000000000), 0xD000000000000010), v122);
  Model.modelDescription.setter(0xD000000000000011, "labelProbability" + 0x8000000000000000);
  Model.predictedFeatureName.setter(0x6C6562616CLL, 0xE500000000000000);
  uint64_t v97 = "labelProbabilityRaw" + 0x8000000000000000;
  Model.predictedProbabilitiesName.setter(v103, "labelProbabilityRaw" + 0x8000000000000000);
  BOOL v99 = (void (*)(unsigned char *, void))Model.outputs.modify(v85);
  uint64_t v118 = v34;
  unint64_t v35 = *v34;
  uint64_t v36 = 0;
  if (!*(void *)(v35 + 16)) {
    goto LABEL_13;
  }
  uint64_t v116 = *(void (**)(uint64_t *, uint64_t))(v35 + 16);
  uint64_t v37 = (*(unsigned __int8 *)(v115 + 80) + 32) & ~*(unsigned __int8 *)(v115 + 80);
  uint64_t v38 = v35 + v37;
  BOOL v117 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v115 + 16);
  uint64_t v39 = *(void *)(v115 + 72);
  unint64_t v113 = v35;
  swift_bridgeObjectRetain(v35);
  uint64_t v108 = v37;
  uint64_t v114 = v39;
  int64_t v40 = (uint64_t *)(v39 + v37);
  uint64_t v121 = 0;
  uint64_t v41 = v120;
  do
  {
    v117(v119, v38, v41);
    uint64_t v42 = FeatureDescription.name.getter();
    char v44 = (char)v43;
    if (v42 == 0xD000000000000013 && v43 == v102)
    {
      swift_bridgeObjectRelease((_BYTE)v102);
      uint64_t v46 = *(void (**)(uint64_t *, uint64_t))(v115 + 8);
      v46(v119, v120);
LABEL_9:
      uint64_t v116 = v46;
      swift_bridgeObjectRelease(v113);
      unint64_t v6 = v121 + 1;
      if (__OFADD__(1, v121)) {
        BUG();
      }
      uint64_t v48 = *v118;
      unint64_t v49 = *(void *)(*v118 + 16);
      if (v6 == v49)
      {
LABEL_11:
        uint64_t v47 = (void (*)(void, void))v121;
        goto LABEL_12;
      }
      uint64_t v69 = (void (*)(uint64_t *, char *, uint64_t))v117;
      uint64_t v70 = v120;
      while (1)
      {
        if (v6 >= v49) {
          BUG();
        }
        uint64_t v119 = v40;
        v69(v109, (char *)v40 + v48, v70);
        uint64_t v71 = FeatureDescription.name.getter();
        char v73 = (char)v72;
        if (v71 == 0xD000000000000013 && v72 == v102)
        {
          swift_bridgeObjectRelease((_BYTE)v102);
          uint64_t v70 = v120;
          v116(v109, v120);
        }
        else
        {
          char v74 = _stringCompareWithSmolCheck(_:_:expecting:)(v71, v72, 0xD000000000000013, v102, 0);
          swift_bridgeObjectRelease(v73);
          uint64_t v70 = v120;
          v116(v109, v120);
          if ((v74 & 1) == 0)
          {
            uint64_t v76 = v121;
            uint64_t v69 = (void (*)(uint64_t *, char *, uint64_t))v117;
            char v75 = v119;
            if (v6 != v121)
            {
              if (v121 < 0) {
                BUG();
              }
              uint64_t v77 = (void *)*v118;
              if ((unint64_t)v121 >= *(void *)(*v118 + 16)) {
                BUG();
              }
              unint64_t v113 = *(void *)(*v118 + 16);
              uint64_t v78 = v114 * v121;
              uint64_t v79 = (void (*)(uint64_t *, char *, uint64_t))v117;
              v117(v106, (uint64_t)v77 + v108 + v114 * v121, v120);
              if (v6 >= v113) {
                BUG();
              }
              v79(v105, (char *)v119 + (void)v77, v120);
              char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v77);
              *uint64_t v118 = v77;
              uint64_t v70 = v120;
              if (!isUniquelyReferenced_nonNull_native)
              {
                uint64_t v77 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v77);
                *uint64_t v118 = v77;
              }
              if ((unint64_t)v121 >= v77[2]) {
                BUG();
              }
              uint64_t v81 = (char *)v77 + v108 + v78;
              uint64_t v82 = *(void (**)(char *, uint64_t *, uint64_t))(v115 + 40);
              v82(v81, v105, v70);
              if (v6 >= *(void *)(*v118 + 16)) {
                BUG();
              }
              char v75 = v119;
              v82((char *)v119 + *v118, v106, v70);
              uint64_t v76 = v121;
              uint64_t v69 = (void (*)(uint64_t *, char *, uint64_t))v117;
            }
            uint64_t v121 = v76 + 1;
            if (__OFADD__(1, v76)) {
              BUG();
            }
            goto LABEL_33;
          }
        }
        uint64_t v69 = (void (*)(uint64_t *, char *, uint64_t))v117;
        char v75 = v119;
LABEL_33:
        if (__OFADD__(1, v6++)) {
          BUG();
        }
        uint64_t v48 = *v118;
        unint64_t v49 = *(void *)(*v118 + 16);
        int64_t v40 = (uint64_t *)((char *)v75 + v114);
        if (v6 == v49) {
          goto LABEL_11;
        }
      }
    }
    char v45 = _stringCompareWithSmolCheck(_:_:expecting:)(v42, v43, 0xD000000000000013, v102, 0);
    swift_bridgeObjectRelease(v44);
    uint64_t v46 = *(void (**)(uint64_t *, uint64_t))(v115 + 8);
    v46(v119, v120);
    if (v45) {
      goto LABEL_9;
    }
    int64_t v40 = (uint64_t *)((char *)v40 + v114);
    v38 += v114;
    ++v121;
    uint64_t v41 = v120;
  }
  while (v116 != (void (*)(uint64_t *, uint64_t))v121);
  swift_bridgeObjectRelease(v113);
  unint64_t v6 = *(void *)(*v118 + 16);
  uint64_t v47 = (void (*)(void, void))v116;
LABEL_12:
  uint64_t v36 = (uint64_t)v47;
  if ((uint64_t)v6 < (uint64_t)v47) {
    BUG();
  }
LABEL_13:
  specialized Array.replaceSubrange<A>(_:with:)(v36, v6);
  v99(v85, 0);
  uint64_t v50 = v95;
  FeatureType.StringParameters.init(optional:)(0);
  uint64_t v121 = *(void *)(v98 + 104);
  ((void (*)(uint64_t *, void, uint64_t))v121)(v50, enum case for FeatureType.string(_:), v104);
  FeatureDescription.init(name:type:description:)(0x6C6562616CLL, 0xE500000000000000, v50, 0, 0xE000000000000000);
  uint64_t v114 = Model.outputs.modify(v85);
  uint64_t v52 = v51;
  specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
  uint64_t v53 = *(void *)(*v52 + 16);
  specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v53);
  uint64_t v54 = *v52;
  *(void *)(v54 + 16) = v53 + 1;
  uint64_t v55 = (*(unsigned __int8 *)(v115 + 80) + 32) & ~*(unsigned __int8 *)(v115 + 80);
  BOOL v117 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v115 + 32);
  uint64_t v119 = *(uint64_t **)(v115 + 72);
  v117((uint64_t *)(v55 + v54 + (void)v119 * v53), (uint64_t)v110, v120);
  ((void (*)(unsigned char *, void))v114)(v85, 0);
  uint64_t v56 = v96;
  FeatureType.StringParameters.init(optional:)(0);
  (*(void (**)(uint64_t *, void, uint64_t))(v93 + 104))(v56, enum case for FeatureType.DictionaryParameters.KeyType.string(_:), v94);
  FeatureType.DictionaryParameters.init(keyType:optional:)(v56, 0);
  ((void (*)(uint64_t *, void, uint64_t))v121)(v50, enum case for FeatureType.dictionary(_:), v104);
  FeatureDescription.init(name:type:description:)(v103, v97, v50, 0, 0xE000000000000000);
  uint64_t v57 = (void (*)(unsigned char *, void))Model.outputs.modify(v85);
  uint64_t v59 = v58;
  specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
  uint64_t v60 = *(void *)(*v59 + 16);
  specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v60);
  uint64_t v61 = *v59;
  *(void *)(v61 + 16) = v60 + 1;
  v117((uint64_t *)(v55 + v61 + (void)v119 * v60), (uint64_t)v110, v120);
  v57(v85, 0);
  uint64_t v62 = type metadata accessor for MLProgram(0);
  uint64_t v63 = v92;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(*(void *)(v62 - 8) + 16))(v92, v89, v62);
  (*(void (**)(uint64_t *, void, uint64_t))(v90 + 104))(v63, enum case for ModelKind.mlProgram(_:), v91);
  uint64_t v64 = v112;
  Model.kind.setter(v63);
  int v65 = v111;
  uint64_t v66 = v87;
  uint64_t v67 = v86;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v86 + 16))(v111, v64, v87);
  Package.setRootModel(_:)(v65);
  if (v3) {
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v67 + 8))(v111, v66);
  }
  (*(void (**)(uint64_t *, uint64_t))(v67 + 8))(v111, v66);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v100 + 8))(v107, v101);
}

uint64_t MLActivityClassifier.Model.addMetadata(_:_:)(uint64_t a1, uint64_t *a2)
{
  uint64_t v29 = a1;
  uint64_t v2 = type metadata accessor for Package.ModelMetadata(0);
  uint64_t v28 = *(void *)(v2 - 8);
  int64_t v3 = *(void *)(v28 + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  int64_t v30 = v26;
  unint64_t v6 = alloca(v3);
  int64_t v7 = alloca(v3);
  uint64_t v35 = *a2;
  uint64_t v8 = a2[1];
  uint64_t v33 = a2[2];
  uint64_t v34 = a2[3];
  uint64_t v36 = a2[4];
  uint64_t v37 = (unsigned char *)a2[5];
  uint64_t v31 = a2[6];
  uint64_t v32 = a2[7];
  uint64_t v9 = a2[8];
  Package.ModelMetadata.init()();
  uint64_t v27 = v2;
  if (v8)
  {
    swift_bridgeObjectRetain(v8);
    Package.ModelMetadata.author.setter(v35, v8);
    uint64_t v10 = v34;
    swift_bridgeObjectRetain(v34);
    Package.ModelMetadata.description.setter(v33, v10);
    uint64_t v11 = v32;
    swift_bridgeObjectRetain(v32);
    Package.ModelMetadata.version.setter(v31, v11);
    if (v37)
    {
      unint64_t v12 = v37;
      swift_bridgeObjectRetain((_BYTE)v37);
      Package.ModelMetadata.license.setter(v36, v12);
    }
    if (v9)
    {
      swift_bridgeObjectRetain(v9);
      Package.ModelMetadata.creatorDefined.setter(v9);
    }
  }
  else
  {
    int64_t v13 = NSFullUserName();
    uint64_t v14 = v13;
    uint64_t v15 = static String._unconditionallyBridgeFromObjectiveC(_:)(v14);
    uint64_t v17 = v16;

    Package.ModelMetadata.author.setter(v15, v17);
  }
  Swift::String v18 = getOSVersion()();
  uint64_t countAndFlagsBits = v18._countAndFlagsBits;
  unsigned __int8 object = v18._object;
  uint64_t v37 = (unsigned char *)Package.ModelMetadata.creatorDefined.modify(v26);
  specialized Dictionary._Variant.setValue(_:forKey:)(countAndFlagsBits, (uint64_t)object, 0xD00000000000001ALL, (uint64_t)("Recommender Model" + 0x8000000000000000));
  ((void (*)(unsigned char *, void))v37)(v26, 0);
  uint64_t v21 = v30;
  uint64_t v37 = v26;
  uint64_t v22 = v27;
  uint64_t v23 = v28;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v28 + 16))(v30, v26, v27);
  Package.writeMetadata(_:)(v21);
  unint64_t v24 = *(void (**)(unsigned char *, uint64_t))(v23 + 8);
  v24(v21, v22);
  return ((uint64_t (*)(unsigned char *, uint64_t))v24)(v37, v22);
}

void *MLActivityClassifier.Model.renameInputsAsNeeded(inputs:)(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 16);
  if (v1)
  {
    swift_bridgeObjectRetain(a1);
    char v14 = a1;
    uint64_t v2 = (unint64_t *)(a1 + 40);
    do
    {
      uint64_t v3 = *(v2 - 1);
      unint64_t v4 = *v2;
      swift_bridgeObjectRetain(*v2);
      if (specialized Sequence.contains(where:)(0, v3, v4))
      {
        v5._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
        uint64_t v13 = v1;
        char object = (char)v5._object;
        String.append(_:)(v5);
        swift_bridgeObjectRelease(object);
        v7._uint64_t countAndFlagsBits = 95;
        v7._char object = (void *)0xE100000000000000;
        String.append(_:)(v7);
        Swift::String v8 = String.asSanitizedMILIdentifier()();
        char v9 = (char)v8._object;
        String.append(_:)(v8);
        swift_bridgeObjectRelease(v9);
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
        uint64_t v1 = v13;
        specialized _NativeDictionary.setValue(_:forKey:isUnique:)(0x656D616E65725F5FLL, 0xEA00000000005F64, v3, v4, isUniquelyReferenced_nonNull_native);
        swift_bridgeObjectRelease(v4);
        char v11 = 0;
      }
      else
      {
        char v11 = v4;
      }
      swift_bridgeObjectRelease(v11);
      v2 += 2;
      --v1;
    }
    while (v1);
    swift_bridgeObjectRelease(v14);
  }
  return _swiftEmptyDictionarySingleton;
}

Swift::String __swiftcall String.asSanitizedMILIdentifier()()
{
  int64_t v2 = String.count.getter();
  if (v2 <= 0) {
    int64_t v2 = 0;
  }
  uint64_t v3 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0, (uint64_t)_swiftEmptyArrayStorage);
  uint64_t v4 = HIBYTE(v1) & 0xF;
  if ((v1 & 0x2000000000000000) == 0) {
    uint64_t v4 = v0 & 0xFFFFFFFFFFFFLL;
  }
  Swift::String v5 = v3;
  uint64_t v26 = v0;
  unint64_t v27 = v1;
  uint64_t v28 = 0;
  uint64_t v29 = v4;
  swift_bridgeObjectRetain(v1);
  Swift::String_optional v6 = String.Iterator.next()();
  if (v6.value._object)
  {
    uint64_t countAndFlagsBits = v6.value._countAndFlagsBits;
    char object = v6.value._object;
    uint64_t v9 = (uint64_t)v5;
    while (1)
    {
      if ((countAndFlagsBits != 2573 || object != (void *)0xE200000000000000)
        && (_stringCompareWithSmolCheck(_:_:expecting:)(countAndFlagsBits, object, 2573, 0xE200000000000000, 0) & 1) == 0)
      {
        if ((Character._isSingleScalar.getter(countAndFlagsBits, object, v10, v11, v12, v13, v25, v26, v27, v28) & 1) == 0) {
          goto LABEL_23;
        }
        unint64_t v14 = specialized Collection.first.getter(countAndFlagsBits, (unint64_t)object);
        if ((v14 & 0x100000000) != 0) {
          BUG();
        }
        if ((v14 & 0xFFFFFF80) != 0)
        {
LABEL_23:
          swift_bridgeObjectRelease((_BYTE)object);
          unint64_t v19 = *(void *)(v9 + 16);
          uint64_t v20 = (void *)v9;
          if (*(void *)(v9 + 24) >> 1 <= v19) {
            uint64_t v20 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*(void *)(v9 + 24) >= 2uLL, v19 + 1, 1, v9);
          }
          void v20[2] = v19 + 1;
          uint64_t v9 = (uint64_t)v20;
          Swift::String v18 = &v20[2 * v19 + 4];
          *Swift::String v18 = 95;
          char object = (void *)0xE100000000000000;
          goto LABEL_26;
        }
        unint64_t v15 = specialized Collection.first.getter(countAndFlagsBits, (unint64_t)object);
        if ((v15 & 0x100000000) != 0) {
          BUG();
        }
        if ((v15 & 0xFFFFFF00) != 0) {
          BUG();
        }
      }
      if ((Character.isLetter.getter(countAndFlagsBits, object) & 1) == 0
        && (Character.isNumber.getter(countAndFlagsBits, object) & 1) == 0)
      {
        goto LABEL_23;
      }
      unint64_t v16 = *(void *)(v9 + 16);
      if (!v16)
      {
        if ((Character.isLetter.getter(countAndFlagsBits, object) & 1) == 0) {
          goto LABEL_23;
        }
        unint64_t v16 = *(void *)(v9 + 16);
      }
      uint64_t v17 = (void *)v9;
      if (*(void *)(v9 + 24) >> 1 <= v16) {
        uint64_t v17 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*(void *)(v9 + 24) >= 2uLL, v16 + 1, 1, v9);
      }
      v17[2] = v16 + 1;
      uint64_t v9 = (uint64_t)v17;
      Swift::String v18 = &v17[2 * v16 + 4];
      *Swift::String v18 = countAndFlagsBits;
LABEL_26:
      v18[1] = (uint64_t)object;
      Swift::String_optional v21 = String.Iterator.next()();
      uint64_t countAndFlagsBits = v21.value._countAndFlagsBits;
      char object = v21.value._object;
      if (!v21.value._object) {
        goto LABEL_29;
      }
    }
  }
  uint64_t v9 = (uint64_t)v5;
LABEL_29:
  swift_bridgeObjectRelease(v27);
  uint64_t v26 = v9;
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Character]);
  uint64_t v23 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Character] and conformance [A], &demangling cache variable for type metadata for [Character], (uint64_t)&protocol conformance descriptor for [A]);
  result._uint64_t countAndFlagsBits = String.init<A>(_:)(&v26, v22, v23);
  return result;
}

void *MLActivityClassifier.Model.makeRenamingModel(inputs:renameMap:)(void *ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG40VG13renamedInputstAN_SDyS2SGtKFA2MXEfU2_SDyS2SGSDySSAHGTf1cn_n, uint64_t a2, uint64_t a3)
{
  uint64_t v25 = a3;
  uint64_t v26 = type metadata accessor for ModelKind(0);
  uint64_t v27 = *(void *)(v26 - 8);
  int64_t v5 = *(void *)(v27 + 64);
  Swift::String_optional v6 = alloca(v5);
  Swift::String v7 = alloca(v5);
  uint64_t v28 = &v24;
  uint64_t v8 = specialized Collection.makeDictionary(indexedBy:)(a2);
  if (!v3)
  {
    uint64_t v9 = v8;
    uint64_t v30 = a2;
    swift_bridgeObjectRetain(v8);
    uint64_t v10 = v25;
    ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG56VG13renamedInputstAN_SDyS2SGtKFAMSS3key_SS5valuet_tXEfU_SDySSAIGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDyS2SG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg5077_s8CreateML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG56VG13renamedInputstAN_SDyS2SGtKFAMSS3key_SS5valuet_tXEfU_SDySSAIGTf1cn_n(v25, v9);
    swift_bridgeObjectRetain(v9);
    swift_bridgeObjectRetain(v10);
    ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20ef17ADV5model_SayAI18gH41VG13renamedInputstAN_SDyS2SGtKFAMSSXEfU0_SDySSAKGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSD6ValuesVyS2S_G_20MLModelSpecification18FeatureDescriptionVs5NeverOTg5077_s8CreateML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20ef17ADV5model_SayAI18gH41VG13renamedInputstAN_SDyS2SGtKFAMSSXEfU0_SDySSAKGTf1cn_n(v10, v9);
    uint64_t v29 = 0;
    swift_bridgeObjectRelease(v9);
    swift_bridgeObjectRelease(v10);
    Model.init()();
    Model.specificationVersion.setter(1);
    Model.modelDescription.setter(0xD00000000000001BLL, "ActivityClassifierPipeline" + 0x8000000000000000);
    uint64_t v12 = ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG56VG13renamedInputstAN_SDyS2SGtKFAMSS3key_SS5valuet_tXEfU_SDySSAIGTf1cn_n;
    swift_bridgeObjectRetain((_BYTE)ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG56VG13renamedInputstAN_SDyS2SGtKFAMSS3key_SS5valuet_tXEfU_SDySSAIGTf1cn_n);
    Model.inputs.setter(v12);
    Model.outputs.setter(ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20ef17ADV5model_SayAI18gH41VG13renamedInputstAN_SDyS2SGtKFAMSSXEfU0_SDySSAKGTf1cn_n);
    uint64_t v13 = v29;
    ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de70ADV5model_SayAI18FeatureDescriptionVG13renamedInputstAN_SDyS2SGtKFAI13fgoH25VSS3key_SS5valuet_tXEfU1_Tf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDyS2SG_20MLModelSpecification13NeuralNetworkV5LayerVs5NeverOTg5077_s8CreateML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de70ADV5model_SayAI18FeatureDescriptionVG13renamedInputstAN_SDyS2SGtKFAI13fgoH25VSS3key_SS5valuet_tXEfU1_Tf1cn_n(v10);
    unint64_t v15 = v28;
    NeuralNetwork.init(layers:preprocessors:)(ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de70ADV5model_SayAI18FeatureDescriptionVG13renamedInputstAN_SDyS2SGtKFAI13fgoH25VSS3key_SS5valuet_tXEfU1_Tf1cn_n, _swiftEmptyArrayStorage);
    (*(void (**)(uint64_t *, void, uint64_t))(v27 + 104))(v15, enum case for ModelKind.neuralNetwork(_:), v26);
    unint64_t v16 = v15;
    uint64_t v17 = ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG40VG13renamedInputstAN_SDyS2SGtKFA2MXEfU2_SDyS2SGSDySSAHGTf1cn_n;
    Model.kind.setter(v16);
    Swift::String v18 = specialized Dictionary<>.inverted()(v10);
    if (v13)
    {
      ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG40VG13renamedInputstAN_SDyS2SGtKFA2MXEfU2_SDyS2SGSDySSAHGTf1cn_n = ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG56VG13renamedInputstAN_SDyS2SGtKFAMSS3key_SS5valuet_tXEfU_SDySSAIGTf1cn_n;
      uint64_t v21 = type metadata accessor for Model(0);
      (*(void (**)(void *, uint64_t))(*(void *)(v21 - 8) + 8))(v17, v21);
      swift_bridgeObjectRelease((_BYTE)ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG40VG13renamedInputstAN_SDyS2SGtKFA2MXEfU2_SDyS2SGSDySSAHGTf1cn_n);
    }
    else
    {
      uint64_t v19 = (uint64_t)v18;
      char v20 = (char)ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG56VG13renamedInputstAN_SDyS2SGtKFAMSS3key_SS5valuet_tXEfU_SDySSAIGTf1cn_n;
      uint64_t v23 = specialized Collection.makeDictionary(indexedBy:)((uint64_t)ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG56VG13renamedInputstAN_SDyS2SGtKFAMSS3key_SS5valuet_tXEfU_SDySSAIGTf1cn_n);
      swift_bridgeObjectRelease(v20);
      swift_bridgeObjectRetain(v19);
      swift_bridgeObjectRetain(v23);
      ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG40VG13renamedInputstAN_SDyS2SGtKFA2MXEfU2_SDyS2SGSDySSAHGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay20MLModelSpecification18FeatureDescriptionVG_AHs5NeverOTg5077_s8CreateML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG40VG13renamedInputstAN_SDyS2SGtKFA2MXEfU2_SDyS2SGSDySSAHGTf1cn_n(v30, v19, v23);
      swift_bridgeObjectRelease(v23);
      swift_bridgeObjectRelease(v19);
    }
  }
  return ML20MLActivityClassifierV5ModelV012makeRenamingE06inputs9renameMap20de17ADV5model_SayAI18fG40VG13renamedInputstAN_SDyS2SGtKFA2MXEfU2_SDyS2SGSDySSAHGTf1cn_n;
}

uint64_t specialized Collection.makeDictionary(indexedBy:)(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for FeatureDescription(0);
  uint64_t v2 = *(void *)(v1 - 8);
  int64_t v3 = *(void *)(v2 + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  unint64_t v49 = &v43;
  Swift::String_optional v6 = alloca(v3);
  Swift::String v7 = alloca(v3);
  uint64_t v53 = v1;
  uint64_t v8 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, v1, &protocol witness table for String);
  if (*(void *)(a1 + 16))
  {
    uint64_t v45 = *(void *)(a1 + 16);
    uint64_t v9 = a1 + ((*(unsigned __int8 *)(v2 + 80) + 32) & ~*(unsigned __int8 *)(v2 + 80));
    uint64_t v47 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v2 + 16);
    uint64_t v50 = *(void *)(v2 + 72);
    uint64_t v46 = a1;
    swift_bridgeObjectRetain(a1);
    uint64_t v10 = v9;
    uint64_t v54 = v8;
    uint64_t v11 = v53;
    uint64_t v12 = &v43;
    uint64_t v48 = v2;
    char v44 = &v43;
    do
    {
      uint64_t v43 = v10;
      v47(v12, v10, v11);
      uint64_t v13 = FeatureDescription.name.getter();
      uint64_t v15 = v14;
      uint64_t v16 = v54;
      BOOL v17 = *(void *)(v54 + 16) == 0;
      uint64_t v52 = v14;
      if (!v17)
      {
        swift_bridgeObjectRetain(v54);
        specialized __RawDictionaryStorage.find<A>(_:)(v13, v15);
        char v19 = v18;
        swift_bridgeObjectRelease(v16);
        BOOL v17 = (v19 & 1) == 0;
        uint64_t v15 = v52;
        if (!v17)
        {
          _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000017, "__coreml_name_compatibility" + 0x8000000000000000, "CreateML/MLActivityClassifier.Model.swift", 41, 2, 556, 0);
          BUG();
        }
      }
      v47(v49, (uint64_t)v12, v53);
      uint64_t v20 = v13;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v16);
      uint64_t v51 = v16;
      uint64_t v54 = v20;
      uint64_t v22 = v15;
      uint64_t v23 = v16;
      unint64_t v24 = specialized __RawDictionaryStorage.find<A>(_:)(v20, v22);
      char v55 = v25;
      BOOL v26 = (v25 & 1) == 0;
      BOOL v27 = __OFADD__(*(void *)(v23 + 16), v26);
      Swift::Int v28 = *(void *)(v23 + 16) + v26;
      if (v27) {
        BUG();
      }
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, FeatureDescription>);
      Swift::Bool v29 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v28);
      char v30 = v55;
      if (v29)
      {
        unint64_t v24 = specialized __RawDictionaryStorage.find<A>(_:)(v54, v52);
        if ((v30 & 1) != (v31 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
          BUG();
        }
      }
      uint64_t v32 = (void *)v51;
      if (v30)
      {
        uint64_t v33 = v53;
        uint64_t v34 = v48;
        (*(void (**)(unint64_t, uint64_t *, uint64_t))(v48 + 40))(*(void *)(v51 + 56) + v50 * v24, v49, v53);
        char v35 = v52;
      }
      else
      {
        *(void *)(v51 + 8 * (v24 >> 6) + 64) |= 1 << v24;
        uint64_t v36 = v32[6];
        uint64_t v37 = 16 * v24;
        *(void *)(v36 + v37) = v54;
        char v35 = v52;
        *(void *)(v36 + v37 + 8) = v52;
        unint64_t v38 = v32[7] + v50 * v24;
        uint64_t v33 = v53;
        uint64_t v39 = v48;
        (*(void (**)(unint64_t, uint64_t *))(v48 + 32))(v38, v49);
        uint64_t v40 = v32[2];
        BOOL v27 = __OFADD__(1, v40);
        uint64_t v41 = v40 + 1;
        if (v27) {
          BUG();
        }
        v32[2] = v41;
        swift_bridgeObjectRetain(v35);
        uint64_t v34 = v39;
      }
      uint64_t v54 = v51;
      swift_bridgeObjectRelease(v35);
      swift_bridgeObjectRelease(0);
      uint64_t v12 = v44;
      (*(void (**)(uint64_t *, uint64_t))(v34 + 8))(v44, v33);
      uint64_t v10 = v50 + v43;
      BOOL v17 = v45-- == 1;
      uint64_t v11 = v33;
    }
    while (!v17);
    swift_bridgeObjectRelease(v46);
    return v54;
  }
  return v8;
}

void *specialized Dictionary<>.inverted()(uint64_t a1)
{
  uint64_t v1 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for String, &protocol witness table for String);
  uint64_t v2 = -1 << *(unsigned char *)(a1 + 32);
  int64_t v3 = (void *)v1;
  uint64_t v4 = ~(-1 << -(char)v2);
  if (-v2 >= 64) {
    uint64_t v4 = -1;
  }
  unint64_t v5 = *(void *)(a1 + 64) & v4;
  uint64_t v51 = a1 + 64;
  int64_t v50 = (unint64_t)(63 - v2) >> 6;
  swift_bridgeObjectRetain(a1);
  int64_t v6 = 0;
  while (1)
  {
    if (v5)
    {
      _BitScanForward64(&v7, v5);
      uint64_t v8 = (v5 - 1) & v5;
      unint64_t v9 = v7 | (v6 << 6);
      int64_t v45 = v6;
      goto LABEL_15;
    }
    int64_t v10 = v6 + 1;
    if (__OFADD__(1, v6)) {
      BUG();
    }
    if (v10 >= v50) {
      break;
    }
    unint64_t i = *(void *)(v51 + 8 * v10);
    if (i)
    {
      int64_t v12 = v6 + 1;
    }
    else
    {
      int64_t v12 = v6 + 2;
      if (v6 + 2 >= v50) {
        break;
      }
      unint64_t i = *(void *)(v51 + 8 * v10 + 8);
      if (!i)
      {
        int64_t v12 = v6 + 3;
        if (v6 + 3 >= v50) {
          break;
        }
        unint64_t i = *(void *)(v51 + 8 * v10 + 16);
        if (!i)
        {
          int64_t v12 = v6 + 4;
          if (v6 + 4 >= v50) {
            break;
          }
          for (unint64_t i = *(void *)(v51 + 8 * v10 + 24); !i; unint64_t i = *(void *)(v51 + 8 * v12))
          {
            BOOL v27 = __OFADD__(1, v12++);
            if (v27) {
              BUG();
            }
            if (v12 >= v50) {
              goto LABEL_31;
            }
          }
        }
      }
    }
    _BitScanForward64(&v13, i);
    uint64_t v8 = i & (i - 1);
    int64_t v45 = v12;
    unint64_t v9 = v13 + (v12 << 6);
LABEL_15:
    unint64_t v43 = v8;
    uint64_t v14 = 16 * v9;
    uint64_t v15 = *(void *)(a1 + 48);
    uint64_t v16 = *(void *)(a1 + 56);
    uint64_t v44 = *(void *)(v15 + v14);
    uint64_t v17 = *(void *)(v15 + v14 + 8);
    uint64_t v48 = *(void *)(v16 + v14);
    uint64_t v18 = *(void *)(v16 + v14 + 8);
    uint64_t v19 = v3[2];
    swift_bridgeObjectRetain(v17);
    swift_bridgeObjectRetain(v18);
    if (v19)
    {
      swift_bridgeObjectRetain((_BYTE)v3);
      specialized __RawDictionaryStorage.find<A>(_:)(v48, v18);
      char v21 = v20;
      swift_bridgeObjectRelease((_BYTE)v3);
      if (v21)
      {
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000020, "Duplicate key in index." + 0x8000000000000000, "CreateML/MLActivityClassifier.Model.swift", 41, 2, 571, 0);
        BUG();
      }
    }
    swift_bridgeObjectRetain(v18);
    uint64_t v49 = v17;
    swift_bridgeObjectRetain(v17);
    uint64_t v22 = v3;
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v3);
    uint64_t v47 = v3;
    uint64_t v42 = v18;
    unint64_t v24 = specialized __RawDictionaryStorage.find<A>(_:)(v48, v18);
    char v52 = v25;
    BOOL v26 = (v25 & 1) == 0;
    BOOL v27 = __OFADD__(v22[2], v26);
    Swift::Int v28 = v22[2] + v26;
    if (v27) {
      BUG();
    }
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, String>);
    if (_NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v28))
    {
      unint64_t v24 = specialized __RawDictionaryStorage.find<A>(_:)(v48, v42);
      if ((v52 & 1) != (v29 & 1))
      {
        KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
        BUG();
      }
    }
    int64_t v3 = v47;
    if (v52)
    {
      uint64_t v30 = v47[7];
      uint64_t v31 = 16 * v24;
      swift_bridgeObjectRelease(*(void *)(v30 + v31 + 8));
      *(void *)(v30 + v31) = v44;
      char v32 = v49;
      *(void *)(v30 + v31 + 8) = v49;
    }
    else
    {
      v47[(v24 >> 6) + 8] |= 1 << v24;
      uint64_t v33 = v47[6];
      uint64_t v34 = 16 * v24;
      *(void *)(v33 + v34) = v48;
      *(void *)(v33 + v34 + 8) = v42;
      uint64_t v35 = v47[7];
      *(void *)(v35 + v34) = v44;
      *(void *)(v35 + v34 + 8) = v49;
      uint64_t v36 = v47[2];
      BOOL v27 = __OFADD__(1, v36);
      uint64_t v37 = v36 + 1;
      if (v27) {
        BUG();
      }
      v47[2] = v37;
      swift_bridgeObjectRetain(v42);
      char v32 = v49;
    }
    swift_bridgeObjectRelease(v32);
    swift_bridgeObjectRelease_n(v42, 2, v38, v39, v40);
    swift_bridgeObjectRelease(0);
    int64_t v6 = v45;
    unint64_t v5 = v43;
  }
LABEL_31:
  outlined consume of [String : [Int]].Iterator._Variant(a1);
  return v3;
}

uint64_t MLActivityClassifier.Model.makePipeline(_:_:_:_:)(uint64_t a1, uint64_t *a2, uint64_t a3, void (*a4)(void, void))
{
  uint64_t v64 = a4;
  uint64_t v56 = a3;
  uint64_t v60 = type metadata accessor for URL(0);
  uint64_t v57 = *(void *)(v60 - 8);
  int64_t v5 = *(void *)(v57 + 64);
  int64_t v6 = alloca(v5);
  unint64_t v7 = alloca(v5);
  uint64_t v53 = &v49;
  uint64_t v8 = alloca(v5);
  unint64_t v9 = alloca(v5);
  uint64_t v59 = &v49;
  uint64_t v50 = type metadata accessor for ModelKind(0);
  uint64_t v51 = *(void *)(v50 - 8);
  int64_t v10 = *(void *)(v51 + 64);
  uint64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  char v52 = &v49;
  uint64_t v62 = type metadata accessor for Model(0);
  uint64_t v58 = *(void *)(v62 - 8);
  int64_t v13 = *(void *)(v58 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  char v55 = &v49;
  uint64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  uint64_t v18 = alloca(v13);
  uint64_t v19 = alloca(v13);
  uint64_t v54 = a2;
  uint64_t v20 = Model.inputs.getter();
  uint64_t v61 = MLActivityClassifier.Model.makeRenamingModel(inputs:renameMap:)(&v49, v20, (uint64_t)v64);
  uint64_t result = swift_bridgeObjectRelease(v20);
  if (!v4)
  {
    uint64_t v63 = &v49;
    uint64_t v22 = v58;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v58 + 32))(&v49, &v49, v62);
    Model.init()();
    uint64_t v64 = 0;
    Model.modelDescription.setter(0xD00000000000001ALL, "ccessfully saved at " + 0x8000000000000000);
    Model.inputs.setter(v61);
    uint64_t v23 = Model.outputs.getter();
    Model.outputs.setter(v23);
    uint64_t v24 = Model.predictedFeatureName.getter();
    Model.predictedFeatureName.setter(v24, v25);
    uint64_t v26 = Model.predictedProbabilitiesName.getter();
    Model.predictedProbabilitiesName.setter(v26, v27);
    Model.specificationVersion.setter(6);
    uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Model>);
    uint64_t v61 = *(void **)(v22 + 72);
    uint64_t v29 = *(unsigned __int8 *)(v22 + 80);
    uint64_t v30 = v22;
    uint64_t v31 = ((int)v29 + 32) & ~*(unsigned __int8 *)(v22 + 80);
    uint64_t v32 = swift_allocObject(v28, v31 + 2 * (void)v61, v29 | 7);
    *(void *)(v32 + 16) = 2;
    *(void *)(v32 + 24) = 4;
    uint64_t v33 = v32 + v31;
    uint64_t v34 = *(void (**)(uint64_t, uint64_t *, uint64_t))(v30 + 16);
    uint64_t v35 = v62;
    v34(v33, v63, v62);
    uint64_t v36 = (char *)v61 + v33;
    uint64_t v37 = v35;
    v34((uint64_t)v36, (uint64_t *)v54, v35);
    uint64_t v38 = v52;
    PipelineClassifierConfiguration.init(models:names:)(v32, _swiftEmptyArrayStorage);
    (*(void (**)(uint64_t *, void, uint64_t))(v51 + 104))(v38, enum case for ModelKind.pipelineClassifier(_:), v50);
    uint64_t v39 = v55;
    Model.kind.setter(v38);
    uint64_t v40 = v59;
    Package.rootModelURL.getter();
    uint64_t v41 = v64;
    Model.write(to:)(v40);
    if (v41)
    {
      uint64_t v64 = v41;
      (*(void (**)(uint64_t *, uint64_t))(v57 + 8))(v59, v60);
      unint64_t v43 = v63;
      uint64_t v44 = *(void (**)(uint64_t *, uint64_t))(v58 + 8);
      v44(v39, v37);
      return ((uint64_t (*)(uint64_t *, uint64_t))v44)(v43, v37);
    }
    else
    {
      uint64_t v64 = *(void (**)(void, void))(v57 + 8);
      v64(v59, v60);
      uint64_t v42 = v53;
      Package.setRootModel(_:)(v39);
      int64_t v45 = v42;
      uint64_t v46 = (void (**)(uint64_t *, uint64_t))(v58 + 8);
      v64(v45, v60);
      uint64_t v47 = *v46;
      uint64_t v48 = v62;
      v47(v39, v62);
      return ((uint64_t (*)(uint64_t *, uint64_t))v47)(v63, v48);
    }
  }
  return result;
}

uint64_t MLActivityClassifier.Model.writeMLPackage(to:metadata:)(uint64_t a1, uint64_t a2, double a3, double a4)
{
  uint64_t v150 = v4;
  uint64_t v189 = v5;
  uint64_t v177 = a1;
  uint64_t v157 = type metadata accessor for ModelKind(0);
  uint64_t v156 = *(void *)(v157 - 8);
  int64_t v6 = *(void *)(v156 + 64);
  unint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v158 = &v133;
  uint64_t v186 = type metadata accessor for MLProgram(0);
  uint64_t v181 = *(void *)(v186 - 8);
  int64_t v9 = *(void *)(v181 + 64);
  int64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  char v188 = &v133;
  uint64_t v183 = type metadata accessor for Model(0);
  uint64_t v182 = *(void *)(v183 - 8);
  int64_t v12 = *(void *)(v182 + 64);
  int64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  Swift::String v187 = &v133;
  uint64_t v152 = type metadata accessor for URL(0);
  uint64_t v151 = *(void *)(v152 - 8);
  int64_t v15 = *(void *)(v151 + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v155 = &v133;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  uint64_t v153 = &v133;
  uint64_t v185 = type metadata accessor for Package(0);
  uint64_t v184 = *(void *)(v185 - 8);
  int64_t v20 = *(void *)(v184 + 64);
  char v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  v193 = &v133;
  uint64_t v172 = type metadata accessor for MLPackageWritingOptions(0);
  uint64_t v171 = *(void *)(v172 - 8);
  int64_t v23 = *(void *)(v171 + 64);
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  unsigned int v178 = &v133;
  uint64_t v170 = type metadata accessor for MLActivityClassifier.Model.MLPackageRepresentation(0);
  int64_t v26 = *(void *)(*(void *)(v170 - 8) + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  unsigned int v180 = &v133;
  uint64_t v179 = type metadata accessor for Tensor(0);
  uint64_t v174 = *(void *)(v179 - 8);
  int64_t v29 = *(void *)(v174 + 64);
  uint64_t v30 = alloca(v29);
  uint64_t v31 = alloca(v29);
  uint64_t v175 = &v133;
  uint64_t v32 = alloca(v29);
  uint64_t v33 = alloca(v29);
  uint64_t v145 = &v133;
  uint64_t v166 = type metadata accessor for ScalarType(0);
  uint64_t v195 = *(void *)(v166 - 8);
  int64_t v34 = *(void *)(v195 + 64);
  uint64_t v35 = alloca(v34);
  uint64_t v36 = alloca(v34);
  uint64_t v167 = &v133;
  int64_t v37 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?)
                              - 8)
                  + 64);
  uint64_t v38 = alloca(v37);
  uint64_t v39 = alloca(v37);
  uint64_t v168 = &v133;
  int64_t v40 = *(void *)(*(void *)(type metadata accessor for TensorShape(0) - 8) + 64);
  uint64_t v41 = alloca(v40);
  uint64_t v42 = alloca(v40);
  uint64_t v176 = &v133;
  uint64_t v159 = *(void *)a2;
  v160 = *(char **)(a2 + 8);
  uint64_t v161 = *(void *)(a2 + 16);
  uint64_t v162 = *(void *)(a2 + 24);
  long long v43 = *(_OWORD *)(a2 + 32);
  long long v142 = v43;
  uint64_t v163 = *(void *)(a2 + 48);
  uint64_t v164 = *(void *)(a2 + 56);
  uint64_t v165 = *(void *)(a2 + 64);
  uint64_t v44 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Tensor)>);
  uint64_t v45 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, Tensor))
                  - 8);
  uint64_t v46 = *(unsigned __int8 *)(v45 + 80);
  uint64_t v47 = ((int)v46 + 32) & ~*(unsigned __int8 *)(v45 + 80);
  uint64_t v48 = swift_allocObject(v44, v47 + *(void *)(v45 + 72), v46 | 7);
  *(void *)(v48 + 16) = 1;
  *(void *)(v48 + 24) = 2;
  *(void *)(v48 + v47) = 0x6E496574617473;
  *(void *)(v48 + v47 + 8) = 0xE700000000000000;
  uint64_t v146 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v49 = (void *)swift_allocObject(v146, 40, 7);
  v49[2] = 1;
  v49[3] = 2;
  uint64_t v50 = type metadata accessor for MLActivityClassifier.Model(0);
  uint64_t v51 = *(void *)(v189 + *(int *)(v50 + 32));
  if (v51 + 0x4000000000000000 < 0) {
    BUG();
  }
  v49[4] = 2 * v51;
  uint64_t v190 = v50;
  TensorShape.init(_:)(v49, *(double *)&v43, a4);
  uint64_t v52 = type metadata accessor for ComputeDevice(0);
  uint64_t v53 = (uint64_t)v168;
  uint64_t v147 = v52;
  __swift_storeEnumTagSinglePayload((uint64_t)v168, 1, 1, v52);
  uint64_t v54 = *(void (**)(void, void, void))(v195 + 104);
  char v55 = v167;
  unsigned int v173 = enum case for ScalarType.float32(_:);
  Swift::String v148 = (void (*)(uint64_t *, void, uint64_t))v54;
  v54(v167, enum case for ScalarType.float32(_:), v166);
  Tensor.init(zeros:scalarType:on:)(v176, v55, v53);
  uint64_t v191 = Dictionary.init(dictionaryLiteral:)(v48, &type metadata for String, v179, &protocol witness table for String);
  uint64_t v169 = *(int *)(v190 + 64);
  uint64_t v56 = *(void *)(v189 + v169 + 40);
  swift_bridgeObjectRetain(v56);
  uint64_t v192 = MLActivityClassifier.Model.renameInputsAsNeeded(inputs:)(v56);
  swift_bridgeObjectRelease(v56);
  if (*(void *)(v56 + 16))
  {
    uint64_t v149 = *(void *)(v56 + 16);
    swift_bridgeObjectRetain(v56);
    uint64_t v154 = v56;
    uint64_t v57 = (uint64_t *)(v56 + 40);
    do
    {
      uint64_t v58 = *(v57 - 1);
      Swift::String v143 = v57;
      uint64_t v59 = *v57;
      uint64_t v60 = v192;
      uint64_t v61 = v192[2];
      swift_bridgeObjectRetain(*v57);
      uint64_t v190 = v58;
      if (v61)
      {
        swift_bridgeObjectRetain(v59);
        unint64_t v62 = specialized __RawDictionaryStorage.find<A>(_:)(v58, v59);
        uint64_t v63 = v59;
        uint64_t v65 = v189;
        if (v64)
        {
          uint64_t v66 = v60[7];
          uint64_t v67 = 16 * v62;
          uint64_t v190 = *(void *)(v66 + v67);
          uint64_t v63 = *(void *)(v66 + v67 + 8);
          swift_bridgeObjectRetain(v63);
          swift_bridgeObjectRelease(v59);
        }
        swift_bridgeObjectRelease(v59);
        uint64_t v195 = v63;
      }
      else
      {
        uint64_t v65 = v189;
        uint64_t v195 = v59;
      }
      uint64_t v68 = (void *)swift_allocObject(v146, 40, 7);
      v68[2] = 1;
      v68[3] = 2;
      v68[4] = *(void *)(v65 + v169 + 32);
      uint64_t v69 = v176;
      TensorShape.init(_:)(v68, *(double *)&v43, a4);
      uint64_t v70 = (uint64_t)v168;
      __swift_storeEnumTagSinglePayload((uint64_t)v168, 1, 1, v147);
      uint64_t v71 = v167;
      v148(v167, v173, v166);
      uint64_t v72 = v145;
      Tensor.init(zeros:scalarType:on:)(v69, v71, v70);
      uint64_t v144 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v174 + 32);
      v144(v175, v72, v179);
      uint64_t v73 = v191;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v191);
      uint64_t v134 = (void *)v73;
      unint64_t v75 = specialized __RawDictionaryStorage.find<A>(_:)(v190, v195);
      char v194 = v76;
      BOOL v77 = (v76 & 1) == 0;
      BOOL v78 = __OFADD__(*(void *)(v73 + 16), v77);
      Swift::Int v79 = *(void *)(v73 + 16) + v77;
      if (v78) {
        BUG();
      }
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, Tensor>);
      Swift::Bool v80 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v79);
      char v81 = v194;
      if (v80)
      {
        unint64_t v75 = specialized __RawDictionaryStorage.find<A>(_:)(v190, v195);
        if ((v81 & 1) != (v82 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
          BUG();
        }
      }
      uint64_t v83 = v134;
      if (v81)
      {
        (*(void (**)(unint64_t, uint64_t *, uint64_t))(v174 + 40))(v134[7] + v75 * *(void *)(v174 + 72), v175, v179);
        uint64_t v84 = v178;
        char v85 = v195;
      }
      else
      {
        v134[(v75 >> 6) + 8] |= 1 << v75;
        uint64_t v86 = v83[6];
        uint64_t v87 = 16 * v75;
        *(void *)(v86 + v87) = v190;
        char v88 = v195;
        *(void *)(v86 + v87 + 8) = v195;
        v144((uint64_t *)(v83[7] + v75 * *(void *)(v174 + 72)), v175, v179);
        uint64_t v89 = v83[2];
        BOOL v78 = __OFADD__(1, v89);
        uint64_t v90 = v89 + 1;
        uint64_t v84 = v178;
        if (v78) {
          BUG();
        }
        v83[2] = v90;
        swift_bridgeObjectRetain(v88);
        char v85 = v88;
      }
      uint64_t v191 = (uint64_t)v134;
      swift_bridgeObjectRelease(v85);
      swift_bridgeObjectRelease(0);
      uint64_t v57 = v143 + 2;
      BOOL v91 = v149-- == 1;
      uint64_t v92 = v186;
      uint64_t v93 = v177;
    }
    while (!v91);
    swift_bridgeObjectRelease(v154);
  }
  else
  {
    uint64_t v92 = v186;
    uint64_t v93 = v177;
    uint64_t v84 = v178;
  }
  uint64_t v94 = (uint64_t)v180;
  outlined init with copy of MLTrainingSessionParameters(v189, (uint64_t)v180, type metadata accessor for MLActivityClassifier.Model);
  char v95 = (char)v192;
  *(void *)(v94 + *(int *)(v170 + 20)) = v192;
  swift_bridgeObjectRetain(v95);
  uint64_t v96 = v191;
  swift_bridgeObjectRetain(v191);
  static MLPackageWritingOptions.default.getter();
  uint64_t v97 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model.MLPackageRepresentation and conformance MLActivityClassifier.Model.MLPackageRepresentation, type metadata accessor for MLActivityClassifier.Model.MLPackageRepresentation, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model.MLPackageRepresentation);
  uint64_t v191 = v96;
  uint64_t v98 = v150;
  Layer<>.writeMLPackage(withInput:output:to:options:)(v96, 0, v93, v84, v170, v97);
  if (v98)
  {
    swift_bridgeObjectRelease((_BYTE)v192);
    char v99 = v191;
    swift_bridgeObjectRelease(v191);
    (*(void (**)(uint64_t *, uint64_t))(v171 + 8))(v84, v172);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v180, type metadata accessor for MLActivityClassifier.Model.MLPackageRepresentation);
    return swift_bridgeObjectRelease(v99);
  }
  swift_bridgeObjectRelease(v191);
  (*(void (**)(uint64_t *, uint64_t))(v171 + 8))(v84, v172);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v180, type metadata accessor for MLActivityClassifier.Model.MLPackageRepresentation);
  uint64_t v100 = v153;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v151 + 16))(v153, v93, v152);
  Package.init(url:)(v100);
  uint64_t v102 = v155;
  Package.rootModelURL.getter();
  Model.init(contentsOf:)(v102);
  uint64_t v195 = 0;
  unint64_t v103 = v158;
  Model.kind.getter();
  uint64_t v104 = v157;
  uint64_t v105 = v156;
  if ((*(unsigned int (**)(uint64_t *, uint64_t))(v156 + 88))(v103, v157) != enum case for ModelKind.mlProgram(_:))
  {
    (*(void (**)(uint64_t *, uint64_t))(v105 + 8))(v103, v104);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000026, "ityClassifier.Model.swift" + 0x8000000000000000, "CreateML/MLActivityClassifier.Model.swift", 41, 2, 482, 0);
    BUG();
  }
  swift_bridgeObjectRelease(v191);
  (*(void (**)(uint64_t *, uint64_t))(v105 + 96))(v103, v104);
  uint64_t v106 = (uint64_t)v188;
  uint64_t v107 = v103;
  uint64_t v108 = v181;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v181 + 32))(v188, v107, v92);
  uint64_t v109 = v189;
  uint64_t v110 = v195;
  MLActivityClassifier.Model.makeClassifier(_:_:_:)(v106, (uint64_t)v187, (uint64_t)v193);
  uint64_t v195 = v110;
  if (v110)
  {
    swift_bridgeObjectRelease((_BYTE)v192);
    (*(void (**)(uint64_t, uint64_t))(v108 + 8))(v106, v92);
    (*(void (**)(uint64_t *, uint64_t))(v182 + 8))(v187, v183);
    uint64_t v111 = (uint64_t)v193;
    return (*(uint64_t (**)(uint64_t, uint64_t))(v184 + 8))(v111, v185);
  }
  uint64_t v112 = *(void *)(v109 + v169 + 40);
  uint64_t v113 = *(void *)(v112 + 16);
  if (v113)
  {
    swift_bridgeObjectRetain(v112);
    uint64_t v190 = v112;
    uint64_t v114 = (unint64_t *)(v112 + 40);
    while (1)
    {
      uint64_t v115 = *(v114 - 1);
      unint64_t v116 = *v114;
      swift_bridgeObjectRetain(*v114);
      uint64_t v117 = v195;
      LOBYTE(v115) = specialized Sequence.contains(where:)(0, v115, v116);
      uint64_t v195 = v117;
      swift_bridgeObjectRelease(v116);
      if (v115) {
        break;
      }
      v114 += 2;
      if (!--v113)
      {
        swift_bridgeObjectRelease((_BYTE)v192);
        swift_bridgeObjectRelease(v190);
        uint64_t v108 = v181;
        uint64_t v92 = v186;
        goto LABEL_32;
      }
    }
    uint64_t v123 = v190;
    swift_bridgeObjectRelease(v190);
    uint64_t v124 = v187;
    uint64_t v119 = (uint64_t)v193;
    char v125 = (char)v192;
    uint64_t v126 = v195;
    MLActivityClassifier.Model.makePipeline(_:_:_:_:)(v123, v187, (uint64_t)v193, (void (*)(void, void))v192);
    uint64_t v195 = v126;
    if (v126)
    {
      swift_bridgeObjectRelease(v125);
      (*(void (**)(uint64_t *, uint64_t))(v181 + 8))(v188, v186);
      (*(void (**)(uint64_t *, uint64_t))(v182 + 8))(v124, v183);
      uint64_t v111 = v119;
      return (*(uint64_t (**)(uint64_t, uint64_t))(v184 + 8))(v111, v185);
    }
    swift_bridgeObjectRelease(v125);
    uint64_t v108 = v181;
    uint64_t v92 = v186;
    uint64_t v118 = v188;
  }
  else
  {
    swift_bridgeObjectRelease((_BYTE)v192);
LABEL_32:
    uint64_t v118 = v188;
    uint64_t v119 = (uint64_t)v193;
  }
  uint64_t v134 = (void *)v159;
  unint64_t v135 = v160;
  uint64_t v136 = v161;
  uint64_t v137 = v162;
  long long v138 = v142;
  uint64_t v139 = v163;
  uint64_t v140 = v164;
  uint64_t v141 = v165;
  uint64_t v120 = v195;
  MLActivityClassifier.Model.addMetadata(_:_:)(v119, (uint64_t *)&v134);
  if (v120)
  {
    uint64_t v121 = v118;
    uint64_t v122 = v92;
  }
  else
  {
    uint64_t v195 = 0;
    uint64_t v134 = 0;
    unint64_t v135 = (char *)0xE000000000000000;
    _StringGuts.grow(_:)(39);
    swift_bridgeObjectRelease((_BYTE)v135);
    uint64_t v134 = (void *)0xD000000000000024;
    unint64_t v135 = "del to be an MLProgram" + 0x8000000000000000;
    Swift::String v127 = URL.path(percentEncoded:)(1);
    char object = (char)v127._object;
    String.append(_:)(v127);
    swift_bridgeObjectRelease(object);
    v129._uint64_t countAndFlagsBits = 46;
    v129._char object = (void *)0xE100000000000000;
    String.append(_:)(v129);
    uint64_t v130 = (uint64_t)v134;
    uint64_t v131 = v135;
    os_log_type_t v132 = static os_log_type_t.info.getter();
    v129._uint64_t countAndFlagsBits = v130;
    v129._char object = v131;
    log(_:type:)(v129, v132);
    swift_bridgeObjectRelease((_BYTE)v131);
    uint64_t v121 = v188;
    uint64_t v122 = v186;
  }
  (*(void (**)(uint64_t *, uint64_t))(v108 + 8))(v121, v122);
  (*(void (**)(uint64_t *, uint64_t))(v182 + 8))(v187, v183);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v184 + 8))(v193, v185);
}

MLModel __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> MLActivityClassifier.Model.makeMLModel()()
{
  uint64_t v60 = v0;
  uint64_t v53 = v1;
  uint64_t v63 = (void (*)(uint64_t *, uint64_t))type metadata accessor for UUID(0);
  uint64_t v54 = *((void *)v63 - 1);
  int64_t v3 = *(void *)(v54 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  char v55 = &v44;
  uint64_t v61 = type metadata accessor for URL(0);
  uint64_t v58 = *(void **)(v61 - 8);
  int64_t v6 = v58[8];
  unint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v57 = &v44;
  int64_t v9 = alloca(v6);
  int64_t v10 = alloca(v6);
  unint64_t v62 = &v44;
  uint64_t v11 = alloca(v6);
  int64_t v12 = alloca(v6);
  uint64_t v59 = &v44;
  int64_t v56 = v6;
  int64_t v13 = alloca(v6);
  uint64_t v14 = alloca(v6);
  char v64 = &v44;
  int64_t v15 = objc_opt_self(NSFileManager);
  id v16 = [v15 defaultManager];
  id v17 = v16;
  id v18 = [v17 temporaryDirectory];
  id v19 = v18;

  static URL._unconditionallyBridgeFromObjectiveC(_:)(v19);
  uint64_t v45 = 0;
  unint64_t v46 = 0xE000000000000000;
  int64_t v20 = v55;
  UUID.init()();
  uint64_t v21 = UUID.uuidString.getter();
  unint64_t v23 = v22;
  (*(void (**)(uint64_t *, void *))(v54 + 8))(v20, v63);
  swift_bridgeObjectRelease(v46);
  uint64_t v45 = v21;
  unint64_t v46 = v23;
  v24._uint64_t countAndFlagsBits = 0x616B6361706C6D2ELL;
  v24._char object = (void *)0xEA00000000006567;
  String.append(_:)(v24);
  LOBYTE(v20) = v46;
  uint64_t v25 = v59;
  URL.appendingPathComponent(_:)(v45, v46);
  swift_bridgeObjectRelease((_BYTE)v20);
  uint64_t v63 = (void (*)(uint64_t *, uint64_t))v58[1];
  v63(v25, v61);
  int64_t v26 = NSFullUserName();
  uint64_t v27 = v26;
  uint64_t v28 = static String._unconditionallyBridgeFromObjectiveC(_:)(v27);
  id v30 = v29;

  uint64_t v45 = v28;
  unint64_t v46 = (unint64_t)v30;
  unint64_t v47 = 0xD000000000000033;
  uint64_t v48 = "RandomForestRegressor" + 0x8000000000000000;
  long long v49 = 0;
  uint64_t v50 = 49;
  unint64_t v51 = 0xE100000000000000;
  uint64_t v52 = 0;
  uint64_t v31 = v60;
  MLActivityClassifier.Model.writeMLPackage(to:metadata:)((uint64_t)v64, (uint64_t)&v45, 0.0, v2);
  swift_bridgeObjectRelease(0);
  swift_bridgeObjectRelease_n(0, 2, v32, v33, v34);
  swift_bridgeObjectRelease(("RandomForestRegressor" + 0x8000000000000000));
  swift_bridgeObjectRelease((_BYTE)v30);
  if (v31)
  {
    v63(v64, v61);
  }
  else
  {
    uint64_t v35 = v58;
    uint64_t v60 = (void (*)(void, void, void))v58[2];
    v60(v59, v64, v61);
    uint64_t v36 = *((unsigned __int8 *)v35 + 80);
    uint64_t v37 = ~*((unsigned __int8 *)v35 + 80) & (v36 + 16);
    uint64_t v38 = swift_allocObject(&unk_398FF0, v37 + v56, v36 | 7);
    uint64_t v39 = v38 + v37;
    uint64_t v40 = v61;
    ((void (*)(uint64_t, uint64_t *, uint64_t))v35[4])(v39, v59, v61);
    specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLActivityClassifier.Model.makeMLModel(), v38);
    swift_release();
    type metadata accessor for MLModel();
    uint64_t v41 = (uint64_t)v57;
    v60(v57, v62, v40);
    id v30 = @nonobjc MLModel.__allocating_init(contentsOf:)(v41);
    long long v43 = v63;
    v63(v62, v40);
    v43(v64, v40);
  }
  return (MLModel)v30;
}

uint64_t closure #1 in MLActivityClassifier.Model.makeMLModel()(uint64_t a1, uint64_t a2)
{
  *(void *)(v2 + 32) = a2;
  *(void *)(v2 + 24) = a1;
  return swift_task_switch(closure #1 in MLActivityClassifier.Model.makeMLModel(), 0, 0);
}

uint64_t closure #1 in MLActivityClassifier.Model.makeMLModel()()
{
  uint64_t v1 = (NSURL *)objc_opt_self(MLModel);
  URL._bridgeToObjectiveC()(v1);
  int64_t v3 = v2;
  *(void *)(v0 + 16) = 0;
  id v4 = [(NSURL *)v1 compileModelAtURL:v2 error:v0 + 16];
  id v5 = v4;

  int64_t v6 = *(void **)(v0 + 16);
  if (v5)
  {
    static URL._unconditionallyBridgeFromObjectiveC(_:)(v5);
    v6;
    id v7 = v5;
  }
  else
  {
    id v9 = *(id *)(v0 + 16);
    _convertNSErrorToError(_:)(v6);
    id v7 = v9;

    swift_willThrow();
  }
  return (*(uint64_t (**)(id, const char *, uint64_t, void))(v0 + 8))(v7, "compileModelAtURL:error:", v8, __stack_chk_guard);
}

uint64_t type metadata accessor for MLActivityClassifier.Model.MLPackageRepresentation(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLActivityClassifier.Model.MLPackageRepresentation, (uint64_t)&nominal type descriptor for MLActivityClassifier.Model.MLPackageRepresentation);
}

unint64_t specialized Collection.first.getter(uint64_t a1, unint64_t a2)
{
  uint64_t v2 = a1 & 0xFFFFFFFFFFFFLL;
  uint64_t v3 = HIBYTE(a2) & 0xF;
  if ((a2 & 0x2000000000000000) == 0) {
    uint64_t v3 = a1 & 0xFFFFFFFFFFFFLL;
  }
  if (v3)
  {
    unint64_t v5 = _StringGuts.validateScalarIndex(_:)(0xFuLL, a1, a2);
    if ((a2 & 0x1000000000000000) != 0)
    {
      unsigned int v10 = _StringGuts.foreignErrorCorrectedScalar(startingAt:)(v5 & 0xFFFFFFFFFFFF0000, a1, a2);
    }
    else
    {
      unint64_t v6 = v5 >> 16;
      if ((a2 & 0x2000000000000000) != 0)
      {
        uint64_t v8 = v14;
        v14[0] = a1;
        v14[1] = a2 & 0xFFFFFFFFFFFFFFLL;
        uint64_t v9 = HIBYTE(a2) & 0xF;
      }
      else
      {
        if ((a1 & 0x1000000000000000) != 0)
        {
          uint64_t v7 = (a2 & 0xFFFFFFFFFFFFFFFLL) + 32;
        }
        else
        {
          unint64_t v12 = v5 >> 16;
          uint64_t v7 = _StringObject.sharedUTF8.getter(a1, a2);
          uint64_t v2 = v13;
          unint64_t v6 = v12;
        }
        uint64_t v8 = (void *)v7;
        uint64_t v9 = v2;
      }
      unsigned int v10 = _decodeScalar(_:startingAt:)(v8, v9, v6);
    }
  }
  else
  {
    unsigned int v10 = 0;
  }
  return ((unint64_t)(v3 == 0) << 32) | v10;
}

unint64_t _StringGuts.validateScalarIndex(_:)(unint64_t a1, uint64_t a2, unint64_t a3)
{
  unint64_t v4 = a1;
  if ((a1 & 1) == 0
    || (a1 & 0xC) == 4 << (((a3 & 0x1000000000000000) == 0) | ((a2 & 0x800000000000000) != 0)))
  {
    unint64_t v6 = _StringGuts.validateSubscalarIndex(_:)(a1, a2, a3);
    unint64_t v4 = v6;
    if ((v6 & 1) == 0) {
      return (_StringGuts.scalarAlignSlow(_:)(v6, a2, a3) & 0xFFFFFFFFFFFFFFF2) + (v6 & 0xC) + 1;
    }
  }
  else
  {
    unint64_t v5 = HIBYTE(a3) & 0xF;
    if ((a3 & 0x2000000000000000) == 0) {
      unint64_t v5 = a2 & 0xFFFFFFFFFFFFLL;
    }
    if (a1 >> 16 >= v5) {
      BUG();
    }
  }
  return v4;
}

unint64_t _StringGuts.validateSubscalarIndex(_:)(unint64_t a1, uint64_t a2, unint64_t a3)
{
  if ((a1 & 0xC) == 4 << (((a3 & 0x1000000000000000) == 0) | ((a2 & 0x800000000000000) != 0))) {
    a1 = _StringGuts._slowEnsureMatchingEncoding(_:)(a1, a2, a3);
  }
  unint64_t v4 = HIBYTE(a3) & 0xF;
  if ((a3 & 0x2000000000000000) == 0) {
    unint64_t v4 = a2 & 0xFFFFFFFFFFFFLL;
  }
  if (a1 >> 16 >= v4) {
    BUG();
  }
  return a1;
}

uint64_t _StringGuts.scalarAlignSlow(_:)(unint64_t a1, uint64_t a2, unint64_t a3)
{
  if ((a1 & 0xC000) != 0 || a1 < 0x10000)
  {
    a1 &= 0xFFFFFFFFFFFF0000;
    return a1;
  }
  unint64_t v3 = a1 >> 16;
  if ((a3 & 0x1000000000000000) == 0)
  {
    if ((a3 & 0x2000000000000000) != 0)
    {
      v12[0] = a2;
      v12[1] = a3 & 0xFFFFFFFFFFFFFFLL;
      if (v3 != (HIBYTE(a3) & 0xF))
      {
        for (char i = *((unsigned char *)v12 + v3); (i & 0xC0) == 0x80; char i = *(&v11 + v3--))
          ;
      }
    }
    else
    {
      if ((a2 & 0x1000000000000000) != 0)
      {
        uint64_t v4 = (a3 & 0xFFFFFFFFFFFFFFFLL) + 32;
        uint64_t v5 = a2 & 0xFFFFFFFFFFFFLL;
      }
      else
      {
        uint64_t v4 = _StringObject.sharedUTF8.getter(a2, a3);
        uint64_t v5 = v10;
      }
      if (v3 != v5)
      {
        for (char j = *(unsigned char *)(v4 + v3); (j & 0xC0) == 0x80; char j = *(unsigned char *)(v4 + v3-- - 1))
          ;
      }
    }
    return v3 << 16;
  }
  uint64_t v9 = HIBYTE(a3) & 0xF;
  if ((a3 & 0x2000000000000000) == 0) {
    uint64_t v9 = a2 & 0xFFFFFFFFFFFFLL;
  }
  if (v3 == v9) {
    return a1;
  }
  return _StringGuts.foreignScalarAlign(_:)(a1, a2, a3);
}

uint64_t sub_101B43()
{
  uint64_t v1 = type metadata accessor for URL(0);
  uint64_t v2 = *(void *)(v1 - 8);
  uint64_t v3 = *(unsigned __int8 *)(v2 + 80);
  uint64_t v4 = ~*(unsigned __int8 *)(v2 + 80) & (v3 + 16);
  uint64_t v5 = v4 + v0;
  uint64_t v6 = *(void *)(v2 + 64) + v4;
  (*(void (**)(uint64_t, uint64_t))(v2 + 8))(v5, v1);
  return swift_deallocObject(v0, v6, v3 | 7);
}

uint64_t partial apply for closure #1 in MLActivityClassifier.Model.makeMLModel()(uint64_t a1)
{
  uint64_t v3 = type metadata accessor for URL(0);
  uint64_t v4 = v1
     + (~*(unsigned __int8 *)(*(void *)(v3 - 8) + 80) & (*(unsigned __int8 *)(*(void *)(v3 - 8)
                                                                                              + 80)
                                                           + 16));
  uint64_t v5 = (void *)swift_task_alloc(dword_3A7794);
  *(void *)(v2 + 16) = v5;
  void *v5 = v2;
  v5[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLActivityClassifier.Model.makeMLModel()(a1, v4);
}

void *initializeBufferWithCopyOfBuffer for MLActivityClassifier.Model.MLPackageRepresentation(_OWORD *a1, char *a2, uint64_t a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v29 = *(void *)a2;
    *uint64_t v3 = *(void *)a2;
    uint64_t v3 = (void *)(v29 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    *a1 = *(_OWORD *)a2;
    uint64_t v5 = *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
    uint64_t v6 = type metadata accessor for LearningPhase(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16))((char *)a1 + v5, &a2[v5], v6);
    uint64_t v7 = (int *)type metadata accessor for MLActivityClassifier.Model(0);
    uint64_t v8 = v7[5];
    __dsta = (void *)type metadata accessor for Conv2D(0);
    char v55 = *(void (**)(char *, char *, void *))(*(__dsta - 1) + 16);
    v55((char *)a1 + v8, &a2[v8], __dsta);
    uint64_t v9 = v7[6];
    uint64_t v47 = type metadata accessor for ReLU(0);
    long long v49 = *(void (**)(char *, char *, uint64_t))(*(void *)(v47 - 8) + 16);
    v49((char *)a1 + v9, &a2[v9], v47);
    uint64_t v10 = v7[7];
    uint64_t v51 = type metadata accessor for Dropout(0);
    uint64_t v53 = *(void (**)(char *, char *, uint64_t))(*(void *)(v51 - 8) + 16);
    v53((char *)a1 + v10, &a2[v10], v51);
    uint64_t v11 = v7[8];
    unint64_t v12 = (char *)a1 + v11;
    uint64_t v13 = &a2[v11];
    *(_OWORD *)((char *)a1 + v11) = *(_OWORD *)&a2[v11];
    *((unsigned char *)a1 + v11 + 16) = a2[v11 + 16];
    *((unsigned char *)a1 + v11 + 17) = a2[v11 + 17];
    uint64_t v14 = *(int *)(type metadata accessor for MLActivityClassifier.LSTMBlock(0) + 32);
    int64_t v15 = &v12[v14];
    id v16 = &v13[v14];
    uint64_t v17 = type metadata accessor for LSTM(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 16))(v15, v16, v17);
    v55((char *)a1 + v7[9], &a2[v7[9]], __dsta);
    uint64_t v18 = v7[10];
    uint64_t v19 = type metadata accessor for BatchNorm(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16))((char *)a1 + v18, &a2[v18], v19);
    v49((char *)a1 + v7[11], &a2[v7[11]], v47);
    v53((char *)a1 + v7[12], &a2[v7[12]], v51);
    v55((char *)a1 + v7[13], &a2[v7[13]], __dsta);
    *(void *)((char *)a1 + v7[14]) = *(void *)&a2[v7[14]];
    uint64_t v20 = v7[15];
    uint64_t v52 = *(void *)&a2[v20];
    *(void *)((char *)a1 + v20) = v52;
    int64_t v56 = v7;
    uint64_t v21 = v7[16];
    unint64_t v22 = (char *)a1 + v21;
    unint64_t v23 = &a2[v21];
    *(void *)((char *)a1 + v21) = *(void *)&a2[v21];
    *(void *)((char *)a1 + v21 + 8) = *(void *)&a2[v21 + 8];
    *((unsigned char *)a1 + v21 + 16) = a2[v21 + 16];
    *(_OWORD *)((char *)a1 + v21 + 24) = *(_OWORD *)&a2[v21 + 24];
    uint64_t v54 = *(void *)&a2[v21 + 40];
    *(void *)((char *)a1 + v21 + 40) = v54;
    *(void *)((char *)a1 + v21 + 48) = *(void *)&a2[v21 + 48];
    uint64_t v45 = *(void *)&a2[v21 + 56];
    *(void *)((char *)a1 + v21 + 56) = v45;
    *(void *)((char *)a1 + v21 + 64) = *(void *)&a2[v21 + 64];
    uint64_t v46 = *(void *)&a2[v21 + 72];
    *(void *)((char *)a1 + v21 + 72) = v46;
    uint64_t v50 = type metadata accessor for MLActivityClassifier.Configuration(0);
    uint64_t v24 = *(int *)(v50 + 44);
    uint64_t v48 = v22;
    __dst = &v22[v24];
    uint64_t v25 = v23;
    int64_t v26 = &v23[v24];
    uint64_t v27 = type metadata accessor for DataFrame(0);
    swift_bridgeObjectRetain(v52);
    swift_bridgeObjectRetain(v54);
    swift_bridgeObjectRetain(v45);
    swift_bridgeObjectRetain(v46);
    if (__swift_getEnumTagSinglePayload((uint64_t)v26, 1, v27))
    {
      uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
      memcpy(__dst, v26, *(void *)(*(void *)(v28 - 8) + 64));
    }
    else
    {
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v27 - 8) + 16))(__dst, v26, v27);
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v27);
    }
    uint64_t v30 = *(int *)(v50 + 48);
    uint64_t v31 = &v48[v30];
    uint64_t v32 = &v25[v30];
    if (__swift_getEnumTagSinglePayload((uint64_t)v32, 1, v27))
    {
      uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
      memcpy(v31, v32, *(void *)(*(void *)(v33 - 8) + 64));
    }
    else
    {
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v27 - 8) + 16))(v31, v32, v27);
      __swift_storeEnumTagSinglePayload((uint64_t)v31, 0, 1, v27);
    }
    uint64_t v34 = v56[17];
    uint64_t v35 = *(void **)&a2[v34];
    *(void *)((char *)v3 + v34) = v35;
    uint64_t v36 = v56[18];
    uint64_t v37 = (void *)((char *)v3 + v36);
    uint64_t v38 = &a2[v36];
    uint64_t v39 = *(void *)&a2[v36];
    v35;
    if (v39)
    {
      *uint64_t v37 = v39;
      v37[1] = *((void *)v38 + 1);
      uint64_t v40 = *((void *)v38 + 2);
      v37[2] = v40;
      swift_retain();
      swift_retain();
      swift_bridgeObjectRetain(v40);
    }
    else
    {
      v37[2] = *((void *)v38 + 2);
      *(_OWORD *)uint64_t v37 = *(_OWORD *)v38;
    }
    uint64_t v41 = *(int *)(a3 + 20);
    uint64_t v42 = *(void *)&a2[v41];
    *(void *)((char *)v3 + v41) = v42;
    swift_bridgeObjectRetain(v42);
  }
  return v3;
}

uint64_t destroy for MLActivityClassifier.Model.MLPackageRepresentation(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a1 + *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
  uint64_t v3 = type metadata accessor for LearningPhase(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8))(v2, v3);
  int v4 = (int *)type metadata accessor for MLActivityClassifier.Model(0);
  uint64_t v5 = a1 + v4[5];
  uint64_t v22 = type metadata accessor for Conv2D(0);
  unint64_t v23 = *(void (**)(uint64_t, uint64_t))(*(void *)(v22 - 8) + 8);
  v23(v5, v22);
  uint64_t v6 = a1 + v4[6];
  uint64_t v24 = type metadata accessor for ReLU(0);
  uint64_t v19 = *(void (**)(uint64_t, uint64_t))(*(void *)(v24 - 8) + 8);
  v19(v6, v24);
  uint64_t v7 = a1 + v4[7];
  uint64_t v20 = type metadata accessor for Dropout(0);
  uint64_t v21 = *(void (**)(uint64_t, uint64_t))(*(void *)(v20 - 8) + 8);
  v21(v7, v20);
  uint64_t v8 = a1 + v4[8];
  uint64_t v9 = v8 + *(int *)(type metadata accessor for MLActivityClassifier.LSTMBlock(0) + 32);
  uint64_t v10 = type metadata accessor for LSTM(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v10 - 8) + 8))(v9, v10);
  v23(a1 + v4[9], v22);
  uint64_t v11 = a1 + v4[10];
  uint64_t v12 = type metadata accessor for BatchNorm(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v12 - 8) + 8))(v11, v12);
  v19(a1 + v4[11], v24);
  v21(a1 + v4[12], v20);
  v23(a1 + v4[13], v22);
  swift_bridgeObjectRelease(*(void *)(a1 + v4[15]));
  uint64_t v13 = (void *)(a1 + v4[16]);
  swift_bridgeObjectRelease(v13[5]);
  swift_bridgeObjectRelease(v13[7]);
  swift_bridgeObjectRelease(v13[9]);
  uint64_t v25 = type metadata accessor for MLActivityClassifier.Configuration(0);
  uint64_t v14 = (uint64_t)v13 + *(int *)(v25 + 44);
  uint64_t v15 = type metadata accessor for DataFrame(0);
  if (!__swift_getEnumTagSinglePayload(v14, 1, v15)) {
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v15 - 8) + 8))(v14, v15);
  }
  uint64_t v16 = (uint64_t)v13 + *(int *)(v25 + 48);
  if (!__swift_getEnumTagSinglePayload(v16, 1, v15)) {
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v15 - 8) + 8))(v16, v15);
  }

  uint64_t v17 = v4[18];
  if (*(void *)(a1 + v17))
  {
    swift_release();
    swift_release();
    swift_bridgeObjectRelease(*(void *)(a1 + v17 + 16));
  }
  return swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(a2 + 20)));
}

char *initializeWithCopy for MLActivityClassifier.Model.MLPackageRepresentation(char *a1, char *a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  uint64_t v4 = *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
  uint64_t v5 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v5 - 8) + 16))(&a1[v4], &a2[v4], v5);
  uint64_t v6 = (int *)type metadata accessor for MLActivityClassifier.Model(0);
  uint64_t v7 = v6[5];
  __dsta = (void *)type metadata accessor for Conv2D(0);
  uint64_t v53 = *(void (**)(char *, char *, void *))(*(__dsta - 1) + 16);
  v53(&a1[v7], &a2[v7], __dsta);
  uint64_t v8 = v6[6];
  uint64_t v45 = type metadata accessor for ReLU(0);
  uint64_t v47 = *(void (**)(char *, char *, uint64_t))(*(void *)(v45 - 8) + 16);
  v47(&a1[v8], &a2[v8], v45);
  uint64_t v9 = v6[7];
  uint64_t v49 = type metadata accessor for Dropout(0);
  uint64_t v51 = *(void (**)(char *, char *, uint64_t))(*(void *)(v49 - 8) + 16);
  v51(&a1[v9], &a2[v9], v49);
  uint64_t v10 = v6[8];
  uint64_t v11 = &a1[v10];
  uint64_t v12 = &a2[v10];
  *(_OWORD *)&a1[v10] = *(_OWORD *)&a2[v10];
  a1[v10 + 16] = a2[v10 + 16];
  a1[v10 + 17] = a2[v10 + 17];
  uint64_t v13 = *(int *)(type metadata accessor for MLActivityClassifier.LSTMBlock(0) + 32);
  uint64_t v14 = &v11[v13];
  uint64_t v15 = &v12[v13];
  uint64_t v16 = type metadata accessor for LSTM(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(v14, v15, v16);
  v53(&a1[v6[9]], &a2[v6[9]], __dsta);
  uint64_t v17 = v6[10];
  uint64_t v18 = type metadata accessor for BatchNorm(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 16))(&a1[v17], &a2[v17], v18);
  v47(&a1[v6[11]], &a2[v6[11]], v45);
  v51(&a1[v6[12]], &a2[v6[12]], v49);
  v53(&a1[v6[13]], &a2[v6[13]], __dsta);
  *(void *)&a1[v6[14]] = *(void *)&a2[v6[14]];
  uint64_t v19 = v6[15];
  uint64_t v50 = *(void *)&a2[v19];
  *(void *)&a1[v19] = v50;
  uint64_t v20 = v6[16];
  uint64_t v21 = &a1[v20];
  uint64_t v22 = &a2[v20];
  *(void *)&a1[v20] = *(void *)&a2[v20];
  *(void *)&a1[v20 + 8] = *(void *)&a2[v20 + 8];
  a1[v20 + 16] = a2[v20 + 16];
  *(_OWORD *)&a1[v20 + 24] = *(_OWORD *)&a2[v20 + 24];
  uint64_t v52 = *(void *)&a2[v20 + 40];
  *(void *)&a1[v20 + 40] = v52;
  *(void *)&a1[v20 + 48] = *(void *)&a2[v20 + 48];
  uint64_t v43 = *(void *)&a2[v20 + 56];
  *(void *)&a1[v20 + 56] = v43;
  *(void *)&a1[v20 + 64] = *(void *)&a2[v20 + 64];
  uint64_t v44 = *(void *)&a2[v20 + 72];
  *(void *)&a1[v20 + 72] = v44;
  uint64_t v48 = type metadata accessor for MLActivityClassifier.Configuration(0);
  uint64_t v23 = *(int *)(v48 + 44);
  uint64_t v46 = v21;
  __dst = &v21[v23];
  uint64_t v24 = v22;
  uint64_t v25 = &v22[v23];
  uint64_t v26 = type metadata accessor for DataFrame(0);
  swift_bridgeObjectRetain(v50);
  swift_bridgeObjectRetain(v52);
  swift_bridgeObjectRetain(v43);
  swift_bridgeObjectRetain(v44);
  if (__swift_getEnumTagSinglePayload((uint64_t)v25, 1, v26))
  {
    uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(__dst, v25, *(void *)(*(void *)(v27 - 8) + 64));
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v26 - 8) + 16))(__dst, v25, v26);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v26);
  }
  uint64_t v28 = *(int *)(v48 + 48);
  uint64_t v29 = &v46[v28];
  uint64_t v30 = &v24[v28];
  if (__swift_getEnumTagSinglePayload((uint64_t)v30, 1, v26))
  {
    uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(v29, v30, *(void *)(*(void *)(v31 - 8) + 64));
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v26 - 8) + 16))(v29, v30, v26);
    __swift_storeEnumTagSinglePayload((uint64_t)v29, 0, 1, v26);
  }
  uint64_t v32 = v6[17];
  uint64_t v33 = *(void **)&a2[v32];
  *(void *)&a1[v32] = v33;
  uint64_t v34 = v6[18];
  uint64_t v35 = &a1[v34];
  uint64_t v36 = &a2[v34];
  uint64_t v37 = *(void *)&a2[v34];
  v33;
  if (v37)
  {
    *(void *)uint64_t v35 = v37;
    *((void *)v35 + 1) = *((void *)v36 + 1);
    uint64_t v38 = *((void *)v36 + 2);
    *((void *)v35 + 2) = v38;
    swift_retain();
    swift_retain();
    swift_bridgeObjectRetain(v38);
  }
  else
  {
    *((void *)v35 + 2) = *((void *)v36 + 2);
    *(_OWORD *)uint64_t v35 = *(_OWORD *)v36;
  }
  uint64_t v39 = *(int *)(a3 + 20);
  uint64_t v40 = *(void *)&a2[v39];
  *(void *)&a1[v39] = v40;
  swift_bridgeObjectRetain(v40);
  return a1;
}

void *assignWithCopy for MLActivityClassifier.Model.MLPackageRepresentation(char *a1, char *a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  *((void *)a1 + 1) = *((void *)a2 + 1);
  uint64_t v4 = *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
  uint64_t v5 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v5 - 8) + 24))(&a1[v4], &a2[v4], v5);
  uint64_t v6 = (int *)type metadata accessor for MLActivityClassifier.Model(0);
  uint64_t v7 = v6[5];
  __src = (void *)type metadata accessor for Conv2D(0);
  uint64_t v69 = *(void (**)(char *, char *, void *))(*(__src - 1) + 24);
  v69(&a1[v7], &a2[v7], __src);
  uint64_t v8 = v6[6];
  uint64_t v66 = type metadata accessor for ReLU(0);
  uint64_t v61 = *(void (**)(char *, char *, uint64_t))(*(void *)(v66 - 8) + 24);
  v61(&a1[v8], &a2[v8], v66);
  uint64_t v9 = v6[7];
  uint64_t v63 = type metadata accessor for Dropout(0);
  uint64_t v65 = *(void (**)(char *, char *, uint64_t))(*(void *)(v63 - 8) + 24);
  v65(&a1[v9], &a2[v9], v63);
  uint64_t v10 = v6[8];
  uint64_t v11 = &a1[v10];
  uint64_t v12 = &a2[v10];
  *(void *)&a1[v10] = *(void *)&a2[v10];
  *(void *)&a1[v10 + 8] = *(void *)&a2[v10 + 8];
  a1[v10 + 16] = a2[v10 + 16];
  a1[v10 + 17] = a2[v10 + 17];
  uint64_t v13 = *(int *)(type metadata accessor for MLActivityClassifier.LSTMBlock(0) + 32);
  uint64_t v14 = &v11[v13];
  uint64_t v15 = &v12[v13];
  uint64_t v16 = type metadata accessor for LSTM(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 24))(v14, v15, v16);
  v69(&a1[v6[9]], &a2[v6[9]], __src);
  uint64_t v17 = v6[10];
  uint64_t v18 = type metadata accessor for BatchNorm(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 24))(&a1[v17], &a2[v17], v18);
  v61(&a1[v6[11]], &a2[v6[11]], v66);
  v65(&a1[v6[12]], &a2[v6[12]], v63);
  v69(&a1[v6[13]], &a2[v6[13]], __src);
  *(void *)&a1[v6[14]] = *(void *)&a2[v6[14]];
  uint64_t v19 = v6[15];
  uint64_t v20 = *(void *)&a2[v19];
  uint64_t v21 = *(void *)&a1[v19];
  *(void *)&a1[v19] = v20;
  swift_bridgeObjectRetain(v20);
  swift_bridgeObjectRelease(v21);
  unint64_t v62 = v6;
  uint64_t v22 = v6[16];
  *(void *)&a1[v22] = *(void *)&a2[v22];
  *(void *)&a1[v22 + 8] = *(void *)&a2[v22 + 8];
  a1[v22 + 16] = a2[v22 + 16];
  *(void *)&a1[v22 + 24] = *(void *)&a2[v22 + 24];
  *(void *)&a1[v22 + 32] = *(void *)&a2[v22 + 32];
  uint64_t v23 = *(void *)&a2[v22 + 40];
  uint64_t v24 = *(void *)&a1[v22 + 40];
  *(void *)&a1[v22 + 40] = v23;
  swift_bridgeObjectRetain(v23);
  swift_bridgeObjectRelease(v24);
  *(void *)&a1[v22 + 48] = *(void *)&a2[v22 + 48];
  uint64_t v25 = *(void *)&a2[v22 + 56];
  uint64_t v26 = *(void *)&a1[v22 + 56];
  *(void *)&a1[v22 + 56] = v25;
  swift_bridgeObjectRetain(v25);
  swift_bridgeObjectRelease(v26);
  *(void *)&a1[v22 + 64] = *(void *)&a2[v22 + 64];
  uint64_t v27 = *(void *)&a2[v22 + 72];
  uint64_t v28 = &a2[v22];
  uint64_t v29 = &a1[v22];
  uint64_t v30 = *(void *)&a1[v22 + 72];
  uint64_t v67 = a1;
  *(void *)&a1[v22 + 72] = v27;
  swift_bridgeObjectRetain(v27);
  swift_bridgeObjectRelease(v30);
  uint64_t v64 = type metadata accessor for MLActivityClassifier.Configuration(0);
  uint64_t v31 = *(int *)(v64 + 44);
  uint64_t v32 = (uint64_t)&v29[v31];
  uint64_t v33 = &v28[v31];
  uint64_t v34 = type metadata accessor for DataFrame(0);
  __dst = (void *)v32;
  LODWORD(v32) = __swift_getEnumTagSinglePayload(v32, 1, v34);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v33, 1, v34);
  if (v32)
  {
    if (EnumTagSinglePayload)
    {
      size_t v36 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      uint64_t v37 = __dst;
LABEL_6:
      memcpy(v37, v33, v36);
      goto LABEL_9;
    }
    (*(void (**)(void *, char *, uint64_t))(*(void *)(v34 - 8) + 16))(__dst, v33, v34);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v34);
  }
  else
  {
    uint64_t v38 = *(void *)(v34 - 8);
    if (EnumTagSinglePayload)
    {
      (*(void (**)(void *, uint64_t))(v38 + 8))(__dst, v34);
      size_t v36 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      uint64_t v37 = __dst;
      goto LABEL_6;
    }
    (*(void (**)(void *, char *, uint64_t))(v38 + 24))(__dst, v33, v34);
  }
LABEL_9:
  uint64_t v39 = *(int *)(v64 + 48);
  uint64_t v40 = &v29[v39];
  uint64_t v41 = &v28[v39];
  int v42 = __swift_getEnumTagSinglePayload((uint64_t)v40, 1, v34);
  int v43 = __swift_getEnumTagSinglePayload((uint64_t)v41, 1, v34);
  if (v42)
  {
    if (!v43)
    {
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v34 - 8) + 16))(v40, v41, v34);
      __swift_storeEnumTagSinglePayload((uint64_t)v40, 0, 1, v34);
      goto LABEL_15;
    }
    goto LABEL_14;
  }
  uint64_t v44 = *(void *)(v34 - 8);
  if (v43)
  {
    (*(void (**)(char *, uint64_t))(v44 + 8))(v40, v34);
LABEL_14:
    uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(v40, v41, *(void *)(*(void *)(v45 - 8) + 64));
    goto LABEL_15;
  }
  (*(void (**)(char *, char *, uint64_t))(v44 + 24))(v40, v41, v34);
LABEL_15:
  uint64_t v46 = v62[17];
  uint64_t v47 = *(void **)((char *)v67 + v46);
  uint64_t v48 = *(void **)&a2[v46];
  *(void *)((char *)v67 + v46) = v48;
  v48;

  uint64_t v49 = v62[18];
  uint64_t v50 = (void *)((char *)v67 + v49);
  uint64_t v51 = &a2[v49];
  uint64_t v52 = *(void *)&a2[v49];
  if (*(void *)((char *)v67 + v49))
  {
    if (v52)
    {
      *uint64_t v50 = v52;
      swift_retain();
      swift_release();
      v50[1] = *((void *)v51 + 1);
      swift_retain();
      swift_release();
      uint64_t v53 = *((void *)v51 + 2);
      uint64_t v54 = v50[2];
      void v50[2] = v53;
      swift_bridgeObjectRetain(v53);
      swift_bridgeObjectRelease(v54);
    }
    else
    {
      outlined destroy of ClassificationMetricsContainer((uint64_t)v50);
      *(_OWORD *)uint64_t v50 = *(_OWORD *)v51;
      void v50[2] = *((void *)v51 + 2);
    }
  }
  else if (v52)
  {
    *uint64_t v50 = v52;
    v50[1] = *((void *)v51 + 1);
    uint64_t v55 = *((void *)v51 + 2);
    void v50[2] = v55;
    swift_retain();
    swift_retain();
    swift_bridgeObjectRetain(v55);
  }
  else
  {
    void v50[2] = *((void *)v51 + 2);
    *(_OWORD *)uint64_t v50 = *(_OWORD *)v51;
  }
  uint64_t v56 = *(int *)(a3 + 20);
  uint64_t v57 = *(void *)&a2[v56];
  uint64_t v58 = *(void *)((char *)v67 + v56);
  *(void *)((char *)v67 + v56) = v57;
  swift_bridgeObjectRetain(v57);
  swift_bridgeObjectRelease(v58);
  return v67;
}

char *initializeWithTake for MLActivityClassifier.Model.MLPackageRepresentation(char *a1, char *a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  uint64_t v3 = *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
  uint64_t v4 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 32))(&a1[v3], &a2[v3], v4);
  uint64_t v5 = type metadata accessor for MLActivityClassifier.Model(0);
  uint64_t v6 = *(int *)(v5 + 20);
  uint64_t v38 = type metadata accessor for Conv2D(0);
  uint64_t v40 = *(void (**)(char *, char *, uint64_t))(*(void *)(v38 - 8) + 32);
  v40(&a1[v6], &a2[v6], v38);
  uint64_t v7 = (int *)v5;
  uint64_t v8 = *(int *)(v5 + 24);
  uint64_t v34 = type metadata accessor for ReLU(0);
  size_t v36 = *(void (**)(char *, char *, uint64_t))(*(void *)(v34 - 8) + 32);
  v36(&a1[v8], &a2[v8], v34);
  uint64_t v9 = v7[7];
  __dsta = (void *)type metadata accessor for Dropout(0);
  uint64_t v33 = *(void (**)(char *, char *, void *))(*(__dsta - 1) + 32);
  v33(&a1[v9], &a2[v9], __dsta);
  uint64_t v10 = v7[8];
  uint64_t v11 = &a1[v10];
  uint64_t v12 = &a2[v10];
  *(_OWORD *)&a1[v10] = *(_OWORD *)&a2[v10];
  a1[v10 + 16] = a2[v10 + 16];
  a1[v10 + 17] = a2[v10 + 17];
  uint64_t v13 = *(int *)(type metadata accessor for MLActivityClassifier.LSTMBlock(0) + 32);
  uint64_t v14 = &v11[v13];
  uint64_t v15 = &v12[v13];
  uint64_t v16 = type metadata accessor for LSTM(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 32))(v14, v15, v16);
  v40(&a1[v7[9]], &a2[v7[9]], v38);
  uint64_t v17 = v7[10];
  uint64_t v18 = type metadata accessor for BatchNorm(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 32))(&a1[v17], &a2[v17], v18);
  v36(&a1[v7[11]], &a2[v7[11]], v34);
  v33(&a1[v7[12]], &a2[v7[12]], __dsta);
  v40(&a1[v7[13]], &a2[v7[13]], v38);
  *(void *)&a1[v7[14]] = *(void *)&a2[v7[14]];
  *(void *)&a1[v7[15]] = *(void *)&a2[v7[15]];
  uint64_t v41 = v7;
  uint64_t v19 = v7[16];
  uint64_t v20 = &a1[v19];
  uint64_t v21 = &a2[v19];
  *(void *)&a1[v19] = *(void *)&a2[v19];
  *(void *)&a1[v19 + 8] = *(void *)&a2[v19 + 8];
  a1[v19 + 16] = a2[v19 + 16];
  *(_OWORD *)&a1[v19 + 24] = *(_OWORD *)&a2[v19 + 24];
  *(void *)&a1[v19 + 40] = *(void *)&a2[v19 + 40];
  *(_OWORD *)&a1[v19 + 48] = *(_OWORD *)&a2[v19 + 48];
  *(_OWORD *)&a1[v19 + 64] = *(_OWORD *)&a2[v19 + 64];
  uint64_t v37 = type metadata accessor for MLActivityClassifier.Configuration(0);
  uint64_t v22 = *(int *)(v37 + 44);
  uint64_t v39 = v20;
  __dst = &v20[v22];
  uint64_t v35 = v21;
  uint64_t v23 = &v21[v22];
  uint64_t v24 = type metadata accessor for DataFrame(0);
  if (__swift_getEnumTagSinglePayload((uint64_t)v23, 1, v24))
  {
    uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(__dst, v23, *(void *)(*(void *)(v25 - 8) + 64));
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v24 - 8) + 32))(__dst, v23, v24);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v24);
  }
  uint64_t v26 = *(int *)(v37 + 48);
  uint64_t v27 = &v39[v26];
  uint64_t v28 = &v21[v26];
  if (__swift_getEnumTagSinglePayload((uint64_t)&v35[v26], 1, v24))
  {
    uint64_t v29 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(v27, v28, *(void *)(*(void *)(v29 - 8) + 64));
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v24 - 8) + 32))(v27, v28, v24);
    __swift_storeEnumTagSinglePayload((uint64_t)v27, 0, 1, v24);
  }
  *(void *)&a1[v41[17]] = *(void *)&a2[v41[17]];
  uint64_t v30 = v41[18];
  *(void *)&a1[v30 + 16] = *(void *)&a2[v30 + 16];
  *(_OWORD *)&a1[v30] = *(_OWORD *)&a2[v30];
  *(void *)&a1[*(int *)(a3 + 20)] = *(void *)&a2[*(int *)(a3 + 20)];
  return a1;
}

_OWORD *assignWithTake for MLActivityClassifier.Model.MLPackageRepresentation(char *a1, char *a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  uint64_t v4 = *(int *)(type metadata accessor for MLActivityClassifier.InputBlock(0) + 24);
  uint64_t v5 = type metadata accessor for LearningPhase(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v5 - 8) + 40))(&a1[v4], &a2[v4], v5);
  uint64_t v6 = type metadata accessor for MLActivityClassifier.Model(0);
  uint64_t v7 = *(int *)(v6 + 20);
  uint64_t v8 = (int *)v6;
  uint64_t v58 = type metadata accessor for Conv2D(0);
  unint64_t v62 = *(void (**)(char *, char *, uint64_t))(*(void *)(v58 - 8) + 40);
  v62(&a1[v7], &a2[v7], v58);
  uint64_t v9 = v8[6];
  uint64_t v60 = type metadata accessor for ReLU(0);
  __srcb = *(void (**)(char *, char *, uint64_t))(*(void *)(v60 - 8) + 40);
  __srcb(&a1[v9], &a2[v9], v60);
  uint64_t v10 = v8;
  uint64_t v11 = v8[7];
  __dsta = (void *)type metadata accessor for Dropout(0);
  uint64_t v56 = *(void (**)(char *, char *, void *))(*(__dsta - 1) + 40);
  v56(&a1[v11], &a2[v11], __dsta);
  uint64_t v12 = v8[8];
  uint64_t v13 = &a1[v12];
  uint64_t v14 = &a2[v12];
  *(_OWORD *)&a1[v12] = *(_OWORD *)&a2[v12];
  a1[v12 + 16] = a2[v12 + 16];
  a1[v12 + 17] = a2[v12 + 17];
  uint64_t v15 = *(int *)(type metadata accessor for MLActivityClassifier.LSTMBlock(0) + 32);
  uint64_t v16 = &v13[v15];
  uint64_t v17 = &v14[v15];
  uint64_t v18 = type metadata accessor for LSTM(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 40))(v16, v17, v18);
  v62(&a1[v10[9]], &a2[v10[9]], v58);
  uint64_t v19 = v10[10];
  uint64_t v20 = type metadata accessor for BatchNorm(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v20 - 8) + 40))(&a1[v19], &a2[v19], v20);
  __srcb(&a1[v10[11]], &a2[v10[11]], v60);
  v56(&a1[v10[12]], &a2[v10[12]], __dsta);
  v62(&a1[v10[13]], &a2[v10[13]], v58);
  *(void *)&a1[v10[14]] = *(void *)&a2[v10[14]];
  uint64_t v21 = v10[15];
  uint64_t v22 = *(void *)&a1[v21];
  *(void *)&a1[v21] = *(void *)&a2[v21];
  swift_bridgeObjectRelease(v22);
  uint64_t v59 = v10;
  uint64_t v23 = v10[16];
  *(void *)&a1[v23] = *(void *)&a2[v23];
  *(void *)&a1[v23 + 8] = *(void *)&a2[v23 + 8];
  a1[v23 + 16] = a2[v23 + 16];
  *(_OWORD *)&a1[v23 + 24] = *(_OWORD *)&a2[v23 + 24];
  uint64_t v24 = *(void *)&a1[v23 + 40];
  *(void *)&a1[v23 + 40] = *(void *)&a2[v23 + 40];
  swift_bridgeObjectRelease(v24);
  *(void *)&a1[v23 + 48] = *(void *)&a2[v23 + 48];
  uint64_t v25 = *(void *)&a1[v23 + 56];
  *(void *)&a1[v23 + 56] = *(void *)&a2[v23 + 56];
  swift_bridgeObjectRelease(v25);
  *(void *)&a1[v23 + 64] = *(void *)&a2[v23 + 64];
  uint64_t v26 = &a2[v23];
  uint64_t v27 = *(void *)&a1[v23 + 72];
  uint64_t v61 = a1;
  *(void *)&a1[v23 + 72] = *(void *)&a2[v23 + 72];
  swift_bridgeObjectRelease(v27);
  __src = (int *)type metadata accessor for MLActivityClassifier.Configuration(0);
  uint64_t v28 = __src[11];
  uint64_t v57 = &a1[v23];
  uint64_t v29 = (uint64_t)&a1[v23 + v28];
  uint64_t v30 = &a2[v23 + v28];
  uint64_t v31 = type metadata accessor for DataFrame(0);
  __dst = (void *)v29;
  LODWORD(v29) = __swift_getEnumTagSinglePayload(v29, 1, v31);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v30, 1, v31);
  if (v29)
  {
    if (EnumTagSinglePayload)
    {
      size_t v33 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      uint64_t v34 = __dst;
LABEL_6:
      memcpy(v34, v30, v33);
      goto LABEL_9;
    }
    (*(void (**)(void *, char *, uint64_t))(*(void *)(v31 - 8) + 32))(__dst, v30, v31);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v31);
  }
  else
  {
    uint64_t v35 = *(void *)(v31 - 8);
    if (EnumTagSinglePayload)
    {
      (*(void (**)(void *, uint64_t))(v35 + 8))(__dst, v31);
      size_t v33 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      uint64_t v34 = __dst;
      goto LABEL_6;
    }
    (*(void (**)(void *, char *, uint64_t))(v35 + 40))(__dst, v30, v31);
  }
LABEL_9:
  uint64_t v36 = __src[12];
  uint64_t v37 = (uint64_t)&v26[v36];
  uint64_t v38 = &v57[v36];
  int v39 = __swift_getEnumTagSinglePayload((uint64_t)&v57[v36], 1, v31);
  __srca = (void *)v37;
  int v40 = __swift_getEnumTagSinglePayload(v37, 1, v31);
  if (v39)
  {
    uint64_t v41 = a2;
    int v42 = v61;
    if (!v40)
    {
      (*(void (**)(char *, void *, uint64_t))(*(void *)(v31 - 8) + 32))(v38, __srca, v31);
      __swift_storeEnumTagSinglePayload((uint64_t)v38, 0, 1, v31);
      goto LABEL_15;
    }
    goto LABEL_14;
  }
  uint64_t v43 = *(void *)(v31 - 8);
  uint64_t v41 = a2;
  int v42 = v61;
  if (v40)
  {
    (*(void (**)(char *, uint64_t))(v43 + 8))(v38, v31);
LABEL_14:
    uint64_t v44 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(v38, __srca, *(void *)(*(void *)(v44 - 8) + 64));
    goto LABEL_15;
  }
  (*(void (**)(char *, void *, uint64_t))(v43 + 40))(v38, __srca, v31);
LABEL_15:
  uint64_t v45 = v59[17];
  uint64_t v46 = *(void **)((char *)v42 + v45);
  *(void *)((char *)v42 + v45) = *(void *)((char *)v41 + v45);

  uint64_t v47 = v59[18];
  uint64_t v48 = (void *)((char *)v42 + v47);
  uint64_t v49 = (char *)v41 + v47;
  if (*(void *)((char *)v42 + v47))
  {
    uint64_t v50 = *(void *)((char *)v41 + v47);
    if (v50)
    {
      *uint64_t v48 = v50;
      swift_release();
      v48[1] = *((void *)v49 + 1);
      swift_release();
      uint64_t v51 = v48[2];
      v48[2] = *((void *)v49 + 2);
      swift_bridgeObjectRelease(v51);
    }
    else
    {
      outlined destroy of ClassificationMetricsContainer((uint64_t)v48);
      *(_OWORD *)uint64_t v48 = *(_OWORD *)v49;
      v48[2] = *((void *)v49 + 2);
    }
  }
  else
  {
    v48[2] = *((void *)v49 + 2);
    *(_OWORD *)uint64_t v48 = *(_OWORD *)v49;
  }
  uint64_t v52 = *(int *)(a3 + 20);
  uint64_t v53 = *(void *)((char *)v42 + v52);
  *(void *)((char *)v42 + v52) = *(void *)((char *)v41 + v52);
  swift_bridgeObjectRelease(v53);
  return v42;
}

uint64_t getEnumTagSinglePayload for MLActivityClassifier.Model.MLPackageRepresentation(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_103315);
}

uint64_t sub_103315(uint64_t a1, unsigned int a2, uint64_t a3)
{
  unsigned int v4 = 0;
  uint64_t v5 = type metadata accessor for MLActivityClassifier.Model(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(a1, a2, v5);
  }
  if ((*(void *)(a1 + *(int *)(a3 + 20)) & 0xFFFFFFFF00000001) == 0) {
    return (*(void *)(a1 + *(int *)(a3 + 20)) >> 1) + 1;
  }
  return v4;
}

uint64_t storeEnumTagSinglePayload for MLActivityClassifier.Model.MLPackageRepresentation(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_10338F);
}

uint64_t sub_10338F(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = type metadata accessor for MLActivityClassifier.Model(0);
  if (*(_DWORD *)(*(void *)(v6 - 8) + 84) == a3) {
    return __swift_storeEnumTagSinglePayload(a1, a2, a2, v6);
  }
  uint64_t result = *(int *)(a4 + 20);
  *(void *)(a1 + result) = 2 * (a2 - 1);
  return result;
}

uint64_t type metadata completion function for MLActivityClassifier.Model.MLPackageRepresentation(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLActivityClassifier.Model(319);
  if (v2 <= 0x3F)
  {
    v3[0] = *(void *)(result - 8) + 64;
    v3[1] = (char *)&value witness table for Builtin.BridgeObject + 64;
    swift_initStructMetadata(a1, 256, 2, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t base witness table accessor for _BaseLayer in MLActivityClassifier.Model.MLPackageRepresentation()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model.MLPackageRepresentation and conformance MLActivityClassifier.Model.MLPackageRepresentation, type metadata accessor for MLActivityClassifier.Model.MLPackageRepresentation, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model.MLPackageRepresentation);
}

uint64_t base witness table accessor for _ComputeDevicePlaceable in MLActivityClassifier.Model.MLPackageRepresentation()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model.MLPackageRepresentation and conformance MLActivityClassifier.Model.MLPackageRepresentation, type metadata accessor for MLActivityClassifier.Model.MLPackageRepresentation, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model.MLPackageRepresentation);
}

uint64_t base witness table accessor for _Differentiable in MLActivityClassifier.Model.MLPackageRepresentation()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model.MLPackageRepresentation and conformance MLActivityClassifier.Model.MLPackageRepresentation, type metadata accessor for MLActivityClassifier.Model.MLPackageRepresentation, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model.MLPackageRepresentation);
}

uint64_t partial apply for closure #2 in MLActivityClassifier.Model.MLPackageRepresentation.forward(_:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return closure #2 in MLActivityClassifier.Model.MLPackageRepresentation.forward(_:)(a1, a2, a3, *(void **)(v3 + 16));
}

uint64_t partial apply for closure #3 in MLActivityClassifier.Model.MLPackageRepresentation.forward(_:)(uint64_t *a1)
{
  return closure #3 in MLActivityClassifier.Model.MLPackageRepresentation.forward(_:)(a1, *(uint64_t **)(v1 + 16), *(void *)(v1 + 24));
}

uint64_t outlined init with take of LSTM.State?(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(a3);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v3 - 8) + 32))(a2, a1, v3);
  return a2;
}

uint64_t MLImageClassifier.ImageAugmentationOptions.rawValue.getter()
{
  return *(void *)v0;
}

void *MLImageClassifier.ImageAugmentationOptions.init(rawValue:)(uint64_t a1)
{
  *uint64_t result = a1;
  return result;
}

void *static MLImageClassifier.ImageAugmentationOptions.blur.getter()
{
  *uint64_t result = 1;
  return result;
}

void *static MLImageClassifier.ImageAugmentationOptions.flip.getter()
{
  *uint64_t result = 2;
  return result;
}

void *static MLImageClassifier.ImageAugmentationOptions.exposure.getter()
{
  *uint64_t result = 4;
  return result;
}

void *static MLImageClassifier.ImageAugmentationOptions.noise.getter()
{
  *uint64_t result = 8;
  return result;
}

void *static MLImageClassifier.ImageAugmentationOptions.rotation.getter()
{
  *uint64_t result = 16;
  return result;
}

void *static MLImageClassifier.ImageAugmentationOptions.crop.getter()
{
  *uint64_t result = 32;
  return result;
}

uint64_t base witness table accessor for RawRepresentable in MLImageClassifier.ImageAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions();
}

uint64_t lazy protocol witness table accessor for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions()
{
  uint64_t result = lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLImageClassifier.ImageAugmentationOptions, &type metadata for MLImageClassifier.ImageAugmentationOptions);
    lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLImageClassifier.ImageAugmentationOptions, &type metadata for MLImageClassifier.ImageAugmentationOptions);
    lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLImageClassifier.ImageAugmentationOptions, &type metadata for MLImageClassifier.ImageAugmentationOptions);
    lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLImageClassifier.ImageAugmentationOptions, &type metadata for MLImageClassifier.ImageAugmentationOptions);
    lazy protocol witness table cache variable for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions = result;
  }
  return result;
}

uint64_t base witness table accessor for SetAlgebra in MLImageClassifier.ImageAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions();
}

void *protocol witness for OptionSet.init(rawValue:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return MLImageClassifier.ImageAugmentationOptions.init(rawValue:)(*a1);
}

uint64_t base witness table accessor for Equatable in MLImageClassifier.ImageAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions();
}

uint64_t base witness table accessor for ExpressibleByArrayLiteral in MLImageClassifier.ImageAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLImageClassifier.ImageAugmentationOptions and conformance MLImageClassifier.ImageAugmentationOptions();
}

uint64_t *protocol witness for SetAlgebra.union(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet.union(_:)(*a1, *v1);
}

uint64_t *protocol witness for SetAlgebra.intersection(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet.intersection(_:)(*a1, *v1);
}

uint64_t *specialized OptionSet.intersection(_:)(uint64_t a1, uint64_t a2)
{
  *uint64_t result = a2 & a1;
  return result;
}

{
  return specialized OptionSet.intersection(_:)(a1, a2);
}

{
  return specialized OptionSet.intersection(_:)(a1, a2);
}

uint64_t *protocol witness for SetAlgebra.symmetricDifference(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet.symmetricDifference(_:)(*a1, *v1);
}

BOOL protocol witness for SetAlgebra.insert(_:) in conformance MLImageClassifier.ImageAugmentationOptions(void *a1, uint64_t *a2)
{
  return specialized OptionSet<>.insert(_:)(a1, *a2);
}

uint64_t protocol witness for SetAlgebra.remove(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet<>.remove(_:)(*a1);
}

uint64_t protocol witness for SetAlgebra.update(with:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet<>.update(with:)(*a1);
}

void protocol witness for SetAlgebra.formUnion(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
}

void protocol witness for SetAlgebra.formIntersection(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
}

void specialized OptionSet<>.formIntersection(_:)(uint64_t a1)
{
  *v1 &= a1;
}

{
  specialized OptionSet<>.formIntersection(_:)(a1);
}

void protocol witness for SetAlgebra.formSymmetricDifference(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
}

uint64_t *protocol witness for SetAlgebra.subtracting(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized SetAlgebra.subtracting(_:)(*a1, *v1);
}

BOOL protocol witness for SetAlgebra.isSubset(of:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized SetAlgebra.isSubset(of:)(*a1, *v1);
}

BOOL specialized SetAlgebra.isSubset(of:)(uint64_t a1, uint64_t a2)
{
  return (~a1 & a2) == 0;
}

{
  return specialized SetAlgebra.isSubset(of:)(a1, a2);
}

BOOL protocol witness for SetAlgebra.isDisjoint(with:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized SetAlgebra.isDisjoint(with:)(*a1, *v1);
}

BOOL protocol witness for SetAlgebra.isSuperset(of:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return specialized SetAlgebra.isSuperset(of:)(*a1, *v1);
}

BOOL specialized SetAlgebra.isSuperset(of:)(uint64_t a1, uint64_t a2)
{
  return (~a2 & a1) == 0;
}

BOOL protocol witness for SetAlgebra.isEmpty.getter in conformance MLImageClassifier.ImageAugmentationOptions()
{
  return specialized SetAlgebra.isEmpty.getter(*v0);
}

uint64_t protocol witness for SetAlgebra.init<A>(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return SetAlgebra.init<A>(_:)(a1, a4, a2, a5, a3);
}

void protocol witness for SetAlgebra.subtract(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
}

void *protocol witness for RawRepresentable.init(rawValue:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  uint64_t v2 = v1;
  uint64_t result = MLImageClassifier.ImageAugmentationOptions.init(rawValue:)(*a1);
  *(unsigned char *)(v2 + 8) = 0;
  return result;
}

uint64_t protocol witness for RawRepresentable.rawValue.getter in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t result = MLImageClassifier.ImageAugmentationOptions.rawValue.getter(a1);
  *uint64_t v2 = result;
  return result;
}

BOOL protocol witness for static Equatable.== infix(_:_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1, uint64_t *a2)
{
  return specialized == infix<A>(_:_:)(*a1, *a2);
}

uint64_t protocol witness for ExpressibleByArrayLiteral.init(arrayLiteral:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t a1)
{
  return specialized SetAlgebra<>.init(arrayLiteral:)(a1);
}

ValueMetadata *type metadata accessor for MLImageClassifier.ImageAugmentationOptions()
{
  return &type metadata for MLImageClassifier.ImageAugmentationOptions;
}

uint64_t closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(char a1)
{
  uint64_t v92 = v1;
  uint64_t v90 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
  uint64_t v91 = *(void *)(v90 - 8);
  int64_t v2 = *(void *)(v91 + 64);
  uint64_t v3 = alloca(v2);
  unsigned int v4 = alloca(v2);
  uint64_t v106 = v86;
  uint64_t v105 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
  uint64_t v93 = *(void *)(v105 - 8);
  int64_t v5 = *(void *)(v93 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  char v125 = v86;
  uint64_t v107 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
  uint64_t v94 = *(void *)(v107 - 8);
  int64_t v8 = *(void *)(v94 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v126 = v86;
  uint64_t v108 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
  uint64_t v95 = *(void *)(v108 - 8);
  int64_t v11 = *(void *)(v95 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  Swift::String v127 = v86;
  uint64_t v109 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>.0);
  uint64_t v96 = *(void *)(v109 - 8);
  int64_t v14 = *(void *)(v96 + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v128 = v86;
  uint64_t v110 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  uint64_t v97 = *(void *)(v110 - 8);
  int64_t v17 = *(void *)(v97 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  Swift::String v129 = v86;
  uint64_t v98 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v99 = *(void *)(v98 - 8);
  int64_t v20 = *(void *)(v99 + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v113 = v86;
  uint64_t v111 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v100 = *(void *)(v111 - 8);
  int64_t v23 = *(void *)(v100 + 64);
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  uint64_t v130 = v86;
  uint64_t v112 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v101 = *(void *)(v112 - 8);
  int64_t v26 = *(void *)(v101 + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  uint64_t v131 = v86;
  uint64_t v114 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v102 = *(void *)(v114 - 8);
  int64_t v29 = *(void *)(v102 + 64);
  uint64_t v30 = alloca(v29);
  uint64_t v31 = alloca(v29);
  os_log_type_t v132 = v86;
  uint64_t v115 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v103 = *(void *)(v115 - 8);
  int64_t v32 = *(void *)(v103 + 64);
  size_t v33 = alloca(v32);
  uint64_t v34 = alloca(v32);
  uint64_t v133 = v86;
  uint64_t v35 = alloca(v32);
  uint64_t v36 = alloca(v32);
  uint64_t v134 = v86;
  uint64_t v116 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v104 = *(void *)(v116 - 8);
  int64_t v37 = *(void *)(v104 + 64);
  uint64_t v38 = alloca(v37);
  int v39 = alloca(v37);
  uint64_t v40 = 0;
  double v119 = 0.0;
  if (a1) {
    uint64_t v40 = 0x3FF0000000000000;
  }
  double v135 = *(double *)&v40;
  uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  uint64_t v42 = type metadata accessor for CIImage();
  uint64_t v43 = type metadata accessor for ImageBlur(255);
  uint64_t v120 = v42;
  uint64_t v121 = v43;
  uint64_t v122 = &protocol witness table for ImageBlur;
  uint64_t OpaqueTypeConformance2 = swift_getOpaqueTypeConformance2(&v120, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>, 1);
  uint64_t v117 = v86;
  ApplyRandomly.init<A>(probability:_:)(partial apply for closure #1 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:), v86, v41, v42, OpaqueTypeConformance2, v135);
  uint64_t v45 = 0;
  if ((a1 & 2) != 0) {
    uint64_t v45 = 0x3FE0000000000000;
  }
  double v135 = *(double *)&v45;
  uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  uint64_t v47 = type metadata accessor for ImageFlipper(255);
  uint64_t v120 = v42;
  uint64_t v121 = v47;
  uint64_t v122 = &protocol witness table for ImageFlipper;
  uint64_t v48 = swift_getOpaqueTypeConformance2(&v120, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>, 1);
  ApplyRandomly.init<A>(probability:_:)(closure #2 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:), 0, v46, v42, v48, v135);
  ApplyRandomly.init<A>(probability:_:)(closure #3 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:), 0, v46, v42, v48, v135);
  uint64_t v49 = 0;
  if ((a1 & 4) != 0) {
    uint64_t v49 = 0x3FF0000000000000;
  }
  double v135 = *(double *)&v49;
  uint64_t v50 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  uint64_t v51 = type metadata accessor for ImageExposureAdjuster(255);
  uint64_t v120 = v42;
  uint64_t v121 = v51;
  uint64_t v122 = &protocol witness table for ImageExposureAdjuster;
  uint64_t v52 = swift_getOpaqueTypeConformance2(&v120, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>, 1);
  ApplyRandomly.init<A>(probability:_:)(partial apply for closure #4 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:), v87, v50, v42, v52, v135);
  uint64_t v53 = 0;
  if ((a1 & 8) != 0) {
    uint64_t v53 = 0x3FF0000000000000;
  }
  double v135 = *(double *)&v53;
  uint64_t v54 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  uint64_t v55 = type metadata accessor for RandomImageNoiseGenerator(255);
  uint64_t v120 = v42;
  uint64_t v121 = v55;
  uint64_t v122 = &protocol witness table for RandomImageNoiseGenerator;
  uint64_t v56 = swift_getOpaqueTypeConformance2(&v120, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>, 1);
  ApplyRandomly.init<A>(probability:_:)(partial apply for closure #5 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:), v88, v54, v42, v56, v135);
  uint64_t v57 = 0;
  if ((a1 & 0x10) != 0) {
    uint64_t v57 = 0x3FF0000000000000;
  }
  double v135 = *(double *)&v57;
  uint64_t v58 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  uint64_t v59 = type metadata accessor for ImageRotator(255);
  uint64_t v120 = v42;
  uint64_t v121 = v59;
  uint64_t v122 = &protocol witness table for ImageRotator;
  uint64_t v60 = swift_getOpaqueTypeConformance2(&v120, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>, 1);
  ApplyRandomly.init<A>(probability:_:)(partial apply for closure #6 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:), v89, v58, v42, v60, v135);
  if ((a1 & 0x20) != 0) {
    double v119 = 1.0;
  }
  uint64_t v61 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0);
  type metadata accessor for RandomImageCropper(255);
  uint64_t v62 = swift_getOpaqueTypeConformance2(&v120, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>, 1);
  ApplyRandomly.init<A>(probability:_:)(closure #7 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:), 0, v61, v42, v62, v119);
  uint64_t v63 = lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  static AugmentationBuilder.buildPartialBlock<A>(first:)(v117, v42, v116, v63);
  uint64_t v64 = swift_getOpaqueTypeConformance2(&v120, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>, 1);
  uint64_t v65 = lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v66 = v115;
  static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)(v129, v134, v42, v110, v115, v64, v65);
  uint64_t v67 = swift_getOpaqueTypeConformance2(&v120, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>, 1);
  uint64_t v118 = v42;
  static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)(v128, v133, v42, v109, v66, v67, v65);
  uint64_t v68 = swift_getOpaqueTypeConformance2(&v120, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>, 1);
  uint64_t v69 = lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v70 = v118;
  static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)(v127, v132, v118, v108, v114, v68, v69);
  uint64_t v71 = swift_getOpaqueTypeConformance2(&v120, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>, 1);
  uint64_t v72 = lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)(v126, v131, v70, v107, v112, v71, v72);
  uint64_t v73 = swift_getOpaqueTypeConformance2(&v120, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>, 1);
  uint64_t v74 = lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  uint64_t v75 = v105;
  char v76 = (void *)v111;
  static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)(v125, v130, v70, v105, v111, v73, v74);
  uint64_t v120 = v70;
  uint64_t v121 = v75;
  uint64_t v122 = v76;
  uint64_t v123 = v73;
  uint64_t v124 = v74;
  uint64_t v77 = swift_getOpaqueTypeConformance2(&v120, &opaque type descriptor for <<opaque return type of static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)>>, 1);
  uint64_t v78 = lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(&lazy protocol witness table cache variable for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>, &demangling cache variable for type metadata for ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0>);
  Swift::Int v79 = v106;
  Swift::Bool v80 = v113;
  uint64_t v81 = v90;
  uint64_t v82 = v98;
  static AugmentationBuilder.buildPartialBlock<A, B>(accumulated:next:)(v106, v113, v118, v90, v98, v77, v78);
  (*(void (**)(unsigned char *, uint64_t))(v91 + 8))(v79, v81);
  (*(void (**)(unsigned char *, uint64_t))(v93 + 8))(v125, v105);
  (*(void (**)(unsigned char *, uint64_t))(v94 + 8))(v126, v107);
  (*(void (**)(unsigned char *, uint64_t))(v95 + 8))(v127, v108);
  (*(void (**)(unsigned char *, uint64_t))(v96 + 8))(v128, v109);
  (*(void (**)(unsigned char *, uint64_t))(v97 + 8))(v129, v110);
  (*(void (**)(unsigned char *, uint64_t))(v99 + 8))(v80, v82);
  (*(void (**)(unsigned char *, uint64_t))(v100 + 8))(v130, v111);
  (*(void (**)(unsigned char *, uint64_t))(v101 + 8))(v131, v112);
  (*(void (**)(unsigned char *, uint64_t))(v102 + 8))(v132, v114);
  uint64_t v83 = *(void (**)(unsigned char *, uint64_t))(v103 + 8);
  uint64_t v84 = v115;
  v83(v133, v115);
  v83(v134, v84);
  return (*(uint64_t (**)(unsigned char *, uint64_t))(v104 + 8))(v117, v116);
}

uint64_t closure #1 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  v9[0] = v0;
  uint64_t v1 = type metadata accessor for ImageBlur(0);
  uint64_t v2 = *(void *)(v1 - 8);
  int64_t v3 = *(void *)(v2 + 64);
  unsigned int v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  int v6 = specialized RandomNumberGenerator.next<A>(upperBound:)(0x20uLL);
  ImageBlur.init(radius:)((double)(v6 + 1));
  uint64_t v7 = type metadata accessor for CIImage();
  static AugmentationBuilder.buildPartialBlock<A>(first:)(v9, v7, v1, &protocol witness table for ImageBlur);
  return (*(uint64_t (**)(void *, uint64_t))(v2 + 8))(v9, v1);
}

uint64_t partial apply for closure #1 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #1 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(*(void *)(v0 + 16));
}

uint64_t type metadata accessor for CIImage()
{
  uint64_t result = lazy cache variable for type metadata for CIImage;
  if (!lazy cache variable for type metadata for CIImage)
  {
    uint64_t v1 = objc_opt_self(CIImage);
    uint64_t result = swift_getObjCClassMetadata(v1);
    lazy cache variable for type metadata for CIImage = result;
  }
  return result;
}

uint64_t closure #2 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #2 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(&enum case for ImageFlipper.Orientation.horizontal(_:));
}

uint64_t closure #3 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #2 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(&enum case for ImageFlipper.Orientation.vertical(_:));
}

uint64_t closure #2 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(unsigned int *a1)
{
  uint64_t v15 = a1;
  uint64_t v13 = v1;
  uint64_t v2 = type metadata accessor for ImageFlipper.Orientation(0);
  uint64_t v3 = *(void *)(v2 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  int64_t v5 = alloca(v4);
  int v6 = alloca(v4);
  uint64_t v7 = type metadata accessor for ImageFlipper(0);
  uint64_t v14 = *(void *)(v7 - 8);
  int64_t v8 = *(void *)(v14 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  (*(void (**)(uint64_t *, void, uint64_t))(v3 + 104))(&v13, *v15, v2);
  ImageFlipper.init(orientation:)(&v13);
  uint64_t v11 = type metadata accessor for CIImage();
  static AugmentationBuilder.buildPartialBlock<A>(first:)(&v13, v11, v7, &protocol witness table for ImageFlipper);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v14 + 8))(&v13, v7);
}

uint64_t closure #4 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  v9[0] = v0;
  uint64_t v1 = type metadata accessor for ImageExposureAdjuster(0);
  uint64_t v2 = *(void *)(v1 - 8);
  int64_t v3 = *(void *)(v2 + 64);
  int64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  int v6 = specialized RandomNumberGenerator.next<A>(upperBound:)(0xBuLL);
  ImageExposureAdjuster.init(amount:)((double)(v6 - 5) / 5.0);
  uint64_t v7 = type metadata accessor for CIImage();
  static AugmentationBuilder.buildPartialBlock<A>(first:)(v9, v7, v1, &protocol witness table for ImageExposureAdjuster);
  return (*(uint64_t (**)(void *, uint64_t))(v2 + 8))(v9, v1);
}

uint64_t partial apply for closure #4 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #4 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(*(void *)(v0 + 16));
}

uint64_t closure #5 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  v9[0] = v0;
  uint64_t v1 = type metadata accessor for RandomImageNoiseGenerator(0);
  uint64_t v2 = *(void *)(v1 - 8);
  int64_t v3 = *(void *)(v2 + 64);
  int64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  int v6 = specialized RandomNumberGenerator.next<A>(upperBound:)(0xBuLL);
  RandomImageNoiseGenerator.init(intensity:)((double)v6 / 10.0);
  uint64_t v7 = type metadata accessor for CIImage();
  static AugmentationBuilder.buildPartialBlock<A>(first:)(v9, v7, v1, &protocol witness table for RandomImageNoiseGenerator);
  return (*(uint64_t (**)(void *, uint64_t))(v2 + 8))(v9, v1);
}

uint64_t partial apply for closure #5 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #5 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(*(void *)(v0 + 16));
}

uint64_t closure #6 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  v9[0] = v0;
  uint64_t v1 = type metadata accessor for ImageRotator(0);
  uint64_t v2 = *(void *)(v1 - 8);
  int64_t v3 = *(void *)(v2 + 64);
  int64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  int v6 = specialized RandomNumberGenerator.next<A>(upperBound:)(0xBuLL);
  ImageRotator.init(angle:)((double)(v6 - 5) + (double)(v6 - 5));
  uint64_t v7 = type metadata accessor for CIImage();
  static AugmentationBuilder.buildPartialBlock<A>(first:)(v9, v7, v1, &protocol witness table for ImageRotator);
  return (*(uint64_t (**)(void *, uint64_t))(v2 + 8))(v9, v1);
}

uint64_t partial apply for closure #6 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  return closure #6 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)(*(void *)(v0 + 16));
}

uint64_t closure #7 in closure #1 in static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)()
{
  uint64_t v0 = type metadata accessor for RandomImageCropper(0);
  uint64_t v1 = *(void *)(v0 - 8);
  int64_t v2 = *(void *)(v1 + 64);
  int64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  RandomImageCropper.init(scale:aspectRatio:)(0x3FF0000000000000, 0, 0.8, 1.0);
  uint64_t v5 = type metadata accessor for CIImage();
  static AugmentationBuilder.buildPartialBlock<A>(first:)(v7, v5, v0, &protocol witness table for RandomImageCropper);
  return (*(uint64_t (**)(unsigned char *, uint64_t))(v1 + 8))(v7, v0);
}

uint64_t lazy protocol witness table accessor for type ApplyRandomly<<<opaque return type of static AugmentationBuilder.buildPartialBlock<A>(first:)>>.0> and conformance ApplyRandomly<A>(uint64_t *a1, uint64_t *a2)
{
  uint64_t result = *a1;
  if (!*a1)
  {
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledNameAbstract(a2);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for ApplyRandomly<A>, v3);
    *a1 = result;
  }
  return result;
}

BOOL specialized OptionSet<>.contains(_:)(uint64_t a1, uint64_t a2)
{
  return specialized SetAlgebra.isSuperset(of:)(a1, a2);
}

BOOL protocol witness for SetAlgebra.contains(_:) in conformance MLImageClassifier.ImageAugmentationOptions(uint64_t *a1)
{
  return protocol witness for SetAlgebra.isSuperset(of:) in conformance MLImageClassifier.ImageAugmentationOptions(a1);
}

uint64_t static MLObjectDetector.validateInput(trainingData:imageColumn:annotationColumn:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, double a6)
{
  uint64_t v20 = v6;
  uint64_t v25 = a5;
  uint64_t v26 = a4;
  uint64_t v24 = a3;
  uint64_t v7 = *(void *)a1;
  char v8 = *(unsigned char *)(a1 + 8);
  uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  uint64_t inited = (void *)swift_initStackObject(v28, v17);
  inited[2] = 1;
  inited[3] = 2;
  uint64_t v21 = a2;
  inited[4] = a2;
  char v10 = v24;
  inited[5] = v24;
  uint64_t v27 = v7;
  uint64_t v22 = v7;
  char v31 = v8;
  char v23 = v8;
  swift_bridgeObjectRetain(v10);
  uint64_t v11 = v20;
  static _ValidationUtilities.validateTableFormat(table:context:columns:)((uint64_t)&v22, 0x4C52556567616D49, (void *)0xE800000000000000, (uint64_t)inited);
  if (v11)
  {
    swift_setDeallocating(inited);
  }
  else
  {
    uint64_t v22 = v27;
    char v23 = v31;
    uint64_t v13 = (void *)swift_initStackObject(v28, v18);
    v13[2] = 1;
    v13[3] = 2;
    void v13[4] = v26;
    char v14 = v25;
    v13[5] = v25;
    swift_bridgeObjectRetain(v14);
    static _ValidationUtilities.validateTableFormat(table:context:columns:)((uint64_t)&v22, 0x697461746F6E6E41, (void *)0xEA00000000006E6FLL, (uint64_t)v13);
    swift_setDeallocating(v13);
    specialized _ContiguousArrayStorage.__deallocating_deinit();
    swift_setDeallocating(inited);
    specialized _ContiguousArrayStorage.__deallocating_deinit();
    uint64_t v22 = v27;
    char v23 = v31;
    uint64_t v15 = (void *)swift_initStackObject(v28, v19);
    v15[2] = 1;
    v15[3] = 2;
    v15[4] = v21;
    char v16 = v24;
    v15[5] = v24;
    char v29 = 2;
    char v30 = 3;
    swift_bridgeObjectRetain(v16);
    static _ValidationUtilities.validateTableTypes(table:featureColumns:featureType:labelColumn:labelType:)(&v22, (unint64_t)v15, &v29, v26, v25, &v30, a6);
    swift_setDeallocating(v15);
  }
  return specialized _ContiguousArrayStorage.__deallocating_deinit();
}

uint64_t static MLObjectDetector.validateAndConvertParameters(_:annotationType:imageColumn:annotationColumn:table:)(uint64_t a1, unsigned char *a2, uint64_t a3, uint64_t a4, uint64_t a5, int *a6, __m128 a7, uint64_t *a8)
{
  char v9 = a2[1];
  char v10 = a2[2];
  uint64_t v11 = *a8;
  char v12 = *((unsigned char *)a8 + 8);
  LOBYTE(v23) = *a2;
  BYTE1(v23) = v9;
  BYTE2(v23) = v10;
  uint64_t result = static MLObjectDetector.validateAndConvertParameters(_:annotationType:imageColumn:annotationColumn:)(a1, (char *)&v23, a3, a4, a5, a6);
  if (!v8)
  {
    uint64_t v25 = result;
    uint64_t v18 = v11;
    char v19 = v12 & 1;
    MLObjectDetector.ModelParameters.ValidationData.generateTables(trainingData:)(&v23, &v20, (uint64_t)&v18, a7);
    char v14 = v24;
    uint64_t v22 = v20;
    char v15 = v21;
    uint64_t v26 = v23;
    CMLParameters.setTraining(table:)(&v23);
    char v27 = v14;
    if (v15 == -1)
    {
      outlined consume of Result<_DataTable, Error>(v26, v27);
      return v25;
    }
    else
    {
      uint64_t v16 = v22;
      uint64_t v23 = v22;
      char v24 = v15 & 1;
      outlined copy of Result<_DataTable, Error>(v22, v15);
      uint64_t v17 = v25;
      CMLParameters.setValidation(table:)(&v23);
      outlined consume of MLDataTable?(v16, v15);
      outlined consume of Result<_DataTable, Error>(v26, v27);
      outlined consume of MLDataTable?(v16, v15);
      return v17;
    }
  }
  return result;
}

uint64_t static MLObjectDetector.validateAndConvertParameters(_:annotationType:imageColumn:annotationColumn:)(uint64_t a1, char *a2, uint64_t a3, uint64_t a4, uint64_t a5, int *a6)
{
  uint64_t inited = v6;
  uint64_t v82 = a6;
  uint64_t v78 = a5;
  uint64_t v79 = a1;
  uint64_t v81 = type metadata accessor for _Model.Parameters(0);
  int64_t v9 = *(void *)(*(void *)(v81 - 8) + 64);
  char v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  char v76 = &v67;
  char v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v73 = &v67;
  char v14 = alloca(v9);
  char v15 = alloca(v9);
  uint64_t v74 = &v67;
  uint64_t v16 = alloca(v9);
  uint64_t v17 = alloca(v9);
  Swift::Bool v80 = &v67;
  char v85 = *a2;
  char v84 = a2[1];
  int v77 = a2[2];
  uint64_t empty = tc_v1_parameters_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v19 = empty;
  uint64_t v20 = type metadata accessor for CMLParameters();
  uint64_t v21 = swift_allocObject(v20, 24, 7);
  *(void *)(v21 + 16) = v19;
  type metadata accessor for CMLFeatureValue();
  swift_bridgeObjectRetain(a4);
  uint64_t v22 = inited;
  uint64_t v23 = CMLFeatureValue.__allocating_init(_:)(a3, a4);
  if (v22)
  {
    swift_unexpectedError(v22, "CreateML/MLDataValueConvertible.swift", 37, 1);
    BUG();
  }
  CMLParameters.add(key:featureValue:)(1, v23);
  swift_release();
  uint64_t v24 = (uint64_t)v82;
  swift_bridgeObjectRetain((_BYTE)v82);
  uint64_t v25 = CMLFeatureValue.__allocating_init(_:)(v78, v24);
  CMLParameters.add(key:featureValue:)(56, v25);
  swift_release();
  uint64_t v27 = tc_v1_flex_dict_create(0);
  if (!v27) {
    BUG();
  }
  uint64_t v28 = v27;
  uint64_t v29 = type metadata accessor for CMLDictionary();
  uint64_t inited = swift_initStackObject(v29, v68);
  *(void *)(inited + 16) = v28;
  char v30 = (int *)type metadata accessor for MLObjectDetector.ModelParameters(0);
  uint64_t v31 = v30[6];
  uint64_t v32 = v79;
  BOOL v33 = *(unsigned char *)(v79 + v31 + 8) == 0;
  uint64_t v82 = v30;
  if (v33)
  {
    uint64_t v34 = (uint64_t)v80;
    *Swift::Bool v80 = *(void *)(v79 + v31);
    swift_storeEnumTagMultiPayload(v34, v81, 0);
    CMLDictionary.add(_:)(v34);
    uint64_t v32 = v79;
    uint64_t v35 = v34;
    char v30 = v82;
    outlined destroy of _Model.Parameters(v35);
  }
  uint64_t v36 = v30[5];
  if (!*(unsigned char *)(v32 + v36 + 8))
  {
    uint64_t v37 = (uint64_t)v80;
    *Swift::Bool v80 = *(void *)(v32 + v36);
    swift_storeEnumTagMultiPayload(v37, v81, 1);
    CMLDictionary.add(_:)(v37);
    uint64_t v32 = v79;
    uint64_t v38 = v37;
    char v30 = v82;
    outlined destroy of _Model.Parameters(v38);
  }
  uint64_t v39 = *(void *)(v32 + v30[7]);
  if (v39 <= 0 || (uint64_t v40 = *(void *)(v32 + v30[8]), v40 <= 0))
  {
    uint64_t v47 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v47, 0, 0);
    *(void *)uint64_t v48 = 0xD000000000000035;
    *(void *)(v48 + 8) = "or is of the wrong size" + 0x8000000000000000;
    *(_OWORD *)(v48 + 16) = 0;
    *(_OWORD *)(v48 + 32) = 0;
    *(unsigned char *)(v48 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v47, v48, v49, v50, v51);
    uint64_t v52 = inited;
    goto LABEL_44;
  }
  double v41 = (double)(int)v39;
  if ((double)(int)v39 <= -9.223372036854778e18) {
    BUG();
  }
  if (v41 >= 9.223372036854776e18) {
    BUG();
  }
  if ((*(void *)&v41 & 0x7FF0000000000000) == 0x7FF0000000000000
    || (double v42 = (double)(int)v40, (COERCE_UNSIGNED_INT64((double)(int)v40) & 0x7FF0000000000000) == 0x7FF0000000000000))
  {
    BUG();
  }
  if (v42 <= -9.223372036854778e18) {
    BUG();
  }
  uint64_t v75 = 0;
  uint64_t v78 = v21;
  if (v42 >= 9.223372036854776e18) {
    BUG();
  }
  uint64_t v43 = 0x2D74656E6B726164;
  uint64_t v44 = (uint64_t)v80;
  *Swift::Bool v80 = (int)v41;
  *(void *)(v44 + 8) = (int)v42;
  swift_storeEnumTagMultiPayload(v44, v81, 13);
  CMLDictionary.add(_:)(v44);
  outlined destroy of _Model.Parameters(v44);
  outlined init with copy of Any?(v32 + v82[10], (uint64_t)v69);
  if (!v70)
  {
    outlined destroy of Any?((uint64_t)v69);
    goto LABEL_27;
  }
  if (!swift_dynamicCast(v71, v69, (char *)&type metadata for Any + 8, &type metadata for MLObjectDetector.ModelParameters.ModelAlgorithmType, 6))
  {
LABEL_27:
    unint64_t v46 = 0xEC0000006F6C6F79;
    goto LABEL_28;
  }
  if (!v72) {
    uint64_t v43 = 0x74656E656E656373;
  }
  unint64_t v45 = 0xEC0000006F6C6F79;
  if (!v72) {
    unint64_t v45 = 0xE800000000000000;
  }
  unint64_t v46 = v45;
LABEL_28:
  uint64_t v53 = 0x7466656C5F706F74;
  uint64_t v54 = v80;
  *Swift::Bool v80 = v43;
  v54[1] = v46;
  uint64_t v55 = v81;
  swift_storeEnumTagMultiPayload(v54, v81, 5);
  CMLDictionary.add(_:)((uint64_t)v54);
  outlined destroy of _Model.Parameters((uint64_t)v54);
  int v56 = *(unsigned __int8 *)(v79 + v82[9]);
  uint64_t v57 = 1869903201;
  if (*(unsigned char *)(v79 + v82[9])) {
    uint64_t v57 = 7696483;
  }
  *uint64_t v54 = v57;
  v54[1] = ((unint64_t)(v56 ^ 1u) << 56) - 0x1D00000000000000;
  swift_storeEnumTagMultiPayload(v54, v55, 9);
  CMLDictionary.add(_:)((uint64_t)v54);
  outlined destroy of _Model.Parameters((uint64_t)v54);
  uint64_t v58 = 0x6C65786970;
  if (v85) {
    uint64_t v58 = 0x7A696C616D726F6ELL;
  }
  unint64_t v59 = 0xE500000000000000;
  if (v85) {
    unint64_t v59 = 0xEA00000000006465;
  }
  uint64_t v60 = (uint64_t)v74;
  uint64_t *v74 = v58;
  *(void *)(v60 + 8) = v59;
  swift_storeEnumTagMultiPayload(v60, v55, 10);
  CMLDictionary.add(_:)(v60);
  outlined destroy of _Model.Parameters(v60);
  uint64_t v61 = 0x7466656C5F706F74;
  if (v84) {
    uint64_t v61 = 0x6C5F6D6F74746F62;
  }
  unint64_t v62 = 0xE800000000000000;
  if (v84) {
    unint64_t v62 = 0xEB00000000746665;
  }
  uint64_t v63 = (uint64_t)v73;
  uint64_t *v73 = v61;
  *(void *)(v63 + 8) = v62;
  swift_storeEnumTagMultiPayload(v63, v55, 11);
  CMLDictionary.add(_:)(v63);
  outlined destroy of _Model.Parameters(v63);
  if (v77)
  {
    uint64_t v21 = v78;
    uint64_t v64 = v76;
    if (v77 == 1)
    {
      unint64_t v65 = 0xE800000000000000;
    }
    else
    {
      uint64_t v53 = 0x6C5F6D6F74746F62;
      unint64_t v65 = 0xEB00000000746665;
    }
  }
  else
  {
    unint64_t v65 = 0xE600000000000000;
    uint64_t v53 = 0x7265746E6563;
    uint64_t v21 = v78;
    uint64_t v64 = v76;
  }
  *uint64_t v64 = v53;
  v64[1] = v65;
  swift_storeEnumTagMultiPayload(v64, v81, 12);
  uint64_t v52 = inited;
  CMLDictionary.add(_:)((uint64_t)v64);
  outlined destroy of _Model.Parameters((uint64_t)v64);
  uint64_t v66 = v75;
  CMLParameters.setOptions(dictionary:)(v52);
  if (!v66)
  {
    swift_setDeallocating(v52);
    tc_v1_release(*(void *)(v52 + 16));
    return v21;
  }
LABEL_44:
  swift_setDeallocating(v52);
  tc_v1_release(*(void *)(v52 + 16));
  swift_release();
  return v21;
}

uint64_t static _FileUtilities.prepareForWriting(to:isDirectory:)(uint64_t a1, char a2)
{
  uint64_t v3 = type metadata accessor for URL(0);
  uint64_t v4 = *(void *)(v3 - 8);
  int64_t v5 = *(void *)(v4 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v18 = v2;
  uint64_t v19 = v3;
  uint64_t v20 = v4;
  if (a2) {
    (*(void (**)(uint64_t *, uint64_t, uint64_t))(v4 + 16))(&v18, a1, v3);
  }
  else {
    URL.deletingLastPathComponent()();
  }
  uint64_t v8 = objc_opt_self(NSFileManager);
  id v9 = [v8 defaultManager];
  char v10 = (NSURL *)v9;
  uint64_t v21 = &v18;
  URL._bridgeToObjectiveC()(v10);
  char v12 = v11;
  id v22 = 0;
  unsigned __int8 v13 = [(NSURL *)v10 createDirectoryAtURL:v11 withIntermediateDirectories:1 attributes:0 error:&v22];

  id v14 = v22;
  if (v13)
  {
    char v15 = *(void (**)(uint64_t *, uint64_t))(v20 + 8);
    v22;
    v15(v21, v19);
  }
  else
  {
    id v16 = v22;
    _convertNSErrorToError(_:)(v14);

    swift_willThrow();
    (*(void (**)(uint64_t *, uint64_t))(v20 + 8))(v21, v19);
  }
  return __stack_chk_guard;
}

uint64_t specialized _ArrayProtocol.filter(_:)(uint64_t (*a1)(uint64_t *), uint64_t a2, uint64_t a3)
{
  uint64_t v37 = a2;
  uint64_t v38 = a1;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v8 = type metadata accessor for URL(0);
  uint64_t v9 = *(void *)(v8 - 8);
  int64_t v10 = *(void *)(v9 + 64);
  uint64_t v11 = alloca(v10);
  char v12 = alloca(v10);
  double v42 = (uint64_t *)&v35;
  unsigned __int8 v13 = alloca(v10);
  id v14 = alloca(v10);
  uint64_t v44 = (uint64_t *)&v35;
  uint64_t v48 = _swiftEmptyArrayStorage;
  uint64_t v15 = a3;
  uint64_t v39 = *(void *)(a3 + 16);
  double v41 = (uint64_t *)&v35;
  if (v39)
  {
    unint64_t v16 = 0;
    uint64_t v17 = a3;
    uint64_t v18 = v3;
    uint64_t v46 = v15;
    uint64_t v45 = v8;
    uint64_t v43 = v9;
    while (1)
    {
      if (v16 >= *(void *)(v17 + 16)) {
        BUG();
      }
      uint64_t v47 = v18;
      uint64_t v19 = v8;
      uint64_t v20 = (*(unsigned __int8 *)(v9 + 80) + 32) & ~*(unsigned __int8 *)(v9 + 80);
      uint64_t v36 = *(void *)(v9 + 72);
      unint64_t v35 = v16;
      uint64_t v21 = v20 + v17 + v16 * v36;
      uint64_t v22 = (uint64_t)v41;
      uint64_t v23 = v9;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v9 + 16))(v41, v21, v19);
      __swift_storeEnumTagSinglePayload(v22, 0, 1, v19);
      if (__swift_getEnumTagSinglePayload(v22, 1, v19) == 1)
      {
        uint64_t v17 = v46;
        goto LABEL_18;
      }
      uint64_t v24 = *(void (**)(char *, uint64_t *, uint64_t))(v23 + 32);
      uint64_t v25 = v44;
      uint64_t v26 = v22;
      uint64_t v27 = v24;
      v24((char *)v44, (uint64_t *)v26, v19);
      uint64_t v28 = v47;
      char v29 = v38(v25);
      uint64_t v18 = v28;
      if (v28) {
        break;
      }
      if (v29)
      {
        uint64_t v40 = v27;
        v27((char *)v42, v44, v45);
        char v30 = v48;
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v48);
        uint64_t v47 = 0;
        if (!isUniquelyReferenced_nonNull_native)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v30[2] + 1, 1);
          char v30 = v48;
        }
        unint64_t v32 = v30[2];
        if (v30[3] >> 1 <= v32)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v30[3] >= 2uLL, v32 + 1, 1);
          char v30 = v48;
        }
        v30[2] = v32 + 1;
        BOOL v33 = (char *)v30 + v20 + v36 * v32;
        uint64_t v8 = v45;
        v40(v33, v42, v45);
        uint64_t v48 = v30;
        uint64_t v18 = v47;
      }
      else
      {
        uint64_t v8 = v45;
        (*(void (**)(uint64_t *, uint64_t))(v43 + 8))(v44, v45);
      }
      uint64_t v17 = v46;
      unint64_t v16 = v35 + 1;
      uint64_t v9 = v43;
      if (v39 == v35 + 1) {
        goto LABEL_16;
      }
    }
    (*(void (**)(uint64_t *, uint64_t))(v43 + 8))(v44, v45);
    swift_bridgeObjectRelease(v46);
    return swift_release(v48);
  }
  else
  {
    uint64_t v17 = a3;
    uint64_t v18 = v3;
LABEL_16:
    uint64_t v47 = v18;
    uint64_t v22 = (uint64_t)v41;
    __swift_storeEnumTagSinglePayload((uint64_t)v41, 1, 1, v8);
LABEL_18:
    swift_bridgeObjectRelease(v17);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v22, &demangling cache variable for type metadata for URL?);
    return (uint64_t)v48;
  }
}

BOOL static _FileUtilities.isReadableFile(at:of:)(uint64_t a1, uint64_t a2)
{
  uint64_t v22 = a2;
  int64_t v2 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for UTType?)
                             - 8)
                 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v5 = type metadata accessor for UTType(0);
  uint64_t v24 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v24 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v9 = alloca(v6);
  int64_t v10 = alloca(v6);
  uint64_t v25 = &v21;
  uint64_t v23 = a1;
  uint64_t v11 = URL.pathExtension.getter();
  uint64_t v13 = v12;
  static UTType.data.getter();
  UTType.init(filenameExtension:conformingTo:)(v11, v13, &v21);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v21, 1, v5) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v21, &demangling cache variable for type metadata for UTType?);
  }
  else
  {
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v24 + 32))(v25, &v21, v5);
    if (UTType.conforms(to:)(v22))
    {
      id v14 = objc_opt_self(NSFileManager);
      id v15 = [v14 defaultManager];
      id v16 = v15;
      URL.path.getter();
      uint64_t v18 = v17;
      NSString v19 = String._bridgeToObjectiveC()();
      swift_bridgeObjectRelease(v18);
      LOBYTE(v18) = [v16 isReadableFileAtPath:v19];

      (*(void (**)(uint64_t *, uint64_t))(v24 + 8))(v25, v5);
      return (_BYTE)v18 != 0;
    }
    (*(void (**)(uint64_t *, uint64_t))(v24 + 8))(v25, v5);
  }
  return 0;
}

uint64_t static _FileUtilities.getReadableJsonFilesInDirectory(at:)(uint64_t a1)
{
  uint64_t v21 = v1;
  uint64_t v2 = type metadata accessor for UTType(0);
  uint64_t v3 = *(void *)(v2 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v23 = &v20;
  uint64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  static UTType.json.getter();
  uint64_t v22 = a1;
  BOOL v9 = static _FileUtilities.isReadableFile(at:of:)(a1, (uint64_t)&v20);
  int64_t v10 = *(void (**)(uint64_t *, uint64_t))(v3 + 8);
  v10(&v20, v2);
  if (v9)
  {
    uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<URL>);
    uint64_t v12 = type metadata accessor for URL(0);
    uint64_t v13 = *(void *)(v12 - 8);
    uint64_t v14 = *(unsigned __int8 *)(v13 + 80);
    uint64_t v15 = ((int)v14 + 32) & ~*(unsigned __int8 *)(v13 + 80);
    uint64_t v16 = swift_allocObject(v11, v15 + *(void *)(v13 + 72), v14 | 7);
    *(void *)(v16 + 16) = 1;
    *(void *)(v16 + 24) = 2;
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v13 + 16))(v16 + v15, v22, v12);
  }
  else
  {
    uint64_t v16 = (uint64_t)v23;
    static UTType.json.getter();
    uint64_t v17 = v21;
    uint64_t v18 = static _FileUtilities.readableFiles(at:type:)(v22, v16);
    if (!v17) {
      uint64_t v16 = (uint64_t)v18;
    }
    v10(v23, v2);
  }
  return v16;
}

void *static _FileUtilities.getReadableSubdirectoriesOfDirectory(at:)()
{
  uint64_t v77 = v0;
  int64_t v1 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URLResourceValues?)
                             - 8)
                 + 64);
  uint64_t v2 = alloca(v1);
  uint64_t v3 = alloca(v1);
  uint64_t v70 = &v59;
  int64_t v4 = alloca(v1);
  uint64_t v5 = alloca(v1);
  uint64_t v66 = &v59;
  int64_t v6 = alloca(v1);
  uint64_t v7 = alloca(v1);
  uint64_t v67 = &v59;
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  BOOL v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  char v76 = &v59;
  uint64_t v78 = type metadata accessor for URL(0);
  uint64_t v73 = *(void *)(v78 - 8);
  int64_t v11 = *(void *)(v73 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v71 = &v59;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  uint64_t v75 = &v59;
  uint64_t v16 = objc_opt_self(NSFileManager);
  id v17 = [v16 defaultManager];
  id v72 = v17;
  URL._bridgeToObjectiveC()((NSURL *)v72);
  id v79 = v18;
  uint64_t v60 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<NSURLResourceKey>);
  NSString v19 = (void *)swift_allocObject(v60, 48, 7);
  v19[2] = 2;
  v19[3] = 4;
  v19[4] = NSURLIsDirectoryKey;
  v19[5] = NSURLIsReadableKey;
  uint64_t v83 = 0;
  id v61 = NSURLIsDirectoryKey;
  id v62 = NSURLIsReadableKey;
  id v20 = v79;
  uint64_t v21 = (uint64_t)v19;
  id v22 = v72;
  id v23 = outlined bridged method (mnbnnnn) of @objc NSFileManager.contentsOfDirectory(at:includingPropertiesForKeys:options:)((uint64_t)v79, v21, 0, (uint64_t)&v83, v72);

  id v24 = v83;
  if (v23)
  {
    uint64_t v25 = v78;
    uint64_t v26 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v23, v78);
    v24;

    uint64_t v83 = _swiftEmptyArrayStorage;
    uint64_t v63 = *(char **)(v26 + 16);
    uint64_t v27 = v25;
    if (v63)
    {
      unint64_t v28 = 0;
      uint64_t v29 = (uint64_t)v76;
      uint64_t v30 = v73;
      uint64_t v74 = v26;
      while (1)
      {
        if (v28 >= *(void *)(v26 + 16)) {
          BUG();
        }
        uint64_t v68 = (*(unsigned __int8 *)(v30 + 80) + 32) & ~*(unsigned __int8 *)(v30 + 80);
        uint64_t v64 = *(void *)(v30 + 72);
        id v72 = (id)v28;
        (*(void (**)(uint64_t, unint64_t, uint64_t))(v30 + 16))(v29, v68 + v26 + v28 * v64, v27);
        __swift_storeEnumTagSinglePayload(v29, 0, 1, v27);
        if (__swift_getEnumTagSinglePayload(v29, 1, v27) == 1)
        {
          uint64_t v26 = v74;
          goto LABEL_29;
        }
        uint64_t v69 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v30 + 32);
        v69(v75, v29, v27);
        uint64_t inited = swift_initStackObject(v60, v84);
        *(void *)(inited + 16) = 2;
        *(void *)(inited + 24) = 4;
        id v32 = v61;
        *(void *)(inited + 32) = v61;
        id v33 = v62;
        *(void *)(inited + 40) = v62;
        id v79 = (id)type metadata accessor for NSURLResourceKey(0);
        uint64_t v34 = lazy protocol witness table accessor for type NSURLResourceKey and conformance NSURLResourceKey();
        v32;
        v33;
        uint64_t v82 = Set.init(minimumCapacity:)(2, v79, v34);
        id v35 = *(id *)(inited + 32);
        specialized Set._Variant.insert(_:)(&v81, v35);

        id v36 = *(id *)(inited + 40);
        specialized Set._Variant.insert(_:)(&v81, v36);

        swift_setDeallocating(inited);
        specialized _ContiguousArrayStorage.__deallocating_deinit();
        uint64_t v37 = v82;
        uint64_t v38 = (uint64_t)v67;
        uint64_t v39 = v77;
        URL.resourceValues(forKeys:)(v82);
        if (v39)
        {
          swift_errorRelease(v39);
          swift_bridgeObjectRelease(v37);
          uint64_t v40 = (void *)type metadata accessor for URLResourceValues(0);
          __swift_storeEnumTagSinglePayload(v38, 1, 1, (uint64_t)v40);
          uint64_t v77 = 0;
        }
        else
        {
          uint64_t v77 = 0;
          swift_bridgeObjectRelease(v37);
          uint64_t v40 = (void *)type metadata accessor for URLResourceValues(0);
          __swift_storeEnumTagSinglePayload(v38, 0, 1, (uint64_t)v40);
        }
        uint64_t v41 = (uint64_t)v66;
        outlined init with copy of URLResourceValues?(v38, (uint64_t)v66);
        type metadata accessor for URLResourceValues(0);
        id v79 = v40;
        int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v41, 1, (uint64_t)v40);
        uint64_t v43 = v41;
        uint64_t v44 = v38;
        uint64_t v26 = v74;
        if (EnumTagSinglePayload == 1) {
          break;
        }
        uint64_t v45 = (uint64_t)v66;
        uint64_t v46 = v74;
        char v47 = URLResourceValues.isDirectory.getter(v43);
        unint64_t v65 = *(void (**)(uint64_t))(*((void *)v79 - 1) + 8);
        v65(v45);
        uint64_t v44 = v38;
        char v80 = v47;
        BOOL v48 = v47 == 2;
        uint64_t v26 = v46;
        if (v48) {
          goto LABEL_12;
        }
        uint64_t v49 = (uint64_t)v67;
        uint64_t v44 = (uint64_t)v70;
        outlined init with copy of URLResourceValues?((uint64_t)v67, (uint64_t)v70);
        uint64_t v43 = v49;
        if (__swift_getEnumTagSinglePayload(v44, 1, (uint64_t)v79) == 1) {
          break;
        }
        uint64_t v50 = (uint64_t)v70;
        char v51 = URLResourceValues.isReadable.getter(v49);
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v49, &demangling cache variable for type metadata for URLResourceValues?);
        ((void (*)(uint64_t, id))v65)(v50, v79);
        if (v51 != 2 && (v80 & 1) != 0 && (v51 & 1) != 0)
        {
          uint64_t v27 = v78;
          v69(v71, (uint64_t)v75, v78);
          uint64_t v52 = v83;
          if (!swift_isUniquelyReferenced_nonNull_native(v83))
          {
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v52[2] + 1, 1);
            uint64_t v27 = v78;
            uint64_t v52 = v83;
          }
          uint64_t v53 = v68;
          unint64_t v54 = v52[2];
          unint64_t v55 = v54 + 1;
          if (v52[3] >> 1 <= v54)
          {
            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v52[3] >= 2uLL, v54 + 1, 1);
            unint64_t v55 = v54 + 1;
            uint64_t v27 = v78;
            uint64_t v52 = v83;
          }
          v52[2] = v55;
          v69((void *)((char *)v52 + v53 + v64 * v54), (uint64_t)v71, v27);
          uint64_t v83 = v52;
          uint64_t v29 = (uint64_t)v76;
          uint64_t v30 = v73;
          uint64_t v26 = v74;
          goto LABEL_14;
        }
LABEL_13:
        uint64_t v27 = v78;
        uint64_t v30 = v73;
        (*(void (**)(uint64_t *, uint64_t))(v73 + 8))(v75, v78);
        uint64_t v29 = (uint64_t)v76;
LABEL_14:
        unint64_t v28 = (unint64_t)v72 + 1;
        if (v63 == (char *)v72 + 1) {
          goto LABEL_27;
        }
      }
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v43, &demangling cache variable for type metadata for URLResourceValues?);
LABEL_12:
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v44, &demangling cache variable for type metadata for URLResourceValues?);
      goto LABEL_13;
    }
    uint64_t v29 = (uint64_t)v76;
LABEL_27:
    __swift_storeEnumTagSinglePayload(v29, 1, 1, v27);
LABEL_29:
    swift_bridgeObjectRelease(v26);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v29, &demangling cache variable for type metadata for URL?);
    return v83;
  }
  else
  {
    int v56 = v83;
    uint64_t v57 = _convertNSErrorToError(_:)(v24);

    uint64_t v77 = v57;
    return (void *)swift_willThrow();
  }
}

void (__cdecl **static _FileUtilities.getNonHiddenFilesInDirectory(at:)())(id)
{
  uint64_t v0 = objc_opt_self(NSFileManager);
  id v1 = [v0 defaultManager];
  uint64_t v2 = (NSURL *)v1;
  URL._bridgeToObjectiveC()(v2);
  int64_t v4 = v3;
  id v12 = 0;
  id v5 = [(NSURL *)v2 contentsOfDirectoryAtURL:v3 includingPropertiesForKeys:0 options:4 error:&v12];
  id v6 = v5;
  uint64_t v7 = &objc_release;

  id v8 = v12;
  if (v6)
  {
    uint64_t v9 = type metadata accessor for URL(0);
    uint64_t v7 = (void (__cdecl **)(id))static Array._unconditionallyBridgeFromObjectiveC(_:)(v6, v9);
    v8;
  }
  else
  {
    id v10 = v12;
    _convertNSErrorToError(_:)(v8);

    swift_willThrow();
  }
  return v7;
}

void *static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)(uint64_t a1, uint64_t a2)
{
  uint64_t v115 = v2;
  uint64_t v96 = a2;
  uint64_t v4 = type metadata accessor for URL(0);
  uint64_t v108 = *(void *)(v4 - 8);
  int64_t v5 = *(void *)(v108 + 64);
  id v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v98 = &v90;
  id v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v112 = &v90;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                              - 8)
                  + 64);
  int64_t v11 = alloca(v10);
  id v12 = alloca(v10);
  uint64_t v103 = &v90;
  uint64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  uint64_t v15 = (void *)a1;
  uint64_t v16 = v115;
  id v17 = static _FileUtilities.getReadableSubdirectoriesOfDirectory(at:)();
  uint64_t v104 = v16;
  if (v16)
  {
    swift_bridgeObjectRelease(_swiftEmptyDictionarySingleton);
    return v15;
  }
  uint64_t v18 = v17;
  uint64_t v115 = a1;
  uint64_t v109 = &v90;
  uint64_t v102 = v17[2];
  if (v102)
  {
    uint64_t v19 = (uint64_t)v109;
LABEL_6:
    uint64_t v25 = v108;
    uint64_t v99 = (*(unsigned __int8 *)(v108 + 80) + 32) & ~*(unsigned __int8 *)(v108 + 80);
    uint64_t v97 = (char *)v18 + v99;
    uint64_t v15 = _swiftEmptyDictionarySingleton;
    unint64_t v114 = 0;
    unint64_t v26 = 0;
    uint64_t v100 = v4;
    uint64_t v107 = v18;
    while (1)
    {
      if (v26 >= v18[2]) {
        BUG();
      }
      uint64_t v113 = v15;
      uint64_t v27 = *(void (**)(uint64_t, char *, uint64_t))(v25 + 16);
      uint64_t v94 = *(void *)(v25 + 72);
      uint64_t v28 = v25;
      uint64_t v93 = v27;
      v27(v19, &v97[v26 * v94], v4);
      __swift_storeEnumTagSinglePayload(v19, 0, 1, v4);
      if (__swift_getEnumTagSinglePayload(v19, 1, v4) == 1)
      {
        swift_bridgeObjectRelease((_BYTE)v107);
        uint64_t v15 = v113;
        uint64_t v88 = v114;
        goto LABEL_47;
      }
      uint64_t v105 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v28 + 32);
      v105(v112, v19, v4);
      uint64_t v15 = v112;
      uint64_t v111 = URL.lastPathComponent.getter();
      uint64_t v115 = v29;
      uint64_t v30 = v104;
      uint64_t v31 = static _FileUtilities.readableFiles(at:type:)((uint64_t)v112, v96);
      uint64_t v104 = v30;
      if (v30)
      {
        swift_bridgeObjectRelease(v115);
        (*(void (**)(uint64_t *, uint64_t))(v108 + 8))(v112, v4);
        swift_bridgeObjectRelease((_BYTE)v113);
        swift_bridgeObjectRelease((_BYTE)v107);
        _sxRi_zRi0_zlySay10Foundation3URLVGIsegr_SgWOe(v114, 0);
        return v15;
      }
      id v32 = v31[2];
      uint64_t v101 = v31;
      uint64_t v95 = v32;
      if (v32)
      {
        unint64_t v106 = v26;
        id v33 = (char *)v31 + v99;
        swift_bridgeObjectRetain((_BYTE)v31);
        uint64_t v34 = v32;
        id v35 = v98;
        uint64_t v36 = (uint64_t)v103;
        while (1)
        {
          uint64_t v92 = v34;
          uint64_t v91 = v33;
          v93(v36, v33, v4);
          __swift_storeEnumTagSinglePayload(v36, 0, 1, v4);
          if (__swift_getEnumTagSinglePayload(v36, 1, v4) == 1) {
            break;
          }
          v105(v35, v36, v4);
          uint64_t v40 = v115;
          swift_bridgeObjectRetain(v115);
          _sxRi_zRi0_zlySay10Foundation3URLVGIsegr_SgWOe(v114, 0);
          uint64_t v41 = v113;
          char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v113);
          uint64_t v110 = v41;
          unint64_t v114 = specialized __RawDictionaryStorage.find<A>(_:)(v111, v40);
          BOOL v44 = (v43 & 1) == 0;
          BOOL v45 = __OFADD__(v41[2], v44);
          Swift::Int v46 = v41[2] + v44;
          if (v45) {
            BUG();
          }
          char v47 = v43;
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [URL]>);
          Swift::Bool v48 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v46);
          uint64_t v49 = v115;
          if (v48)
          {
            unint64_t v114 = specialized __RawDictionaryStorage.find<A>(_:)(v111, v115);
            if ((v47 & 1) != (v50 & 1)) {
              goto LABEL_54;
            }
          }
          char v51 = v110;
          swift_bridgeObjectRelease(0);
          char v52 = (char)v51;
          if ((v47 & 1) == 0)
          {
            unint64_t v53 = v114;
            v51[(v114 >> 6) + 8] |= 1 << v114;
            uint64_t v54 = v51[6];
            uint64_t v55 = 16 * v53;
            *(void *)(v54 + v55) = v111;
            *(void *)(v54 + v55 + 8) = v49;
            *(void *)(v51[7] + 8 * v53) = _swiftEmptyArrayStorage;
            uint64_t v56 = v51[2];
            swift_bridgeObjectRetain((_BYTE)v51);
            BOOL v45 = __OFADD__(1, v56);
            uint64_t v57 = v56 + 1;
            if (v45) {
              BUG();
            }
            v51[2] = v57;
            char v52 = v49;
          }
          swift_bridgeObjectRetain(v52);
          uint64_t v58 = v51[7];
          swift_bridgeObjectRelease((_BYTE)v51);
          unint64_t v59 = v114;
          uint64_t v60 = *(void **)(v58 + 8 * v114);
          char v61 = swift_isUniquelyReferenced_nonNull_native(v60);
          *(void *)(v58 + 8 * v59) = v60;
          uint64_t v113 = v51;
          if (!v61)
          {
            uint64_t v60 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v60[2] + 1, 1, (uint64_t)v60);
            *(void *)(v58 + 8 * v114) = v60;
          }
          unint64_t v62 = v60[2];
          if (v60[3] >> 1 <= v62)
          {
            uint64_t v60 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v60[3] >= 2uLL, v62 + 1, 1, (uint64_t)v60);
            *(void *)(v58 + 8 * v114) = v60;
          }
          v60[2] = v62 + 1;
          uint64_t v63 = v94;
          uint64_t v64 = (char *)v60 + v99 + v94 * v62;
          id v35 = v98;
          uint64_t v4 = v100;
          v105((uint64_t *)v64, (uint64_t)v98, v100);
          swift_bridgeObjectRelease(v115);
          id v33 = &v91[v63];
          unint64_t v114 = (unint64_t)specialized thunk for @callee_guaranteed () -> (@owned [Double]);
          uint64_t v34 = (void (__cdecl *)(id))((char *)v92 - 1);
          uint64_t v36 = (uint64_t)v103;
          if (v92 == (void (__cdecl *)(id))((char *)&dword_0 + 1))
          {
            unint64_t v114 = (unint64_t)specialized thunk for @callee_guaranteed () -> (@owned [Double]);
            uint64_t v19 = (uint64_t)v109;
            unint64_t v26 = v106;
            goto LABEL_27;
          }
        }
        swift_bridgeObjectRelease_n(v101, 2, v37, v38, v39);
        uint64_t v65 = (uint64_t)v112;
        uint64_t v19 = (uint64_t)v109;
        unint64_t v26 = v106;
        uint64_t v15 = v113;
      }
      else
      {
        swift_bridgeObjectRetain((_BYTE)v31);
        uint64_t v36 = (uint64_t)v103;
LABEL_27:
        __swift_storeEnumTagSinglePayload(v36, 1, 1, v4);
        swift_bridgeObjectRelease_n(v101, 2, v66, v67, v68);
        if (v95)
        {
          uint64_t v15 = v113;
          uint64_t v65 = (uint64_t)v112;
        }
        else
        {
          uint64_t v15 = v113;
          if (!v113[2]
            || (uint64_t v69 = v115,
                swift_bridgeObjectRetain(v115),
                specialized __RawDictionaryStorage.find<A>(_:)(v111, v69),
                uint64_t v15 = v113,
                LOBYTE(v105) = v70,
                swift_bridgeObjectRelease(v69),
                (v105 & 1) == 0))
          {
            unint64_t v106 = v26;
            char v71 = swift_isUniquelyReferenced_nonNull_native(v15);
            uint64_t v110 = v15;
            id v72 = v15;
            unint64_t v73 = specialized __RawDictionaryStorage.find<A>(_:)(v111, v115);
            LOBYTE(v113) = v74;
            BOOL v75 = (v74 & 1) == 0;
            BOOL v45 = __OFADD__(v72[2], v75);
            Swift::Int v76 = v72[2] + v75;
            if (v45) {
              BUG();
            }
            __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [URL]>);
            Swift::Bool v77 = _NativeDictionary.ensureUnique(isUnique:capacity:)(v71, v76);
            uint64_t v4 = v100;
            char v78 = (char)v113;
            if (v77)
            {
              unint64_t v73 = specialized __RawDictionaryStorage.find<A>(_:)(v111, v115);
              if ((v78 & 1) != (v79 & 1))
              {
LABEL_54:
                KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
                BUG();
              }
            }
            uint64_t v15 = v110;
            if (v78)
            {
              uint64_t v80 = v110[7];
              swift_bridgeObjectRelease(*(void *)(v80 + 8 * v73));
              *(void *)(v80 + 8 * v73) = _swiftEmptyArrayStorage;
              uint64_t v81 = (uint64_t)v112;
              char v82 = v115;
            }
            else
            {
              v110[(v73 >> 6) + 8] |= 1 << v73;
              uint64_t v83 = v15[6];
              uint64_t v84 = 16 * v73;
              *(void *)(v83 + v84) = v111;
              char v85 = v115;
              *(void *)(v83 + v84 + 8) = v115;
              *(void *)(v15[7] + 8 * v73) = _swiftEmptyArrayStorage;
              uint64_t v86 = v15[2];
              BOOL v45 = __OFADD__(1, v86);
              uint64_t v87 = v86 + 1;
              uint64_t v81 = (uint64_t)v112;
              if (v45) {
                BUG();
              }
              v15[2] = v87;
              swift_bridgeObjectRetain(v85);
              char v82 = v85;
            }
            swift_bridgeObjectRelease(v82);
            swift_bridgeObjectRelease(0);
            (*(void (**)(uint64_t, uint64_t))(v108 + 8))(v81, v4);
            uint64_t v19 = (uint64_t)v109;
            unint64_t v26 = v106;
            goto LABEL_30;
          }
          uint64_t v65 = (uint64_t)v112;
          uint64_t v19 = (uint64_t)v109;
        }
      }
      (*(void (**)(uint64_t, uint64_t))(v108 + 8))(v65, v4);
      swift_bridgeObjectRelease(v115);
LABEL_30:
      ++v26;
      uint64_t v25 = v108;
      uint64_t v18 = v107;
      if (v26 == v102)
      {
        uint64_t v88 = v114;
        goto LABEL_46;
      }
    }
  }
  swift_bridgeObjectRelease((_BYTE)v17);
  uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<URL>);
  uint64_t v21 = v108;
  uint64_t v22 = *(unsigned __int8 *)(v108 + 80);
  uint64_t v23 = ((int)v22 + 32) & ~*(unsigned __int8 *)(v108 + 80);
  uint64_t v24 = swift_allocObject(v20, v23 + *(void *)(v108 + 72), v22 | 7);
  *(void *)(v24 + 16) = 1;
  *(void *)(v24 + 24) = 2;
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v21 + 16))(v24 + v23, v115, v4);
  uint64_t v18 = (void *)v24;
  uint64_t v102 = *(void *)(v24 + 16);
  uint64_t v19 = (uint64_t)v109;
  if (v102) {
    goto LABEL_6;
  }
  uint64_t v107 = v18;
  uint64_t v15 = _swiftEmptyDictionarySingleton;
  uint64_t v88 = 0;
LABEL_46:
  __swift_storeEnumTagSinglePayload(v19, 1, 1, v4);
  swift_bridgeObjectRelease((_BYTE)v107);
LABEL_47:
  _sxRi_zRi0_zlySay10Foundation3URLVGIsegr_SgWOe(v88, 0);
  return v15;
}

void (__cdecl **static _FileUtilities.readableFiles(at:type:)(uint64_t a1, uint64_t a2))(id)
{
  int64_t v37 = a2;
  uint64_t v3 = type metadata accessor for URL(0);
  uint64_t v4 = *(void *)(v3 - 8);
  int64_t v5 = *(void *)(v4 + 64);
  id v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v28 = &v27;
  id v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t result = static _FileUtilities.getNonHiddenFilesInDirectory(at:)();
  if (!v2)
  {
    int64_t v11 = v37;
    uint64_t v38 = &v27;
    uint64_t v36 = v4;
    uint64_t v35 = v3;
    uint64_t v33 = 0;
    int64_t v12 = (int64_t)result[2];
    if (v12)
    {
      uint64_t v13 = result;
      uint64_t v40 = _swiftEmptyArrayStorage;
      int64_t v29 = v12;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v12, 0);
      uint64_t v14 = v36;
      uint64_t v15 = (*(unsigned __int8 *)(v36 + 80) + 32) & ~*(unsigned __int8 *)(v36 + 80);
      uint64_t v34 = v13;
      uint64_t v30 = v15;
      uint64_t v16 = (char *)v13 + v15;
      uint64_t v31 = *(void (**)(char **, char *, uint64_t))(v36 + 16);
      uint64_t v39 = *(void *)(v36 + 72);
      uint64_t v17 = v35;
      do
      {
        uint64_t v18 = v28;
        uint64_t v27 = v16;
        v31(v28, v16, v17);
        URL.resolvingSymlinksInPath()();
        (*(void (**)(char **, uint64_t))(v14 + 8))(v18, v17);
        uint64_t v19 = v40;
        if (!swift_isUniquelyReferenced_nonNull_native(v40))
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v19[2] + 1, 1);
          uint64_t v19 = v40;
        }
        unint64_t v20 = v19[2];
        uint64_t v21 = v38;
        if (v19[3] >> 1 <= v20)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v19[3] >= 2uLL, v20 + 1, 1);
          uint64_t v21 = v38;
          uint64_t v19 = v40;
        }
        v19[2] = v20 + 1;
        uint64_t v22 = (char *)v19 + v30 + v39 * v20;
        uint64_t v17 = v35;
        uint64_t v14 = v36;
        (*(void (**)(char *, char **, uint64_t))(v36 + 32))(v22, v21, v35);
        id v32 = v19;
        uint64_t v40 = v19;
        uint64_t v16 = &v27[v39];
        --v29;
      }
      while (v29);
      swift_bridgeObjectRelease(v34);
      int64_t v23 = v37;
      uint64_t v24 = v32;
    }
    else
    {
      swift_bridgeObjectRelease(result);
      uint64_t v24 = _swiftEmptyArrayStorage;
      int64_t v23 = v11;
    }
    uint64_t v25 = alloca(24);
    unint64_t v26 = alloca(32);
    int64_t v29 = v23;
    return (void (__cdecl **)(id))specialized _ArrayProtocol.filter(_:)((uint64_t (*)(uint64_t *))partial apply for closure #2 in static _FileUtilities.readableFiles(at:type:), (uint64_t)&v27, (uint64_t)v24);
  }
  return result;
}

uint64_t static _FileUtilities.collectFilesLabeledByFileName(at:type:)(uint64_t a1, uint64_t a2)
{
  unint64_t v62 = v2;
  uint64_t v63 = a2;
  uint64_t v3 = type metadata accessor for URL(0);
  uint64_t v4 = *(void *)(v3 - 8);
  int64_t v5 = *(void *)(v4 + 64);
  id v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  unint64_t v59 = &v53;
  id v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v66 = &v53;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                              - 8)
                  + 64);
  int64_t v11 = alloca(v10);
  int64_t v12 = alloca(v10);
  uint64_t v13 = v62;
  uint64_t v14 = static _FileUtilities.readableFiles(at:type:)(a1, v63);
  if (v13) {
    return swift_bridgeObjectRelease(_swiftEmptyDictionarySingleton);
  }
  uint64_t v64 = &v53;
  uint64_t v65 = v4;
  uint64_t v56 = 0;
  uint64_t v67 = v3;
  uint64_t v16 = v14[2];
  uint64_t v57 = v14;
  if (v16)
  {
    uint64_t v55 = (*(unsigned __int8 *)(v65 + 80) + 32) & ~*(unsigned __int8 *)(v65 + 80);
    uint64_t v17 = (uint64_t)v14 + v55;
    uint64_t v58 = *(void (**)(uint64_t, uint64_t, uint64_t))(v65 + 16);
    uint64_t v18 = *(void *)(v65 + 72);
    uint64_t v68 = _swiftEmptyDictionarySingleton;
    char v70 = 0;
    uint64_t v19 = v67;
    unint64_t v20 = v66;
    uint64_t v21 = (uint64_t)v64;
    uint64_t v60 = v18;
    while (1)
    {
      unint64_t v62 = v16;
      uint64_t v63 = v17;
      v58(v21, v17, v19);
      __swift_storeEnumTagSinglePayload(v21, 0, 1, v19);
      if (__swift_getEnumTagSinglePayload(v21, 1, v19) == 1) {
        break;
      }
      unint64_t v53 = *(void (**)(uint64_t, uint64_t, uint64_t))(v65 + 32);
      v53((uint64_t)v20, v21, v19);
      uint64_t v22 = URL.lastPathComponent.getter();
      unint64_t v24 = v23;
      unint64_t v25 = specialized Collection<>.firstIndex(of:)(46, 0xE100000000000000, v22, v23);
      if ((v26 & 1) != 0 || v25 < 0x4000)
      {
        unint64_t v20 = v66;
        (*(void (**)(void (**)(uint64_t, uint64_t, uint64_t), uint64_t))(v65 + 8))(v66, v19);
        swift_bridgeObjectRelease(v24);
        uint64_t v52 = v60;
      }
      else
      {
        uint64_t v69 = String.subscript.getter(15, v25, v22, v24);
        uint64_t v28 = v27;
        uint64_t v30 = v29;
        uint64_t v32 = v31;
        swift_bridgeObjectRelease(v24);
        uint64_t v33 = static String._fromSubstring(_:)(v69, v28, v30, v32);
        uint64_t v35 = v34;
        swift_bridgeObjectRelease(v32);
        v58((uint64_t)v59, (uint64_t)v66, v67);
        _sxRi_zRi0_zlySay10Foundation3URLVGIsegr_SgWOe((uint64_t)v70, 0);
        uint64_t v36 = v68;
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v68);
        char v61 = v36;
        uint64_t v69 = v33;
        char v70 = v35;
        unint64_t v54 = specialized __RawDictionaryStorage.find<A>(_:)(v33, (uint64_t)v35);
        BOOL v39 = (v38 & 1) == 0;
        BOOL v40 = __OFADD__(v36[2], v39);
        Swift::Int v41 = v36[2] + v39;
        if (v40) {
          BUG();
        }
        char v42 = v38;
        __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [URL]>);
        Swift::Bool v43 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v41);
        char v44 = v42;
        unint64_t v45 = v54;
        if (v43)
        {
          unint64_t v45 = specialized __RawDictionaryStorage.find<A>(_:)(v69, (uint64_t)v70);
          if ((v44 & 1) != (v46 & 1))
          {
            KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
            BUG();
          }
        }
        char v47 = v61;
        swift_bridgeObjectRelease(0);
        swift_bridgeObjectRetain((_BYTE)v47);
        if ((v44 & 1) == 0)
        {
          char v48 = (char)v70;
          specialized _NativeDictionary._insert(at:key:value:)(v45, v69, (uint64_t)v70, (uint64_t)_swiftEmptyArrayStorage, v47);
          swift_bridgeObjectRetain(v48);
        }
        uint64_t v49 = v47[7];
        uint64_t v68 = v47;
        swift_bridgeObjectRelease((_BYTE)v47);
        specialized Array._makeUniqueAndReserveCapacityIfNotUnique()();
        uint64_t v50 = *(void *)(*(void *)(v49 + 8 * v45) + 16);
        specialized Array._reserveCapacityAssumingUniqueBuffer(oldCount:)(v50);
        uint64_t v51 = *(void *)(v49 + 8 * v45);
        *(void *)(v51 + 16) = v50 + 1;
        uint64_t v52 = v60;
        uint64_t v19 = v67;
        v53(v55 + v51 + v60 * v50, (uint64_t)v59, v67);
        swift_bridgeObjectRelease((_BYTE)v70);
        unint64_t v20 = v66;
        (*(void (**)(void (**)(uint64_t, uint64_t, uint64_t), uint64_t))(v65 + 8))(v66, v19);
        char v70 = specialized thunk for @callee_guaranteed () -> (@owned [Double]);
      }
      uint64_t v17 = v52 + v63;
      uint64_t v16 = (void (__cdecl *)(id))((char *)v62 - 1);
      uint64_t v21 = (uint64_t)v64;
      if (v62 == (void (__cdecl *)(id))((char *)&dword_0 + 1)) {
        goto LABEL_18;
      }
    }
  }
  else
  {
    uint64_t v68 = _swiftEmptyDictionarySingleton;
    char v70 = 0;
    uint64_t v19 = v67;
    uint64_t v21 = (uint64_t)v64;
LABEL_18:
    __swift_storeEnumTagSinglePayload(v21, 1, 1, v19);
  }
  swift_bridgeObjectRelease((_BYTE)v57);
  _sxRi_zRi0_zlySay10Foundation3URLVGIsegr_SgWOe((uint64_t)v70, 0);
  return (uint64_t)v68;
}

id outlined bridged method (mnbnnnn) of @objc NSFileManager.contentsOfDirectory(at:includingPropertiesForKeys:options:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void *a5)
{
  type metadata accessor for NSURLResourceKey(0);
  Class isa = Array._bridgeToObjectiveC()().super.isa;
  swift_bridgeObjectRelease(a2);
  id v8 = [a5 contentsOfDirectoryAtURL:a1 includingPropertiesForKeys:isa options:a3 error:a4];
  id v9 = v8;

  return v9;
}

uint64_t lazy protocol witness table accessor for type NSURLResourceKey and conformance NSURLResourceKey()
{
  uint64_t result = lazy protocol witness table cache variable for type NSURLResourceKey and conformance NSURLResourceKey;
  if (!lazy protocol witness table cache variable for type NSURLResourceKey and conformance NSURLResourceKey)
  {
    uint64_t v1 = type metadata accessor for NSURLResourceKey(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for NSURLResourceKey, v1);
    lazy protocol witness table cache variable for type NSURLResourceKey and conformance NSURLResourceKey = result;
  }
  return result;
}

uint64_t outlined init with copy of URLResourceValues?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URLResourceValues?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

BOOL partial apply for closure #2 in static _FileUtilities.readableFiles(at:type:)(uint64_t a1)
{
  return static _FileUtilities.isReadableFile(at:of:)(a1, *(void *)(v1 + 16));
}

uint64_t _sxRi_zRi0_zlySay10Foundation3URLVGIsegr_SgWOe(uint64_t a1, uint64_t a2)
{
  if (a1) {
    return swift_release(a2);
  }
  return result;
}

void *initializeBufferWithCopyOfBuffer for AnyTreeClassifierModel(void *a1, void *a2, uint64_t a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v9 = *a2;
    *uint64_t v3 = *a2;
    uint64_t v3 = (void *)(v9 + ((v4 + 16) & ~v4));
    swift_retain(v9);
  }
  else
  {
    *a1 = *a2;
    uint64_t v6 = a2[1];
    v3[1] = v6;
    uint64_t v7 = a2[2];
    swift_bridgeObjectRetain(v6);
    if (v7)
    {
      v3[2] = v7;
      void v3[3] = a2[3];
      uint64_t v8 = a2[4];
      void v3[4] = v8;
      swift_bridgeObjectRetain(v7);
      swift_bridgeObjectRetain(v8);
    }
    else
    {
      void v3[4] = a2[4];
      *((_OWORD *)v3 + 1) = *((_OWORD *)a2 + 1);
    }
    uint64_t v10 = *(int *)(a3 + 24);
    uint64_t v11 = type metadata accessor for BaseTreeClassifierModel(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 16))((char *)v3 + v10, (char *)a2 + v10, v11);
    uint64_t v12 = *(int *)(a3 + 28);
    uint64_t v13 = *(void *)((char *)a2 + v12);
    char v14 = *((unsigned char *)a2 + v12 + 8);
    *(void *)((char *)v3 + v12) = v13;
    *((unsigned char *)v3 + v12 + 8) = v14;
    swift_bridgeObjectRetain(v13);
  }
  return v3;
}

uint64_t destroy for AnyTreeClassifierModel(void *a1, uint64_t a2)
{
  swift_bridgeObjectRelease(a1[1]);
  uint64_t v3 = a1[2];
  if (v3)
  {
    swift_bridgeObjectRelease(v3);
    swift_bridgeObjectRelease(a1[4]);
  }
  int v4 = (char *)a1 + *(int *)(a2 + 24);
  uint64_t v5 = type metadata accessor for BaseTreeClassifierModel(0);
  (*(void (**)(char *, uint64_t))(*(void *)(v5 - 8) + 8))(v4, v5);
  return swift_bridgeObjectRelease(*(void *)((char *)a1 + *(int *)(a2 + 28)));
}

void *initializeWithCopy for AnyTreeClassifierModel(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v5 = a2[1];
  a1[1] = v5;
  uint64_t v6 = a2[2];
  swift_bridgeObjectRetain(v5);
  if (v6)
  {
    a1[2] = v6;
    a1[3] = a2[3];
    uint64_t v7 = a2[4];
    a1[4] = v7;
    swift_bridgeObjectRetain(v6);
    swift_bridgeObjectRetain(v7);
  }
  else
  {
    a1[4] = a2[4];
    *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
  }
  uint64_t v8 = *(int *)(a3 + 24);
  uint64_t v9 = type metadata accessor for BaseTreeClassifierModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))((char *)a1 + v8, (char *)a2 + v8, v9);
  uint64_t v10 = *(int *)(a3 + 28);
  uint64_t v11 = *(void *)((char *)a2 + v10);
  char v12 = *((unsigned char *)a2 + v10 + 8);
  *(void *)((char *)a1 + v10) = v11;
  *((unsigned char *)a1 + v10 + 8) = v12;
  swift_bridgeObjectRetain(v11);
  return a1;
}

void *assignWithCopy for AnyTreeClassifierModel(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v4 = a2[1];
  uint64_t v5 = a1[1];
  a1[1] = v4;
  swift_bridgeObjectRetain(v4);
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = a1 + 2;
  uint64_t v7 = a2 + 2;
  uint64_t v8 = a1[2];
  uint64_t v9 = a2[2];
  if (v8)
  {
    if (v9)
    {
      a1[2] = v9;
      swift_bridgeObjectRetain(v9);
      swift_bridgeObjectRelease(v8);
      a1[3] = a2[3];
      uint64_t v10 = a2[4];
      uint64_t v11 = a1[4];
      a1[4] = v10;
      swift_bridgeObjectRetain(v10);
      swift_bridgeObjectRelease(v11);
    }
    else
    {
      outlined destroy of FeatureVectorizer<Float>.Transformer((uint64_t)(a1 + 2));
      _OWORD *v6 = *v7;
      a1[4] = a2[4];
    }
  }
  else if (v9)
  {
    a1[2] = v9;
    a1[3] = a2[3];
    uint64_t v12 = a2[4];
    a1[4] = v12;
    swift_bridgeObjectRetain(v9);
    swift_bridgeObjectRetain(v12);
  }
  else
  {
    a1[4] = a2[4];
    _OWORD *v6 = *v7;
  }
  uint64_t v13 = *(int *)(a3 + 24);
  uint64_t v14 = type metadata accessor for BaseTreeClassifierModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 24))((char *)a1 + v13, (char *)a2 + v13, v14);
  uint64_t v15 = *(int *)(a3 + 28);
  uint64_t v16 = *(void *)((char *)a2 + v15);
  char v17 = *((unsigned char *)a2 + v15 + 8);
  uint64_t v18 = *(void *)((char *)a1 + v15);
  *(void *)((char *)a1 + v15) = v16;
  *((unsigned char *)a1 + v15 + 8) = v17;
  swift_bridgeObjectRetain(v16);
  swift_bridgeObjectRelease(v18);
  return a1;
}

uint64_t outlined destroy of FeatureVectorizer<Float>.Transformer(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Float>.Transformer);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t initializeWithTake for AnyTreeClassifierModel(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = *(_OWORD *)(a2 + 16);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v4 = *(int *)(a3 + 24);
  uint64_t v5 = type metadata accessor for BaseTreeClassifierModel(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 32))(a1 + v4, a2 + v4, v5);
  uint64_t v6 = *(int *)(a3 + 28);
  *(unsigned char *)(a1 + v6 + 8) = *(unsigned char *)(a2 + v6 + 8);
  *(void *)(a1 + v6) = *(void *)(a2 + v6);
  return a1;
}

void *assignWithTake for AnyTreeClassifierModel(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v5 = a1[1];
  a1[1] = a2[1];
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = a1 + 2;
  uint64_t v7 = a2 + 2;
  uint64_t v8 = a1[2];
  if (v8)
  {
    uint64_t v9 = a2[2];
    if (v9)
    {
      a1[2] = v9;
      swift_bridgeObjectRelease(v8);
      a1[3] = a2[3];
      uint64_t v10 = a1[4];
      a1[4] = a2[4];
      swift_bridgeObjectRelease(v10);
    }
    else
    {
      outlined destroy of FeatureVectorizer<Float>.Transformer((uint64_t)(a1 + 2));
      _OWORD *v6 = *v7;
      a1[4] = a2[4];
    }
  }
  else
  {
    a1[4] = a2[4];
    _OWORD *v6 = *v7;
  }
  uint64_t v11 = *(int *)(a3 + 24);
  uint64_t v12 = type metadata accessor for BaseTreeClassifierModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 40))((char *)a1 + v11, (char *)a2 + v11, v12);
  uint64_t v13 = *(int *)(a3 + 28);
  char v14 = *((unsigned char *)a2 + v13 + 8);
  uint64_t v15 = *(void *)((char *)a1 + v13);
  *(void *)((char *)a1 + v13) = *(void *)((char *)a2 + v13);
  *((unsigned char *)a1 + v13 + 8) = v14;
  swift_bridgeObjectRelease(v15);
  return a1;
}

uint64_t getEnumTagSinglePayload for AnyTreeClassifierModel(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_107453);
}

uint64_t sub_107453(uint64_t a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t result = 0;
    if ((*(void *)(a1 + 8) & 0xFFFFFFFF00000001) == 0) {
      return (*(void *)(a1 + 8) >> 1) + 1;
    }
  }
  else
  {
    uint64_t v5 = type metadata accessor for BaseTreeClassifierModel(0);
    return __swift_getEnumTagSinglePayload(*(int *)(a3 + 24) + a1, a2, v5);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for AnyTreeClassifierModel(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_1074DB);
}

uint64_t sub_1074DB(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(a1 + 8) = 2 * (a2 - 1);
  }
  else
  {
    uint64_t v5 = type metadata accessor for BaseTreeClassifierModel(0);
    return __swift_storeEnumTagSinglePayload(*(int *)(a4 + 24) + a1, a2, a2, v5);
  }
  return result;
}

uint64_t type metadata accessor for AnyTreeClassifierModel(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for AnyTreeClassifierModel;
  if (!type metadata singleton initialization cache for AnyTreeClassifierModel) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for AnyTreeClassifierModel);
  }
  return result;
}

uint64_t type metadata completion function for AnyTreeClassifierModel(uint64_t a1)
{
  v3[0] = &unk_34A5F8;
  v3[1] = &unk_34A610;
  uint64_t result = type metadata accessor for BaseTreeClassifierModel(319);
  if (v2 <= 0x3F)
  {
    v3[2] = *(void *)(result - 8) + 64;
    void v3[3] = &unk_34A628;
    swift_initStructMetadata(a1, 256, 4, v3, a1 + 16);
    return 0;
  }
  return result;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n(uint64_t a1, uint64_t a2)
{
  int64_t v2 = *(void *)(a1 + 16);
  if (v2)
  {
    uint64_t v11 = a2;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    uint64_t v3 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>)
                   - 8);
    uint64_t v4 = ((*(unsigned __int8 *)(v3 + 80) + 32) & ~*(unsigned __int8 *)(v3 + 80)) + a1;
    uint64_t v10 = *(void *)(v3 + 72);
    do
    {
      swift_getAtKeyPath(v4, a2);
      long long v5 = v9;
      unint64_t v6 = _swiftEmptyArrayStorage[2];
      unint64_t v7 = v6 + 1;
      if (_swiftEmptyArrayStorage[3] >> 1 <= v6)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v6 + 1, 1);
        unint64_t v7 = v6 + 1;
        long long v5 = v9;
      }
      _swiftEmptyArrayStorage[2] = v7;
      *(_OWORD *)&_swiftEmptyArrayStorage[2 * v6 + 4] = v5;
      v4 += v10;
      --v2;
      a2 = v11;
    }
    while (v2);
  }
  swift_release();
  return _swiftEmptyArrayStorage;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n(uint64_t a1, uint64_t a2)
{
  int64_t v3 = *(void *)(a1 + 16);
  if (v3)
  {
    uint64_t v13 = *(void *)(a1 + 16);
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3, 0);
    uint64_t v4 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<Int>)
                   - 8);
    uint64_t v5 = ((*(unsigned __int8 *)(v4 + 80) + 32) & ~*(unsigned __int8 *)(v4 + 80)) + a1;
    uint64_t v14 = *(void *)(v4 + 72);
    uint64_t v12 = a2;
    do
    {
      swift_getAtKeyPath(v5, a2);
      uint64_t v6 = v15;
      unint64_t v7 = _swiftEmptyArrayStorage[2];
      int64_t v8 = v7 + 1;
      if (_swiftEmptyArrayStorage[3] >> 1 <= v7)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v8, 1);
        int64_t v8 = v7 + 1;
        uint64_t v6 = v15;
      }
      _swiftEmptyArrayStorage[2] = v8;
      uint64_t v9 = 2 * v7;
      _swiftEmptyArrayStorage[v9 + 4] = v6;
      LOBYTE(_swiftEmptyArrayStorage[v9 + 5]) = v16 & 1;
      v5 += v14;
      BOOL v10 = v13-- == 1;
      a2 = v12;
    }
    while (!v10);
  }
  swift_release();
  return _swiftEmptyArrayStorage;
}

uint64_t AnyTreeClassifierModel.applied(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v26 = v4;
  unint64_t v25 = a3;
  uint64_t v22 = a2;
  uint64_t v24 = v3;
  uint64_t v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Float>);
  uint64_t v6 = *(void *)(v23 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v27 = v5;
  uint64_t v10 = *(void *)(v5 + 16);
  if (!v10)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000001CLL, "ressorModel.swift" + 0x8000000000000000, "CreateML/AnyTreeClassifierModel.swift", 37, 2, 29, 0);
    BUG();
  }
  uint64_t result = specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(a1, 0, v10, *(void *)(v27 + 24), *(void *)(v27 + 32));
  if (!v26)
  {
    uint64_t v26 = v6;
    uint64_t v12 = type metadata accessor for AnyTreeClassifierModel(0);
    uint64_t v13 = BaseTreeClassifierModel.applied(features:eventHandler:)(&v21, v22, v25);
    char v14 = v13;
    unint64_t v25 = &v21;
    uint64_t v15 = *(int *)(v12 + 28);
    uint64_t v16 = *(void *)(v27 + v15);
    char v17 = alloca(32);
    uint64_t v18 = alloca(32);
    BOOL v19 = *(unsigned char *)(v27 + v15 + 8) == 0;
    uint64_t v22 = v27;
    uint64_t v23 = v16;
    if (v19)
    {
      MLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5((void (*)(uint64_t))partial apply for closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:), (uint64_t)&v21, v13);
      swift_bridgeObjectRelease(v14);
      specialized AnyTreeClassifierModel.buildDataFrame<A>(_:)((uint64_t)MLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5);
    }
    else
    {
      MLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_AHySSGs5NeverOTg5((void (*)(uint64_t))partial apply for closure #2 in AnyTreeClassifierModel.applied(to:eventHandler:), &v21, v13, (uint64_t)&v21);
      swift_bridgeObjectRelease(v14);
      specialized AnyTreeClassifierModel.buildDataFrame<A>(_:)((uint64_t)MLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5);
    }
    swift_bridgeObjectRelease((_BYTE)MLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5);
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v26 + 8))(v25, v23);
  }
  return result;
}

uint64_t specialized AnyTreeClassifierModel.buildDataFrame<A>(_:)(uint64_t a1)
{
  v28[6] = v1;
  uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v29 = *(void *)(v31 - 8);
  int64_t v4 = *(void *)(v29 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  BOOL v40 = v28;
  uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<ClassificationDistribution<Int>>);
  uint64_t v30 = *(void *)(v32 - 8);
  int64_t v7 = *(void *)(v30 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v33 = v28;
  uint64_t v34 = (void *)*v2;
  uint64_t v10 = v2[1];
  char v38 = v34;
  uint64_t v39 = v10;
  swift_bridgeObjectRetain(v10);
  v11._uint64_t countAndFlagsBits = 0x6C696261626F7250;
  v11._char object = (void *)0xEB00000000797469;
  String.append(_:)(v11);
  uint64_t v36 = v38;
  uint64_t v37 = v39;
  uint64_t v35 = a1;
  char v38 = (void *)a1;
  swift_bridgeObjectRetain(a1);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<Int>);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [ClassificationDistribution<Int>]);
  uint64_t v14 = lazy protocol witness table accessor for type [String] and conformance [A](&lazy protocol witness table cache variable for type [ClassificationDistribution<Int>] and conformance [A], &demangling cache variable for type metadata for [ClassificationDistribution<Int>]);
  Column.init<A>(name:contents:)(v36, v37, &v38, v12, v13, v14);
  v28[2] = &type metadata for Int;
  v28[3] = &protocol witness table for Int;
  uint64_t KeyPath = swift_getKeyPath(&unk_34A6A0);
  swift_bridgeObjectRetain(v10);
  swift_retain();
  MLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n(v35, KeyPath);
  swift_release();
  char v38 = MLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n;
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int?]);
  uint64_t v18 = lazy protocol witness table accessor for type [String] and conformance [A](&lazy protocol witness table cache variable for type [Int?] and conformance [A], &demangling cache variable for type metadata for [Int?]);
  Column.init<A>(name:contents:)(v34, v10, &v38, &type metadata for Int, v17, v18);
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  uint64_t v20 = *(void *)(type metadata accessor for AnyColumn(0) - 8);
  uint64_t v21 = swift_allocObject(v19, ((*(unsigned __int8 *)(v20 + 80) + 32) & ~*(unsigned __int8 *)(v20 + 80)) + 2 * *(void *)(v20 + 72), *(unsigned __int8 *)(v20 + 80) | 7);
  *(void *)(v21 + 16) = 2;
  *(void *)(v21 + 24) = 4;
  uint64_t v22 = v31;
  Column.eraseToAnyColumn()(v31);
  uint64_t v23 = v32;
  uint64_t v24 = v33;
  Column.eraseToAnyColumn()(v32);
  char v38 = (void *)v21;
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  uint64_t v26 = lazy protocol witness table accessor for type [String] and conformance [A](&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn]);
  DataFrame.init<A>(columns:)(&v38, v25, v26);
  (*(void (**)(void *, uint64_t))(v29 + 8))(v40, v22);
  return (*(uint64_t (**)(void *, uint64_t))(v30 + 8))(v24, v23);
}

{
  uint64_t v1;
  void *v2;
  int64_t v4;
  void *v5;
  void *v6;
  int64_t v7;
  void *v8;
  void *v9;
  uint64_t v10;
  Swift::String v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t KeyPath;
  void *MLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  void *v24;
  uint64_t v25;
  uint64_t v26;
  void v28[7];
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  void *v33;
  void *v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  void *v38;
  uint64_t v39;
  void *v40;

  v28[6] = v1;
  uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v29 = *(void *)(v31 - 8);
  int64_t v4 = *(void *)(v29 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  BOOL v40 = v28;
  uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<ClassificationDistribution<String>>);
  uint64_t v30 = *(void *)(v32 - 8);
  int64_t v7 = *(void *)(v30 + 64);
  int64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v33 = v28;
  uint64_t v34 = (void *)*v2;
  uint64_t v10 = v2[1];
  char v38 = v34;
  uint64_t v39 = v10;
  swift_bridgeObjectRetain(v10);
  v11._uint64_t countAndFlagsBits = 0x6C696261626F7250;
  v11._char object = (void *)0xEB00000000797469;
  String.append(_:)(v11);
  uint64_t v36 = v38;
  uint64_t v37 = v39;
  uint64_t v35 = a1;
  char v38 = (void *)a1;
  swift_bridgeObjectRetain(a1);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [ClassificationDistribution<String>]);
  uint64_t v14 = lazy protocol witness table accessor for type [String] and conformance [A](&lazy protocol witness table cache variable for type [ClassificationDistribution<String>] and conformance [A], &demangling cache variable for type metadata for [ClassificationDistribution<String>]);
  Column.init<A>(name:contents:)(v36, v37, &v38, v12, v13, v14);
  v28[2] = &type metadata for String;
  v28[3] = &protocol witness table for String;
  uint64_t KeyPath = swift_getKeyPath(&unk_34A6A0);
  swift_bridgeObjectRetain(v10);
  swift_retain();
  MLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n(v35, KeyPath);
  swift_release();
  char v38 = MLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n;
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String?]);
  uint64_t v18 = lazy protocol witness table accessor for type [String] and conformance [A](&lazy protocol witness table cache variable for type [String?] and conformance [A], &demangling cache variable for type metadata for [String?]);
  Column.init<A>(name:contents:)(v34, v10, &v38, &type metadata for String, v17, v18);
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  uint64_t v20 = *(void *)(type metadata accessor for AnyColumn(0) - 8);
  uint64_t v21 = swift_allocObject(v19, ((*(unsigned __int8 *)(v20 + 80) + 32) & ~*(unsigned __int8 *)(v20 + 80)) + 2 * *(void *)(v20 + 72), *(unsigned __int8 *)(v20 + 80) | 7);
  *(void *)(v21 + 16) = 2;
  *(void *)(v21 + 24) = 4;
  uint64_t v22 = v31;
  Column.eraseToAnyColumn()(v31);
  uint64_t v23 = v32;
  uint64_t v24 = v33;
  Column.eraseToAnyColumn()(v32);
  char v38 = (void *)v21;
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  uint64_t v26 = lazy protocol witness table accessor for type [String] and conformance [A](&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn]);
  DataFrame.init<A>(columns:)(&v38, v25, v26);
  (*(void (**)(void *, uint64_t))(v29 + 8))(v40, v22);
  return (*(uint64_t (**)(void *, uint64_t))(v30 + 8))(v24, v23);
}

uint64_t closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  uint64_t v12 = a6;
  uint64_t v11 = a3;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<Int>);
  return ClassificationDistribution.map<A>(_:)(a5, v10, v8, v12, a7);
}

uint64_t closure #1 in AnyTreeClassifierModel.convertDistribution(_:labels:)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 16);
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Classification<Int>);
  Classification.label.getter(v3);
  if (v5[0] < 0 || v5[0] >= v2)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000029, "ClassifierModel.swift" + 0x8000000000000000, "CreateML/AnyTreeClassifierModel.swift", 37, 2, 47, 0);
    BUG();
  }
  Classification.label.getter(v3);
  if (v5[0] >= v2) {
    BUG();
  }
  v5[0] = *(void *)(a2 + 8 * v5[0] + 32);
  Classification.probability.getter(v3);
  return Classification.init(label:probability:)(v5, &type metadata for Int, &protocol witness table for Int);
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  void v6[6];

  uint64_t v2 = *(void *)(a2 + 16);
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Classification<Int>);
  Classification.label.getter(v3);
  if (v6[0] < 0 || v6[0] >= v2)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000029, "ClassifierModel.swift" + 0x8000000000000000, "CreateML/AnyTreeClassifierModel.swift", 37, 2, 57, 0);
    BUG();
  }
  Classification.label.getter(v3);
  if (v6[0] < 0 || v6[0] >= v2) {
    BUG();
  }
  int64_t v4 = *(void *)(a2 + 16 * v6[0] + 40);
  v6[0] = *(void *)(a2 + 16 * v6[0] + 32);
  v6[1] = v4;
  swift_bridgeObjectRetain(v4);
  Classification.probability.getter(v3);
  return Classification.init(label:probability:)(v6, &type metadata for String, &protocol witness table for String);
}

uint64_t key path getter for ClassificationDistribution.mostLikelyLabel : <A>ClassificationDistribution<A>(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = type metadata accessor for ClassificationDistribution(0, *(void *)(a3 + a2 - 16), *(void *)(a3 + a2 - 8));
  return ClassificationDistribution.mostLikelyLabel.getter(v3);
}

uint64_t AnyTreeClassifierModel.computeMetrics(on:)(uint64_t a1)
{
  v14[0] = v1;
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for AnyColumn(0) - 8) + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v15 = v14;
  int64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  uint64_t v20 = v14;
  uint64_t v17 = type metadata accessor for DataFrame(0);
  uint64_t v16 = *(void *)(v17 - 8);
  int64_t v9 = *(void *)(v16 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  v14[1] = a1;
  uint64_t result = AnyTreeClassifierModel.applied(to:eventHandler:)(a1, 0, 0);
  if (!v2)
  {
    uint64_t v18 = *v3;
    uint64_t v19 = v3[1];
    DataFrame.subscript.getter(v18, v19);
    uint64_t v13 = (uint64_t)v15;
    DataFrame.subscript.getter(v18, v19);
    AnyClassificationMetrics.init(_:_:)((uint64_t)v20, v13);
    return (*(uint64_t (**)(void *, uint64_t))(v16 + 8))(v14, v17);
  }
  return result;
}

uint64_t protocol witness for Transformer.applied(to:eventHandler:) in conformance AnyTreeClassifierModel(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4)
{
  AnyTreeClassifierModel.applied(to:eventHandler:)(a2, a3, a4);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(*(uint64_t (**)(void))(v4 + 8));
}

uint64_t base witness table accessor for Transformer in AnyTreeClassifierModel()
{
  return lazy protocol witness table accessor for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel();
}

uint64_t lazy protocol witness table accessor for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel()
{
  uint64_t result = lazy protocol witness table cache variable for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel;
  if (!lazy protocol witness table cache variable for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel)
  {
    uint64_t v1 = type metadata accessor for AnyTreeClassifierModel(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for AnyTreeClassifierModel, v1);
    lazy protocol witness table cache variable for type AnyTreeClassifierModel and conformance AnyTreeClassifierModel = result;
  }
  return result;
}

uint64_t partial apply for closure #2 in AnyTreeClassifierModel.applied(to:eventHandler:)(uint64_t a1, uint64_t a2)
{
  return closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:)(a1, *(void *)(v2 + 16), *(void *)(v2 + 24), a2, (uint64_t)partial apply for closure #1 in AnyTreeClassifierModel.convertDistribution(_:labels:), (uint64_t)&type metadata for String, (uint64_t)&protocol witness table for String);
}

uint64_t partial apply for closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:)(uint64_t a1, uint64_t a2)
{
  return closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:)(a1, *(void *)(v2 + 16), *(void *)(v2 + 24), a2, (uint64_t)partial apply for closure #1 in AnyTreeClassifierModel.convertDistribution(_:labels:), (uint64_t)&type metadata for Int, (uint64_t)&protocol witness table for Int);
}

uint64_t sub_108412(uint64_t a1)
{
  return *(void *)(a1 + 8);
}

uint64_t sub_10841C(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return key path getter for ClassificationDistribution.mostLikelyLabel : <A>ClassificationDistribution<A>(a1, a2, a3);
}

uint64_t sub_108426()
{
  return 16;
}

void sub_108440(_OWORD *a1, _OWORD *a2)
{
  *a2 = *a1;
}

uint64_t partial apply for closure #1 in AnyTreeClassifierModel.convertDistribution(_:labels:)(uint64_t a1)
{
  return closure #1 in AnyTreeClassifierModel.convertDistribution(_:labels:)(a1, *(void *)(v1 + 16));
}

{
  uint64_t v1;

  return closure #1 in AnyTreeClassifierModel.convertDistribution(_:labels:)(a1, *(void *)(v1 + 16));
}

uint64_t _UntypedColumn.__allocating_init<A>(_:)(uint64_t a1, uint64_t a2, void *a3, double a4)
{
  uint64_t v6 = swift_allocObject(v4, 24, 7);
  _UntypedColumn.init<A>(_:)(a1, a2, a3, a4);
  return v6;
}

uint64_t _UntypedColumn.init<A>(_:)(uint64_t a1, uint64_t a2, void *a3, double a4)
{
  uint64_t v84 = v4;
  uint64_t v70 = v5;
  uint64_t v79 = a1;
  uint64_t v6 = *(void *)(a2 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  uint64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  char v82 = &v66;
  uint64_t v81 = a3;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, a2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v71 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v10 = *(void *)(v71 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v13 = tc_v1_flex_list_create(0);
  if (!v13) {
    BUG();
  }
  uint64_t v14 = v13;
  uint64_t v15 = type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject(v15, v67);
  *(void *)(inited + 16) = v14;
  uint64_t v83 = inited;
  *(unsigned char *)(inited + 24) = 1;
  uint64_t v76 = v6;
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v6 + 16))(v82, v79, a2);
  uint64_t v17 = v81;
  dispatch thunk of Sequence.makeIterator()(a2, v81);
  uint64_t v77 = a2;
  uint64_t v18 = AssociatedTypeWitness;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v17, a2, AssociatedTypeWitness, &protocol requirements base descriptor for Sequence, &associated conformance descriptor for Sequence.Sequence.Iterator: IteratorProtocol);
  uint64_t v68 = AssociatedConformanceWitness;
  LOBYTE(AssociatedConformanceWitness) = 6;
  uint64_t v80 = AssociatedConformanceWitness;
  uint64_t v20 = v79;
  uint64_t v21 = v18;
  BOOL v75 = &v66;
  while (1)
  {
    dispatch thunk of IteratorProtocol.next()(v21, v68);
    double v22 = v72;
    uint64_t v23 = v73;
    BOOL v24 = v74 == 6;
    uint64_t v81 = v73;
    LODWORD(v82) = v74;
    if (v74 >= 6u) {
      break;
    }
    BOOL v24 = (_BYTE)v80 == 6;
    uint64_t v20 = v76;
    if ((_BYTE)v80 == 6)
    {
      switch(v74)
      {
        case 0u:
          goto LABEL_8;
        case 1u:
          goto LABEL_22;
        case 2u:
          goto LABEL_17;
        case 3u:
          goto LABEL_20;
        case 4u:
          goto LABEL_15;
        case 5u:
          goto LABEL_26;
        default:
          goto LABEL_11;
      }
    }
    uint64_t v25 = v77;
    switch(v74)
    {
      case 0u:
        if ((_BYTE)v80) {
          goto LABEL_31;
        }
LABEL_8:
        uint64_t v26 = v84;
        uint64_t v27 = specialized handling<A, B>(_:_:)(*(uint64_t *)&v72);
        if (v26) {
          goto LABEL_44;
        }
        uint64_t v28 = v27;
        uint64_t v84 = 0;
        if (!v27) {
          BUG();
        }
        uint64_t v80 = 0;
        uint64_t v29 = type metadata accessor for CMLFeatureValue();
        swift_allocObject(v29, 25, 7);
        uint64_t v30 = CMLFeatureValue.init(rawValue:ownsValue:)(v28, 1);
        double v31 = v22;
        uint64_t v32 = v81;
        char v33 = (char)v82;
        goto LABEL_13;
      case 1u:
        if ((_BYTE)v80 != 1) {
          goto LABEL_31;
        }
LABEL_22:
        a4 = v72;
        uint64_t v26 = v84;
        uint64_t v42 = specialized handling<A, B>(_:_:)();
        if (v26)
        {
LABEL_44:
          uint64_t v65 = v26;
LABEL_45:
          swift_unexpectedError(v65, "CreateML/MLDataValueConvertible.swift", 37, 1);
          BUG();
        }
        uint64_t v43 = v42;
        uint64_t v84 = 0;
        if (!v42) {
          BUG();
        }
        uint64_t v44 = type metadata accessor for CMLFeatureValue();
        swift_allocObject(v44, 25, 7);
        uint64_t v30 = CMLFeatureValue.init(rawValue:ownsValue:)(v43, 1);
        outlined consume of MLDataValue?(*(void **)&v22, v81, (char)v82);
        LOBYTE(v34) = 1;
        goto LABEL_27;
      case 2u:
        if ((_BYTE)v80 != 2) {
          goto LABEL_31;
        }
LABEL_17:
        type metadata accessor for CMLFeatureValue();
        double v35 = v22;
        uint64_t v36 = v81;
        double v37 = v22;
        char v38 = (char)v82;
        outlined copy of MLDataValue(*(void **)&v35, v81, v82);
        swift_bridgeObjectRetain((_BYTE)v36);
        double v69 = v37;
        uint64_t v39 = v84;
        uint64_t v40 = CMLFeatureValue.__allocating_init(_:)(*(uint64_t *)&v37, (uint64_t)v36);
        uint64_t v84 = v39;
        if (v39)
        {
          uint64_t v65 = v84;
          goto LABEL_45;
        }
        uint64_t v30 = v40;
        outlined consume of MLDataValue?(*(void **)&v69, v36, v38);
        LOBYTE(v41) = 2;
        uint64_t v80 = v41;
        double v22 = v69;
        break;
      case 3u:
        if ((_BYTE)v80 != 3) {
          goto LABEL_31;
        }
LABEL_20:
        uint64_t v34 = MLDataValue.SequenceType.featureValue.getter(a4);
        uint64_t v30 = v34;
        LOBYTE(v34) = 3;
        goto LABEL_27;
      case 4u:
        if ((_BYTE)v80 != 4) {
          goto LABEL_31;
        }
LABEL_15:
        uint64_t v34 = MLDataValue.DictionaryType.featureValue.getter();
        uint64_t v30 = v34;
        LOBYTE(v34) = 4;
        goto LABEL_27;
      case 5u:
        if ((_BYTE)v80 != 5)
        {
LABEL_31:
          uint64_t v46 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          swift_allocError(&type metadata for MLCreateError, v46, 0, 0);
          *(void *)uint64_t v47 = 0xD000000000000027;
          *(void *)(v47 + 8) = "Invalid labelColumn." + 0x8000000000000000;
          *(_OWORD *)(v47 + 16) = 0;
          *(_OWORD *)(v47 + 32) = 0;
          *(unsigned char *)(v47 + 48) = 1;
          swift_willThrow(&type metadata for MLCreateError, v46, v47, v48, v49, v50);
          swift_release();
          outlined consume of MLDataValue?(*(void **)&v22, v81, (char)v82);
          (*(void (**)(uint64_t, uint64_t))(v20 + 8))(v79, v25);
          uint64_t v51 = v75;
          uint64_t v52 = AssociatedTypeWitness;
          uint64_t v53 = v71;
LABEL_32:
          (*(void (**)(uint64_t *, uint64_t))(v53 + 8))(v51, v52);
LABEL_33:
          uint64_t v54 = type metadata accessor for _UntypedColumn();
          uint64_t v55 = v70;
          swift_deallocPartialClassInstance(v70, v54, 24, 7);
          return v55;
        }
LABEL_26:
        uint64_t v34 = MLDataValue.MultiArrayType.featureValue.getter();
        uint64_t v30 = v34;
        LOBYTE(v34) = 5;
LABEL_27:
        uint64_t v80 = v34;
        break;
      default:
        goto LABEL_11;
    }
LABEL_28:
    uint64_t v45 = v84;
    CMLSequence.append(_:)(v30);
    uint64_t v84 = v45;
    if (v45)
    {
      swift_release();
      swift_release();
      outlined consume of MLDataValue?(*(void **)&v22, v81, (char)v82);
      (*(void (**)(uint64_t, uint64_t))(v76 + 8))(v79, v77);
      (*(void (**)(uint64_t *, uint64_t))(v71 + 8))(v75, AssociatedTypeWitness);
      goto LABEL_33;
    }
    swift_release();
    outlined consume of MLDataValue?(*(void **)&v22, v81, (char)v82);
    uint64_t v20 = v79;
    uint64_t v21 = AssociatedTypeWitness;
  }
LABEL_11:
  if (v24)
  {
    type metadata accessor for CMLFeatureValue();
    uint64_t v30 = CMLFeatureValue.__allocating_init()(0);
    double v31 = v22;
    uint64_t v32 = v23;
    char v33 = 6;
LABEL_13:
    outlined consume of MLDataValue?(*(void **)&v31, v32, v33);
    goto LABEL_28;
  }
  (*(void (**)(uint64_t *, uint64_t))(v71 + 8))(v75, AssociatedTypeWitness);
  uint64_t v57 = v83;
  uint64_t v58 = v84;
  uint64_t v59 = specialized handling<A, B>(_:_:)(*(void *)(v83 + 16));
  if (v58)
  {
    swift_setDeallocating(v57);
    uint64_t v60 = CMLFeatureValue.deinit(a4);
    swift_deallocClassInstance(v60, 25, 7);
    uint64_t v51 = (uint64_t *)v20;
    uint64_t v52 = v77;
    uint64_t v53 = v76;
    goto LABEL_32;
  }
  uint64_t v61 = v59;
  if (!v59) {
    BUG();
  }
  swift_setDeallocating(v57);
  uint64_t v62 = CMLFeatureValue.deinit(a4);
  swift_deallocClassInstance(v62, 25, 7);
  uint64_t v63 = type metadata accessor for CMLColumn();
  uint64_t v64 = swift_allocObject(v63, 24, 7);
  *(void *)(v64 + 16) = v61;
  (*(void (**)(uint64_t, uint64_t))(v76 + 8))(v79, v77);
  uint64_t v55 = v70;
  *(void *)(v70 + 16) = v64;
  return v55;
}

uint64_t _UntypedColumn.__allocating_init<A>(_:)(uint64_t *a1, uint64_t a2, uint64_t *a3, uint64_t a4)
{
  uint64_t v6 = swift_allocObject(v4, 24, 7);
  _UntypedColumn.init<A>(_:)(a1, a2, a3, a4);
  return v6;
}

uint64_t _UntypedColumn.init<A>(_:)(uint64_t *a1, uint64_t a2, uint64_t *a3, uint64_t a4)
{
  uint64_t v55 = v4;
  uint64_t v61 = v5;
  uint64_t v53 = a4;
  uint64_t v64 = a1;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, a2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v59 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v9 = *(void *)(v59 + 64);
  int64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v56 = &v48;
  uint64_t v52 = AssociatedTypeWitness;
  int64_t v12 = *(void *)(*(void *)(type metadata accessor for Optional(0, AssociatedTypeWitness) - 8) + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v51 = &v48;
  uint64_t v15 = *(void *)(a2 - 8);
  int64_t v16 = *(void *)(v15 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v60 = &v48;
  uint64_t v65 = a3;
  uint64_t v19 = a3;
  uint64_t v20 = a2;
  uint64_t v57 = swift_getAssociatedTypeWitness(0, v19, a2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v54 = *(void *)(v57 - 8);
  int64_t v21 = *(void *)(v54 + 64);
  double v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  uint64_t v24 = tc_v1_flex_list_create(0);
  if (!v24) {
    BUG();
  }
  uint64_t v25 = v24;
  uint64_t v26 = type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject(v26, v49);
  *(void *)(inited + 16) = v25;
  uint64_t v58 = inited;
  *(unsigned char *)(inited + 24) = 1;
  uint64_t v63 = v15;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v15 + 16))(v60, v64, v20);
  uint64_t v28 = v65;
  dispatch thunk of Sequence.makeIterator()(v20, v65);
  uint64_t v29 = v28;
  uint64_t v62 = v20;
  uint64_t v30 = v57;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v29, v20, v57, &protocol requirements base descriptor for Sequence, &associated conformance descriptor for Sequence.Sequence.Iterator: IteratorProtocol);
  uint64_t v32 = (uint64_t)v51;
  uint64_t v65 = &v48;
  uint64_t v33 = v30;
  uint64_t v60 = (uint64_t *)AssociatedConformanceWitness;
  dispatch thunk of IteratorProtocol.next()(v30, AssociatedConformanceWitness);
  uint64_t v34 = v52;
  if (__swift_getEnumTagSinglePayload(v32, 1, v52) != 1)
  {
    uint64_t v50 = *(void (**)(void, void, void))(v59 + 32);
    while (1)
    {
      v50(v56, v32, v34);
      uint64_t v35 = v34;
      uint64_t v36 = MLDataValueConvertible.featureValue.getter(v34, v53);
      uint64_t v37 = v55;
      CMLSequence.append(_:)(v36);
      if (v37) {
        break;
      }
      uint64_t v55 = 0;
      (*(void (**)(uint64_t *, uint64_t))(v59 + 8))(v56, v35);
      swift_release();
      uint64_t v33 = v57;
      dispatch thunk of IteratorProtocol.next()(v57, v60);
      uint64_t v34 = v52;
      if (__swift_getEnumTagSinglePayload(v32, 1, v52) == 1) {
        goto LABEL_6;
      }
    }
    swift_release();
    swift_release();
    (*(void (**)(uint64_t *, uint64_t))(v63 + 8))(v64, v62);
    (*(void (**)(uint64_t *, uint64_t))(v59 + 8))(v56, v35);
    uint64_t v41 = v65;
    uint64_t v42 = v57;
    uint64_t v43 = v54;
    goto LABEL_10;
  }
LABEL_6:
  (*(void (**)(uint64_t *, uint64_t))(v54 + 8))(v65, v33);
  (*(void (**)(uint64_t))(v53 + 8))(v34);
  unint64_t v38 = 0x5060403020100uLL >> (8 * v66);
  type metadata accessor for CMLColumn();
  uint64_t v39 = v55;
  uint64_t v40 = CMLColumn.__allocating_init(_:type:)(v58, v38);
  if (v39)
  {
    uint64_t v41 = v64;
    uint64_t v42 = v62;
    uint64_t v43 = v63;
LABEL_10:
    (*(void (**)(uint64_t *, uint64_t))(v43 + 8))(v41, v42);
    uint64_t v45 = v61;
    uint64_t v46 = type metadata accessor for _UntypedColumn();
    swift_deallocPartialClassInstance(v45, v46, 24, 7);
    return v45;
  }
  uint64_t v44 = v40;
  (*(void (**)(uint64_t *, uint64_t))(v63 + 8))(v64, v62);
  uint64_t v45 = v61;
  *(void *)(v61 + 16) = v44;
  return v45;
}

uint64_t _UntypedColumn.init(repeating:count:)(uint64_t a1, uint64_t a2, double a3)
{
  uint64_t v9 = v3;
  uint64_t v4 = *(void **)a1;
  uint64_t v5 = *(void **)(a1 + 8);
  int v6 = *(_DWORD *)(a1 + 16);
  type metadata accessor for CMLColumn();
  uint64_t v7 = MLDataValue.featureValue.getter(a3);
  outlined consume of MLDataValue(v4, v5, v6);
  *(void *)(v9 + 16) = CMLColumn.__allocating_init(repeating:count:)(v7, a2);
  return v9;
}

uint64_t _UntypedColumn.__allocating_init<A>(repeating:count:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v7 = swift_allocObject(v4, 24, 7);
  _UntypedColumn.init<A>(repeating:count:)(a1, a2, a3, a4);
  return v7;
}

uint64_t _UntypedColumn.init<A>(repeating:count:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v10 = v4;
  type metadata accessor for CMLColumn();
  uint64_t v7 = MLDataValueConvertible.featureValue.getter(a3, a4);
  uint64_t v8 = CMLColumn.__allocating_init(repeating:count:)(v7, a2);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(a3 - 8) + 8))(a1, a3);
  uint64_t result = v10;
  *(void *)(v10 + 16) = v8;
  return result;
}

uint64_t _UntypedColumn.init(_:)(uint64_t a1, uint64_t a2)
{
  type metadata accessor for CMLColumn();
  if (__OFADD__(1, a2)) {
    BUG();
  }
  *(void *)(v2 + 16) = CMLColumn.__allocating_init(_:)(a1, a2 + 1);
  return v2;
}

uint64_t _UntypedColumn.appending(contentsOf:)(uint64_t a1)
{
  uint64_t v3 = *(void *)(v2 + 16);
  char v4 = CMLColumn.type.getter();
  uint64_t v5 = *(void *)(a1 + 16);
  if (v4 == CMLColumn.type.getter())
  {
    type metadata accessor for CMLColumn();
    swift_retain();
    swift_retain();
    uint64_t result = CMLColumn.__allocating_init(concatenating:and:)(v3, v5);
    if (!v1)
    {
      uint64_t v7 = result;
      uint64_t v8 = type metadata accessor for _UntypedColumn();
      uint64_t result = swift_allocObject(v8, 24, 7);
      *(void *)(result + 16) = v7;
    }
  }
  else
  {
    uint64_t v9 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v9, 0, 0);
    *(void *)uint64_t v10 = 0xD000000000000034;
    *(void *)(v10 + 8) = " \nValues:        [" + 0x8000000000000000;
    *(_OWORD *)(v10 + 16) = 0;
    *(_OWORD *)(v10 + 32) = 0;
    *(unsigned char *)(v10 + 48) = 1;
    return swift_willThrow();
  }
  return result;
}

unint64_t _UntypedColumn.type.getter()
{
  uint64_t v1 = v0;
  unint64_t result = 0x5060403020100uLL >> (8 * CMLColumn.type.getter());
  *uint64_t v1 = result;
  return result;
}

uint64_t static _UntypedColumn.performRightScalar(op:a:b:)(char a1, uint64_t a2, double *a3)
{
  uint64_t v4 = MLDataValue.featureValue.getter(*a3);
  switch(a1)
  {
    case 0:
      uint64_t v5 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(*(void *)(a2 + 16) + 16), (uint64_t)"+", *(void *)(v4 + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v21 = v5;
      if (!v5) {
        BUG();
      }
      goto LABEL_33;
    case 1:
      uint64_t v8 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(*(void *)(a2 + 16) + 16), (uint64_t)"-", *(void *)(v4 + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v21 = v8;
      if (!v8) {
        BUG();
      }
      goto LABEL_33;
    case 2:
      uint64_t v9 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(*(void *)(a2 + 16) + 16), (uint64_t)"/", *(void *)(v4 + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v21 = v9;
      if (!v9) {
        BUG();
      }
      goto LABEL_33;
    case 3:
      uint64_t v10 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(*(void *)(a2 + 16) + 16), (uint64_t)"*", *(void *)(v4 + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v21 = v10;
      if (!v10) {
        BUG();
      }
      goto LABEL_33;
    case 4:
      uint64_t v11 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(*(void *)(a2 + 16) + 16), (uint64_t)"==", *(void *)(v4 + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v21 = v11;
      if (!v11) {
        BUG();
      }
      goto LABEL_33;
    case 5:
      uint64_t v12 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(*(void *)(a2 + 16) + 16), (uint64_t)"!=", *(void *)(v4 + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v21 = v12;
      if (!v12) {
        BUG();
      }
      goto LABEL_33;
    case 6:
      uint64_t v13 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(*(void *)(a2 + 16) + 16), (uint64_t)"<", *(void *)(v4 + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v21 = v13;
      if (!v13) {
        BUG();
      }
      goto LABEL_33;
    case 7:
      uint64_t v14 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(*(void *)(a2 + 16) + 16), (uint64_t)">", *(void *)(v4 + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v21 = v14;
      if (!v14) {
        BUG();
      }
      goto LABEL_33;
    case 8:
      uint64_t v15 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(*(void *)(a2 + 16) + 16), (uint64_t)"<=", *(void *)(v4 + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v21 = v15;
      if (!v15) {
        BUG();
      }
      goto LABEL_33;
    case 9:
      uint64_t v16 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(*(void *)(a2 + 16) + 16), (uint64_t)">=", *(void *)(v4 + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v21 = v16;
      if (!v16) {
        BUG();
      }
LABEL_33:
      swift_release();
      uint64_t v18 = type metadata accessor for CMLColumn();
      uint64_t v19 = swift_allocObject(v18, 24, 7);
      *(void *)(v19 + 16) = v21;
      uint64_t v20 = type metadata accessor for _UntypedColumn();
      uint64_t result = swift_allocObject(v20, 24, 7);
      *(void *)(result + 16) = v19;
      break;
    default:
      uint64_t v6 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v6, 0, 0);
      *(void *)uint64_t v7 = 0xD000000000000017;
      *(void *)(v7 + 8) = "h columns must match" + 0x8000000000000000;
      *(_OWORD *)(v7 + 16) = 0;
      *(_OWORD *)(v7 + 32) = 0;
      *(unsigned char *)(v7 + 48) = 1;
      swift_willThrow();
LABEL_31:
      uint64_t result = swift_release();
      break;
  }
  return result;
}

uint64_t static _UntypedColumn.performLeftScalar(op:a:b:)(char a1, double *a2, uint64_t a3)
{
  uint64_t v5 = MLDataValue.featureValue.getter(*a2);
  switch(a1)
  {
    case 0:
      uint64_t v6 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(v5 + 16), (uint64_t)"+", *(void *)(*(void *)(a3 + 16) + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v25 = v6;
      if (!v6) {
        BUG();
      }
      goto LABEL_33;
    case 1:
      uint64_t v12 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(v5 + 16), (uint64_t)"-", *(void *)(*(void *)(a3 + 16) + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v25 = v12;
      if (!v12) {
        BUG();
      }
      goto LABEL_33;
    case 2:
      uint64_t v13 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(v5 + 16), (uint64_t)"/", *(void *)(*(void *)(a3 + 16) + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v25 = v13;
      if (!v13) {
        BUG();
      }
      goto LABEL_33;
    case 3:
      uint64_t v14 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(v5 + 16), (uint64_t)"*", *(void *)(*(void *)(a3 + 16) + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v25 = v14;
      if (!v14) {
        BUG();
      }
      goto LABEL_33;
    case 4:
      uint64_t v15 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(v5 + 16), (uint64_t)"==", *(void *)(*(void *)(a3 + 16) + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v25 = v15;
      if (!v15) {
        BUG();
      }
      goto LABEL_33;
    case 5:
      uint64_t v16 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(v5 + 16), (uint64_t)"!=", *(void *)(*(void *)(a3 + 16) + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v25 = v16;
      if (!v16) {
        BUG();
      }
      goto LABEL_33;
    case 6:
      uint64_t v17 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(v5 + 16), (uint64_t)"<", *(void *)(*(void *)(a3 + 16) + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v25 = v17;
      if (!v17) {
        BUG();
      }
      goto LABEL_33;
    case 7:
      uint64_t v18 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(v5 + 16), (uint64_t)">", *(void *)(*(void *)(a3 + 16) + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v25 = v18;
      if (!v18) {
        BUG();
      }
      goto LABEL_33;
    case 8:
      uint64_t v19 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(v5 + 16), (uint64_t)"<=", *(void *)(*(void *)(a3 + 16) + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v25 = v19;
      if (!v19) {
        BUG();
      }
      goto LABEL_33;
    case 9:
      uint64_t v20 = specialized handling<A, B, C, D>(_:_:_:_:)(*(void *)(v5 + 16), (uint64_t)">=", *(void *)(*(void *)(a3 + 16) + 16));
      if (v3) {
        goto LABEL_31;
      }
      uint64_t v25 = v20;
      if (!v20) {
        BUG();
      }
LABEL_33:
      swift_release();
      uint64_t v22 = type metadata accessor for CMLColumn();
      uint64_t v23 = swift_allocObject(v22, 24, 7);
      *(void *)(v23 + 16) = v25;
      uint64_t v24 = type metadata accessor for _UntypedColumn();
      uint64_t result = swift_allocObject(v24, 24, 7);
      *(void *)(result + 16) = v23;
      break;
    default:
      uint64_t v7 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v7, 0, 0);
      *(void *)uint64_t v8 = 0xD000000000000017;
      *(void *)(v8 + 8) = "h columns must match" + 0x8000000000000000;
      *(_OWORD *)(v8 + 16) = 0;
      *(_OWORD *)(v8 + 32) = 0;
      *(unsigned char *)(v8 + 48) = 1;
      swift_willThrow(&type metadata for MLCreateError, v7, v8, v9, v10, v11);
LABEL_31:
      uint64_t result = swift_release();
      break;
  }
  return result;
}

char _UntypedColumn.valueAtIndex(index:)(uint64_t a1, double a2)
{
  uint64_t v3 = v2;
  if (a1 < 0 || (uint64_t v2 = CMLColumn.size.getter(), v2 <= a1))
  {
    *(_OWORD *)uint64_t v3 = 0;
    *(unsigned char *)(v3 + 16) = 6;
  }
  else
  {
    uint64_t v4 = CMLColumn.value(at:)(a1);
    LOBYTE(v2) = MLDataValue.init(_:)(v4, a2);
  }
  return v2;
}

uint64_t _UntypedColumn.description.getter()
{
  _UntypedColumn.type.getter();
  switch(v32)
  {
    case 0:
      unint64_t v0 = 0xE300000000000000;
      v1._uint64_t countAndFlagsBits = 7630409;
      break;
    case 1:
      v1._uint64_t countAndFlagsBits = 0x656C62756F44;
      goto LABEL_5;
    case 2:
      v1._uint64_t countAndFlagsBits = 0x676E69727453;
LABEL_5:
      unint64_t v0 = 0xE600000000000000;
      break;
    case 3:
      unint64_t v0 = 0xE800000000000000;
      v1._uint64_t countAndFlagsBits = 0x65636E6575716553;
      break;
    case 4:
      unint64_t v0 = 0xEA00000000007972;
      v1._uint64_t countAndFlagsBits = 0x616E6F6974636944;
      break;
    case 5:
      v1._uint64_t countAndFlagsBits = 0x72724169746C754DLL;
      unint64_t v0 = 0xEA00000000007961;
      break;
    case 6:
      v1._uint64_t countAndFlagsBits = 0x676E697373694DLL;
      unint64_t v0 = 0xE700000000000000;
      break;
  }
  v33._uint64_t countAndFlagsBits = 0x70795465756C6156;
  v33._char object = (void *)0xEB00000000203A65;
  v1._char object = (void *)v0;
  String.append(_:)(v1);
  swift_bridgeObjectRelease(v0);
  char object = (char)v33._object;
  swift_bridgeObjectRetain(v33._object);
  v3._char object = "CreateML/_UntypedColumn.swift" + 0x8000000000000000;
  v3._uint64_t countAndFlagsBits = 0xD000000000000012;
  String.append(_:)(v3);
  swift_bridgeObjectRelease(object);
  *(void *)&double v4 = _mm_loadu_si128((const __m128i *)&v33).u64[0];
  uint64_t v5 = CMLColumn.size.getter();
  uint64_t v6 = 10;
  if (v5 < 10) {
    uint64_t v6 = v5;
  }
  uint64_t v30 = v6;
  if (v6 < 0) {
    BUG();
  }
  uint64_t v31 = v5;
  if (v6)
  {
    uint64_t v7 = 0;
    do
    {
      if (v7)
      {
        v8._uint64_t countAndFlagsBits = 8236;
        v8._char object = (void *)0xE200000000000000;
        String.append(_:)(v8);
      }
      _UntypedColumn.valueAtIndex(index:)(v7, v4);
      uint64_t countAndFlagsBits = (void *)v33._countAndFlagsBits;
      uint64_t v10 = v33._object;
      switch((char)v34)
      {
        case 0:
          uint64_t v11 = lazy protocol witness table accessor for type Int and conformance Int();
          v12._uint64_t countAndFlagsBits = BinaryInteger.description.getter(&type metadata for Int, v11);
          LOBYTE(v13) = v12._object;
          String.append(_:)(v12);
          goto LABEL_24;
        case 1:
          JUMPOUT(0x109A24);
        case 2:
          swift_bridgeObjectRetain(v33._object);
          v14._uint64_t countAndFlagsBits = (uint64_t)countAndFlagsBits;
          v14._char object = v10;
          String.append(_:)(v14);
          outlined consume of MLDataValue(countAndFlagsBits, v10, 2);
          outlined consume of MLDataValue(countAndFlagsBits, v10, 2);
          break;
        case 3:
          v33._char object = closure #1 in MLDataValue.SequenceType.description.getter;
          uint64_t v34 = 0;
          outlined copy of MLDataValue((void *)v33._countAndFlagsBits, v10, 3u);
          swift_retain_n(countAndFlagsBits);
          uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LazyMapSequence<MLDataValue.SequenceType, String>);
          uint64_t v16 = lazy protocol witness table accessor for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>();
          uint64_t v17 = BidirectionalCollection<>.joined(separator:)(8236, 0xE200000000000000, v15, v16);
          uint64_t v19 = v18;
          swift_release();
          v33._uint64_t countAndFlagsBits = 91;
          v33._char object = (void *)0xE100000000000000;
          v20._uint64_t countAndFlagsBits = v17;
          v20._char object = v19;
          String.append(_:)(v20);
          swift_bridgeObjectRelease((_BYTE)v19);
          LOBYTE(v19) = v33._object;
          swift_bridgeObjectRetain(v33._object);
          v20._uint64_t countAndFlagsBits = 93;
          v20._char object = (void *)0xE100000000000000;
          String.append(_:)(v20);
          swift_bridgeObjectRelease((_BYTE)v19);
          outlined consume of MLDataValue(countAndFlagsBits, v10, 3);
          String.append(_:)(v33);
          JUMPOUT(0x109B5ELL);
        case 4:
          uint64_t v21 = lazy protocol witness table accessor for type MLDataValue and conformance MLDataValue();
          swift_bridgeObjectRetain((_BYTE)countAndFlagsBits);
          uint64_t v22 = Dictionary.description.getter(countAndFlagsBits, &type metadata for MLDataValue, &type metadata for MLDataValue, v21);
          uint64_t v13 = v23;
          outlined consume of MLDataValue(countAndFlagsBits, v10, 4);
          v24._uint64_t countAndFlagsBits = v22;
          v24._char object = v13;
          String.append(_:)(v24);
          outlined consume of MLDataValue(countAndFlagsBits, v10, 4);
LABEL_24:
          swift_bridgeObjectRelease((_BYTE)v13);
          break;
        case 5:
          id v25 = (id)v33._countAndFlagsBits;
          v25;
          JUMPOUT(0x109BF4);
        case 6:
          v26._uint64_t countAndFlagsBits = 0x676E697373694DLL;
          v26._char object = (void *)0xE700000000000000;
          String.append(_:)(v26);
          break;
      }
      ++v7;
    }
    while (v30 != v7);
  }
  if (v31 >= 11)
  {
    v27._uint64_t countAndFlagsBits = 0x2E2E2E202CLL;
    v27._char object = (void *)0xE500000000000000;
    String.append(_:)(v27);
  }
  v28._uint64_t countAndFlagsBits = 93;
  v28._char object = (void *)0xE100000000000000;
  String.append(_:)(v28);
  return *(void *)&v4;
}

uint64_t _UntypedColumn.map(_:skipUndefined:outputType:)(uint64_t a1, uint64_t a2, char a3, unsigned char *a4)
{
  uint64_t v4 = CMLColumn.apply(transform:type:skipUndefined:)(a1, a2, 0x5060403020100uLL >> (8 * *a4), a3);
  uint64_t v5 = type metadata accessor for _UntypedColumn();
  uint64_t result = swift_allocObject(v5, 24, 7);
  *(void *)(result + 16) = v4;
  return result;
}

uint64_t _UntypedColumn.__deallocating_deinit()
{
  swift_release(*(void *)(v0 + 16));
  return swift_deallocClassInstance(v0, 24, 7);
}

uint64_t type metadata accessor for _UntypedColumn()
{
  return objc_opt_self(_TtC8CreateML14_UntypedColumn);
}

void outlined consume of MLDataValue?(void *a1, void *a2, char a3)
{
  if (a3 != -1) {
    outlined consume of MLDataValue(a1, a2, a3);
  }
}

uint64_t lazy protocol witness table accessor for type MLDataValue and conformance MLDataValue()
{
  uint64_t result = lazy protocol witness table cache variable for type MLDataValue and conformance MLDataValue;
  if (!lazy protocol witness table cache variable for type MLDataValue and conformance MLDataValue)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLDataValue, &type metadata for MLDataValue);
    lazy protocol witness table cache variable for type MLDataValue and conformance MLDataValue = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLDataValue and conformance MLDataValue;
  if (!lazy protocol witness table cache variable for type MLDataValue and conformance MLDataValue)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLDataValue, &type metadata for MLDataValue);
    lazy protocol witness table cache variable for type MLDataValue and conformance MLDataValue = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>()
{
  uint64_t result = lazy protocol witness table cache variable for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>;
  if (!lazy protocol witness table cache variable for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>)
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for LazyMapSequence<MLDataValue.SequenceType, String>);
    lazy protocol witness table accessor for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType();
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for <> LazyMapSequence<A, B>, v1);
    lazy protocol witness table cache variable for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B> = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType()
{
  uint64_t result = lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType;
  if (!lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLDataValue.SequenceType, &type metadata for MLDataValue.SequenceType);
    lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType;
  if (!lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLDataValue.SequenceType, &type metadata for MLDataValue.SequenceType);
    lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType;
  if (!lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLDataValue.SequenceType, &type metadata for MLDataValue.SequenceType);
    lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType;
  if (!lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLDataValue.SequenceType, &type metadata for MLDataValue.SequenceType);
    lazy protocol witness table cache variable for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType = result;
  }
  return result;
}

char MLActivityClassifier.ModelParameters.init(validationData:batchSize:maximumIterations:predictionWindowSize:)(uint64_t *a1, uint64_t a2, char a3, uint64_t a4, char a5, uint64_t a6, char a7)
{
  uint64_t v9 = v7;
  uint64_t v19 = *a1;
  char v21 = *((unsigned char *)a1 + 8);
  uint64_t v11 = (int *)type metadata accessor for MLActivityClassifier.ModelParameters(0);
  uint64_t v20 = v11[6];
  uint64_t v12 = v11[7];
  uint64_t v18 = v11[8];
  uint64_t v13 = v9 + v11[5];
  uint64_t v14 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
  swift_storeEnumTagMultiPayload(v13, v14, 2);
  *(void *)uint64_t v9 = v19;
  *(unsigned char *)(v9 + 8) = v21;
  *(void *)(v9 + v12) = a2;
  *(unsigned char *)(v9 + v12 + 8) = a3 & 1;
  *(void *)(v9 + v20) = a4;
  *(unsigned char *)(v9 + v20 + 8) = a5 & 1;
  *(void *)(v9 + v18) = a6;
  char result = a7 & 1;
  *(unsigned char *)(v9 + v18 + 8) = a7 & 1;
  return result;
}

uint64_t type metadata accessor for MLActivityClassifier.ModelParameters(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLActivityClassifier.ModelParameters, (uint64_t)&nominal type descriptor for MLActivityClassifier.ModelParameters);
}

uint64_t type metadata accessor for MLActivityClassifier.ModelParameters.Validation(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLActivityClassifier.ModelParameters.Validation, (uint64_t)&nominal type descriptor for MLActivityClassifier.ModelParameters.Validation);
}

uint64_t MLActivityClassifier.ModelParameters.init(validation:batchSize:maximumIterations:predictionWindowSize:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, char a5, uint64_t a6, char a7)
{
  uint64_t v9 = v7;
  *(void *)uint64_t v7 = 0;
  *(unsigned char *)(v7 + 8) = -1;
  uint64_t v11 = (int *)type metadata accessor for MLActivityClassifier.ModelParameters(0);
  uint64_t v17 = v11[6];
  uint64_t v12 = v11[7];
  uint64_t v16 = v11[8];
  outlined init with take of MLClassifierMetrics(a1, v9 + v11[5], type metadata accessor for MLActivityClassifier.ModelParameters.Validation);
  *(void *)(v9 + v12) = a2;
  *(unsigned char *)(v9 + v12 + 8) = a3 & 1;
  *(void *)(v9 + v17) = a4;
  *(unsigned char *)(v9 + v17 + 8) = a5 & 1;
  uint64_t result = a6;
  *(void *)(v9 + v16) = a6;
  *(unsigned char *)(v9 + v16 + 8) = a7 & 1;
  return result;
}

uint64_t MLActivityClassifier.ModelParameters.description.getter()
{
  strcpy((char *)v17, "Batch Size: ");
  BYTE5(v17[1]) = 0;
  HIWORD(v17[1]) = -5120;
  uint64_t v22 = (int *)type metadata accessor for MLActivityClassifier.ModelParameters(0);
  uint64_t v1 = v22[7];
  char v2 = *(unsigned char *)(v0 + v1 + 8);
  v19._uint64_t countAndFlagsBits = *(void *)(v0 + v1);
  LOBYTE(v19._object) = v2;
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Int?);
  v3._uint64_t countAndFlagsBits = String.init<A>(describing:)(&v19, v18);
  char object = (char)v3._object;
  String.append(_:)(v3);
  swift_bridgeObjectRelease(object);
  v5._uint64_t countAndFlagsBits = 10;
  v5._char object = (void *)0xE100000000000000;
  String.append(_:)(v5);
  v19._uint64_t countAndFlagsBits = 0;
  v19._char object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(19);
  swift_bridgeObjectRelease(v19._object);
  v19._uint64_t countAndFlagsBits = 0xD000000000000010;
  v19._char object = "ansformer have different types." + 0x8000000000000000;
  uint64_t v6 = v22[6];
  uint64_t v7 = *(void *)(v0 + v6);
  LOBYTE(v6) = *(unsigned char *)(v0 + v6 + 8);
  uint64_t v20 = v7;
  char v21 = v6;
  v8._uint64_t countAndFlagsBits = String.init<A>(describing:)(&v20, v18);
  char v9 = (char)v8._object;
  String.append(_:)(v8);
  swift_bridgeObjectRelease(v9);
  v5._uint64_t countAndFlagsBits = 10;
  v5._char object = (void *)0xE100000000000000;
  String.append(_:)(v5);
  char v10 = (char)v19._object;
  String.append(_:)(v19);
  swift_bridgeObjectRelease(v10);
  v19._uint64_t countAndFlagsBits = 0;
  v19._char object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(22);
  swift_bridgeObjectRelease(v19._object);
  v19._uint64_t countAndFlagsBits = 0xD000000000000013;
  v19._char object = "ported." + 0x8000000000000000;
  uint64_t v11 = v22[8];
  uint64_t v12 = *(void *)(v0 + v11);
  LOBYTE(v11) = *(unsigned char *)(v0 + v11 + 8);
  uint64_t v20 = v12;
  char v21 = v11;
  v13._uint64_t countAndFlagsBits = String.init<A>(describing:)(&v20, v18);
  char v14 = (char)v13._object;
  String.append(_:)(v13);
  swift_bridgeObjectRelease(v14);
  v5._uint64_t countAndFlagsBits = 10;
  v5._char object = (void *)0xE100000000000000;
  String.append(_:)(v5);
  char v15 = (char)v19._object;
  String.append(_:)(v19);
  swift_bridgeObjectRelease(v15);
  return v17[0];
}

uint64_t MLActivityClassifier.ModelParameters.validationData.getter()
{
  uint64_t v2 = *(void *)v1;
  int v3 = *(_DWORD *)(v1 + 8);
  *(void *)uint64_t v0 = *(void *)v1;
  *(unsigned char *)(v0 + 8) = v3;
  return outlined copy of MLDataTable?(v2, v3);
}

uint64_t MLActivityClassifier.ModelParameters.validationData.setter(uint64_t *a1)
{
  uint64_t v2 = *a1;
  char v3 = *((unsigned char *)a1 + 8);
  uint64_t result = outlined consume of MLDataTable?(*(void *)v1, *(_DWORD *)(v1 + 8));
  *(void *)uint64_t v1 = v2;
  *(unsigned char *)(v1 + 8) = v3;
  return result;
}

void (*MLActivityClassifier.ModelParameters.validationData.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLActivityClassifier.ModelParameters.validation.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLActivityClassifier.ModelParameters(0);
  return outlined init with copy of MLActivityClassifier.ModelParameters.Validation(v1 + *(int *)(v3 + 20), v2);
}

uint64_t key path setter for MLActivityClassifier.ModelParameters.validation : MLActivityClassifier.ModelParameters(uint64_t a1)
{
  v6[0] = v1;
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0) - 8)
                 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  outlined init with copy of MLActivityClassifier.ModelParameters.Validation(a1, (uint64_t)v6);
  return MLActivityClassifier.ModelParameters.validation.setter((uint64_t)v6);
}

uint64_t MLActivityClassifier.ModelParameters.validation.setter(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLActivityClassifier.ModelParameters(0);
  return outlined assign with take of MLActivityClassifier.ModelParameters.Validation(a1, v1 + *(int *)(v2 + 20));
}

void (*MLActivityClassifier.ModelParameters.validation.modify(uint64_t a1))(uint64_t a1, char a2)
{
  *(void *)a1 = v1;
  size_t v3 = *(void *)(*(void *)(type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0) - 8)
                 + 64);
  *(void *)(a1 + 8) = malloc(v3);
  uint64_t v4 = malloc(v3);
  *(void *)(a1 + 16) = v4;
  uint64_t v5 = *(int *)(type metadata accessor for MLActivityClassifier.ModelParameters(0) + 20);
  *(_DWORD *)(a1 + 24) = v5;
  outlined init with copy of MLActivityClassifier.ModelParameters.Validation(v1 + v5, (uint64_t)v4);
  return MLActivityClassifier.ModelParameters.validation.modify;
}

void MLActivityClassifier.ModelParameters.validation.modify(uint64_t a1, char a2)
{
  uint64_t v2 = *(void **)(a1 + 8);
  size_t v3 = *(void **)(a1 + 16);
  uint64_t v4 = *(void *)a1 + *(int *)(a1 + 24);
  if (a2)
  {
    outlined init with copy of MLActivityClassifier.ModelParameters.Validation((uint64_t)v3, (uint64_t)v2);
    outlined assign with take of MLActivityClassifier.ModelParameters.Validation((uint64_t)v2, v4);
    outlined destroy of MLActivityClassifier.ModelParameters.Validation((uint64_t)v3, type metadata accessor for MLActivityClassifier.ModelParameters.Validation);
  }
  else
  {
    outlined assign with take of MLActivityClassifier.ModelParameters.Validation((uint64_t)v3, v4);
  }
  free(v3);
  free(v2);
}

uint64_t MLActivityClassifier.ModelParameters.maximumIterations.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLActivityClassifier.ModelParameters(0) + 24));
}

uint64_t MLActivityClassifier.ModelParameters.maximumIterations.setter(uint64_t a1, char a2)
{
  uint64_t result = *(int *)(type metadata accessor for MLActivityClassifier.ModelParameters(0) + 24);
  *(void *)(v2 + result) = a1;
  *(unsigned char *)(v2 + result + 8) = a2 & 1;
  return result;
}

void (*MLActivityClassifier.ModelParameters.maximumIterations.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLActivityClassifier.ModelParameters.batchSize.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLActivityClassifier.ModelParameters(0) + 28));
}

uint64_t MLActivityClassifier.ModelParameters.batchSize.setter(uint64_t a1, char a2)
{
  uint64_t result = *(int *)(type metadata accessor for MLActivityClassifier.ModelParameters(0) + 28);
  *(void *)(v2 + result) = a1;
  *(unsigned char *)(v2 + result + 8) = a2 & 1;
  return result;
}

void (*MLActivityClassifier.ModelParameters.batchSize.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLActivityClassifier.ModelParameters.predictionWindowSize.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLActivityClassifier.ModelParameters(0) + 32));
}

uint64_t MLActivityClassifier.ModelParameters.predictionWindowSize.setter(uint64_t a1, char a2)
{
  uint64_t result = *(int *)(type metadata accessor for MLActivityClassifier.ModelParameters(0) + 32);
  *(void *)(v2 + result) = a1;
  *(unsigned char *)(v2 + result + 8) = a2 & 1;
  return result;
}

void (*MLActivityClassifier.ModelParameters.predictionWindowSize.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

char MLActivityClassifier.ModelParameters.init(validationData:batchSize:maximumIterations:predictionWindowSize:)(uint64_t a1, uint64_t a2, char a3, uint64_t a4, char a5, uint64_t a6, char a7)
{
  uint64_t v9 = v7;
  *(void *)uint64_t v7 = 0;
  *(unsigned char *)(v7 + 8) = -1;
  uint64_t v11 = (int *)type metadata accessor for MLActivityClassifier.ModelParameters(0);
  uint64_t v19 = v11[6];
  uint64_t v12 = v11[7];
  uint64_t v18 = v11[8];
  uint64_t v13 = v9 + v11[5];
  outlined init with take of MLClassifierMetrics(a1, v13, type metadata accessor for MLActivityClassifier.DataSource);
  uint64_t v14 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
  swift_storeEnumTagMultiPayload(v13, v14, 1);
  *(void *)(v9 + v12) = a2;
  *(unsigned char *)(v9 + v12 + 8) = a3 & 1;
  *(void *)(v9 + v19) = a4;
  *(unsigned char *)(v9 + v19 + 8) = a5 & 1;
  *(void *)(v9 + v18) = a6;
  char result = a7 & 1;
  *(unsigned char *)(v9 + v18 + 8) = a7 & 1;
  return result;
}

uint64_t MLActivityClassifier.ModelParameters.generateTables(trainingData:featureColumns:labelColumn:recordingFileColumn:)(uint64_t *a1, uint64_t *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t *a6, __m128 a7, void *a8, void *a9)
{
  uint64_t v56 = v9;
  uint64_t v54 = a6;
  uint64_t v55 = a5;
  uint64_t v47 = a4;
  uint64_t v48 = a2;
  uint64_t v49 = a1;
  uint64_t v12 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
  int64_t v13 = *(void *)(*(void *)(v12 - 8) + 64);
  uint64_t v14 = alloca(v13);
  char v15 = alloca(v13);
  uint64_t v50 = *(void *)a3;
  char v57 = *(unsigned char *)(a3 + 8);
  unsigned __int8 v16 = *(unsigned char *)(v10 + 8);
  if (v16 == 0xFF) {
    goto LABEL_7;
  }
  uint64_t v53 = *(void *)v10;
  uint64_t v17 = type metadata accessor for MLActivityClassifier.ModelParameters(0);
  outlined init with copy of MLActivityClassifier.ModelParameters.Validation(v10 + *(int *)(v17 + 20), (uint64_t)&v44);
  if (swift_getEnumCaseMultiPayload(&v44, v12) != 2)
  {
    outlined destroy of MLActivityClassifier.ModelParameters.Validation((uint64_t)&v44, type metadata accessor for MLActivityClassifier.ModelParameters.Validation);
LABEL_7:
    type metadata accessor for MLActivityClassifier.ModelParameters(0);
    uint64_t v51 = v50;
    LOBYTE(v52) = v57 & 1;
    MLActivityClassifier.ModelParameters.Validation.generateTables(trainingData:featureColumns:labelColumn:recordingFileColumn:)(v49, v48, (uint64_t)&v51, v47, v55, v54, a8, a9);
    return v43;
  }
  uint64_t v18 = v53;
  outlined copy of Result<_DataTable, Error>(v53, v16);
  outlined destroy of MLActivityClassifier.ModelParameters.Validation((uint64_t)&v44, type metadata accessor for MLActivityClassifier.ModelParameters.Validation);
  uint64_t v45 = v18;
  LOBYTE(v46) = v16 & 1;
  uint64_t v19 = v56;
  validateAndConvertRawDataToInternalData(_:featureColumns:labelColumn:recordingFileColumn:)((uint64_t)&v45, v47, v55, (uint64_t)v54, (uint64_t)a8, a9, a7);
  if (v19)
  {
    uint64_t v20 = v18;
    char v21 = v16;
    return outlined consume of MLDataTable?(v20, v21);
  }
  LODWORD(v54) = v16;
  uint64_t v23 = v51;
  LOBYTE(v56) = v52;
  if ((_BYTE)v52)
  {
    outlined copy of Result<_DataTable, Error>(v51, 1);
    uint64_t v24 = tc_v1_flex_list_create(0);
    if (!v24) {
      BUG();
    }
    uint64_t v25 = v24;
    outlined consume of Result<_DataTable, Error>(v23, 1);
    uint64_t v26 = type metadata accessor for CMLSequence();
    uint64_t v27 = swift_allocObject(v26, 25, 7);
    *(void *)(v27 + 16) = v25;
    *(unsigned char *)(v27 + 24) = 1;
  }
  else
  {
    outlined copy of Result<_DataTable, Error>(v51, 0);
    _DataTable.columnNames.getter();
    outlined consume of Result<_DataTable, Error>(v23, 0);
    uint64_t v27 = v51;
  }
  swift_retain();
  uint64_t v28 = CMLSequence.size.getter();
  uint64_t v29 = specialized RandomAccessCollection<>.distance(from:to:)(0, v28);
  swift_release_n(v27, 2);
  uint64_t v55 = v23;
  if (v29)
  {
    if ((_BYTE)v56)
    {
      outlined copy of Result<_DataTable, Error>(v23, 1);
      uint64_t v30 = tc_v1_flex_list_create(0);
      if (!v30) {
        BUG();
      }
      uint64_t v31 = v30;
      uint64_t v32 = type metadata accessor for CMLSequence();
      uint64_t v33 = swift_allocObject(v32, 25, 7);
      *(void *)(v33 + 16) = v31;
      *(unsigned char *)(v33 + 24) = 1;
      outlined consume of Result<_DataTable, Error>(v23, 1);
    }
    else
    {
      outlined copy of Result<_DataTable, Error>(v23, 0);
      _DataTable.columnNames.getter();
      outlined consume of Result<_DataTable, Error>(v23, 0);
      uint64_t v33 = v45;
    }
    uint64_t v51 = 0x6C6562616CLL;
    unint64_t v52 = 0xE500000000000000;
    uint64_t v34 = alloca(24);
    uint64_t v35 = alloca(32);
    uint64_t v46 = &v51;
    char v36 = specialized Sequence.contains(where:)((uint64_t (*)(unint64_t *))partial apply for specialized closure #1 in Sequence<>.contains(_:), (uint64_t)&v44, v33);
    swift_release();
    if ((v36 & 1) == 0)
    {
      uint64_t v51 = 0;
      unint64_t v52 = 0xE000000000000000;
      _StringGuts.grow(_:)(45);
      swift_bridgeObjectRelease(v52);
      uint64_t v41 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v41, 0, 0);
      *(void *)uint64_t v42 = 0xD000000000000030;
      *(void *)(v42 + 8) = "Prediction Window: " + 0x8000000000000000;
      *(_OWORD *)(v42 + 16) = 0;
      *(_OWORD *)(v42 + 32) = 0;
      *(unsigned char *)(v42 + 48) = 1;
      swift_willThrow();
      outlined consume of Result<_DataTable, Error>(v55, v56);
      uint64_t v20 = v53;
      char v21 = (char)v54;
      return outlined consume of MLDataTable?(v20, v21);
    }
  }
  uint64_t v37 = v48;
  unint64_t v38 = v49;
  uint64_t v39 = v50;
  outlined consume of MLDataTable?(v53, (char)v54);
  uint64_t *v38 = v39;
  char v40 = v57;
  *((unsigned char *)v38 + 8) = v57 & 1;
  *uint64_t v37 = v55;
  *((unsigned char *)v37 + 8) = v56;
  return outlined copy of Result<_DataTable, Error>(v39, v40);
}

uint64_t MLActivityClassifier.ModelParameters.Validation.generateTables(trainingData:featureColumns:labelColumn:recordingFileColumn:)(uint64_t *a1, uint64_t *a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t *a6, void *a7, void *a8)
{
  uint64_t v51 = v8;
  uint64_t v47 = a6;
  uint64_t v48 = a5;
  uint64_t v49 = a4;
  unint64_t v52 = a2;
  uint64_t v53 = a1;
  int64_t v11 = *(void *)(*(void *)(type metadata accessor for MLActivityClassifier.DataSource.Columns(0) - 8) + 64);
  uint64_t v12 = alloca(v11);
  int64_t v13 = alloca(v11);
  uint64_t v50 = &v39;
  int64_t v14 = *(void *)(*(void *)(type metadata accessor for MLActivityClassifier.DataSource(0) - 8) + 64);
  char v15 = alloca(v14);
  unsigned __int8 v16 = alloca(v14);
  uint64_t v46 = &v39;
  uint64_t v17 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
  int64_t v18 = *(void *)(*(void *)(v17 - 8) + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v54 = *(void *)a3;
  char v21 = *(unsigned char *)(a3 + 8);
  outlined init with copy of MLActivityClassifier.ModelParameters.Validation(v9, (uint64_t)&v39);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v39, v17);
  if (EnumCaseMultiPayload)
  {
    if (EnumCaseMultiPayload == 1)
    {
      uint64_t v23 = (uint64_t)v46;
      outlined init with take of MLClassifierMetrics((uint64_t)&v39, (uint64_t)v46, type metadata accessor for MLActivityClassifier.DataSource);
      uint64_t v24 = v51;
      MLActivityClassifier.DataSource.gatherData(featureColumns:labelColumn:recordingFileColumn:)(v49, v48, v47, a7, a8);
      if (v24)
      {
        return outlined destroy of MLActivityClassifier.ModelParameters.Validation(v23, type metadata accessor for MLActivityClassifier.DataSource);
      }
      else
      {
        uint64_t v25 = (uint64_t)v50;
        MLActivityClassifier.DataSource.Columns.convertToTuriCore()();
        outlined destroy of MLActivityClassifier.ModelParameters.Validation(v25, type metadata accessor for MLActivityClassifier.DataSource.Columns);
        outlined destroy of MLActivityClassifier.ModelParameters.Validation(v23, type metadata accessor for MLActivityClassifier.DataSource);
        uint64_t v33 = v44;
        char v34 = BYTE8(v44);
        uint64_t v35 = v53;
        uint64_t v36 = v54;
        *uint64_t v53 = v54;
        *((unsigned char *)v35 + 8) = v21 & 1;
        uint64_t v37 = v52;
        *unint64_t v52 = v33;
        *((unsigned char *)v37 + 8) = v34;
        return outlined copy of Result<_DataTable, Error>(v36, v21);
      }
    }
    else
    {
      uint64_t v30 = v53;
      uint64_t v31 = v54;
      *uint64_t v53 = v54;
      *((unsigned char *)v30 + 8) = v21 & 1;
      uint64_t v32 = v52;
      *unint64_t v52 = 0;
      *((unsigned char *)v32 + 8) = -1;
      return outlined copy of Result<_DataTable, Error>(v31, v21);
    }
  }
  else
  {
    uint64_t v42 = v54;
    char v43 = v21 & 1;
    long long v44 = v39;
    __int16 v45 = v40;
    MLDataTable.randomSplit(strategy:)((uint64_t *)&v39, &v40, (uint64_t)&v44);
    uint64_t result = v39;
    char v26 = BYTE8(v39);
    char v27 = v41;
    uint64_t v28 = v53;
    *uint64_t v53 = v40;
    *((unsigned char *)v28 + 8) = v27;
    uint64_t v29 = v52;
    *unint64_t v52 = result;
    *((unsigned char *)v29 + 8) = v26;
  }
  return result;
}

uint64_t MLActivityClassifier.ModelParameters.debugDescription.getter()
{
  return MLActivityClassifier.ModelParameters.description.getter();
}

uint64_t MLActivityClassifier.ModelParameters.playgroundDescription.getter(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t result = MLActivityClassifier.ModelParameters.description.getter(a1);
  v2[3] = (uint64_t)&type metadata for String;
  *uint64_t v2 = result;
  v2[1] = v4;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLActivityClassifier.ModelParameters()
{
  return MLActivityClassifier.ModelParameters.description.getter();
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLActivityClassifier.ModelParameters()
{
  return MLActivityClassifier.ModelParameters.debugDescription.getter();
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLActivityClassifier.ModelParameters(uint64_t a1)
{
  return MLActivityClassifier.ModelParameters.playgroundDescription.getter(a1);
}

uint64_t outlined init with copy of MLActivityClassifier.ModelParameters.Validation(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined assign with take of MLActivityClassifier.ModelParameters.Validation(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 40))(a2, a1, v2);
  return a2;
}

uint64_t sub_10ACEB(uint64_t a1)
{
  return MLActivityClassifier.ModelParameters.validation.getter(a1);
}

uint64_t sub_10AD02(uint64_t a1)
{
  return key path setter for MLActivityClassifier.ModelParameters.validation : MLActivityClassifier.ModelParameters(a1);
}

void *initializeBufferWithCopyOfBuffer for MLActivityClassifier.ModelParameters(uint64_t a1, uint64_t *a2, int *a3)
{
  size_t v3 = (void *)a1;
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v4 & 0x20000) == 0)
  {
    char v6 = *((unsigned char *)a2 + 8);
    if (v6 == -1)
    {
      *(unsigned char *)(a1 + 8) = *((unsigned char *)a2 + 8);
      *(void *)a1 = *a2;
    }
    else
    {
      uint64_t v7 = *a2;
      outlined copy of Result<_DataTable, Error>(*a2, v6);
      *(void *)a1 = v7;
      *(unsigned char *)(a1 + 8) = v6 & 1;
    }
    uint64_t v35 = a3;
    uint64_t v9 = a3[5];
    uint64_t v10 = (char *)(a1 + v9);
    int64_t v11 = (char *)a2 + v9;
    uint64_t v12 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
    if (swift_getEnumCaseMultiPayload(v11, v12) != 1)
    {
      memcpy(v10, v11, *(void *)(*(void *)(v12 - 8) + 64));
      uint64_t v24 = v35;
LABEL_15:
      uint64_t v27 = v24[6];
      *((unsigned char *)v3 + v27 + 8) = *((unsigned char *)a2 + v27 + 8);
      *(void *)((char *)v3 + v27) = *(uint64_t *)((char *)a2 + v27);
      uint64_t v28 = v24[7];
      *(void *)((char *)v3 + v28) = *(uint64_t *)((char *)a2 + v28);
      *((unsigned char *)v3 + v28 + 8) = *((unsigned char *)a2 + v28 + 8);
      uint64_t v29 = v24[8];
      *(void *)((char *)v3 + v29) = *(uint64_t *)((char *)a2 + v29);
      *((unsigned char *)v3 + v29 + 8) = *((unsigned char *)a2 + v29 + 8);
      return v3;
    }
    uint64_t v31 = v12;
    uint64_t v32 = type metadata accessor for MLActivityClassifier.DataSource(0);
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v11, v32);
    unsigned int v34 = EnumCaseMultiPayload;
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v25 = type metadata accessor for DataFrame(0);
      int64_t v14 = v10;
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v25 - 8) + 16))(v10, v11, v25);
    }
    else
    {
      int64_t v14 = v10;
      if (EnumCaseMultiPayload != 1)
      {
        uint64_t v24 = v35;
        uint64_t v26 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v26 - 8) + 16))(v14, v11, v26);
        goto LABEL_14;
      }
      uint64_t v15 = type metadata accessor for URL(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 16))(v10, v11, v15);
      unsigned __int8 v16 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
      uint64_t v17 = v16[12];
      *(void *)&v10[v17] = *(void *)&v11[v17];
      uint64_t v18 = *(void *)&v11[v17 + 8];
      *(void *)&v10[v17 + 8] = v18;
      uint64_t v19 = v16[16];
      *(void *)&v10[v19] = *(void *)&v11[v19];
      uint64_t v20 = *(void *)&v11[v19 + 8];
      *(void *)&v14[v19 + 8] = v20;
      uint64_t v21 = v16[20];
      *(void *)&v14[v21] = *(void *)&v11[v21];
      uint64_t v33 = *(void *)&v11[v21 + 8];
      *(void *)&v14[v21 + 8] = v33;
      uint64_t v22 = v16[24];
      *(void *)&v14[v22] = *(void *)&v11[v22];
      uint64_t v23 = *(void *)&v11[v22 + 8];
      *(void *)&v14[v22 + 8] = v23;
      swift_bridgeObjectRetain(v18);
      swift_bridgeObjectRetain(v20);
      swift_bridgeObjectRetain(v33);
      swift_bridgeObjectRetain(v23);
    }
    uint64_t v24 = v35;
LABEL_14:
    swift_storeEnumTagMultiPayload(v14, v32, v34);
    swift_storeEnumTagMultiPayload(v14, v31, 1);
    goto LABEL_15;
  }
  uint64_t v8 = *a2;
  *size_t v3 = *a2;
  size_t v3 = (void *)(v8 + ((v4 + 16) & ~v4));
  swift_retain();
  return v3;
}

uint64_t destroy for MLActivityClassifier.ModelParameters(uint64_t a1, uint64_t a2)
{
  char v2 = *(unsigned char *)(a1 + 8);
  if (v2 != -1) {
    outlined consume of Result<_DataTable, Error>(*(void *)a1, v2 & 1);
  }
  uint64_t v3 = *(int *)(a2 + 20) + a1;
  uint64_t v4 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
  uint64_t result = swift_getEnumCaseMultiPayload(v3, v4);
  if (result == 1)
  {
    uint64_t v6 = type metadata accessor for MLActivityClassifier.DataSource(0);
    uint64_t result = swift_getEnumCaseMultiPayload(v3, v6);
    switch(result)
    {
      case 2:
        uint64_t v7 = type metadata accessor for DataFrame(0);
        return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v7 - 8) + 8))(v3, v7);
      case 1:
        uint64_t v8 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v8 - 8) + 8))(v3, v8);
        uint64_t v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
        swift_bridgeObjectRelease(*(void *)(v3 + v9[12] + 8));
        swift_bridgeObjectRelease(*(void *)(v3 + v9[16] + 8));
        swift_bridgeObjectRelease(*(void *)(v3 + v9[20] + 8));
        return swift_bridgeObjectRelease(*(void *)(v3 + v9[24] + 8));
      case 0:
        uint64_t v7 = type metadata accessor for URL(0);
        return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v7 - 8) + 8))(v3, v7);
    }
  }
  return result;
}

uint64_t initializeWithCopy for MLActivityClassifier.ModelParameters(uint64_t a1, uint64_t *a2, int *a3)
{
  char v5 = *((unsigned char *)a2 + 8);
  if (v5 == -1)
  {
    *(unsigned char *)(a1 + 8) = *((unsigned char *)a2 + 8);
    *(void *)a1 = *a2;
  }
  else
  {
    uint64_t v6 = *a2;
    outlined copy of Result<_DataTable, Error>(*a2, v5);
    *(void *)a1 = v6;
    *(unsigned char *)(a1 + 8) = v5 & 1;
  }
  uint64_t v32 = a3;
  uint64_t v7 = a3[5];
  uint64_t v8 = (char *)(a1 + v7);
  uint64_t v9 = (char *)a2 + v7;
  uint64_t v10 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
  if (swift_getEnumCaseMultiPayload(v9, v10) == 1)
  {
    uint64_t v27 = v10;
    uint64_t v28 = type metadata accessor for MLActivityClassifier.DataSource(0);
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v9, v28);
    unsigned int v31 = EnumCaseMultiPayload;
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v21 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v21 - 8) + 16))(v8, v9, v21);
      uint64_t v12 = v32;
    }
    else
    {
      uint64_t v12 = v32;
      if (EnumCaseMultiPayload == 1)
      {
        uint64_t v13 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v13 - 8) + 16))(v8, v9, v13);
        int64_t v14 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
        uint64_t v15 = v14[12];
        *(void *)&v8[v15] = *(void *)&v9[v15];
        uint64_t v16 = *(void *)&v9[v15 + 8];
        *(void *)&v8[v15 + 8] = v16;
        uint64_t v17 = v14[16];
        *(void *)&v8[v17] = *(void *)&v9[v17];
        uint64_t v29 = *(void *)&v9[v17 + 8];
        *(void *)&v8[v17 + 8] = v29;
        uint64_t v18 = v14[20];
        *(void *)&v8[v18] = *(void *)&v9[v18];
        uint64_t v30 = *(void *)&v9[v18 + 8];
        *(void *)&v8[v18 + 8] = v30;
        uint64_t v19 = v14[24];
        *(void *)&v8[v19] = *(void *)&v9[v19];
        uint64_t v20 = *(void *)&v9[v19 + 8];
        *(void *)&v8[v19 + 8] = v20;
        swift_bridgeObjectRetain(v16);
        swift_bridgeObjectRetain(v29);
        swift_bridgeObjectRetain(v30);
        swift_bridgeObjectRetain(v20);
      }
      else
      {
        uint64_t v22 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v22 - 8) + 16))(v8, v9, v22);
      }
    }
    swift_storeEnumTagMultiPayload(v8, v28, v31);
    swift_storeEnumTagMultiPayload(v8, v27, 1);
  }
  else
  {
    memcpy(v8, v9, *(void *)(*(void *)(v10 - 8) + 64));
    uint64_t v12 = v32;
  }
  uint64_t v23 = v12[6];
  *(unsigned char *)(a1 + v23 + 8) = *((unsigned char *)a2 + v23 + 8);
  *(void *)(a1 + v23) = *(uint64_t *)((char *)a2 + v23);
  uint64_t v24 = v12[7];
  *(void *)(a1 + v24) = *(uint64_t *)((char *)a2 + v24);
  *(unsigned char *)(a1 + v24 + 8) = *((unsigned char *)a2 + v24 + 8);
  uint64_t v25 = v12[8];
  *(void *)(a1 + v25) = *(uint64_t *)((char *)a2 + v25);
  *(unsigned char *)(a1 + v25 + 8) = *((unsigned char *)a2 + v25 + 8);
  return a1;
}

uint64_t assignWithCopy for MLActivityClassifier.ModelParameters(uint64_t a1, uint64_t *a2, int *a3)
{
  char v6 = *((unsigned char *)a2 + 8);
  if (*(unsigned char *)(a1 + 8) == 0xFF)
  {
    if (v6 == -1)
    {
      *(unsigned char *)(a1 + 8) = *((unsigned char *)a2 + 8);
      *(void *)a1 = *a2;
    }
    else
    {
      uint64_t v10 = *a2;
      outlined copy of Result<_DataTable, Error>(*a2, v6);
      *(void *)a1 = v10;
      *(unsigned char *)(a1 + 8) = v6 & 1;
    }
  }
  else if (v6 == -1)
  {
    outlined destroy of MLDataTable(a1);
    *(void *)a1 = *a2;
    *(unsigned char *)(a1 + 8) = *((unsigned char *)a2 + 8);
  }
  else
  {
    uint64_t v7 = *a2;
    outlined copy of Result<_DataTable, Error>(*a2, v6);
    uint64_t v8 = *(void *)a1;
    *(void *)a1 = v7;
    int v9 = *(_DWORD *)(a1 + 8);
    *(unsigned char *)(a1 + 8) = v6 & 1;
    outlined consume of Result<_DataTable, Error>(v8, v9);
  }
  if ((uint64_t *)a1 != a2)
  {
    uint64_t v35 = a3;
    uint64_t v11 = a3[5];
    uint64_t v12 = (char *)(a1 + v11);
    uint64_t v13 = (char *)a2 + v11;
    outlined destroy of MLActivityClassifier.ModelParameters.Validation((uint64_t)v12, type metadata accessor for MLActivityClassifier.ModelParameters.Validation);
    uint64_t v14 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
    if (swift_getEnumCaseMultiPayload(v13, v14) == 1)
    {
      uint64_t v30 = v14;
      uint64_t v31 = type metadata accessor for MLActivityClassifier.DataSource(0);
      unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v13, v31);
      unsigned int v34 = EnumCaseMultiPayload;
      if (EnumCaseMultiPayload == 2)
      {
        uint64_t v24 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v24 - 8) + 16))(v12, v13, v24);
        a3 = v35;
      }
      else
      {
        a3 = v35;
        if (EnumCaseMultiPayload == 1)
        {
          uint64_t v16 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(v12, v13, v16);
          uint64_t v17 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
          uint64_t v18 = v17[12];
          *(void *)&v12[v18] = *(void *)&v13[v18];
          uint64_t v19 = *(void *)&v13[v18 + 8];
          *(void *)&v12[v18 + 8] = v19;
          uint64_t v20 = v17[16];
          *(void *)&v12[v20] = *(void *)&v13[v20];
          uint64_t v32 = *(void *)&v13[v20 + 8];
          *(void *)&v12[v20 + 8] = v32;
          uint64_t v21 = v17[20];
          *(void *)&v12[v21] = *(void *)&v13[v21];
          uint64_t v33 = *(void *)&v13[v21 + 8];
          *(void *)&v12[v21 + 8] = v33;
          uint64_t v22 = v17[24];
          *(void *)&v12[v22] = *(void *)&v13[v22];
          uint64_t v23 = *(void *)&v13[v22 + 8];
          *(void *)&v12[v22 + 8] = v23;
          swift_bridgeObjectRetain(v19);
          swift_bridgeObjectRetain(v32);
          swift_bridgeObjectRetain(v33);
          swift_bridgeObjectRetain(v23);
        }
        else
        {
          uint64_t v25 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v25 - 8) + 16))(v12, v13, v25);
        }
      }
      swift_storeEnumTagMultiPayload(v12, v31, v34);
      swift_storeEnumTagMultiPayload(v12, v30, 1);
    }
    else
    {
      memcpy(v12, v13, *(void *)(*(void *)(v14 - 8) + 64));
      a3 = v35;
    }
  }
  uint64_t v26 = a3[6];
  *(unsigned char *)(a1 + v26 + 8) = *((unsigned char *)a2 + v26 + 8);
  *(void *)(a1 + v26) = *(uint64_t *)((char *)a2 + v26);
  uint64_t v27 = a3[7];
  *(void *)(a1 + v27) = *(uint64_t *)((char *)a2 + v27);
  *(unsigned char *)(a1 + v27 + 8) = *((unsigned char *)a2 + v27 + 8);
  uint64_t v28 = a3[8];
  *(void *)(a1 + v28) = *(uint64_t *)((char *)a2 + v28);
  *(unsigned char *)(a1 + v28 + 8) = *((unsigned char *)a2 + v28 + 8);
  return a1;
}

uint64_t initializeWithTake for MLActivityClassifier.ModelParameters(uint64_t a1, uint64_t a2, int *a3)
{
  *(unsigned char *)(a1 + 8) = *(unsigned char *)(a2 + 8);
  *(void *)a1 = *(void *)a2;
  uint64_t v3 = a3[5];
  uint64_t v4 = (char *)(a1 + v3);
  char v5 = (char *)(a2 + v3);
  uint64_t v6 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
  if (swift_getEnumCaseMultiPayload(v5, v6) == 1)
  {
    uint64_t v16 = type metadata accessor for MLActivityClassifier.DataSource(0);
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v5, v16);
    unsigned int v17 = EnumCaseMultiPayload;
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v10 = type metadata accessor for DataFrame(0);
    }
    else
    {
      if (EnumCaseMultiPayload == 1)
      {
        uint64_t v8 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(v4, v5, v8);
        int v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
        *(_OWORD *)&v4[v9[12]] = *(_OWORD *)&v5[v9[12]];
        *(_OWORD *)&v4[v9[16]] = *(_OWORD *)&v5[v9[16]];
        *(_OWORD *)&v4[v9[20]] = *(_OWORD *)&v5[v9[20]];
        *(_OWORD *)&v4[v9[24]] = *(_OWORD *)&v5[v9[24]];
LABEL_9:
        swift_storeEnumTagMultiPayload(v4, v16, v17);
        swift_storeEnumTagMultiPayload(v4, v6, 1);
        goto LABEL_10;
      }
      uint64_t v10 = type metadata accessor for URL(0);
    }
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(v4, v5, v10);
    goto LABEL_9;
  }
  memcpy(v4, v5, *(void *)(*(void *)(v6 - 8) + 64));
LABEL_10:
  uint64_t v11 = a3[6];
  *(unsigned char *)(a1 + v11 + 8) = *(unsigned char *)(a2 + v11 + 8);
  *(void *)(a1 + v11) = *(void *)(a2 + v11);
  uint64_t v12 = a3[7];
  *(void *)(a1 + v12) = *(void *)(a2 + v12);
  *(unsigned char *)(a1 + v12 + 8) = *(unsigned char *)(a2 + v12 + 8);
  uint64_t v13 = a3[8];
  *(void *)(a1 + v13) = *(void *)(a2 + v13);
  *(unsigned char *)(a1 + v13 + 8) = *(unsigned char *)(a2 + v13 + 8);
  return a1;
}

uint64_t assignWithTake for MLActivityClassifier.ModelParameters(uint64_t a1, uint64_t a2, int *a3)
{
  char v5 = *(unsigned char *)(a1 + 8);
  if (v5 == -1)
  {
    *(unsigned char *)(a1 + 8) = *(unsigned char *)(a2 + 8);
    *(void *)a1 = *(void *)a2;
  }
  else
  {
    char v6 = *(unsigned char *)(a2 + 8);
    if (v6 == -1)
    {
      outlined destroy of MLDataTable(a1);
      *(void *)a1 = *(void *)a2;
      *(unsigned char *)(a1 + 8) = *(unsigned char *)(a2 + 8);
    }
    else
    {
      uint64_t v7 = *(void *)a1;
      *(void *)a1 = *(void *)a2;
      *(unsigned char *)(a1 + 8) = v6 & 1;
      outlined consume of Result<_DataTable, Error>(v7, v5 & 1);
    }
  }
  if (a1 != a2)
  {
    uint64_t v25 = a3;
    uint64_t v8 = a3[5];
    int v9 = (char *)(a1 + v8);
    uint64_t v10 = (char *)(a2 + v8);
    outlined destroy of MLActivityClassifier.ModelParameters.Validation((uint64_t)v9, type metadata accessor for MLActivityClassifier.ModelParameters.Validation);
    uint64_t v11 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
    if (swift_getEnumCaseMultiPayload(v10, v11) == 1)
    {
      uint64_t v22 = v11;
      uint64_t v23 = type metadata accessor for MLActivityClassifier.DataSource(0);
      unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v10, v23);
      unsigned int v24 = EnumCaseMultiPayload;
      if (EnumCaseMultiPayload == 2)
      {
        uint64_t v16 = type metadata accessor for DataFrame(0);
        uint64_t v13 = v9;
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 32))(v9, v10, v16);
      }
      else
      {
        uint64_t v13 = v9;
        if (EnumCaseMultiPayload != 1)
        {
          a3 = v25;
          uint64_t v17 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 32))(v13, v10, v17);
          goto LABEL_15;
        }
        uint64_t v14 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 32))(v9, v10, v14);
        uint64_t v15 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
        *(_OWORD *)&v9[v15[12]] = *(_OWORD *)&v10[v15[12]];
        *(_OWORD *)&v9[v15[16]] = *(_OWORD *)&v10[v15[16]];
        *(_OWORD *)&v9[v15[20]] = *(_OWORD *)&v10[v15[20]];
        *(_OWORD *)&v9[v15[24]] = *(_OWORD *)&v10[v15[24]];
      }
      a3 = v25;
LABEL_15:
      swift_storeEnumTagMultiPayload(v13, v23, v24);
      swift_storeEnumTagMultiPayload(v13, v22, 1);
      goto LABEL_16;
    }
    memcpy(v9, v10, *(void *)(*(void *)(v11 - 8) + 64));
    a3 = v25;
  }
LABEL_16:
  uint64_t v18 = a3[6];
  *(unsigned char *)(a1 + v18 + 8) = *(unsigned char *)(a2 + v18 + 8);
  *(void *)(a1 + v18) = *(void *)(a2 + v18);
  uint64_t v19 = a3[7];
  *(void *)(a1 + v19) = *(void *)(a2 + v19);
  *(unsigned char *)(a1 + v19 + 8) = *(unsigned char *)(a2 + v19 + 8);
  uint64_t v20 = a3[8];
  *(void *)(a1 + v20) = *(void *)(a2 + v20);
  *(unsigned char *)(a1 + v20 + 8) = *(unsigned char *)(a2 + v20 + 8);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLActivityClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_10B84A);
}

uint64_t sub_10B84A(uint64_t a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 253)
  {
    unsigned __int8 v3 = *(unsigned char *)(a1 + 8);
    BOOL v4 = v3 < 2u;
    LOBYTE(result) = ~v3;
    if (v4) {
      LOBYTE(result) = 0;
    }
    return result;
  }
  else
  {
    uint64_t v7 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
    return __swift_getEnumTagSinglePayload(*(int *)(a3 + 20) + a1, a2, v7);
  }
}

uint64_t storeEnumTagSinglePayload for MLActivityClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_10B8C7);
}

uint64_t sub_10B8C7(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 253)
  {
    *(unsigned char *)(a1 + 8) = ~(_BYTE)a2;
  }
  else
  {
    uint64_t v5 = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(0);
    return __swift_storeEnumTagSinglePayload(*(int *)(a4 + 20) + a1, a2, a2, v5);
  }
  return result;
}

uint64_t type metadata completion function for MLActivityClassifier.ModelParameters(uint64_t a1)
{
  v3[0] = "\t";
  uint64_t result = type metadata accessor for MLActivityClassifier.ModelParameters.Validation(319);
  if (v2 <= 0x3F)
  {
    v3[1] = *(void *)(result - 8) + 64;
    v3[2] = &unk_34A7B8;
    void v3[3] = &unk_34A7B8;
    void v3[4] = &unk_34A7B8;
    swift_initStructMetadata(a1, 256, 5, v3, a1 + 16);
    return 0;
  }
  return result;
}

void *initializeBufferWithCopyOfBuffer for MLActivityClassifier.ModelParameters.Validation(char *__dst, char *__src, uint64_t a3)
{
  unsigned __int8 v3 = __dst;
  uint64_t v4 = *(void *)(a3 - 8);
  int v5 = *(_DWORD *)(v4 + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v18 = *(void *)__src;
    *unsigned __int8 v3 = *(void *)__src;
    unsigned __int8 v3 = (void *)(v18 + ((v5 + 16) & ~v5));
    swift_retain();
  }
  else
  {
    if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
    {
      uint64_t v7 = type metadata accessor for MLActivityClassifier.DataSource(0);
      unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v7);
      if (EnumCaseMultiPayload == 2)
      {
        uint64_t v19 = type metadata accessor for DataFrame(0);
      }
      else
      {
        if (EnumCaseMultiPayload == 1)
        {
          uint64_t v9 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))(__dst, __src, v9);
          uint64_t v10 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
          uint64_t v11 = v10[12];
          *(void *)&__dst[v11] = *(void *)&__src[v11];
          uint64_t v12 = *(void *)&__src[v11 + 8];
          *(void *)((char *)v3 + v11 + 8) = v12;
          uint64_t v13 = v10[16];
          *(void *)((char *)v3 + v13) = *(void *)&__src[v13];
          uint64_t v22 = *(void *)&__src[v13 + 8];
          *(void *)((char *)v3 + v13 + 8) = v22;
          uint64_t v14 = v10[20];
          *(void *)((char *)v3 + v14) = *(void *)&__src[v14];
          uint64_t v21 = v7;
          uint64_t v15 = *(void *)&__src[v14 + 8];
          *(void *)((char *)v3 + v14 + 8) = v15;
          uint64_t v16 = v10[24];
          *(void *)((char *)v3 + v16) = *(void *)&__src[v16];
          uint64_t v17 = *(void *)&__src[v16 + 8];
          *(void *)((char *)v3 + v16 + 8) = v17;
          swift_bridgeObjectRetain(v12);
          swift_bridgeObjectRetain(v22);
          LOBYTE(v12) = v15;
          uint64_t v7 = v21;
          swift_bridgeObjectRetain(v12);
          swift_bridgeObjectRetain(v17);
LABEL_11:
          swift_storeEnumTagMultiPayload(v3, v7, EnumCaseMultiPayload);
          swift_storeEnumTagMultiPayload(v3, a3, 1);
          return v3;
        }
        uint64_t v19 = type metadata accessor for URL(0);
      }
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16))(__dst, __src, v19);
      goto LABEL_11;
    }
    memcpy(__dst, __src, *(void *)(v4 + 64));
  }
  return v3;
}

uint64_t destroy for MLActivityClassifier.ModelParameters.Validation(uint64_t a1, uint64_t a2)
{
  uint64_t result = swift_getEnumCaseMultiPayload(a1, a2);
  if (result == 1)
  {
    uint64_t v3 = type metadata accessor for MLActivityClassifier.DataSource(0);
    uint64_t result = swift_getEnumCaseMultiPayload(a1, v3);
    switch(result)
    {
      case 2:
        uint64_t v4 = type metadata accessor for DataFrame(0);
        return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
      case 1:
        uint64_t v5 = type metadata accessor for URL(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8))(a1, v5);
        char v6 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
        swift_bridgeObjectRelease(*(void *)(a1 + v6[12] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v6[16] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v6[20] + 8));
        return swift_bridgeObjectRelease(*(void *)(a1 + v6[24] + 8));
      case 0:
        uint64_t v4 = type metadata accessor for URL(0);
        return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
    }
  }
  return result;
}

char *initializeWithCopy for MLActivityClassifier.ModelParameters.Validation(char *__dst, char *__src, uint64_t a3)
{
  if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
  {
    uint64_t v5 = type metadata accessor for MLActivityClassifier.DataSource(0);
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v5);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v16 = type metadata accessor for DataFrame(0);
    }
    else
    {
      if (EnumCaseMultiPayload == 1)
      {
        uint64_t v7 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
        uint64_t v8 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
        uint64_t v9 = v8[12];
        *(void *)&__dst[v9] = *(void *)&__src[v9];
        uint64_t v10 = *(void *)&__src[v9 + 8];
        *(void *)&__dst[v9 + 8] = v10;
        uint64_t v11 = v8[16];
        *(void *)&__dst[v11] = *(void *)&__src[v11];
        uint64_t v19 = *(void *)&__src[v11 + 8];
        *(void *)&__dst[v11 + 8] = v19;
        uint64_t v12 = v8[20];
        *(void *)&__dst[v12] = *(void *)&__src[v12];
        uint64_t v18 = v5;
        uint64_t v13 = *(void *)&__src[v12 + 8];
        *(void *)&__dst[v12 + 8] = v13;
        uint64_t v14 = v8[24];
        *(void *)&__dst[v14] = *(void *)&__src[v14];
        uint64_t v15 = *(void *)&__src[v14 + 8];
        *(void *)&__dst[v14 + 8] = v15;
        swift_bridgeObjectRetain(v10);
        swift_bridgeObjectRetain(v19);
        LOBYTE(v10) = v13;
        uint64_t v5 = v18;
        swift_bridgeObjectRetain(v10);
        swift_bridgeObjectRetain(v15);
LABEL_9:
        swift_storeEnumTagMultiPayload(__dst, v5, EnumCaseMultiPayload);
        swift_storeEnumTagMultiPayload(__dst, a3, 1);
        return __dst;
      }
      uint64_t v16 = type metadata accessor for URL(0);
    }
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(__dst, __src, v16);
    goto LABEL_9;
  }
  memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
  return __dst;
}

char *assignWithCopy for MLActivityClassifier.ModelParameters.Validation(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters.Validation((uint64_t)__dst, type metadata accessor for MLActivityClassifier.ModelParameters.Validation);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
    {
      uint64_t v5 = type metadata accessor for MLActivityClassifier.DataSource(0);
      unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v5);
      if (EnumCaseMultiPayload == 2)
      {
        uint64_t v16 = type metadata accessor for DataFrame(0);
      }
      else
      {
        if (EnumCaseMultiPayload == 1)
        {
          uint64_t v7 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
          uint64_t v8 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
          uint64_t v9 = v8[12];
          *(void *)&__dst[v9] = *(void *)&__src[v9];
          uint64_t v10 = *(void *)&__src[v9 + 8];
          *(void *)&__dst[v9 + 8] = v10;
          uint64_t v11 = v8[16];
          *(void *)&__dst[v11] = *(void *)&__src[v11];
          uint64_t v19 = *(void *)&__src[v11 + 8];
          *(void *)&__dst[v11 + 8] = v19;
          uint64_t v12 = v8[20];
          *(void *)&__dst[v12] = *(void *)&__src[v12];
          uint64_t v18 = v5;
          uint64_t v13 = *(void *)&__src[v12 + 8];
          *(void *)&__dst[v12 + 8] = v13;
          uint64_t v14 = v8[24];
          *(void *)&__dst[v14] = *(void *)&__src[v14];
          uint64_t v15 = *(void *)&__src[v14 + 8];
          *(void *)&__dst[v14 + 8] = v15;
          swift_bridgeObjectRetain(v10);
          swift_bridgeObjectRetain(v19);
          LOBYTE(v10) = v13;
          uint64_t v5 = v18;
          swift_bridgeObjectRetain(v10);
          swift_bridgeObjectRetain(v15);
LABEL_10:
          swift_storeEnumTagMultiPayload(__dst, v5, EnumCaseMultiPayload);
          swift_storeEnumTagMultiPayload(__dst, a3, 1);
          return __dst;
        }
        uint64_t v16 = type metadata accessor for URL(0);
      }
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(__dst, __src, v16);
      goto LABEL_10;
    }
    memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
  }
  return __dst;
}

char *initializeWithTake for MLActivityClassifier.ModelParameters.Validation(char *__dst, char *__src, uint64_t a3)
{
  if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
  {
    uint64_t v4 = type metadata accessor for MLActivityClassifier.DataSource(0);
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v4);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v8 = type metadata accessor for DataFrame(0);
    }
    else
    {
      if (EnumCaseMultiPayload == 1)
      {
        uint64_t v6 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 32))(__dst, __src, v6);
        uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
        *(_OWORD *)&__dst[v7[12]] = *(_OWORD *)&__src[v7[12]];
        *(_OWORD *)&__dst[v7[16]] = *(_OWORD *)&__src[v7[16]];
        *(_OWORD *)&__dst[v7[20]] = *(_OWORD *)&__src[v7[20]];
        *(_OWORD *)&__dst[v7[24]] = *(_OWORD *)&__src[v7[24]];
LABEL_9:
        swift_storeEnumTagMultiPayload(__dst, v4, EnumCaseMultiPayload);
        swift_storeEnumTagMultiPayload(__dst, a3, 1);
        return __dst;
      }
      uint64_t v8 = type metadata accessor for URL(0);
    }
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
    goto LABEL_9;
  }
  memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
  return __dst;
}

char *assignWithTake for MLActivityClassifier.ModelParameters.Validation(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters.Validation((uint64_t)__dst, type metadata accessor for MLActivityClassifier.ModelParameters.Validation);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
    {
      uint64_t v4 = type metadata accessor for MLActivityClassifier.DataSource(0);
      unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, v4);
      if (EnumCaseMultiPayload == 2)
      {
        uint64_t v8 = type metadata accessor for DataFrame(0);
      }
      else
      {
        if (EnumCaseMultiPayload == 1)
        {
          uint64_t v6 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 32))(__dst, __src, v6);
          uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFileName: String, timeStampColumn: String, labelStartTimeColumn: String, labelEndTimeColumn: String));
          *(_OWORD *)&__dst[v7[12]] = *(_OWORD *)&__src[v7[12]];
          *(_OWORD *)&__dst[v7[16]] = *(_OWORD *)&__src[v7[16]];
          *(_OWORD *)&__dst[v7[20]] = *(_OWORD *)&__src[v7[20]];
          *(_OWORD *)&__dst[v7[24]] = *(_OWORD *)&__src[v7[24]];
LABEL_10:
          swift_storeEnumTagMultiPayload(__dst, v4, EnumCaseMultiPayload);
          swift_storeEnumTagMultiPayload(__dst, a3, 1);
          return __dst;
        }
        uint64_t v8 = type metadata accessor for URL(0);
      }
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
      goto LABEL_10;
    }
    memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
  }
  return __dst;
}

uint64_t type metadata completion function for MLActivityClassifier.ModelParameters.Validation(uint64_t a1)
{
  v5[0] = &unk_34A7E0;
  uint64_t result = type metadata accessor for MLActivityClassifier.DataSource(319);
  if (v4 <= 0x3F)
  {
    v5[1] = *(void *)(result - 8) + 64;
    swift_initEnumMetadataMultiPayload(a1, 256, 2, v5, v2, v3);
    return 0;
  }
  return result;
}

uint64_t outlined destroy of MLActivityClassifier.ModelParameters.Validation(uint64_t a1, uint64_t (*a2)(void))
{
  uint64_t v2 = a2(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

unsigned char *assignWithCopy for MLDecisionTreeRegressor.ModelParameters.ValidationData(unsigned char *__dst, unsigned char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData((uint64_t)__dst);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v7 = type metadata accessor for DataFrame(0);
      (*(void (**)(unsigned char *, unsigned char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v5 = *(void *)__src;
      char v6 = __src[8];
      outlined copy of Result<_DataTable, Error>(*(void *)__src, v6);
      *(void *)__dst = v5;
      __dst[8] = v6;
      swift_storeEnumTagMultiPayload(__dst, a3, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLDecisionTreeRegressor.ModelParameters.ValidationData;
  if (!type metadata singleton initialization cache for MLDecisionTreeRegressor.ModelParameters.ValidationData) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLDecisionTreeRegressor.ModelParameters.ValidationData);
  }
  return result;
}

void *assignWithTake for MLDecisionTreeRegressor.ModelParameters.ValidationData(void *__dst, void *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLDecisionTreeRegressor.ModelParameters.ValidationData((uint64_t)__dst);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 2)
    {
      uint64_t v4 = type metadata accessor for DataFrame(0);
      (*(void (**)(void *, void *, uint64_t))(*(void *)(v4 - 8) + 32))(__dst, __src, v4);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLDecisionTreeRegressor.ModelParameters.ValidationData(uint64_t a1)
{
  v5[0] = &unk_34A818;
  v5[1] = &unk_34A830;
  uint64_t result = type metadata accessor for DataFrame(319);
  if (v4 <= 0x3F)
  {
    v5[2] = *(void *)(result - 8) + 64;
    swift_initEnumMetadataMultiPayload(a1, 256, 3, v5, v2, v3);
    return 0;
  }
  return result;
}

uint64_t MLDecisionTreeRegressor.ModelParameters.ValidationData.table.getter(__m128 a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = type metadata accessor for DataFrame(0);
  uint64_t v27 = *(void *)(v4 - 8);
  int64_t v5 = *(void *)(v27 + 64);
  char v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v29 = &v25;
  uint64_t v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v28 = &v25;
  uint64_t v10 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData(0);
  int64_t v11 = *(void *)(*(void *)(v10 - 8) + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  outlined init with copy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v2, (uint64_t)&v25);
  uint64_t result = swift_getEnumCaseMultiPayload(&v25, v10);
  switch((int)result)
  {
    case 0:
      *(void *)uint64_t v3 = 0;
      *(unsigned char *)(v3 + 8) = -1;
      break;
    case 1:
      uint64_t result = v25;
      char v15 = v26;
      goto LABEL_7;
    case 2:
      uint64_t v16 = v28;
      uint64_t v17 = v27;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v27 + 32))(v28, &v25, v4);
      uint64_t v18 = (uint64_t)v29;
      *(double *)a1.i64 = (*(double (**)(uint64_t *, uint64_t *, uint64_t))(v17 + 16))(v29, v16, v4);
      MLDataTable.init(_:convertArraysToShapedArrays:)(v18, 1, a1);
      (*(void (**)(uint64_t *, uint64_t))(v17 + 8))(v16, v4);
      uint64_t result = v30;
      char v15 = v31;
LABEL_7:
      *(void *)uint64_t v3 = result;
      *(unsigned char *)(v3 + 8) = v15;
      break;
    case 3:
      uint64_t v19 = v3;
      uint64_t empty = tc_v1_sframe_create_empty(0);
      if (!empty) {
        BUG();
      }
      uint64_t v21 = empty;
      uint64_t v22 = type metadata accessor for CMLTable();
      uint64_t v23 = swift_allocObject(v22, 24, 7);
      *(void *)(v23 + 16) = v21;
      uint64_t v24 = type metadata accessor for _DataTable();
      swift_allocObject(v24, 40, 7);
      uint64_t result = _DataTable.init(impl:)(v23);
      *(void *)uint64_t v19 = result;
      *(unsigned char *)(v19 + 8) = 0;
      break;
  }
  return result;
}

uint64_t MLDecisionTreeRegressor.ModelParameters.ValidationData.generateDataFrames(trainingData:)(uint64_t a1, uint64_t a2, void (*a3)(uint64_t *, uint64_t, uint64_t))
{
  uint64_t v55 = v3;
  char v57 = a3;
  uint64_t v56 = (uint64_t *)a2;
  uint64_t v54 = a1;
  uint64_t v5 = type metadata accessor for DataFrame(0);
  uint64_t v58 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v58 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v50 = &v44;
  uint64_t v46 = type metadata accessor for DataFrame.Slice(0);
  uint64_t v51 = *(void *)(v46 - 8);
  int64_t v9 = *(void *)(v51 + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v48 = &v44;
  uint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v53 = &v44;
  uint64_t v14 = alloca(v9);
  char v15 = alloca(v9);
  unint64_t v52 = &v44;
  int64_t v16 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame.Slice?)
                              - 8)
                  + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v47 = &v44;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v49 = &v44;
  uint64_t v21 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData(0);
  int64_t v22 = *(void *)(*(void *)(v21 - 8) + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  outlined init with copy of MLDecisionTreeRegressor.ModelParameters.ValidationData(v4, (uint64_t)&v44);
  switch(swift_getEnumCaseMultiPayload(&v44, v21))
  {
    case 0u:
      uint64_t v58 = v5;
      uint64_t v25 = (uint64_t)v49;
      uint64_t v26 = (uint64_t)v52;
      DataFrame.randomSplit(strategy:)((uint64_t)v49, (uint64_t)v52, (uint64_t)&v44);
      uint64_t v27 = v53;
      uint64_t v28 = v46;
      char v57 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 16);
      v57(v53, v26, v46);
      DataFrame.init(_:)(v27);
      uint64_t v29 = (uint64_t)v47;
      outlined init with copy of DataFrame.Slice?(v25, (uint64_t)v47);
      if (__swift_getEnumTagSinglePayload(v29, 1, v28) == 1)
      {
        __swift_storeEnumTagSinglePayload((uint64_t)v56, 1, 1, v58);
        uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v51 + 8);
      }
      else
      {
        uint64_t v40 = v53;
        uint64_t v41 = v51;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 32))(v53, v29, v28);
        uint64_t v42 = v48;
        v57(v48, (uint64_t)v40, v28);
        uint64_t v43 = (uint64_t)v56;
        DataFrame.init(_:)(v42);
        uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v41 + 8);
        v30(v53, v28);
        __swift_storeEnumTagSinglePayload(v43, 0, 1, v58);
      }
      v30(v52, v28);
      return outlined destroy of DataFrame.Slice?((uint64_t)v49);
    case 1u:
      uint64_t v35 = v44;
      char v36 = v45;
      (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
      uint64_t v44 = v35;
      char v45 = v36;
      uint64_t v37 = (uint64_t)v56;
      DataFrame.init(_:)((uint64_t)&v44);
      uint64_t v33 = v37;
      goto LABEL_10;
    case 2u:
      char v31 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v58 + 32);
      v31(v50, &v44, v5);
      if (DataFrameProtocol.isEmpty.getter(v5, &protocol witness table for DataFrame))
      {
        uint64_t v32 = v58;
        (*(void (**)(uint64_t *, uint64_t))(v58 + 8))(v50, v5);
        (*(void (**)(uint64_t, void, uint64_t))(v32 + 16))(v54, v57, v5);
LABEL_7:
        uint64_t v33 = (uint64_t)v56;
        uint64_t v34 = 1;
      }
      else
      {
        (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
        uint64_t v38 = (uint64_t)v56;
        v31(v56, v50, v5);
        uint64_t v33 = v38;
LABEL_10:
        uint64_t v34 = 0;
      }
      return __swift_storeEnumTagSinglePayload(v33, v34, 1, v5);
    case 3u:
      (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
      goto LABEL_7;
  }
}

uint64_t outlined init with copy of MLDecisionTreeRegressor.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLDecisionTreeRegressor.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

void *initializeBufferWithCopyOfBuffer for MLWordTagger.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  uint64_t v3 = __dst;
  uint64_t v4 = *(void *)(a3 - 8);
  int v5 = *(_DWORD *)(v4 + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v12 = *(void *)__src;
    *uint64_t v3 = *(void *)__src;
    uint64_t v3 = (void *)(v12 + ((v5 + 16) & ~v5));
    swift_retain();
  }
  else
  {
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
    switch(EnumCaseMultiPayload)
    {
      case 3:
        uint64_t v13 = *(void *)__src;
        *uint64_t v3 = *(void *)__src;
        swift_bridgeObjectRetain(v13);
        swift_storeEnumTagMultiPayload(v3, a3, 3);
        break;
      case 2:
        uint64_t v14 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 16))(__dst, __src, v14);
        uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, tokenColumn: String, labelColumn: String));
        uint64_t v16 = *(int *)(v15 + 48);
        *(void *)&__dst[v16] = *(void *)&__src[v16];
        uint64_t v17 = *(void *)&__src[v16 + 8];
        *(void *)((char *)v3 + v16 + 8) = v17;
        uint64_t v18 = *(int *)(v15 + 64);
        *(void *)((char *)v3 + v18) = *(void *)&__src[v18];
        uint64_t v19 = *(void *)&__src[v18 + 8];
        *(void *)((char *)v3 + v18 + 8) = v19;
        swift_bridgeObjectRetain(v17);
        swift_bridgeObjectRetain(v19);
        swift_storeEnumTagMultiPayload(v3, a3, 2);
        break;
      case 1:
        uint64_t v8 = *(void *)__src;
        char v9 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v9);
        *(void *)__dst = v8;
        __dst[8] = v9;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v10 = *((void *)__src + 3);
        void v3[3] = v10;
        void v3[4] = *((void *)__src + 4);
        uint64_t v11 = *((void *)__src + 5);
        void v3[5] = v11;
        swift_bridgeObjectRetain(v10);
        swift_bridgeObjectRetain(v11);
        swift_storeEnumTagMultiPayload(v3, a3, 1);
        break;
      default:
        memcpy(__dst, __src, *(void *)(v4 + 64));
        break;
    }
  }
  return v3;
}

uint64_t destroy for MLWordTagger.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = (void *)a1;
  uint64_t result = swift_getEnumCaseMultiPayload(a1, a2);
  if (result != 3)
  {
    if (result == 2)
    {
      uint64_t v4 = type metadata accessor for DataFrame(0);
      (*(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
      uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, tokenColumn: String, labelColumn: String));
      swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(v5 + 48) + 8));
      uint64_t v2 = (void *)(*(int *)(v5 + 64) + a1 + 8);
    }
    else
    {
      if (result != 1) {
        return result;
      }
      outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
      swift_bridgeObjectRelease(*(void *)(a1 + 24));
      uint64_t v2 = (void *)(a1 + 40);
    }
  }
  return swift_bridgeObjectRelease(*v2);
}

char *initializeWithCopy for MLWordTagger.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
  switch(EnumCaseMultiPayload)
  {
    case 3:
      uint64_t v10 = *(void *)__src;
      *(void *)__dst = *(void *)__src;
      swift_bridgeObjectRetain(v10);
      swift_storeEnumTagMultiPayload(__dst, a3, 3);
      break;
    case 2:
      uint64_t v11 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 16))(__dst, __src, v11);
      uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, tokenColumn: String, labelColumn: String));
      uint64_t v13 = *(int *)(v12 + 48);
      *(void *)&__dst[v13] = *(void *)&__src[v13];
      uint64_t v14 = *(void *)&__src[v13 + 8];
      *(void *)&__dst[v13 + 8] = v14;
      uint64_t v15 = *(int *)(v12 + 64);
      *(void *)&__dst[v15] = *(void *)&__src[v15];
      uint64_t v16 = *(void *)&__src[v15 + 8];
      *(void *)&__dst[v15 + 8] = v16;
      swift_bridgeObjectRetain(v14);
      swift_bridgeObjectRetain(v16);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
      break;
    case 1:
      uint64_t v6 = *(void *)__src;
      char v7 = __src[8];
      outlined copy of Result<_DataTable, Error>(*(void *)__src, v7);
      *(void *)__dst = v6;
      __dst[8] = v7;
      *((void *)__dst + 2) = *((void *)__src + 2);
      uint64_t v8 = *((void *)__src + 3);
      *((void *)__dst + 3) = v8;
      *((void *)__dst + 4) = *((void *)__src + 4);
      uint64_t v9 = *((void *)__src + 5);
      *((void *)__dst + 5) = v9;
      swift_bridgeObjectRetain(v8);
      swift_bridgeObjectRetain(v9);
      swift_storeEnumTagMultiPayload(__dst, a3, 1);
      break;
    default:
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
      break;
  }
  return __dst;
}

char *assignWithCopy for MLWordTagger.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLWordTagger.ModelParameters.ValidationData((uint64_t)__dst);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
    switch(EnumCaseMultiPayload)
    {
      case 3:
        uint64_t v10 = *(void *)__src;
        *(void *)__dst = *(void *)__src;
        swift_bridgeObjectRetain(v10);
        swift_storeEnumTagMultiPayload(__dst, a3, 3);
        break;
      case 2:
        uint64_t v11 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 16))(__dst, __src, v11);
        uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, tokenColumn: String, labelColumn: String));
        uint64_t v13 = *(int *)(v12 + 48);
        *(void *)&__dst[v13] = *(void *)&__src[v13];
        uint64_t v14 = *(void *)&__src[v13 + 8];
        *(void *)&__dst[v13 + 8] = v14;
        uint64_t v15 = *(int *)(v12 + 64);
        *(void *)&__dst[v15] = *(void *)&__src[v15];
        uint64_t v16 = *(void *)&__src[v15 + 8];
        *(void *)&__dst[v15 + 8] = v16;
        swift_bridgeObjectRetain(v14);
        swift_bridgeObjectRetain(v16);
        swift_storeEnumTagMultiPayload(__dst, a3, 2);
        break;
      case 1:
        uint64_t v6 = *(void *)__src;
        char v7 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v7);
        *(void *)__dst = v6;
        __dst[8] = v7;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v8 = *((void *)__src + 3);
        *((void *)__dst + 3) = v8;
        *((void *)__dst + 4) = *((void *)__src + 4);
        uint64_t v9 = *((void *)__src + 5);
        *((void *)__dst + 5) = v9;
        swift_bridgeObjectRetain(v8);
        swift_bridgeObjectRetain(v9);
        swift_storeEnumTagMultiPayload(__dst, a3, 1);
        break;
      default:
        memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
        break;
    }
  }
  return __dst;
}

uint64_t outlined destroy of MLWordTagger.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLWordTagger.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t type metadata accessor for MLWordTagger.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLWordTagger.ModelParameters.ValidationData;
  if (!type metadata singleton initialization cache for MLWordTagger.ModelParameters.ValidationData) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLWordTagger.ModelParameters.ValidationData);
  }
  return result;
}

char *initializeWithTake for MLWordTagger.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (swift_getEnumCaseMultiPayload(__src, a3) == 2)
  {
    uint64_t v4 = type metadata accessor for DataFrame(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 32))(__dst, __src, v4);
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, tokenColumn: String, labelColumn: String));
    *(_OWORD *)&__dst[*(int *)(v5 + 48)] = *(_OWORD *)&__src[*(int *)(v5 + 48)];
    *(_OWORD *)&__dst[*(int *)(v5 + 64)] = *(_OWORD *)&__src[*(int *)(v5 + 64)];
    swift_storeEnumTagMultiPayload(__dst, a3, 2);
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
  }
  return __dst;
}

char *assignWithTake for MLWordTagger.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLWordTagger.ModelParameters.ValidationData((uint64_t)__dst);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 2)
    {
      uint64_t v4 = type metadata accessor for DataFrame(0);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 32))(__dst, __src, v4);
      uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, tokenColumn: String, labelColumn: String));
      *(_OWORD *)&__dst[*(int *)(v5 + 48)] = *(_OWORD *)&__src[*(int *)(v5 + 48)];
      *(_OWORD *)&__dst[*(int *)(v5 + 64)] = *(_OWORD *)&__src[*(int *)(v5 + 64)];
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLWordTagger.ModelParameters.ValidationData(uint64_t a1)
{
  v6[0] = &unk_34A868;
  v6[1] = &unk_34A880;
  uint64_t result = type metadata accessor for DataFrame(319);
  if (v2 <= 0x3F)
  {
    swift_getTupleTypeLayout3(v5, *(void *)(result - 8) + 64, &unk_34A898, &unk_34A898);
    v6[2] = v5;
    v6[3] = (char *)&value witness table for Builtin.BridgeObject + 64;
    swift_initEnumMetadataMultiPayload(a1, 256, 4, v6, v3, v4);
    return 0;
  }
  return result;
}

uint64_t MLWordTagger.ModelParameters.ValidationData.createValidationData(trainingData:tokenColumnName:labelColumnName:)(uint64_t a1, uint64_t a2, char *a3, uint64_t a4, void *a5)
{
  to_8._char countAndFlagsBits = a4;
  uint64_t v107 = a3;
  uint64_t v119 = v5;
  uint64_t to = a2;
  uint64_t v121 = v6;
  v126._char countAndFlagsBits = v7;
  to_8._char object = a5;
  v120._char countAndFlagsBits = a1;
  uint64_t v115 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String]>);
  uint64_t v116 = *(void *)(v115 - 8);
  int64_t v8 = *(void *)(v116 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v111 = (uint64_t *)&v102;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v113 = (uint64_t *)&v102;
  uint64_t v13 = alloca(v8);
  uint64_t v14 = alloca(v8);
  uint64_t v112 = (uint64_t *)&v102;
  uint64_t v15 = alloca(v8);
  uint64_t v16 = alloca(v8);
  unint64_t v114 = (uint64_t *)&v102;
  uint64_t v17 = (void *)type metadata accessor for DataFrame(0);
  uint64_t v122 = *(v17 - 1);
  int64_t v18 = *(void *)(v122 + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v124 = (uint64_t *)&v102;
  uint64_t v21 = alloca(v18);
  int64_t v22 = alloca(v18);
  uint64_t v117 = (uint64_t *)&v102;
  uint64_t v23 = alloca(v18);
  uint64_t v24 = alloca(v18);
  char v125 = (char *)&v102;
  _ = (char *)type metadata accessor for DataFrame.Slice(0);
  uint64_t v25 = *((void *)_ - 1);
  int64_t v26 = *(void *)(v25 + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  uint64_t v105 = (uint64_t *)&v102;
  uint64_t v29 = alloca(v26);
  uint64_t v30 = alloca(v26);
  unint64_t v106 = (uint64_t *)&v102;
  char v31 = alloca(v26);
  uint64_t v32 = alloca(v26);
  v123._char countAndFlagsBits = (uint64_t)&v102;
  int64_t v33 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame.Slice?)
                              - 8)
                  + 64);
  uint64_t v34 = alloca(v33);
  uint64_t v35 = alloca(v33);
  uint64_t v110 = (uint64_t *)&v102;
  char v36 = alloca(v33);
  uint64_t v37 = alloca(v33);
  v120._char object = &v102;
  uint64_t v38 = type metadata accessor for MLWordTagger.ModelParameters.ValidationData(0);
  int64_t v39 = *(void *)(*(void *)(v38 - 8) + 64);
  uint64_t v40 = alloca(v39);
  uint64_t v41 = alloca(v39);
  outlined init with copy of MLWordTagger.ModelParameters.ValidationData(v126._countAndFlagsBits, (uint64_t)&v102);
  switch(swift_getEnumCaseMultiPayload(&v102, v38))
  {
    case 0u:
      char object = v120._object;
      DataFrame.randomSplit(strategy:)((uint64_t)v120._object, v123._countAndFlagsBits, (uint64_t)&v102);
      uint64_t v43 = (uint64_t)v110;
      outlined init with copy of DataFrame.Slice?((uint64_t)object, (uint64_t)v110);
      uint64_t v44 = _;
      if (__swift_getEnumTagSinglePayload(v43, 1, (uint64_t)_) == 1)
      {
        (*(void (**)(uint64_t, char *))(v25 + 8))(v123._countAndFlagsBits, v44);
        outlined destroy of DataFrame.Slice?((uint64_t)v120._object);
        outlined destroy of DataFrame.Slice?(v43);
        goto LABEL_4;
      }
      v123._char object = v17;
      (*(void (**)(uint64_t, void *))(v122 + 8))(v120._countAndFlagsBits, v17);
      (*(void (**)(uint64_t *, uint64_t, char *))(v25 + 32))(v106, v43, v44);
      double v69 = v44;
      v126._char countAndFlagsBits = *(void *)(v25 + 16);
      uint64_t v70 = v105;
      ((void (*)(uint64_t *, uint64_t, char *))v126._countAndFlagsBits)(v105, v123._countAndFlagsBits, v44);
      DataFrame.init(_:)(v70);
      uint64_t v71 = v106;
      ((void (*)(uint64_t *, uint64_t *, char *))v126._countAndFlagsBits)(v70, v106, v69);
      DataFrame.init(_:)(v70);
      double v72 = *(void (**)(uint64_t *, char *))(v25 + 8);
      v72(v71, v69);
      v72((uint64_t *)v123._countAndFlagsBits, v69);
      outlined destroy of DataFrame.Slice?((uint64_t)v120._object);
      uint64_t v45 = v119;
      uint64_t v46 = 0;
      uint64_t v47 = v123._object;
      return __swift_storeEnumTagSinglePayload(v45, v46, 1, (uint64_t)v47);
    case 1u:
      v123._char object = v17;
      int v48 = v103;
      uint64_t v49 = v104;
      v126._char countAndFlagsBits = (uint64_t)v105;
      uint64_t v50 = v106;
      uint64_t v51 = v107;
      LOBYTE(v103) = v103 & 1;
      uint64_t v124 = v102;
      LODWORD(v123._countAndFlagsBits) = v48;
      outlined copy of Result<_DataTable, Error>((uint64_t)v102, v48);
      unint64_t v52 = v125;
      DataFrame.init(_:)((uint64_t)&v102);
      v120._char countAndFlagsBits = v49;
      v120._char object = v50;
      uint64_t v53 = v121;
      static MLWordTagger.validateDataFrame(_:tokenColumnName:labelColumnName:)((uint64_t)v52, v49, (uint64_t *)v126._countAndFlagsBits, (uint64_t)v50, v51);
      if (v53)
      {
        (*(void (**)(char *, void *))(v122 + 8))(v125, v123._object);
        outlined consume of Result<_DataTable, Error>((uint64_t)v124, v123._countAndFlagsBits);
        swift_bridgeObjectRelease((_BYTE)v51);
        char countAndFlagsBits = v126._countAndFlagsBits;
        return swift_bridgeObjectRelease(countAndFlagsBits);
      }
      _ = v51;
      static MLWordTagger.createTextColumn(_:name:context:)((uint64_t)v125, v120._countAndFlagsBits, (void *)v126._countAndFlagsBits, 0x6E656B6F54, (void *)0xE500000000000000);
      unsigned __int8 v74 = v125;
      BOOL v75 = v120._object;
      static MLWordTagger.createTextColumn(_:name:context:)((uint64_t)v125, (uint64_t)v120._object, _, 0x6C6562614CLL, (void *)0xE500000000000000);
      DataFrame.init()(v74, v75, v80, v81);
      uint64_t v110 = (uint64_t *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
      uint64_t v121 = 0;
      DataFrame.append<A>(column:)(v114, v110);
      DataFrame.append<A>(column:)(v112, v110);
      v82._char countAndFlagsBits = (uint64_t)v120._object;
      char v83 = (char)_;
      v82._char object = _;
      DataFrame.renameColumn(_:to:)(v82, to_8);
      swift_bridgeObjectRelease(v83);
      v82._char countAndFlagsBits = v120._countAndFlagsBits;
      char v84 = v126._countAndFlagsBits;
      v82._char object = (void *)v126._countAndFlagsBits;
      v85._char countAndFlagsBits = to;
      v85._char object = v107;
      DataFrame.renameColumn(_:to:)(v82, v85);
      swift_bridgeObjectRelease(v84);
      outlined consume of Result<_DataTable, Error>((uint64_t)v124, v123._countAndFlagsBits);
      uint64_t v86 = *(void (**)(uint64_t *, uint64_t))(v116 + 8);
      uint64_t v87 = v115;
      v86(v112, v115);
      v86(v114, v87);
      uint64_t v88 = v123._object;
      uint64_t v89 = v122;
      (*(void (**)(char *, void *))(v122 + 8))(v125, v123._object);
      uint64_t v90 = v119;
      (*(void (**)(uint64_t, uint64_t *, void *))(v89 + 32))(v119, v117, v88);
      uint64_t v91 = v90;
      uint64_t v92 = (uint64_t)v88;
      return __swift_storeEnumTagSinglePayload(v91, 0, 1, v92);
    case 2u:
      uint64_t v55 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, tokenColumn: String, labelColumn: String));
      uint64_t v56 = *(int *)(v55 + 48);
      v126._char countAndFlagsBits = *(uint64_t *)((char *)&v102 + v56);
      char v57 = *(uint64_t **)((char *)&v102 + v56 + 8);
      uint64_t v58 = *(int *)(v55 + 64);
      uint64_t v59 = *(uint64_t *)((char *)&v102 + v58);
      char v125 = *(char **)((char *)&v102 + v58 + 8);
      uint64_t v60 = (uint64_t)v124;
      uint64_t v61 = v57;
      v120._char countAndFlagsBits = *(void *)(v122 + 32);
      ((void (*)(uint64_t *, uint64_t **, void *))v120._countAndFlagsBits)(v124, &v102, v17);
      uint64_t v62 = v60;
      char v63 = (char)v125;
      v123._char countAndFlagsBits = v59;
      uint64_t v64 = v121;
      static MLWordTagger.validateDataFrame(_:tokenColumnName:labelColumnName:)(v62, v126._countAndFlagsBits, v61, v59, v125);
      if (v64)
      {
        (*(void (**)(uint64_t *, void *))(v122 + 8))(v124, v17);
        swift_bridgeObjectRelease((_BYTE)v61);
        char countAndFlagsBits = v63;
        return swift_bridgeObjectRelease(countAndFlagsBits);
      }
      else
      {
        v123._char object = v17;
        static MLWordTagger.createTextColumn(_:name:context:)((uint64_t)v124, v126._countAndFlagsBits, v61, 0x6E656B6F54, (void *)0xE500000000000000);
        v120._char object = v61;
        uint64_t v76 = (uint64_t)v124;
        uint64_t v77 = v123._countAndFlagsBits;
        uint64_t v78 = v123._countAndFlagsBits;
        uint64_t v79 = v125;
        static MLWordTagger.createTextColumn(_:name:context:)((uint64_t)v124, v123._countAndFlagsBits, v125, 0x6C6562614CLL, (void *)0xE500000000000000);
        DataFrame.init()(v76, v78, v93, v94);
        uint64_t v95 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
        uint64_t v121 = 0;
        DataFrame.append<A>(column:)(v113, v95);
        DataFrame.append<A>(column:)(v111, v95);
        v96._char countAndFlagsBits = v77;
        v96._char object = v79;
        DataFrame.renameColumn(_:to:)(v96, to_8);
        swift_bridgeObjectRelease((_BYTE)v79);
        v96._char countAndFlagsBits = v126._countAndFlagsBits;
        LOBYTE(v79) = v120._object;
        v96._char object = v120._object;
        v97._char countAndFlagsBits = to;
        v97._char object = v107;
        DataFrame.renameColumn(_:to:)(v96, v97);
        swift_bridgeObjectRelease((_BYTE)v79);
        uint64_t v98 = *(void (**)(uint64_t *, uint64_t))(v116 + 8);
        uint64_t v99 = v115;
        v98(v111, v115);
        v98(v113, v99);
        uint64_t v100 = v123._object;
        (*(void (**)(uint64_t *, void *))(v122 + 8))(v124, v123._object);
        uint64_t v101 = v119;
        ((void (*)(uint64_t, uint64_t *, void *))v120._countAndFlagsBits)(v119, v117, v100);
        uint64_t v91 = v101;
        uint64_t v92 = (uint64_t)v100;
        return __swift_storeEnumTagSinglePayload(v91, 0, 1, v92);
      }
    case 3u:
      uint64_t v65 = (uint64_t)v17;
      char v66 = (char)v102;
      uint64_t v67 = v119;
      uint64_t v68 = v121;
      static MLWordTagger.generateTextDataFrame(_:tokenColumn:labelColumn:)((uint64_t)v102, to, (uint64_t)v107, to_8._countAndFlagsBits, (uint64_t)to_8._object);
      if (!v68) {
        __swift_storeEnumTagSinglePayload(v67, 0, 1, v65);
      }
      char countAndFlagsBits = v66;
      return swift_bridgeObjectRelease(countAndFlagsBits);
    case 4u:
LABEL_4:
      uint64_t v45 = v119;
      uint64_t v46 = 1;
      uint64_t v47 = v17;
      return __swift_storeEnumTagSinglePayload(v45, v46, 1, (uint64_t)v47);
  }
}

uint64_t MLWordTagger.ModelParameters.ValidationData.table.getter(__m128 a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = type metadata accessor for DataFrame(0);
  uint64_t v32 = *(void *)(v4 - 8);
  int64_t v5 = *(void *)(v32 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  int64_t v33 = &v30;
  int64_t v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v34 = &v30;
  uint64_t v10 = type metadata accessor for MLWordTagger.ModelParameters.ValidationData(0);
  int64_t v11 = *(void *)(*(void *)(v10 - 8) + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  outlined init with copy of MLWordTagger.ModelParameters.ValidationData(v2, (uint64_t)&v30);
  uint64_t result = swift_getEnumCaseMultiPayload(&v30, v10);
  switch((int)result)
  {
    case 0:
      *(void *)uint64_t v3 = 0;
      *(unsigned char *)(v3 + 8) = -1;
      break;
    case 1:
      uint64_t v15 = v30;
      char v16 = v31;
      char v17 = v35;
      swift_bridgeObjectRelease((_BYTE)v33);
      uint64_t result = swift_bridgeObjectRelease(v17);
      *(void *)uint64_t v3 = v15;
      *(unsigned char *)(v3 + 8) = v16;
      break;
    case 2:
      uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, tokenColumn: String, labelColumn: String));
      swift_bridgeObjectRelease(*(uint64_t *)((char *)&v30 + *(int *)(v18 + 48) + 8));
      swift_bridgeObjectRelease(*(uint64_t *)((char *)&v30 + *(int *)(v18 + 64) + 8));
      uint64_t v19 = v34;
      uint64_t v20 = v32;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v32 + 32))(v34, &v30, v4);
      uint64_t v21 = (uint64_t)v33;
      *(double *)a1.i64 = (*(double (**)(uint64_t *, uint64_t *, uint64_t))(v20 + 16))(v33, v19, v4);
      MLDataTable.init(_:convertArraysToShapedArrays:)(v21, 0, a1);
      (*(void (**)(uint64_t *, uint64_t))(v20 + 8))(v34, v4);
      goto LABEL_8;
    case 3:
      char v22 = v30;
      static MLWordTagger.generateTextTable(_:tokenColumn:labelColumn:)(v30, 1954047348, 0xE400000000000000, 0x736C6562616CLL, 0xE600000000000000);
      swift_bridgeObjectRelease(v22);
LABEL_8:
      uint64_t result = v35;
      char v29 = v36;
      *(void *)uint64_t v3 = v35;
      *(unsigned char *)(v3 + 8) = v29;
      break;
    case 4:
      uint64_t v23 = v3;
      uint64_t empty = tc_v1_sframe_create_empty(0);
      if (!empty) {
        BUG();
      }
      uint64_t v25 = empty;
      uint64_t v26 = type metadata accessor for CMLTable();
      uint64_t v27 = swift_allocObject(v26, 24, 7);
      *(void *)(v27 + 16) = v25;
      uint64_t v28 = type metadata accessor for _DataTable();
      swift_allocObject(v28, 40, 7);
      uint64_t result = _DataTable.init(impl:)(v27);
      *(void *)uint64_t v23 = result;
      *(unsigned char *)(v23 + 8) = 0;
      break;
  }
  return result;
}

uint64_t outlined init with copy of MLWordTagger.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLWordTagger.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined init with copy of DataFrame.Slice?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame.Slice?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t specialized BidirectionalCollection.last.getter()
{
  uint64_t v0 = 0;
  uint64_t v1 = type metadata accessor for TensorShape(0);
  uint64_t v2 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type TensorShape and conformance TensorShape, (uint64_t (*)(uint64_t))&type metadata accessor for TensorShape, (uint64_t)&protocol conformance descriptor for TensorShape);
  if ((dispatch thunk of Collection.isEmpty.getter(v1, v2) & 1) == 0)
  {
    dispatch thunk of Collection.endIndex.getter(v1, v2);
    uint64_t v3 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type TensorShape and conformance TensorShape, (uint64_t (*)(uint64_t))&type metadata accessor for TensorShape, (uint64_t)&protocol conformance descriptor for TensorShape);
    dispatch thunk of BidirectionalCollection.index(before:)(v8, v1, v3);
    uint64_t v4 = (void (*)(unsigned char *, void))dispatch thunk of Collection.subscript.read(v8, v7, v1, v2);
    uint64_t v0 = *v5;
    v4(v8, 0);
  }
  return v0;
}

uint64_t specialized BidirectionalCollection.last.getter(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t v3 = *(void *)(a1 + 16);
  if (v3)
  {
    uint64_t v4 = type metadata accessor for MLCheckpoint(0);
    outlined init with copy of MLActivityClassifier.Model(((*(unsigned __int8 *)(*(void *)(v4 - 8) + 80) + 32) & ~*(unsigned __int8 *)(*(void *)(v4 - 8) + 80))+ a1+ *(void *)(*(void *)(v4 - 8) + 72) * (v3 - 1), v2, type metadata accessor for MLCheckpoint);
    return __swift_storeEnumTagSinglePayload(v2, 0, 1, v4);
  }
  else
  {
    uint64_t v6 = type metadata accessor for MLCheckpoint(0);
    return __swift_storeEnumTagSinglePayload(v2, 1, 1, v6);
  }
}

{
  return specialized BidirectionalCollection.last.getter(a1, (uint64_t (*)(void))&type metadata accessor for NeuralNetwork.Layer);
}

{
  return specialized BidirectionalCollection.last.getter(a1, (uint64_t (*)(void))&type metadata accessor for Model);
}

{
  uint64_t v1;

  uint64_t v1 = *(void *)(a1 + 16);
  if (v1) {
    return *(void *)(a1 + 8 * v1 + 24);
  }
  else {
    return 0;
  }
}

uint64_t specialized BidirectionalCollection.last.getter(uint64_t a1, unint64_t a2)
{
  uint64_t v2 = HIBYTE(a2) & 0xF;
  if ((a2 & 0x2000000000000000) == 0) {
    uint64_t v2 = a1 & 0xFFFFFFFFFFFFLL;
  }
  if (!v2) {
    return 0;
  }
  uint64_t v3 = String.index(before:)((v2 << 16) + 4 * ((a2 >> 60) & ((a1 & 0x800000000000000) == 0)) + 7, a1, a2);
  return String.subscript.getter(v3, a1, a2);
}

uint64_t specialized BidirectionalCollection.last.getter(uint64_t a1, uint64_t (*a2)(void))
{
  uint64_t v3 = v2;
  uint64_t v4 = *(void *)(a1 + 16);
  if (v4)
  {
    uint64_t v5 = a2(0);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16))(v3, ((*(unsigned __int8 *)(*(void *)(v5 - 8) + 80) + 32) & ~*(unsigned __int8 *)(*(void *)(v5 - 8) + 80))+ a1+ *(void *)(*(void *)(v5 - 8) + 72) * (v4 - 1), v5);
    return __swift_storeEnumTagSinglePayload(v3, 0, 1, v5);
  }
  else
  {
    uint64_t v7 = a2(0);
    return __swift_storeEnumTagSinglePayload(v3, 1, 1, v7);
  }
}

uint64_t specialized Zip2Sequence.Iterator.next()()
{
  if (*(unsigned char *)(v0 + 32)) {
    return 0;
  }
  unint64_t v1 = *(void *)(v0 + 8);
  if (v1 == *(void *)(*(void *)v0 + 16)) {
    goto LABEL_5;
  }
  if (v1 >= *(void *)(*(void *)v0 + 16)) {
    BUG();
  }
  uint64_t v2 = *(void *)(*(void *)v0 + 8 * v1 + 32);
  *(void *)(v0 + 8) = v1 + 1;
  uint64_t v3 = *(void *)(v0 + 16);
  unint64_t v4 = *(void *)(v0 + 24);
  if (v4 == *(void *)(v3 + 16))
  {
LABEL_5:
    *(unsigned char *)(v0 + 32) = 1;
    return 0;
  }
  if (v4 >= *(void *)(v3 + 16)) {
    BUG();
  }
  uint64_t v6 = *(void *)(v3 + 8 * v4 + 32);
  *(void *)(v0 + 24) = v4 + 1;
  swift_bridgeObjectRetain(v2);
  swift_bridgeObjectRetain(v6);
  return v2;
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  int64_t v5;
  void *v6;
  void *v7;
  uint64_t v8;
  uint64_t v10;
  unint64_t v11;
  uint64_t v12;
  void (*v13)(uint64_t, uint64_t, uint64_t);
  uint64_t v14;
  uint64_t v15;
  unint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  void (*v22)(uint64_t, uint64_t, uint64_t);
  uint64_t v23;
  uint64_t v24;

  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for Tensor(0);
  unint64_t v4 = *(void *)(v3 - 8);
  uint64_t v5 = *(void *)(v4 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  if (*((unsigned char *)v1 + 32) == 1)
  {
    int64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (Tensor, Tensor));
    return __swift_storeEnumTagSinglePayload(v2, 1, 1, v8);
  }
  uint64_t v10 = *v1;
  int64_t v11 = v1[1];
  if (v11 != *(void *)(*v1 + 16))
  {
    if (v11 >= *(void *)(*v1 + 16)) {
      BUG();
    }
    uint64_t v23 = v2;
    uint64_t v12 = (*(unsigned __int8 *)(v4 + 80) + 32) & ~*(unsigned __int8 *)(v4 + 80);
    uint64_t v13 = *(void (**)(uint64_t, uint64_t, uint64_t))(v4 + 16);
    uint64_t v24 = *(void *)(v4 + 72);
    uint64_t v14 = v11 * v24;
    v1[1] = v11 + 1;
    char v22 = v13;
    v13((uint64_t)&v22, v12 + v10 + v14, v3);
    uint64_t v15 = v1[2];
    char v16 = v1[3];
    if (v16 != *(void *)(v15 + 16))
    {
      if (v16 >= *(void *)(v15 + 16)) {
        BUG();
      }
      uint64_t v20 = v12 + v15 + v16 * v24;
      v1[3] = v16 + 1;
      uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (Tensor, Tensor));
      uint64_t v21 = v23 + *(int *)(v24 + 48);
      (*(void (**)(uint64_t, void, uint64_t))(v4 + 32))(v23, &v22, v3);
      v22(v21, v20, v3);
      char v17 = v23;
      uint64_t v18 = 0;
      uint64_t v19 = v24;
      return __swift_storeEnumTagSinglePayload(v17, v18, 1, v19);
    }
    (*(void (**)(void (**)(uint64_t, uint64_t, uint64_t), uint64_t))(v4 + 8))(&v22, v3);
    uint64_t v2 = v23;
  }
  *((unsigned char *)v1 + 32) = 1;
  char v17 = v2;
  uint64_t v18 = 1;
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (Tensor, Tensor));
  return __swift_storeEnumTagSinglePayload(v17, v18, 1, v19);
}

uint64_t MLActivityClassifier.evaluation(on:featureColumns:labelColumn:recordingFileColumn:)(uint64_t a1, void (*a2)(unint64_t *, uint64_t), void *a3, void (*a4)(uint64_t, uint64_t, uint64_t), void *a5, void *a6, __m128 a7, double a8)
{
  v272 = a4;
  v273 = a3;
  v265 = v8;
  v261 = a2;
  uint64_t v248 = v9;
  v270 = a6;
  v271 = a5;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLClassifierMetrics?)
                              - 8)
                  + 64);
  int64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  v232 = v210;
  uint64_t v262 = type metadata accessor for TensorShape(0);
  uint64_t v241 = *(void *)(v262 - 8);
  int64_t v13 = *(void *)(v241 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  v225 = v210;
  char v16 = alloca(v13);
  char v17 = alloca(v13);
  v238 = v210;
  uint64_t v18 = alloca(v13);
  uint64_t v19 = alloca(v13);
  v224 = v210;
  int64_t v20 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (Tensor, Tensor)?)
                              - 8)
                  + 64);
  uint64_t v21 = alloca(v20);
  char v22 = alloca(v20);
  v240 = v210;
  uint64_t v217 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (label: Tensor, weight: Tensor?));
  int64_t v23 = *(void *)(*(void *)(v217 - 8) + 64);
  uint64_t v24 = alloca(v23);
  uint64_t v25 = alloca(v23);
  v218 = v210;
  int64_t v26 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Tensor?)
                              - 8)
                  + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  v219 = (void (*)(unint64_t *, uint64_t))v210;
  char v29 = alloca(v26);
  uint64_t v30 = alloca(v26);
  v220 = v210;
  uint64_t v257 = type metadata accessor for Tensor(0);
  v267 = *(void **)(v257 - 8);
  int64_t v31 = v267[8];
  uint64_t v32 = alloca(v31);
  int64_t v33 = alloca(v31);
  v226 = v210;
  uint64_t v34 = alloca(v31);
  uint64_t v35 = alloca(v31);
  v239 = v210;
  char v36 = alloca(v31);
  uint64_t v37 = alloca(v31);
  v247 = v210;
  uint64_t v38 = alloca(v31);
  int64_t v39 = alloca(v31);
  v249 = v210;
  uint64_t v40 = alloca(v31);
  uint64_t v41 = alloca(v31);
  v237 = v210;
  uint64_t v42 = alloca(v31);
  uint64_t v43 = alloca(v31);
  v260 = v210;
  uint64_t v44 = alloca(v31);
  uint64_t v45 = alloca(v31);
  v221 = v210;
  uint64_t v46 = alloca(v31);
  uint64_t v47 = alloca(v31);
  v258 = (unint64_t *)v210;
  int v48 = alloca(v31);
  uint64_t v49 = alloca(v31);
  v251 = (unint64_t *)v210;
  uint64_t v222 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (LSTM.State?, Tensor));
  int64_t v50 = *(void *)(*(void *)(v222 - 8) + 64);
  uint64_t v51 = alloca(v50);
  unint64_t v52 = alloca(v50);
  v216 = v210;
  int64_t v53 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LSTM.State?)
                              - 8)
                  + 64);
  uint64_t v54 = alloca(v53);
  uint64_t v55 = alloca(v53);
  v235 = v210;
  uint64_t v223 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (LSTM.State, Tensor));
  int64_t v56 = *(void *)(*(void *)(v223 - 8) + 64);
  char v57 = alloca(v56);
  uint64_t v58 = alloca(v56);
  v252 = v210;
  uint64_t v259 = type metadata accessor for WeightedDataSample(0);
  int64_t v59 = *(void *)(*(void *)(v259 - 8) + 64);
  uint64_t v60 = alloca(v59);
  uint64_t v61 = alloca(v59);
  v234 = v210;
  int64_t v62 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for WeightedDataSample?)
                              - 8)
                  + 64);
  char v63 = alloca(v62);
  uint64_t v64 = alloca(v62);
  v236 = v210;
  uint64_t v227 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[WeightedDataSample]>>, WeightedDataSample>>, WeightedDataSample>.Iterator);
  int64_t v65 = *(void *)(*(void *)(v227 - 8) + 64);
  char v66 = alloca(v65);
  uint64_t v67 = alloca(v65);
  v246 = v210;
  uint64_t v230 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[WeightedDataSample], WeightedDataSample>.PrefetchMode);
  uint64_t v231 = *(void *)(v230 - 8);
  int64_t v68 = *(void *)(v231 + 64);
  double v69 = alloca(v68);
  uint64_t v70 = alloca(v68);
  v229 = v210;
  uint64_t v71 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[WeightedDataSample], WeightedDataSample>);
  uint64_t v72 = *(void *)(v71 - 8);
  int64_t v73 = *(void *)(v72 + 64);
  unsigned __int8 v74 = alloca(v73);
  BOOL v75 = alloca(v73);
  v228 = v210;
  uint64_t v76 = alloca(v73);
  uint64_t v77 = alloca(v73);
  v253 = v210;
  int64_t v78 = *(void *)(*(void *)(type metadata accessor for DataFrame(0) - 8) + 64);
  uint64_t v79 = alloca(v78);
  uint64_t v80 = alloca(v78);
  v266 = v210;
  int64_t v81 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLActivityClassifier.DataBatcher?)
                              - 8)
                  + 64);
  Swift::String v82 = alloca(v81);
  char v83 = alloca(v81);
  uint64_t v250 = (uint64_t)v210;
  uint64_t v84 = type metadata accessor for MLActivityClassifier.DataBatcher(0);
  int64_t v85 = *(void *)(*(void *)(v84 - 8) + 64);
  uint64_t v86 = alloca(v85);
  uint64_t v87 = alloca(v85);
  int64_t v88 = *(void *)(*(void *)(type metadata accessor for MLActivityClassifier.Configuration(0) - 8) + 64);
  uint64_t v89 = alloca(v88);
  uint64_t v90 = alloca(v88);
  v268 = v210;
  uint64_t v245 = type metadata accessor for MLActivityClassifier.Model(0);
  int64_t v91 = *(void *)(*(void *)(v245 - 8) + 64);
  uint64_t v92 = alloca(v91);
  uint64_t v93 = alloca(v91);
  uint64_t v264 = (uint64_t)v210;
  char v94 = *(unsigned char *)(a1 + 8);
  v242 = *(void (**)(void **, uint64_t))a1;
  char v243 = v94;
  validateAndConvertRawDataToInternalData(_:featureColumns:labelColumn:recordingFileColumn:)((uint64_t)&v242, (uint64_t)v261, (uint64_t)v273, (uint64_t)v272, (uint64_t)v271, v270, a7);
  v271 = (void *)v84;
  v254 = v210;
  uint64_t v256 = v71;
  uint64_t v255 = v72;
  uint64_t v95 = (uint64_t)v211;
  LODWORD(v84) = v212;
  uint64_t v96 = v264;
  outlined init with copy of MLActivityClassifier.Model(v248, v264, type metadata accessor for MLActivityClassifier.Model);
  uint64_t v97 = v96 + *(int *)(v245 + 64);
  uint64_t v98 = v268;
  outlined init with copy of MLActivityClassifier.Model(v97, (uint64_t)v268, type metadata accessor for MLActivityClassifier.Configuration);
  v211 = (void (*)(void **, uint64_t))v95;
  LOBYTE(v212) = v84 & 1;
  uint64_t v263 = v95;
  int v269 = v84;
  outlined copy of Result<_DataTable, Error>(v95, v84);
  DataFrame.init(_:)((uint64_t)&v211);
  v270 = (void *)v98[8];
  uint64_t v99 = v98[9];
  v273 = (void *)v98[6];
  unint64_t v100 = v98[7];
  v272 = (void (*)(uint64_t, uint64_t, uint64_t))v98[4];
  uint64_t v101 = (void *)v98[5];
  swift_bridgeObjectRetain(v99);
  swift_bridgeObjectRetain(v100);
  swift_bridgeObjectRetain((_BYTE)v101);
  uint64_t v102 = v250;
  MLActivityClassifier.DataBatcher.init(input:sessionIdColumn:labelColumn:featureColumns:windowSize:sortSessions:mode:)((uint64_t)v266, (uint64_t)v270, v99, (uint64_t)v273, v100, v101, *(double *)a7.i64, (uint64_t)v272, 0, 1);
  __swift_storeEnumTagSinglePayload(v102, 0, 1, (uint64_t)v271);
  outlined init with take of MLClassifierMetrics(v102, (uint64_t)v254, type metadata accessor for MLActivityClassifier.DataBatcher);
  uint64_t v103 = *(int *)(v245 + 60);
  uint64_t v104 = *(void (**)(void **, uint64_t))(v264 + v103);
  swift_bridgeObjectRetain((_BYTE)v104);
  uint64_t v105 = MLActivityClassifier.DataBatcher.asWeightedSamples(with:classLabels:labels:)((uint64_t)v268, v104, *(double *)a7.i64, a8);
  uint64_t v233 = 0;
  v266 = (unsigned char *)v103;
  v242 = v105;
  uint64_t v106 = (uint64_t)v268;
  v273 = (void *)*((void *)v268 + 3);
  v272 = (void (*)(uint64_t, uint64_t, uint64_t))v104;
  LOBYTE(v104) = (_BYTE)v105;
  uint64_t v107 = type metadata accessor for ShuffleSampler(0);
  uint64_t v108 = *(void *)(v106 + 8);
  LODWORD(v99) = *(unsigned __int8 *)(v106 + 16);
  swift_bridgeObjectRetain((_BYTE)v104);
  uint64_t v109 = ShuffleSampler.__allocating_init(seed:)(v108, v99);
  uint64_t v214 = v107;
  v215 = &protocol witness table for ShuffleSampler;
  v211 = (void (*)(void **, uint64_t))v109;
  uint64_t v110 = v229;
  (*(void (**)(unsigned char *, void, uint64_t))(v231 + 104))(v229, enum case for Dataset.PrefetchMode.serial<A, B>(_:), v230);
  v270 = (void *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [WeightedDataSample]);
  v271 = (void *)lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [WeightedDataSample] and conformance [A], &demangling cache variable for type metadata for [WeightedDataSample], (uint64_t)&protocol conformance descriptor for [A]);
  uint64_t v111 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type WeightedDataSample and conformance WeightedDataSample, type metadata accessor for WeightedDataSample, (uint64_t)&protocol conformance descriptor for WeightedDataSample);
  uint64_t v112 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type WeightedDataSample and conformance WeightedDataSample, type metadata accessor for WeightedDataSample, (uint64_t)&protocol conformance descriptor for WeightedDataSample);
  uint64_t v113 = v228;
  uint64_t v209 = v111;
  uint64_t v114 = v259;
  Dataset.init<>(samples:batchSize:batchSampler:dropsLastPartialBatch:prefetchMode:transform:)(&v242, v273, &v211, 0, v110, 0, 0, v270, v259, v271, v209, v112);
  swift_bridgeObjectRelease((_BYTE)v272);
  swift_bridgeObjectRelease((_BYTE)v104);
  uint64_t v115 = v256;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v255 + 32))(v253, v113, v256);
  Dataset.makeIterator()(v115);
  uint64_t v250 = *(int *)(v227 + 44);
  uint64_t v248 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[WeightedDataSample]>>, WeightedDataSample>>.Iterator and conformance Batches<A>.Iterator, &demangling cache variable for type metadata for Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[WeightedDataSample]>>, WeightedDataSample>>.Iterator, (uint64_t)&protocol conformance descriptor for Batches<A>.Iterator);
  v271 = _swiftEmptyArrayStorage;
  v273 = _swiftEmptyArrayStorage;
  while (1)
  {
    uint64_t v116 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[WeightedDataSample]>>, WeightedDataSample>>.Iterator);
    uint64_t v117 = (uint64_t)v246;
    dispatch thunk of IteratorProtocol.next()(v116, v248);
    char v118 = (char)v211;
    uint64_t v119 = (uint64_t)v216;
    if (v211)
    {
      Swift::String v120 = *(void (**)(void (**)(void **, uint64_t)))(v117 + v250);
      v242 = v211;
      uint64_t v121 = (uint64_t)v236;
      v120(&v242);
      swift_bridgeObjectRelease(v118);
      uint64_t v122 = v121;
      uint64_t v123 = 0;
    }
    else
    {
      uint64_t v121 = (uint64_t)v236;
      uint64_t v122 = (uint64_t)v236;
      uint64_t v123 = 1;
    }
    __swift_storeEnumTagSinglePayload(v122, v123, 1, v114);
    uint64_t v124 = v114;
    uint64_t v125 = (uint64_t)v266;
    uint64_t v126 = (uint64_t)v235;
    if (__swift_getEnumTagSinglePayload(v121, 1, v124) == 1) {
      break;
    }
    uint64_t v127 = (uint64_t)v234;
    outlined init with take of MLClassifierMetrics(v121, (uint64_t)v234, type metadata accessor for WeightedDataSample);
    uint64_t v128 = type metadata accessor for LSTM.State(0);
    __swift_storeEnumTagSinglePayload(v126, 1, 1, v128);
    uint64_t v129 = v119 + *(int *)(v222 + 48);
    outlined init with take of LSTM.State?(v126, v119);
    v272 = (void (*)(uint64_t, uint64_t, uint64_t))v267[2];
    uint64_t v130 = v129;
    uint64_t v131 = v257;
    v272(v130, v127, v257);
    uint64_t v132 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLActivityClassifier.Model and conformance MLActivityClassifier.Model, type metadata accessor for MLActivityClassifier.Model, (uint64_t)&protocol conformance descriptor for MLActivityClassifier.Model);
    uint64_t v133 = (uint64_t)v252;
    Layer.callAsFunction(_:)(v119, v245, v132);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v119, &demangling cache variable for type metadata for (LSTM.State?, Tensor));
    v261 = (void (*)(unint64_t *, uint64_t))(v133 + *(int *)(v223 + 48));
    uint64_t v134 = v127 + *(int *)(v259 + 20);
    uint64_t v135 = *(int *)(v217 + 48);
    uint64_t v136 = v218;
    uint64_t v137 = (uint64_t)&v218[v135];
    v272((uint64_t)v218, v134, v131);
    outlined init with copy of Tensor?(v134 + v135, v137);
    long long v138 = (unint64_t *)v221;
    v270 = (void *)v267[4];
    ((void (*)(unint64_t *, unsigned char *, uint64_t))v270)((unint64_t *)v221, v136, v131);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v137, &demangling cache variable for type metadata for Tensor?);
    uint64_t v139 = v219;
    __swift_storeEnumTagSinglePayload((uint64_t)v219, 1, 1, v131);
    uint64_t v140 = v251;
    uint64_t v141 = (uint64_t)v220;
    static MLActivityClassifier.Trainer.reshapeLabels(prediction:target:weights:)(v251, (uint64_t)v258, (uint64_t)v220, (uint64_t)v261, (void (*)(void, void, void))v138, v139);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v139, &demangling cache variable for type metadata for Tensor?);
    v261 = (void (*)(unint64_t *, uint64_t))v267[1];
    v261(v138, v131);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v141, &demangling cache variable for type metadata for Tensor?);
    v272((uint64_t)v260, (uint64_t)v140, v131);
    long long v142 = v271;
    if (!swift_isUniquelyReferenced_nonNull_native(v271)) {
      long long v142 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v142[2] + 1, 1, (uint64_t)v142);
    }
    Swift::String v143 = v237;
    unint64_t v144 = v142[2];
    uint64_t v145 = v267;
    if (v142[3] >> 1 <= v144)
    {
      uint64_t v156 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v142[3] >= 2uLL, v144 + 1, 1, (uint64_t)v142);
      uint64_t v145 = v267;
      long long v142 = v156;
    }
    v142[2] = v144 + 1;
    uint64_t v146 = (*((unsigned __int8 *)v145 + 80) + 32) & ~*((unsigned __int8 *)v145 + 80);
    v271 = v142;
    uint64_t v147 = (char *)v142 + v146;
    uint64_t v148 = v145[9];
    uint64_t v149 = &v147[v148 * v144];
    uint64_t v150 = v257;
    ((void (*)(char *, unsigned char *, uint64_t))v270)(v149, v260, v257);
    v272((uint64_t)v143, (uint64_t)v258, v150);
    if (!swift_isUniquelyReferenced_nonNull_native(v273)) {
      v273 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v273[2] + 1, 1, (uint64_t)v273);
    }
    unint64_t v151 = v273[2];
    if (v273[3] >> 1 <= v151) {
      v273 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v273[3] >= 2uLL, v151 + 1, 1, (uint64_t)v273);
    }
    uint64_t v152 = v273;
    v273[2] = v151 + 1;
    uint64_t v153 = v143;
    uint64_t v154 = v257;
    ((void (*)(char *, unsigned char *, uint64_t))v270)((char *)v152 + v146 + v148 * v151, v153, v257);
    uint64_t v155 = v261;
    v261(v258, v154);
    v155(v251, v154);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v252, &demangling cache variable for type metadata for (LSTM.State, Tensor));
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v234, type metadata accessor for WeightedDataSample);
    uint64_t v114 = v259;
  }
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v246, &demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[WeightedDataSample]>>, WeightedDataSample>>, WeightedDataSample>.Iterator);
  uint64_t v157 = *(void *)(v264 + v125);
  uint64_t v158 = v264;
  uint64_t v159 = *(void *)(v157 + 16);
  uint64_t v160 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
  swift_allocObject(v160, *(unsigned int *)(v160 + 48), *(unsigned __int16 *)(v160 + 52));
  uint64_t v161 = v233;
  uint64_t v162 = _MetricUtilities.ConfusionMatrixMeter.init(classCount:)(v159);
  if (v161)
  {
    swift_errorRelease(v161);
    swift_bridgeObjectRelease((_BYTE)v271);
    swift_bridgeObjectRelease((_BYTE)v273);
    uint64_t v163 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v164 = swift_allocError(&type metadata for MLCreateError, v163, 0, 0);
    v165._char countAndFlagsBits = 0xD000000000000010;
    v165._char object = "om the given data table." + 0x8000000000000000;
    static MLCreateError.metricNotFound(metric:)(v165);
LABEL_24:
    outlined consume of Result<_DataTable, Error>(v263, v269);
    (*(void (**)(unsigned char *, uint64_t))(v255 + 8))(v253, v256);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v254, type metadata accessor for MLActivityClassifier.DataBatcher);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v268, type metadata accessor for MLActivityClassifier.Configuration);
    outlined destroy of MLActivityClassifier.ModelParameters(v158, type metadata accessor for MLActivityClassifier.Model);
    v205 = v265;
    uint64_t *v265 = v164;
    uint64_t v206 = type metadata accessor for MLClassifierMetrics.Contents(0);
    return swift_storeEnumTagMultiPayload(v205, v206, 2);
  }
  v252 = 0;
  v260 = (unsigned char *)v162;
  v211 = (void (*)(void **, uint64_t))v271;
  uint64_t v212 = 0;
  char v166 = (char)v273;
  v213 = v273;
  uint64_t v214 = 0;
  LOBYTE(v215) = 0;
  swift_bridgeObjectRetain((_BYTE)v271);
  swift_bridgeObjectRetain(v166);
  uint64_t v167 = (uint64_t)v240;
  specialized Zip2Sequence.Iterator.next()();
  uint64_t v168 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (Tensor, Tensor));
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v167, 1, v168);
  uint64_t v170 = v257;
  uint64_t v171 = v249;
  if (EnumTagSinglePayload != 1)
  {
    v251 = (unint64_t *)v267[4];
    do
    {
      uint64_t v172 = v167 + *(int *)(v168 + 48);
      uint64_t v173 = v167;
      uint64_t v174 = v251;
      ((void (*)(unsigned char *, uint64_t, uint64_t))v251)(v171, v173, v170);
      ((void (*)(unsigned char *, uint64_t, uint64_t))v174)(v247, v172, v170);
      v258 = (unint64_t *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
      uint64_t v175 = (void *)swift_allocObject(v258, 48, 7);
      v175[2] = 2;
      v175[3] = 4;
      v175[4] = -1;
      uint64_t v176 = v224;
      Tensor.shape.getter();
      v272 = (void (*)(uint64_t, uint64_t, uint64_t))lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type TensorShape and conformance TensorShape, (uint64_t (*)(uint64_t))&type metadata accessor for TensorShape, (uint64_t)&protocol conformance descriptor for TensorShape);
      if (dispatch thunk of Collection.isEmpty.getter(v262, v272))
      {
        (*(void (**)(unsigned char *, uint64_t))(v241 + 8))(v176, v262);
        BUG();
      }
      uint64_t v177 = v262;
      unsigned int v178 = v272;
      dispatch thunk of Collection.endIndex.getter(v262, v272);
      uint64_t v259 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type TensorShape and conformance TensorShape, (uint64_t (*)(uint64_t))&type metadata accessor for TensorShape, (uint64_t)&protocol conformance descriptor for TensorShape);
      dispatch thunk of BidirectionalCollection.index(before:)(&v242, v177, v259);
      uint64_t v179 = (void (*)(void, void))dispatch thunk of Collection.subscript.read(&v242, v244, v177, v178);
      uint64_t v181 = *v180;
      v179(&v242, 0);
      uint64_t v182 = *(double (**)(unsigned char *, uint64_t))(v241 + 8);
      double v183 = v182(v176, v177);
      v175[5] = v181;
      uint64_t v184 = v238;
      TensorShape.init(_:)(v175, v183);
      Tensor.reshaped(to:)(v184);
      v270 = v182;
      v182(v184, v177);
      uint64_t v185 = (void *)swift_allocObject(v258, 48, 7);
      v185[2] = 2;
      v185[3] = 4;
      v185[4] = -1;
      uint64_t v186 = v225;
      Tensor.shape.getter();
      if (dispatch thunk of Collection.isEmpty.getter(v177, v272))
      {
        ((void (*)(unsigned char *, uint64_t))v270)(v186, v262);
        BUG();
      }
      uint64_t v187 = v262;
      char v188 = v272;
      dispatch thunk of Collection.endIndex.getter(v262, v272);
      dispatch thunk of BidirectionalCollection.index(before:)(&v242, v187, v259);
      uint64_t v189 = (void (*)(void, void))dispatch thunk of Collection.subscript.read(&v242, v244, v187, v188);
      uint64_t v191 = *v190;
      v189(&v242, 0);
      uint64_t v192 = v186;
      v193 = (void (*)(unsigned char *, uint64_t))v270;
      *(double *)a7.i64 = ((double (*)(unsigned char *, uint64_t))v270)(v192, v187);
      v185[5] = v191;
      char v194 = v238;
      TensorShape.init(_:)(v185, *(double *)a7.i64);
      uint64_t v195 = (uint64_t)v226;
      Tensor.reshaped(to:)(v194);
      v193(v194, v187);
      uint64_t v196 = (uint64_t)v239;
      _MetricUtilities.ConfusionMatrixMeter.add(predicted:target:)((uint64_t)v239, v195);
      uint64_t v197 = (void (*)(uint64_t, uint64_t))v267[1];
      uint64_t v170 = v257;
      v197(v195, v257);
      v197(v196, v170);
      v197((uint64_t)v247, v170);
      uint64_t v171 = v249;
      v197((uint64_t)v249, v170);
      uint64_t v167 = (uint64_t)v240;
      specialized Zip2Sequence.Iterator.next()();
      uint64_t v168 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (Tensor, Tensor));
    }
    while (__swift_getEnumTagSinglePayload(v167, 1, v168) != 1);
  }
  swift_bridgeObjectRelease((_BYTE)v211);
  char v198 = (char)v213;
  swift_bridgeObjectRelease((_BYTE)v271);
  swift_bridgeObjectRelease((_BYTE)v273);
  swift_bridgeObjectRelease(v198);
  uint64_t v158 = v264;
  uint64_t v199 = *(void *)&v266[v264];
  swift_bridgeObjectRetain(v199);
  uint64_t v200 = (uint64_t)v232;
  uint64_t v201 = (uint64_t)v252;
  static _MetricUtilities.makeClassifierMetrics(confusionMeter:classLabels:)(*(double *)a7.i64, a8, (uint64_t)v260, v199);
  if (v201)
  {
    swift_errorRelease(v201);
    swift_bridgeObjectRelease(v199);
    uint64_t v202 = type metadata accessor for MLClassifierMetrics(0);
    __swift_storeEnumTagSinglePayload(v200, 1, 1, v202);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v200, &demangling cache variable for type metadata for MLClassifierMetrics?);
    uint64_t v203 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v164 = swift_allocError(&type metadata for MLCreateError, v203, 0, 0);
    v204._char countAndFlagsBits = 0xD000000000000012;
    v204._char object = "confusion matrix" + 0x8000000000000000;
    static MLCreateError.metricNotFound(metric:)(v204);
    swift_release();
    goto LABEL_24;
  }
  swift_bridgeObjectRelease(v199);
  uint64_t v208 = type metadata accessor for MLClassifierMetrics(0);
  __swift_storeEnumTagSinglePayload(v200, 0, 1, v208);
  swift_release();
  outlined consume of Result<_DataTable, Error>(v263, v269);
  (*(void (**)(unsigned char *, uint64_t))(v255 + 8))(v253, v256);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v254, type metadata accessor for MLActivityClassifier.DataBatcher);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v268, type metadata accessor for MLActivityClassifier.Configuration);
  outlined destroy of MLActivityClassifier.ModelParameters(v158, type metadata accessor for MLActivityClassifier.Model);
  return outlined init with take of MLClassifierMetrics(v200, (uint64_t)v265, type metadata accessor for MLClassifierMetrics);
}

uint64_t MLActivityClassifier.evaluation(on:featureColumns:labelColumn:recordingFileColumn:)(__m128 a1, double a2, uint64_t a3, void (*a4)(unint64_t *, uint64_t), void (*a5)(uint64_t, uint64_t, uint64_t), uint64_t *a6, void *a7, void *a8)
{
  uint64_t v20 = v8;
  uint64_t v11 = (uint64_t)a7;
  char v22 = a5;
  MLActivityClassifier.DataSource.labeledSensorData(featureColumns:labelColumn:recordingFileColumn:)((uint64_t)a4, (uint64_t)a5, a6, a7, a8, a1);
  uint64_t v17 = v18;
  int v21 = v19;
  uint64_t v12 = (uint64_t)v22;
  if (!a6) {
    uint64_t v12 = 0x6C6562616CLL;
  }
  int64_t v13 = (void (*)(uint64_t, uint64_t, uint64_t))0xE500000000000000;
  if (a6) {
    int64_t v13 = (void (*)(uint64_t, uint64_t, uint64_t))a6;
  }
  char v22 = v13;
  if (!a8) {
    uint64_t v11 = 0x6E6964726F636572;
  }
  uint64_t v14 = (void *)0xED0000656C694667;
  if (a8) {
    uint64_t v14 = a8;
  }
  swift_bridgeObjectRetain((_BYTE)a6);
  swift_bridgeObjectRetain((_BYTE)a8);
  char v15 = (char)v22;
  MLActivityClassifier.evaluation(on:featureColumns:labelColumn:recordingFileColumn:)((uint64_t)&v18, a4, (void *)v12, v22, (void *)v11, v14, a1, a2);
  swift_bridgeObjectRelease((_BYTE)v14);
  swift_bridgeObjectRelease(v15);
  return outlined consume of Result<_DataTable, Error>(v17, v21);
}

uint64_t specialized Sequence<>.makeDataset(configuration:)(uint64_t a1, uint64_t a2)
{
  v16[2] = v2;
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[WeightedDataSample], WeightedDataSample>.PrefetchMode);
  uint64_t v20 = *(void *)(v19 - 8);
  int64_t v3 = *(void *)(v20 + 64);
  unint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v18 = v15;
  v16[0] = a2;
  uint64_t v17 = *(void *)(a1 + 24);
  uint64_t v6 = type metadata accessor for ShuffleSampler(0);
  uint64_t v7 = *(void *)(a1 + 8);
  unsigned int v8 = *(unsigned __int8 *)(a1 + 16);
  swift_bridgeObjectRetain(a2);
  uint64_t v9 = ShuffleSampler.__allocating_init(seed:)(v7, v8);
  v15[3] = v6;
  v15[4] = &protocol witness table for ShuffleSampler;
  v15[0] = v9;
  int64_t v10 = v18;
  (*(void (**)(void *, void, uint64_t))(v20 + 104))(v18, enum case for Dataset.PrefetchMode.serial<A, B>(_:), v19);
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [WeightedDataSample]);
  uint64_t v20 = type metadata accessor for WeightedDataSample(0);
  uint64_t v11 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [WeightedDataSample] and conformance [A], &demangling cache variable for type metadata for [WeightedDataSample], (uint64_t)&protocol conformance descriptor for [A]);
  uint64_t v12 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type WeightedDataSample and conformance WeightedDataSample, type metadata accessor for WeightedDataSample, (uint64_t)&protocol conformance descriptor for WeightedDataSample);
  uint64_t v13 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type WeightedDataSample and conformance WeightedDataSample, type metadata accessor for WeightedDataSample, (uint64_t)&protocol conformance descriptor for WeightedDataSample);
  return Dataset.init<>(samples:batchSize:batchSampler:dropsLastPartialBatch:prefetchMode:transform:)(v16, v17, v15, 0, v10, 0, 0, v19, v20, v11, v12, v13);
}

uint64_t outlined init with copy of MLActivityClassifier.Model(uint64_t a1, uint64_t a2, uint64_t (*a3)(void))
{
  uint64_t v3 = a3(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v3 - 8) + 16))(a2, a1, v3);
  return a2;
}

uint64_t *initializeBufferWithCopyOfBuffer for MLFewShotSoundClassifier.DataSource(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v6 = *a2;
    *uint64_t v3 = *a2;
    uint64_t v3 = (uint64_t *)(v6 + ((v4 + 16) & ~v4));
    swift_retain(v6);
  }
  else
  {
    uint64_t v5 = type metadata accessor for URL(0);
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v5 - 8) + 16))(a1, a2, v5);
  }
  return v3;
}

uint64_t destroy for MLFewShotSoundClassifier.DataSource(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for URL(0);
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
}

uint64_t initializeWithCopy for MLFewShotSoundClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for URL(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a1, a2, v2);
  return a1;
}

uint64_t assignWithCopy for MLFewShotSoundClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for URL(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 24))(a1, a2, v2);
  return a1;
}

uint64_t initializeWithTake for MLFewShotSoundClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for URL(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a1, a2, v2);
  return a1;
}

uint64_t assignWithTake for MLFewShotSoundClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for URL(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 40))(a1, a2, v2);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLFewShotSoundClassifier.DataSource(uint64_t a1, unsigned int a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL));
  return __swift_getEnumTagSinglePayload(a1, a2, v2);
}

uint64_t storeEnumTagSinglePayload for MLFewShotSoundClassifier.DataSource(uint64_t a1, unsigned int a2, unsigned int a3)
{
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL));
  return __swift_storeEnumTagSinglePayload(a1, a2, a3, v4);
}

uint64_t type metadata accessor for MLFewShotSoundClassifier.DataSource(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLFewShotSoundClassifier.DataSource;
  if (!type metadata singleton initialization cache for MLFewShotSoundClassifier.DataSource) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLFewShotSoundClassifier.DataSource);
  }
  return result;
}

uint64_t type metadata completion function for MLFewShotSoundClassifier.DataSource(uint64_t a1)
{
  uint64_t result = type metadata accessor for URL(319);
  if (v2 <= 0x3F)
  {
    uint64_t v3 = *(void *)(result - 8);
    swift_initEnumMetadataSingleCase(a1, 256, v3 + 64);
    *(_DWORD *)(*(void *)(a1 - 8) + 84) = *(_DWORD *)(v3 + 84);
    return 0;
  }
  return result;
}

uint64_t *MLFewShotSoundClassifier.DataSource.extractFeatures(with:)(void *a1)
{
  uint64_t v32 = v1;
  uint64_t v27 = v2;
  int64_t v26 = a1;
  uint64_t v28 = type metadata accessor for UTType(0);
  uint64_t v29 = *(void *)(v28 - 8);
  int64_t v3 = *(void *)(v29 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v6 = type metadata accessor for URL(0);
  uint64_t v30 = *(void *)(v6 - 8);
  int64_t v7 = *(void *)(v30 + 64);
  unsigned int v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  int64_t v10 = &v25;
  int64_t v11 = *(void *)(*(void *)(type metadata accessor for MLFewShotSoundClassifier.DataSource(0) - 8) + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  outlined init with copy of MLFewShotSoundClassifier.DataSource(v27, (uint64_t)&v25);
  uint64_t v31 = v6;
  uint64_t v14 = v6;
  uint64_t v15 = v30;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v30 + 32))(&v25, &v25, v14);
  static UTType.audio.getter();
  char v16 = v32;
  uint64_t v17 = static _FileUtilities.readableFiles(at:type:)((uint64_t)&v25, (uint64_t)&v25);
  if (v16)
  {
    (*(void (**)(uint64_t *, uint64_t))(v29 + 8))(&v25, v28);
    (*(void (**)(uint64_t *, uint64_t))(v15 + 8))(&v25, v31);
  }
  else
  {
    uint64_t v32 = &v25;
    uint64_t v19 = (uint64_t)v17;
    (*(void (**)(uint64_t *, uint64_t))(v29 + 8))(&v25, v28);
    if (*(void *)(v19 + 16))
    {
      int64_t v10 = (uint64_t *)MLFewShotSoundClassifier.DataSource.extractFeatures(with:from:)(v26, v19);
      (*(void (**)(uint64_t *, uint64_t))(v30 + 8))(v32, v31);
      swift_bridgeObjectRelease(v19);
    }
    else
    {
      swift_bridgeObjectRelease(v19);
      uint64_t v20 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v20, 0, 0);
      *(void *)uint64_t v21 = 0xD00000000000002ELL;
      *(void *)(v21 + 8) = "om the given data source." + 0x8000000000000000;
      *(_OWORD *)(v21 + 16) = 0;
      *(_OWORD *)(v21 + 32) = 0;
      *(unsigned char *)(v21 + 48) = 2;
      swift_willThrow(&type metadata for MLCreateError, v20, v21, v22, v23, v24);
      (*(void (**)(uint64_t *, uint64_t))(v30 + 8))(v32, v31);
    }
  }
  return v10;
}

uint64_t outlined init with copy of MLFewShotSoundClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLFewShotSoundClassifier.DataSource(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

unint64_t MLFewShotSoundClassifier.DataSource.extractFeatures(with:from:)(void *a1, uint64_t a2)
{
  uint64_t v92 = v2;
  uint64_t v101 = a2;
  id v103 = a1;
  uint64_t v98 = type metadata accessor for DispatchTimeInterval(0);
  uint64_t v88 = *(void *)(v98 - 8);
  int64_t v3 = *(void *)(v88 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v99 = v85;
  uint64_t v87 = type metadata accessor for DispatchTime(0);
  uint64_t v89 = *(void *)(v87 - 8);
  int64_t v6 = *(void *)(v89 + 64);
  int64_t v7 = alloca(v6);
  unsigned int v8 = alloca(v6);
  uint64_t v93 = v85;
  uint64_t v9 = alloca(v6);
  int64_t v10 = alloca(v6);
  uint64_t v90 = v85;
  id v102 = (id)type metadata accessor for OS_dispatch_queue.AutoreleaseFrequency(0);
  id v94 = (id)*((void *)v102 - 1);
  int64_t v11 = *((void *)v94 + 8);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  id isa = v85;
  uint64_t v14 = type metadata accessor for OS_dispatch_queue.Attributes(0);
  int64_t v15 = *(void *)(*(void *)(v14 - 8) + 64);
  char v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  int64_t v18 = *(void *)(*(void *)(type metadata accessor for DispatchQoS(0) - 8) + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v97 = v85;
  id v91 = dispatch_semaphore_create(0);
  id v96 = (id)type metadata accessor for OS_dispatch_queue(0, &lazy cache variable for type metadata for OS_dispatch_queue, OS_dispatch_queue_ptr);
  static DispatchQoS.default.getter();
  aBlock[0] = _swiftEmptyArrayStorage;
  uint64_t v21 = lazy protocol witness table accessor for type OS_dispatch_queue.Attributes and conformance OS_dispatch_queue.Attributes();
  uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [OS_dispatch_queue.Attributes]);
  uint64_t v23 = lazy protocol witness table accessor for type [OS_dispatch_queue.Attributes] and conformance [A]();
  dispatch thunk of SetAlgebra.init<A>(_:)(aBlock, v22, v23, v14, v21);
  id v24 = isa;
  (*((void (**)(id, void, id))v94 + 13))(isa, enum case for OS_dispatch_queue.AutoreleaseFrequency.inherit(_:), v102);
  id v102 = (id)OS_dispatch_queue.init(label:qos:attributes:autoreleaseFrequency:target:)(0xD00000000000003DLL, "o files provided for training." + 0x8000000000000000, v97, v85, v24, 0);
  uint64_t v25 = swift_allocObject(&unk_399070, 24, 7);
  *(void *)(v25 + 16) = 0;
  uint64_t v26 = swift_allocObject(&unk_399098, 24, 7);
  *(void *)(v26 + 16) = 0;
  id v94 = (id)objc_opt_self(SNKShotFeaturizer);
  type metadata accessor for URL(0);
  id isa = Array._bridgeToObjectiveC()().super.isa;
  URL._bridgeToObjectiveC()((NSURL *)isa);
  id v96 = v27;
  uint64_t v28 = (void *)swift_allocObject(&unk_3990C0, 40, 7);
  v28[2] = v25;
  v28[3] = v26;
  id v29 = v91;
  v28[4] = v91;
  aBlock[4] = partial apply for closure #1 in MLFewShotSoundClassifier.DataSource.extractFeatures(with:from:);
  aBlock[5] = v28;
  aBlock[0] = _NSConcreteStackBlock;
  aBlock[1] = 1107296256;
  aBlock[2] = thunk for @escaping @callee_guaranteed (@guaranteed SNKShotFeaturizationResult?, @guaranteed Error?) -> ();
  aBlock[3] = &block_descriptor_4;
  uint64_t v97 = _Block_copy(aBlock);
  uint64_t v101 = v25;
  swift_retain();
  uint64_t v100 = v26;
  swift_retain();
  id v103 = v29;
  swift_release();
  id v30 = isa;
  id v31 = v96;
  uint64_t v32 = v97;
  id v33 = [v94 featurizeFiles:isa hallucinatorModelURL:v96 queue:v102 completionHandler:v97];
  id v34 = v33;
  _Block_release(v32);
  swift_unknownObjectRelease(v34);

  static DispatchTime.now()();
  uint64_t v35 = v99;
  *uint64_t v99 = 600;
  uint64_t v36 = v88;
  (*(void (**)(void *, void, uint64_t))(v88 + 104))(v35, enum case for DispatchTimeInterval.seconds(_:), v98);
  uint64_t v37 = v90;
  DispatchTime.advanced(by:)(v35);
  (*(void (**)(void *, uint64_t))(v36 + 8))(v99, v98);
  uint64_t v38 = *(void (**)(unsigned char *, uint64_t))(v89 + 8);
  uint64_t v39 = v87;
  v38(v93, v87);
  unint64_t v40 = OS_dispatch_semaphore.wait(timeout:)(v37);
  v38(v37, v39);
  if (v40)
  {
    uint64_t v60 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v60, 0, 0);
    *(void *)uint64_t v61 = 0xD00000000000001ELL;
    *(void *)(v61 + 8) = "lt\"8@\"NSError\"16" + 0x8000000000000000;
    *(_OWORD *)(v61 + 16) = 0;
    *(_OWORD *)(v61 + 32) = 0;
    *(unsigned char *)(v61 + 48) = 2;
    swift_willThrow(&type metadata for MLCreateError, v60, v61, v62, v63, v64);
    swift_release();
LABEL_23:
    swift_release();
LABEL_27:
    id v79 = v102;

    return v40;
  }
  uint64_t v41 = (id *)(v101 + 16);
  swift_beginAccess(v101 + 16, aBlock, 0, 0);
  if (!*v41)
  {
    int64_t v65 = (ValueMetadata **)(v100 + 16);
    char v66 = v85;
    swift_beginAccess(v100 + 16, v85, 0, 0);
    uint64_t v67 = *v65;
    if (v67)
    {
      int64_t v68 = v67;
      swift_errorRetain(v67);
    }
    else
    {
      int64_t v68 = &type metadata for MLCreateError;
      char v66 = (unsigned char *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v66, 0, 0);
      *(void *)uint64_t v69 = 0xD000000000000029;
      *(void *)(v69 + 8) = "timed out retrieving features." + 0x8000000000000000;
      *(_OWORD *)(v69 + 16) = 0;
      *(_OWORD *)(v69 + 32) = 0;
      *(unsigned char *)(v69 + 48) = 2;
    }
    swift_willThrow(v68, v66, v69, v70, v71, v72);
    swift_release();
    goto LABEL_23;
  }
  id v42 = *v41;
  id v43 = [v42 trainingDataEmbeddings];
  id v44 = v43;
  uint64_t v98 = type metadata accessor for OS_dispatch_queue(0, &lazy cache variable for type metadata for MLMultiArray, MLMultiArray_ptr);
  uint64_t v45 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v44, v98);

  if ((v45 & 0x4000000000000001) != 0)
  {
    uint64_t v81 = v45 & 0xFFFFFFFFFFFFF8;
    if (v45) {
      uint64_t v81 = v45;
    }
    swift_bridgeObjectRetain(v45);
    uint64_t v46 = _CocoaArrayWrapper.endIndex.getter(v81);
    swift_bridgeObjectRelease(v45);
  }
  else
  {
    uint64_t v46 = *(void *)((char *)&dword_10 + (v45 & 0xFFFFFFFFFFFFF8));
  }
  swift_bridgeObjectRelease(v45);
  unint64_t v40 = (unint64_t)v42;
  if (!v46)
  {
    uint64_t v73 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v73, 0, 0);
    *(void *)uint64_t v74 = 0xD000000000000036;
    int64_t v78 = "trieved features.";
LABEL_26:
    *(void *)(v74 + 8) = (unint64_t)v78 | 0x8000000000000000;
    *(_OWORD *)(v74 + 16) = 0;
    *(_OWORD *)(v74 + 32) = 0;
    *(unsigned char *)(v74 + 48) = 2;
    swift_willThrow(&type metadata for MLCreateError, v73, v74, v75, v76, v77);
    swift_release();
    swift_release();

    goto LABEL_27;
  }
  id v47 = [v42 trainingDataLabels];
  id v48 = v47;
  uint64_t v49 = type metadata accessor for OS_dispatch_queue(0, &lazy cache variable for type metadata for NSNumber, NSNumber_ptr);
  uint64_t v50 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v48, v49);

  if ((v50 & 0x4000000000000001) != 0)
  {
    uint64_t v82 = v50 & 0xFFFFFFFFFFFFF8;
    if (v50) {
      uint64_t v82 = v50;
    }
    swift_bridgeObjectRetain(v50);
    uint64_t v51 = _CocoaArrayWrapper.endIndex.getter(v82);
    swift_bridgeObjectRelease(v50);
  }
  else
  {
    uint64_t v51 = *(void *)((char *)&dword_10 + (v50 & 0xFFFFFFFFFFFFF8));
  }
  swift_bridgeObjectRelease(v50);
  if (!v51)
  {
    uint64_t v73 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v73, 0, 0);
    *(void *)uint64_t v74 = 0xD000000000000031;
    int64_t v78 = "s in retrieved features.";
    goto LABEL_26;
  }
  uint64_t v99 = (void *)v49;
  id v52 = [(id)v40 validationDataEmbeddings];
  id v53 = v52;
  uint64_t v54 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v53, v98);

  if ((v54 & 0x4000000000000001) != 0)
  {
    uint64_t v83 = v54 & 0xFFFFFFFFFFFFF8;
    if (v54) {
      uint64_t v83 = v54;
    }
    swift_bridgeObjectRetain(v54);
    uint64_t v55 = _CocoaArrayWrapper.endIndex.getter(v83);
    swift_bridgeObjectRelease(v54);
  }
  else
  {
    uint64_t v55 = *(void *)((char *)&dword_10 + (v54 & 0xFFFFFFFFFFFFF8));
  }
  swift_bridgeObjectRelease(v54);
  if (!v55)
  {
    uint64_t v73 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v73, 0, 0);
    *(void *)uint64_t v74 = 0xD000000000000038;
    int64_t v78 = "retrieved features.";
    goto LABEL_26;
  }
  id v56 = [(id)v40 validationDataLabels];
  id v57 = v56;
  uint64_t v58 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v57, v99);

  if ((v58 & 0x4000000000000001) != 0)
  {
    uint64_t v84 = v58 & 0xFFFFFFFFFFFFF8;
    if (v58) {
      uint64_t v84 = v58;
    }
    swift_bridgeObjectRetain(v58);
    uint64_t v59 = _CocoaArrayWrapper.endIndex.getter(v84);
    swift_bridgeObjectRelease(v58);
  }
  else
  {
    uint64_t v59 = *(void *)((char *)&dword_10 + (v58 & 0xFFFFFFFFFFFFF8));
  }
  swift_bridgeObjectRelease(v58);
  if (!v59)
  {
    uint64_t v73 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v73, 0, 0);
    *(void *)uint64_t v74 = 0xD000000000000033;
    int64_t v78 = "rown from Sound Analysis.";
    goto LABEL_26;
  }

  swift_release();
  swift_release();
  return v40;
}

uint64_t lazy protocol witness table accessor for type OS_dispatch_queue.Attributes and conformance OS_dispatch_queue.Attributes()
{
  uint64_t result = lazy protocol witness table cache variable for type OS_dispatch_queue.Attributes and conformance OS_dispatch_queue.Attributes;
  if (!lazy protocol witness table cache variable for type OS_dispatch_queue.Attributes and conformance OS_dispatch_queue.Attributes)
  {
    uint64_t v1 = type metadata accessor for OS_dispatch_queue.Attributes(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for OS_dispatch_queue.Attributes, v1);
    lazy protocol witness table cache variable for type OS_dispatch_queue.Attributes and conformance OS_dispatch_queue.Attributes = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type [OS_dispatch_queue.Attributes] and conformance [A]()
{
  uint64_t result = lazy protocol witness table cache variable for type [OS_dispatch_queue.Attributes] and conformance [A];
  if (!lazy protocol witness table cache variable for type [OS_dispatch_queue.Attributes] and conformance [A])
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [OS_dispatch_queue.Attributes]);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for [A], v1);
    lazy protocol witness table cache variable for type [OS_dispatch_queue.Attributes] and conformance [A] = result;
  }
  return result;
}

uint64_t sub_110342()
{
  return swift_deallocObject(v0, 24, 7);
}

uint64_t sub_11035F()
{
  swift_errorRelease(*(void *)(v0 + 16));
  return swift_deallocObject(v0, 24, 7);
}

Swift::Int closure #1 in MLFewShotSoundClassifier.DataSource.extractFeatures(with:from:)(id a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v12 = a5;
  uint64_t v13 = a4 + 16;
  swift_beginAccess(a3 + 16, v10, 1, 0);
  int64_t v7 = *(void **)(a3 + 16);
  *(void *)(a3 + 16) = a1;
  a1;

  swift_beginAccess(v13, v11, 1, 0);
  uint64_t v8 = *(void *)(a4 + 16);
  *(void *)(a4 + 16) = a2;
  swift_errorRetain(a2);
  swift_errorRelease(v8);
  return OS_dispatch_semaphore.signal()();
}

uint64_t sub_110412()
{
  swift_release(*(void *)(v0 + 16));
  swift_release(*(void *)(v0 + 24));

  return swift_deallocObject(v0, 40, 7);
}

Swift::Int partial apply for closure #1 in MLFewShotSoundClassifier.DataSource.extractFeatures(with:from:)(void *a1, uint64_t a2)
{
  return closure #1 in MLFewShotSoundClassifier.DataSource.extractFeatures(with:from:)(a1, a2, v2[2], v2[3], v2[4]);
}

void thunk for @escaping @callee_guaranteed (@guaranteed SNKShotFeaturizationResult?, @guaranteed Error?) -> ()(uint64_t a1, void *a2, void *a3)
{
  int64_t v7 = *(void (**)(void *, void *))(a1 + 32);
  uint64_t v4 = *(void *)(a1 + 40);
  swift_retain(v4);
  id v5 = a2;
  id v6 = a3;
  v7(a2, a3);
  swift_release(v4);
}

uint64_t block_copy_helper_3(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 40);
  *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
  return swift_retain(v2);
}

uint64_t type metadata accessor for OS_dispatch_queue(uint64_t a1, uint64_t *a2, void *a3)
{
  uint64_t result = *a2;
  if (!*a2)
  {
    uint64_t v4 = objc_opt_self(*a3);
    uint64_t result = swift_getObjCClassMetadata(v4);
    *a2 = result;
  }
  return result;
}

uint64_t *initializeBufferWithCopyOfBuffer for MLImageClassifier.Model(uint64_t *a1, uint64_t *a2)
{
  uint64_t v2 = a1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int v4 = *(_DWORD *)(*(void *)(v3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v8 = *a2;
    *uint64_t v2 = *a2;
    uint64_t v2 = (uint64_t *)(v8 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    if (swift_getEnumCaseMultiPayload(a2, v3) == 1)
    {
      uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v5 - 8) + 16))(a1, a2, v5);
      uint64_t v6 = 1;
      uint64_t v7 = v3;
    }
    else
    {
      uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v9 - 8) + 16))(a1, a2, v9);
      uint64_t v7 = v3;
      uint64_t v6 = 0;
    }
    swift_storeEnumTagMultiPayload(a1, v7, v6);
  }
  return v2;
}

uint64_t destroy for MLImageClassifier.Model(uint64_t a1)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a1, v2);
  int v4 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (EnumCaseMultiPayload == 1) {
    int v4 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(v4);
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8))(a1, v5);
}

uint64_t initializeWithCopy for MLImageClassifier.Model(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, v3);
  BOOL v5 = EnumCaseMultiPayload == 1;
  uint64_t v6 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (EnumCaseMultiPayload == 1) {
    uint64_t v6 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(v6);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v7 - 8) + 16))(a1, a2, v7);
  swift_storeEnumTagMultiPayload(a1, v3, v5);
  return a1;
}

uint64_t assignWithCopy for MLImageClassifier.Model(uint64_t a1, uint64_t a2)
{
  if (a1 != a2)
  {
    outlined destroy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(a1);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, v3);
    BOOL v5 = EnumCaseMultiPayload == 1;
    uint64_t v6 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
    if (EnumCaseMultiPayload == 1) {
      uint64_t v6 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
    }
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(v6);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v7 - 8) + 16))(a1, a2, v7);
    swift_storeEnumTagMultiPayload(a1, v3, v5);
  }
  return a1;
}

uint64_t initializeWithTake for MLImageClassifier.Model(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, v3);
  BOOL v5 = EnumCaseMultiPayload == 1;
  uint64_t v6 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (EnumCaseMultiPayload == 1) {
    uint64_t v6 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(v6);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v7 - 8) + 32))(a1, a2, v7);
  swift_storeEnumTagMultiPayload(a1, v3, v5);
  return a1;
}

uint64_t assignWithTake for MLImageClassifier.Model(uint64_t a1, uint64_t a2)
{
  if (a1 != a2)
  {
    outlined destroy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(a1);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, v3);
    BOOL v5 = EnumCaseMultiPayload == 1;
    uint64_t v6 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
    if (EnumCaseMultiPayload == 1) {
      uint64_t v6 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
    }
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(v6);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v7 - 8) + 32))(a1, a2, v7);
    swift_storeEnumTagMultiPayload(a1, v3, v5);
  }
  return a1;
}

uint64_t getEnumTagSinglePayload for MLImageClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_110839);
}

uint64_t sub_110839(uint64_t a1, unsigned int a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  return __swift_getEnumTagSinglePayload(a1, a2, v2);
}

uint64_t storeEnumTagSinglePayload for MLImageClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_110882);
}

uint64_t sub_110882(uint64_t a1, unsigned int a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  return __swift_storeEnumTagSinglePayload(a1, a2, a2, v2);
}

uint64_t type metadata accessor for MLImageClassifier.Model(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLImageClassifier.Model;
  if (!type metadata singleton initialization cache for MLImageClassifier.Model) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLImageClassifier.Model);
  }
  return result;
}

uint64_t type metadata completion function for MLImageClassifier.Model(uint64_t a1)
{
  uint64_t v4 = v1;
  uint64_t result = type metadata accessor for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(319);
  if (v3 <= 0x3F)
  {
    uint64_t v4 = *(void *)(result - 8) + 64;
    swift_initStructMetadata(a1, 256, 1, &v4, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t __swift_instantiateConcreteTypeFromMangledNameAbstract(uint64_t *a1)
{
  uint64_t result = *a1;
  if (*a1 < 0)
  {
    uint64_t result = swift_getTypeByMangledNameInContextInMetadataState2(255, (char *)a1 + (int)result, -(result >> 32), 0, 0);
    *a1 = result;
  }
  return result;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay20MLModelSpecification5ModelVG_Sis5NeverOTg5032_s8CreateML17MLImageClassifierV5f41V6export8metadata20featureExtractorType20dE92ADVAA0K8MetadataV_AC07FeatureiJ0OtKFSiAJcfu_32b63bdf5f6c975d31a36a8f37561ba444AJSiTf3nnnpk_nTf1cn_n(uint64_t a1)
{
  int64_t v1 = *(void *)(a1 + 16);
  if (v1)
  {
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0);
    uint64_t v2 = *(void *)(type metadata accessor for Model(0) - 8);
    uint64_t v3 = ((*(unsigned __int8 *)(v2 + 80) + 32) & ~*(unsigned __int8 *)(v2 + 80)) + a1;
    uint64_t v9 = *(void *)(v2 + 72);
    do
    {
      int64_t v8 = v1;
      uint64_t v4 = Model.specificationVersion.getter();
      unint64_t v5 = _swiftEmptyArrayStorage[2];
      int64_t v6 = v5 + 1;
      if (_swiftEmptyArrayStorage[3] >> 1 <= v5)
      {
        uint64_t v10 = v4;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v6, 1);
        uint64_t v4 = v10;
      }
      _swiftEmptyArrayStorage[2] = v6;
      _swiftEmptyArrayStorage[v5 + 4] = v4;
      v3 += v9;
      int64_t v1 = v8 - 1;
    }
    while (v8 != 1);
  }
  return _swiftEmptyArrayStorage;
}

void MLImageClassifier.Model.export(metadata:featureExtractorType:)(uint64_t *a1, uint64_t a2)
{
  uint64_t v47 = v3;
  uint64_t v44 = v4;
  uint64_t v45 = a2;
  uint64_t v5 = v2;
  uint64_t v6 = type metadata accessor for Model(0);
  uint64_t v7 = *(void *)(v6 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  id v34 = &v32;
  uint64_t v37 = *a1;
  uint64_t v38 = a1[1];
  uint64_t v41 = a1[2];
  uint64_t v42 = a1[3];
  uint64_t v35 = a1[4];
  unint64_t v36 = a1[5];
  uint64_t v39 = a1[6];
  uint64_t v40 = a1[7];
  uint64_t v46 = (void (*)(unsigned char *, void))a1[8];
  MLImageClassifier.Model.createPipelineModel(featureExtractorType:)(a2, a2);
  if (!v3)
  {
    uint64_t v45 = v6;
    uint64_t v44 = v7;
    uint64_t v47 = 0;
    uint64_t v11 = v42;
    swift_bridgeObjectRetain(v42);
    Model.modelDescription.setter(v41, v11);
    uint64_t v12 = v40;
    swift_bridgeObjectRetain(v40);
    Model.versionString.setter(v39, v12);
    uint64_t v13 = v38;
    swift_bridgeObjectRetain(v38);
    Model.author.setter(v37, v13);
    uint64_t v14 = v35;
    if (!v36) {
      uint64_t v14 = 0;
    }
    unint64_t v15 = 0xE000000000000000;
    if (v36) {
      unint64_t v15 = v36;
    }
    swift_bridgeObjectRetain(v36);
    Model.license.setter(v14, v15);
    char v16 = (char)v46;
    if (v46)
    {
      uint64_t v17 = (uint64_t)v46;
    }
    else
    {
      uint64_t v17 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for String, &protocol witness table for String);
      char v16 = 0;
    }
    swift_bridgeObjectRetain(v16);
    Model.metadata.setter(v17);
    Swift::String v18 = getOSVersion()();
    uint64_t countAndFlagsBits = v18._countAndFlagsBits;
    char object = v18._object;
    uint64_t v21 = v5;
    uint64_t v43 = v5;
    uint64_t v46 = (void (*)(unsigned char *, void))Model.metadata.modify(v33);
    specialized Dictionary._Variant.setValue(_:forKey:)(countAndFlagsBits, (uint64_t)object, 0xD00000000000001ALL, (uint64_t)("Recommender Model" + 0x8000000000000000));
    v46(v33, 0);
    uint64_t v22 = v34;
    uint64_t v23 = v21;
    uint64_t v24 = v45;
    uint64_t v25 = v44;
    (*(void (**)(uint64_t *, uint64_t, uint64_t))(v44 + 16))(v34, v23, v45);
    uint64_t v26 = Model.nestedModels.getter();
    (*(void (**)(uint64_t *, uint64_t))(v25 + 8))(v22, v24);
    uint64_t v27 = v47;
    ML17MLImageClassifierV5f41V6export8metadata20featureExtractorType20dE92ADVAA0K8MetadataV_AC07FeatureiJ0OtKFSiAJcfu_32b63bdf5f6c975d31a36a8f37561ba444AJSiTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay20MLModelSpecification5ModelVG_Sis5NeverOTg5032_s8CreateML17MLImageClassifierV5f41V6export8metadata20featureExtractorType20dE92ADVAA0K8MetadataV_AC07FeatureiJ0OtKFSiAJcfu_32b63bdf5f6c975d31a36a8f37561ba444AJSiTf3nnnpk_nTf1cn_n(v26);
    uint64_t v47 = v27;
    swift_bridgeObjectRelease(v26);
    uint64_t v29 = specialized Sequence<>.max()((uint64_t)ML17MLImageClassifierV5f41V6export8metadata20featureExtractorType20dE92ADVAA0K8MetadataV_AC07FeatureiJ0OtKFSiAJcfu_32b63bdf5f6c975d31a36a8f37561ba444AJSiTf3nnnpk_nTf1cn_n);
    LOBYTE(v24) = v30;
    swift_bridgeObjectRelease((_BYTE)ML17MLImageClassifierV5f41V6export8metadata20featureExtractorType20dE92ADVAA0K8MetadataV_AC07FeatureiJ0OtKFSiAJcfu_32b63bdf5f6c975d31a36a8f37561ba444AJSiTf3nnnpk_nTf1cn_n);
    uint64_t v31 = 1;
    if ((v24 & 1) == 0) {
      uint64_t v31 = v29;
    }
    Model.specificationVersion.setter(v31);
  }
}

uint64_t MLImageClassifier.Model.applied(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v5[6] = v4;
  uint64_t v5[5] = a4;
  void v5[4] = a3;
  void v5[3] = a2;
  v5[2] = a1;
  uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  v5[7] = v6;
  uint64_t v7 = *(void *)(v6 - 8);
  v5[8] = v7;
  v5[9] = swift_task_alloc((*(void *)(v7 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  v5[10] = v8;
  uint64_t v9 = *(void *)(v8 - 8);
  v5[11] = v9;
  v5[12] = swift_task_alloc((*(void *)(v9 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  v5[13] = v10;
  v5[14] = swift_task_alloc((*(void *)(*(void *)(v10 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLImageClassifier.Model.applied(to:eventHandler:), 0, 0);
}

uint64_t MLImageClassifier.Model.applied(to:eventHandler:)()
{
  uint64_t v1 = v0[14];
  uint64_t v2 = v0[13];
  outlined init with copy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(v0[6], v1);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v1, v2);
  uint64_t v4 = v0[14];
  if (EnumCaseMultiPayload == 1)
  {
    (*(void (**)(void, uint64_t, void))(v0[8] + 32))(v0[9], v4, v0[7]);
    uint64_t v5 = (void *)swift_task_alloc(async function pointer to FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)[1]);
    v0[17] = v5;
    void *v5 = v0;
    v5[1] = MLImageClassifier.Model.applied(to:eventHandler:);
    return FullyConnectedNetworkClassifierModel.applied(to:eventHandler:)(v0[2], v0[3], v0[4], v0[5], v0[7]);
  }
  else
  {
    (*(void (**)(void, uint64_t, void))(v0[11] + 32))(v0[12], v4, v0[10]);
    uint64_t v7 = (void *)swift_task_alloc(async function pointer to LogisticRegressionClassifierModel.applied(to:eventHandler:)[1]);
    v0[15] = v7;
    void *v7 = v0;
    v7[1] = MLImageClassifier.Model.applied(to:eventHandler:);
    return LogisticRegressionClassifierModel.applied(to:eventHandler:)(v0[2], v0[3], v0[4], v0[5], v0[10]);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 120);
  *(void *)(*(void *)v1 + 128) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLImageClassifier.Model.applied(to:eventHandler:);
  }
  else {
    uint64_t v3 = MLImageClassifier.Model.applied(to:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v1 = *(void *)(v0 + 96);
  uint64_t v2 = *(void *)(v0 + 72);
  uint64_t v3 = *(void *)(v0 + 112);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 88) + 8))(v1, *(void *)(v0 + 80));
  swift_task_dealloc(v3);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 136);
  *(void *)(*(void *)v1 + 144) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLImageClassifier.Model.applied(to:eventHandler:);
  }
  else {
    uint64_t v3 = MLImageClassifier.Model.applied(to:eventHandler:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v1 = *(void *)(v0 + 72);
  uint64_t v2 = *(void *)(v0 + 112);
  uint64_t v3 = *(void *)(v0 + 96);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 64) + 8))(v1, *(void *)(v0 + 56));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v1 = *(void *)(v0 + 96);
  uint64_t v2 = *(void *)(v0 + 72);
  uint64_t v3 = *(void *)(v0 + 112);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 88) + 8))(v1, *(void *)(v0 + 80));
  swift_task_dealloc(v3);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v1 = *(void *)(v0 + 72);
  uint64_t v2 = *(void *)(v0 + 112);
  uint64_t v3 = *(void *)(v0 + 96);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 64) + 8))(v1, *(void *)(v0 + 56));
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t protocol witness for Transformer.applied(to:eventHandler:) in conformance MLImageClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v7 = (void *)swift_task_alloc(dword_3A8014);
  *(void *)(v4 + 16) = v7;
  void *v7 = v4;
  v7[1] = protocol witness for SupervisedEstimator.fitted<A, B>(to:validateOn:eventHandler:) in conformance MLImageClassifier.Classifier;
  return MLImageClassifier.Model.applied(to:eventHandler:)(a1, a2, a3, a4);
}

uint64_t base witness table accessor for Transformer in MLImageClassifier.Model()
{
  return lazy protocol witness table accessor for type MLImageClassifier.Model and conformance MLImageClassifier.Model();
}

uint64_t lazy protocol witness table accessor for type MLImageClassifier.Model and conformance MLImageClassifier.Model()
{
  uint64_t result = lazy protocol witness table cache variable for type MLImageClassifier.Model and conformance MLImageClassifier.Model;
  if (!lazy protocol witness table cache variable for type MLImageClassifier.Model and conformance MLImageClassifier.Model)
  {
    uint64_t v1 = type metadata accessor for MLImageClassifier.Model(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLImageClassifier.Model, v1);
    lazy protocol witness table cache variable for type MLImageClassifier.Model and conformance MLImageClassifier.Model = result;
  }
  return result;
}

void *associated type witness table accessor for Classifier.Label : Hashable in MLImageClassifier.Model()
{
  return &protocol witness table for String;
}

uint64_t outlined init with copy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:)(uint64_t a1)
{
  v2[3] = v1;
  v2[2] = a1;
  uint64_t v3 = type metadata accessor for Model(0);
  v2[4] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[5] = v4;
  v2[6] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:), 0, 0);
}

{
  uint64_t v1;
  uint64_t *v2;
  uint64_t v4;
  uint64_t v5;
  uint64_t (*v6)();

  uint64_t v5 = *(void *)(*v2 + 56);
  uint64_t v4 = *v2;
  *(void *)(*v2 + 64) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:);
  }
  else
  {
    *(void *)(v4 + 72) = a1;
    uint64_t v6 = MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:);
  }
  return swift_task_switch(v6, 0, 0);
}

uint64_t MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:)()
{
  uint64_t v20 = v0 | 0x1000000000000000;
  uint64_t v19 = v1;
  uint64_t v17 = v1[2];
  uint64_t v18 = v1[3];
  uint64_t v2 = NSFullUserName();
  uint64_t v3 = v2;
  uint64_t v4 = static String._unconditionallyBridgeFromObjectiveC(_:)(v3);
  uint64_t v6 = v5;

  v12[0] = v4;
  v12[1] = v6;
  v12[2] = 0xD000000000000033;
  void v12[3] = (uint64_t)("RandomForestRegressor" + 0x8000000000000000);
  long long v13 = 0;
  uint64_t v14 = 49;
  unint64_t v15 = 0xE100000000000000;
  uint64_t v16 = 0;
  MLImageClassifier.Model.export(metadata:featureExtractorType:)(v12, v17);
  swift_bridgeObjectRelease(v6);
  swift_bridgeObjectRelease(("RandomForestRegressor" + 0x8000000000000000));
  swift_bridgeObjectRelease_n(0, 2, v7, v8, v9);
  swift_bridgeObjectRelease(0);
  type metadata accessor for MLModel();
  uint64_t v10 = (void *)swift_task_alloc(dword_3A701C);
  v1[7] = v10;
  *uint64_t v10 = v1;
  v10[1] = MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:);
  return static MLModel.compile(_:)(v1[6]);
}

{
  uint64_t v0;
  uint64_t v1;

  uint64_t v1 = *(void *)(v0 + 48);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 40) + 8))(v1, *(void *)(v0 + 32));
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))(*(void *)(v0 + 72));
}

{
  uint64_t v0;

  (*(void (**)(void, void))(*(void *)(v0 + 40) + 8))(*(void *)(v0 + 48), *(void *)(v0 + 32));
  swift_task_dealloc(*(void *)(v0 + 48));
  return (*(uint64_t (**)(void))(v0 + 8))();
}

void MLImageClassifier.Model.createPipelineModel(featureExtractorType:)(uint64_t a1, uint64_t a2)
{
  uint64_t v75 = a1;
  uint64_t v67 = v2;
  uint64_t v62 = type metadata accessor for ModelKind(0);
  uint64_t v61 = *(void *)(v62 - 8);
  int64_t v4 = *(void *)(v61 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v63 = &v60;
  uint64_t v72 = type metadata accessor for FeatureDescription(0);
  uint64_t v77 = *(void *)(v72 - 8);
  int64_t v7 = *(void *)(v77 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v69 = &v60;
  uint64_t v70 = type metadata accessor for FeatureType(0);
  uint64_t v68 = *(void *)(v70 - 8);
  int64_t v10 = *(void *)(v68 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v64 = &v60;
  long long v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  uint64_t v71 = &v60;
  int64_t v15 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureDescription?)
                              - 8)
                  + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v60 = (uint64_t)&v60;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  int64_t v78 = &v60;
  uint64_t v20 = type metadata accessor for Model(0);
  uint64_t v21 = *(void *)(v20 - 8);
  int64_t v22 = *(void *)(v21 + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  uint64_t v76 = &v60;
  uint64_t v25 = alloca(v22);
  uint64_t v26 = alloca(v22);
  uint64_t v27 = v75;
  MLImageClassifier.Model.createFeatureExtractorModel(_:)(v75);
  if (!v3)
  {
    id v79 = &v60;
    uint64_t v73 = v21;
    uint64_t v74 = v20;
    MLImageClassifier.Model.createClassifierModel()();
    uint64_t v75 = 0;
    uint64_t v28 = Model.outputs.getter(v27, a2);
    char v29 = v28;
    uint64_t v30 = (uint64_t)v78;
    specialized Collection.first.getter(v28);
    swift_bridgeObjectRelease(v29);
    uint64_t v31 = v72;
    if (__swift_getEnumTagSinglePayload(v30, 1, v72) == 1) {
      BUG();
    }
    uint64_t v65 = FeatureDescription.name.getter();
    uint64_t v66 = v32;
    int64_t v78 = *(uint64_t **)(v77 + 8);
    ((void (*)(uint64_t, uint64_t))v78)(v30, v31);
    uint64_t v33 = Model.inputs.getter();
    uint64_t v34 = v60;
    specialized Collection.first.getter(v33);
    swift_bridgeObjectRelease(v33);
    if (__swift_getEnumTagSinglePayload(v34, 1, v31) == 1) {
      BUG();
    }
    uint64_t v35 = v71;
    FeatureDescription.type.getter();
    ((void (*)(uint64_t, uint64_t))v78)(v34, v31);
    unint64_t v36 = v64;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v68 + 16))(v64, v35, v70);
    uint64_t v37 = v69;
    FeatureDescription.init(name:type:description:)(v65, v66, v36, 0, 0xE000000000000000);
    uint64_t v38 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
    uint64_t v39 = v77;
    uint64_t v40 = *(unsigned __int8 *)(v77 + 80);
    uint64_t v41 = ((int)v40 + 32) & ~*(unsigned __int8 *)(v77 + 80);
    uint64_t v42 = swift_allocObject(v38, v41 + *(void *)(v77 + 72), v40 | 7);
    *(void *)(v42 + 16) = 1;
    *(void *)(v42 + 24) = 2;
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v39 + 16))(v42 + v41, v37, v72);
    Model.outputs.setter(v42);
    uint64_t v43 = Model.outputs.getter(v42, v37);
    Model.inputs.setter(v43);
    Model.init()();
    Model.specificationVersion.setter(1);
    uint64_t v44 = Model.inputs.getter();
    Model.inputs.setter(v44);
    uint64_t v45 = Model.outputs.getter(v44, v37);
    Model.outputs.setter(v45);
    uint64_t v46 = Model.predictedFeatureName.getter();
    Model.predictedFeatureName.setter(v46, v47);
    uint64_t v48 = Model.predictedProbabilitiesName.getter();
    Model.predictedProbabilitiesName.setter(v48, v49);
    uint64_t v50 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Model>);
    uint64_t v51 = v73;
    uint64_t v77 = *(void *)(v73 + 72);
    uint64_t v52 = *(unsigned __int8 *)(v73 + 80);
    uint64_t v53 = ((int)v52 + 32) & ~*(unsigned __int8 *)(v73 + 80);
    uint64_t v54 = swift_allocObject(v50, v53 + 2 * v77, v52 | 7);
    *(void *)(v54 + 16) = 2;
    *(void *)(v54 + 24) = 4;
    uint64_t v55 = v54 + v53;
    id v56 = *(void (**)(uint64_t, uint64_t *, uint64_t))(v51 + 16);
    uint64_t v57 = v74;
    v56(v55, v79, v74);
    v56(v77 + v55, v76, v57);
    uint64_t v58 = v63;
    PipelineClassifierConfiguration.init(models:names:)(v54, _swiftEmptyArrayStorage);
    (*(void (**)(uint64_t *, void, uint64_t))(v61 + 104))(v58, enum case for ModelKind.pipelineClassifier(_:), v62);
    Model.kind.setter(v58);
    ((void (*)(uint64_t *, uint64_t))v78)(v69, v72);
    (*(void (**)(uint64_t *, uint64_t))(v68 + 8))(v71, v70);
    uint64_t v59 = *(void (**)(uint64_t *, uint64_t))(v73 + 8);
    v59(v76, v57);
    v59(v79, v57);
  }
}

void MLImageClassifier.Model.createFeatureExtractorModel(_:)(uint64_t a1)
{
  uint64_t v11 = v2;
  uint64_t v12 = v1;
  int64_t v3 = *(void *)(*(void *)(type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0) - 8) + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v6 = type metadata accessor for MLImageClassifier.FeatureExtractorType(0);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  outlined init with copy of MLImageClassifier.FeatureExtractorType(a1, (uint64_t)&v11);
  if (swift_getEnumCaseMultiPayload(&v11, v6) == 1)
  {
    outlined init with take of MLImageClassifier.CustomFeatureExtractor((uint64_t)&v11, (uint64_t)&v11);
    MLImageClassifier.CustomFeatureExtractor.buildModel()();
    outlined destroy of MLImageClassifier.CustomFeatureExtractor((uint64_t)&v11);
  }
  else
  {
    if ((_BYTE)v12) {
      uint64_t v10 = 1;
    }
    else {
      uint64_t v10 = v11;
    }
    MLImageClassifier.Model.createScenePrintFeatureExtractorModel(revision:)(v10);
  }
}

void MLImageClassifier.Model.createScenePrintFeatureExtractorModel(revision:)(uint64_t a1)
{
  uint64_t v51 = a1;
  uint64_t v57 = v1;
  uint64_t v50 = type metadata accessor for ImageFeaturePrint(0);
  uint64_t v2 = *(void *)(v50 - 8);
  int64_t v3 = *(void *)(v2 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v62 = &v47;
  uint64_t v52 = type metadata accessor for URL.DirectoryHint(0);
  uint64_t v53 = *(void *)(v52 - 8);
  int64_t v6 = *(void *)(v53 + 64);
  int64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v54 = &v47;
  uint64_t v65 = type metadata accessor for UUID(0);
  uint64_t v55 = *(void *)(v65 - 8);
  int64_t v9 = *(void *)(v55 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  id v56 = &v47;
  uint64_t v63 = type metadata accessor for URL(0);
  uint64_t v60 = *(void *)(v63 - 8);
  int64_t v12 = *(void *)(v60 + 64);
  long long v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v58 = &v47;
  int64_t v15 = alloca(v12);
  uint64_t v16 = alloca(v12);
  uint64_t v59 = &v47;
  uint64_t v17 = alloca(v12);
  uint64_t v18 = alloca(v12);
  uint64_t v66 = &v47;
  uint64_t v19 = alloca(v12);
  uint64_t v20 = alloca(v12);
  uint64_t v64 = &v47;
  uint64_t v21 = objc_opt_self(NSFileManager);
  id v22 = [v21 defaultManager];
  id v23 = v22;
  NSFileManager.createTemporaryModelDirectory()();

  if (!v24)
  {
    uint64_t v61 = v2;
    id v25 = [v21 defaultManager];
    id v26 = v25;
    NSFileManager.temporaryModelDirectory.getter();

    uint64_t v27 = v56;
    UUID.init()();
    uint64_t v28 = UUID.uuidString.getter();
    uint64_t v30 = v29;
    (*(void (**)(uint64_t *, uint64_t))(v55 + 8))(v27, v65);
    uint64_t v48 = v28;
    uint64_t v49 = v30;
    uint64_t v65 = 0;
    uint64_t v31 = v54;
    uint64_t v32 = v52;
    uint64_t v33 = v53;
    (*(void (**)(uint64_t *, void, uint64_t))(v53 + 104))(v54, enum case for URL.DirectoryHint.inferFromPath(_:), v52);
    uint64_t v34 = lazy protocol witness table accessor for type String and conformance String();
    uint64_t v35 = v59;
    URL.appending<A>(component:directoryHint:)(&v48, v31, &type metadata for String, v34);
    (*(void (**)(uint64_t *, uint64_t))(v33 + 8))(v31, v32);
    swift_bridgeObjectRelease(v49);
    unint64_t v36 = *(void (**)(uint64_t *, uint64_t))(v60 + 8);
    uint64_t v37 = v63;
    v36(v35, v63);
    uint64_t v38 = v64;
    uint64_t v39 = v66;
    URL.appendingPathExtension(_:)(0x6C65646F6D6C6D2ELL, 0xE800000000000000);
    uint64_t v66 = (uint64_t *)v36;
    v36(v39, v37);
    id v40 = objc_allocWithZone((Class)CIContext);
    id v41 = [v40 init];
    ImageFeaturePrint.init(revision:cropAndScale:context:)(v51, 0, v41);
    uint64_t v42 = v50;
    uint64_t v43 = v65;
    Transformer.export(to:)(v38, v50, &protocol witness table for ImageFeaturePrint);
    (*(void (**)(uint64_t *, uint64_t))(v61 + 8))(v62, v42);
    if (v43)
    {
      uint64_t v44 = v63;
      uint64_t v45 = v64;
    }
    else
    {
      uint64_t v46 = v58;
      uint64_t v45 = v64;
      uint64_t v44 = v63;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v60 + 16))(v58, v64, v63);
      Model.init(contentsOf:)(v46);
      $defer #1 () in MLImageClassifier.Model.createScenePrintFeatureExtractorModel(revision:)();
    }
    ((void (*)(uint64_t *, uint64_t))v66)(v45, v44);
  }
}

void MLImageClassifier.Model.createClassifierModel()()
{
  uint64_t v62 = v1;
  uint64_t v77 = v0;
  uint64_t v72 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
  uint64_t v71 = *(void *)(v72 - 8);
  int64_t v2 = *(void *)(v71 + 64);
  int64_t v3 = alloca(v2);
  int64_t v4 = alloca(v2);
  uint64_t v73 = &v59;
  uint64_t v75 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
  uint64_t v74 = *(void *)(v75 - 8);
  int64_t v5 = *(void *)(v74 + 64);
  int64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v76 = &v59;
  uint64_t v64 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int64_t v8 = *(void *)(*(void *)(v64 - 8) + 64);
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v63 = &v59;
  uint64_t v65 = type metadata accessor for URL.DirectoryHint(0);
  uint64_t v66 = *(void *)(v65 - 8);
  int64_t v11 = *(void *)(v66 + 64);
  int64_t v12 = alloca(v11);
  long long v13 = alloca(v11);
  uint64_t v67 = &v59;
  uint64_t v68 = type metadata accessor for UUID(0);
  uint64_t v69 = *(void *)(v68 - 8);
  int64_t v14 = *(void *)(v69 + 64);
  int64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v70 = &v59;
  uint64_t v81 = type metadata accessor for URL(0);
  uint64_t v80 = *(void *)(v81 - 8);
  int64_t v17 = *(void *)(v80 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v20 = alloca(v17);
  uint64_t v21 = alloca(v17);
  int64_t v78 = &v59;
  id v22 = alloca(v17);
  id v23 = alloca(v17);
  uint64_t v84 = &v59;
  uint64_t v24 = alloca(v17);
  id v25 = alloca(v17);
  uint64_t v82 = &v59;
  id v26 = objc_opt_self(NSFileManager);
  id v27 = [v26 defaultManager];
  id v28 = v27;
  NSFileManager.createTemporaryModelDirectory()();

  uint64_t v83 = v29;
  if (!v29)
  {
    id v79 = &v59;
    id v30 = [v26 defaultManager];
    id v31 = v30;
    NSFileManager.temporaryModelDirectory.getter();

    uint64_t v32 = v70;
    UUID.init()();
    uint64_t v33 = UUID.uuidString.getter();
    uint64_t v35 = v34;
    (*(void (**)(uint64_t *, uint64_t))(v69 + 8))(v32, v68);
    uint64_t v60 = v33;
    uint64_t v61 = v35;
    unint64_t v36 = v67;
    uint64_t v37 = v65;
    uint64_t v38 = v66;
    (*(void (**)(uint64_t *, void, uint64_t))(v66 + 104))(v67, enum case for URL.DirectoryHint.inferFromPath(_:), v65);
    uint64_t v39 = lazy protocol witness table accessor for type String and conformance String();
    id v40 = v78;
    URL.appending<A>(component:directoryHint:)(&v60, v36, &type metadata for String, v39);
    (*(void (**)(uint64_t *, uint64_t))(v38 + 8))(v36, v37);
    swift_bridgeObjectRelease(v61);
    id v41 = *(void (**)(uint64_t *, uint64_t))(v80 + 8);
    uint64_t v42 = v81;
    v41(v40, v81);
    uint64_t v43 = v82;
    uint64_t v44 = v84;
    URL.appendingPathExtension(_:)(0x6C65646F6D6C6D2ELL, 0xE800000000000000);
    uint64_t v84 = (uint64_t *)v41;
    v41(v44, v42);
    uint64_t v45 = (uint64_t)v63;
    outlined init with copy of Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(v62, (uint64_t)v63);
    if (swift_getEnumCaseMultiPayload(v45, v64) == 1)
    {
      uint64_t v46 = v73;
      uint64_t v47 = v45;
      uint64_t v48 = v72;
      uint64_t v49 = v71;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v71 + 32))(v73, v47, v72);
      uint64_t v50 = (uint64_t *)&lazy protocol witness table cache variable for type FullyConnectedNetworkClassifierModel<Float, String> and conformance FullyConnectedNetworkClassifierModel<A, B>;
      uint64_t v51 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
      uint64_t v52 = &protocol conformance descriptor for FullyConnectedNetworkClassifierModel<A, B>;
    }
    else
    {
      uint64_t v46 = v76;
      uint64_t v53 = v45;
      uint64_t v48 = v75;
      uint64_t v49 = v74;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v74 + 32))(v76, v53, v75);
      uint64_t v50 = (uint64_t *)&lazy protocol witness table cache variable for type LogisticRegressionClassifierModel<Float, String> and conformance LogisticRegressionClassifierModel<A, B>;
      uint64_t v51 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
      uint64_t v52 = &protocol conformance descriptor for LogisticRegressionClassifierModel<A, B>;
    }
    uint64_t v54 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(v50, v51, (uint64_t)v52);
    uint64_t v55 = v83;
    Transformer.export(to:)(v43, v48, v54);
    if (v55)
    {
      uint64_t v83 = v55;
      (*(void (**)(uint64_t *, uint64_t))(v49 + 8))(v46, v48);
      ((void (*)(uint64_t *, uint64_t))v84)(v82, v81);
    }
    else
    {
      (*(void (**)(uint64_t *, uint64_t))(v49 + 8))(v46, v48);
      id v56 = v82;
      uint64_t v57 = v79;
      uint64_t v58 = v81;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v80 + 16))(v79, v82, v81);
      Model.init(contentsOf:)(v57);
      $defer #1 () in MLImageClassifier.Model.createScenePrintFeatureExtractorModel(revision:)();
      ((void (*)(uint64_t *, uint64_t))v84)(v56, v58);
    }
  }
}

id $defer #1 () in MLImageClassifier.Model.createScenePrintFeatureExtractorModel(revision:)()
{
  uint64_t v0 = objc_opt_self(NSFileManager);
  id v1 = [v0 defaultManager];
  int64_t v2 = (NSURL *)v1;
  URL._bridgeToObjectiveC()(v2);
  int64_t v4 = v3;
  id v10 = 0;
  unsigned __int8 v5 = [(NSURL *)v2 removeItemAtURL:v3 error:&v10];

  id v6 = v10;
  if (v5) {
    return v10;
  }
  id v8 = v10;
  uint64_t v9 = _convertNSErrorToError(_:)(v6);

  swift_willThrow();
  swift_errorRelease(v9);
  return (id)__stack_chk_guard;
}

uint64_t outlined destroy of MLImageClassifier.CustomFeatureExtractor(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLImageClassifier.CustomFeatureExtractor(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t instantiation function for generic protocol witness table for SGD<A>(uint64_t a1, uint64_t a2)
{
  uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for SGD<A>, a2);
  *(void *)(a1 + 8) = result;
  return result;
}

unsigned char *assignWithCopy for MLRandomForestClassifier.ModelParameters.ValidationData(unsigned char *__dst, unsigned char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLRandomForestClassifier.ModelParameters.ValidationData((uint64_t)__dst);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(__src, a3);
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v7 = type metadata accessor for DataFrame(0);
      (*(void (**)(unsigned char *, unsigned char *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, __src, v7);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else if (EnumCaseMultiPayload == 1)
    {
      uint64_t v5 = *(void *)__src;
      char v6 = __src[8];
      outlined copy of Result<_DataTable, Error>(*(void *)__src, v6);
      *(void *)__dst = v5;
      __dst[8] = v6;
      swift_storeEnumTagMultiPayload(__dst, a3, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t outlined destroy of MLRandomForestClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLRandomForestClassifier.ModelParameters.ValidationData;
  if (!type metadata singleton initialization cache for MLRandomForestClassifier.ModelParameters.ValidationData) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLRandomForestClassifier.ModelParameters.ValidationData);
  }
  return result;
}

void *assignWithTake for MLRandomForestClassifier.ModelParameters.ValidationData(void *__dst, void *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLRandomForestClassifier.ModelParameters.ValidationData((uint64_t)__dst);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 2)
    {
      uint64_t v4 = type metadata accessor for DataFrame(0);
      (*(void (**)(void *, void *, uint64_t))(*(void *)(v4 - 8) + 32))(__dst, __src, v4);
      swift_storeEnumTagMultiPayload(__dst, a3, 2);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLRandomForestClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  v5[0] = &unk_34A978;
  v5[1] = &unk_34A990;
  uint64_t result = type metadata accessor for DataFrame(319);
  if (v4 <= 0x3F)
  {
    v5[2] = *(void *)(result - 8) + 64;
    swift_initEnumMetadataMultiPayload(a1, 256, 3, v5, v2, v3);
    return 0;
  }
  return result;
}

uint64_t MLRandomForestClassifier.ModelParameters.ValidationData.asTable()(__m128 a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = type metadata accessor for DataFrame(0);
  uint64_t v27 = *(void *)(v4 - 8);
  int64_t v5 = *(void *)(v27 + 64);
  char v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v29 = &v25;
  id v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  id v28 = &v25;
  uint64_t v10 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData(0);
  int64_t v11 = *(void *)(*(void *)(v10 - 8) + 64);
  int64_t v12 = alloca(v11);
  long long v13 = alloca(v11);
  outlined init with copy of MLRandomForestClassifier.ModelParameters.ValidationData(v2, (uint64_t)&v25);
  uint64_t result = swift_getEnumCaseMultiPayload(&v25, v10);
  switch((int)result)
  {
    case 0:
      *(void *)uint64_t v3 = 0;
      *(unsigned char *)(v3 + 8) = -1;
      break;
    case 1:
      uint64_t result = v25;
      char v15 = v26;
      goto LABEL_7;
    case 2:
      uint64_t v16 = v28;
      uint64_t v17 = v27;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v27 + 32))(v28, &v25, v4);
      uint64_t v18 = (uint64_t)v29;
      *(double *)a1.i64 = (*(double (**)(uint64_t *, uint64_t *, uint64_t))(v17 + 16))(v29, v16, v4);
      MLDataTable.init(_:convertArraysToShapedArrays:)(v18, 1, a1);
      (*(void (**)(uint64_t *, uint64_t))(v17 + 8))(v16, v4);
      uint64_t result = v30;
      char v15 = v31;
LABEL_7:
      *(void *)uint64_t v3 = result;
      *(unsigned char *)(v3 + 8) = v15;
      break;
    case 3:
      uint64_t v19 = v3;
      uint64_t empty = tc_v1_sframe_create_empty(0);
      if (!empty) {
        BUG();
      }
      uint64_t v21 = empty;
      uint64_t v22 = type metadata accessor for CMLTable();
      uint64_t v23 = swift_allocObject(v22, 24, 7);
      *(void *)(v23 + 16) = v21;
      uint64_t v24 = type metadata accessor for _DataTable();
      swift_allocObject(v24, 40, 7);
      uint64_t result = _DataTable.init(impl:)(v23);
      *(void *)uint64_t v19 = result;
      *(unsigned char *)(v19 + 8) = 0;
      break;
  }
  return result;
}

uint64_t MLRandomForestClassifier.ModelParameters.ValidationData.generateDataFrames(trainingData:)(uint64_t a1, uint64_t a2, void (*a3)(uint64_t *, uint64_t, uint64_t))
{
  uint64_t v55 = v3;
  uint64_t v57 = a3;
  id v56 = (uint64_t *)a2;
  uint64_t v54 = a1;
  uint64_t v5 = type metadata accessor for DataFrame(0);
  uint64_t v58 = *(void *)(v5 - 8);
  int64_t v6 = *(void *)(v58 + 64);
  uint64_t v7 = alloca(v6);
  id v8 = alloca(v6);
  uint64_t v50 = &v44;
  uint64_t v46 = type metadata accessor for DataFrame.Slice(0);
  uint64_t v51 = *(void *)(v46 - 8);
  int64_t v9 = *(void *)(v51 + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v48 = &v44;
  int64_t v12 = alloca(v9);
  long long v13 = alloca(v9);
  uint64_t v53 = &v44;
  int64_t v14 = alloca(v9);
  char v15 = alloca(v9);
  uint64_t v52 = &v44;
  int64_t v16 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame.Slice?)
                              - 8)
                  + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v47 = &v44;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v49 = &v44;
  uint64_t v21 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData(0);
  int64_t v22 = *(void *)(*(void *)(v21 - 8) + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  outlined init with copy of MLRandomForestClassifier.ModelParameters.ValidationData(v4, (uint64_t)&v44);
  switch(swift_getEnumCaseMultiPayload(&v44, v21))
  {
    case 0u:
      uint64_t v58 = v5;
      uint64_t v25 = (uint64_t)v49;
      uint64_t v26 = (uint64_t)v52;
      DataFrame.randomSplit(strategy:)((uint64_t)v49, (uint64_t)v52, (uint64_t)&v44);
      uint64_t v27 = v53;
      uint64_t v28 = v46;
      uint64_t v57 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 16);
      v57(v53, v26, v46);
      DataFrame.init(_:)(v27);
      uint64_t v29 = (uint64_t)v47;
      outlined init with copy of DataFrame.Slice?(v25, (uint64_t)v47);
      if (__swift_getEnumTagSinglePayload(v29, 1, v28) == 1)
      {
        __swift_storeEnumTagSinglePayload((uint64_t)v56, 1, 1, v58);
        uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v51 + 8);
      }
      else
      {
        id v40 = v53;
        uint64_t v41 = v51;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v51 + 32))(v53, v29, v28);
        uint64_t v42 = v48;
        v57(v48, (uint64_t)v40, v28);
        uint64_t v43 = (uint64_t)v56;
        DataFrame.init(_:)(v42);
        uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v41 + 8);
        v30(v53, v28);
        __swift_storeEnumTagSinglePayload(v43, 0, 1, v58);
      }
      v30(v52, v28);
      return outlined destroy of DataFrame.Slice?((uint64_t)v49);
    case 1u:
      uint64_t v35 = v44;
      char v36 = v45;
      (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
      uint64_t v44 = v35;
      char v45 = v36;
      uint64_t v37 = (uint64_t)v56;
      DataFrame.init(_:)((uint64_t)&v44);
      uint64_t v33 = v37;
      goto LABEL_10;
    case 2u:
      char v31 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v58 + 32);
      v31(v50, &v44, v5);
      if (DataFrameProtocol.isEmpty.getter(v5, &protocol witness table for DataFrame))
      {
        uint64_t v32 = v58;
        (*(void (**)(uint64_t *, uint64_t))(v58 + 8))(v50, v5);
        (*(void (**)(uint64_t, void, uint64_t))(v32 + 16))(v54, v57, v5);
LABEL_7:
        uint64_t v33 = (uint64_t)v56;
        uint64_t v34 = 1;
      }
      else
      {
        (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
        uint64_t v38 = (uint64_t)v56;
        v31(v56, v50, v5);
        uint64_t v33 = v38;
LABEL_10:
        uint64_t v34 = 0;
      }
      return __swift_storeEnumTagSinglePayload(v33, v34, 1, v5);
    case 3u:
      (*(void (**)(uint64_t, void, uint64_t))(v58 + 16))(v54, v57, v5);
      goto LABEL_7;
  }
}

uint64_t outlined init with copy of MLRandomForestClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLRandomForestClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t MLLinearRegressor.ModelParameters.validationData.getter(__m128 a1)
{
  uint64_t v2 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  int64_t v3 = *(void *)(*(void *)(v2 - 8) + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  outlined init with copy of Any?(v1, (uint64_t)&v9);
  if (!v10) {
    BUG();
  }
  outlined init with take of Any(&v9, v8);
  swift_dynamicCast(&v7, v8, (char *)&type metadata for Any + 8, v2, 7);
  MLLinearRegressor.ModelParameters.ValidationData.asTable()(a1);
  return outlined destroy of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)&v7);
}

uint64_t key path getter for MLLinearRegressor.ModelParameters.validationData : MLLinearRegressor.ModelParameters(__m128 a1)
{
  uint64_t v2 = v1;
  MLLinearRegressor.ModelParameters.validationData.getter(a1);
  uint64_t result = v4;
  *(void *)uint64_t v2 = v4;
  *(unsigned char *)(v2 + 8) = v5;
  return result;
}

uint64_t key path setter for MLLinearRegressor.ModelParameters.validationData : MLLinearRegressor.ModelParameters(uint64_t a1)
{
  int v1 = *(_DWORD *)(a1 + 8);
  uint64_t v3 = *(void *)a1;
  char v4 = v1;
  outlined copy of MLDataTable?(v3, v1);
  return MLLinearRegressor.ModelParameters.validationData.setter((uint64_t)&v3);
}

uint64_t MLLinearRegressor.ModelParameters.validationData.setter(uint64_t a1)
{
  uint64_t v20 = v1;
  unsigned int v2 = 0;
  uint64_t v3 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  int64_t v4 = *(void *)(*(void *)(v3 - 8) + 64);
  char v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v19 = *(void *)a1;
  char v7 = *(unsigned char *)(a1 + 8);
  uint64_t v15 = v3;
  id v8 = __swift_allocate_boxed_opaque_existential_1(&v13);
  uint64_t v9 = (uint64_t)v8;
  if (v7 == -1)
  {
    long long v13 = 0;
    __int16 v14 = 256;
    uint64_t v10 = v20;
  }
  else
  {
    uint64_t v18 = v8;
    uint64_t v16 = v19;
    char v17 = v7 & 1;
    if (MLDataTable.size.getter())
    {
      *(void *)&long long v13 = v19;
      BYTE8(v13) = v7 & 1;
      int v12 = 1;
    }
    else
    {
      outlined consume of MLDataTable?(v19, v7);
      int v12 = 3;
    }
    unsigned int v2 = v12;
    uint64_t v10 = v20;
    uint64_t v9 = (uint64_t)v18;
  }
  swift_storeEnumTagMultiPayload(&v13, v3, v2);
  outlined init with take of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)&v13, v9);
  return outlined assign with take of Any?((uint64_t)&v13, v10);
}

uint64_t MLLinearRegressor.ModelParameters.validation.getter()
{
  uint64_t v2 = v0;
  outlined init with copy of Any?(v1, (uint64_t)&v6);
  if (!v7) {
    BUG();
  }
  outlined init with take of Any(&v6, v5);
  uint64_t v3 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  return swift_dynamicCast(v2, v5, (char *)&type metadata for Any + 8, v3, 7);
}

uint64_t (*MLLinearRegressor.ModelParameters.validationData.modify(uint64_t a1, __m128 a2))(uint64_t a1, char a2)
{
  *(void *)(a1 + 16) = v2;
  MLLinearRegressor.ModelParameters.validationData.getter(a2);
  return MLLinearRegressor.ModelParameters.validationData.modify;
}

uint64_t MLLinearRegressor.ModelParameters.validationData.modify(uint64_t a1, char a2)
{
  uint64_t v2 = *(void *)a1;
  char v3 = *(unsigned char *)(a1 + 8);
  uint64_t v6 = *(void *)a1;
  char v7 = v3;
  if ((a2 & 1) == 0) {
    return MLLinearRegressor.ModelParameters.validationData.setter((uint64_t)&v6);
  }
  char v4 = v3;
  outlined copy of MLDataTable?(v2, v3);
  MLLinearRegressor.ModelParameters.validationData.setter((uint64_t)&v6);
  return outlined consume of MLDataTable?(v2, v4);
}

uint64_t key path setter for MLLinearRegressor.ModelParameters.validation : MLLinearRegressor.ModelParameters(uint64_t a1)
{
  v6[0] = v1;
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0) - 8)
                 + 64);
  char v3 = alloca(v2);
  char v4 = alloca(v2);
  outlined init with copy of MLLinearRegressor.ModelParameters.ValidationData(a1, (uint64_t)v6);
  return MLLinearRegressor.ModelParameters.validation.setter((uint64_t)v6);
}

uint64_t MLLinearRegressor.ModelParameters.validation.setter(uint64_t a1)
{
  v4[3] = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v4);
  outlined init with take of MLLinearRegressor.ModelParameters.ValidationData(a1, (uint64_t)boxed_opaque_existential_1);
  return outlined assign with take of Any?((uint64_t)v4, v1);
}

void (*MLLinearRegressor.ModelParameters.validation.modify(void *a1))(uint64_t a1, char a2)
{
  int64_t v2 = malloc(0xA0uLL);
  *a1 = v2;
  *((void *)v2 + 16) = v1;
  uint64_t v3 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  *((void *)v2 + 17) = v3;
  size_t v4 = *(void *)(*(void *)(v3 - 8) + 64);
  *((void *)v2 + 18) = malloc(v4);
  char v5 = malloc(v4);
  *((void *)v2 + 19) = v5;
  outlined init with copy of Any?(v1, (uint64_t)(v2 + 2));
  if (!*((void *)v2 + 7)) {
    BUG();
  }
  outlined init with take of Any(v2 + 2, v2);
  swift_dynamicCast(v5, v2, (char *)&type metadata for Any + 8, v3, 7);
  return MLLinearRegressor.ModelParameters.validation.modify;
}

void MLLinearRegressor.ModelParameters.validation.modify(uint64_t a1, char a2)
{
  int64_t v2 = *(void **)a1;
  uint64_t v3 = *(void **)(*(void *)a1 + 152);
  size_t v4 = *(void **)(*(void *)a1 + 144);
  uint64_t v8 = *(void *)(*(void *)a1 + 128);
  uint64_t v5 = *(void *)(*(void *)a1 + 136);
  if (a2)
  {
    outlined init with copy of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)v3, (uint64_t)v4);
    v2[11] = v5;
    boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v2 + 8);
    outlined init with take of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)v4, (uint64_t)boxed_opaque_existential_1);
    outlined assign with take of Any?((uint64_t)(v2 + 8), v8);
    outlined destroy of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)v3);
  }
  else
  {
    v2[15] = v5;
    char v7 = __swift_allocate_boxed_opaque_existential_1(v2 + 12);
    outlined init with take of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)v3, (uint64_t)v7);
    outlined assign with take of Any?((uint64_t)(v2 + 12), v8);
  }
  free(v3);
  free(v4);
  free(v2);
}

uint64_t MLLinearRegressor.ModelParameters.maxIterations.getter()
{
  return *(void *)(v0 + 32);
}

void MLLinearRegressor.ModelParameters.maxIterations.setter(uint64_t a1)
{
  *(void *)(v1 + 32) = a1;
}

void (*MLLinearRegressor.ModelParameters.maxIterations.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLLinearRegressor.ModelParameters.l1Penalty.getter()
{
  return *(double *)(v0 + 40);
}

void MLLinearRegressor.ModelParameters.l1Penalty.setter(double a1)
{
  *(double *)(v1 + 40) = a1;
}

void (*MLLinearRegressor.ModelParameters.l1Penalty.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLLinearRegressor.ModelParameters.l2Penalty.getter()
{
  return *(double *)(v0 + 48);
}

void MLLinearRegressor.ModelParameters.l2Penalty.setter(double a1)
{
  *(double *)(v1 + 48) = a1;
}

void (*MLLinearRegressor.ModelParameters.l2Penalty.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLLinearRegressor.ModelParameters.stepSize.getter()
{
  return *(double *)(v0 + 56);
}

void MLLinearRegressor.ModelParameters.stepSize.setter(double a1)
{
  *(double *)(v1 + 56) = a1;
}

void (*MLLinearRegressor.ModelParameters.stepSize.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLLinearRegressor.ModelParameters.convergenceThreshold.getter()
{
  return *(double *)(v0 + 64);
}

void MLLinearRegressor.ModelParameters.convergenceThreshold.setter(double a1)
{
  *(double *)(v1 + 64) = a1;
}

void (*MLLinearRegressor.ModelParameters.convergenceThreshold.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

char MLLinearRegressor.ModelParameters.featureRescaling.getter()
{
  return *(unsigned char *)(v0 + 72);
}

void MLLinearRegressor.ModelParameters.featureRescaling.setter(char a1)
{
  *(unsigned char *)(v1 + 72) = a1 & 1;
}

void (*MLLinearRegressor.ModelParameters.featureRescaling.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLLinearRegressor.ModelParameters.init(validation:maxIterations:l1Penalty:l2Penalty:stepSize:convergenceThreshold:featureRescaling:)(uint64_t a1, uint64_t a2, char a3, double a4, double a5, double a6, double a7)
{
  double v17 = a7;
  double v18 = a6;
  double v19 = a5;
  double v20 = a4;
  uint64_t v21 = a2;
  uint64_t v9 = v7;
  uint64_t v10 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  int64_t v11 = *(void *)(*(void *)(v10 - 8) + 64);
  int v12 = alloca(v11);
  long long v13 = alloca(v11);
  *(_OWORD *)(v9 + 16) = 0;
  *(_OWORD *)uint64_t v9 = 0;
  *(void *)(v9 + 32) = v21;
  *(double *)(v9 + 40) = v20;
  *(double *)(v9 + 48) = v19;
  *(double *)(v9 + 56) = v18;
  *(double *)(v9 + 64) = v17;
  *(unsigned char *)(v9 + 72) = a3 & 1;
  outlined init with copy of MLLinearRegressor.ModelParameters.ValidationData(a1, (uint64_t)v16);
  void v16[3] = v10;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v16);
  outlined init with take of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)v16, (uint64_t)boxed_opaque_existential_1);
  outlined assign with take of Any?((uint64_t)v16, v9);
  return outlined destroy of MLLinearRegressor.ModelParameters.ValidationData(a1);
}

uint64_t MLLinearRegressor.ModelParameters.init(validationData:maxIterations:l1Penalty:l2Penalty:stepSize:convergenceThreshold:featureRescaling:)(uint64_t *a1, uint64_t a2, char a3, double a4, double a5, double a6, double a7)
{
  uint64_t v8 = *a1;
  char v9 = *((unsigned char *)a1 + 8);
  *(_OWORD *)(v7 + 16) = 0;
  *(_OWORD *)uint64_t v7 = 0;
  *(void *)(v7 + 32) = a2;
  *(double *)(v7 + 40) = a4;
  *(double *)(v7 + 48) = a5;
  *(double *)(v7 + 56) = a6;
  *(double *)(v7 + 64) = a7;
  *(unsigned char *)(v7 + 72) = a3 & 1;
  uint64_t v11 = v8;
  char v12 = v9;
  return MLLinearRegressor.ModelParameters.validationData.setter((uint64_t)&v11);
}

unint64_t MLLinearRegressor.ModelParameters.description.getter()
{
  _StringGuts.grow(_:)(19);
  swift_bridgeObjectRelease(0xE000000000000000);
  v1._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  char object = v1._object;
  String.append(_:)(v1);
  swift_bridgeObjectRelease(object);
  v3._uint64_t countAndFlagsBits = 10;
  v3._char object = (void *)0xE100000000000000;
  String.append(_:)(v3);
  v13._uint64_t countAndFlagsBits = 0;
  v13._char object = (void *)0xE000000000000000;
  v3._char object = (void *)0xEC000000203A7974;
  v3._uint64_t countAndFlagsBits = 0x6C616E655020314CLL;
  String.append(_:)(v3);
  Double.write<A>(to:)(&v13, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v3._uint64_t countAndFlagsBits = 10;
  v3._char object = (void *)0xE100000000000000;
  String.append(_:)(v3);
  size_t v4 = v13._object;
  String.append(_:)(v13);
  swift_bridgeObjectRelease(v4);
  v13._uint64_t countAndFlagsBits = 0;
  v13._char object = (void *)0xE000000000000000;
  v3._uint64_t countAndFlagsBits = 0x6C616E655020324CLL;
  v3._char object = (void *)0xEC000000203A7974;
  String.append(_:)(v3);
  Double.write<A>(to:)(&v13, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v3._uint64_t countAndFlagsBits = 10;
  v3._char object = (void *)0xE100000000000000;
  String.append(_:)(v3);
  uint64_t v5 = v13._object;
  String.append(_:)(v13);
  swift_bridgeObjectRelease(v5);
  v13._uint64_t countAndFlagsBits = 0;
  v13._char object = (void *)0xE000000000000000;
  v3._uint64_t countAndFlagsBits = 0x7A69532070657453;
  v3._char object = (void *)0xEB00000000203A65;
  String.append(_:)(v3);
  Double.write<A>(to:)(&v13, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v3._uint64_t countAndFlagsBits = 10;
  v3._char object = (void *)0xE100000000000000;
  String.append(_:)(v3);
  uint64_t v6 = v13._object;
  String.append(_:)(v13);
  swift_bridgeObjectRelease(v6);
  v13._uint64_t countAndFlagsBits = 0;
  v13._char object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(26);
  v3._uint64_t countAndFlagsBits = 0xD000000000000017;
  v3._char object = "ml.actionClassifier" + 0x8000000000000000;
  String.append(_:)(v3);
  Double.write<A>(to:)(&v13, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v3._uint64_t countAndFlagsBits = 10;
  v9._char object = (void *)0xE100000000000000;
  String.append(_:)(v9);
  uint64_t v7 = v13._object;
  String.append(_:)(v13);
  swift_bridgeObjectRelease(v7);
  v13._uint64_t countAndFlagsBits = 0;
  v13._char object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(22);
  swift_bridgeObjectRelease(v13._object);
  v13._uint64_t countAndFlagsBits = 0xD000000000000013;
  unsigned __int8 v8 = *(unsigned char *)(v0 + 72);
  v9._uint64_t countAndFlagsBits = 0x65736C6166;
  if (v8) {
    v9._uint64_t countAndFlagsBits = 1702195828;
  }
  v13._char object = "Convergence Threshold: " + 0x8000000000000000;
  v9._char object = (void *)((v8 ^ 1u | 0xFFFFFFFFFFFFFFE4) << 56);
  String.append(_:)(v9);
  swift_bridgeObjectRelease(v9._object);
  v10._uint64_t countAndFlagsBits = 10;
  v10._char object = (void *)0xE100000000000000;
  String.append(_:)(v10);
  uint64_t v11 = v13._object;
  String.append(_:)(v13);
  swift_bridgeObjectRelease(v11);
  return 0xD000000000000010;
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLLinearRegressor.ModelParameters()
{
  return MLLinearRegressor.ModelParameters.description.getter();
}

unint64_t MLLinearRegressor.ModelParameters.debugDescription.getter()
{
  return MLLinearRegressor.ModelParameters.description.getter();
}

unint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLLinearRegressor.ModelParameters()
{
  return MLLinearRegressor.ModelParameters.debugDescription.getter();
}

unint64_t MLLinearRegressor.ModelParameters.playgroundDescription.getter()
{
  Swift::String v1 = v0;
  unint64_t result = MLLinearRegressor.ModelParameters.description.getter();
  v1[3] = (unint64_t)&type metadata for String;
  *Swift::String v1 = result;
  v1[1] = v3;
  return result;
}

unint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLLinearRegressor.ModelParameters()
{
  return MLLinearRegressor.ModelParameters.playgroundDescription.getter();
}

uint64_t sub_1134DE(__m128 a1)
{
  return key path getter for MLLinearRegressor.ModelParameters.validationData : MLLinearRegressor.ModelParameters(a1);
}

uint64_t sub_1134E8(uint64_t a1)
{
  return key path setter for MLLinearRegressor.ModelParameters.validationData : MLLinearRegressor.ModelParameters(a1);
}

uint64_t sub_1134F2(uint64_t a1)
{
  return MLLinearRegressor.ModelParameters.validation.getter(a1);
}

uint64_t sub_113509(uint64_t a1)
{
  return key path setter for MLLinearRegressor.ModelParameters.validation : MLLinearRegressor.ModelParameters(a1);
}

uint64_t initializeWithCopy for MLLinearRegressor.ModelParameters(uint64_t a1, long long *a2)
{
  uint64_t v2 = *((void *)a2 + 3);
  if (v2)
  {
    *(void *)(a1 + 24) = v2;
    (**(void (***)(uint64_t, long long *))(v2 - 8))(a1, a2);
  }
  else
  {
    long long v3 = *a2;
    *(_OWORD *)(a1 + 16) = a2[1];
    *(_OWORD *)a1 = v3;
  }
  *(_OWORD *)(a1 + 32) = a2[2];
  *(_OWORD *)(a1 + 48) = a2[3];
  *(void *)(a1 + 64) = *((void *)a2 + 8);
  *(unsigned char *)(a1 + 72) = *((unsigned char *)a2 + 72);
  return a1;
}

uint64_t assignWithCopy for MLLinearRegressor.ModelParameters(uint64_t a1, long long *a2)
{
  uint64_t v2 = *((void *)a2 + 3);
  if (!*(void *)(a1 + 24))
  {
    if (v2)
    {
      *(void *)(a1 + 24) = v2;
      (**(void (***)(uint64_t, long long *))(v2 - 8))(a1, a2);
      goto LABEL_8;
    }
LABEL_7:
    long long v3 = *a2;
    *(_OWORD *)(a1 + 16) = a2[1];
    *(_OWORD *)a1 = v3;
    goto LABEL_8;
  }
  if (!v2)
  {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)a1);
    goto LABEL_7;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)a1, (uint64_t *)a2);
LABEL_8:
  *(void *)(a1 + 32) = *((void *)a2 + 4);
  *(void *)(a1 + 40) = *((void *)a2 + 5);
  *(void *)(a1 + 48) = *((void *)a2 + 6);
  *(void *)(a1 + 56) = *((void *)a2 + 7);
  *(void *)(a1 + 64) = *((void *)a2 + 8);
  *(unsigned char *)(a1 + 72) = *((unsigned char *)a2 + 72);
  return a1;
}

uint64_t assignWithTake for MLLinearRegressor.ModelParameters(uint64_t a1, long long *a2)
{
  if (*(void *)(a1 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)a1);
  }
  long long v2 = *a2;
  *(_OWORD *)(a1 + 16) = a2[1];
  *(_OWORD *)a1 = v2;
  *(void *)(a1 + 32) = *((void *)a2 + 4);
  *(_OWORD *)(a1 + 40) = *(long long *)((char *)a2 + 40);
  *(_OWORD *)(a1 + 56) = *(long long *)((char *)a2 + 56);
  *(unsigned char *)(a1 + 72) = *((unsigned char *)a2 + 72);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLinearRegressor.ModelParameters(uint64_t a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 >= 0x7FFFFFFF && *(unsigned char *)(a1 + 73))
    {
      int v2 = *(_DWORD *)a1 + 2147483646;
    }
    else
    {
      unint64_t v3 = *(void *)(a1 + 24);
      unint64_t v4 = v3 & 0xFFFFFFFF00000001;
      int v5 = (v3 >> 1) - 1;
      int v6 = -1;
      if (v5 >= 0) {
        int v6 = v5;
      }
      int v2 = v4 != 0 ? -1 : v6;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

uint64_t storeEnumTagSinglePayload for MLLinearRegressor.ModelParameters(uint64_t a1, unsigned int a2, unsigned int a3)
{
  if (a2 > 0x7FFFFFFE)
  {
    *(_OWORD *)(a1 + 56) = 0;
    *(_OWORD *)(a1 + 40) = 0;
    *(_OWORD *)(a1 + 24) = 0;
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 - 0x7FFFFFFF;
    *(unsigned char *)(a1 + 72) = 0;
    if (a3 >= 0x7FFFFFFF) {
      *(unsigned char *)(a1 + 73) = 1;
    }
  }
  else
  {
    if (a3 >= 0x7FFFFFFF) {
      *(unsigned char *)(a1 + 73) = 0;
    }
    if (a2)
    {
      uint64_t result = 2 * a2;
      *(void *)(a1 + 24) = result;
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for MLLinearRegressor.ModelParameters()
{
  return &type metadata for MLLinearRegressor.ModelParameters;
}

uint64_t static MLSoundClassifier.VGGishFeatureExtractor.buildSoundAnalysisPreprocessingSpec()()
{
  uint64_t v44 = v0;
  uint64_t v33 = type metadata accessor for ModelKind(0);
  uint64_t v34 = *(void *)(v33 - 8);
  int64_t v1 = *(void *)(v34 + 64);
  int v2 = alloca(v1);
  unint64_t v3 = alloca(v1);
  uint64_t v35 = &v32;
  uint64_t v45 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType(0);
  uint64_t v51 = *(void *)(v45 - 8);
  int64_t v4 = *(void *)(v51 + 64);
  int v5 = alloca(v4);
  int v6 = alloca(v4);
  uint64_t v47 = &v32;
  int64_t v7 = *(void *)(*(void *)(type metadata accessor for FeatureType(0) - 8) + 64);
  unsigned __int8 v8 = alloca(v7);
  Swift::String v9 = alloca(v7);
  uint64_t v43 = type metadata accessor for FeatureDescription(0);
  uint64_t v46 = *(void *)(v43 - 8);
  int64_t v10 = *(void *)(v46 + 64);
  uint64_t v11 = alloca(v10);
  char v12 = alloca(v10);
  uint64_t v50 = &v32;
  Swift::String v13 = alloca(v10);
  __int16 v14 = alloca(v10);
  uint64_t v49 = &v32;
  Model.init()();
  Model.specificationVersion.setter(4);
  char v36 = "Feature embedding for VGGish" + 0x8000000000000000;
  Model.predictedFeatureName.setter(0xD000000000000011, "Feature embedding for VGGish" + 0x8000000000000000);
  Model.modelDescription.setter(0xD000000000000027, "be a neural network, got " + 0x8000000000000000);
  FeatureDescription.init()();
  FeatureDescription.name.setter(0x6D61536F69647561, 0xEC00000073656C70);
  FeatureDescription.featureDescription.setter(0xD000000000000024, "reprocessing for VGGish" + 0x8000000000000000);
  unsigned int v48 = enum case for FeatureType.ShapedArrayParameters.DataType.float32(_:);
  uint64_t v37 = *(void (**)(uint64_t *, void, uint64_t))(v51 + 104);
  uint64_t v15 = v47;
  uint64_t v16 = v45;
  v37(v47, enum case for FeatureType.ShapedArrayParameters.DataType.float32(_:), v45);
  uint64_t v38 = &v32;
  static FeatureType.shapedArray(dataType:shape:optional:)(v15, &outlined read-only object #0 of static MLSoundClassifier.VGGishFeatureExtractor.buildSoundAnalysisPreprocessingSpec(), 0);
  uint64_t v51 = *(void *)(v51 + 8);
  ((void (*)(uint64_t *, uint64_t))v51)(v15, v16);
  FeatureDescription.type.setter(&v32);
  uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  uint64_t v17 = v46;
  uint64_t v18 = *(unsigned __int8 *)(v46 + 80);
  uint64_t v19 = ((int)v18 + 32) & ~*(unsigned __int8 *)(v46 + 80);
  uint64_t v41 = v19 + *(void *)(v46 + 72);
  uint64_t v39 = v18 | 7;
  uint64_t v20 = swift_allocObject(v40, v41, v18 | 7);
  *(void *)(v20 + 16) = 1;
  *(void *)(v20 + 24) = 2;
  uint64_t v42 = *(void (**)(uint64_t, uint64_t *, uint64_t))(v17 + 16);
  v42(v20 + v19, v49, v43);
  Model.inputs.setter(v20);
  FeatureDescription.init()();
  FeatureDescription.name.setter(0xD000000000000011, v36);
  uint64_t v21 = v47;
  uint64_t v22 = v45;
  v37(v47, v48, v45);
  uint64_t v23 = v38;
  static FeatureType.shapedArray(dataType:shape:optional:)(v21, &outlined read-only object #1 of static MLSoundClassifier.VGGishFeatureExtractor.buildSoundAnalysisPreprocessingSpec(), 0);
  ((void (*)(uint64_t *, uint64_t))v51)(v21, v22);
  uint64_t v24 = v50;
  FeatureDescription.type.setter(v23);
  uint64_t v25 = swift_allocObject(v40, v41, v39);
  *(void *)(v25 + 16) = 1;
  *(void *)(v25 + 24) = 2;
  uint64_t v26 = v25 + v19;
  uint64_t v27 = v43;
  v42(v26, v24, v43);
  Model.outputs.setter(v25);
  uint64_t v28 = v35;
  SoundAnalysisPreprocessorKind.VGGishParameters.init()();
  LODWORD(v25) = enum case for SoundAnalysisPreprocessorKind.vggish(_:);
  uint64_t v29 = type metadata accessor for SoundAnalysisPreprocessorKind(0);
  (*(void (**)(uint64_t *, void, uint64_t))(*(void *)(v29 - 8) + 104))(v28, v25, v29);
  (*(void (**)(uint64_t *, void, uint64_t))(v34 + 104))(v28, enum case for ModelKind.soundPreprocessor(_:), v33);
  Model.kind.setter(v28);
  uint64_t v30 = *(void (**)(uint64_t *, uint64_t))(v46 + 8);
  v30(v50, v27);
  return ((uint64_t (*)(uint64_t *, uint64_t))v30)(v49, v27);
}

uint64_t static MLSoundClassifier.VGGishFeatureExtractor.buildFeatureEmbeddingNeuralNetworkSpec(outputName:)(uint64_t a1, uint64_t a2)
{
  *(void *)&long long v126 = v3;
  uint64_t v124 = a2;
  uint64_t v121 = a1;
  uint64_t v127 = v2;
  uint64_t v108 = type metadata accessor for ModelKind(0);
  uint64_t v109 = *(void *)(v108 - 8);
  int64_t v4 = *(void *)(v109 + 64);
  int v5 = alloca(v4);
  int v6 = alloca(v4);
  uint64_t v110 = v98;
  int64_t v7 = alloca(v4);
  unsigned __int8 v8 = alloca(v4);
  uint64_t v100 = v98;
  uint64_t v111 = type metadata accessor for NeuralNetwork(0);
  uint64_t v112 = *(void *)(v111 - 8);
  int64_t v9 = *(void *)(v112 + 64);
  int64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v125 = v98;
  uint64_t v122 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType(0);
  uint64_t v116 = *(void *)(v122 - 8);
  int64_t v12 = *(void *)(v116 + 64);
  Swift::String v13 = alloca(v12);
  __int16 v14 = alloca(v12);
  uint64_t v123 = v98;
  int64_t v15 = *(void *)(*(void *)(type metadata accessor for FeatureType(0) - 8) + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v107 = v98;
  uint64_t v118 = type metadata accessor for FeatureDescription(0);
  uint64_t v18 = *(void *)(v118 - 8);
  int64_t v19 = *(void *)(v18 + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  Swift::String v120 = v98;
  uint64_t v22 = alloca(v19);
  uint64_t v23 = alloca(v19);
  uint64_t v119 = v98;
  uint64_t v24 = type metadata accessor for URL(0);
  uint64_t v25 = *(void *)(v24 - 8);
  int64_t v26 = *(void *)(v25 + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  uint64_t v128 = v98;
  uint64_t v29 = alloca(v26);
  uint64_t v30 = alloca(v26);
  char v31 = v98;
  uint64_t v32 = v126;
  uint64_t result = static BundleUtilities.getMLModelURL(at:)(0xD000000000000018, (uint64_t)("h feature from audio samples" + 0x8000000000000000));
  if (v32) {
    return result;
  }
  uint64_t v117 = v18;
  uint64_t v34 = v128;
  *(void *)&long long v126 = 0;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v25 + 16))(v128, v98, v24);
  uint64_t v35 = v126;
  Model.init(contentsOf:)(v34);
  *(void *)&long long v126 = v35;
  if (v35) {
    return (*(uint64_t (**)(unsigned char *, uint64_t))(v25 + 8))(v31, v24);
  }
  uint64_t v115 = v98;
  uint64_t v114 = v24;
  uint64_t v113 = v25;
  Model.specificationVersion.setter(4);
  uint64_t v36 = v124;
  swift_bridgeObjectRetain(v124);
  Model.predictedFeatureName.setter(v121, v36);
  Model.modelDescription.setter(0xD00000000000001CLL, "SNVGGEmbeddingExtractor8" + 0x8000000000000000);
  FeatureDescription.init()();
  uint64_t v106 = "Feature embedding for VGGish" + 0x8000000000000000;
  FeatureDescription.name.setter(0xD000000000000011, "Feature embedding for VGGish" + 0x8000000000000000);
  LODWORD(v128) = enum case for FeatureType.ShapedArrayParameters.DataType.float32(_:);
  uint64_t v37 = v116;
  uint64_t v101 = *(void (**)(unsigned char *, void, uint64_t))(v116 + 104);
  uint64_t v38 = v123;
  uint64_t v39 = v122;
  v101(v123, enum case for FeatureType.ShapedArrayParameters.DataType.float32(_:), v122);
  uint64_t v40 = v107;
  static FeatureType.shapedArray(dataType:shape:optional:)(v38, &outlined read-only object #0 of static MLSoundClassifier.VGGishFeatureExtractor.buildFeatureEmbeddingNeuralNetworkSpec(outputName:), 0);
  uint64_t v116 = *(void *)(v37 + 8);
  ((void (*)(unsigned char *, uint64_t))v116)(v38, v39);
  uint64_t v41 = v119;
  FeatureDescription.type.setter(v40);
  uint64_t v103 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  uint64_t v42 = v117;
  uint64_t v43 = *(unsigned __int8 *)(v117 + 80);
  uint64_t v44 = ((int)v43 + 32) & ~*(unsigned __int8 *)(v117 + 80);
  uint64_t v104 = v44 + *(void *)(v117 + 72);
  uint64_t v102 = v43 | 7;
  uint64_t v45 = swift_allocObject(v103, v104, v43 | 7);
  *(void *)(v45 + 16) = 1;
  *(void *)(v45 + 24) = 2;
  uint64_t v105 = *(void (**)(uint64_t, unsigned char *, uint64_t))(v42 + 16);
  v105(v45 + v44, v41, v118);
  Model.inputs.setter(v45);
  FeatureDescription.init()();
  uint64_t v46 = v124;
  swift_bridgeObjectRetain(v124);
  FeatureDescription.name.setter(v121, v46);
  uint64_t v47 = v123;
  uint64_t v48 = v122;
  v101(v123, v128, v122);
  uint64_t v49 = v107;
  static FeatureType.shapedArray(dataType:shape:optional:)(v47, &outlined read-only object #1 of static MLSoundClassifier.VGGishFeatureExtractor.buildFeatureEmbeddingNeuralNetworkSpec(outputName:), 0);
  ((void (*)(unsigned char *, uint64_t))v116)(v47, v48);
  uint64_t v50 = v120;
  FeatureDescription.type.setter(v49);
  uint64_t v51 = swift_allocObject(v103, v104, v102);
  *(void *)(v51 + 16) = 1;
  *(void *)(v51 + 24) = 2;
  v105(v51 + v44, v50, v118);
  Model.outputs.setter(v51);
  uint64_t v52 = v100;
  Model.kind.getter();
  uint64_t v53 = v52;
  uint64_t v54 = v52;
  uint64_t v55 = v108;
  uint64_t v56 = v109;
  int v57 = (*(uint64_t (**)(unsigned char *, uint64_t))(v109 + 88))(v54, v108);
  if (v57 != enum case for ModelKind.neuralNetwork(_:))
  {
    *(void *)&long long v126 = *(void *)(v56 + 8);
    ((void (*)(unsigned char *, uint64_t))v126)(v53, v55);
    *(void *)&v99[0] = 0;
    *((void *)&v99[0] + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(52);
    v88._uint64_t countAndFlagsBits = 0xD000000000000029;
    v88._char object = "preprocessedAudio" + 0x8000000000000000;
    String.append(_:)(v88);
    uint64_t v89 = v110;
    Model.kind.getter();
    _print_unlocked<A, B>(_:_:)(v89, v99, v55, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    ((void (*)(unsigned char *, uint64_t))v126)(v89, v55);
    v88._uint64_t countAndFlagsBits = 0x64616574736E6920;
    v88._char object = (void *)0xE90000000000002ELL;
    String.append(_:)(v88);
    long long v126 = v99[0];
    v88._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v90 = swift_allocError(&type metadata for MLCreateError, v88._object, 0, 0);
    *(_OWORD *)uint64_t v91 = v126;
    *(_OWORD *)(v91 + 16) = 0;
    *(_OWORD *)(v91 + 32) = 0;
    *(unsigned char *)(v91 + 48) = 2;
    *(void *)&long long v126 = v90;
    swift_willThrow(&type metadata for MLCreateError, v88._object, v91, v92, v93, v94);
    uint64_t v95 = *(void (**)(unsigned char *, uint64_t))(v117 + 8);
    uint64_t v96 = v118;
    v95(v120, v118);
    v95(v119, v96);
    uint64_t v97 = type metadata accessor for Model(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v97 - 8) + 8))(v127, v97);
    uint64_t v25 = v113;
    uint64_t v24 = v114;
    char v31 = v115;
    return (*(uint64_t (**)(unsigned char *, uint64_t))(v25 + 8))(v31, v24);
  }
  LODWORD(v122) = v57;
  (*(void (**)(unsigned char *, uint64_t))(v56 + 96))(v53, v55);
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v112 + 32))(v125, v53, v111);
  uint64_t v128 = (unsigned char *)NeuralNetwork.layers.modify(v99);
  uint64_t v59 = v58;
  uint64_t v60 = (void *)*v58;
  char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(*v58);
  *uint64_t v59 = v60;
  if (!isUniquelyReferenced_nonNull_native)
  {
    uint64_t v60 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v60);
    *uint64_t v59 = v60;
  }
  if (!v60[2]) {
    BUG();
  }
  uint64_t v123 = *(unsigned char **)(type metadata accessor for NeuralNetwork.Layer(0) - 8);
  uint64_t v62 = (void (*)(unsigned char *, void))NeuralNetwork.Layer.inputNames.modify(v98);
  uint64_t v64 = v63;
  uint64_t v65 = (void *)*v63;
  char v66 = swift_isUniquelyReferenced_nonNull_native(*v63);
  *uint64_t v64 = v65;
  if (!v66)
  {
    uint64_t v65 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v65);
    *uint64_t v64 = v65;
  }
  if (!v65[2]) {
    BUG();
  }
  uint64_t v67 = v65[5];
  void v65[4] = 0xD000000000000011;
  v65[5] = v106;
  swift_bridgeObjectRelease(v67);
  v62(v98, 0);
  ((void (*)(_OWORD *, void))v128)(v99, 0);
  uint64_t v68 = NeuralNetwork.layers.getter();
  unint64_t v69 = *(void *)(v68 + 16);
  swift_bridgeObjectRelease(v68);
  swift_bridgeObjectRetain(v124);
  uint64_t v128 = (unsigned char *)NeuralNetwork.layers.modify(v99);
  uint64_t v71 = v70;
  uint64_t v72 = (void *)*v70;
  char v73 = swift_isUniquelyReferenced_nonNull_native(*v70);
  *uint64_t v71 = v72;
  if (!v73)
  {
    uint64_t v72 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v72);
    *uint64_t v71 = v72;
  }
  if (!v69) {
    BUG();
  }
  if (v69 > v72[2]) {
    BUG();
  }
  uint64_t v74 = (void (*)(unsigned char *, void))NeuralNetwork.Layer.outputNames.modify(v98);
  uint64_t v76 = v75;
  uint64_t v77 = (void *)*v75;
  char v78 = swift_isUniquelyReferenced_nonNull_native(*v75);
  void *v76 = v77;
  if (!v78)
  {
    uint64_t v77 = specialized _ArrayBuffer._consumeAndCreateNew()((uint64_t)v77);
    void *v76 = v77;
  }
  uint64_t v79 = v124;
  uint64_t v80 = v125;
  if (!v77[2]) {
    BUG();
  }
  uint64_t v81 = v77[5];
  v77[4] = v121;
  v77[5] = v79;
  swift_bridgeObjectRelease(v81);
  v74(v98, 0);
  ((void (*)(_OWORD *, void))v128)(v99, 0);
  uint64_t v82 = v110;
  uint64_t v83 = v80;
  uint64_t v84 = v111;
  uint64_t v85 = v112;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v112 + 16))(v110, v83, v111);
  (*(void (**)(unsigned char *, void, uint64_t))(v109 + 104))(v82, v122, v108);
  Model.kind.setter(v82);
  (*(void (**)(unsigned char *, uint64_t))(v85 + 8))(v125, v84);
  uint64_t v86 = *(void (**)(unsigned char *, uint64_t))(v117 + 8);
  uint64_t v87 = v118;
  v86(v120, v118);
  v86(v119, v87);
  return (*(uint64_t (**)(unsigned char *, uint64_t))(v113 + 8))(v115, v114);
}

uint64_t static MLSoundClassifier.VGGishFeatureExtractor.buildCoreMLSpec(outputName:)(uint64_t a1, uint64_t a2)
{
  uint64_t v43 = v3;
  uint64_t v4 = v2;
  uint64_t v35 = type metadata accessor for ModelKind(0);
  uint64_t v34 = *(void *)(v35 - 8);
  int64_t v5 = *(void *)(v34 + 64);
  int v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  uint64_t v36 = &v34;
  uint64_t v42 = type metadata accessor for Model(0);
  uint64_t v40 = *(void *)(v42 - 8);
  int64_t v8 = *(void *)(v40 + 64);
  int64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  uint64_t v39 = &v34;
  uint64_t v11 = alloca(v8);
  int64_t v12 = alloca(v8);
  Model.init()();
  Model.specificationVersion.setter(4);
  swift_bridgeObjectRetain(a2);
  uint64_t v41 = a1;
  Model.predictedFeatureName.setter(a1, a2);
  uint64_t v38 = v4;
  Model.modelDescription.setter(0xD00000000000002CLL, "in retrieved features." + 0x8000000000000000);
  uint64_t v13 = v43;
  static MLSoundClassifier.VGGishFeatureExtractor.buildSoundAnalysisPreprocessingSpec()();
  if (v13) {
    return (*(uint64_t (**)(uint64_t, uint64_t))(v40 + 8))(v38, v42);
  }
  uint64_t v14 = v40;
  static MLSoundClassifier.VGGishFeatureExtractor.buildFeatureEmbeddingNeuralNetworkSpec(outputName:)(v41, a2);
  uint64_t v43 = 0;
  uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Model>);
  uint64_t v41 = *(void *)(v14 + 72);
  uint64_t v17 = *(unsigned __int8 *)(v14 + 80);
  uint64_t v18 = ((int)v17 + 32) & ~*(unsigned __int8 *)(v14 + 80);
  uint64_t v19 = swift_allocObject(v16, v18 + 2 * v41, v17 | 7);
  uint64_t v37 = &v34;
  uint64_t v20 = v19;
  *(void *)(v19 + 16) = 2;
  *(void *)(v19 + 24) = 4;
  uint64_t v21 = v19 + v18;
  uint64_t v22 = *(void (**)(uint64_t, uint64_t *, uint64_t))(v14 + 16);
  uint64_t v23 = v42;
  v22(v21, &v34, v42);
  uint64_t v24 = v41 + v21;
  uint64_t v25 = v39;
  v22(v24, v39, v23);
  int64_t v26 = v36;
  PipelineClassifierConfiguration.init(models:names:)(v20, _swiftEmptyArrayStorage);
  uint64_t v27 = enum case for ModelKind.pipelineClassifier(_:);
  (*(void (**)(uint64_t *, void, uint64_t))(v34 + 104))(v26, enum case for ModelKind.pipelineClassifier(_:), v35);
  Model.kind.setter(v26);
  uint64_t v28 = v37;
  uint64_t v29 = Model.inputs.getter();
  Model.inputs.setter(v29);
  uint64_t v30 = Model.outputs.getter(v29, v27);
  Model.outputs.setter(v30);
  char v31 = *(void (**)(uint64_t *, uint64_t))(v40 + 8);
  uint64_t v32 = v25;
  uint64_t v33 = v42;
  v31(v32, v42);
  return ((uint64_t (*)(uint64_t *, uint64_t))v31)(v28, v33);
}

uint64_t *initializeBufferWithCopyOfBuffer for MLLinearRegressor.PersistentParameters(uint64_t *a1, uint64_t *a2, int *a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v10 = *a2;
    *uint64_t v3 = *a2;
    uint64_t v3 = (uint64_t *)(v10 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    uint64_t v6 = type metadata accessor for DataFrame(0);
    uint64_t v21 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(*(void *)(v6 - 8) + 16);
    v21(a1, a2, v6);
    uint64_t v7 = a3[5];
    __dst = (char *)a1 + v7;
    int64_t v8 = (char *)a2 + v7;
    if (__swift_getEnumTagSinglePayload((uint64_t)v8, 1, v6))
    {
      uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
      memcpy(__dst, v8, *(void *)(*(void *)(v9 - 8) + 64));
    }
    else
    {
      v21((uint64_t *)__dst, (uint64_t *)v8, v6);
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v6);
    }
    uint64_t v11 = a3[6];
    *(uint64_t *)((char *)a1 + v11) = *(uint64_t *)((char *)a2 + v11);
    uint64_t v12 = *(uint64_t *)((char *)a2 + v11 + 8);
    *(uint64_t *)((char *)v3 + v11 + 8) = v12;
    uint64_t v13 = a3[7];
    uint64_t v14 = *(uint64_t *)((char *)a2 + v13);
    *(uint64_t *)((char *)v3 + v13) = v14;
    uint64_t v15 = a3[8];
    uint64_t v16 = (char *)v3 + v15;
    uint64_t v17 = (char *)a2 + v15;
    uint64_t v18 = *(uint64_t *)((char *)a2 + v15 + 24);
    swift_bridgeObjectRetain(v12);
    swift_bridgeObjectRetain(v14);
    if (v18)
    {
      *((void *)v16 + 3) = v18;
      (**(void (***)(char *, char *, uint64_t))(v18 - 8))(v16, v17, v18);
    }
    else
    {
      long long v19 = *(_OWORD *)v17;
      *((_OWORD *)v16 + 1) = *((_OWORD *)v17 + 1);
      *(_OWORD *)uint64_t v16 = v19;
    }
    *((_OWORD *)v16 + 2) = *((_OWORD *)v17 + 2);
    *((_OWORD *)v16 + 3) = *((_OWORD *)v17 + 3);
    *((void *)v16 + 8) = *((void *)v17 + 8);
    v16[72] = v17[72];
  }
  return v3;
}

uint64_t destroy for MLLinearRegressor.PersistentParameters(uint64_t a1, int *a2)
{
  uint64_t v2 = type metadata accessor for DataFrame(0);
  uint64_t v3 = *(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8);
  v3(a1, v2);
  uint64_t v4 = a1 + a2[5];
  if (!__swift_getEnumTagSinglePayload(v4, 1, v2)) {
    v3(v4, v2);
  }
  swift_bridgeObjectRelease(*(void *)(a1 + a2[6] + 8));
  swift_bridgeObjectRelease(*(void *)(a1 + a2[7]));
  uint64_t result = a2[8];
  if (*(void *)(a1 + result + 24)) {
    return __swift_destroy_boxed_opaque_existential_1Tm((void *)(result + a1));
  }
  return result;
}

char *initializeWithCopy for MLLinearRegressor.PersistentParameters(char *a1, char *a2, int *a3)
{
  uint64_t v5 = type metadata accessor for DataFrame(0);
  long long v19 = *(void (**)(void *, const void *, uint64_t))(*(void *)(v5 - 8) + 16);
  v19(a1, a2, v5);
  uint64_t v6 = a3[5];
  __dst = &a1[v6];
  uint64_t v7 = &a2[v6];
  if (__swift_getEnumTagSinglePayload((uint64_t)v7, 1, v5))
  {
    uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(__dst, v7, *(void *)(*(void *)(v8 - 8) + 64));
  }
  else
  {
    v19(__dst, v7, v5);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v5);
  }
  uint64_t v9 = a3[6];
  *(void *)&a1[v9] = *(void *)&a2[v9];
  uint64_t v10 = *(void *)&a2[v9 + 8];
  *(void *)&a1[v9 + 8] = v10;
  uint64_t v11 = a3[7];
  uint64_t v12 = *(void *)&a2[v11];
  *(void *)&a1[v11] = v12;
  uint64_t v13 = a3[8];
  uint64_t v14 = &a1[v13];
  uint64_t v15 = (long long *)&a2[v13];
  uint64_t v16 = *(void *)&a2[v13 + 24];
  swift_bridgeObjectRetain(v10);
  swift_bridgeObjectRetain(v12);
  if (v16)
  {
    *((void *)v14 + 3) = v16;
    (**(void (***)(uint64_t, long long *, uint64_t))(v16 - 8))((uint64_t)v14, v15, v16);
  }
  else
  {
    long long v17 = *v15;
    *((_OWORD *)v14 + 1) = v15[1];
    *(_OWORD *)uint64_t v14 = v17;
  }
  *((_OWORD *)v14 + 2) = v15[2];
  *((_OWORD *)v14 + 3) = v15[3];
  *((void *)v14 + 8) = *((void *)v15 + 8);
  v14[72] = *((unsigned char *)v15 + 72);
  return a1;
}

uint64_t assignWithCopy for MLLinearRegressor.PersistentParameters(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v5 = type metadata accessor for DataFrame(0);
  uint64_t v27 = *(void *)(v5 - 8);
  int64_t v26 = *(void (**)(uint64_t, uint64_t, uint64_t))(v27 + 24);
  v26(a1, a2, v5);
  uint64_t v25 = a3;
  uint64_t v6 = a3[5];
  uint64_t v7 = (void *)(a1 + v6);
  uint64_t v8 = (const void *)(a2 + v6);
  LODWORD(a3) = __swift_getEnumTagSinglePayload((uint64_t)v7, 1, v5);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v8, 1, v5);
  if (a3)
  {
    if (EnumTagSinglePayload)
    {
      size_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
LABEL_6:
      memcpy(v7, v8, v11);
      goto LABEL_9;
    }
    (*(void (**)(void *, const void *, uint64_t))(v27 + 16))(v7, v8, v5);
    __swift_storeEnumTagSinglePayload((uint64_t)v7, 0, 1, v5);
  }
  else
  {
    if (EnumTagSinglePayload)
    {
      (*(void (**)(void *, uint64_t, uint64_t, void (*)(uint64_t, uint64_t, uint64_t)))(v27 + 8))(v7, v5, v10, v26);
      size_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      goto LABEL_6;
    }
    v26((uint64_t)v7, (uint64_t)v8, v5);
  }
LABEL_9:
  uint64_t v12 = v25[6];
  *(void *)(a1 + v12) = *(void *)(a2 + v12);
  uint64_t v13 = *(void *)(a2 + v12 + 8);
  uint64_t v14 = *(void *)(a1 + v12 + 8);
  *(void *)(a1 + v12 + 8) = v13;
  swift_bridgeObjectRetain(v13);
  swift_bridgeObjectRelease(v14);
  uint64_t v15 = v25[7];
  uint64_t v16 = *(void *)(a2 + v15);
  uint64_t v17 = *(void *)(a1 + v15);
  *(void *)(a1 + v15) = v16;
  swift_bridgeObjectRetain(v16);
  swift_bridgeObjectRelease(v17);
  uint64_t v18 = v25[8];
  uint64_t v19 = a1 + v18;
  uint64_t v20 = (long long *)(a2 + v18);
  uint64_t v21 = *(void *)(a2 + v18 + 24);
  if (!*(void *)(a1 + v18 + 24))
  {
    if (v21)
    {
      *(void *)(v19 + 24) = v21;
      (**(void (***)(uint64_t, long long *))(v21 - 8))(v19, v20);
      goto LABEL_16;
    }
LABEL_15:
    long long v23 = *v20;
    *(_OWORD *)(v19 + 16) = v20[1];
    *(_OWORD *)uint64_t v19 = v23;
    goto LABEL_16;
  }
  uint64_t v22 = (uint64_t *)(a1 + v18);
  if (!v21)
  {
    __swift_destroy_boxed_opaque_existential_1Tm(v22);
    goto LABEL_15;
  }
  __swift_assign_boxed_opaque_existential_0(v22, (uint64_t *)(a2 + v18));
LABEL_16:
  *(void *)(v19 + 32) = *((void *)v20 + 4);
  *(void *)(v19 + 40) = *((void *)v20 + 5);
  *(void *)(v19 + 48) = *((void *)v20 + 6);
  *(void *)(v19 + 56) = *((void *)v20 + 7);
  *(void *)(v19 + 64) = *((void *)v20 + 8);
  *(unsigned char *)(v19 + 72) = *((unsigned char *)v20 + 72);
  return a1;
}

uint64_t assignWithTake for MLLinearRegressor.PersistentParameters(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v5 = type metadata accessor for DataFrame(0);
  uint64_t v22 = *(void *)(v5 - 8);
  uint64_t v21 = *(void (**)(uint64_t, uint64_t, uint64_t))(v22 + 40);
  v21(a1, a2, v5);
  uint64_t v20 = a3;
  uint64_t v6 = a3[5];
  uint64_t v7 = (void *)(a1 + v6);
  uint64_t v8 = (const void *)(a2 + v6);
  LODWORD(a3) = __swift_getEnumTagSinglePayload((uint64_t)v7, 1, v5);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v8, 1, v5);
  if (a3)
  {
    if (EnumTagSinglePayload)
    {
      size_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
LABEL_6:
      memcpy(v7, v8, v11);
      goto LABEL_9;
    }
    (*(void (**)(void *, const void *, uint64_t))(v22 + 32))(v7, v8, v5);
    __swift_storeEnumTagSinglePayload((uint64_t)v7, 0, 1, v5);
  }
  else
  {
    if (EnumTagSinglePayload)
    {
      (*(void (**)(void *, uint64_t, uint64_t, void (*)(uint64_t, uint64_t, uint64_t)))(v22 + 8))(v7, v5, v10, v21);
      size_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                  - 8)
                      + 64);
      goto LABEL_6;
    }
    v21((uint64_t)v7, (uint64_t)v8, v5);
  }
LABEL_9:
  uint64_t v12 = v20[6];
  *(void *)(a1 + v12) = *(void *)(a2 + v12);
  uint64_t v13 = *(void *)(a1 + v12 + 8);
  *(void *)(a1 + v12 + 8) = *(void *)(a2 + v12 + 8);
  swift_bridgeObjectRelease(v13);
  uint64_t v14 = v20[7];
  uint64_t v15 = *(void *)(a1 + v14);
  *(void *)(a1 + v14) = *(void *)(a2 + v14);
  swift_bridgeObjectRelease(v15);
  uint64_t v16 = v20[8];
  uint64_t v17 = (_OWORD *)(a1 + v16);
  if (*(void *)(a1 + v16 + 24)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + v16));
  }
  long long v18 = *(_OWORD *)(a2 + v16);
  v17[1] = *(_OWORD *)(a2 + v16 + 16);
  *uint64_t v17 = v18;
  *(void *)(a1 + v16 + 32) = *(void *)(a2 + v16 + 32);
  *(_OWORD *)(a1 + v16 + 40) = *(_OWORD *)(a2 + v16 + 40);
  *(_OWORD *)(a1 + v16 + 56) = *(_OWORD *)(a2 + v16 + 56);
  *(unsigned char *)(a1 + v16 + 72) = *(unsigned char *)(a2 + v16 + 72);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLinearRegressor.PersistentParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_114C56);
}

uint64_t sub_114C56(uint64_t a1, unsigned int a2, uint64_t a3)
{
  uint64_t v4 = a1;
  uint64_t v5 = type metadata accessor for DataFrame(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(v4, a2, v5);
  }
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2)
  {
    uint64_t v4 = *(int *)(a3 + 20) + a1;
    return __swift_getEnumTagSinglePayload(v4, a2, v5);
  }
  uint64_t result = 0;
  if ((*(void *)(a1 + *(int *)(a3 + 24) + 8) & 0xFFFFFFFF00000001) == 0) {
    return (*(void *)(a1 + *(int *)(a3 + 24) + 8) >> 1) + 1;
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLLinearRegressor.PersistentParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_114CEA);
}

uint64_t sub_114CEA(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = a1;
  uint64_t v7 = type metadata accessor for DataFrame(0);
  if (*(_DWORD *)(*(void *)(v7 - 8) + 84) == a3) {
    return __swift_storeEnumTagSinglePayload(v6, a2, a2, v7);
  }
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  if (*(_DWORD *)(*(void *)(v7 - 8) + 84) == a3)
  {
    uint64_t v6 = *(int *)(a4 + 20) + a1;
    return __swift_storeEnumTagSinglePayload(v6, a2, a2, v7);
  }
  uint64_t result = *(int *)(a4 + 24);
  *(void *)(a1 + result + 8) = 2 * (a2 - 1);
  return result;
}

uint64_t type metadata accessor for MLLinearRegressor.PersistentParameters(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLLinearRegressor.PersistentParameters;
  if (!type metadata singleton initialization cache for MLLinearRegressor.PersistentParameters) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLLinearRegressor.PersistentParameters);
  }
  return result;
}

uint64_t type metadata completion function for MLLinearRegressor.PersistentParameters(uint64_t a1)
{
  uint64_t result = type metadata accessor for DataFrame(319);
  if (v2 <= 0x3F)
  {
    v4[0] = *(void *)(result - 8) + 64;
    uint64_t result = type metadata accessor for DataFrame?(319);
    if (v3 <= 0x3F)
    {
      v4[1] = *(void *)(result - 8) + 64;
      v4[2] = &unk_34AA78;
      v4[3] = (char *)&value witness table for Builtin.BridgeObject + 64;
      v4[4] = &unk_34AA90;
      swift_initStructMetadata(a1, 256, 5, v4, a1 + 16);
      return 0;
    }
  }
  return result;
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML17MLLinearRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML17ij13V20Persistentl48V16sessionDirectoryAE10Foundation3URLV_tKcfcAC05k5F0V14md3O07c5M00M5E17VcAMmcfu_AmPcfu0_AOXMtTf1ncn_n(uint64_t a1)
{
  uint64_t v19 = v1;
  uint64_t v2 = type metadata accessor for DataFrame(0);
  uint64_t v17 = *(void *)(v2 - 8);
  int64_t v3 = *(void *)(v17 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                             - 8)
                 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  outlined init with copy of DataFrame?(a1, (uint64_t)&v16);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v16, 1, v2) == 1)
  {
    uint64_t v9 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
    uint64_t v10 = v19;
    uint64_t v11 = 1;
    uint64_t v12 = v9;
  }
  else
  {
    uint64_t v13 = v17;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v17 + 32))(&v16, &v16, v2);
    uint64_t v14 = v19;
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v13 + 16))(v19, &v16, v2);
    uint64_t v18 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
    swift_storeEnumTagMultiPayload(v14, v18, 2);
    (*(void (**)(uint64_t *, uint64_t))(v13 + 8))(&v16, v2);
    uint64_t v10 = v14;
    uint64_t v11 = 0;
    uint64_t v12 = v18;
  }
  return __swift_storeEnumTagSinglePayload(v10, v11, 1, v12);
}

NSURL *MLLinearRegressor.PersistentParameters.init(sessionDirectory:)(uint64_t *a1)
{
  uint64_t v162 = v2;
  uint64_t v4 = v1;
  uint64_t v139 = type metadata accessor for CSVType(0);
  uint64_t v128 = *(void *)(v139 - 8);
  int64_t v5 = *(void *)(v128 + 64);
  int64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  long long v138 = &v125;
  int64_t v8 = *(void *)(*(void *)(type metadata accessor for CSVReadingOptions(0) - 8) + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v127 = &v125;
  uint64_t v11 = alloca(v8);
  uint64_t v12 = alloca(v8);
  uint64_t v130 = &v125;
  int64_t v13 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLLinearRegressor.ModelParameters.ValidationData?)
                              - 8)
                  + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  unint64_t v144 = &v125;
  int64_t v16 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                              - 8)
                  + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  long long v142 = &v125;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v159 = &v125;
  uint64_t v21 = type metadata accessor for DataFrame(0);
  uint64_t v141 = *(void *)(v21 - 8);
  int64_t v22 = *(void *)(v141 + 64);
  long long v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  uint64_t v140 = &v125;
  uint64_t v25 = alloca(v22);
  int64_t v26 = alloca(v22);
  uint64_t v149 = &v125;
  uint64_t v151 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  int64_t v27 = *(void *)(*(void *)(v151 - 8) + 64);
  uint64_t v28 = alloca(v27);
  uint64_t v29 = alloca(v27);
  uint64_t v145 = &v125;
  uint64_t v30 = alloca(v27);
  char v31 = alloca(v27);
  long long v126 = &v125;
  uint64_t v32 = alloca(v27);
  uint64_t v33 = alloca(v27);
  uint64_t v153 = &v125;
  uint64_t v166 = type metadata accessor for URL(0);
  uint64_t v161 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v166 - 8);
  int64_t v34 = *((void *)v161 + 8);
  uint64_t v35 = alloca(v34);
  uint64_t v36 = alloca(v34);
  uint64_t v137 = &v125;
  uint64_t v37 = alloca(v34);
  uint64_t v38 = alloca(v34);
  Swift::String v143 = &v125;
  uint64_t v39 = alloca(v34);
  uint64_t v40 = alloca(v34);
  uint64_t v129 = &v125;
  uint64_t v41 = alloca(v34);
  uint64_t v42 = alloca(v34);
  uint64_t v146 = &v125;
  uint64_t v43 = alloca(v34);
  uint64_t v44 = alloca(v34);
  uint64_t v152 = &v125;
  uint64_t v45 = alloca(v34);
  uint64_t v46 = alloca(v34);
  uint64_t v148 = &v125;
  uint64_t v47 = alloca(v34);
  uint64_t v48 = alloca(v34);
  uint64_t v147 = type metadata accessor for MLLinearRegressor.PersistentParameters(0);
  uint64_t v49 = *(int *)(v147 + 20);
  uint64_t v158 = v4;
  uint64_t v157 = (uint64_t)v4 + v49;
  uint64_t v150 = v21;
  __swift_storeEnumTagSinglePayload((uint64_t)v4 + v49, 1, 1, v21);
  URL.appendingPathComponent(_:)(0xD000000000000010, "ObjectDetectorMetrics." + 0x8000000000000000);
  uint64_t v50 = v162;
  uint64_t v51 = Data.init(contentsOf:options:)(&v125, 0);
  uint64_t v162 = v50;
  if (v50)
  {
    uint64_t v53 = (void (*)(uint64_t, uint64_t))*((void *)v161 + 1);
    uint64_t v54 = a1;
    uint64_t v55 = v166;
    v53((uint64_t)v54, v166);
    v53((uint64_t)&v125, v55);
    uint64_t v56 = v157;
LABEL_39:
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v56, &demangling cache variable for type metadata for DataFrame?);
    return __stack_chk_guard;
  }
  uint64_t v57 = v51;
  unint64_t v58 = v52;
  Swift::String v165 = a1;
  uint64_t v59 = v166;
  uint64_t v154 = (void (*)(uint64_t *, uint64_t))*((void *)v161 + 1);
  v154(&v125, v166);
  uint64_t v60 = objc_opt_self(NSPropertyListSerialization);
  v61.super.Class isa = Data._bridgeToObjectiveC()().super.isa;
  uint64_t v156 = v57;
  Class isa = v61.super.isa;
  unint64_t v155 = v58;
  v168[0] = 0;
  id v63 = [v60 propertyListWithData:v61.super.isa options:0 format:0 error:v168];
  id v64 = v63;

  id v65 = v168[0];
  if (!v64)
  {
    uint64_t v87 = v65;
    _convertNSErrorToError(_:)(v65);

    swift_willThrow(v87, "propertyListWithData:options:format:error:", v88, v89, v90, v91);
    outlined consume of Data._Representation(v156, v155);
    v154(v165, v59);
LABEL_38:
    uint64_t v56 = v157;
    goto LABEL_39;
  }
  _bridgeAnyObjectToAny(_:)(v64);
  swift_unknownObjectRelease(v64);
  outlined init with copy of Any((uint64_t)v170, (uint64_t)v168);
  uint64_t v66 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any]);
  if (!swift_dynamicCast(v167, v168, (char *)&type metadata for Any + 8, v66, 6))
  {
    uint64_t v92 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v92, 0, 0);
    *(void *)uint64_t v93 = 0xD000000000000037;
    *(void *)(v93 + 8) = "parameters.plist" + 0x8000000000000000;
    *(_OWORD *)(v93 + 16) = 0;
    *(_OWORD *)(v93 + 32) = 0;
    *(unsigned char *)(v93 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v92, v93, v94, v95, v96);
    outlined consume of Data._Representation(v156, v155);
    uint64_t v97 = v165;
    uint64_t v98 = v166;
LABEL_37:
    v154(v97, v98);
    __swift_destroy_boxed_opaque_existential_1Tm(v170);
    goto LABEL_38;
  }
  uint64_t v67 = v167[0];
  specialized Dictionary.subscript.getter(0x746567726174, 0xE600000000000000, v167[0]);
  if (!v169) {
    goto LABEL_34;
  }
  if (!swift_dynamicCast(v167, v168, (char *)&type metadata for Any + 8, &type metadata for String, 6))
  {
LABEL_29:
    char v101 = v67;
LABEL_30:
    swift_bridgeObjectRelease(v101);
LABEL_36:
    uint64_t v103 = v165;
    uint64_t v104 = v166;
    uint64_t v105 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v105, 0, 0);
    *(void *)uint64_t v106 = 0xD000000000000034;
    *(void *)(v106 + 8) = "ad training parameters." + 0x8000000000000000;
    *(_OWORD *)(v106 + 16) = 0;
    *(_OWORD *)(v106 + 32) = 0;
    *(unsigned char *)(v106 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v105, v106, v107, v108, v109);
    outlined consume of Data._Representation(v156, v155);
    uint64_t v97 = v103;
    uint64_t v98 = v104;
    goto LABEL_37;
  }
  uint64_t v131 = v167[0];
  uint64_t v68 = v167[1];
  specialized Dictionary.subscript.getter(0xD000000000000010, (uint64_t)("training parameters." + 0x8000000000000000), v67);
  if (!v169)
  {
    char v99 = v68;
LABEL_33:
    swift_bridgeObjectRelease(v99);
LABEL_34:
    char v102 = v67;
LABEL_35:
    swift_bridgeObjectRelease(v102);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v168, &demangling cache variable for type metadata for Any?);
    goto LABEL_36;
  }
  uint64_t v164 = v68;
  uint64_t v69 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  if (!swift_dynamicCast(v167, v168, (char *)&type metadata for Any + 8, v69, 6))
  {
LABEL_28:
    swift_bridgeObjectRelease(v164);
    goto LABEL_29;
  }
  uint64_t v70 = v167[0];
  specialized Dictionary.subscript.getter(0x617265744978616DLL, 0xED0000736E6F6974, v67);
  if (!v169)
  {
    char v100 = v70;
LABEL_32:
    swift_bridgeObjectRelease(v100);
    char v99 = v164;
    goto LABEL_33;
  }
  uint64_t v163 = v70;
  if (!swift_dynamicCast(v167, v168, (char *)&type metadata for Any + 8, &type metadata for Int, 6)) {
    goto LABEL_27;
  }
  uint64_t v132 = v167[0];
  specialized Dictionary.subscript.getter(0x746C616E6550316CLL, 0xE900000000000079, v67);
  if (!v169) {
    goto LABEL_31;
  }
  uint64_t v160 = v67;
  if (!swift_dynamicCast(v167, v168, (char *)&type metadata for Any + 8, &type metadata for Double, 6))goto LABEL_41; {
  uint64_t v133 = v167[0];
  }
  char v71 = v160;
  specialized Dictionary.subscript.getter(0x746C616E6550326CLL, 0xE900000000000079, v160);
  if (!v169)
  {
    swift_bridgeObjectRelease(v163);
    swift_bridgeObjectRelease(v164);
    char v102 = v71;
    goto LABEL_35;
  }
  if (!swift_dynamicCast(v167, v168, (char *)&type metadata for Any + 8, &type metadata for Double, 6))
  {
LABEL_41:
    swift_bridgeObjectRelease(v163);
    swift_bridgeObjectRelease(v164);
    char v101 = v160;
    goto LABEL_30;
  }
  uint64_t v134 = v167[0];
  uint64_t v67 = v160;
  specialized Dictionary.subscript.getter(0x657A695370657473, 0xE800000000000000, v160);
  if (!v169) {
    goto LABEL_31;
  }
  if (!swift_dynamicCast(v167, v168, (char *)&type metadata for Any + 8, &type metadata for Double, 6))
  {
LABEL_27:
    swift_bridgeObjectRelease(v163);
    goto LABEL_28;
  }
  uint64_t v135 = v167[0];
  specialized Dictionary.subscript.getter(0xD000000000000014, (uint64_t)("oating-point numbers." + 0x8000000000000000), v67);
  if (!v169)
  {
LABEL_31:
    char v100 = v163;
    goto LABEL_32;
  }
  if (!swift_dynamicCast(v167, v168, (char *)&type metadata for Any + 8, &type metadata for Double, 6))goto LABEL_27; {
  uint64_t v136 = v167[0];
  }
  specialized Dictionary.subscript.getter(0xD000000000000010, (uint64_t)("convergenceThreshold" + 0x8000000000000000), v67);
  swift_bridgeObjectRelease(v67);
  if (!v169)
  {
    swift_bridgeObjectRelease(v163);
    char v102 = v164;
    goto LABEL_35;
  }
  if (!swift_dynamicCast(v167, v168, (char *)&type metadata for Any + 8, &type metadata for Bool, 6))
  {
    swift_bridgeObjectRelease(v163);
    char v101 = v164;
    goto LABEL_30;
  }
  LOBYTE(v160) = v167[0];
  uint64_t v72 = v147;
  uint64_t v73 = *(int *)(v147 + 24);
  uint64_t v74 = v158;
  *(void *)((char *)v158 + v73) = v131;
  *(void *)((char *)v74 + v73 + 8) = v164;
  *(void *)((char *)v74 + *(int *)(v72 + 28)) = v163;
  uint64_t v75 = (uint64_t)v153;
  *(_OWORD *)uint64_t v153 = 0;
  *(_WORD *)(v75 + 16) = 256;
  swift_storeEnumTagMultiPayload(v75, v151, 0);
  uint64_t v76 = *(int *)(v72 + 32);
  uint64_t v164 = (uint64_t)v74 + v76;
  *(_OWORD *)((char *)v74 + v76 + 16) = 0;
  *(_OWORD *)((char *)v74 + v76) = 0;
  *(void *)((char *)v74 + v76 + 32) = 10;
  *(__m128 *)((char *)v74 + v76 + 40) = _mm_loadh_ps((const double *)&qword_349108);
  *(_OWORD *)((char *)v74 + v76 + 56) = xmmword_349110;
  *((unsigned char *)v74 + v76 + 72) = 1;
  uint64_t v77 = (uint64_t)v126;
  outlined init with copy of MLLinearRegressor.ModelParameters.ValidationData(v75, (uint64_t)v126);
  uint64_t v169 = v151;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v168);
  outlined init with take of MLLinearRegressor.ModelParameters.ValidationData(v77, (uint64_t)boxed_opaque_existential_1);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v168, v164, &demangling cache variable for type metadata for Any?);
  outlined destroy of MLLinearRegressor.ModelParameters.ValidationData(v75);
  *(void *)((char *)v74 + v76 + 32) = v132;
  *(void *)((char *)v74 + v76 + 40) = v133;
  *(void *)((char *)v74 + v76 + 48) = v134;
  *(void *)((char *)v74 + v76 + 56) = v135;
  *(void *)((char *)v74 + v76 + 64) = v136;
  *((unsigned char *)v74 + v76 + 72) = v160;
  uint64_t v79 = v148;
  URL.appendingPathComponent(_:)(1635017060, 0xE400000000000000);
  URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEE00617461446E6FLL);
  uint64_t v80 = v146;
  uint64_t v161 = (void (*)(uint64_t *, uint64_t *, uint64_t))*((void *)v161 + 2);
  v161(v146, v79, v166);
  uint64_t v81 = v162;
  DataFrame.init(contentsOfSFrameDirectory:columns:rows:)(v80, 0, 0, 0, 1);
  uint64_t v153 = v81;
  if (v81)
  {
    v161(v137, v148, v166);
    uint64_t v162 = specialized Dictionary.init(dictionaryLiteral:)((uint64_t)_swiftEmptyArrayStorage);
    uint64_t v159 = default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
    uint64_t v82 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 2 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
    uint64_t v83 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 3 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
    uint64_t v84 = *(uint64_t **)(v128 + 104);
    uint64_t v85 = v138;
    LODWORD(v146) = enum case for CSVType.double(_:);
    uint64_t v149 = v84;
    ((void (*)(uint64_t *, void, uint64_t))v84)(v138, enum case for CSVType.double(_:), v139);
    uint64_t v86 = v127;
    CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)(1, v159, v82, v83, v85, 1, 1, 0, 44, 0xE100000000000000, 92, 0xE100000000000000);
    DataFrame.init(contentsOfCSVFile:columns:rows:types:options:)(v137, 0, 0, 0, 1, v162, v86);
    uint64_t v162 = 0;
    (*(void (**)(void *, uint64_t *, uint64_t))(v141 + 32))(v158, v140, v150);
    v161(v143, v152, v166);
    uint64_t v161 = (void (*)(uint64_t *, uint64_t *, uint64_t))specialized Dictionary.init(dictionaryLiteral:)((uint64_t)_swiftEmptyArrayStorage);
    uint64_t v158 = default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)();
    uint64_t v147 = (uint64_t)specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 2 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
    uint64_t v114 = specialized Set.init(_nonEmptyArrayLiteral:)((uint64_t)&outlined read-only object #0 of default argument 3 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
    uint64_t v115 = v138;
    ((void (*)(uint64_t *, void, uint64_t))v149)(v138, v146, v139);
    unsigned int v116 = 1;
    uint64_t v117 = v130;
    CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)(1, v158, v147, v114, v115, 1, 1, 0, 44, 0xE100000000000000, 92, 0xE100000000000000);
    uint64_t v118 = v162;
    DataFrame.init(contentsOfCSVFile:columns:rows:types:options:)(v143, 0, 0, 0, 1, v161, v117);
    if (v118) {
      swift_errorRelease(v118);
    }
    else {
      unsigned int v116 = 0;
    }
    swift_errorRelease(v153);
    uint64_t v119 = (uint64_t)v142;
    __swift_storeEnumTagSinglePayload((uint64_t)v142, v116, 1, v150);
    uint64_t v159 = (uint64_t *)v119;
  }
  else
  {
    (*(void (**)(void *, uint64_t *, uint64_t))(v141 + 32))(v158, v149, v150);
    uint64_t v111 = v129;
    v161(v129, v152, v166);
    unsigned int v112 = 1;
    uint64_t v113 = v153;
    DataFrame.init(contentsOfSFrameDirectory:columns:rows:)(v111, 0, 0, 0, 1);
    if (v113) {
      swift_errorRelease(v113);
    }
    else {
      unsigned int v112 = 0;
    }
    __swift_storeEnumTagSinglePayload((uint64_t)v159, v112, 1, v150);
  }
  uint64_t v120 = v157;
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v159, v157, &demangling cache variable for type metadata for DataFrame?);
  uint64_t v121 = (uint64_t)v144;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML17MLLinearRegressorV15ModelParametersV010ValidationD0OTg503_s8g4ML17ij13V20Persistentl48V16sessionDirectoryAE10Foundation3URLV_tKcfcAC05k5F0V14md3O07c5M00M5E17VcAMmcfu_AmPcfu0_AOXMtTf1ncn_n(v120);
  if (__swift_getEnumTagSinglePayload(v121, 1, v151) == 1)
  {
    swift_storeEnumTagMultiPayload(v145, v151, 3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v144, &demangling cache variable for type metadata for MLLinearRegressor.ModelParameters.ValidationData?);
  }
  else
  {
    outlined init with take of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)v144, (uint64_t)v145);
  }
  uint64_t v169 = v151;
  uint64_t v122 = __swift_allocate_boxed_opaque_existential_1(v168);
  outlined init with take of MLLinearRegressor.ModelParameters.ValidationData((uint64_t)v145, (uint64_t)v122);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v168, v164, &demangling cache variable for type metadata for Any?);
  outlined consume of Data._Representation(v156, v155);
  uint64_t v123 = v166;
  uint64_t v124 = v154;
  v154(v165, v166);
  v124(v152, v123);
  v124(v148, v123);
  __swift_destroy_boxed_opaque_existential_1Tm(v170);
  return __stack_chk_guard;
}

NSURL *MLLinearRegressor.PersistentParameters.save(toSessionDirectory:)(uint64_t a1)
{
  uint64_t v68 = v1;
  uint64_t v60 = a1;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                             - 8)
                 + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  id v65 = &v54;
  uint64_t v63 = type metadata accessor for CSVWritingOptions(0);
  uint64_t v59 = *(void *)(v63 - 8);
  int64_t v6 = *(void *)(v59 + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  unint64_t v58 = &v54;
  uint64_t v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  uint64_t v55 = &v54;
  uint64_t v67 = type metadata accessor for URL(0);
  uint64_t v69 = *(void *)(v67 - 8);
  int64_t v11 = *(void *)(v69 + 64);
  uint64_t v12 = alloca(v11);
  int64_t v13 = alloca(v11);
  NSData v61 = &v54;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  uint64_t v56 = &v54;
  int64_t v16 = alloca(v11);
  uint64_t v17 = alloca(v11);
  uint64_t v62 = &v54;
  uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
  uint64_t inited = swift_initStackObject(v18, v71);
  *(void *)(inited + 16) = 8;
  *(void *)(inited + 24) = 16;
  *(void *)(inited + 32) = 0x746567726174;
  *(void *)(inited + 40) = 0xE600000000000000;
  uint64_t v20 = (int *)type metadata accessor for MLLinearRegressor.PersistentParameters(0);
  uint64_t v21 = v20[6];
  uint64_t v22 = *(void *)(v2 + v21);
  uint64_t v66 = *(void *)(v2 + v21 + 8);
  uint64_t v23 = v66;
  *(void *)(inited + 72) = &type metadata for String;
  *(void *)(inited + 48) = v22;
  *(void *)(inited + 56) = v23;
  *(void *)(inited + 80) = 0xD000000000000010;
  *(void *)(inited + 88) = "training parameters." + 0x8000000000000000;
  uint64_t v24 = *(void *)(v2 + v20[7]);
  *(void *)(inited + 120) = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  *(void *)(inited + 96) = v24;
  strcpy((char *)(inited + 128), "maxIterations");
  *(_WORD *)(inited + 142) = -4864;
  uint64_t v57 = v20;
  uint64_t v25 = v20[8];
  uint64_t v26 = *(void *)(v2 + v25 + 32);
  *(void *)(inited + 168) = &type metadata for Int;
  *(void *)(inited + 144) = v26;
  *(void *)(inited + 176) = 0x746C616E6550316CLL;
  *(void *)(inited + 184) = 0xE900000000000079;
  uint64_t v27 = *(void *)(v2 + v25 + 40);
  *(void *)(inited + 216) = &type metadata for Double;
  *(void *)(inited + 192) = v27;
  *(void *)(inited + 224) = 0x746C616E6550326CLL;
  *(void *)(inited + 232) = 0xE900000000000079;
  uint64_t v28 = *(void *)(v2 + v25 + 48);
  *(void *)(inited + 264) = &type metadata for Double;
  *(void *)(inited + 240) = v28;
  *(void *)(inited + 272) = 0x657A695370657473;
  *(void *)(inited + 280) = 0xE800000000000000;
  uint64_t v29 = *(void *)(v2 + v25 + 56);
  *(void *)(inited + 312) = &type metadata for Double;
  *(void *)(inited + 288) = v29;
  *(void *)(inited + 320) = 0xD000000000000014;
  *(void *)(inited + 328) = "oating-point numbers." + 0x8000000000000000;
  uint64_t v30 = *(void *)(v2 + v25 + 64);
  *(void *)(inited + 360) = &type metadata for Double;
  *(void *)(inited + 336) = v30;
  *(void *)(inited + 368) = 0xD000000000000010;
  *(void *)(inited + 376) = "convergenceThreshold" + 0x8000000000000000;
  uint64_t v54 = v2;
  LOBYTE(v25) = *(unsigned char *)(v2 + v25 + 72);
  *(void *)(inited + 408) = &type metadata for Bool;
  *(unsigned char *)(inited + 384) = v25;
  swift_bridgeObjectRetain(v66);
  swift_bridgeObjectRetain(v24);
  LOBYTE(inited) = Dictionary.init(dictionaryLiteral:)(inited, &type metadata for String, (char *)&type metadata for Any + 8, &protocol witness table for String);
  char v31 = objc_opt_self(NSPropertyListSerialization);
  Class isa = Dictionary._bridgeToObjectiveC()().super.isa;
  swift_bridgeObjectRelease(inited);
  id v70 = 0;
  id v33 = [v31 dataWithPropertyList:isa format:200 options:0 error:&v70];
  id v34 = v33;

  id v35 = v70;
  if (v34)
  {
    uint64_t v66 = static Data._unconditionallyBridgeFromObjectiveC(_:)(v34);
    unint64_t v37 = v36;

    uint64_t v38 = v62;
    URL.appendingPathComponent(_:)(0xD000000000000010, "ObjectDetectorMetrics." + 0x8000000000000000);
    uint64_t v39 = v66;
    unint64_t v64 = v37;
    uint64_t v40 = v68;
    Data.write(to:options:)(v38, 0, v66, v37);
    if (v40)
    {
      (*(void (**)(uint64_t *, uint64_t))(v69 + 8))(v38, v67);
      outlined consume of Data._Representation(v39, v64);
    }
    else
    {
      uint64_t v68 = *(void (**)(void, void))(v69 + 8);
      v68(v38, v67);
      uint64_t v46 = v56;
      URL.appendingPathComponent(_:)(1635017060, 0xE400000000000000);
      uint64_t v47 = v55;
      CSVWritingOptions.init(includesHeader:dateFormat:nilEncoding:trueEncoding:falseEncoding:newline:delimiter:)(1, 0, 0, 0, 0xE000000000000000, 1702195828, 0xE400000000000000, 0x65736C6166, 0xE500000000000000, 10, 0xE100000000000000, 44, 0xE100000000000000);
      uint64_t v69 = type metadata accessor for DataFrame(0);
      uint64_t v48 = v54;
      DataFrameProtocol.writeCSV(to:options:)(v46, v47, v69, &protocol witness table for DataFrame);
      uint64_t v62 = *(uint64_t **)(v59 + 8);
      ((void (*)(uint64_t *, uint64_t))v62)(v47, v63);
      v68(v46, v67);
      uint64_t v49 = v57[5] + v48;
      uint64_t v50 = (uint64_t)v65;
      outlined init with copy of DataFrame?(v49, (uint64_t)v65);
      if (__swift_getEnumTagSinglePayload(v50, 1, v69) == 1)
      {
        outlined consume of Data._Representation(v66, v64);
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v50, &demangling cache variable for type metadata for DataFrame?);
      }
      else
      {
        unint64_t v52 = v61;
        URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEE00617461446E6FLL);
        uint64_t v53 = v58;
        CSVWritingOptions.init(includesHeader:dateFormat:nilEncoding:trueEncoding:falseEncoding:newline:delimiter:)(1, 0, 0, 0, 0xE000000000000000, 1702195828, 0xE400000000000000, 0x65736C6166, 0xE500000000000000, 10, 0xE100000000000000, 44, 0xE100000000000000);
        DataFrameProtocol.writeCSV(to:options:)(v52, v53, v69, &protocol witness table for DataFrame);
        outlined consume of Data._Representation(v66, v64);
        ((void (*)(uint64_t *, uint64_t))v62)(v53, v63);
        v68(v61, v67);
        (*(void (**)(uint64_t *))(*(void *)(v69 - 8) + 8))(v65);
      }
    }
  }
  else
  {
    uint64_t v41 = v35;
    _convertNSErrorToError(_:)(v35);

    swift_willThrow(v41, "dataWithPropertyList:format:options:error:", v42, v43, v44, v45);
  }
  return __stack_chk_guard;
}

uint64_t outlined init with copy of MLLinearRegressor.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined init with take of MLLinearRegressor.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t outlined destroy of MLLinearRegressor.ModelParameters.ValidationData(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLLinearRegressor.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t outlined init with copy of DataFrame?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

double MLRegressorMetrics.rootMeanSquaredError.getter()
{
  if (*(unsigned char *)(v0 + 16)) {
    return -1.0;
  }
  else {
    return *(double *)(v0 + 8);
  }
}

uint64_t MLRegressorMetrics.init(maximumError:rootMeanSquaredError:)(double a1, double a2)
{
  *(double *)uint64_t result = a1;
  *(double *)(result + 8) = a2;
  *(unsigned char *)(result + 16) = 0;
  return result;
}

unint64_t MLRegressorMetrics.description.getter()
{
  unint64_t v1 = 0xD000000000000038;
  if (!*(unsigned char *)(v0 + 16))
  {
    double v2 = *(double *)v0;
    if (*(double *)v0 >= 0.0 && *(double *)(v0 + 8) >= 0.0)
    {
      uint64_t v14 = *(void *)(v0 + 8);
      uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
      uint64_t v4 = (double *)swift_allocObject(v3, 72, 7);
      *((void *)v4 + 2) = 1;
      *((void *)v4 + 3) = 2;
      *((void *)v4 + 7) = &type metadata for Double;
      *((void *)v4 + 8) = &protocol witness table for Double;
      v4[4] = v2;
      uint64_t v5 = String.init(format:_:)(0xD000000000000010, "root mean squared error." + 0x8000000000000000, v4);
      char v7 = v6;
      int64_t v8 = (void *)swift_allocObject(v3, 72, 7);
      _OWORD v8[2] = 1;
      v8[3] = 2;
      v8[7] = &type metadata for Double;
      v8[8] = &protocol witness table for Double;
      v8[4] = v14;
      uint64_t v9 = String.init(format:_:)(0xD00000000000001ELL, "Max error: %.2f\n" + 0x8000000000000000, v8);
      int64_t v11 = v10;
      swift_bridgeObjectRetain(v7);
      v12._uint64_t countAndFlagsBits = v9;
      v12._char object = v11;
      String.append(_:)(v12);
      swift_bridgeObjectRelease(v7);
      swift_bridgeObjectRelease((_BYTE)v11);
      return v5;
    }
  }
  return v1;
}

char MLRegressorMetrics.isValid.getter()
{
  return *(unsigned char *)(v0 + 16) ^ 1;
}

uint64_t MLRegressorMetrics.error.getter()
{
  if (*((unsigned char *)v0 + 16) != 1) {
    return 0;
  }
  uint64_t v1 = *v0;
  swift_errorRetain(*v0);
  return v1;
}

double MLRegressorMetrics.maximumError.getter()
{
  if (v0[16]) {
    return -1.0;
  }
  else {
    return *(double *)v0;
  }
}

unint64_t MLRegressorMetrics.debugDescription.getter()
{
  double v1 = *(double *)v0;
  double v2 = *((double *)v0 + 1);
  char v3 = *((unsigned char *)v0 + 16);
  if (v3)
  {
    swift_errorRetain(*v0);
LABEL_6:
    outlined consume of Result<(Int, Int), Error>(*(uint64_t *)&v1, *(uint64_t *)&v2, v3);
    return 0xD000000000000038;
  }
  if (v1 < 0.0 || v2 < 0.0) {
    goto LABEL_6;
  }
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v5 = swift_allocObject(v4, 72, 7);
  *(void *)(v5 + 16) = 1;
  *(void *)(v5 + 24) = 2;
  *(void *)(v5 + 56) = &type metadata for Double;
  *(void *)(v5 + 64) = &protocol witness table for Double;
  *(double *)(v5 + 32) = v1;
  uint64_t v15 = String.init(format:_:)(0xD000000000000010, "root mean squared error." + 0x8000000000000000, v5);
  char v7 = v6;
  uint64_t v8 = swift_allocObject(v4, 72, 7);
  *(void *)(v8 + 16) = 1;
  *(void *)(v8 + 24) = 2;
  *(void *)(v8 + 56) = &type metadata for Double;
  *(void *)(v8 + 64) = &protocol witness table for Double;
  *(double *)(v8 + 32) = v2;
  uint64_t v9 = String.init(format:_:)(0xD00000000000001ELL, "Max error: %.2f\n" + 0x8000000000000000, v8);
  int64_t v11 = v10;
  swift_bridgeObjectRetain(v7);
  v12._uint64_t countAndFlagsBits = v9;
  v12._char object = v11;
  String.append(_:)(v12);
  swift_bridgeObjectRelease(v7);
  swift_bridgeObjectRelease((_BYTE)v11);
  outlined consume of Result<(Int, Int), Error>(*(uint64_t *)&v1, *(uint64_t *)&v2, 0);
  return v15;
}

uint64_t MLRegressorMetrics.playgroundDescription.getter()
{
  double v1 = v0;
  unint64_t v2 = MLRegressorMetrics.description.getter();
  char v4 = v3;
  objc_allocWithZone((Class)NSAttributedString);
  id v5 = @nonobjc NSAttributedString.init(string:attributes:)(v2, v4, 0);
  uint64_t result = type metadata accessor for NSAttributedString();
  v1[3] = result;
  *double v1 = v5;
  return result;
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLRegressorMetrics()
{
  return MLRegressorMetrics.description.getter();
}

unint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLRegressorMetrics()
{
  return MLRegressorMetrics.debugDescription.getter();
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLRegressorMetrics()
{
  return MLRegressorMetrics.playgroundDescription.getter();
}

uint64_t initializeBufferWithCopyOfBuffer for MLRegressorMetrics(uint64_t a1, uint64_t a2)
{
  return initializeBufferWithCopyOfBuffer for MLRegressorMetrics(a1, a2);
}

{
  uint64_t v2;
  uint64_t v3;
  char v4;

  unint64_t v2 = *(void *)a2;
  char v3 = *(void *)(a2 + 8);
  char v4 = *(unsigned char *)(a2 + 16);
  outlined copy of Result<_RegressorMetrics, Error>(*(void *)a2, v3, v4);
  *(void *)a1 = v2;
  *(void *)(a1 + 8) = v3;
  *(unsigned char *)(a1 + 16) = v4;
  return a1;
}

uint64_t destroy for MLRegressorMetrics(uint64_t a1)
{
  return outlined consume of Result<(Int, Int), Error>(*(void *)a1, *(void *)(a1 + 8), *(_DWORD *)(a1 + 16));
}

uint64_t assignWithCopy for MLRegressorMetrics(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = *(void *)a2;
  uint64_t v4 = *(void *)(a2 + 8);
  char v5 = *(unsigned char *)(a2 + 16);
  outlined copy of Result<_RegressorMetrics, Error>(*(void *)a2, v4, v5);
  uint64_t v6 = *(void *)a1;
  uint64_t v7 = *(void *)(a1 + 8);
  *(void *)a1 = v3;
  *(void *)(a1 + 8) = v4;
  int v8 = *(_DWORD *)(a1 + 16);
  *(unsigned char *)(a1 + 16) = v5;
  outlined consume of Result<(Int, Int), Error>(v6, v7, v8);
  return a1;
}

uint64_t assignWithTake for MLRegressorMetrics(uint64_t a1, uint64_t a2)
{
  char v3 = *(unsigned char *)(a2 + 16);
  uint64_t v4 = *(void *)a1;
  uint64_t v5 = *(void *)(a1 + 8);
  *(_OWORD *)a1 = *(_OWORD *)a2;
  int v6 = *(_DWORD *)(a1 + 16);
  *(unsigned char *)(a1 + 16) = v3;
  outlined consume of Result<(Int, Int), Error>(v4, v5, v6);
  return a1;
}

ValueMetadata *type metadata accessor for MLRegressorMetrics()
{
  return &type metadata for MLRegressorMetrics;
}

void *type metadata accessor for _RegressorMetrics()
{
  return &unk_3992C8;
}

uint64_t MLRecommender.ModelParameters.init(algorithm:threshold:maxCount:nearestItems:maxSimilarityIterations:)(char *a1, uint64_t a2, uint64_t *a3, uint64_t a4, double a5)
{
  uint64_t v6 = v5;
  char v7 = *a1;
  uint64_t v8 = *a3;
  char v15 = *((unsigned char *)a3 + 8);
  uint64_t v9 = (int *)type metadata accessor for MLRecommender.ModelParameters(0);
  uint64_t v10 = v6 + v9[7];
  uint64_t v11 = type metadata accessor for DataFrame(0);
  __swift_storeEnumTagSinglePayload(v10, 1, 1, v11);
  uint64_t v12 = v9[8];
  *(unsigned char *)uint64_t v6 = v7;
  *(double *)(v6 + 8) = a5;
  *(void *)(v6 + 16) = a2;
  *(void *)(v6 + v12) = v8;
  *(unsigned char *)(v6 + v12 + 8) = v15;
  uint64_t result = v9[9];
  *(void *)(v6 + result) = a4;
  return result;
}

uint64_t type metadata accessor for MLRecommender.ModelParameters(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLRecommender.ModelParameters;
  if (!type metadata singleton initialization cache for MLRecommender.ModelParameters) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLRecommender.ModelParameters);
  }
  return result;
}

uint64_t MLRecommender.ModelParameters.init(algorithm:threshold:maxCount:nearestItemsDataFrame:maxSimilarityIterations:)(char *a1, uint64_t a2, uint64_t a3, uint64_t a4, double a5)
{
  uint64_t v6 = v5;
  char v7 = *a1;
  uint64_t v8 = (int *)type metadata accessor for MLRecommender.ModelParameters(0);
  uint64_t v9 = v6 + v8[7];
  uint64_t v10 = type metadata accessor for DataFrame(0);
  __swift_storeEnumTagSinglePayload(v9, 1, 1, v10);
  uint64_t v11 = v8[8];
  *(void *)(v6 + v11) = 0;
  *(unsigned char *)(v6 + v11 + 8) = -1;
  *(unsigned char *)uint64_t v6 = v7;
  *(double *)(v6 + 8) = a5;
  *(void *)(v6 + 16) = a2;
  outlined assign with take of DataFrame?(a3, v9);
  uint64_t result = v8[9];
  *(void *)(v6 + result) = a4;
  return result;
}

unsigned char *MLRecommender.ModelParameters.algorithm.getter()
{
  *uint64_t result = *v1;
  return result;
}

char MLRecommender.ModelParameters.algorithm.setter(char *a1)
{
  char result = *a1;
  *double v1 = *a1;
  return result;
}

void (*MLRecommender.ModelParameters.algorithm.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLRecommender.ModelParameters.threshold.getter()
{
  return *(double *)(v0 + 8);
}

void MLRecommender.ModelParameters.threshold.setter(double a1)
{
  *(double *)(v1 + 8) = a1;
}

void (*MLRecommender.ModelParameters.threshold.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLRecommender.ModelParameters.maxCount.getter()
{
  return *(void *)(v0 + 16);
}

void MLRecommender.ModelParameters.maxCount.setter(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
}

void (*MLRecommender.ModelParameters.maxCount.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLRecommender.ModelParameters.nearestItemsDataFrame.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLRecommender.ModelParameters(0);
  return outlined init with copy of DataFrame?(v1 + *(int *)(v3 + 28), v2);
}

uint64_t MLRecommender.ModelParameters.nearestItemsDataFrame.setter(uint64_t a1)
{
  uint64_t v2 = type metadata accessor for MLRecommender.ModelParameters(0);
  return outlined assign with take of DataFrame?(a1, v1 + *(int *)(v2 + 28));
}

void (*MLRecommender.ModelParameters.nearestItemsDataFrame.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLRecommender.ModelParameters.nearestItems.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = *(int *)(type metadata accessor for MLRecommender.ModelParameters(0) + 32);
  uint64_t v4 = *(void *)(v1 + v3);
  int v5 = *(_DWORD *)(v1 + v3 + 8);
  *(void *)uint64_t v2 = v4;
  *(unsigned char *)(v2 + 8) = v5;
  return outlined copy of MLDataTable?(v4, v5);
}

uint64_t MLRecommender.ModelParameters.nearestItems.setter(uint64_t *a1)
{
  uint64_t v2 = *a1;
  char v3 = *((unsigned char *)a1 + 8);
  uint64_t v4 = *(int *)(type metadata accessor for MLRecommender.ModelParameters(0) + 32);
  uint64_t result = outlined consume of MLDataTable?(*(void *)(v1 + v4), *(_DWORD *)(v1 + v4 + 8));
  *(void *)(v1 + v4) = v2;
  *(unsigned char *)(v1 + v4 + 8) = v3;
  return result;
}

void (*MLRecommender.ModelParameters.nearestItems.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLRecommender.ModelParameters.maxSimilarityIterations.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLRecommender.ModelParameters(0) + 36));
}

uint64_t MLRecommender.ModelParameters.maxSimilarityIterations.setter(uint64_t a1)
{
  uint64_t result = *(int *)(type metadata accessor for MLRecommender.ModelParameters(0) + 36);
  *(void *)(v1 + result) = a1;
  return result;
}

void (*MLRecommender.ModelParameters.maxSimilarityIterations.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

BOOL static MLRecommender.SimilarityType.== infix(_:_:)(unsigned char *a1, unsigned char *a2)
{
  return *a1 == *a2;
}

void MLRecommender.SimilarityType.hash(into:)()
{
  Hasher._combine(_:)(*v0);
}

Swift::Int MLRecommender.SimilarityType.hashValue.getter()
{
  Swift::UInt v1 = *v0;
  Hasher.init(_seed:)(0);
  Hasher._combine(_:)(v1);
  return Hasher._finalize()();
}

BOOL protocol witness for static Equatable.== infix(_:_:) in conformance MLRecommender.SimilarityType(unsigned char *a1, unsigned char *a2)
{
  return static MLRecommender.SimilarityType.== infix(_:_:)(a1, a2);
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLRecommender.SimilarityType()
{
  return MLRecommender.SimilarityType.hashValue.getter();
}

void protocol witness for Hashable.hash(into:) in conformance MLRecommender.SimilarityType()
{
}

uint64_t base witness table accessor for Equatable in MLRecommender.SimilarityType()
{
  return lazy protocol witness table accessor for type MLRecommender.SimilarityType and conformance MLRecommender.SimilarityType();
}

uint64_t lazy protocol witness table accessor for type MLRecommender.SimilarityType and conformance MLRecommender.SimilarityType()
{
  uint64_t result = lazy protocol witness table cache variable for type MLRecommender.SimilarityType and conformance MLRecommender.SimilarityType;
  if (!lazy protocol witness table cache variable for type MLRecommender.SimilarityType and conformance MLRecommender.SimilarityType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLRecommender.SimilarityType, &type metadata for MLRecommender.SimilarityType);
    lazy protocol witness table cache variable for type MLRecommender.SimilarityType and conformance MLRecommender.SimilarityType = result;
  }
  return result;
}

void *initializeBufferWithCopyOfBuffer for MLRecommender.ModelParameters(uint64_t a1, uint64_t *a2, int *a3)
{
  char v3 = (void *)a1;
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v10 = *a2;
    *char v3 = *a2;
    char v3 = (void *)(v10 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    *(unsigned char *)a1 = *(unsigned char *)a2;
    *(_OWORD *)(a1 + 8) = *(_OWORD *)(a2 + 1);
    uint64_t v6 = a3[7];
    __dst = (void *)(a1 + v6);
    char v7 = (char *)a2 + v6;
    uint64_t v8 = type metadata accessor for DataFrame(0);
    if (__swift_getEnumTagSinglePayload((uint64_t)v7, 1, v8))
    {
      uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
      memcpy(__dst, v7, *(void *)(*(void *)(v9 - 8) + 64));
    }
    else
    {
      (*(void (**)(void *, char *, uint64_t))(*(void *)(v8 - 8) + 16))(__dst, v7, v8);
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v8);
    }
    __dsta = a3;
    uint64_t v11 = a3[8];
    uint64_t v12 = a1 + v11;
    int64_t v13 = (uint64_t *)((char *)a2 + v11);
    char v14 = *((unsigned char *)a2 + v11 + 8);
    if (v14 == -1)
    {
      *(unsigned char *)(v12 + 8) = *((unsigned char *)v13 + 8);
      *(void *)uint64_t v12 = *v13;
    }
    else
    {
      uint64_t v15 = *v13;
      outlined copy of Result<_DataTable, Error>(*v13, v14);
      *(void *)uint64_t v12 = v15;
      *(unsigned char *)(v12 + 8) = v14 & 1;
    }
    *(void *)(a1 + __dsta[9]) = *(uint64_t *)((char *)a2 + __dsta[9]);
  }
  return v3;
}

uint64_t destroy for MLRecommender.ModelParameters(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a1 + *(int *)(a2 + 28);
  uint64_t v3 = type metadata accessor for DataFrame(0);
  if (!__swift_getEnumTagSinglePayload(v2, 1, v3)) {
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v3 - 8) + 8))(v2, v3);
  }
  uint64_t result = *(int *)(a2 + 32);
  char v5 = *(unsigned char *)(a1 + result + 8);
  if (v5 != -1) {
    return outlined consume of Result<_DataTable, Error>(*(void *)(a1 + result), v5 & 1);
  }
  return result;
}

uint64_t initializeWithCopy for MLRecommender.ModelParameters(uint64_t a1, uint64_t a2, int *a3)
{
  *(unsigned char *)a1 = *(unsigned char *)a2;
  *(_OWORD *)(a1 + 8) = *(_OWORD *)(a2 + 8);
  uint64_t v3 = a3[7];
  int v4 = (void *)(a1 + v3);
  char v5 = (const void *)(a2 + v3);
  uint64_t v6 = type metadata accessor for DataFrame(0);
  if (__swift_getEnumTagSinglePayload((uint64_t)v5, 1, v6))
  {
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(v4, v5, *(void *)(*(void *)(v7 - 8) + 64));
  }
  else
  {
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v6 - 8) + 16))(v4, v5, v6);
    __swift_storeEnumTagSinglePayload((uint64_t)v4, 0, 1, v6);
  }
  uint64_t v8 = a3[8];
  uint64_t v9 = a1 + v8;
  uint64_t v10 = (uint64_t *)(a2 + v8);
  char v11 = *(unsigned char *)(a2 + v8 + 8);
  if (v11 == -1)
  {
    *(unsigned char *)(v9 + 8) = *((unsigned char *)v10 + 8);
    *(void *)uint64_t v9 = *v10;
  }
  else
  {
    uint64_t v12 = *v10;
    outlined copy of Result<_DataTable, Error>(*v10, v11);
    *(void *)uint64_t v9 = v12;
    *(unsigned char *)(v9 + 8) = v11 & 1;
  }
  *(void *)(a1 + a3[9]) = *(void *)(a2 + a3[9]);
  return a1;
}

uint64_t assignWithCopy for MLRecommender.ModelParameters(uint64_t a1, uint64_t a2, int *a3)
{
  *(unsigned char *)a1 = *(unsigned char *)a2;
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  uint64_t v4 = a3[7];
  uint64_t v5 = a1 + v4;
  uint64_t v6 = (const void *)(a2 + v4);
  uint64_t v7 = type metadata accessor for DataFrame(0);
  __dst = (void *)v5;
  LODWORD(v5) = __swift_getEnumTagSinglePayload(v5, 1, v7);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v6, 1, v7);
  if (v5)
  {
    if (EnumTagSinglePayload)
    {
      size_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                 - 8)
                     + 64);
      uint64_t v10 = __dst;
LABEL_6:
      memcpy(v10, v6, v9);
      goto LABEL_9;
    }
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v7 - 8) + 16))(__dst, v6, v7);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v7);
  }
  else
  {
    uint64_t v11 = *(void *)(v7 - 8);
    if (EnumTagSinglePayload)
    {
      (*(void (**)(void *, uint64_t))(v11 + 8))(__dst, v7);
      size_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                 - 8)
                     + 64);
      uint64_t v10 = __dst;
      goto LABEL_6;
    }
    (*(void (**)(void *, const void *, uint64_t))(v11 + 24))(__dst, v6, v7);
  }
LABEL_9:
  uint64_t v12 = a3[8];
  uint64_t v13 = a1 + v12;
  uint64_t v14 = v12 + a2;
  char v15 = *(unsigned char *)(v12 + a2 + 8);
  if (*(unsigned char *)(a1 + v12 + 8) == 0xFF)
  {
    if (v15 == -1)
    {
      *(unsigned char *)(v13 + 8) = *(unsigned char *)(v14 + 8);
      *(void *)uint64_t v13 = *(void *)v14;
    }
    else
    {
      uint64_t v19 = *(void *)v14;
      outlined copy of Result<_DataTable, Error>(v19, v15);
      *(void *)uint64_t v13 = v19;
      *(unsigned char *)(v13 + 8) = v15 & 1;
    }
  }
  else if (v15 == -1)
  {
    outlined destroy of MLDataTable(a1 + v12);
    *(void *)uint64_t v13 = *(void *)v14;
    *(unsigned char *)(v13 + 8) = *(unsigned char *)(v14 + 8);
  }
  else
  {
    uint64_t v16 = *(void *)v14;
    outlined copy of Result<_DataTable, Error>(v16, v15);
    uint64_t v17 = *(void *)v13;
    *(void *)uint64_t v13 = v16;
    int v18 = *(_DWORD *)(v13 + 8);
    *(unsigned char *)(v13 + 8) = v15 & 1;
    outlined consume of Result<_DataTable, Error>(v17, v18);
  }
  *(void *)(a1 + a3[9]) = *(void *)(a2 + a3[9]);
  return a1;
}

uint64_t initializeWithTake for MLRecommender.ModelParameters(uint64_t a1, uint64_t a2, int *a3)
{
  *(unsigned char *)a1 = *(unsigned char *)a2;
  *(_OWORD *)(a1 + 8) = *(_OWORD *)(a2 + 8);
  uint64_t v4 = a3[7];
  __dst = (void *)(a1 + v4);
  uint64_t v5 = (const void *)(a2 + v4);
  uint64_t v6 = type metadata accessor for DataFrame(0);
  if (__swift_getEnumTagSinglePayload((uint64_t)v5, 1, v6))
  {
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    memcpy(__dst, v5, *(void *)(*(void *)(v7 - 8) + 64));
  }
  else
  {
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v6 - 8) + 32))(__dst, v5, v6);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v6);
  }
  uint64_t v8 = a3[8];
  *(unsigned char *)(a1 + v8 + 8) = *(unsigned char *)(a2 + v8 + 8);
  *(void *)(a1 + v8) = *(void *)(a2 + v8);
  *(void *)(a1 + a3[9]) = *(void *)(a2 + a3[9]);
  return a1;
}

uint64_t assignWithTake for MLRecommender.ModelParameters(uint64_t a1, uint64_t a2, int *a3)
{
  *(unsigned char *)a1 = *(unsigned char *)a2;
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  uint64_t v4 = a3[7];
  uint64_t v5 = a1 + v4;
  uint64_t v6 = (const void *)(a2 + v4);
  uint64_t v7 = type metadata accessor for DataFrame(0);
  __dst = (void *)v5;
  LODWORD(v5) = __swift_getEnumTagSinglePayload(v5, 1, v7);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v6, 1, v7);
  if (v5)
  {
    if (EnumTagSinglePayload)
    {
      size_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                 - 8)
                     + 64);
      uint64_t v10 = __dst;
LABEL_6:
      memcpy(v10, v6, v9);
      goto LABEL_9;
    }
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v7 - 8) + 32))(__dst, v6, v7);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v7);
  }
  else
  {
    uint64_t v11 = *(void *)(v7 - 8);
    if (EnumTagSinglePayload)
    {
      (*(void (**)(void *, uint64_t))(v11 + 8))(__dst, v7);
      size_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                                 - 8)
                     + 64);
      uint64_t v10 = __dst;
      goto LABEL_6;
    }
    (*(void (**)(void *, const void *, uint64_t))(v11 + 40))(__dst, v6, v7);
  }
LABEL_9:
  uint64_t v12 = a3[8];
  uint64_t v13 = a1 + v12;
  uint64_t v14 = a2 + v12;
  char v15 = *(unsigned char *)(a1 + v12 + 8);
  if (v15 == -1)
  {
    *(unsigned char *)(v13 + 8) = *(unsigned char *)(v14 + 8);
    *(void *)uint64_t v13 = *(void *)v14;
  }
  else
  {
    char v16 = *(unsigned char *)(a2 + v12 + 8);
    if (v16 == -1)
    {
      outlined destroy of MLDataTable(v13);
      *(void *)uint64_t v13 = *(void *)v14;
      *(unsigned char *)(v13 + 8) = *(unsigned char *)(v14 + 8);
    }
    else
    {
      uint64_t v17 = *(void *)v13;
      *(void *)uint64_t v13 = *(void *)v14;
      *(unsigned char *)(v13 + 8) = v16 & 1;
      outlined consume of Result<_DataTable, Error>(v17, v15 & 1);
    }
  }
  *(void *)(a1 + a3[9]) = *(void *)(a2 + a3[9]);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLRecommender.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_11772D);
}

uint64_t sub_11772D(unsigned __int8 *a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 253)
  {
    unsigned int v3 = *a1;
    uint64_t result = 0;
    if (v3 >= 3) {
      return v3 - 2;
    }
  }
  else
  {
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    return __swift_getEnumTagSinglePayload((uint64_t)&a1[*(int *)(a3 + 28)], a2, v6);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLRecommender.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_11779C);
}

uint64_t sub_11779C(unsigned char *a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 253)
  {
    *a1 = a2 + 2;
  }
  else
  {
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
    return __swift_storeEnumTagSinglePayload((uint64_t)&a1[*(int *)(a4 + 28)], a2, a2, v5);
  }
  return result;
}

uint64_t type metadata completion function for MLRecommender.ModelParameters(uint64_t a1)
{
  v3[0] = &unk_34AC10;
  v3[1] = (char *)&value witness table for Builtin.Int64 + 64;
  v3[2] = (char *)&value witness table for Builtin.Int64 + 64;
  uint64_t result = type metadata accessor for DataFrame?(319);
  if (v2 <= 0x3F)
  {
    void v3[3] = *(void *)(result - 8) + 64;
    void v3[4] = &unk_34AC28;
    void v3[5] = (char *)&value witness table for Builtin.Int64 + 64;
    swift_initStructMetadata(a1, 256, 6, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t type metadata accessor for DataFrame?(uint64_t a1)
{
  uint64_t result = lazy cache variable for type metadata for DataFrame?;
  if (!lazy cache variable for type metadata for DataFrame?)
  {
    uint64_t v2 = type metadata accessor for DataFrame(255);
    uint64_t result = type metadata accessor for Optional(a1, v2);
    if (!v3) {
      lazy cache variable for type metadata for DataFrame? = result;
    }
  }
  return result;
}

uint64_t getEnumTagSinglePayload for MLRecommender.ModelAlgorithmType(unsigned __int8 *a1, unsigned int a2)
{
  return getEnumTagSinglePayload for MLRecommender.ModelAlgorithmType(a1, a2);
}

{
  unsigned int v2;
  int v3;
  int v4;
  int v5;
  unsigned int v6;
  int v7;
  BOOL v8;

  if (a2)
  {
    if (a2 < 0xFE) {
      goto LABEL_13;
    }
    uint64_t v2 = a2 + 2;
    uint64_t v3 = 1;
    if (v2 >= 0xFF00) {
      uint64_t v3 = 2 * (v2 >= 0xFFFF00) + 2;
    }
    if (v3 == 4) {
      uint64_t v4 = *(_DWORD *)(a1 + 1);
    }
    else {
      uint64_t v4 = v3 == 2 ? *(unsigned __int16 *)(a1 + 1) : a1[1];
    }
    if (v4)
    {
      uint64_t v5 = *a1 + (v4 << 8) - 3;
    }
    else
    {
LABEL_13:
      uint64_t v6 = *a1;
      uint64_t v7 = v6 - 3;
      uint64_t v8 = v6 < 3;
      uint64_t v5 = -1;
      if (!v8) {
        uint64_t v5 = v7;
      }
    }
  }
  else
  {
    uint64_t v5 = -1;
  }
  return (v5 + 1);
}

uint64_t storeEnumTagSinglePayload for MLRecommender.ModelAlgorithmType(unsigned char *a1, unsigned int a2, unsigned int a3)
{
  return storeEnumTagSinglePayload for MLRecommender.ModelAlgorithmType(a1, a2, a3);
}

{
  uint64_t result;
  unsigned int v4;
  unsigned int v5;
  int v6;

  LODWORD(result) = 0;
  if (a3 >= 0xFE)
  {
    uint64_t v4 = a3 + 2;
    LODWORD(result) = 1;
    if (v4 >= 0xFF00) {
      LODWORD(result) = 2 * (v4 >= 0xFFFF00) + 2;
    }
  }
  if (a2 > 0xFD)
  {
    uint64_t v5 = a2 - 254;
    uint64_t v6 = (v5 >> 8) + 1;
    *a1 = v5;
    uint64_t result = result;
    switch((int)result)
    {
      case 0:
        return result;
      case 1:
        a1[1] = v6;
        break;
      case 2:
        *(_WORD *)(a1 + 1) = v6;
        break;
      case 3:
LABEL_16:
        BUG();
      case 4:
        *(_DWORD *)(a1 + 1) = v6;
        break;
    }
  }
  else
  {
    uint64_t result = result;
    switch((int)result)
    {
      case 0:
        goto LABEL_11;
      case 1:
        a1[1] = 0;
        goto LABEL_11;
      case 2:
        *(_WORD *)(a1 + 1) = 0;
        goto LABEL_11;
      case 3:
        goto LABEL_16;
      case 4:
        *(_DWORD *)(a1 + 1) = 0;
LABEL_11:
        if (a2) {
          *a1 = a2 + 2;
        }
        break;
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for MLRecommender.ModelAlgorithmType()
{
  return &type metadata for MLRecommender.ModelAlgorithmType;
}

ValueMetadata *type metadata accessor for MLRecommender.SimilarityType()
{
  return &type metadata for MLRecommender.SimilarityType;
}

uint64_t LabelEncoder<>.encode(to:)(void *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v18 = a6;
  uint64_t v19 = a4;
  uint64_t v6 = a1[3];
  uint64_t v7 = a1[4];
  __swift_project_boxed_opaque_existential_0Tm(a1, v6);
  dispatch thunk of Encoder.singleValueContainer()(v6, v7);
  uint64_t v17 = a2;
  uint64_t v8 = v14;
  uint64_t v9 = v15;
  __swift_mutable_project_boxed_opaque_existential_1((uint64_t)v13, v14);
  uint64_t v10 = type metadata accessor for Array(0, v19);
  uint64_t v16 = v18;
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for <A> [A], v10);
  dispatch thunk of SingleValueEncodingContainer.encode<A>(_:)(&v17, v10, WitnessTable, v8, v9);
  return __swift_destroy_boxed_opaque_existential_1Tm(v13);
}

uint64_t protocol witness for Encodable.encode(to:) in conformance <> LabelEncoder<A>(void *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return LabelEncoder<>.encode(to:)(a1, *v5, a3, *(void *)(a2 + 16), a5, *(void *)(a3 - 8));
}

uint64_t LabelEncoder<>.init(from:)(void *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v26 = v5;
  uint64_t v22 = a5;
  uint64_t v21 = a4;
  uint64_t v23 = a3;
  uint64_t v25 = a2;
  uint64_t v6 = a1[3];
  uint64_t v7 = a1[4];
  __swift_project_boxed_opaque_existential_0Tm(a1, v6);
  dispatch thunk of Decoder.singleValueContainer()(v6, v7);
  if (v5)
  {
    __swift_destroy_boxed_opaque_existential_1Tm(a1);
  }
  else
  {
    uint64_t v26 = a1;
    uint64_t v8 = v17;
    uint64_t v24 = v18;
    __swift_project_boxed_opaque_existential_0Tm(v16, v17);
    uint64_t v9 = type metadata accessor for Array(0, v25);
    uint64_t v19 = v21;
    uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for <A> [A], v9);
    dispatch thunk of SingleValueDecodingContainer.decode<A>(_:)(v9, v9, WitnessTable, v8, v24);
    uint64_t v12 = swift_getWitnessTable(&protocol conformance descriptor for [A], v9);
    uint64_t v13 = v25;
    uint64_t v14 = v22;
    uint64_t v15 = Set.init<A>(_:)(v20, v25, v9, v22, v12);
    uint64_t v6 = SortedSet.init(_:)(v15, v13, v23, v14);
    __swift_destroy_boxed_opaque_existential_1Tm(v16);
    __swift_destroy_boxed_opaque_existential_1Tm(v26);
  }
  return v6;
}

uint64_t protocol witness for Decodable.init(from:) in conformance <> LabelEncoder<A>(void *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v5 = v3;
  uint64_t result = LabelEncoder<>.init(from:)(a1, a2[2], a2[3], *(void *)(a3 - 8), a2[4]);
  if (!v4)
  {
    uint64_t *v5 = result;
    v5[1] = v7;
  }
  return result;
}

uint64_t type metadata accessor for LabelEncoder(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for LabelEncoder);
}

unint64_t MLSoundClassifier.ModelParameters.ClassifierType.description.getter()
{
  unint64_t result = 0xD000000000000015;
  if (!*v0) {
    return 0xD000000000000012;
  }
  return result;
}

BOOL static MLSoundClassifier.ModelParameters.ClassifierType.== infix(_:_:)(uint64_t *a1, uint64_t *a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v5 = *a1;
  uint64_t v6 = *a2;
  if (v5)
  {
    if (v6) {
      return specialized static Array<A>.== infix(_:_:)(v5, v6);
    }
    return 0;
  }
  if (v6) {
    return 0;
  }
  swift_bridgeObjectRelease_n(0, 2, a3, a4, a5);
  return 1;
}

void MLSoundClassifier.ModelParameters.ClassifierType.hash(into:)(uint64_t a1)
{
  uint64_t v2 = *v1;
  if (*v1)
  {
    Hasher._combine(_:)(1uLL);
    specialized Array<A>.hash(into:)(a1, v2);
  }
  else
  {
    Hasher._combine(_:)(0);
  }
}

Swift::Int MLSoundClassifier.ModelParameters.ClassifierType.hashValue.getter()
{
  uint64_t v1 = *v0;
  Hasher.init(_seed:)(0);
  if (v1)
  {
    Hasher._combine(_:)(1uLL);
    specialized Array<A>.hash(into:)((uint64_t)v3, v1);
  }
  else
  {
    Hasher._combine(_:)(0);
  }
  return Hasher._finalize()();
}

BOOL protocol witness for static Equatable.== infix(_:_:) in conformance MLSoundClassifier.ModelParameters.ClassifierType(uint64_t *a1, uint64_t *a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return static MLSoundClassifier.ModelParameters.ClassifierType.== infix(_:_:)(a1, a2, a3, a4, a5);
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLSoundClassifier.ModelParameters.ClassifierType()
{
  return MLSoundClassifier.ModelParameters.ClassifierType.hashValue.getter();
}

void protocol witness for Hashable.hash(into:) in conformance MLSoundClassifier.ModelParameters.ClassifierType(uint64_t a1)
{
}

Swift::Int protocol witness for Hashable._rawHashValue(seed:) in conformance MLSoundClassifier.ModelParameters.ClassifierType(uint64_t a1)
{
  uint64_t v2 = *v1;
  Hasher.init(_seed:)(a1);
  if (v2)
  {
    Hasher._combine(_:)(1uLL);
    specialized Array<A>.hash(into:)((uint64_t)v4, v2);
  }
  else
  {
    Hasher._combine(_:)(0);
  }
  return Hasher._finalize()();
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLSoundClassifier.ModelParameters.ClassifierType()
{
  return MLSoundClassifier.ModelParameters.ClassifierType.description.getter();
}

void specialized Array<A>.hash(into:)(uint64_t a1, uint64_t a2)
{
  Swift::UInt v2 = *(void *)(a2 + 16);
  Hasher._combine(_:)(v2);
  if (v2)
  {
    for (uint64_t i = 0; i != v2; ++i)
    {
      Swift::UInt v4 = *(void *)(a2 + 8 * i + 32);
      Hasher._combine(_:)(v4);
    }
  }
}

uint64_t base witness table accessor for Equatable in MLSoundClassifier.ModelParameters.ClassifierType()
{
  return lazy protocol witness table accessor for type MLSoundClassifier.ModelParameters.ClassifierType and conformance MLSoundClassifier.ModelParameters.ClassifierType();
}

uint64_t lazy protocol witness table accessor for type MLSoundClassifier.ModelParameters.ClassifierType and conformance MLSoundClassifier.ModelParameters.ClassifierType()
{
  uint64_t result = lazy protocol witness table cache variable for type MLSoundClassifier.ModelParameters.ClassifierType and conformance MLSoundClassifier.ModelParameters.ClassifierType;
  if (!lazy protocol witness table cache variable for type MLSoundClassifier.ModelParameters.ClassifierType and conformance MLSoundClassifier.ModelParameters.ClassifierType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLSoundClassifier.ModelParameters.ClassifierType, &type metadata for MLSoundClassifier.ModelParameters.ClassifierType);
    lazy protocol witness table cache variable for type MLSoundClassifier.ModelParameters.ClassifierType and conformance MLSoundClassifier.ModelParameters.ClassifierType = result;
  }
  return result;
}

uint64_t *initializeBufferWithCopyOfBuffer for MLSoundClassifier.ModelParameters.ClassifierType(uint64_t *a1, uint64_t *a2)
{
  uint64_t v3 = *a2;
  *a1 = *a2;
  swift_bridgeObjectRetain(v3);
  return a1;
}

uint64_t destroy for MLSoundClassifier.ModelParameters.ClassifierType(void *a1)
{
  return swift_bridgeObjectRelease(*a1);
}

uint64_t *assignWithCopy for MLSoundClassifier.ModelParameters.ClassifierType(uint64_t *a1, uint64_t *a2)
{
  uint64_t v3 = *a2;
  uint64_t v4 = *a1;
  *a1 = *a2;
  swift_bridgeObjectRetain(v3);
  swift_bridgeObjectRelease(v4);
  return a1;
}

uint64_t *assignWithTake for MLSoundClassifier.ModelParameters.ClassifierType(uint64_t *a1, uint64_t *a2)
{
  uint64_t v3 = *a1;
  *a1 = *a2;
  swift_bridgeObjectRelease(v3);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLSoundClassifier.ModelParameters.ClassifierType(uint64_t a1, unsigned int a2)
{
  if (!a2) {
    return 0;
  }
  if (a2 >= 0x7FFFFFFF && *(unsigned char *)(a1 + 8)) {
    return (*(_DWORD *)a1 + 0x7FFFFFFF);
  }
  uint64_t result = (*(void *)a1 & 0xFFFFFFFF00000001) != 0 ? -1 : (*(void *)a1 >> 1);
  if ((result + 1) < 2) {
    return 0;
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLSoundClassifier.ModelParameters.ClassifierType(uint64_t a1, unsigned int a2, unsigned int a3)
{
  if (a2 > 0x7FFFFFFE)
  {
    *(void *)a1 = 0;
    *(_DWORD *)a1 = a2 - 0x7FFFFFFF;
    if (a3 >= 0x7FFFFFFF) {
      *(unsigned char *)(a1 + 8) = 1;
    }
  }
  else
  {
    if (a3 >= 0x7FFFFFFF) {
      *(unsigned char *)(a1 + 8) = 0;
    }
    if (a2)
    {
      uint64_t result = 2 * a2;
      *(void *)a1 = result;
    }
  }
  return result;
}

uint64_t getEnumTag for MLSoundClassifier.ModelParameters.ClassifierType(void *a1)
{
  uint64_t result = 0;
  if ((*a1 & 0xFFFFFFFF00000001) == 0) {
    return (*a1 >> 1) + 1;
  }
  return result;
}

void destructiveInjectEnumTag for MLSoundClassifier.ModelParameters.ClassifierType(uint64_t *a1, int a2)
{
  if (a2 < 0)
  {
    uint64_t v2 = a2 + 0x80000000;
  }
  else
  {
    if (!a2) {
      return;
    }
    uint64_t v2 = 2 * (a2 - 1);
  }
  *a1 = v2;
}

ValueMetadata *type metadata accessor for MLSoundClassifier.ModelParameters.ClassifierType()
{
  return &type metadata for MLSoundClassifier.ModelParameters.ClassifierType;
}

uint64_t *initializeWithCopy for MLSoundClassifier.ModelParameters.ClassifierType(uint64_t *a1, uint64_t *a2)
{
  return initializeBufferWithCopyOfBuffer for MLSoundClassifier.ModelParameters.ClassifierType(a1, a2);
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay8CreateML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n(uint64_t a1)
{
  uint64_t v18 = type metadata accessor for FeatureDescription(0);
  uint64_t v19 = *(void *)(v18 - 8);
  int64_t v2 = *(void *)(v19 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  int64_t v5 = *(void *)(a1 + 16);
  if (!v5) {
    return _swiftEmptyArrayStorage;
  }
  uint64_t v22 = v1;
  uint64_t v23 = _swiftEmptyArrayStorage;
  int64_t v20 = v5;
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v5, 0);
  uint64_t v6 = v23;
  uint64_t v7 = (char *)(a1 + 56);
  uint64_t v21 = &v14;
  do
  {
    uint64_t v16 = v7;
    uint64_t v15 = v6;
    uint64_t v17 = *((void *)v7 - 3);
    uint64_t v8 = *((void *)v7 - 2);
    uint64_t v9 = *((void *)v7 - 1);
    char v10 = *v7;
    swift_bridgeObjectRetain(v8);
    outlined copy of ColumnDescriptor.ColumnTypeDescriptor(v9, v10);
    ColumnDescriptor.featureDescription.getter(v17, v8, v9, v10);
    char v11 = v8;
    uint64_t v6 = v15;
    swift_bridgeObjectRelease(v11);
    outlined consume of ColumnDescriptor.ColumnTypeDescriptor(v9, v10);
    uint64_t v23 = v6;
    unint64_t v12 = v6[2];
    if (v6[3] >> 1 <= v12)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v6[3] >= 2uLL, v12 + 1, 1);
      uint64_t v6 = v23;
    }
    v6[2] = v12 + 1;
    (*(void (**)(char *, uint64_t *, uint64_t))(v19 + 32))((char *)v6+ ((*(unsigned __int8 *)(v19 + 80) + 32) & ~*(unsigned __int8 *)(v19 + 80))+ *(void *)(v19 + 72) * v12, v21, v18);
    uint64_t v7 = v16 + 32;
    --v20;
  }
  while (v20);
  return v6;
}

void TreeRegressorModel.export(internalMetadata:)()
{
  uint64_t v111 = v1;
  uint64_t v91 = v0;
  uint64_t v93 = type metadata accessor for ModelKind(0);
  uint64_t v92 = *(void *)(v93 - 8);
  int64_t v3 = *(void *)(v92 + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  uint64_t v94 = v82;
  uint64_t v97 = type metadata accessor for FeatureType(0);
  uint64_t v96 = *(void *)(v97 - 8);
  int64_t v6 = *(void *)(v96 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v98 = v82;
  int64_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Model?)
                             - 8)
                 + 64);
  char v10 = alloca(v9);
  char v11 = alloca(v9);
  char v99 = v82;
  uint64_t v102 = type metadata accessor for Model(0);
  uint64_t v103 = *(void *)(v102 - 8);
  int64_t v12 = *(void *)(v103 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v95 = v82;
  uint64_t v15 = alloca(v12);
  uint64_t v16 = alloca(v12);
  uint64_t v109 = v82;
  uint64_t v85 = type metadata accessor for URL.DirectoryHint(0);
  uint64_t v86 = *(void *)(v85 - 8);
  int64_t v17 = *(void *)(v86 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v87 = v82;
  uint64_t v20 = type metadata accessor for UUID(0);
  uint64_t v88 = *(void *)(v20 - 8);
  int64_t v21 = *(void *)(v88 + 64);
  uint64_t v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  uint64_t v89 = v82;
  uint64_t v107 = type metadata accessor for URL(0);
  uint64_t v106 = *(void *)(v107 - 8);
  int64_t v24 = *(void *)(v106 + 64);
  uint64_t v25 = alloca(v24);
  uint64_t v26 = alloca(v24);
  uint64_t v90 = v82;
  uint64_t v27 = alloca(v24);
  uint64_t v28 = alloca(v24);
  uint64_t v105 = v82;
  uint64_t v29 = alloca(v24);
  uint64_t v30 = alloca(v24);
  uint64_t v108 = v82;
  char v31 = alloca(v24);
  uint64_t v32 = alloca(v24);
  uint64_t v33 = v2[2];
  if (!v33)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000001CLL, "ressorModel.swift" + 0x8000000000000000, "CreateML/TreeRegressorModel+CoreML.swift", 40, 2, 11, 0);
    BUG();
  }
  uint64_t v34 = v111;
  uint64_t v35 = specialized FeatureVectorizer.Transformer.exportEncoders()(v2[2], v2[3], v2[4]);
  if (!v34)
  {
    uint64_t v100 = v33;
    uint64_t v111 = v35;
    char v101 = v82;
    uint64_t v104 = v2;
    unint64_t v36 = objc_opt_self(NSFileManager);
    id v37 = [v36 defaultManager];
    id v38 = v37;
    NSFileManager.createTemporaryModelDirectory()();
    if (v39)
    {
      swift_bridgeObjectRelease(v111);
    }
    else
    {

      id v40 = [v36 defaultManager];
      id v41 = v40;
      NSFileManager.temporaryModelDirectory.getter();

      uint64_t v110 = 0;
      uint64_t v42 = v89;
      UUID.init()();
      uint64_t v43 = UUID.uuidString.getter();
      uint64_t v45 = v44;
      (*(void (**)(char *, uint64_t))(v88 + 8))(v42, v20);
      uint64_t v83 = v43;
      uint64_t v84 = v45;
      uint64_t v46 = v87;
      uint64_t v47 = v85;
      uint64_t v48 = v86;
      (*(void (**)(char *, void, uint64_t))(v86 + 104))(v87, enum case for URL.DirectoryHint.inferFromPath(_:), v85);
      uint64_t v49 = lazy protocol witness table accessor for type String and conformance String();
      uint64_t v50 = v105;
      URL.appending<A>(component:directoryHint:)(&v83, v46, &type metadata for String, v49);
      (*(void (**)(char *, uint64_t))(v48 + 8))(v46, v47);
      swift_bridgeObjectRelease(v84);
      uint64_t v51 = *(void (**)(char *, uint64_t))(v106 + 8);
      uint64_t v52 = v107;
      v51(v50, v107);
      uint64_t v53 = v101;
      uint64_t v54 = v108;
      URL.appendingPathExtension(_:)(0x6C65646F6D6C6D2ELL, 0xE800000000000000);
      v51(v54, v52);
      type metadata accessor for TreeRegressorModel(0);
      uint64_t v55 = v110;
      BaseTreeRegressorModel.export(to:)(v53);
      if (v55)
      {
        v51(v53, v107);
        swift_bridgeObjectRelease(v111);
      }
      else
      {
        uint64_t v108 = (char *)v51;
        uint64_t v56 = v90;
        (*(void (**)(char *, char *, uint64_t))(v106 + 16))(v90, v53, v107);
        Model.init(contentsOf:)(v56);
        uint64_t v110 = 0;
        uint64_t v57 = (uint64_t)v99;
        specialized BidirectionalCollection.last.getter(v111);
        uint64_t v58 = v102;
        if (__swift_getEnumTagSinglePayload(v57, 1, v102) == 1) {
          BUG();
        }
        uint64_t v59 = ((uint64_t (*)(void))Model.outputs.getter)();
        uint64_t v105 = *(char **)(v103 + 8);
        ((void (*)(uint64_t, uint64_t))v105)(v57, v58);
        Model.inputs.setter(v59);
        uint64_t v60 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
        uint64_t v61 = *(void *)(type metadata accessor for FeatureDescription(0) - 8);
        uint64_t v62 = swift_allocObject(v60, ((*(unsigned __int8 *)(v61 + 80) + 32) & ~*(unsigned __int8 *)(v61 + 80)) + *(void *)(v61 + 72), *(unsigned __int8 *)(v61 + 80) | 7);
        *(void *)(v62 + 16) = 1;
        *(void *)(v62 + 24) = 2;
        uint64_t v106 = *v104;
        uint64_t v63 = v104[1];
        swift_bridgeObjectRetain(v63);
        unint64_t v64 = v98;
        FeatureType.DoubleParameters.init(optional:)(0);
        (*(void (**)(char *, void, uint64_t))(v96 + 104))(v64, enum case for FeatureType.double(_:), v97);
        uint64_t v65 = v106;
        FeatureDescription.init(name:type:description:)(v106, v63, v64, 0, 0xE000000000000000);
        Model.outputs.setter(v62);
        swift_bridgeObjectRetain(v63);
        Model.predictedFeatureName.setter(v65, v63);
        uint64_t v66 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for String, &protocol witness table for String);
        Model.metadata.setter(v66);
        uint64_t v67 = v95;
        Model.init()();
        Model.specificationVersion.setter(1);
        uint64_t v68 = v100;
        swift_bridgeObjectRetain(v100);
        uint64_t v69 = v110;
        ML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay8CreateML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n(v68);
        uint64_t v110 = v69;
        swift_bridgeObjectRelease(v68);
        Model.inputs.setter(ML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n);
        uint64_t v71 = Model.outputs.getter(ML16ColumnDescriptorVG_20MLModelSpecification18FeatureDescriptionVs5NeverOTg503_s8d50ML18TreeRegressorModelV6export16internalMetadata20h33Specification0E0VSDyS2SGz_tKFAF18jk5VAA16fG54Vcfu0_33_3fd57c9cf8bb5b882e179ce0f1f8c55eAmKTf3nnnpk_nTf1cn_n, v82);
        Model.outputs.setter(v71);
        uint64_t v72 = *v104;
        uint64_t v73 = v104[1];
        swift_bridgeObjectRetain(v73);
        Model.predictedFeatureName.setter(v72, v73);
        uint64_t v74 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Model>);
        uint64_t v75 = *(unsigned __int8 *)(v103 + 80);
        uint64_t v76 = ((int)v75 + 32) & ~*(unsigned __int8 *)(v103 + 80);
        uint64_t v77 = v103;
        uint64_t v78 = swift_allocObject(v74, v76 + *(void *)(v103 + 72), v75 | 7);
        *(void *)(v78 + 16) = 1;
        *(void *)(v78 + 24) = 2;
        (*(void (**)(uint64_t, char *, uint64_t))(v77 + 16))(v78 + v76, v109, v102);
        uint64_t v83 = v111;
        specialized Array.append<A>(contentsOf:)(v78);
        uint64_t v79 = v94;
        PipelineRegressorConfiguration.init(models:names:)(v83, _swiftEmptyArrayStorage);
        (*(void (**)(char *, void, uint64_t))(v92 + 104))(v79, enum case for ModelKind.pipelineRegressor(_:), v93);
        Model.kind.setter(v79);
        uint64_t v80 = v102;
        ((void (*)(char *, uint64_t))v105)(v109, v102);
        (*(void (**)(uint64_t, char *, uint64_t))(v103 + 32))(v91, v67, v80);
        uint64_t v81 = v101;
        $defer #1 () in TreeRegressorModel.export(internalMetadata:)();
        ((void (*)(char *, uint64_t))v108)(v81, v107);
      }
    }
  }
}

id $defer #1 () in TreeRegressorModel.export(internalMetadata:)()
{
  uint64_t v0 = objc_opt_self(NSFileManager);
  id v1 = [v0 defaultManager];
  int64_t v2 = (NSURL *)v1;
  URL._bridgeToObjectiveC()(v2);
  uint64_t v4 = v3;
  id v10 = 0;
  unsigned __int8 v5 = [(NSURL *)v2 removeItemAtURL:v3 error:&v10];

  id v6 = v10;
  if (v5) {
    return v10;
  }
  id v8 = v10;
  uint64_t v9 = _convertNSErrorToError(_:)(v6);

  swift_willThrow();
  swift_errorRelease(v9);
  return (id)__stack_chk_guard;
}

uint64_t outlined consume of ColumnDescriptor.ColumnTypeDescriptor(uint64_t a1, char a2)
{
  if ((a2 & 0xFE) == 4) {
    return swift_bridgeObjectRelease(a1);
  }
  return result;
}

uint64_t TreeClassifierTrainingSessionDelegate.init(sessionParameters:)(uint64_t a1)
{
  uint64_t v2 = v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters;
  uint64_t v3 = type metadata accessor for PersistentParametersForTreeBasedMethods(0);
  __swift_storeEnumTagSinglePayload(v2, 1, 1, v3);
  DataFrame.init()(v2, 1, v4, v5);
  uint64_t v6 = v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData;
  uint64_t v7 = type metadata accessor for DataFrame(0);
  __swift_storeEnumTagSinglePayload(v6, 1, 1, v7);
  uint64_t v8 = v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
  uint64_t v9 = type metadata accessor for AnyTreeClassifier(0);
  __swift_storeEnumTagSinglePayload(v8, 1, 1, v9);
  uint64_t v10 = v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model;
  uint64_t v11 = type metadata accessor for AnyTreeClassifierModel(0);
  __swift_storeEnumTagSinglePayload(v10, 1, 1, v11);
  uint64_t v12 = v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingMetrics;
  uint64_t v13 = type metadata accessor for AnyClassificationMetrics(0);
  __swift_storeEnumTagSinglePayload(v12, 1, 1, v13);
  __swift_storeEnumTagSinglePayload(v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics, 1, 1, v13);
  outlined init with take of MLClassifierMetrics(a1, v1 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  return v1;
}

char *TreeClassifierTrainingSessionDelegate.init(trainingData:validationData:targetColumn:featureColumns:configuration:sessionParameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, void (*a5)(void, void), uint64_t a6, uint64_t a7)
{
  uint64_t v113 = v7;
  uint64_t v9 = v8;
  uint64_t v116 = a6;
  uint64_t v128 = a5;
  uint64_t v127 = (void *)a4;
  uint64_t v125 = a3;
  uint64_t v115 = a2;
  uint64_t v126 = a1;
  uint64_t v114 = *(void (**)(uint64_t *, uint64_t, uint64_t))v8;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>)
                              - 8)
                  + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v105 = &v96;
  int64_t v13 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>)
                              - 8)
                  + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v104 = &v96;
  int64_t v16 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifier?)
                              - 8)
                  + 64);
  int64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v118 = &v96;
  uint64_t v109 = type metadata accessor for AnyColumn(0);
  uint64_t v99 = *(void *)(v109 - 8);
  int64_t v19 = *(void *)(v99 + 64);
  uint64_t v20 = alloca(v19);
  int64_t v21 = alloca(v19);
  uint64_t v106 = &v96;
  uint64_t v22 = alloca(v19);
  uint64_t v23 = alloca(v19);
  uint64_t v100 = &v96;
  int64_t v24 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?)
                              - 8)
                  + 64);
  uint64_t v25 = alloca(v24);
  uint64_t v26 = alloca(v24);
  char v101 = &v96;
  uint64_t v120 = type metadata accessor for BoostedTreeConfiguration(0);
  uint64_t v119 = *(void *)(v120 - 8);
  int64_t v27 = *(void *)(v119 + 64);
  uint64_t v28 = alloca(v27);
  uint64_t v29 = alloca(v27);
  uint64_t v117 = &v96;
  int64_t v30 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                              - 8)
                  + 64);
  char v31 = alloca(v30);
  uint64_t v32 = alloca(v30);
  uint64_t v107 = &v96;
  uint64_t v33 = type metadata accessor for DataFrame(0);
  uint64_t v121 = *(void *)(v33 - 8);
  int64_t v34 = *(void *)(v121 + 64);
  uint64_t v35 = alloca(v34);
  unint64_t v36 = alloca(v34);
  uint64_t v111 = &v96;
  id v37 = alloca(v34);
  id v38 = alloca(v34);
  uint64_t v108 = &v96;
  uint64_t v39 = (int *)type metadata accessor for PersistentParametersForTreeBasedMethods(0);
  int64_t v40 = *(void *)(*((void *)v39 - 1) + 64);
  id v41 = alloca(v40);
  uint64_t v42 = alloca(v40);
  uint64_t v103 = &v96;
  uint64_t v43 = alloca(v40);
  uint64_t v44 = alloca(v40);
  uint64_t v124 = &v96;
  uint64_t v45 = &v8[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters];
  uint64_t v102 = &v8[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters];
  uint64_t v122 = v39;
  __swift_storeEnumTagSinglePayload((uint64_t)&v8[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters], 1, 1, (uint64_t)v39);
  DataFrame.init()(v45, 1, v46, v47);
  uint64_t v123 = v33;
  __swift_storeEnumTagSinglePayload((uint64_t)&v8[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData], 1, 1, v33);
  uint64_t v48 = (uint64_t)&v8[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier];
  uint64_t v110 = type metadata accessor for AnyTreeClassifier(0);
  __swift_storeEnumTagSinglePayload(v48, 1, 1, v110);
  uint64_t v49 = (uint64_t)&v8[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model];
  uint64_t v50 = type metadata accessor for AnyTreeClassifierModel(0);
  __swift_storeEnumTagSinglePayload(v49, 1, 1, v50);
  uint64_t v51 = &v8[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingMetrics];
  uint64_t v52 = type metadata accessor for AnyClassificationMetrics(0);
  uint64_t v53 = (uint64_t)v51;
  uint64_t v54 = v127;
  __swift_storeEnumTagSinglePayload(v53, 1, 1, v52);
  uint64_t v55 = v128;
  uint64_t v56 = v52;
  uint64_t v57 = v126;
  __swift_storeEnumTagSinglePayload((uint64_t)&v9[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics], 1, 1, v56);
  uint64_t v58 = v113;
  uint64_t v59 = static _FeatureUtilities.selectFeaturesFromTrainingData(trainingData:targetColumn:featureColumns:)(v57, v125, v54, (uint64_t)v55);
  uint64_t v113 = v58;
  if (v58)
  {
    swift_bridgeObjectRelease((_BYTE)v54);
    swift_bridgeObjectRelease((_BYTE)v55);
    outlined destroy of MLActivityClassifier.ModelParameters(a7, type metadata accessor for MLTrainingSessionParameters);
    (*(void (**)(uint64_t, uint64_t))(v119 + 8))(v116, v120);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v115, &demangling cache variable for type metadata for DataFrame?);
    uint64_t v60 = *(void (**)(uint64_t, uint64_t))(v121 + 8);
    uint64_t v61 = v57;
    uint64_t v62 = v123;
    v60(v61, v123);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v9[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters], &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
    v60((uint64_t)&v9[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData], v62);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v9[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData], &demangling cache variable for type metadata for DataFrame?);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v9[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier], &demangling cache variable for type metadata for AnyTreeClassifier?);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v9[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model], &demangling cache variable for type metadata for AnyTreeClassifierModel?);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v9[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingMetrics], &demangling cache variable for type metadata for AnyClassificationMetrics?);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v9[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics], &demangling cache variable for type metadata for AnyClassificationMetrics?);
    swift_deallocPartialClassInstance(v9, v114, *(unsigned int *)(*(void *)v9 + 48), *(unsigned __int16 *)(*(void *)v9 + 52));
  }
  else
  {
    uint64_t v128 = (void (*)(void, void))v59;
    swift_bridgeObjectRelease((_BYTE)v55);
    uint64_t v63 = v123;
    uint64_t v114 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v121 + 16);
    v114(v108, v57, v123);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v115, (uint64_t)v107, &demangling cache variable for type metadata for DataFrame?);
    (*(void (**)(uint64_t *, uint64_t, uint64_t))(v119 + 16))(v117, v116, v120);
    uint64_t v64 = (uint64_t)v103;
    uint64_t v65 = (uint64_t)v103 + v122[5];
    __swift_storeEnumTagSinglePayload(v65, 1, 1, v63);
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v121 + 32))(v64, v108, v63);
    uint64_t v66 = (uint64_t)v127;
    swift_bridgeObjectRetain((_BYTE)v127);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata((uint64_t)v107, v65, &demangling cache variable for type metadata for DataFrame?);
    uint64_t v67 = v122;
    uint64_t v68 = v122[6];
    *(void *)(v64 + v68) = v125;
    *(void *)(v64 + v68 + 8) = v66;
    *(void *)(v64 + v67[7]) = v128;
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v119 + 32))(v64 + v67[8], v117, v120);
    uint64_t v69 = (uint64_t)v124;
    outlined init with take of MLClassifierMetrics(v64, (uint64_t)v124, type metadata accessor for PersistentParametersForTreeBasedMethods);
    uint64_t v70 = v69;
    uint64_t v71 = (uint64_t)v101;
    outlined init with copy of PersistentParametersForTreeBasedMethods(v70, (uint64_t)v101, type metadata accessor for PersistentParametersForTreeBasedMethods);
    __swift_storeEnumTagSinglePayload(v71, 0, 1, (uint64_t)v122);
    uint64_t v72 = (uint64_t)v102;
    swift_beginAccess(v102, &v97, 33, 0);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v71, v72, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
    swift_endAccess(&v97);
    outlined init with copy of PersistentParametersForTreeBasedMethods(a7, (uint64_t)&v9[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_sessionParameters], type metadata accessor for MLTrainingSessionParameters);
    uint64_t v73 = v100;
    DataFrame.subscript.getter(v125, v127);
    uint64_t v74 = AnyColumn.wrappedElementType.getter();
    uint64_t v75 = *(void (**)(uint64_t *, uint64_t))(v99 + 8);
    v75(v73, v109);
    uint64_t v76 = swift_dynamicCastMetatype(v74, &type metadata for String);
    unsigned int v112 = v9;
    if (v76)
    {
      uint64_t v77 = (uint64_t)v104;
      uint64_t v78 = v125;
      DataFrame.subscript.getter(v125, v127, &type metadata for String);
      uint64_t v79 = specialized Set.init<A>(_:)(v77);
      uint64_t v80 = *(uint64_t *)((char *)v124 + v122[7]);
      swift_bridgeObjectRetain(v80);
      uint64_t v81 = (uint64_t)v117;
      BoostedTreeConfiguration.init()();
      AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)(v79, v78, (uint64_t)v127, v80, v81);
    }
    else
    {
      uint64_t v128 = (void (*)(void, void))v75;
      uint64_t v82 = v114;
      uint64_t v83 = v126;
      if (!swift_dynamicCastMetatype(v74, &type metadata for Int))
      {
        v82(v111, v83, v123);
        unint64_t v97 = 0;
        uint64_t v98 = (char *)0xE000000000000000;
        _StringGuts.grow(_:)(38);
        swift_bridgeObjectRelease((_BYTE)v98);
        unint64_t v97 = 0xD000000000000023;
        uint64_t v98 = "rt a new session." + 0x8000000000000000;
        uint64_t v91 = v106;
        char v92 = (char)v127;
        DataFrame.subscript.getter(v125, v127);
        swift_bridgeObjectRelease(v92);
        uint64_t v93 = AnyColumn.wrappedElementType.getter();
        v128(v91, v109);
        v94._uint64_t countAndFlagsBits = _typeName(_:qualified:)(v93, 0);
        LOBYTE(v93) = v94._object;
        String.append(_:)(v94);
        swift_bridgeObjectRelease(v93);
        v95._uint64_t countAndFlagsBits = 46;
        v95._char object = (void *)0xE100000000000000;
        String.append(_:)(v95);
        _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v97, v98, "CreateML/TreeClassifierTrainingSessionDelegate.swift", 52, 2, 73, 0);
        BUG();
      }
      uint64_t v84 = v125;
      uint64_t v85 = (uint64_t)v127;
      DataFrame.subscript.getter(v125, v127, &type metadata for Int);
      uint64_t v128 = (void (*)(void, void))specialized Set.init<A>(_:)();
      uint64_t v86 = *(uint64_t *)((char *)v124 + v122[7]);
      swift_bridgeObjectRetain(v86);
      uint64_t v87 = (uint64_t)v117;
      BoostedTreeConfiguration.init()();
      AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)((uint64_t)v128, v84, v85, v86, v87);
    }
    outlined destroy of MLActivityClassifier.ModelParameters(a7, type metadata accessor for MLTrainingSessionParameters);
    (*(void (**)(uint64_t, uint64_t))(v119 + 8))(v116, v120);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v115, &demangling cache variable for type metadata for DataFrame?);
    (*(void (**)(uint64_t, uint64_t))(v121 + 8))(v126, v123);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v124, type metadata accessor for PersistentParametersForTreeBasedMethods);
    uint64_t v88 = (uint64_t)v118;
    __swift_storeEnumTagSinglePayload((uint64_t)v118, 0, 1, v110);
    uint64_t v9 = v112;
    uint64_t v89 = (uint64_t)&v112[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier];
    swift_beginAccess(&v112[OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier], &v97, 33, 0);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v88, v89, &demangling cache variable for type metadata for AnyTreeClassifier?);
    swift_endAccess(&v97);
  }
  return v9;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> TreeClassifierTrainingSessionDelegate.setUp()()
{
  uint64_t v99 = v1;
  uint64_t v87 = type metadata accessor for BaseTreeClassifierModel(0);
  uint64_t v86 = *(void *)(v87 - 8);
  int64_t v2 = *(void *)(v86 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v88 = &v81;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifierModel?)
                             - 8)
                 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v85 = &v81;
  int64_t v8 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>)
                             - 8)
                 + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  uint64_t v90 = &v81;
  uint64_t v83 = type metadata accessor for BoostedTreeConfiguration(0);
  uint64_t v96 = *(void *)(v83 - 8);
  int64_t v11 = *(void *)(v96 + 64);
  uint64_t v12 = alloca(v11);
  int64_t v13 = alloca(v11);
  unint64_t v97 = &v81;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  Swift::String v94 = &v81;
  int64_t v16 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>)
                              - 8)
                  + 64);
  int64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v89 = &v81;
  int64_t v19 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifier?)
                              - 8)
                  + 64);
  uint64_t v20 = alloca(v19);
  int64_t v21 = alloca(v19);
  uint64_t v91 = &v81;
  uint64_t v22 = alloca(v19);
  uint64_t v23 = alloca(v19);
  char v92 = &v81;
  uint64_t v103 = type metadata accessor for AnyColumn(0);
  uint64_t v100 = *(void *)(v103 - 8);
  int64_t v24 = *(void *)(v100 + 64);
  uint64_t v25 = alloca(v24);
  uint64_t v26 = alloca(v24);
  uint64_t v84 = &v81;
  int64_t v27 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?)
                              - 8)
                  + 64);
  uint64_t v28 = alloca(v27);
  uint64_t v29 = alloca(v27);
  uint64_t v30 = type metadata accessor for PersistentParametersForTreeBasedMethods(0);
  int64_t v31 = *(void *)(*(void *)(v30 - 8) + 64);
  uint64_t v32 = alloca(v31);
  uint64_t v33 = alloca(v31);
  char v101 = &v81;
  uint64_t v34 = v99 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v99 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters, v82, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v34, (uint64_t)&v81, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  uint64_t v102 = v30;
  if (__swift_getEnumTagSinglePayload((uint64_t)&v81, 1, v30) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v81, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
    BUG();
  }
  uint64_t v35 = (uint64_t)v101;
  outlined init with take of MLClassifierMetrics((uint64_t)&v81, (uint64_t)v101, type metadata accessor for PersistentParametersForTreeBasedMethods);
  uint64_t v36 = v99;
  uint64_t v37 = v99 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData;
  swift_beginAccess(v99 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData, v95, 33, 0);
  uint64_t v38 = type metadata accessor for DataFrame(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v38 - 8) + 24))(v37, v35, v38);
  swift_endAccess(v95);
  uint64_t v39 = v35 + *(int *)(v102 + 20);
  uint64_t v40 = v36 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData;
  swift_beginAccess(v40, v95, 33, 0);
  outlined assign with copy of DataFrame?(v39, v40);
  swift_endAccess(v95);
  uint64_t v41 = *(int *)(v102 + 24);
  uint64_t v98 = *(void *)(v35 + v41);
  uint64_t v93 = v41;
  uint64_t v42 = *(void *)(v35 + v41 + 8);
  swift_beginAccess(v37, v95, 32, 0);
  swift_bridgeObjectRetain(v42);
  uint64_t v43 = v84;
  uint64_t v44 = v98;
  uint64_t v98 = v37;
  DataFrame.subscript.getter(v44, v42);
  swift_endAccess(v95);
  swift_bridgeObjectRelease(v42);
  uint64_t v45 = AnyColumn.wrappedElementType.getter();
  (*(void (**)(uint64_t *, uint64_t))(v100 + 8))(v43, v103);
  if (swift_dynamicCastMetatype(v45, &type metadata for String))
  {
    uint64_t v103 = *(uint64_t *)((char *)v101 + v93);
    uint64_t v46 = v103;
    uint64_t v47 = *(uint64_t *)((char *)v101 + v93 + 8);
    swift_beginAccess(v98, v95, 32, 0);
    swift_bridgeObjectRetain(v47);
    uint64_t v48 = (uint64_t)v89;
    DataFrame.subscript.getter(v46, v47, &type metadata for String);
    swift_endAccess(v95);
    swift_bridgeObjectRelease(v47);
    uint64_t v100 = specialized Set.init<A>(_:)(v48);
    uint64_t v49 = *(uint64_t *)((char *)v101 + *(int *)(v102 + 28));
    swift_bridgeObjectRetain(v47);
    swift_bridgeObjectRetain(v49);
    uint64_t v50 = (uint64_t)v94;
    BoostedTreeConfiguration.init()();
    uint64_t v51 = (uint64_t)v92;
    AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)(v100, v103, v47, v49, v50);
    uint64_t v103 = type metadata accessor for AnyTreeClassifier(0);
    __swift_storeEnumTagSinglePayload(v51, 0, 1, v103);
    uint64_t v52 = v99;
    uint64_t v53 = v99 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
    swift_beginAccess(v99 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier, v95, 33, 0);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v51, v53, &demangling cache variable for type metadata for AnyTreeClassifier?);
    swift_endAccess(v95);
    uint64_t v54 = v52;
  }
  else
  {
    uint64_t v55 = v93;
    uint64_t v56 = v98;
    uint64_t v57 = (uint64_t)v101;
    if (!swift_dynamicCastMetatype(v45, &type metadata for Int))
    {
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000001ELL, "essionDelegate.swift" + 0x8000000000000000, "CreateML/TreeClassifierTrainingSessionDelegate.swift", 52, 2, 101, 0);
      BUG();
    }
    uint64_t v58 = v57;
    uint64_t v103 = *(void *)(v57 + v55);
    uint64_t v59 = *(void *)(v57 + v55 + 8);
    swift_beginAccess(v56, v95, 32, 0);
    swift_bridgeObjectRetain(v59);
    DataFrame.subscript.getter(v103, v59, &type metadata for Int);
    swift_endAccess(v95);
    swift_bridgeObjectRelease(v59);
    uint64_t v100 = specialized Set.init<A>(_:)();
    uint64_t v60 = *(void *)(v58 + *(int *)(v102 + 28));
    swift_bridgeObjectRetain(v59);
    swift_bridgeObjectRetain(v60);
    uint64_t v61 = (uint64_t)v94;
    BoostedTreeConfiguration.init()();
    uint64_t v62 = (uint64_t)v92;
    AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)(v100, v103, v59, v60, v61);
    uint64_t v103 = type metadata accessor for AnyTreeClassifier(0);
    __swift_storeEnumTagSinglePayload(v62, 0, 1, v103);
    uint64_t v63 = v99;
    uint64_t v64 = v99 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
    swift_beginAccess(v99 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier, v95, 33, 0);
    uint64_t v65 = v64;
    uint64_t v54 = v63;
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v62, v65, &demangling cache variable for type metadata for AnyTreeClassifier?);
    swift_endAccess(v95);
  }
  uint64_t v66 = (char *)v101 + *(int *)(v102 + 32);
  uint64_t v67 = v97;
  uint64_t v68 = v83;
  uint64_t v102 = *(void *)(v96 + 16);
  ((void (*)(uint64_t *, char *))v102)(v97, v66);
  uint64_t v69 = v54 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
  swift_beginAccess(v54 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier, v95, 33, 0);
  type metadata accessor for AnyTreeClassifier(0);
  if (__swift_getEnumTagSinglePayload(v69, 1, v103) == 1) {
    BUG();
  }
  uint64_t v70 = v94;
  ((void (*)(uint64_t *, uint64_t *, uint64_t))v102)(v94, v67, v68);
  BaseTreeClassifier.configuration.setter(v70);
  (*(void (**)(uint64_t *, uint64_t))(v96 + 8))(v97, v68);
  swift_endAccess(v95);
  uint64_t v71 = (uint64_t)v91;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v69, (uint64_t)v91, &demangling cache variable for type metadata for AnyTreeClassifier?);
  if (__swift_getEnumTagSinglePayload(v71, 1, v103) == 1) {
    BUG();
  }
  unint64_t v97 = *(uint64_t **)v71;
  uint64_t v72 = *(void *)(v71 + 8);
  uint64_t v73 = *(void *)(v71 + 24);
  LOBYTE(v96) = *(unsigned char *)(v71 + 32);
  uint64_t v102 = v73;
  uint64_t v74 = *(void *)(v73 + 16);
  swift_bridgeObjectRetain(v72);
  uint64_t v75 = v88;
  BaseTreeClassifier.makeTransformer(classCount:featureCount:)(v74, 0);
  if (v0)
  {
    swift_bridgeObjectRelease(v72);
    swift_unexpectedError(v0, "CreateML/AnyTreeClassifier.swift", 32, 1);
    BUG();
  }
  uint64_t v76 = (uint64_t)v85;
  *uint64_t v85 = (uint64_t)v97;
  *(void *)(v76 + 8) = v72;
  uint64_t v77 = type metadata accessor for AnyTreeClassifierModel(0);
  *(void *)(v76 + 32) = 0;
  *(_OWORD *)(v76 + 16) = 0;
  (*(void (**)(uint64_t, uint64_t *, uint64_t))(v86 + 32))(v76 + *(int *)(v77 + 24), v75, v87);
  uint64_t v78 = *(int *)(v77 + 28);
  char v79 = v102;
  *(void *)(v76 + v78) = v102;
  *(unsigned char *)(v76 + v78 + 8) = v96 & 1;
  swift_bridgeObjectRetain(v79);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v101, type metadata accessor for PersistentParametersForTreeBasedMethods);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v91, type metadata accessor for AnyTreeClassifier);
  __swift_storeEnumTagSinglePayload(v76, 0, 1, v77);
  uint64_t v80 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model + v99;
  swift_beginAccess(OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model + v99, v95, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v76, v80, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  swift_endAccess(v95);
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> TreeClassifierTrainingSessionDelegate.resume(from:)(Swift::OpaquePointer from)
{
  uint64_t v101 = v1;
  uint64_t v108 = v2;
  rawValue = from._rawValue;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifierModel?)
                             - 8)
                 + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  unint64_t v97 = v89;
  uint64_t v6 = alloca(v3);
  uint64_t v7 = alloca(v3);
  Swift::String v95 = v89;
  int64_t v8 = *(void *)(*(void *)(type metadata accessor for BoostedTreeConfiguration(0) - 8) + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  uint64_t v100 = v89;
  int64_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifier?)
                              - 8)
                  + 64);
  uint64_t v12 = alloca(v11);
  int64_t v13 = alloca(v11);
  uint64_t v96 = v89;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  Swift::String v94 = v89;
  int64_t v16 = alloca(v11);
  int64_t v17 = alloca(v11);
  uint64_t v99 = v89;
  uint64_t v91 = type metadata accessor for AnyColumn(0);
  uint64_t v92 = *(void *)(v91 - 8);
  int64_t v18 = *(void *)(v92 + 64);
  int64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  uint64_t v93 = v89;
  int64_t v21 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                              - 8)
                  + 64);
  uint64_t v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  uint64_t v107 = v89;
  uint64_t v105 = type metadata accessor for MLCheckpoint(0);
  int64_t v24 = *(void *)(*(void *)(v105 - 8) + 64);
  uint64_t v25 = alloca(v24);
  uint64_t v26 = alloca(v24);
  uint64_t v103 = v89;
  int64_t v27 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?)
                              - 8)
                  + 64);
  uint64_t v28 = alloca(v27);
  uint64_t v29 = alloca(v27);
  uint64_t v30 = type metadata accessor for PersistentParametersForTreeBasedMethods(0);
  int64_t v31 = *(void *)(*(void *)(v30 - 8) + 64);
  uint64_t v32 = alloca(v31);
  uint64_t v33 = alloca(v31);
  uint64_t v34 = v108 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v108 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters, v90, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v34, (uint64_t)v89, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  uint64_t v102 = v30;
  if (__swift_getEnumTagSinglePayload((uint64_t)v89, 1, v30) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v89, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
    BUG();
  }
  outlined init with take of MLClassifierMetrics((uint64_t)v89, (uint64_t)v89, type metadata accessor for PersistentParametersForTreeBasedMethods);
  uint64_t v35 = (uint64_t)v107;
  specialized BidirectionalCollection.last.getter((uint64_t)rawValue);
  if (__swift_getEnumTagSinglePayload(v35, 1, v105) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v35, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v36 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v36, 0, 0);
    *(void *)uint64_t v37 = 0xD00000000000001DLL;
    *(void *)(v37 + 8) = "reated." + 0x8000000000000000;
    *(_OWORD *)(v37 + 16) = 0;
    *(_OWORD *)(v37 + 32) = 0;
    *(unsigned char *)(v37 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v36, v37, v38, v39, v40);
LABEL_17:
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v89, type metadata accessor for PersistentParametersForTreeBasedMethods);
    return;
  }
  unint64_t v41 = 0xEB0000000064657ALL;
  uint64_t v42 = v35;
  uint64_t v43 = (uint64_t)v103;
  outlined init with take of MLClassifierMetrics(v42, (uint64_t)v103, type metadata accessor for MLCheckpoint);
  switch(*(unsigned char *)(v43 + *(int *)(v105 + 20)))
  {
    case 0:
      uint64_t v44 = 0x696C616974696E69;
      break;
    case 1:
      uint64_t v44 = 0x6974636172747865;
      goto LABEL_10;
    case 2:
      swift_bridgeObjectRelease(0);
      uint64_t v45 = v108;
      goto LABEL_12;
    case 3:
      uint64_t v44 = 0x697461756C617665;
LABEL_10:
      unint64_t v41 = 0xEA0000000000676ELL;
      break;
    case 4:
      unint64_t v41 = 0xEB00000000676E69;
      uint64_t v44 = 0x636E657265666E69;
      break;
  }
  uint64_t v45 = v108;
  char v46 = _stringCompareWithSmolCheck(_:_:expecting:)(v44, v41, 0x676E696E69617274, 0xE800000000000000, 0);
  swift_bridgeObjectRelease(v41);
  if ((v46 & 1) == 0)
  {
    uint64_t v70 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v70, 0, 0);
    *(void *)uint64_t v71 = 0xD000000000000028;
    *(void *)(v71 + 8) = "" + 0x8000000000000000;
    *(_OWORD *)(v71 + 16) = 0;
    *(_OWORD *)(v71 + 32) = 0;
    *(unsigned char *)(v71 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v70, v71, v72, v73, v74);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v103, type metadata accessor for MLCheckpoint);
    goto LABEL_17;
  }
LABEL_12:
  uint64_t v47 = v45 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData;
  rawValue = (void *)(v45 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData);
  swift_beginAccess(v45 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData, v98, 33, 0);
  uint64_t v48 = type metadata accessor for DataFrame(0);
  (*(void (**)(uint64_t, unsigned char *, uint64_t))(*(void *)(v48 - 8) + 24))(v47, v89, v48);
  swift_endAccess(v98);
  uint64_t v49 = v102;
  uint64_t v50 = &v89[*(int *)(v102 + 20)];
  uint64_t v51 = v45 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData;
  swift_beginAccess(v51, v98, 33, 0);
  outlined assign with copy of DataFrame?((uint64_t)v50, v51);
  swift_endAccess(v98);
  uint64_t v52 = *(int *)(v49 + 24);
  uint64_t v107 = *(unsigned char **)&v89[v52];
  uint64_t v104 = v89;
  uint64_t v105 = v52;
  uint64_t v53 = *(void *)&v89[v52 + 8];
  swift_beginAccess(rawValue, v98, 32, 0);
  swift_bridgeObjectRetain(v53);
  uint64_t v54 = v93;
  DataFrame.subscript.getter(v107, v53);
  swift_endAccess(v98);
  swift_bridgeObjectRelease(v53);
  uint64_t v55 = AnyColumn.wrappedElementType.getter();
  (*(void (**)(unsigned char *, uint64_t))(v92 + 8))(v54, v91);
  if (swift_dynamicCastMetatype(v55, &type metadata for String))
  {
    rawValue = specialized _setUpCast<A, B>(_:)((uint64_t)&_swiftEmptySetSingleton);
    uint64_t v107 = *(unsigned char **)&v104[v105];
    uint64_t v56 = *(void *)&v104[v105 + 8];
    uint64_t v57 = *(void *)&v104[*(int *)(v102 + 28)];
    swift_bridgeObjectRetain(v56);
    swift_bridgeObjectRetain(v57);
    uint64_t v58 = (uint64_t)v100;
    BoostedTreeConfiguration.init()();
    uint64_t v59 = (uint64_t)v99;
    AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)((uint64_t)rawValue, (uint64_t)v107, v56, v57, v58);
    uint64_t v60 = type metadata accessor for AnyTreeClassifier(0);
    __swift_storeEnumTagSinglePayload(v59, 0, 1, v60);
    uint64_t v61 = v108 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
    swift_beginAccess(v108 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier, v98, 33, 0);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v59, v61, &demangling cache variable for type metadata for AnyTreeClassifier?);
    swift_endAccess(v98);
    uint64_t v62 = (uint64_t)v94;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v61, (uint64_t)v94, &demangling cache variable for type metadata for AnyTreeClassifier?);
    if (__swift_getEnumTagSinglePayload(v62, 1, v60) == 1) {
      BUG();
    }
    uint64_t v63 = lazy protocol witness table accessor for type AnyTreeClassifier and conformance AnyTreeClassifier();
    uint64_t v64 = (uint64_t)v95;
    uint64_t v65 = (uint64_t)v103;
    uint64_t v66 = v101;
    SupervisedTabularEstimator.read(from:)(v103, v60, v63);
    outlined destroy of MLActivityClassifier.ModelParameters(v65, type metadata accessor for MLCheckpoint);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v104, type metadata accessor for PersistentParametersForTreeBasedMethods);
    outlined destroy of MLActivityClassifier.ModelParameters(v62, type metadata accessor for AnyTreeClassifier);
    if (!v66)
    {
      uint64_t v67 = type metadata accessor for AnyTreeClassifierModel(0);
      __swift_storeEnumTagSinglePayload(v64, 0, 1, v67);
      uint64_t v68 = v64;
      uint64_t v69 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model + v108;
LABEL_23:
      swift_beginAccess(v69, v98, 33, 0);
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v68, v69, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
      swift_endAccess(v98);
    }
  }
  else
  {
    uint64_t v75 = v105;
    uint64_t v76 = (uint64_t)v104;
    if (!swift_dynamicCastMetatype(v55, &type metadata for Int))
    {
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000001ELL, "essionDelegate.swift" + 0x8000000000000000, "CreateML/TreeClassifierTrainingSessionDelegate.swift", 52, 2, 142, 0);
      BUG();
    }
    rawValue = specialized _setUpCast<A, B>(_:)((uint64_t)&_swiftEmptySetSingleton);
    uint64_t v107 = *(unsigned char **)(v76 + v75);
    uint64_t v77 = *(void *)(v76 + v75 + 8);
    uint64_t v78 = *(void *)(v76 + *(int *)(v102 + 28));
    swift_bridgeObjectRetain(v77);
    swift_bridgeObjectRetain(v78);
    uint64_t v79 = (uint64_t)v100;
    BoostedTreeConfiguration.init()();
    uint64_t v80 = (uint64_t)v99;
    AnyTreeClassifier.init(labels:annotationColumnName:featureColumnNames:configuration:)((uint64_t)rawValue, (uint64_t)v107, v77, v78, v79);
    uint64_t v81 = type metadata accessor for AnyTreeClassifier(0);
    __swift_storeEnumTagSinglePayload(v80, 0, 1, v81);
    uint64_t v82 = v108 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
    swift_beginAccess(v108 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier, v98, 33, 0);
    outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v80, v82, &demangling cache variable for type metadata for AnyTreeClassifier?);
    swift_endAccess(v98);
    uint64_t v83 = (uint64_t)v96;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v82, (uint64_t)v96, &demangling cache variable for type metadata for AnyTreeClassifier?);
    if (__swift_getEnumTagSinglePayload(v83, 1, v81) == 1) {
      BUG();
    }
    uint64_t v84 = lazy protocol witness table accessor for type AnyTreeClassifier and conformance AnyTreeClassifier();
    uint64_t v85 = (uint64_t)v97;
    uint64_t v86 = (uint64_t)v103;
    uint64_t v87 = v101;
    SupervisedTabularEstimator.read(from:)(v103, v81, v84);
    outlined destroy of MLActivityClassifier.ModelParameters(v86, type metadata accessor for MLCheckpoint);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v104, type metadata accessor for PersistentParametersForTreeBasedMethods);
    outlined destroy of MLActivityClassifier.ModelParameters(v83, type metadata accessor for AnyTreeClassifier);
    if (!v87)
    {
      uint64_t v88 = type metadata accessor for AnyTreeClassifierModel(0);
      __swift_storeEnumTagSinglePayload(v85, 0, 1, v88);
      uint64_t v69 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model + v108;
      uint64_t v68 = v85;
      goto LABEL_23;
    }
  }
}

Swift::Int_optional __swiftcall TreeClassifierTrainingSessionDelegate.itemCount(phase:)(CreateML::MLPhase phase)
{
  if (*(unsigned char *)phase == 2)
  {
    uint64_t v2 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_sessionParameters + v1;
    char v3 = 0;
    v4.value = *(void *)(*(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 28) + v2);
  }
  else
  {
    char v3 = 1;
    v4.value = 0;
  }
  v4.is_nil = v3;
  return v4;
}

uint64_t TreeClassifierTrainingSessionDelegate.train(from:)(uint64_t a1)
{
  v2[20] = v1;
  v2[19] = a1;
  uint64_t v3 = type metadata accessor for MetricsKey(0);
  v2[21] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[22] = v4;
  v2[23] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for DataFrame(0);
  v2[24] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[25] = v6;
  v2[26] = swift_task_alloc((*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifier?);
  v2[27] = swift_task_alloc((*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  v2[28] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifierModel?);
  v2[29] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(TreeClassifierTrainingSessionDelegate.train(from:), 0, 0);
}

uint64_t TreeClassifierTrainingSessionDelegate.train(from:)()
{
  uint64_t v1 = *(void *)(v0 + 232);
  uint64_t v2 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model;
  *(void *)(v0 + 240) = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model;
  uint64_t v3 = *(void *)(v0 + 160) + v2;
  swift_beginAccess(v3, v0 + 16, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v3, v1, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  uint64_t v4 = type metadata accessor for AnyTreeClassifierModel(0);
  *(void *)(v0 + 248) = v4;
  LODWORD(v3) = __swift_getEnumTagSinglePayload(v1, 1, v4);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  if (v3 == 1) {
    BUG();
  }
  uint64_t v5 = *(void *)(v0 + 224);
  uint64_t v6 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters + *(void *)(v0 + 160);
  swift_beginAccess(v6, v0 + 40, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v6, v5, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  uint64_t v7 = type metadata accessor for PersistentParametersForTreeBasedMethods(0);
  LODWORD(v6) = __swift_getEnumTagSinglePayload(v5, 1, v7);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v5, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  if (v6 == 1) {
    BUG();
  }
  uint64_t v8 = *(void *)(v0 + 152);
  uint64_t v9 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_sessionParameters + *(void *)(v0 + 160);
  uint64_t v10 = type metadata accessor for MLTrainingSessionParameters(0);
  uint64_t v11 = *(void *)(*(int *)(v10 + 20) + v9);
  *(unsigned char *)(v0 + 144) = __OFADD__(v11, v8);
  *(void *)(v0 + 136) = v11 + v8;
  if (__OFADD__(v11, v8)) {
    BUG();
  }
  uint64_t v12 = *(void *)(v9 + *(int *)(v10 + 28));
  *(void *)(v0 + 256) = v12;
  BOOL v13 = __OFSUB__(v12, v8);
  uint64_t v14 = v12 - v8;
  if (v13) {
    BUG();
  }
  if (v11 < v14) {
    uint64_t v14 = v11;
  }
  *(void *)(v0 + 264) = v14;
  uint64_t v15 = type metadata accessor for EventCollector();
  swift_allocObject(v15, 32, 7);
  *(void *)(v0 + 272) = EventCollector.init()();
  if (v14 < 0) {
    BUG();
  }
  if (v14)
  {
    uint64_t v16 = *(void *)(v0 + 160);
    uint64_t v17 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
    *(void *)(v0 + 280) = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier;
    uint64_t v18 = v16 + v17;
    uint64_t v19 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData;
    *(void *)(v0 + 288) = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData;
    uint64_t v20 = v19 + v16;
    swift_beginAccess(v18, v0 + 64, 0, 0);
    swift_beginAccess(v20, v0 + 88, 0, 0);
    *(void *)(v0 + 296) = 0;
    if (!*(void *)(v0 + 264)) {
      BUG();
    }
    uint64_t v21 = *(void *)(v0 + 216);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 280) + *(void *)(v0 + 160), v21, &demangling cache variable for type metadata for AnyTreeClassifier?);
    uint64_t v22 = type metadata accessor for AnyTreeClassifier(0);
    if (__swift_getEnumTagSinglePayload(v21, 1, v22) == 1) {
      BUG();
    }
    uint64_t v23 = *(void *)(v0 + 248);
    uint64_t v24 = *(void *)(v0 + 160);
    uint64_t v25 = v24 + *(void *)(v0 + 288);
    uint64_t v26 = *(void *)(v0 + 240) + v24;
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 200) + 16))(*(void *)(v0 + 208), v25, *(void *)(v0 + 192));
    swift_beginAccess(v26, v0 + 112, 33, 0);
    if (__swift_getEnumTagSinglePayload(v26, 1, v23) == 1) {
      BUG();
    }
    uint64_t v27 = *(void *)(v0 + 272);
    uint64_t v28 = dword_3A9EDC;
    uint64_t v29 = *(void *)(v0 + 240) + *(void *)(v0 + 160);
    swift_retain();
    uint64_t v30 = (void *)swift_task_alloc(v28);
    *(void *)(v0 + 304) = v30;
    void *v30 = v0;
    v30[1] = TreeClassifierTrainingSessionDelegate.train(from:);
    return AnyTreeClassifier.update(_:with:eventHandler:)(v29, *(void *)(v0 + 208), (uint64_t)partial apply for closure #1 in TreeClassifierTrainingSessionDelegate.train(from:), v27);
  }
  else
  {
    unint64_t v32 = *(void *)(v0 + 184);
    uint64_t v52 = *(void *)(v0 + 168);
    uint64_t v33 = *(void *)(v0 + 176);
    static MetricsKey.trainingAccuracy.getter();
    id v34 = specialized EventCollector.getLast<A>(metric:type:)();
    char v36 = v35;
    unint64_t v37 = v32;
    uint64_t v38 = v52;
    uint64_t v53 = *(void (**)(unint64_t, uint64_t))(v33 + 8);
    v53(v32, v38);
    if ((v36 & 1) == 0)
    {
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
      specialized _NativeDictionary.setValue(_:forKey:isUnique:)(3, isUniquelyReferenced_nonNull_native, *(double *)&v34);
      unint64_t v37 = 0x8000000000000000;
      swift_bridgeObjectRelease(0);
    }
    uint64_t v40 = *(void *)(v0 + 168);
    unint64_t v41 = *(void *)(v0 + 184);
    static MetricsKey.trainingLoss.getter(v37);
    id v50 = specialized EventCollector.getLast<A>(metric:type:)();
    char v43 = v42;
    v53(v41, v40);
    if ((v43 & 1) == 0)
    {
      char v44 = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
      specialized _NativeDictionary.setValue(_:forKey:isUnique:)(0, v44, *(double *)&v50);
      swift_bridgeObjectRelease(0);
    }
    uint64_t v45 = *(void *)(v0 + 232);
    uint64_t v49 = *(void *)(v0 + 224);
    uint64_t v48 = *(void *)(v0 + 216);
    uint64_t v47 = *(void *)(v0 + 208);
    uint64_t v51 = *(void *)(v0 + 184);
    BOOL v46 = *(void *)(v0 + 136) >= *(void *)(v0 + 256);
    uint64_t v54 = specialized _dictionaryUpCast<A, B, C, D>(_:)((uint64_t)_swiftEmptyDictionarySingleton);
    swift_release();
    swift_bridgeObjectRelease(_swiftEmptyDictionarySingleton);
    swift_task_dealloc(v45);
    swift_task_dealloc(v49);
    swift_task_dealloc(v48);
    swift_task_dealloc(v47);
    swift_task_dealloc(v51);
    return (*(uint64_t (**)(void, void *, BOOL))(v0 + 8))(*(void *)(v0 + 264), v54, v46);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t (*v4)();
  void *v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;

  uint64_t v3 = *(void *)(*(void *)v1 + 304);
  uint64_t v2 = *(void **)v1;
  *(void *)(*(void *)v1 + 312) = v0;
  swift_task_dealloc(v3);
  if (v0)
  {
    uint64_t v4 = TreeClassifierTrainingSessionDelegate.train(from:);
  }
  else
  {
    uint64_t v5 = v2 + 14;
    uint64_t v10 = v2[27];
    uint64_t v6 = v2[26];
    uint64_t v7 = v2[24];
    uint64_t v8 = v2[25];
    swift_endAccess(v5);
    swift_release();
    (*(void (**)(uint64_t, uint64_t))(v8 + 8))(v6, v7);
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for AnyTreeClassifier);
    uint64_t v4 = TreeClassifierTrainingSessionDelegate.train(from:);
  }
  return swift_task_switch(v4, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  unint64_t v2;
  uint64_t v3;
  id v4;
  char v5;
  char v6;
  unint64_t v7;
  uint64_t v8;
  char isUniquelyReferenced_nonNull_native;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  void *v19;
  uint64_t v21;
  unint64_t v22;
  char v23;
  char v24;
  char v25;
  uint64_t v26;
  BOOL v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  id v31;
  uint64_t v32;
  uint64_t v33;
  void (*v34)(unint64_t, uint64_t);
  void *v35;

  uint64_t v1 = *(void *)(v0 + 296) + 1;
  if (v1 == *(void *)(v0 + 264))
  {
    uint64_t v2 = *(void *)(v0 + 184);
    uint64_t v33 = *(void *)(v0 + 168);
    uint64_t v3 = *(void *)(v0 + 176);
    static MetricsKey.trainingAccuracy.getter();
    uint64_t v4 = specialized EventCollector.getLast<A>(metric:type:)();
    uint64_t v6 = v5;
    uint64_t v7 = v2;
    uint64_t v8 = v33;
    id v34 = *(void (**)(unint64_t, uint64_t))(v3 + 8);
    v34(v2, v8);
    if ((v6 & 1) == 0)
    {
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
      specialized _NativeDictionary.setValue(_:forKey:isUnique:)(3, isUniquelyReferenced_nonNull_native, *(double *)&v4);
      uint64_t v7 = 0x8000000000000000;
      swift_bridgeObjectRelease(0);
    }
    uint64_t v21 = *(void *)(v0 + 168);
    uint64_t v22 = *(void *)(v0 + 184);
    static MetricsKey.trainingLoss.getter(v7);
    int64_t v31 = specialized EventCollector.getLast<A>(metric:type:)();
    uint64_t v24 = v23;
    v34(v22, v21);
    if ((v24 & 1) == 0)
    {
      uint64_t v25 = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
      specialized _NativeDictionary.setValue(_:forKey:isUnique:)(0, v25, *(double *)&v31);
      swift_bridgeObjectRelease(0);
    }
    uint64_t v26 = *(void *)(v0 + 232);
    uint64_t v30 = *(void *)(v0 + 224);
    uint64_t v29 = *(void *)(v0 + 216);
    uint64_t v28 = *(void *)(v0 + 208);
    unint64_t v32 = *(void *)(v0 + 184);
    uint64_t v27 = *(void *)(v0 + 136) >= *(void *)(v0 + 256);
    char v35 = specialized _dictionaryUpCast<A, B, C, D>(_:)((uint64_t)_swiftEmptyDictionarySingleton);
    swift_release();
    swift_bridgeObjectRelease(_swiftEmptyDictionarySingleton);
    swift_task_dealloc(v26);
    swift_task_dealloc(v30);
    swift_task_dealloc(v29);
    swift_task_dealloc(v28);
    swift_task_dealloc(v32);
    return (*(uint64_t (**)(void, void *, BOOL))(v0 + 8))(*(void *)(v0 + 264), v35, v27);
  }
  else
  {
    *(void *)(v0 + 296) = v1;
    uint64_t v10 = *(void *)(v0 + 216);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 280) + *(void *)(v0 + 160), v10, &demangling cache variable for type metadata for AnyTreeClassifier?);
    uint64_t v11 = type metadata accessor for AnyTreeClassifier(0);
    if (__swift_getEnumTagSinglePayload(v10, 1, v11) == 1) {
      BUG();
    }
    uint64_t v12 = *(void *)(v0 + 248);
    BOOL v13 = *(void *)(v0 + 160);
    uint64_t v14 = v13 + *(void *)(v0 + 288);
    uint64_t v15 = *(void *)(v0 + 240) + v13;
    (*(void (**)(void, uint64_t, void))(*(void *)(v0 + 200) + 16))(*(void *)(v0 + 208), v14, *(void *)(v0 + 192));
    swift_beginAccess(v15, v0 + 112, 33, 0);
    if (__swift_getEnumTagSinglePayload(v15, 1, v12) == 1) {
      BUG();
    }
    uint64_t v16 = *(void *)(v0 + 272);
    uint64_t v17 = dword_3A9EDC;
    uint64_t v18 = *(void *)(v0 + 240) + *(void *)(v0 + 160);
    swift_retain();
    uint64_t v19 = (void *)swift_task_alloc(v17);
    *(void *)(v0 + 304) = v19;
    *uint64_t v19 = v0;
    v19[1] = TreeClassifierTrainingSessionDelegate.train(from:);
    return AnyTreeClassifier.update(_:with:eventHandler:)(v18, *(void *)(v0 + 208), (uint64_t)partial apply for closure #1 in TreeClassifierTrainingSessionDelegate.train(from:), v16);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;

  uint64_t v1 = *(void *)(v0 + 272);
  uint64_t v8 = *(void *)(v0 + 232);
  uint64_t v7 = *(void *)(v0 + 224);
  uint64_t v2 = *(void *)(v0 + 216);
  uint64_t v3 = *(void *)(v0 + 208);
  uint64_t v9 = *(void *)(v0 + 200);
  uint64_t v6 = *(void *)(v0 + 184);
  uint64_t v4 = *(void *)(v0 + 192);
  swift_endAccess(v0 + 112);
  swift_release_n(v1);
  (*(void (**)(uint64_t, uint64_t))(v9 + 8))(v3, v4);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for AnyTreeClassifier);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v6);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t TreeClassifierTrainingSessionDelegate.evaluate(from:)()
{
  v1[26] = v0;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  v1[27] = swift_task_alloc((*(void *)(*(void *)(v2 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v3 = (*(void *)(*(void *)(type metadata accessor for AnyColumn(0) - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v1[28] = swift_task_alloc(v3);
  v1[29] = swift_task_alloc(v3);
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyClassificationMetrics?);
  v1[30] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for DataFrame(0);
  v1[31] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v1[32] = v6;
  unint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v1[33] = swift_task_alloc(v7);
  v1[34] = swift_task_alloc(v7);
  v1[35] = swift_task_alloc(v7);
  v1[36] = swift_task_alloc(v7);
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifierModel?);
  v1[37] = swift_task_alloc((*(void *)(*(void *)(v8 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v9 = type metadata accessor for AnyTreeClassifierModel(0);
  v1[38] = v9;
  v1[39] = swift_task_alloc((*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(TreeClassifierTrainingSessionDelegate.evaluate(from:), 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  int EnumTagSinglePayload;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  void (*v46)(uint64_t, uint64_t);
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  uint64_t v56;
  uint64_t v57;
  uint64_t v58;

  uint64_t v1 = *(void *)(v0 + 304);
  uint64_t v2 = *(void *)(v0 + 296);
  unint64_t v3 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model + *(void *)(v0 + 208);
  swift_beginAccess(v3, v0 + 16, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v3, v2, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 296), &demangling cache variable for type metadata for AnyTreeClassifierModel?);
LABEL_5:
    unint64_t v7 = 0;
    goto LABEL_6;
  }
  uint64_t v4 = *(void *)(v0 + 208);
  outlined init with take of MLClassifierMetrics(*(void *)(v0 + 296), *(void *)(v0 + 312), type metadata accessor for AnyTreeClassifierModel);
  uint64_t v5 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters + v4;
  swift_beginAccess(v5, v0 + 40, 0, 0);
  uint64_t v6 = type metadata accessor for PersistentParametersForTreeBasedMethods(0);
  if (__swift_getEnumTagSinglePayload(v5, 1, v6))
  {
    outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 312), type metadata accessor for AnyTreeClassifierModel);
    goto LABEL_5;
  }
  uint64_t v56 = *(void *)(v0 + 280);
  uint64_t v45 = *(void *)(v0 + 256);
  uint64_t v48 = *(void *)(v0 + 248);
  BOOL v13 = *(int *)(v6 + 24);
  char v42 = *(void *)(v5 + v13);
  uint64_t v14 = *(void *)(v5 + v13 + 8);
  uint64_t v15 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData + *(void *)(v0 + 208);
  swift_beginAccess(v15, v0 + 64, 0, 0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(v45 + 16))(v56, v15, v48);
  swift_bridgeObjectRetain(v14);
  AnyTreeClassifierModel.applied(to:eventHandler:)(v56, 0, 0);
  uint64_t v57 = *(void *)(v0 + 248);
  uint64_t v33 = *(void *)(v0 + 240);
  uint64_t v51 = v14;
  char v36 = *(void *)(v0 + 232);
  uint64_t v53 = *(void *)(v0 + 224);
  int64_t v31 = *(void *)(v0 + 208);
  uint64_t v39 = *(void *)(v0 + 216);
  BOOL v46 = *(void (**)(uint64_t, uint64_t))(*(void *)(v0 + 256) + 8);
  ((void (*)(void))v46)(*(void *)(v0 + 280));
  DataFrame.subscript.getter(v42, v14);
  swift_beginAccess(v15, v0 + 88, 32, 0);
  DataFrame.subscript.getter(v42, v14);
  swift_endAccess(v0 + 88);
  AnyClassificationMetrics.init(_:_:)(v36, v53);
  uint64_t v54 = type metadata accessor for AnyClassificationMetrics(0);
  __swift_storeEnumTagSinglePayload(v33, 0, 1, v54);
  uint64_t v16 = v31 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingMetrics;
  swift_beginAccess(v31 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingMetrics, v0 + 112, 33, 0);
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v33, v16, &demangling cache variable for type metadata for AnyClassificationMetrics?);
  swift_endAccess(v0 + 112);
  uint64_t v17 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData + v31;
  swift_beginAccess(OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData + v31, v0 + 136, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v17, v39, &demangling cache variable for type metadata for DataFrame?);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v39, 1, v57);
  uint64_t v19 = *(void *)(v0 + 312);
  if (EnumTagSinglePayload == 1)
  {
    uint64_t v20 = *(void *)(v0 + 288);
    uint64_t v21 = *(void *)(v0 + 248);
    uint64_t v49 = *(void *)(v0 + 240);
    uint64_t v22 = *(void *)(v0 + 208);
    char v43 = *(void *)(v0 + 216);
    swift_bridgeObjectRelease(v51);
    v46(v20, v21);
    outlined destroy of MLActivityClassifier.ModelParameters(v19, type metadata accessor for AnyTreeClassifierModel);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v43, &demangling cache variable for type metadata for DataFrame?);
    __swift_storeEnumTagSinglePayload(v49, 1, 1, v54);
    uint64_t v23 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics + v22;
    uint64_t v24 = v0 + 160;
    swift_beginAccess(v23, v0 + 160, 33, 0);
    uint64_t v25 = v49;
    uint64_t v26 = v23;
  }
  else
  {
    uint64_t v27 = *(void *)(v0 + 272);
    (*(void (**)(uint64_t, void, void))(*(void *)(v0 + 256) + 32))(v27, *(void *)(v0 + 216), *(void *)(v0 + 248));
    AnyTreeClassifierModel.applied(to:eventHandler:)(v27, 0, 0);
    uint64_t v30 = *(void *)(v0 + 312);
    unint64_t v32 = *(void *)(v0 + 288);
    uint64_t v58 = *(void *)(v0 + 272);
    unint64_t v37 = *(void *)(v0 + 264);
    id v34 = *(void *)(v0 + 248);
    char v35 = *(void *)(v0 + 240);
    uint64_t v38 = *(void *)(v0 + 232);
    uint64_t v40 = *(void *)(v0 + 208);
    uint64_t v28 = *(void *)(v0 + 224);
    DataFrame.subscript.getter(v42, v51);
    DataFrame.subscript.getter(v42, v51);
    swift_bridgeObjectRelease(v51);
    AnyClassificationMetrics.init(_:_:)(v38, v28);
    v46(v37, v34);
    v46(v58, v34);
    v46(v32, v34);
    outlined destroy of MLActivityClassifier.ModelParameters(v30, type metadata accessor for AnyTreeClassifierModel);
    __swift_storeEnumTagSinglePayload(v35, 0, 1, v54);
    uint64_t v29 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics + v40;
    uint64_t v24 = v0 + 184;
    swift_beginAccess(OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics + v40, v0 + 184, 33, 0);
    uint64_t v25 = v35;
    uint64_t v26 = v29;
  }
  outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v25, v26, &demangling cache variable for type metadata for AnyClassificationMetrics?);
  swift_endAccess(v24);
  unint64_t v7 = 1;
LABEL_6:
  id v50 = v7;
  uint64_t v8 = *(void *)(v0 + 296);
  uint64_t v9 = *(void *)(v0 + 288);
  uint64_t v10 = *(void *)(v0 + 280);
  uint64_t v11 = *(void *)(v0 + 272);
  unint64_t v41 = *(void *)(v0 + 264);
  uint64_t v47 = *(void *)(v0 + 240);
  uint64_t v55 = *(void *)(v0 + 232);
  uint64_t v52 = *(void *)(v0 + 216);
  char v44 = *(void *)(v0 + 224);
  swift_task_dealloc(*(void *)(v0 + 312));
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v10);
  swift_task_dealloc(v11);
  swift_task_dealloc(v41);
  swift_task_dealloc(v47);
  swift_task_dealloc(v55);
  swift_task_dealloc(v44);
  swift_task_dealloc(v52);
  return (*(uint64_t (**)(uint64_t, uint64_t))(v0 + 8))(v50, 1);
}

char TreeClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)(uint64_t a1, unsigned __int8 *a2)
{
  uint64_t v32 = v2;
  uint64_t v30 = a1;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifier?)
                             - 8)
                 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v28 = v25;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyTreeClassifierModel?)
                             - 8)
                 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = type metadata accessor for AnyTreeClassifierModel(0);
  int64_t v11 = *(void *)(*(void *)(v10 - 8) + 64);
  uint64_t v12 = alloca(v11);
  BOOL v13 = alloca(v11);
  uint64_t v27 = v25;
  int v31 = *a2;
  uint64_t v29 = v3;
  uint64_t v14 = v3 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model;
  swift_beginAccess(v3 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model, v25, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v14, (uint64_t)v25, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  if (__swift_getEnumTagSinglePayload((uint64_t)v25, 1, v10) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v25, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
    return 0;
  }
  unint64_t v15 = 0xEB0000000064657ALL;
  uint64_t v16 = (uint64_t)v27;
  outlined init with take of MLClassifierMetrics((uint64_t)v25, (uint64_t)v27, type metadata accessor for AnyTreeClassifierModel);
  switch(v31)
  {
    case 0:
      uint64_t v17 = 0x696C616974696E69;
      break;
    case 1:
      uint64_t v17 = 0x6974636172747865;
      goto LABEL_8;
    case 2:
      swift_bridgeObjectRelease(0);
      goto LABEL_11;
    case 3:
      uint64_t v17 = 0x697461756C617665;
LABEL_8:
      unint64_t v15 = 0xEA0000000000676ELL;
      break;
    case 4:
      unint64_t v15 = 0xEB00000000676E69;
      uint64_t v17 = 0x636E657265666E69;
      break;
  }
  char v18 = _stringCompareWithSmolCheck(_:_:expecting:)(v17, v15, 0x676E696E69617274, 0xE800000000000000, 0);
  swift_bridgeObjectRelease(v15);
  if ((v18 & 1) == 0)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(v16, type metadata accessor for AnyTreeClassifierModel);
    return 0;
  }
LABEL_11:
  uint64_t v19 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier + v29;
  swift_beginAccess(OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier + v29, v26, 0, 0);
  uint64_t v20 = (uint64_t)v28;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v19, (uint64_t)v28, &demangling cache variable for type metadata for AnyTreeClassifier?);
  uint64_t v21 = type metadata accessor for AnyTreeClassifier(0);
  if (__swift_getEnumTagSinglePayload(v20, 1, v21) == 1) {
    BUG();
  }
  uint64_t v22 = lazy protocol witness table accessor for type AnyTreeClassifier and conformance AnyTreeClassifier();
  uint64_t v23 = v32;
  SupervisedTabularEstimator.write(_:to:overwrite:)(v16, v30, 1, v21, v22);
  outlined destroy of MLActivityClassifier.ModelParameters(v16, type metadata accessor for AnyTreeClassifierModel);
  char result = outlined destroy of MLActivityClassifier.ModelParameters(v20, type metadata accessor for AnyTreeClassifier);
  if (!v23) {
    return 1;
  }
  return result;
}

uint64_t TreeClassifierTrainingSessionDelegate.save(to:)(uint64_t a1)
{
  uint64_t v19 = v1;
  uint64_t v20 = a1;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?)
                             - 8)
                 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v6 = type metadata accessor for PersistentParametersForTreeBasedMethods(0);
  int64_t v7 = *(void *)(*(void *)(v6 - 8) + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters + v2;
  swift_beginAccess(v10, v18, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, (uint64_t)&v17, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v17, 1, v6) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v17, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
    uint64_t v11 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v11, 0, 0);
    *(void *)uint64_t v12 = 0xD000000000000031;
    *(void *)(v12 + 8) = "Selected features" + 0x8000000000000000;
    *(_OWORD *)(v12 + 16) = 0;
    *(_OWORD *)(v12 + 32) = 0;
    *(unsigned char *)(v12 + 48) = 2;
    return swift_willThrow(&type metadata for MLCreateError, v11, v12, v13, v14, v15);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)&v17, (uint64_t)&v17, type metadata accessor for PersistentParametersForTreeBasedMethods);
    PersistentParametersForTreeBasedMethods.save(toSessionDirectory:)(v20);
    return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v17, type metadata accessor for PersistentParametersForTreeBasedMethods);
  }
}

NSURL *TreeClassifierTrainingSessionDelegate.restore(from:phase:)(uint64_t a1)
{
  char v36 = (uint64_t *)v1;
  uint64_t v31 = v2;
  uint64_t v30 = a1;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?)
                             - 8)
                 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v33 = &v27;
  uint64_t v6 = alloca(v3);
  int64_t v7 = alloca(v3);
  char v35 = &v27;
  uint64_t v8 = type metadata accessor for URL(0);
  uint64_t v9 = *(void *)(v8 - 8);
  int64_t v10 = *(void *)(v9 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v32 = type metadata accessor for PersistentParametersForTreeBasedMethods(0);
  int64_t v13 = *(void *)(*(void *)(v32 - 8) + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  id v34 = &v27;
  uint64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v9 + 16))(&v27, v30, v8);
  uint64_t v18 = (uint64_t)v36;
  char result = PersistentParametersForTreeBasedMethods.init(sessionDirectory:)((uint64_t)&v27);
  if (!v18)
  {
    char v36 = &v27;
    uint64_t v20 = OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters + v31;
    swift_beginAccess(OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters + v31, v28, 0, 0);
    uint64_t v21 = (uint64_t)v35;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v20, (uint64_t)v35, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
    uint64_t v22 = v21;
    uint64_t v23 = v32;
    if (__swift_getEnumTagSinglePayload(v22, 1, v32) == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v35, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
      uint64_t v24 = (uint64_t)v33;
      outlined init with take of MLClassifierMetrics((uint64_t)v36, (uint64_t)v33, type metadata accessor for PersistentParametersForTreeBasedMethods);
      __swift_storeEnumTagSinglePayload(v24, 0, 1, v23);
      swift_beginAccess(v20, v29, 33, 0);
      outlined assign with take of MLTrainingSession<MLImageClassifier>.Metadata(v24, v20, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
      return (NSURL *)swift_endAccess(v29);
    }
    else
    {
      uint64_t v25 = (uint64_t)v34;
      outlined init with take of MLClassifierMetrics((uint64_t)v35, (uint64_t)v34, type metadata accessor for PersistentParametersForTreeBasedMethods);
      uint64_t v26 = (uint64_t)v36;
      TreeClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)((uint64_t)v36, v25);
      outlined destroy of MLActivityClassifier.ModelParameters(v25, type metadata accessor for PersistentParametersForTreeBasedMethods);
      return (NSURL *)outlined destroy of MLActivityClassifier.ModelParameters(v26, type metadata accessor for PersistentParametersForTreeBasedMethods);
    }
  }
  return result;
}

uint64_t TreeClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v42 = v2;
  uint64_t v3 = type metadata accessor for PersistentParametersForTreeBasedMethods(0);
  uint64_t v4 = *(int *)(v3 + 24);
  uint64_t v5 = *(void *)(a1 + v4);
  uint64_t v6 = *(void *)(a1 + v4 + 8);
  uint64_t v7 = *(void *)(a2 + v4);
  uint64_t v46 = a2;
  uint64_t v8 = *(void *)(a2 + v4 + 8);
  uint64_t v47 = v3;
  if (v5 == v7 && v6 == v8
    || (v45 = v6, v9 = _stringCompareWithSmolCheck(_:_:expecting:)(v5, v6, v7, v8, 0), uint64_t v3 = v47, (v9 & 1) != 0))
  {
    uint64_t v10 = *(void *)(a1 + *(int *)(v3 + 28));
    uint64_t v11 = v3;
    swift_bridgeObjectRetain(v10);
    uint64_t v44 = v10;
    uint64_t v12 = specialized Set.init<A>(_:)(v10);
    uint64_t v13 = *(void *)(v46 + *(int *)(v11 + 28));
    swift_bridgeObjectRetain(v13);
    uint64_t v43 = v13;
    uint64_t v14 = specialized Set.init<A>(_:)(v13);
    LOBYTE(v13) = v14;
    LOBYTE(v11) = specialized static Set.== infix(_:_:)(v12, v14);
    swift_bridgeObjectRelease(v12);
    swift_bridgeObjectRelease(v13);
    if (v11)
    {
      static BoostedTreeConfiguration.firstIncompatibility(_:_:)(*(int *)(v47 + 32) + a1, *(int *)(v47 + 32) + v46);
      uint64_t result = outlined init with take of (name: String, originalValue: String, newValue: String)?((uint64_t)v33, (uint64_t)&v34);
      uint64_t v16 = v35;
      if (!v35) {
        return result;
      }
      uint64_t v17 = v34;
      uint64_t v47 = v36;
      uint64_t v45 = v37;
      uint64_t v46 = v38;
      uint64_t v18 = v39;
      uint64_t v19 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v19, 0, 0);
      *(void *)uint64_t v20 = v17;
      uint64_t v24 = v47;
    }
    else
    {
      swift_bridgeObjectRetain(v44);
      uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
      uint64_t v26 = lazy protocol witness table accessor for type [String] and conformance [A]();
      uint64_t v47 = BidirectionalCollection<>.joined(separator:)(8236, 0xE200000000000000, v25, v26);
      uint64_t v45 = v27;
      swift_bridgeObjectRelease(v44);
      swift_bridgeObjectRetain(v43);
      uint64_t v28 = BidirectionalCollection<>.joined(separator:)(8236, 0xE200000000000000, v25, v26);
      uint64_t v30 = v29;
      swift_bridgeObjectRelease(v43);
      uint64_t v40 = v28;
      uint64_t v41 = v30;
      uint64_t v24 = v47;
      uint64_t v46 = String.init<A>(_:)(&v40, &type metadata for String, &protocol witness table for String, &protocol witness table for String);
      uint64_t v18 = v31;
      uint64_t v19 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v19, 0, 0);
      *(void *)uint64_t v20 = 0xD000000000000011;
      uint64_t v16 = "Classifier.swift" + 0x8000000000000000;
    }
  }
  else
  {
    uint64_t v40 = v7;
    uint64_t v41 = v8;
    swift_bridgeObjectRetain(v45);
    swift_bridgeObjectRetain(v8);
    uint64_t v46 = String.init<A>(_:)(&v40, &type metadata for String, &protocol witness table for String, &protocol witness table for String);
    uint64_t v24 = v5;
    uint64_t v18 = v32;
    uint64_t v19 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v19, 0, 0);
    *(void *)uint64_t v20 = 0x6320746567726154;
    uint64_t v16 = (char *)0xED00006E6D756C6FLL;
  }
  *(void *)(v20 + 8) = v16;
  *(void *)(v20 + 16) = v24;
  *(void *)(v20 + 24) = v45;
  *(void *)(v20 + 32) = v46;
  *(void *)(v20 + 40) = v18;
  *(unsigned char *)(v20 + 48) = 3;
  return swift_willThrow(&type metadata for MLCreateError, v19, v20, v21, v22, v23);
}

char specialized static Set.== infix(_:_:)(uint64_t a1, uint64_t a2)
{
  char result = 1;
  if (a1 != a2)
  {
    if (*(void *)(a1 + 16) == *(void *)(a2 + 16))
    {
      uint64_t v31 = a2;
      uint64_t v3 = 1 << *(unsigned char *)(a1 + 32);
      uint64_t v4 = ~(-1 << v3);
      if (v3 >= 64) {
        uint64_t v4 = -1;
      }
      unint64_t v5 = *(void *)(a1 + 56) & v4;
      int64_t v32 = (unint64_t)(v3 + 63) >> 6;
      int64_t v6 = 0;
      uint64_t v28 = a1;
      while (1)
      {
        if (v5)
        {
          _BitScanForward64(&v7, v5);
          uint64_t v30 = (v5 - 1) & v5;
          int64_t v29 = v6;
          unint64_t v8 = v7 | (v6 << 6);
        }
        else
        {
          BOOL v9 = __OFADD__(1, v6);
          int64_t v10 = v6 + 1;
          if (v9) {
            BUG();
          }
          if (v10 >= v32) {
            return 1;
          }
          unint64_t i = *(void *)(a1 + 8 * v10 + 56);
          if (i)
          {
            int64_t v12 = v10;
          }
          else
          {
            int64_t v12 = v10 + 1;
            if (v10 + 1 >= v32) {
              return 1;
            }
            unint64_t i = *(void *)(a1 + 8 * v10 + 64);
            if (!i)
            {
              int64_t v12 = v10 + 2;
              if (v10 + 2 >= v32) {
                return 1;
              }
              unint64_t i = *(void *)(a1 + 8 * v10 + 72);
              if (!i)
              {
                int64_t v12 = v10 + 3;
                if (v10 + 3 >= v32) {
                  return 1;
                }
                unint64_t i = *(void *)(a1 + 8 * v10 + 80);
                if (!i)
                {
                  int64_t v12 = v10 + 4;
                  if (v10 + 4 >= v32) {
                    return 1;
                  }
                  for (unint64_t i = *(void *)(a1 + 8 * v10 + 88); !i; unint64_t i = *(void *)(a1 + 8 * v12 + 56))
                  {
                    BOOL v9 = __OFADD__(1, v12++);
                    if (v9) {
                      BUG();
                    }
                    if (v12 >= v32) {
                      return 1;
                    }
                  }
                }
              }
            }
          }
          _BitScanForward64(&v13, i);
          uint64_t v30 = i & (i - 1);
          unint64_t v8 = v13 + (v12 << 6);
          int64_t v29 = v12;
        }
        uint64_t v14 = *(void *)(a1 + 48);
        uint64_t v15 = 16 * v8;
        uint64_t v16 = *(void *)(v14 + v15);
        uint64_t v17 = *(void *)(v14 + v15 + 8);
        uint64_t v18 = v31;
        Hasher.init(_seed:)(*(void *)(v31 + 40));
        swift_bridgeObjectRetain(v17);
        String.hash(into:)(v27, v16);
        Swift::Int v19 = Hasher._finalize()();
        uint64_t v20 = ~(-1 << *(unsigned char *)(v18 + 32));
        unint64_t v21 = v20 & v19;
        uint64_t v22 = *(void *)(v18 + 8 * ((v20 & (unint64_t)v19) >> 6) + 56);
        if (!_bittest64(&v22, v21))
        {
LABEL_33:
          swift_bridgeObjectRelease(v17);
          return 0;
        }
        uint64_t v23 = *(void *)(v18 + 48);
        while (1)
        {
          uint64_t v24 = *(void *)(v23 + 16 * v21);
          uint64_t v25 = *(void *)(v23 + 16 * v21 + 8);
          if (v24 == v16 && v25 == v17) {
            break;
          }
          if (_stringCompareWithSmolCheck(_:_:expecting:)(v24, v25, v16, v17, 0)) {
            break;
          }
          unint64_t v21 = v20 & (v21 + 1);
          uint64_t v26 = *(void *)(v31 + 8 * (v21 >> 6) + 56);
          if (!_bittest64(&v26, v21)) {
            goto LABEL_33;
          }
        }
        swift_bridgeObjectRelease(v17);
        a1 = v28;
        int64_t v6 = v29;
        unint64_t v5 = v30;
      }
    }
    return 0;
  }
  return result;
}

uint64_t TreeClassifierTrainingSessionDelegate.deinit()
{
  outlined destroy of MLActivityClassifier.ModelParameters(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for PersistentParametersForTreeBasedMethods?);
  uint64_t v1 = v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingData;
  uint64_t v2 = type metadata accessor for DataFrame(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(v1, v2);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationData, &demangling cache variable for type metadata for DataFrame?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_classifier, &demangling cache variable for type metadata for AnyTreeClassifier?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_model, &demangling cache variable for type metadata for AnyTreeClassifierModel?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_trainingMetrics, &demangling cache variable for type metadata for AnyClassificationMetrics?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML37TreeClassifierTrainingSessionDelegate_validationMetrics, &demangling cache variable for type metadata for AnyClassificationMetrics?);
  return v0;
}

uint64_t TreeClassifierTrainingSessionDelegate.__deallocating_deinit()
{
  TreeClassifierTrainingSessionDelegate.deinit();
  return swift_deallocClassInstance(v0, *(unsigned int *)(*(void *)v0 + 48), *(unsigned __int16 *)(*(void *)v0 + 52));
}

uint64_t ObjC metadata update function for TreeClassifierTrainingSessionDelegate()
{
  return type metadata accessor for TreeClassifierTrainingSessionDelegate(0);
}

uint64_t type metadata accessor for TreeClassifierTrainingSessionDelegate(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for TreeClassifierTrainingSessionDelegate;
  if (!type metadata singleton initialization cache for TreeClassifierTrainingSessionDelegate) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for TreeClassifierTrainingSessionDelegate);
  }
  return result;
}

uint64_t type metadata completion function for TreeClassifierTrainingSessionDelegate(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLTrainingSessionParameters(319);
  if (v2 <= 0x3F)
  {
    v9[0] = *(void *)(result - 8) + 64;
    uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for PersistentParametersForTreeBasedMethods?, type metadata accessor for PersistentParametersForTreeBasedMethods);
    if (v3 <= 0x3F)
    {
      v9[1] = *(void *)(result - 8) + 64;
      uint64_t result = type metadata accessor for DataFrame(319);
      if (v4 <= 0x3F)
      {
        v9[2] = *(void *)(result - 8) + 64;
        uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for DataFrame?, (uint64_t (*)(uint64_t))&type metadata accessor for DataFrame);
        if (v5 <= 0x3F)
        {
          v9[3] = *(void *)(result - 8) + 64;
          uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for AnyTreeClassifier?, type metadata accessor for AnyTreeClassifier);
          if (v6 <= 0x3F)
          {
            void v9[4] = *(void *)(result - 8) + 64;
            uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for AnyTreeClassifierModel?, type metadata accessor for AnyTreeClassifierModel);
            if (v7 <= 0x3F)
            {
              double v9[5] = *(void *)(result - 8) + 64;
              uint64_t result = type metadata accessor for MLSoundClassifier.PersistentParameters?(319, &lazy cache variable for type metadata for AnyClassificationMetrics?, type metadata accessor for AnyClassificationMetrics);
              if (v8 <= 0x3F)
              {
                uint64_t v10 = *(void *)(result - 8) + 64;
                uint64_t v11 = v10;
                uint64_t result = swift_updateClassMetadata2(a1, 256, 8, v9, a1 + 80);
                if (!result) {
                  return 0;
                }
              }
            }
          }
        }
      }
    }
  }
  return result;
}

void protocol witness for TrainingSessionDelegate.setUp() in conformance TreeClassifierTrainingSessionDelegate()
{
}

void protocol witness for TrainingSessionDelegate.resume(from:) in conformance TreeClassifierTrainingSessionDelegate(Swift::OpaquePointer a1)
{
}

unint64_t protocol witness for TrainingSessionDelegate.itemCount(phase:) in conformance TreeClassifierTrainingSessionDelegate(CreateML::MLPhase a1)
{
  return (unint64_t)TreeClassifierTrainingSessionDelegate.itemCount(phase:)(a1);
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance TreeClassifierTrainingSessionDelegate(uint64_t a1)
{
  unint64_t v2 = (void *)swift_task_alloc(dword_3A8404);
  *(void *)(v1 + 16) = v2;
  *unint64_t v2 = v1;
  v2[1] = protocol witness for TrainingSessionDelegate.train(from:) in conformance SoundClassifierTrainingSessionDelegate;
  return TreeClassifierTrainingSessionDelegate.train(from:)(a1);
}

uint64_t protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance TreeClassifierTrainingSessionDelegate()
{
  uint64_t v1 = (void *)swift_task_alloc(dword_3A83F4);
  *(void *)(v0 + 16) = v1;
  *uint64_t v1 = v0;
  v1[1] = protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance SoundClassifierTrainingSessionDelegate;
  return TreeClassifierTrainingSessionDelegate.evaluate(from:)();
}

char protocol witness for TrainingSessionDelegate.saveCheckpoint(to:phase:iteration:) in conformance TreeClassifierTrainingSessionDelegate(uint64_t a1, unsigned __int8 *a2)
{
  return TreeClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)(a1, a2);
}

uint64_t protocol witness for TrainingSessionCodable.save(to:) in conformance TreeClassifierTrainingSessionDelegate(uint64_t a1)
{
  return TreeClassifierTrainingSessionDelegate.save(to:)(a1);
}

NSURL *protocol witness for TrainingSessionCodable.restore(from:phase:) in conformance TreeClassifierTrainingSessionDelegate(uint64_t a1)
{
  return TreeClassifierTrainingSessionDelegate.restore(from:phase:)(a1);
}

uint64_t lazy protocol witness table accessor for type AnyTreeClassifier and conformance AnyTreeClassifier()
{
  uint64_t result = lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier;
  if (!lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier)
  {
    uint64_t v1 = type metadata accessor for AnyTreeClassifier(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for AnyTreeClassifier, v1);
    lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier = result;
  }
  return result;
}

{
  uint64_t result;
  uint64_t v1;

  uint64_t result = lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier;
  if (!lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier)
  {
    uint64_t v1 = type metadata accessor for AnyTreeClassifier(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for AnyTreeClassifier, v1);
    lazy protocol witness table cache variable for type AnyTreeClassifier and conformance AnyTreeClassifier = result;
  }
  return result;
}

void partial apply for closure #1 in TreeClassifierTrainingSessionDelegate.train(from:)()
{
}

uint64_t outlined init with copy of PersistentParametersForTreeBasedMethods(uint64_t a1, uint64_t a2, uint64_t (*a3)(void))
{
  uint64_t v3 = a3(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v3 - 8) + 16))(a2, a1, v3);
  return a2;
}

uint64_t CMLModel.initialize(options:)(uint64_t a1)
{
  uint64_t v11 = v2;
  uint64_t empty = tc_v1_parameters_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v4 = empty;
  uint64_t v5 = type metadata accessor for CMLParameters();
  uint64_t inited = swift_initStackObject(v5, v10);
  *(void *)(inited + 16) = v4;
  type metadata accessor for CMLFeatureValue();
  uint64_t v12 = v4;
  swift_retain();
  uint64_t v7 = CMLFeatureValue.__allocating_init(_:)(a1);
  if (v1) {
    return swift_release();
  }
  uint64_t v8 = v7;
  CMLParameters.add(key:featureValue:)(33, v7);
  uint64_t v13 = v8;
  CMLModel.callFunction(name:arguments:)(14, inited);
  swift_release();
  swift_release();
  swift_setDeallocating(inited);
  return tc_v1_release(v12);
}

uint64_t CMLModel.addMetadata(_:)(uint64_t a1)
{
  uint64_t v10 = v2;
  uint64_t empty = tc_v1_parameters_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v4 = empty;
  uint64_t v5 = type metadata accessor for CMLParameters();
  uint64_t inited = swift_initStackObject(v5, v9);
  *(void *)(inited + 16) = v4;
  type metadata accessor for CMLFeatureValue();
  uint64_t v11 = v4;
  swift_retain();
  uint64_t v7 = CMLFeatureValue.__allocating_init(_:)(a1);
  if (v1) {
    return swift_release();
  }
  CMLParameters.add(key:featureValue:)(32, v7);
  swift_release();
  CMLModel.callFunction(name:arguments:)(7, inited);
  swift_release();
  swift_setDeallocating(inited);
  return tc_v1_release(v11);
}

uint64_t CMLModel.listFields()()
{
  uint64_t empty = tc_v1_parameters_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v2 = empty;
  uint64_t v3 = type metadata accessor for CMLParameters();
  uint64_t inited = swift_initStackObject(v3, v7);
  *(void *)(inited + 16) = v2;
  CMLModel.callFunction(name:arguments:)(15, inited);
  if (v0) {
    return swift_release();
  }
  uint64_t v6 = CMLVariant.featureValue()();
  swift_release();
  swift_setDeallocating(inited);
  tc_v1_release(v2);
  return v6;
}

uint64_t CMLModel.getValue(field:)(uint64_t a1, uint64_t a2)
{
  uint64_t v13 = v2;
  uint64_t v14 = v3;
  uint64_t empty = tc_v1_parameters_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v5 = empty;
  uint64_t v6 = type metadata accessor for CMLParameters();
  uint64_t inited = swift_initStackObject(v6, v12);
  uint64_t v15 = v5;
  *(void *)(inited + 16) = v5;
  type metadata accessor for CMLFeatureValue();
  swift_bridgeObjectRetain(a2);
  uint64_t v8 = v13;
  uint64_t v9 = CMLFeatureValue.__allocating_init(_:)(a1, a2);
  if (v8)
  {
    swift_unexpectedError(v8, "CreateML/MLDataValueConvertible.swift", 37, 1);
    BUG();
  }
  CMLParameters.add(key:featureValue:)(35, v9);
  swift_release();
  uint64_t v11 = CMLModel.callFunction(name:arguments:)(16, inited);
  swift_setDeallocating(inited);
  tc_v1_release(v15);
  return v11;
}

uint64_t CMLModel.resume(training:validation:)(uint64_t a1, uint64_t a2)
{
  uint64_t v11 = v3;
  uint64_t v12 = a2;
  uint64_t empty = tc_v1_parameters_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v5 = empty;
  uint64_t v6 = type metadata accessor for CMLParameters();
  uint64_t inited = swift_initStackObject(v6, v10);
  *(void *)(inited + 16) = v5;
  CMLParameters.add(key:table:)(4, a1);
  if (v2) {
    return swift_release();
  }
  uint64_t v9 = v12;
  if (v12)
  {
    swift_retain();
    CMLParameters.add(key:table:)(3, v9);
    swift_release();
  }
  CMLModel.callFunction(name:arguments:)(3, inited);
  swift_release();
  swift_setDeallocating(inited);
  return tc_v1_release(v5);
}

uint64_t CMLModel.resume(data:_:)(uint64_t a1, uint64_t a2)
{
  uint64_t v11 = v3;
  uint64_t v10 = a2;
  uint64_t empty = tc_v1_parameters_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v5 = empty;
  uint64_t v6 = type metadata accessor for CMLParameters();
  uint64_t inited = swift_initStackObject(v6, v9);
  *(void *)(inited + 16) = v5;
  CMLParameters.add(key:table:)(4, a1);
  if (v2) {
    return swift_release();
  }
  CMLParameters.add(key:table:)(3, v10);
  CMLModel.callFunction(name:arguments:)(3, inited);
  swift_release();
  swift_setDeallocating(inited);
  return tc_v1_release(v5);
}

uint64_t CMLModel.evaluate(table:)(uint64_t *a1)
{
  uint64_t v17 = v1;
  uint64_t v18 = v2;
  uint64_t v4 = *a1;
  LOBYTE(v3) = *((unsigned char *)a1 + 8);
  uint64_t empty = tc_v1_parameters_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v6 = empty;
  uint64_t v7 = type metadata accessor for CMLParameters();
  uint64_t inited = swift_initStackObject(v7, v16);
  *(void *)(inited + 16) = v6;
  if (v3)
  {
    swift_errorRetain(v4);
    swift_willThrow(v4, v16, v9, v10, v11, v12);
LABEL_7:
    swift_release();
    return v3;
  }
  uint64_t v19 = v6;
  uint64_t v3 = *(void *)(v4 + 16);
  swift_retain();
  uint64_t v13 = v17;
  CMLParameters.add(key:table:)(4, v3);
  if (v13)
  {
    swift_release();
    goto LABEL_7;
  }
  swift_release();
  type metadata accessor for CMLFeatureValue();
  uint64_t v14 = CMLFeatureValue.__allocating_init(_:)(0x74726F706572, 0xE600000000000000);
  CMLParameters.add(key:featureValue:)(29, v14);
  swift_release();
  uint64_t v3 = CMLModel.callFunction(name:arguments:)(13, inited);
  swift_setDeallocating(inited);
  tc_v1_release(v19);
  return v3;
}

uint64_t CMLModel.save(to:)()
{
  uint64_t v15 = v1;
  uint64_t empty = tc_v1_parameters_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v3 = empty;
  uint64_t v4 = type metadata accessor for CMLParameters();
  uint64_t inited = swift_initStackObject(v4, v13);
  uint64_t v16 = v3;
  uint64_t v14 = inited;
  *(void *)(inited + 16) = v3;
  uint64_t v6 = URL.path.getter(v4);
  uint64_t v8 = v7;
  type metadata accessor for CMLFeatureValue();
  swift_bridgeObjectRetain(v8);
  uint64_t v9 = CMLFeatureValue.__allocating_init(_:)(v6, v8);
  if (v0)
  {
    swift_unexpectedError(v0, "CreateML/MLDataValueConvertible.swift", 37, 1, 170);
    BUG();
  }
  uint64_t v10 = v9;
  swift_bridgeObjectRelease(v8);
  uint64_t v11 = v14;
  CMLParameters.add(key:featureValue:)(8, v10);
  swift_release();
  CMLModel.callFunction(name:arguments:)(6, v11);
  swift_release();
  swift_setDeallocating(v11);
  return tc_v1_release(v16);
}

uint64_t CMLModel.export(to:)(uint64_t a1)
{
  uint64_t v33 = v1;
  uint64_t v37 = a1;
  uint64_t v31 = v2;
  uint64_t v32 = *v2;
  int64_t v3 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v6 = type metadata accessor for URL(0);
  uint64_t v7 = *(void *)(v6 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  char v35 = v30;
  uint64_t empty = tc_v1_parameters_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v12 = empty;
  uint64_t v13 = type metadata accessor for CMLParameters();
  uint64_t inited = swift_initStackObject(v13, v30);
  *(void *)(inited + 16) = v12;
  outlined init with copy of URL?(v37, (uint64_t)v30);
  if (__swift_getEnumTagSinglePayload((uint64_t)v30, 1, v6) == 1)
  {
    outlined destroy of URL?((uint64_t)v30);
    type metadata accessor for CMLFeatureValue();
    uint64_t v14 = v33;
    uint64_t v15 = CMLFeatureValue.__allocating_init(_:)(0, 0xE000000000000000);
    if (!v14)
    {
      uint64_t v16 = inited;
      CMLParameters.add(key:featureValue:)(27, v15);
      goto LABEL_7;
    }
    uint64_t v29 = v14;
LABEL_13:
    swift_unexpectedError(v29, "CreateML/MLDataValueConvertible.swift", 37, 1, 170);
    BUG();
  }
  uint64_t v17 = v35;
  uint64_t v34 = v6;
  uint64_t v37 = v7;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v7 + 32))(v35, v30, v6);
  uint64_t v18 = URL.path.getter(v17);
  uint64_t v20 = v19;
  type metadata accessor for CMLFeatureValue();
  swift_bridgeObjectRetain(v20);
  uint64_t v21 = v33;
  uint64_t v22 = CMLFeatureValue.__allocating_init(_:)(v18, v20);
  if (v21)
  {
    uint64_t v29 = v21;
    goto LABEL_13;
  }
  uint64_t v23 = v22;
  swift_bridgeObjectRelease(v20);
  uint64_t v24 = inited;
  CMLParameters.add(key:featureValue:)(27, v23);
  (*(void (**)(unsigned char *, uint64_t))(v37 + 8))(v35, v34);
  uint64_t v16 = v24;
LABEL_7:
  swift_release();
  uint64_t v25 = CMLModel.callFunction(name:arguments:)(8, v16);
  uint64_t v26 = specialized handling<A, B>(_:_:)(*(void *)(v25 + 16));
  if (!v26) {
    BUG();
  }
  swift_release();
  uint64_t v27 = inited;
  swift_setDeallocating(inited);
  tc_v1_release(*(void *)(v27 + 16));
  uint64_t result = swift_allocObject(v32, 24, 7);
  *(void *)(result + 16) = v26;
  return result;
}

uint64_t CMLModel.compile()()
{
  v1[16] = v0;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  v1[17] = swift_task_alloc((*(void *)(*(void *)(v2 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v3 = type metadata accessor for UUID(0);
  v1[18] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v1[19] = v4;
  v1[20] = swift_task_alloc((*(void *)(v4 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for URL(0);
  v1[21] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v1[22] = v6;
  unint64_t v7 = (*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v1[23] = swift_task_alloc(v7);
  v1[24] = swift_task_alloc(v7);
  v1[25] = swift_task_alloc(v7);
  return swift_task_switch(CMLModel.compile(), 0, 0);
}

{
  uint64_t v0;
  void *v1;
  id v2;
  id v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  void (*v10)(uint64_t, uint64_t);
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  unint64_t v14;
  uint64_t v15;
  unint64_t v16;
  id v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  id v23;
  id v24;
  id v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  void *v32;

  uint64_t v1 = objc_opt_self(NSFileManager);
  uint64_t v2 = [v1 defaultManager];
  uint64_t v3 = v2;
  *(void *)(v0 + 208) = v3;
  NSFileManager.createTemporaryModelDirectory()();
  if (v4)
  {

    uint64_t v18 = *(void *)(v0 + 192);
    uint64_t v19 = *(void *)(v0 + 184);
    uint64_t v20 = *(void *)(v0 + 136);
    uint64_t v21 = *(void *)(v0 + 160);
    swift_task_dealloc(*(void *)(v0 + 200));
    swift_task_dealloc(v18);
    swift_task_dealloc(v19);
    swift_task_dealloc(v21);
    swift_task_dealloc(v20);
    return (*(uint64_t (**)(void))(v0 + 8))();
  }
  else
  {
    uint64_t v28 = *(void *)(v0 + 192);
    uint64_t v5 = *(void *)(v0 + 184);
    uint64_t v27 = *(void *)(v0 + 176);
    uint64_t v31 = *(void *)(v0 + 168);
    uint64_t v6 = *(void *)(v0 + 160);
    uint64_t v29 = *(void *)(v0 + 152);
    uint64_t v30 = *(void *)(v0 + 144);
    uint64_t v26 = *(void *)(v0 + 136);
    NSFileManager.temporaryModelDirectory.getter();
    UUID.init()();
    unint64_t v7 = UUID.uuidString.getter();
    uint64_t v9 = v8;
    (*(void (**)(uint64_t, uint64_t))(v29 + 8))(v6, v30);
    URL.appendingPathComponent(_:)(v7, v9);
    swift_bridgeObjectRelease(v9);
    URL.appendingPathExtension(_:)(0x6C65646F6D6C6DLL, 0xE700000000000000);
    uint64_t v10 = *(void (**)(uint64_t, uint64_t))(v27 + 8);
    *(void *)(v0 + 216) = v10;
    v10(v5, v31);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(v27 + 16))(v26, v28, v31);
    __swift_storeEnumTagSinglePayload(v26, 0, 1, v31);
    CMLModel.export(to:)(v26);
    uint64_t v11 = *(void *)(v0 + 136);
    uint64_t v12 = *(void *)(v0 + 192);
    swift_release();
    outlined destroy of URL?(v11);
    uint64_t v13 = Data.init(contentsOf:options:)(v12, 0);
    *(void *)(v0 + 224) = v13;
    *(void *)(v0 + 232) = v14;
    uint64_t v15 = v13;
    uint64_t v16 = v14;
    type metadata accessor for MLModelAsset();
    outlined copy of Data._Representation(v15, v16);
    uint64_t v17 = @nonobjc MLModelAsset.__allocating_init(specification:)(v15, v16);
    *(void *)(v0 + 240) = v17;
    uint64_t v23 = v17;
    uint64_t v32 = objc_opt_self(MLModel);
    uint64_t v24 = objc_allocWithZone((Class)MLModelConfiguration);
    uint64_t v25 = [v24 init];
    *(void *)(v0 + 248) = v25;
    *(void *)(v0 + 16) = v0;
    *(void *)(v0 + 56) = v0 + 120;
    *(void *)(v0 + 24) = CMLModel.compile();
    *(void *)(v0 + 112) = swift_continuation_init(v0 + 16, 1);
    *(void *)(v0 + 80) = _NSConcreteStackBlock;
    *(void *)(v0 + 88) = 0x40000000;
    *(void *)(v0 + 96) = @objc completion handler block implementation for @escaping @callee_unowned @convention(block) (@unowned MLModel?, @unowned NSError?) -> () with result type MLModel;
    *(void *)(v0 + 104) = &block_descriptor_5;
    [v32 loadModelAsset:v23 configuration:v25 completionHandler:v0 + 80];
    return swift_continuation_await(v0 + 16);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t (*v2)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t);

  uint64_t v1 = *(void *)(*(void *)v0 + 48);
  *(void *)(*(void *)v0 + 256) = v1;
  if (v1) {
    uint64_t v2 = CMLModel.compile();
  }
  else {
    uint64_t v2 = (uint64_t (*)(uint64_t, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))CMLModel.compile();
  }
  return swift_task_switch(v2, 0, 0);
}

{
  uint64_t v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  void (*v9)(uint64_t, uint64_t);
  void *v10;
  void *v11;
  uint64_t v12;

  uint64_t v10 = *(void **)(v0 + 248);
  uint64_t v11 = *(void **)(v0 + 240);
  uint64_t v9 = *(void (**)(uint64_t, uint64_t))(v0 + 216);
  uint64_t v1 = *(void **)(v0 + 208);
  int64_t v8 = *(void *)(v0 + 200);
  uint64_t v2 = *(void *)(v0 + 192);
  unint64_t v7 = *(void *)(v0 + 184);
  uint64_t v3 = *(void *)(v0 + 168);
  uint64_t v5 = *(void *)(v0 + 136);
  uint64_t v6 = *(void *)(v0 + 160);
  outlined consume of Data._Representation(*(void *)(v0 + 224), *(void *)(v0 + 232));

  uint64_t v12 = *(void *)(v0 + 120);
  $defer #1 () in CMLModel.compile()(v1);

  v9(v2, v3);
  v9(v8, v3);
  swift_task_dealloc(v8);
  swift_task_dealloc(v2);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  swift_task_dealloc(v5);
  return (*(uint64_t (**)(uint64_t))(v0 + 8))(v12);
}

uint64_t CMLModel.compile()(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v17 = *(void **)(v6 + 248);
  uint64_t v18 = *(void **)(v6 + 240);
  unint64_t v19 = *(void *)(v6 + 232);
  uint64_t v7 = *(void *)(v6 + 224);
  uint64_t v15 = *(void (**)(uint64_t, uint64_t))(v6 + 216);
  int64_t v8 = *(void **)(v6 + 208);
  uint64_t v20 = *(void *)(v6 + 200);
  uint64_t v16 = *(void *)(v6 + 168);
  uint64_t v9 = *(void *)(v6 + 192);
  swift_willThrow(a1, a2, a3, a4, a5, a6);
  outlined consume of Data._Representation(v7, v19);

  $defer #1 () in CMLModel.compile()(v8);
  v15(v9, v16);
  v15(v20, v16);
  uint64_t v10 = *(void *)(v6 + 192);
  uint64_t v11 = *(void *)(v6 + 184);
  uint64_t v12 = *(void *)(v6 + 136);
  uint64_t v13 = *(void *)(v6 + 160);
  swift_task_dealloc(*(void *)(v6 + 200));
  swift_task_dealloc(v10);
  swift_task_dealloc(v11);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  return (*(uint64_t (**)(void))(v6 + 8))();
}

uint64_t outlined destroy of URL?(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

NSURL *$defer #1 () in CMLModel.compile()(id a1)
{
  URL._bridgeToObjectiveC()(__stack_chk_guard);
  uint64_t v2 = v1;
  id v8 = 0;
  unsigned __int8 v3 = [a1 removeItemAtURL:v1 error:&v8];

  id v4 = v8;
  if (v3) {
    return (NSURL *)v8;
  }
  id v6 = v8;
  uint64_t v7 = _convertNSErrorToError(_:)(v4);

  swift_willThrow();
  swift_errorRelease(v7);
  return __stack_chk_guard;
}

uint64_t type metadata accessor for MLModelAsset()
{
  uint64_t result = lazy cache variable for type metadata for MLModelAsset;
  if (!lazy cache variable for type metadata for MLModelAsset)
  {
    uint64_t v1 = objc_opt_self(MLModelAsset);
    uint64_t result = swift_getObjCClassMetadata(v1);
    lazy cache variable for type metadata for MLModelAsset = result;
  }
  return result;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SiSgs5NeverOTg5059_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSiSgR5XEfU_0K2ML0O6ColumnVySiGTf1cn_n(uint64_t a1, uint64_t a2, uint64_t a3, char a4, double a5)
{
  uint64_t v5 = a2 - a1;
  if (__OFSUB__(a2, a1)) {
    BUG();
  }
  if (a2 == a1)
  {
    outlined consume of Result<_DataTable, Error>(a3, a4 & 1);
    return _swiftEmptyArrayStorage;
  }
  else
  {
    uint64_t v6 = a1;
    int64_t v7 = 0;
    if (v5 > 0) {
      int64_t v7 = v5;
    }
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v7, 0);
    uint64_t v8 = a2;
    if (a2 < a1 || v5 < 0) {
      BUG();
    }
    uint64_t v9 = _swiftEmptyArrayStorage;
    char v10 = a4;
    do
    {
      if (v8 == v6) {
        BUG();
      }
      if (v10)
      {
        char v11 = 1;
        uint64_t v12 = 0;
      }
      else
      {
        outlined copy of Result<_DataTable, Error>(a3, 0);
        _UntypedColumn.valueAtIndex(index:)(v6, a5);
        outlined consume of Result<_DataTable, Error>(a3, 0);
        uint64_t v12 = v19;
        if (v21)
        {
          outlined consume of MLDataValue(v19, v20, v21);
          char v11 = 1;
          uint64_t v12 = 0;
          char v10 = a4;
          uint64_t v8 = a2;
        }
        else
        {
          char v10 = a4;
          uint64_t v8 = a2;
          char v11 = 0;
        }
      }
      uint64_t v23 = v9;
      unint64_t v13 = v9[2];
      unint64_t v14 = v9[3];
      int64_t v15 = v13 + 1;
      if (v14 >> 1 <= v13)
      {
        uint64_t v17 = v12;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v14 >= 2, v15, 1);
        int64_t v15 = v13 + 1;
        uint64_t v12 = v17;
        uint64_t v8 = a2;
        char v10 = a4;
        uint64_t v9 = v23;
      }
      v9[2] = v15;
      uint64_t v16 = 2 * v13;
      v9[v16 + 4] = v12;
      LOBYTE(v9[v16 + 5]) = v11;
      ++v6;
    }
    while (v8 != v6);
    outlined consume of Result<_DataTable, Error>(a3, v10 & 1);
  }
  return v9;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SdSgs5NeverOTg567_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSdSgSiXEfU0_0K2ML0O6ColumnVySdGTf1cn_n(uint64_t a1, uint64_t a2, uint64_t a3, char a4, double a5)
{
  uint64_t v5 = a2 - a1;
  if (__OFSUB__(a2, a1)) {
    BUG();
  }
  if (a2 == a1)
  {
    outlined consume of Result<_DataTable, Error>(a3, a4 & 1);
    return _swiftEmptyArrayStorage;
  }
  else
  {
    uint64_t v6 = a1;
    int64_t v7 = 0;
    if (v5 > 0) {
      int64_t v7 = v5;
    }
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v7, 0);
    uint64_t v8 = a2;
    if (a2 < a1 || v5 < 0) {
      BUG();
    }
    uint64_t v9 = _swiftEmptyArrayStorage;
    char v10 = a4;
    do
    {
      if (v8 == v6) {
        BUG();
      }
      if (v10)
      {
        char v11 = 1;
        uint64_t v12 = 0;
      }
      else
      {
        outlined copy of Result<_DataTable, Error>(a3, 0);
        _UntypedColumn.valueAtIndex(index:)(v6, a5);
        outlined consume of Result<_DataTable, Error>(a3, 0);
        uint64_t v12 = v19;
        if (v21 == 1)
        {
          char v10 = a4;
          uint64_t v8 = a2;
          char v11 = 0;
        }
        else
        {
          outlined consume of MLDataValue(v19, v20, v21);
          char v11 = 1;
          uint64_t v12 = 0;
          char v10 = a4;
          uint64_t v8 = a2;
        }
      }
      uint64_t v23 = v9;
      unint64_t v13 = v9[2];
      unint64_t v14 = v9[3];
      int64_t v15 = v13 + 1;
      if (v14 >> 1 <= v13)
      {
        uint64_t v17 = v12;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v14 >= 2, v15, 1);
        int64_t v15 = v13 + 1;
        uint64_t v12 = v17;
        uint64_t v8 = a2;
        char v10 = a4;
        uint64_t v9 = v23;
      }
      v9[2] = v15;
      uint64_t v16 = 2 * v13;
      v9[v16 + 4] = v12;
      LOBYTE(v9[v16 + 5]) = v11;
      ++v6;
    }
    while (v8 != v6);
    outlined consume of Result<_DataTable, Error>(a3, v10 & 1);
  }
  return v9;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SSSgs5NeverOTg567_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSSSgSiXEfU1_0K2ML0O6ColumnVySSGTf1cn_n(uint64_t a1, uint64_t a2, uint64_t a3, char a4, double a5)
{
  uint64_t v5 = a2 - a1;
  if (__OFSUB__(a2, a1)) {
    BUG();
  }
  if (a2 == a1)
  {
    outlined consume of Result<_DataTable, Error>(a3, a4 & 1);
    return _swiftEmptyArrayStorage;
  }
  else
  {
    uint64_t v6 = a1;
    int64_t v7 = 0;
    if (v5 > 0) {
      int64_t v7 = v5;
    }
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v7, 0);
    uint64_t v8 = a2;
    if (a2 < a1 || v5 < 0) {
      BUG();
    }
    uint64_t v9 = _swiftEmptyArrayStorage;
    char v10 = a4;
    do
    {
      if (v8 == v6) {
        BUG();
      }
      if (v10)
      {
        char v11 = 0;
        uint64_t v12 = 0;
      }
      else
      {
        outlined copy of Result<_DataTable, Error>(a3, 0);
        _UntypedColumn.valueAtIndex(index:)(v6, a5);
        outlined consume of Result<_DataTable, Error>(a3, 0);
        char v11 = v19;
        uint64_t v12 = v20;
        if (v21 != 2)
        {
          outlined consume of MLDataValue(v19, v20, v21);
          char v11 = 0;
          uint64_t v12 = 0;
        }
        char v10 = a4;
        uint64_t v8 = a2;
      }
      uint64_t v23 = v9;
      unint64_t v13 = v9[2];
      unint64_t v14 = v9[3];
      int64_t v15 = v13 + 1;
      if (v14 >> 1 <= v13)
      {
        uint64_t v17 = v12;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v14 >= 2, v15, 1);
        int64_t v15 = v13 + 1;
        uint64_t v12 = v17;
        uint64_t v8 = a2;
        char v10 = a4;
        uint64_t v9 = v23;
      }
      v9[2] = v15;
      uint64_t v16 = 2 * v13;
      v9[v16 + 4] = v11;
      v9[v16 + 5] = v12;
      ++v6;
    }
    while (v8 != v6);
    outlined consume of Result<_DataTable, Error>(a3, v10 & 1);
  }
  return v9;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_Say8CreateML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n(uint64_t a1, uint64_t a2, uint64_t a3, int a4, double a5)
{
  uint64_t v105 = a3;
  uint64_t v6 = a2 - a1;
  if (__OFSUB__(a2, a1)) {
    BUG();
  }
  uint64_t v121 = v5;
  if (a2 == a1)
  {
    outlined consume of Result<_DataTable, Error>(v105, a4 & 1);
    return _swiftEmptyArrayStorage;
  }
  else
  {
    uint64_t v110 = a1;
    uint64_t v109 = a2;
    int v119 = a4;
    uint64_t v106 = _swiftEmptyArrayStorage;
    int64_t v7 = 0;
    if (v6 > 0) {
      int64_t v7 = v6;
    }
    uint64_t v108 = v6;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v7, 0);
    uint64_t v8 = v108;
    if (v108 < 0) {
      BUG();
    }
    uint64_t v9 = v106;
    uint64_t v10 = 0;
    uint64_t v11 = v110;
    uint64_t v12 = v110;
    char v13 = v119;
    uint64_t v14 = v109;
    do
    {
      if (v10 == v8) {
        BUG();
      }
      if (v13)
      {
        int64_t v15 = 0;
      }
      else
      {
        uint64_t v107 = v10;
        uint64_t v101 = v9;
        uint64_t v16 = v105;
        uint64_t v17 = v12;
        outlined copy of Result<_DataTable, Error>(v105, 0);
        uint64_t v102 = v17;
        _UntypedColumn.valueAtIndex(index:)(v17, a5);
        outlined consume of Result<_DataTable, Error>(v16, 0);
        uint64_t v18 = v115;
        unint64_t v19 = v116;
        if ((_BYTE)v117 == 3)
        {
          outlined copy of MLDataValue(v115, v116, 3u);
          uint64_t v20 = CMLSequence.size.getter();
          if (CMLSequence.size.getter() < 0) {
            BUG();
          }
          uint64_t v21 = CMLSequence.size.getter();
          if (v20 < 0 || v21 < v20) {
            BUG();
          }
          if (v20)
          {
            uint64_t v22 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLDataValue>);
            uint64_t v23 = (void *)swift_allocObject(v22, 24 * v20 + 32, 7);
            uint64_t v99 = v20;
            uint64_t v24 = v23;
            long long v25 = (uint64_t)(_swift_stdlib_malloc_size(v23) - 32);
            v24[2] = v99;
            uint64_t v114 = v24;
            v24[3] = 2 * (v25 / 24);
            outlined copy of MLDataValue(v18, v19, 3u);
            if (!CMLSequence.size.getter())
            {
LABEL_76:
              outlined consume of MLDataValue(v18, v19, 3);
              BUG();
            }
            swift_retain();
            uint64_t v113 = v18;
            uint64_t v26 = v121;
            uint64_t v27 = CMLSequence.value(at:)(0);
            unsigned int v112 = v19;
            uint64_t v121 = v26;
            if (v26)
            {
LABEL_87:
              outlined consume of MLDataValue(v113, v112, 3);
              uint64_t v85 = "CreateML/SequenceType.swift";
              uint64_t v86 = 27;
              uint64_t v87 = 36;
              uint64_t v88 = v121;
              goto LABEL_88;
            }
            uint64_t v28 = v27;
            uint64_t v98 = v114 + 4;
            uint64_t v29 = 1;
            uint64_t v30 = 0;
            uint64_t v18 = v113;
            while (1)
            {
              outlined consume of MLDataValue(v18, v112, 3);
              char v31 = CMLFeatureValue.type.getter();
              uint64_t v96 = v29;
              uint64_t v95 = v30;
              switch(v31)
              {
                case 0:
                  uint64_t v32 = v121;
                  double v120 = COERCE_DOUBLE(specialized handling<A, B>(_:_:)(*(void *)(v28 + 16)));
                  uint64_t v121 = v32;
                  if (v32)
                  {
                    swift_errorRelease(v121);
                    BUG();
                  }
                  swift_release();
                  char object = 0;
                  char v34 = 0;
                  goto LABEL_49;
                case 1:
                  uint64_t v75 = v121;
                  specialized handling<A, B>(_:_:)(*(void *)(v28 + 16));
                  double v118 = a5;
                  uint64_t v121 = v75;
                  if (v75)
                  {
                    swift_errorRelease(v121);
                    BUG();
                  }
                  swift_release();
                  a5 = v118;
                  double v120 = v118;
                  char v34 = 1;
                  goto LABEL_48;
                case 2:
                  swift_retain();
                  Swift::String v67 = CMLFeatureValue.stringValue()();
                  double v120 = *(double *)&v67._countAndFlagsBits;
                  uint64_t v121 = v68;
                  if (v68)
                  {
                    swift_release();
                    swift_errorRelease(v121);
                    BUG();
                  }
                  char object = v67._object;
                  swift_release_n(v28, 2);
                  char v34 = 2;
                  goto LABEL_49;
                case 3:
                  uint64_t v69 = *(void *)(v28 + 16);
                  swift_retain();
                  uint64_t v70 = v121;
                  uint64_t v71 = specialized handling<A, B>(_:_:)(v69);
                  if (v70)
                  {
                    swift_release();
                    swift_errorRelease(v70);
                    BUG();
                  }
                  uint64_t v72 = v71;
                  uint64_t v121 = 0;
                  if (!v71) {
                    BUG();
                  }
                  uint64_t v73 = type metadata accessor for CMLSequence();
                  uint64_t v74 = swift_allocObject(v73, 25, 7);
                  *(void *)(v74 + 16) = v72;
                  double v120 = *(double *)&v74;
                  *(unsigned char *)(v74 + 24) = 1;
                  swift_release_n(v28, 2);
                  char v34 = 3;
                  goto LABEL_48;
                case 4:
                  uint64_t v35 = *(void *)(v28 + 16);
                  uint64_t v100 = v28;
                  swift_retain();
                  uint64_t v36 = v121;
                  uint64_t v37 = specialized handling<A, B>(_:_:)(v35);
                  if (v36)
                  {
                    swift_release();
                    swift_errorRelease(v36);
                    BUG();
                  }
                  uint64_t v38 = v37;
                  if (!v37) {
                    BUG();
                  }
                  uint64_t v39 = type metadata accessor for CMLDictionary();
                  uint64_t inited = swift_initStackObject(v39, v91);
                  *(void *)(inited + 16) = v38;
                  uint64_t v104 = _swiftEmptyDictionarySingleton;
                  swift_retain_n(inited, 3);
                  if (CMLDictionary.size.getter())
                  {
                    double v120 = COERCE_DOUBLE(_swiftEmptyDictionarySingleton);
                    uint64_t v41 = 0;
                    do
                    {
                      while (1)
                      {
                        double v118 = COERCE_DOUBLE(CMLDictionary.keyAndValue(at:)(v41));
                        uint64_t v111 = v42;
                        uint64_t v43 = v36;
                        if (v36)
                        {
                          uint64_t v85 = "CreateML/DictionaryType.swift";
                          uint64_t v86 = 29;
                          uint64_t v87 = 75;
                          goto LABEL_86;
                        }
                        swift_retain();
                        uint64_t v44 = specialized RandomAccessCollection<>.index(after:)(v41);
                        swift_release();
                        Swift::String v45 = CMLFeatureValue.stringValue()();
                        if (v46) {
                          break;
                        }
                        uint64_t v47 = v45._object;
                        uint64_t v97 = v44;
                        uint64_t v103 = inited;
                        uint64_t v121 = 0;
                        uint64_t v48 = (uint64_t)v111;
                        uint64_t countAndFlagsBits = (void *)v45._countAndFlagsBits;
                        swift_retain();
                        MLDataValue.init(_:)(v48, a5);
                        swift_release();
                        swift_release();
                        uint64_t v111 = v115;
                        double v118 = *(double *)&v116;
                        char v122 = v117;
                        uint64_t v115 = countAndFlagsBits;
                        uint64_t v116 = v47;
                        LOBYTE(v117) = 2;
                        unint64_t v50 = (unint64_t)countAndFlagsBits;
                        long long v51 = __PAIR128__((unint64_t)v47, (unint64_t)countAndFlagsBits);
                        unint64_t v52 = (unint64_t)v47;
                        double v53 = v120;
                        unint64_t v54 = specialized __RawDictionaryStorage.find<A>(_:)(v51, 2);
                        *(void *)&long long v51 = (v55 & 1) == 0;
                        BOOL v56 = __OFADD__(*(void *)(*(void *)&v53 + 16), (void)v51);
                        uint64_t v57 = *(void *)(*(void *)&v53 + 16) + v51;
                        if (v56) {
                          BUG();
                        }
                        char v58 = v55;
                        if (*(void *)(*(void *)&v53 + 24) < v57)
                        {
                          specialized _NativeDictionary._copyOrMoveAndResize(capacity:moveElements:)(v57, 1u);
                          unint64_t v54 = specialized __RawDictionaryStorage.find<A>(_:)(__PAIR128__(v52, v50), 2);
                          if ((v58 & 1) != (v59 & 1))
                          {
                            KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for MLDataValue);
                            BUG();
                          }
                        }
                        if (v58)
                        {
                          uint64_t v43 = swift_allocError(&type metadata for _MergeError, &protocol witness table for _MergeError, 0, 0);
                          swift_willThrow();
                          uint64_t v94 = v43;
                          swift_errorRetain(v43);
                          uint64_t v89 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
                          if (swift_dynamicCast(&demangling cache variable for type metadata for Error, &v94, v89, &type metadata for _MergeError, 0))
                          {
                            uint64_t v92 = 0;
                            unint64_t v93 = 0xE000000000000000;
                            _StringGuts.grow(_:)(30);
                            v90._char object = "Swift/NativeDictionary.swift" + 0x8000000000000000;
                            v90._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
                            String.append(_:)(v90);
                            _print_unlocked<A, B>(_:_:)(&v115, &v92, &type metadata for MLDataValue, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
                            v90._uint64_t countAndFlagsBits = 39;
                            v90._char object = (void *)0xE100000000000000;
                            String.append(_:)(v90);
                            _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v92, v93, "Swift/NativeDictionary.swift", 28, 2, 783, 0);
                            BUG();
                          }
                          swift_release();
                          outlined consume of MLDataValue(v111, *(void **)&v118, v122);
                          outlined consume of MLDataValue(v115, v116, v117);
                          swift_release();
                          swift_errorRelease(v94);
                          uint64_t v85 = "Swift/Dictionary.swift";
                          uint64_t v86 = 22;
                          uint64_t v87 = 489;
LABEL_86:
                          uint64_t v88 = v43;
LABEL_88:
                          swift_unexpectedError(v88, v85, v86, 1, v87);
                          BUG();
                        }
                        uint64_t v60 = v104;
                        v104[(v54 >> 6) + 8] |= 1 << v54;
                        uint64_t v61 = v60[6];
                        uint64_t v62 = 24 * v54;
                        *(void *)(v61 + v62) = v50;
                        *(void *)(v61 + v62 + 8) = v52;
                        *(unsigned char *)(v61 + v62 + 16) = 2;
                        uint64_t v63 = v60[7];
                        *(void *)(v63 + v62) = v111;
                        *(double *)(v63 + v62 + 8) = v118;
                        *(unsigned char *)(v63 + v62 + 16) = v122;
                        uint64_t v64 = v60[2];
                        BOOL v56 = __OFADD__(1, v64);
                        uint64_t v65 = v64 + 1;
                        if (v56) {
                          BUG();
                        }
                        double v120 = *(double *)&v60;
                        v60[2] = v65;
                        uint64_t inited = v103;
                        uint64_t v66 = CMLDictionary.size.getter();
                        uint64_t v41 = v97;
                        uint64_t v36 = v121;
                        if (v97 == v66) {
                          goto LABEL_47;
                        }
                      }
                      swift_errorRelease(v46);
                      swift_release();
                      swift_release();
                      uint64_t v36 = 0;
                      uint64_t v41 = v44;
                    }
                    while (v44 != CMLDictionary.size.getter());
                    uint64_t v36 = 0;
                  }
                  else
                  {
                    double v120 = COERCE_DOUBLE(_swiftEmptyDictionarySingleton);
                  }
LABEL_47:
                  uint64_t v121 = v36;
                  swift_release();
                  swift_release_n(inited, 4);
                  swift_release();
                  char v34 = 4;
LABEL_48:
                  char object = 0;
LABEL_49:
                  uint64_t v76 = v113;
                  swift_retain();
                  uint64_t v77 = CMLSequence.size.getter();
                  outlined consume of MLDataValue(v76, v112, 3);
                  if (v95 >= v77) {
                    BUG();
                  }
                  uint64_t v78 = v98;
                  *(double *)uint64_t v98 = v120;
                  v78[1] = object;
                  *((unsigned char *)v78 + 16) = v34;
                  uint64_t v30 = v96;
                  if (v96 == v99)
                  {
                    uint64_t v18 = v113;
                    unint64_t v19 = v112;
                    outlined consume of MLDataValue(v113, v112, 3);
                    goto LABEL_57;
                  }
                  uint64_t v18 = v113;
                  uint64_t v79 = CMLSequence.size.getter();
                  unint64_t v19 = v112;
                  if (v30 == v79) {
                    goto LABEL_76;
                  }
                  v98 += 3;
                  uint64_t v29 = v30 + 1;
                  swift_retain();
                  uint64_t v80 = v121;
                  uint64_t v28 = CMLSequence.value(at:)(v30);
                  uint64_t v121 = v80;
                  if (v80) {
                    goto LABEL_87;
                  }
                  break;
                case 5:
                  swift_release();
                  char v34 = 6;
                  double v120 = 0.0;
                  goto LABEL_48;
                case 6:
                  swift_retain();
                  MLDataValue.MultiArrayType.init(from:)(v28);
                  double v120 = *(double *)&v115;
                  if (!v115) {
                    BUG();
                  }
                  swift_release();
                  char v34 = 5;
                  goto LABEL_48;
              }
            }
          }
          uint64_t v114 = _swiftEmptyArrayStorage;
LABEL_57:
          outlined consume of MLDataValue(v18, v19, 3);
          outlined consume of MLDataValue(v18, v19, 3);
          char v13 = v119;
          uint64_t v14 = v109;
          uint64_t v11 = v110;
          uint64_t v8 = v108;
          uint64_t v9 = v101;
          uint64_t v10 = v107;
          uint64_t v12 = v102;
          int64_t v15 = v114;
        }
        else
        {
          outlined consume of MLDataValue(v115, v116, v117);
          int64_t v15 = 0;
          char v13 = v119;
          uint64_t v14 = v109;
          uint64_t v11 = v110;
          uint64_t v8 = v108;
          uint64_t v9 = v101;
          uint64_t v10 = v107;
          uint64_t v12 = v102;
        }
      }
      uint64_t v106 = v9;
      unint64_t v81 = v9[2];
      unint64_t v82 = v9[3];
      if (v82 >> 1 <= v81)
      {
        uint64_t v107 = v10;
        uint64_t v83 = v12;
        uint64_t v114 = v15;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v82 >= 2, v81 + 1, 1);
        int64_t v15 = v114;
        uint64_t v12 = v83;
        uint64_t v10 = v107;
        uint64_t v8 = v108;
        uint64_t v11 = v110;
        uint64_t v14 = v109;
        char v13 = v119;
        uint64_t v9 = v106;
      }
      v9[2] = v81 + 1;
      v9[v81 + 4] = v15;
      if (v14 < v11) {
        BUG();
      }
      if (v12 >= v14) {
        BUG();
      }
      ++v10;
      ++v12;
    }
    while (v10 != v8);
    outlined consume of Result<_DataTable, Error>(v105, v13 & 1);
  }
  return v9;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_Say8CreateML11MLDataValueO3key_AI5valuetGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G26O3key_AH5valuetGSgSiXEfU3_AG0F6ColumnVyAI14DictionaryTypeVGTf1cn_n(uint64_t a1, uint64_t a2, uint64_t a3, int a4, double a5)
{
  uint64_t v34 = a3;
  uint64_t v5 = a2 - a1;
  if (__OFSUB__(a2, a1)) {
    BUG();
  }
  if (a2 == a1)
  {
    outlined consume of Result<_DataTable, Error>(v34, a4 & 1);
    return _swiftEmptyArrayStorage;
  }
  else
  {
    uint64_t v6 = a1;
    int v39 = a4;
    uint64_t v37 = _swiftEmptyArrayStorage;
    uint64_t v38 = a2;
    int64_t v7 = 0;
    if (v5 > 0) {
      int64_t v7 = v5;
    }
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v7, 0);
    uint64_t v8 = v38;
    if (v38 < a1 || v5 < 0) {
      BUG();
    }
    uint64_t v9 = v37;
    char v10 = v39;
    do
    {
      if (v8 == v6) {
        BUG();
      }
      if (v10)
      {
        uint64_t v11 = 0;
      }
      else
      {
        char v31 = v9;
        uint64_t v12 = v34;
        outlined copy of Result<_DataTable, Error>(v34, 0);
        _UntypedColumn.valueAtIndex(index:)(v6, a5);
        outlined consume of Result<_DataTable, Error>(v12, 0);
        char v13 = v27;
        uint64_t v14 = v28;
        if ((_BYTE)v29 == 4)
        {
          uint64_t v15 = v27[2];
          if (v15)
          {
            uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(key: MLDataValue, value: MLDataValue)>);
            uint64_t v17 = (void *)swift_allocObject(v16, 48 * v15 + 32, 7);
            uint64_t v32 = v15;
            uint64_t v18 = v17;
            long long v19 = (uint64_t)(_swift_stdlib_malloc_size(v17) - 32);
            v18[2] = v32;
            v18[3] = 2 * (v19 / 48);
            uint64_t v35 = v18;
            uint64_t v36 = v18 + 4;
            uint64_t v20 = v14;
            outlined copy of MLDataValue(v13, v14, 4u);
            swift_bridgeObjectRetain(v13);
            uint64_t v21 = v32;
            uint64_t v36 = (void *)specialized Sequence._copySequenceContents(initializing:)((uint64_t)&v27, (uint64_t)v36, v32, (uint64_t)v13);
            uint64_t v25 = (uint64_t)v28;
            uint64_t v26 = v29;
            int v33 = v30;
            swift_bridgeObjectRelease(v27);
            outlined consume of [MLDataValue : MLDataValue].Index._Variant(v25, v26, v33);
            if (v36 != (void *)v21) {
              BUG();
            }
            outlined consume of MLDataValue(v13, v20, 4);
            outlined consume of MLDataValue(v13, v20, 4);
            uint64_t v11 = v35;
          }
          else
          {
            outlined consume of MLDataValue(v27, v28, 4);
            uint64_t v11 = _swiftEmptyArrayStorage;
          }
        }
        else
        {
          outlined consume of MLDataValue(v27, v28, v29);
          uint64_t v11 = 0;
        }
        char v10 = v39;
        uint64_t v8 = v38;
        uint64_t v9 = v31;
      }
      uint64_t v37 = v9;
      unint64_t v22 = v9[2];
      unint64_t v23 = v9[3];
      if (v23 >> 1 <= v22)
      {
        uint64_t v35 = v11;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v23 >= 2, v22 + 1, 1);
        uint64_t v11 = v35;
        uint64_t v8 = v38;
        char v10 = v39;
        uint64_t v9 = v37;
      }
      v9[2] = v22 + 1;
      v9[v22 + 4] = v11;
      ++v6;
    }
    while (v8 != v6);
    outlined consume of Result<_DataTable, Error>(v34, v10 & 1);
  }
  return v9;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_So12MLMultiArrayCSgs5NeverOTg5059_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSo12dE11CSgSiXEfU4_0M2ML0Q6ColumnVyAM0Q5ValueO05MultiE4TypeVGTf1cn_n(uint64_t a1, uint64_t a2, uint64_t a3, char a4, double a5)
{
  if (__OFSUB__(a2, a1)) {
    BUG();
  }
  if (a2 == a1)
  {
    outlined consume of Result<_DataTable, Error>(a3, a4 & 1);
    return _swiftEmptyArrayStorage;
  }
  uint64_t v5 = a1;
  specialized ContiguousArray.reserveCapacity(_:)(a2 - a1);
  uint64_t v6 = a2;
  if (a2 < a1 || a2 - a1 < 0) {
    BUG();
  }
  do
  {
    if (v6 == v5) {
      BUG();
    }
    if ((a4 & 1) == 0)
    {
      outlined copy of Result<_DataTable, Error>(a3, 0);
      _UntypedColumn.valueAtIndex(index:)(v5, a5);
      outlined consume of Result<_DataTable, Error>(a3, 0);
      int64_t v7 = v10;
      if (v12 == 5) {
        goto LABEL_10;
      }
      outlined consume of MLDataValue(v10, v11, v12);
    }
    int64_t v7 = 0;
LABEL_10:
    specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()();
    uint64_t v8 = _swiftEmptyArrayStorage[2];
    specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)(v8);
    specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)(v8, v7);
    specialized ContiguousArray._endMutation()();
    ++v5;
    uint64_t v6 = a2;
  }
  while (a2 != v5);
  outlined consume of Result<_DataTable, Error>(a3, a4 & 1);
  return _swiftEmptyArrayStorage;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSypG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRyp_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_yp_Tg5Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  int64_t v2 = *(void *)(a1 + 16);
  if (v2)
  {
    uint64_t v3 = a1;
    uint64_t v55 = v1;
    BOOL v56 = _swiftEmptyArrayStorage;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    int64_t v4 = specialized Dictionary.startIndex.getter(a1);
    if (v4 < 0 || v4 >= 1 << *(unsigned char *)(a1 + 32)) {
LABEL_30:
    }
      BUG();
    uint64_t v6 = a1 + 64;
    uint64_t v48 = (char *)&type metadata for Any + 8;
    uint64_t v54 = a1 + 64;
    uint64_t v47 = a1;
    while (1)
    {
      uint64_t v7 = *(void *)(v6 + 8 * ((unint64_t)v4 >> 6));
      if (!_bittest64(&v7, v4)) {
        BUG();
      }
      if (v5 != *(_DWORD *)(v3 + 36)) {
        BUG();
      }
      uint64_t v44 = 1 << v4;
      unint64_t v43 = (unint64_t)v4 >> 6;
      uint64_t v45 = v5;
      int64_t v46 = v2;
      uint64_t v8 = *(void *)(v3 + 48);
      uint64_t v9 = v3;
      uint64_t v10 = *(void *)(v8 + 16 * v4);
      uint64_t v11 = *(void *)(v8 + 16 * v4 + 8);
      int64_t v53 = v4;
      outlined init with copy of Any(*(void *)(v9 + 56) + 32 * v4, (uint64_t)v28);
      v27[0] = v10;
      v27[1] = v11;
      *(void *)&long long v30 = v10;
      *((void *)&v30 + 1) = v11;
      outlined init with copy of Any((uint64_t)v28, (uint64_t)v31);
      double v12 = *(double *)&v30;
      v40[1] = v31[1];
      v40[0] = v31[0];
      long long v39 = v30;
      swift_bridgeObjectRetain_n(v11, 2);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v27, &demangling cache variable for type metadata for (key: String, value: Any));
      uint64_t v14 = (void *)*((void *)&v39 + 1);
      uint64_t v13 = v39;
      outlined init with copy of Any((uint64_t)v40, (uint64_t)v23);
      v32[0] = v13;
      v32[1] = v14;
      outlined init with take of Any(v23, &v33);
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v32, (uint64_t)&v36, &demangling cache variable for type metadata for (key: String, value: Any)?);
      uint64_t v15 = v37;
      if (v37)
      {
        uint64_t v16 = v36;
        v34[0] = v36;
        v34[1] = v37;
        outlined init with take of Any(v38, v35);
        uint64_t v36 = v16;
        uint64_t v37 = v15;
        outlined init with copy of Any((uint64_t)v35, (uint64_t)v38);
        *(void *)&long long v49 = v16;
        *((void *)&v49 + 1) = v15;
        char v50 = 2;
        uint64_t v24 = v16;
        uint64_t v25 = v15;
        outlined init with copy of Any((uint64_t)v35, (uint64_t)v26);
        v29[3] = v48;
        v29[0] = swift_allocObject(&unk_399590, 48, 7);
        outlined init with take of Any(v26, (_OWORD *)(v29[0] + 16));
        swift_bridgeObjectRetain(v14);
        swift_bridgeObjectRetain(v15);
        uint64_t v17 = v55;
        MLDataValue.init(fromAny:)(v29, v12);
        uint64_t v55 = v17;
        if (v17)
        {
          swift_bridgeObjectRelease(v15);
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v34, &demangling cache variable for type metadata for (key: String, value: Any));
          __swift_destroy_boxed_opaque_existential_1Tm(v38);
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v32, &demangling cache variable for type metadata for (key: String, value: Any)?);
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v39, &demangling cache variable for type metadata for (key: String, value: Any));
          swift_release(v56);
          return v14;
        }
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v34, &demangling cache variable for type metadata for (key: String, value: Any));
        __swift_destroy_boxed_opaque_existential_1Tm(v38);
        long long v41 = v49;
        char v58 = v50;
        long long v42 = v51;
        char v57 = v52;
        uint64_t v6 = v54;
      }
      else
      {
        swift_bridgeObjectRetain(v14);
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v36, &demangling cache variable for type metadata for (key: String, value: Any)?);
        long long v49 = 0;
        char v50 = 6;
        long long v51 = 0;
        char v57 = 6;
        char v52 = 6;
        long long v41 = 0;
        char v58 = 6;
        long long v42 = 0;
        uint64_t v6 = v54;
      }
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v32, &demangling cache variable for type metadata for (key: String, value: Any)?);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v39, &demangling cache variable for type metadata for (key: String, value: Any));
      uint64_t v14 = v56;
      if (!swift_isUniquelyReferenced_nonNull_native(v56))
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v14[2] + 1, 1);
        uint64_t v6 = v54;
        uint64_t v14 = v56;
      }
      uint64_t v18 = v53;
      unint64_t v19 = v14[2];
      if (v14[3] >> 1 <= v19)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v14[3] >= 2uLL, v19 + 1, 1);
        uint64_t v6 = v54;
        uint64_t v18 = v53;
        uint64_t v14 = v56;
      }
      void v14[2] = v19 + 1;
      uint64_t v20 = 6 * v19;
      *(_OWORD *)&v14[v20 + 4] = v41;
      LOBYTE(v14[v20 + 6]) = v58;
      *(_OWORD *)&v14[v20 + 7] = v42;
      LOBYTE(v14[v20 + 9]) = v57;
      uint64_t v3 = v47;
      uint64_t v21 = -1 << *(unsigned char *)(v47 + 32);
      if (v18 >= -v21) {
        BUG();
      }
      if ((v44 & *(void *)(v6 + 8 * v43)) == 0) {
        BUG();
      }
      if (v45 != *(_DWORD *)(v47 + 36)) {
        BUG();
      }
      int64_t v4 = _HashTable.occupiedBucket(after:)(v18, v6, ~v21);
      int64_t v2 = v46 - 1;
      if (v46 == 1) {
        return v14;
      }
      if (v4 >= 0)
      {
        uint64_t v5 = *(unsigned int *)(v3 + 36);
        if (v4 < 1 << *(unsigned char *)(v3 + 32)) {
          continue;
        }
      }
      goto LABEL_30;
    }
  }
  return _swiftEmptyArrayStorage;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSypSgG_8CreateML11MLDataValueO_AJtsAE_pTg5022_sSS3key_xSg5valuetSg8d4ML11fg5OAGs5c138_pIgnrrzo_SSAA_AbCtAG_AGtsAH_pIegnrzr_lTRyp_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l20SDySSxSgGGKclufcAA11ef33OAHSgKXEfU_AK_AKtI31_AG5valuetsW8U_yp_Tg5Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  int64_t v2 = *(void *)(a1 + 16);
  if (!v2) {
    return _swiftEmptyArrayStorage;
  }
  uint64_t v3 = a1;
  uint64_t v46 = v1;
  uint64_t v47 = _swiftEmptyArrayStorage;
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
  int64_t v4 = specialized Dictionary.startIndex.getter(a1);
  if (v4 < 0 || v4 >= 1 << *(unsigned char *)(a1 + 32)) {
LABEL_27:
  }
    BUG();
  uint64_t v44 = a1 + 64;
  uint64_t v43 = a1;
  while (1)
  {
    int64_t v40 = v2;
    unint64_t v6 = (unint64_t)v4 >> 6;
    uint64_t v7 = *(void *)(v44 + 8 * ((unint64_t)v4 >> 6));
    if (!_bittest64(&v7, v4)) {
      BUG();
    }
    if (v5 != *(_DWORD *)(v3 + 36)) {
      BUG();
    }
    uint64_t v41 = 1 << v4;
    uint64_t v42 = v5;
    uint64_t v8 = *(void *)(v3 + 48);
    uint64_t v9 = *(void *)(v8 + 16 * v4);
    uint64_t v10 = v3;
    uint64_t v11 = *(void *)(v8 + 16 * v4 + 8);
    int64_t v45 = v4;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v10 + 56) + 32 * v4, (uint64_t)v27, &demangling cache variable for type metadata for Any?);
    v26[0] = v9;
    v26[1] = v11;
    *(void *)&long long v30 = v9;
    *((void *)&v30 + 1) = v11;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v27, (uint64_t)v31, &demangling cache variable for type metadata for Any?);
    double v12 = *(double *)&v30;
    v35[1] = v31[1];
    v35[0] = v31[0];
    long long v34 = v30;
    swift_bridgeObjectRetain_n(v11, 2);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v26, &demangling cache variable for type metadata for (key: String, value: Any?));
    uint64_t v13 = *((void *)&v34 + 1);
    uint64_t v14 = v34;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v35, (uint64_t)v25, &demangling cache variable for type metadata for Any?);
    v28[0] = v14;
    v28[1] = v13;
    outlined init with take of Any?((uint64_t)v25, (uint64_t)v29);
    swift_bridgeObjectRetain(v13);
    uint64_t v15 = v28;
    uint64_t v16 = v46;
    specialized closure #1 in closure #1 in MLUntypedColumn.init<A>(_:)((uint64_t)&v36, (uint64_t)&v38, (uint64_t)v28, v12);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v28, &demangling cache variable for type metadata for (key: String, value: Any?)?);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v34, &demangling cache variable for type metadata for (key: String, value: Any?));
    uint64_t v46 = v16;
    if (v16) {
      break;
    }
    long long v32 = v36;
    char v17 = v37;
    long long v33 = v38;
    char v48 = v39;
    uint64_t v15 = v47;
    if (!swift_isUniquelyReferenced_nonNull_native(v47))
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v15[2] + 1, 1);
      uint64_t v15 = v47;
    }
    uint64_t v18 = v45;
    unint64_t v19 = v15[2];
    unint64_t v20 = v15[3];
    unint64_t v21 = v19 + 1;
    if (v20 >> 1 <= v19)
    {
      char v49 = v17;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v20 >= 2, v19 + 1, 1);
      unint64_t v21 = v19 + 1;
      char v17 = v49;
      uint64_t v18 = v45;
      uint64_t v15 = v47;
    }
    v15[2] = v21;
    uint64_t v22 = 6 * v19;
    *(_OWORD *)&v15[v22 + 4] = v32;
    LOBYTE(v15[v22 + 6]) = v17;
    *(_OWORD *)&v15[v22 + 7] = v33;
    LOBYTE(v15[v22 + 9]) = v48;
    uint64_t v3 = v43;
    uint64_t v23 = -1 << *(unsigned char *)(v43 + 32);
    if (v18 >= -v23) {
      BUG();
    }
    if ((v41 & *(void *)(v44 + 8 * v6)) == 0) {
      BUG();
    }
    if (v42 != *(_DWORD *)(v43 + 36)) {
      BUG();
    }
    int64_t v4 = _HashTable.occupiedBucket(after:)(v18, v44, ~v23);
    int64_t v2 = v40 - 1;
    if (v40 == 1) {
      return v15;
    }
    if (v4 >= 0)
    {
      uint64_t v5 = *(unsigned int *)(v3 + 36);
      if (v4 < 1 << *(unsigned char *)(v3 + 32)) {
        continue;
      }
    }
    goto LABEL_27;
  }
  swift_release(v47);
  return v15;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDyS2SG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSS_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_SS_TG5Tf3nnnpf_nTf1cn_n(uint64_t a1, __m128 a2)
{
  int64_t v3 = *(void *)(a1 + 16);
  if (!v3) {
    return _swiftEmptyArrayStorage;
  }
  uint64_t v4 = a1;
  uint64_t v49 = v2;
  uint64_t v47 = _swiftEmptyArrayStorage;
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3, 0);
  uint64_t v5 = _swiftEmptyArrayStorage;
  int64_t v6 = specialized Dictionary.startIndex.getter(a1);
  if (v6 < 0 || v6 >= 1 << *(unsigned char *)(a1 + 32)) {
LABEL_25:
  }
    BUG();
  uint64_t v48 = a1 + 64;
  uint64_t v46 = a1;
  while (1)
  {
    unint64_t v8 = (unint64_t)v6 >> 6;
    uint64_t v9 = *(void *)(v48 + 8 * ((unint64_t)v6 >> 6));
    if (!_bittest64(&v9, v6)) {
      BUG();
    }
    if (v7 != *(_DWORD *)(v4 + 36)) {
      BUG();
    }
    uint64_t v43 = 1 << v6;
    uint64_t v44 = v7;
    int64_t v45 = v3;
    int64_t v42 = v6;
    uint64_t v10 = 16 * v6;
    uint64_t v11 = *(void *)(v4 + 48);
    uint64_t v12 = *(void *)(v4 + 56);
    uint64_t v13 = *(void *)(v11 + v10);
    uint64_t v14 = *(void *)(v11 + v10 + 8);
    uint64_t v15 = *(void *)(v12 + v10);
    uint64_t v16 = *(void *)(v12 + v10 + 8);
    v38.i64[0] = v13;
    v38.i64[1] = v14;
    char v39 = 2;
    v35[3] = &type metadata for String;
    v35[0] = v15;
    v35[1] = v16;
    swift_bridgeObjectRetain_n(v14, 3);
    swift_bridgeObjectRetain_n(v16, 4);
    uint64_t v17 = v49;
    MLDataValue.init(fromAny:)(v35, *(double *)a2.i64);
    uint64_t v49 = v17;
    if (v17) {
      break;
    }
    swift_bridgeObjectRelease_n(v14, 2, v18, v19, v20);
    swift_bridgeObjectRelease_n(v16, 2, v21, v22, v23);
    swift_bridgeObjectRelease(v16);
    a2 = v38;
    char v24 = v39;
    long long v25 = v40;
    char v26 = v41;
    uint64_t v47 = v5;
    unint64_t v27 = v5[2];
    unint64_t v28 = v5[3];
    if (v28 >> 1 <= v27)
    {
      char v51 = v41;
      char v50 = v39;
      __m128 v36 = v38;
      long long v37 = v40;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v28 >= 2, v27 + 1, 1);
      char v26 = v51;
      long long v25 = v37;
      char v24 = v50;
      a2 = v36;
      uint64_t v5 = v47;
    }
    _OWORD v5[2] = v27 + 1;
    uint64_t v29 = 6 * v27;
    *(__m128 *)&v5[v29 + 4] = a2;
    LOBYTE(v5[v29 + 6]) = v24;
    *(_OWORD *)&v5[v29 + 7] = v25;
    LOBYTE(v5[v29 + 9]) = v26;
    uint64_t v4 = v46;
    uint64_t v30 = -1 << *(unsigned char *)(v46 + 32);
    if (v42 >= -v30) {
      BUG();
    }
    if ((v43 & *(void *)(v48 + 8 * v8)) == 0) {
      BUG();
    }
    if (v44 != *(_DWORD *)(v46 + 36)) {
      BUG();
    }
    int64_t v6 = _HashTable.occupiedBucket(after:)(v42, v48, ~v30);
    int64_t v3 = v45 - 1;
    if (v45 == 1) {
      return v5;
    }
    if (v6 >= 0)
    {
      uint64_t v7 = *(unsigned int *)(v4 + 36);
      if (v6 < 1 << *(unsigned char *)(v4 + 32)) {
        continue;
      }
    }
    goto LABEL_25;
  }
  swift_bridgeObjectRelease_n(v16, 2, v18, v19, v20);
  swift_bridgeObjectRelease_n(v14, 3, v31, v32, v33);
  swift_release(v5);
  swift_bridgeObjectRelease(v16);
  return v5;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSSfG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSf_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_Sf_TG5Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  int64_t v2 = *(void *)(a1 + 16);
  if (!v2) {
    return _swiftEmptyArrayStorage;
  }
  uint64_t v3 = a1;
  uint64_t v46 = v1;
  uint64_t v44 = _swiftEmptyArrayStorage;
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
  uint64_t v4 = _swiftEmptyArrayStorage;
  int64_t v5 = specialized Dictionary.startIndex.getter(a1);
  if (v5 < 0 || v5 >= 1 << *(unsigned char *)(a1 + 32)) {
LABEL_25:
  }
    BUG();
  uint64_t v45 = a1 + 64;
  uint64_t v42 = a1;
  while (1)
  {
    int64_t v40 = v2;
    unint64_t v7 = (unint64_t)v5 >> 6;
    uint64_t v8 = *(void *)(v45 + 8 * ((unint64_t)v5 >> 6));
    uint64_t v9 = 1 << v5;
    if (!_bittest64(&v8, v5)) {
      BUG();
    }
    if (v6 != *(_DWORD *)(v3 + 36)) {
      BUG();
    }
    uint64_t v41 = v6;
    uint64_t v10 = *(void *)(v3 + 48);
    uint64_t v11 = *(void *)(v3 + 56);
    uint64_t v12 = *(void *)(v10 + 16 * v5);
    uint64_t v13 = *(void *)(v10 + 16 * v5 + 8);
    uint64_t v39 = v5;
    *(void *)&double v14 = *(unsigned int *)(v11 + 4 * v5);
    *(void *)&long long v35 = v12;
    *((void *)&v35 + 1) = v13;
    char v36 = 2;
    v32[3] = &type metadata for Float;
    LODWORD(v32[0]) = LODWORD(v14);
    swift_bridgeObjectRetain_n(v13, 3);
    uint64_t v15 = v46;
    MLDataValue.init(fromAny:)(v32, v14);
    uint64_t v46 = v15;
    if (v15) {
      break;
    }
    swift_bridgeObjectRelease_n(v13, 2, v16, v17, v18);
    long long v19 = v35;
    char v20 = v36;
    long long v21 = v37;
    char v22 = v38;
    uint64_t v44 = v4;
    unint64_t v23 = v4[2];
    unint64_t v24 = v4[3];
    int64_t v25 = v23 + 1;
    if (v24 >> 1 <= v23)
    {
      char v48 = v38;
      char v47 = v36;
      long long v33 = v35;
      long long v34 = v37;
      int64_t v43 = v23 + 1;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v24 >= 2, v25, 1);
      int64_t v25 = v43;
      char v22 = v48;
      long long v21 = v34;
      char v20 = v47;
      long long v19 = v33;
      uint64_t v4 = v44;
    }
    v4[2] = v25;
    uint64_t v26 = 6 * v23;
    *(_OWORD *)&v4[v26 + 4] = v19;
    LOBYTE(v4[v26 + 6]) = v20;
    *(_OWORD *)&v4[v26 + 7] = v21;
    LOBYTE(v4[v26 + 9]) = v22;
    uint64_t v3 = v42;
    char v27 = *(unsigned char *)(v42 + 32);
    if (v39 >= -(-1 << v27)) {
      BUG();
    }
    if ((v9 & *(void *)(v45 + 8 * v7)) == 0) {
      BUG();
    }
    if (v41 != *(_DWORD *)(v42 + 36)) {
      BUG();
    }
    int64_t v5 = _HashTable.occupiedBucket(after:)(v39, v45, ~(-1 << v27));
    int64_t v2 = v40 - 1;
    if (v40 == 1) {
      return v4;
    }
    if (v5 >= 0)
    {
      uint64_t v6 = *(unsigned int *)(v3 + 36);
      if (v5 < 1 << *(unsigned char *)(v3 + 32)) {
        continue;
      }
    }
    goto LABEL_25;
  }
  swift_release(v4);
  swift_bridgeObjectRelease_n(v13, 3, v28, v29, v30);
  return v4;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSSdG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSd_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_Sd_TG5Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  int64_t v2 = *(void *)(a1 + 16);
  if (!v2) {
    return _swiftEmptyArrayStorage;
  }
  uint64_t v3 = a1;
  uint64_t v46 = v1;
  uint64_t v44 = _swiftEmptyArrayStorage;
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
  uint64_t v4 = _swiftEmptyArrayStorage;
  int64_t v5 = specialized Dictionary.startIndex.getter(a1);
  if (v5 < 0 || v5 >= 1 << *(unsigned char *)(a1 + 32)) {
LABEL_25:
  }
    BUG();
  uint64_t v45 = a1 + 64;
  uint64_t v42 = a1;
  while (1)
  {
    int64_t v40 = v2;
    unint64_t v7 = (unint64_t)v5 >> 6;
    uint64_t v8 = *(void *)(v45 + 8 * ((unint64_t)v5 >> 6));
    uint64_t v9 = 1 << v5;
    if (!_bittest64(&v8, v5)) {
      BUG();
    }
    if (v6 != *(_DWORD *)(v3 + 36)) {
      BUG();
    }
    uint64_t v41 = v6;
    uint64_t v10 = *(void *)(v3 + 48);
    uint64_t v11 = *(void *)(v3 + 56);
    uint64_t v12 = *(void *)(v10 + 16 * v5);
    uint64_t v13 = *(void *)(v10 + 16 * v5 + 8);
    uint64_t v39 = v5;
    double v14 = *(double *)(v11 + 8 * v5);
    *(void *)&long long v35 = v12;
    *((void *)&v35 + 1) = v13;
    char v36 = 2;
    v32[3] = &type metadata for Double;
    *(double *)uint64_t v32 = v14;
    swift_bridgeObjectRetain_n(v13, 3);
    uint64_t v15 = v46;
    MLDataValue.init(fromAny:)(v32, v14);
    uint64_t v46 = v15;
    if (v15) {
      break;
    }
    swift_bridgeObjectRelease_n(v13, 2, v16, v17, v18);
    long long v19 = v35;
    char v20 = v36;
    long long v21 = v37;
    char v22 = v38;
    uint64_t v44 = v4;
    unint64_t v23 = v4[2];
    unint64_t v24 = v4[3];
    int64_t v25 = v23 + 1;
    if (v24 >> 1 <= v23)
    {
      char v48 = v38;
      char v47 = v36;
      long long v33 = v35;
      long long v34 = v37;
      int64_t v43 = v23 + 1;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v24 >= 2, v25, 1);
      int64_t v25 = v43;
      char v22 = v48;
      long long v21 = v34;
      char v20 = v47;
      long long v19 = v33;
      uint64_t v4 = v44;
    }
    v4[2] = v25;
    uint64_t v26 = 6 * v23;
    *(_OWORD *)&v4[v26 + 4] = v19;
    LOBYTE(v4[v26 + 6]) = v20;
    *(_OWORD *)&v4[v26 + 7] = v21;
    LOBYTE(v4[v26 + 9]) = v22;
    uint64_t v3 = v42;
    char v27 = *(unsigned char *)(v42 + 32);
    if (v39 >= -(-1 << v27)) {
      BUG();
    }
    if ((v9 & *(void *)(v45 + 8 * v7)) == 0) {
      BUG();
    }
    if (v41 != *(_DWORD *)(v42 + 36)) {
      BUG();
    }
    int64_t v5 = _HashTable.occupiedBucket(after:)(v39, v45, ~(-1 << v27));
    int64_t v2 = v40 - 1;
    if (v40 == 1) {
      return v4;
    }
    if (v5 >= 0)
    {
      uint64_t v6 = *(unsigned int *)(v3 + 36);
      if (v5 < 1 << *(unsigned char *)(v3 + 32)) {
        continue;
      }
    }
    goto LABEL_25;
  }
  swift_release(v4);
  swift_bridgeObjectRelease_n(v13, 3, v28, v29, v30);
  return v4;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSSiG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSi_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_Si_TG5Tf3nnnpf_nTf1cn_n(uint64_t a1, __m128 a2)
{
  int64_t v3 = *(void *)(a1 + 16);
  if (!v3) {
    return _swiftEmptyArrayStorage;
  }
  uint64_t v4 = a1;
  uint64_t v46 = v2;
  uint64_t v44 = _swiftEmptyArrayStorage;
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3, 0);
  int64_t v5 = _swiftEmptyArrayStorage;
  int64_t v6 = specialized Dictionary.startIndex.getter(a1);
  if (v6 < 0 || v6 >= 1 << *(unsigned char *)(a1 + 32)) {
LABEL_25:
  }
    BUG();
  uint64_t v45 = a1 + 64;
  uint64_t v42 = a1;
  while (1)
  {
    int64_t v40 = v3;
    unint64_t v8 = (unint64_t)v6 >> 6;
    uint64_t v9 = *(void *)(v45 + 8 * ((unint64_t)v6 >> 6));
    uint64_t v10 = 1 << v6;
    if (!_bittest64(&v9, v6)) {
      BUG();
    }
    if (v7 != *(_DWORD *)(v4 + 36)) {
      BUG();
    }
    uint64_t v41 = v7;
    uint64_t v11 = *(void *)(v4 + 48);
    uint64_t v12 = *(void *)(v4 + 56);
    uint64_t v13 = *(void *)(v11 + 16 * v6);
    uint64_t v14 = *(void *)(v11 + 16 * v6 + 8);
    uint64_t v39 = v6;
    uint64_t v15 = *(void *)(v12 + 8 * v6);
    v35.i64[0] = v13;
    v35.i64[1] = v14;
    char v36 = 2;
    v32[3] = &type metadata for Int;
    v32[0] = v15;
    swift_bridgeObjectRetain_n(v14, 3);
    uint64_t v16 = v46;
    MLDataValue.init(fromAny:)(v32, *(double *)a2.i64);
    uint64_t v46 = v16;
    if (v16) {
      break;
    }
    swift_bridgeObjectRelease_n(v14, 2, v17, v18, v19);
    a2 = v35;
    char v20 = v36;
    long long v21 = v37;
    char v22 = v38;
    uint64_t v44 = v5;
    unint64_t v23 = v5[2];
    unint64_t v24 = v5[3];
    int64_t v25 = v23 + 1;
    if (v24 >> 1 <= v23)
    {
      char v48 = v38;
      char v47 = v36;
      __m128 v33 = v35;
      long long v34 = v37;
      int64_t v43 = v23 + 1;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v24 >= 2, v25, 1);
      int64_t v25 = v43;
      char v22 = v48;
      long long v21 = v34;
      char v20 = v47;
      a2 = v33;
      int64_t v5 = v44;
    }
    _OWORD v5[2] = v25;
    uint64_t v26 = 6 * v23;
    *(__m128 *)&v5[v26 + 4] = a2;
    LOBYTE(v5[v26 + 6]) = v20;
    *(_OWORD *)&v5[v26 + 7] = v21;
    LOBYTE(v5[v26 + 9]) = v22;
    uint64_t v4 = v42;
    char v27 = *(unsigned char *)(v42 + 32);
    if (v39 >= -(-1 << v27)) {
      BUG();
    }
    if ((v10 & *(void *)(v45 + 8 * v8)) == 0) {
      BUG();
    }
    if (v41 != *(_DWORD *)(v42 + 36)) {
      BUG();
    }
    int64_t v6 = _HashTable.occupiedBucket(after:)(v39, v45, ~(-1 << v27));
    int64_t v3 = v40 - 1;
    if (v40 == 1) {
      return v5;
    }
    if (v6 >= 0)
    {
      uint64_t v7 = *(unsigned int *)(v4 + 36);
      if (v6 < 1 << *(unsigned char *)(v4 + 32)) {
        continue;
      }
    }
    goto LABEL_25;
  }
  swift_release(v5);
  swift_bridgeObjectRelease_n(v14, 3, v28, v29, v30);
  return v5;
}

uint64_t MLDataTable.init(_:convertArraysToShapedArrays:)(uint64_t a1, int a2, __m128 a3)
{
  *(void *)&long long v68 = v4;
  LODWORD(v69) = a2;
  uint64_t v62 = v3;
  uint64_t v72 = type metadata accessor for AnyColumn(0);
  uint64_t v67 = *(void *)(v72 - 8);
  int64_t v5 = *(void *)(v67 + 64);
  int64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  char v57 = &v56;
  unint64_t v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v63 = &v56;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?)
                              - 8)
                  + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v74 = &v56;
  uint64_t empty = tc_v1_sframe_create_empty(0);
  if (!empty) {
    BUG();
  }
  uint64_t v14 = empty;
  uint64_t v15 = type metadata accessor for CMLTable();
  uint64_t v16 = swift_allocObject(v15, 24, 7);
  *(void *)(v16 + 16) = v14;
  uint64_t v17 = type metadata accessor for _DataTable();
  swift_allocObject(v17, 40, 7);
  uint64_t v75 = _DataTable.init(impl:)(v16);
  LOBYTE(v76) = 0;
  uint64_t v18 = DataFrame.columns.getter();
  uint64_t v19 = *(void *)(v18 + 16);
  uint64_t v64 = a1;
  uint64_t v65 = v18;
  if (v19)
  {
    uint64_t v20 = ((*(unsigned __int8 *)(v67 + 80) + 32) & ~*(unsigned __int8 *)(v67 + 80)) + v18;
    long long v21 = *(double (**)(void, void, void))(v67 + 16);
    uint64_t v59 = *(void *)(v67 + 72);
    int v66 = v69;
    uint64_t v61 = "Duplicate values for key: '" + 0x8000000000000000;
    uint64_t v22 = v72;
    uint64_t v23 = (uint64_t)v74;
    char v58 = v21;
    while (1)
    {
      uint64_t v71 = v19;
      uint64_t v56 = v20;
      v21(v23, v20, v22);
      uint64_t v24 = v23;
      __swift_storeEnumTagSinglePayload(v23, 0, 1, v22);
      uint64_t v25 = v22;
      if (__swift_getEnumTagSinglePayload(v24, 1, v22) == 1) {
        goto LABEL_23;
      }
      uint64_t v26 = v63;
      uint64_t v27 = v24;
      uint64_t v28 = v25;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v67 + 32))(v63, v27, v25);
      uint64_t v29 = (uint64_t)v57;
      *(double *)a3.i64 = v21(v57, v26, v28);
      uint64_t v30 = v68;
      MLUntypedColumn.init(_:convertArraysToShapedArrays:)(v29, v66, a3);
      if (v30)
      {
        uint64_t v55 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v55 - 8) + 8))(v64, v55);
        (*(void (**)(uint64_t *, uint64_t))(v67 + 8))(v26, v28);
        swift_bridgeObjectRelease(v65);
        return outlined consume of Result<_DataTable, Error>(v75, v76);
      }
      *(void *)&long long v68 = 0;
      uint64_t v70 = v73;
      char v31 = BYTE8(v73);
      uint64_t v32 = AnyColumn.name.getter();
      uint64_t v69 = v33;
      MLDataTable.willMutate()();
      uint64_t v34 = v75;
      char v77 = v31;
      if ((_BYTE)v76)
      {
        *(void *)&long long v73 = v75;
        outlined copy of Result<_DataTable, Error>(v75, 1);
        swift_errorRetain(v34);
        uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
        uint64_t v36 = _getErrorEmbeddedNSError<A>(_:)(&v73, v35, &protocol self-conformance witness table for Error);
        uint64_t v23 = (uint64_t)v74;
        if (v36)
        {
          uint64_t v37 = v36;
          outlined consume of Result<_DataTable, Error>(v34, 1);
        }
        else
        {
          uint64_t v37 = swift_allocError(v35, &protocol self-conformance witness table for Error, 0, 0);
          *char v47 = v73;
        }
        uint64_t v41 = v71;
        outlined consume of Result<_DataTable, Error>(v34, 1);
      }
      else
      {
        BOOL v38 = (v31 & 1) == 0;
        uint64_t v23 = (uint64_t)v74;
        if (v38)
        {
          uint64_t v60 = *(void *)(v75 + 16);
          uint64_t v42 = v70;
          uint64_t v43 = *(void *)(v70 + 16);
          outlined copy of Result<_DataTable, Error>(v75, 0);
          uint64_t v44 = v42;
          uint64_t v45 = v43;
          outlined copy of Result<_DataTable, Error>(v44, 0);
          swift_retain(v43);
          uint64_t v46 = v68;
          CMLTable.addColumn(name:_:)(v32, (uint64_t)v69, v43);
          uint64_t v37 = v46;
          if (!v46)
          {
            *(void *)&long long v68 = 0;
            uint64_t v48 = v70;
            outlined consume of Result<_DataTable, Error>(v70, 0);
            swift_release(v45);
            outlined consume of Result<_DataTable, Error>(v34, 0);
            uint64_t v41 = v71;
            if (!(_BYTE)v76)
            {
              uint64_t v49 = v75;
              outlined copy of Result<_DataTable, Error>(v75, 0);
              _DataTable.columnNamesDidChange()();
              uint64_t v50 = v49;
              uint64_t v48 = v70;
              outlined consume of Result<_DataTable, Error>(v50, 0);
            }
            uint64_t v22 = v72;
            uint64_t v23 = (uint64_t)v74;
            goto LABEL_16;
          }
          swift_release(v45);
          outlined consume of Result<_DataTable, Error>(v70, 0);
          outlined consume of Result<_DataTable, Error>(v34, 0);
          *(void *)&long long v68 = 0;
          uint64_t v41 = v71;
          uint64_t v23 = (uint64_t)v74;
        }
        else
        {
          *(void *)&long long v73 = 0;
          *((void *)&v73 + 1) = 0xE000000000000000;
          swift_retain(v75);
          _StringGuts.grow(_:)(36);
          swift_bridgeObjectRelease(*((void *)&v73 + 1));
          *(void *)&long long v73 = 0xD000000000000021;
          *((void *)&v73 + 1) = v61;
          v39._uint64_t countAndFlagsBits = v32;
          v39._char object = v69;
          String.append(_:)(v39);
          v39._uint64_t countAndFlagsBits = 39;
          v39._char object = (void *)0xE100000000000000;
          String.append(_:)(v39);
          long long v68 = v73;
          v39._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v37 = swift_allocError(&type metadata for MLCreateError, v39._object, 0, 0);
          *(_OWORD *)uint64_t v40 = v68;
          a3 = 0;
          *(_OWORD *)(v40 + 16) = 0;
          *(_OWORD *)(v40 + 32) = 0;
          *(unsigned char *)(v40 + 48) = 1;
          swift_willThrow();
          outlined consume of Result<_DataTable, Error>(v34, 0);
          *(void *)&long long v68 = 0;
          uint64_t v41 = v71;
        }
      }
      outlined consume of Result<_DataTable, Error>(v75, v76);
      uint64_t v75 = v37;
      LOBYTE(v76) = 1;
      uint64_t v22 = v72;
      uint64_t v48 = v70;
LABEL_16:
      swift_bridgeObjectRelease(v69);
      (*(void (**)(uint64_t *, uint64_t))(v67 + 8))(v63, v22);
      outlined consume of Result<_DataTable, Error>(v48, v77);
      uint64_t v20 = v59 + v56;
      uint64_t v19 = v41 - 1;
      long long v21 = v58;
      if (!v19) {
        goto LABEL_22;
      }
    }
  }
  uint64_t v22 = v72;
  uint64_t v23 = (uint64_t)v74;
LABEL_22:
  __swift_storeEnumTagSinglePayload(v23, 1, 1, v22);
LABEL_23:
  uint64_t v51 = type metadata accessor for DataFrame(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v51 - 8) + 8))(v64, v51);
  swift_bridgeObjectRelease(v65);
  uint64_t result = v75;
  char v53 = v76;
  uint64_t v54 = v62;
  *uint64_t v62 = v75;
  *((unsigned char *)v54 + 8) = v53;
  return result;
}

uint64_t DataFrame.init(_:)(uint64_t a1)
{
  uint64_t v3 = v1;
  uint64_t v154 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLMultiArray>);
  uint64_t v155 = *(void *)(v154 - 8);
  int64_t v4 = *(void *)(v155 + 64);
  int64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v172 = v153;
  uint64_t v156 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[(MLDataValue, MLDataValue)]>);
  uint64_t v157 = *(void *)(v156 - 8);
  int64_t v7 = *(void *)(v157 + 64);
  unint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v158 = v153;
  uint64_t v159 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[MLDataValue]>);
  uint64_t v160 = *(void *)(v159 - 8);
  int64_t v10 = *(void *)(v160 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v173 = v153;
  uint64_t v161 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v162 = *(void *)(v161 - 8);
  int64_t v13 = *(void *)(v162 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v163 = v153;
  uint64_t v164 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  uint64_t v165 = *(void *)(v164 - 8);
  int64_t v16 = *(void *)(v165 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v166 = v153;
  uint64_t v167 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v168 = *(void *)(v167 - 8);
  int64_t v19 = *(void *)(v168 + 64);
  uint64_t v20 = alloca(v19);
  long long v21 = alloca(v19);
  uint64_t v169 = v153;
  uint64_t v22 = *(void *)a1;
  LOBYTE(v2) = *(unsigned char *)(a1 + 8);
  uint64_t v174 = v3;
  DataFrame.init()();
  if ((_BYTE)v2)
  {
    uint64_t v23 = tc_v1_flex_list_create(0);
    if (!v23) {
      BUG();
    }
    uint64_t v24 = v23;
    uint64_t v25 = type metadata accessor for CMLSequence();
    uint64_t countAndFlagsBits = swift_allocObject(v25, 25, 7);
    *(void *)(countAndFlagsBits + 16) = v24;
    *(unsigned char *)(countAndFlagsBits + 24) = 1;
  }
  else
  {
    swift_retain();
    _DataTable.columnNames.getter(v22);
    outlined consume of Result<_DataTable, Error>(v22, 0);
    uint64_t countAndFlagsBits = v177._countAndFlagsBits;
  }
  v177._uint64_t countAndFlagsBits = v22;
  LOBYTE(v177._object) = v2;
  uint64_t v171 = MLDataTable.columnTypes.getter();
  swift_retain_n(countAndFlagsBits, 2);
  uint64_t v27 = CMLSequence.size.getter();
  uint64_t v28 = specialized RandomAccessCollection<>.distance(from:to:)(0, v27);
  swift_release();
  if (!v28)
  {
    swift_release();
    char v123 = v2;
    uint64_t v124 = v22;
    goto LABEL_43;
  }
  uint64_t v179 = v2;
  uint64_t v181 = v22;
  uint64_t v29 = 0;
  uint64_t v30 = 0;
  while (2)
  {
    CMLSequence.value(at:)(v30);
    if (v29)
    {
      swift_unexpectedError(v29, "CreateML/SequenceType.swift", 27, 1, 76);
      BUG();
    }
    Swift::String v31 = CMLFeatureValue.stringValue()();
    v176._uint64_t countAndFlagsBits = v31._countAndFlagsBits;
    if (v29)
    {
      swift_release();
      swift_errorRelease(v29);
      v177._uint64_t countAndFlagsBits = 0;
      v177._char object = (void *)0xE000000000000000;
      _StringGuts.grow(_:)(37);
      swift_bridgeObjectRelease(v177._object);
      v177._uint64_t countAndFlagsBits = 0xD000000000000022;
      v177._char object = "able.ColumnNames.swift" + 0x8000000000000000;
      v153[1] = v30;
      v150._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
      char object = v150._object;
      String.append(_:)(v150);
      swift_bridgeObjectRelease(object);
      v152._uint64_t countAndFlagsBits = 46;
      v152._char object = (void *)0xE100000000000000;
      String.append(_:)(v152);
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v177._countAndFlagsBits, v177._object, "CreateML/MLDataTable.ColumnNames.swift", 38, 2, 17, 0);
      BUG();
    }
    __m128 v33 = v31._object;
    swift_release();
    swift_retain();
    uint64_t v34 = CMLSequence.size.getter();
    uint64_t v35 = specialized RandomAccessCollection<>.distance(from:to:)(0, v34);
    swift_release();
    if (v30 >= v35) {
      BUG();
    }
    uint64_t v36 = v171;
    if (!*(void *)(v171 + 16))
    {
LABEL_17:
      swift_bridgeObjectRelease(v33);
      goto LABEL_40;
    }
    swift_bridgeObjectRetain(v33);
    unint64_t v37 = specialized __RawDictionaryStorage.find<A>(_:)(v176._countAndFlagsBits, (uint64_t)v33);
    if ((v38 & 1) == 0)
    {
      swift_bridgeObjectRelease_n(v33, 2, v38, v39, v40);
      goto LABEL_40;
    }
    uint64_t v41 = *(unsigned __int8 *)(*(void *)(v36 + 56) + v37);
    swift_bridgeObjectRelease(v33);
    switch(v41)
    {
      case 0:
        if ((_BYTE)v179)
        {
          uint64_t v126 = v181;
          outlined copy of Result<_DataTable, Error>(v181, 1);
          outlined copy of Result<_DataTable, Error>(v126, 1);
          swift_willThrow();
          v177._uint64_t countAndFlagsBits = 0;
          v177._char object = (void *)0xE000000000000000;
          _StringGuts.grow(_:)(34);
          swift_bridgeObjectRelease(v177._object);
          v177._uint64_t countAndFlagsBits = 0xD00000000000001FLL;
          v177._char object = "ml.activityclassifier" + 0x8000000000000000;
          v127._uint64_t countAndFlagsBits = v176._countAndFlagsBits;
          v127._char object = v33;
          String.append(_:)(v127);
          v127._char object = (void *)0xE100000000000000;
          v127._uint64_t countAndFlagsBits = 34;
          String.append(_:)(v127);
          Swift::String v176 = v177;
          uint64_t v128 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v47 = swift_allocError(&type metadata for MLCreateError, v128, 0, 0);
          *(Swift::String *)uint64_t v129 = v176;
          *(_OWORD *)(v129 + 16) = 0;
          *(_OWORD *)(v129 + 32) = 0;
          *(unsigned char *)(v129 + 48) = 1;
          outlined consume of Result<_DataTable, Error>(v181, v179);
          char v45 = 1;
          goto LABEL_53;
        }
        uint64_t v42 = v181;
        uint64_t v180 = *(void *)(v181 + 16);
        outlined copy of Result<_DataTable, Error>(v181, 0);
        uint64_t v43 = v42;
        uint64_t v44 = v180;
        outlined copy of Result<_DataTable, Error>(v43, 0);
        swift_retain();
        uint64_t v178 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.column(name:), v44, v176._countAndFlagsBits, (uint64_t)v33);
        uint64_t v175 = 0;
        swift_release();
        char v45 = 0;
        uint64_t v46 = type metadata accessor for _UntypedColumn();
        uint64_t v47 = swift_allocObject(v46, 24, 7);
        *(void *)(v47 + 16) = v178;
        outlined consume of Result<_DataTable, Error>(v181, 0);
        outlined copy of Result<_DataTable, Error>(v47, 0);
        _UntypedColumn.type.getter();
        outlined consume of Result<_DataTable, Error>(v47, 0);
        if (LOBYTE(v177._countAndFlagsBits))
        {
          uint64_t v179 = 0;
LABEL_53:
          outlined consume of Result<_DataTable, Error>(v47, v45);
          outlined consume of Result<_DataTable, Error>(v181, v179);
          BUG();
        }
        outlined consume of Result<_DataTable, Error>(v181, 0);
        uint64_t v48 = v47;
        outlined copy of Result<_DataTable, Error>(v47, 0);
        uint64_t v49 = CMLColumn.size.getter();
        uint64_t v180 = v48;
        outlined consume of Result<_DataTable, Error>(v48, 0);
        if (v49 < 0) {
          BUG();
        }
        uint64_t v50 = v180;
        outlined copy of Result<_DataTable, Error>(v180, 0);
        uint64_t v51 = v50;
        uint64_t v29 = v175;
        v177._uint64_t countAndFlagsBits = (uint64_t)_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SiSgs5NeverOTg5059_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSiSgR5XEfU_0K2ML0O6ColumnVySiGTf1cn_n(0, v49, v51, 0, v32);
        uint64_t v178 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int?]);
        uint64_t v52 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Int?] and conformance [A], &demangling cache variable for type metadata for [Int?], (uint64_t)&protocol conformance descriptor for [A]);
        char v53 = v169;
        Column.init<A>(name:contents:)(v176._countAndFlagsBits, v33, &v177, &type metadata for Int, v178, v52);
        DataFrame.append<A>(column:)(v53, &type metadata for Int);
        outlined consume of Result<_DataTable, Error>(v180, 0);
        uint64_t v54 = v53;
        uint64_t v55 = v167;
        uint64_t v56 = v168;
LABEL_39:
        (*(void (**)(void *, uint64_t))(v56 + 8))(v54, v55);
LABEL_40:
        ++v30;
        swift_retain();
        uint64_t v121 = CMLSequence.size.getter();
        uint64_t v122 = specialized RandomAccessCollection<>.distance(from:to:)(0, v121);
        swift_release();
        if (v30 != v122) {
          continue;
        }
        swift_release();
        char v123 = v179;
        uint64_t v124 = v181;
LABEL_43:
        outlined consume of Result<_DataTable, Error>(v124, v123);
        swift_release();
        return swift_bridgeObjectRelease(v171);
      case 1:
        if ((_BYTE)v179)
        {
          uint64_t v131 = v181;
          outlined copy of Result<_DataTable, Error>(v181, 1);
          outlined copy of Result<_DataTable, Error>(v131, 1);
          swift_willThrow();
          v177._uint64_t countAndFlagsBits = 0;
          v177._char object = (void *)0xE000000000000000;
          _StringGuts.grow(_:)(34);
          swift_bridgeObjectRelease(v177._object);
          v177._uint64_t countAndFlagsBits = 0xD00000000000001FLL;
          v177._char object = "ml.activityclassifier" + 0x8000000000000000;
          v132._uint64_t countAndFlagsBits = v176._countAndFlagsBits;
          v132._char object = v33;
          String.append(_:)(v132);
          v132._char object = (void *)0xE100000000000000;
          v132._uint64_t countAndFlagsBits = 34;
          String.append(_:)(v132);
          Swift::String v176 = v177;
          uint64_t v133 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v75 = swift_allocError(&type metadata for MLCreateError, v133, 0, 0);
          *(Swift::String *)uint64_t v134 = v176;
          *(_OWORD *)(v134 + 16) = 0;
          *(_OWORD *)(v134 + 32) = 0;
          *(unsigned char *)(v134 + 48) = 1;
          outlined consume of Result<_DataTable, Error>(v181, v179);
          char v73 = 1;
        }
        else
        {
          uint64_t v70 = v181;
          uint64_t v180 = *(void *)(v181 + 16);
          outlined copy of Result<_DataTable, Error>(v181, 0);
          uint64_t v71 = v70;
          uint64_t v72 = v180;
          outlined copy of Result<_DataTable, Error>(v71, 0);
          swift_retain();
          uint64_t v178 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.column(name:), v72, v176._countAndFlagsBits, (uint64_t)v33);
          uint64_t v175 = 0;
          swift_release();
          char v73 = 0;
          uint64_t v74 = type metadata accessor for _UntypedColumn();
          uint64_t v75 = swift_allocObject(v74, 24, 7);
          *(void *)(v75 + 16) = v178;
          outlined consume of Result<_DataTable, Error>(v181, 0);
          outlined copy of Result<_DataTable, Error>(v75, 0);
          _UntypedColumn.type.getter();
          outlined consume of Result<_DataTable, Error>(v75, 0);
          if (LOBYTE(v177._countAndFlagsBits) == 1)
          {
            outlined consume of Result<_DataTable, Error>(v181, 0);
            uint64_t v76 = v75;
            outlined copy of Result<_DataTable, Error>(v75, 0);
            uint64_t v77 = CMLColumn.size.getter();
            uint64_t v180 = v76;
            outlined consume of Result<_DataTable, Error>(v76, 0);
            if (v77 < 0) {
              BUG();
            }
            uint64_t v78 = v180;
            outlined copy of Result<_DataTable, Error>(v180, 0);
            uint64_t v79 = v78;
            uint64_t v29 = v175;
            v177._uint64_t countAndFlagsBits = (uint64_t)_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SdSgs5NeverOTg567_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSdSgSiXEfU0_0K2ML0O6ColumnVySdGTf1cn_n(0, v77, v79, 0, v32);
            uint64_t v178 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double?]);
            uint64_t v80 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Double?] and conformance [A], &demangling cache variable for type metadata for [Double?], (uint64_t)&protocol conformance descriptor for [A]);
            unint64_t v81 = v166;
            Column.init<A>(name:contents:)(v176._countAndFlagsBits, v33, &v177, &type metadata for Double, v178, v80);
            DataFrame.append<A>(column:)(v81, &type metadata for Double);
            outlined consume of Result<_DataTable, Error>(v180, 0);
            uint64_t v54 = v81;
            uint64_t v55 = v164;
            uint64_t v56 = v165;
            goto LABEL_39;
          }
          uint64_t v179 = 0;
        }
        outlined consume of Result<_DataTable, Error>(v75, v73);
        outlined consume of Result<_DataTable, Error>(v181, v179);
        BUG();
      case 2:
        if ((_BYTE)v179)
        {
          uint64_t v135 = v181;
          outlined copy of Result<_DataTable, Error>(v181, 1);
          outlined copy of Result<_DataTable, Error>(v135, 1);
          swift_willThrow();
          v177._uint64_t countAndFlagsBits = 0;
          v177._char object = (void *)0xE000000000000000;
          _StringGuts.grow(_:)(34);
          swift_bridgeObjectRelease(v177._object);
          v177._uint64_t countAndFlagsBits = 0xD00000000000001FLL;
          v177._char object = "ml.activityclassifier" + 0x8000000000000000;
          v136._uint64_t countAndFlagsBits = v176._countAndFlagsBits;
          v136._char object = v33;
          String.append(_:)(v136);
          v136._char object = (void *)0xE100000000000000;
          v136._uint64_t countAndFlagsBits = 34;
          String.append(_:)(v136);
          Swift::String v176 = v177;
          uint64_t v137 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v87 = swift_allocError(&type metadata for MLCreateError, v137, 0, 0);
          *(Swift::String *)uint64_t v138 = v176;
          *(_OWORD *)(v138 + 16) = 0;
          *(_OWORD *)(v138 + 32) = 0;
          *(unsigned char *)(v138 + 48) = 1;
          outlined consume of Result<_DataTable, Error>(v181, v179);
          char v85 = 1;
        }
        else
        {
          uint64_t v82 = v181;
          uint64_t v180 = *(void *)(v181 + 16);
          outlined copy of Result<_DataTable, Error>(v181, 0);
          uint64_t v83 = v82;
          uint64_t v84 = v180;
          outlined copy of Result<_DataTable, Error>(v83, 0);
          swift_retain();
          uint64_t v178 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.column(name:), v84, v176._countAndFlagsBits, (uint64_t)v33);
          uint64_t v175 = 0;
          swift_release();
          char v85 = 0;
          uint64_t v86 = type metadata accessor for _UntypedColumn();
          uint64_t v87 = swift_allocObject(v86, 24, 7);
          *(void *)(v87 + 16) = v178;
          outlined consume of Result<_DataTable, Error>(v181, 0);
          outlined copy of Result<_DataTable, Error>(v87, 0);
          _UntypedColumn.type.getter();
          outlined consume of Result<_DataTable, Error>(v87, 0);
          if (LOBYTE(v177._countAndFlagsBits) == 2)
          {
            outlined consume of Result<_DataTable, Error>(v181, 0);
            uint64_t v88 = v87;
            outlined copy of Result<_DataTable, Error>(v87, 0);
            uint64_t v89 = CMLColumn.size.getter();
            uint64_t v180 = v88;
            outlined consume of Result<_DataTable, Error>(v88, 0);
            if (v89 < 0) {
              BUG();
            }
            uint64_t v90 = v180;
            outlined copy of Result<_DataTable, Error>(v180, 0);
            uint64_t v91 = v90;
            uint64_t v29 = v175;
            v177._uint64_t countAndFlagsBits = (uint64_t)_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_SSSgs5NeverOTg567_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSSSgSiXEfU1_0K2ML0O6ColumnVySSGTf1cn_n(0, v89, v91, 0, v32);
            uint64_t v178 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String?]);
            uint64_t v92 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [String?] and conformance [A], &demangling cache variable for type metadata for [String?], (uint64_t)&protocol conformance descriptor for [A]);
            unint64_t v93 = v163;
            Column.init<A>(name:contents:)(v176._countAndFlagsBits, v33, &v177, &type metadata for String, v178, v92);
            DataFrame.append<A>(column:)(v93, &type metadata for String);
            outlined consume of Result<_DataTable, Error>(v180, 0);
            uint64_t v54 = v93;
            uint64_t v55 = v161;
            uint64_t v56 = v162;
            goto LABEL_39;
          }
          uint64_t v179 = 0;
        }
        outlined consume of Result<_DataTable, Error>(v87, v85);
        outlined consume of Result<_DataTable, Error>(v181, v179);
        BUG();
      case 3:
        if ((_BYTE)v179)
        {
          uint64_t v130 = v181;
          outlined copy of Result<_DataTable, Error>(v181, 1);
          outlined copy of Result<_DataTable, Error>(v130, 1);
          swift_willThrow();
          v177._uint64_t countAndFlagsBits = 0;
          v177._char object = (void *)0xE000000000000000;
          _StringGuts.grow(_:)(34);
          swift_bridgeObjectRelease(v177._object);
          v177._uint64_t countAndFlagsBits = 0xD00000000000001FLL;
          v177._char object = "ml.activityclassifier" + 0x8000000000000000;
          v139._uint64_t countAndFlagsBits = v176._countAndFlagsBits;
          v139._char object = v33;
          String.append(_:)(v139);
          v139._char object = (void *)0xE100000000000000;
          v139._uint64_t countAndFlagsBits = 34;
          String.append(_:)(v139);
          Swift::String v176 = v177;
          uint64_t v140 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v62 = swift_allocError(&type metadata for MLCreateError, v140, 0, 0);
          *(Swift::String *)uint64_t v141 = v176;
          *(_OWORD *)(v141 + 16) = 0;
          *(_OWORD *)(v141 + 32) = 0;
          *(unsigned char *)(v141 + 48) = 1;
          outlined consume of Result<_DataTable, Error>(v181, v179);
          char v60 = 1;
        }
        else
        {
          uint64_t v57 = v181;
          uint64_t v180 = *(void *)(v181 + 16);
          outlined copy of Result<_DataTable, Error>(v181, 0);
          uint64_t v58 = v57;
          uint64_t v59 = v180;
          outlined copy of Result<_DataTable, Error>(v58, 0);
          swift_retain();
          uint64_t v178 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.column(name:), v59, v176._countAndFlagsBits, (uint64_t)v33);
          uint64_t v175 = 0;
          swift_release();
          char v60 = 0;
          uint64_t v61 = type metadata accessor for _UntypedColumn();
          uint64_t v62 = swift_allocObject(v61, 24, 7);
          *(void *)(v62 + 16) = v178;
          outlined consume of Result<_DataTable, Error>(v181, 0);
          outlined copy of Result<_DataTable, Error>(v62, 0);
          _UntypedColumn.type.getter();
          outlined consume of Result<_DataTable, Error>(v62, 0);
          if (LOBYTE(v177._countAndFlagsBits) == 3)
          {
            outlined consume of Result<_DataTable, Error>(v181, 0);
            uint64_t v63 = v62;
            outlined copy of Result<_DataTable, Error>(v62, 0);
            uint64_t v64 = CMLColumn.size.getter();
            uint64_t v180 = v63;
            outlined consume of Result<_DataTable, Error>(v63, 0);
            if (v64 < 0) {
              BUG();
            }
            uint64_t v65 = v180;
            outlined copy of Result<_DataTable, Error>(v180, 0);
            uint64_t v66 = v65;
            uint64_t v29 = v175;
            v177._uint64_t countAndFlagsBits = (uint64_t)_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_Say8CreateML11MLDataValueOGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G12OGSgSiXEfU2_AG0F6ColumnVyAI12SequenceTypeVGTf1cn_n(0, v64, v66, 0, v32);
            uint64_t v67 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLDataValue]);
            uint64_t v178 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [[MLDataValue]?]);
            uint64_t v68 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [[MLDataValue]?] and conformance [A], &demangling cache variable for type metadata for [[MLDataValue]?], (uint64_t)&protocol conformance descriptor for [A]);
            Column.init<A>(name:contents:)(v176._countAndFlagsBits, v33, &v177, v67, v178, v68);
            uint64_t v69 = v173;
            DataFrame.append<A>(column:)(v173, v67);
            outlined consume of Result<_DataTable, Error>(v180, 0);
            uint64_t v54 = v69;
            uint64_t v55 = v159;
            uint64_t v56 = v160;
            goto LABEL_39;
          }
          uint64_t v179 = 0;
        }
        outlined consume of Result<_DataTable, Error>(v62, v60);
        outlined consume of Result<_DataTable, Error>(v181, v179);
        BUG();
      case 4:
        if ((_BYTE)v179)
        {
          uint64_t v142 = v181;
          outlined copy of Result<_DataTable, Error>(v181, 1);
          outlined copy of Result<_DataTable, Error>(v142, 1);
          swift_willThrow();
          v177._uint64_t countAndFlagsBits = 0;
          v177._char object = (void *)0xE000000000000000;
          _StringGuts.grow(_:)(34);
          swift_bridgeObjectRelease(v177._object);
          v177._uint64_t countAndFlagsBits = 0xD00000000000001FLL;
          v177._char object = "ml.activityclassifier" + 0x8000000000000000;
          v143._uint64_t countAndFlagsBits = v176._countAndFlagsBits;
          v143._char object = v33;
          String.append(_:)(v143);
          v143._char object = (void *)0xE100000000000000;
          v143._uint64_t countAndFlagsBits = 34;
          String.append(_:)(v143);
          Swift::String v176 = v177;
          uint64_t v144 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v99 = swift_allocError(&type metadata for MLCreateError, v144, 0, 0);
          *(Swift::String *)uint64_t v145 = v176;
          *(_OWORD *)(v145 + 16) = 0;
          *(_OWORD *)(v145 + 32) = 0;
          *(unsigned char *)(v145 + 48) = 1;
          outlined consume of Result<_DataTable, Error>(v181, v179);
          char v97 = 1;
        }
        else
        {
          uint64_t v94 = v181;
          uint64_t v180 = *(void *)(v181 + 16);
          outlined copy of Result<_DataTable, Error>(v181, 0);
          uint64_t v95 = v94;
          uint64_t v96 = v180;
          outlined copy of Result<_DataTable, Error>(v95, 0);
          swift_retain();
          uint64_t v178 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.column(name:), v96, v176._countAndFlagsBits, (uint64_t)v33);
          uint64_t v170 = 0;
          uint64_t v175 = v33;
          swift_release();
          char v97 = 0;
          uint64_t v98 = type metadata accessor for _UntypedColumn();
          uint64_t v99 = swift_allocObject(v98, 24, 7);
          *(void *)(v99 + 16) = v178;
          uint64_t v100 = v181;
          outlined consume of Result<_DataTable, Error>(v181, 0);
          outlined copy of Result<_DataTable, Error>(v99, 0);
          _UntypedColumn.type.getter();
          outlined consume of Result<_DataTable, Error>(v99, 0);
          if (LOBYTE(v177._countAndFlagsBits) == 4)
          {
            outlined consume of Result<_DataTable, Error>(v100, 0);
            uint64_t v101 = v99;
            outlined copy of Result<_DataTable, Error>(v99, 0);
            uint64_t v102 = CMLColumn.size.getter();
            outlined consume of Result<_DataTable, Error>(v101, 0);
            if (v102 < 0) {
              BUG();
            }
            uint64_t v180 = v101;
            outlined copy of Result<_DataTable, Error>(v101, 0);
            uint64_t v29 = v170;
            ML11MLDataValueO3key_AI5valuetGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G26O3key_AH5valuetGSgSiXEfU3_AG0F6ColumnVyAI14DictionaryTypeVGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_Say8CreateML11MLDataValueO3key_AI5valuetGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G26O3key_AH5valuetGSgSiXEfU3_AG0F6ColumnVyAI14DictionaryTypeVGTf1cn_n(0, v102, v101, 0, v32);
            uint64_t v104 = specialized _arrayForceCast<A, B>(_:)((uint64_t)ML11MLDataValueO3key_AI5valuetGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G26O3key_AH5valuetGSgSiXEfU3_AG0F6ColumnVyAI14DictionaryTypeVGTf1cn_n);
            swift_bridgeObjectRelease(ML11MLDataValueO3key_AI5valuetGSgs5NeverOTg5025_s11TabularData0B5FrameV8d9MLEyAcD11f17TableVcfcSayAD0F5G26O3key_AH5valuetGSgSiXEfU3_AG0F6ColumnVyAI14DictionaryTypeVGTf1cn_n);
            v177._uint64_t countAndFlagsBits = (uint64_t)v104;
            uint64_t v105 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [(MLDataValue, MLDataValue)]);
            uint64_t v178 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [[(MLDataValue, MLDataValue)]?]);
            uint64_t v106 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [[(MLDataValue, MLDataValue)]?] and conformance [A], &demangling cache variable for type metadata for [[(MLDataValue, MLDataValue)]?], (uint64_t)&protocol conformance descriptor for [A]);
            uint64_t v107 = v158;
            Column.init<A>(name:contents:)(v176._countAndFlagsBits, v175, &v177, v105, v178, v106);
            DataFrame.append<A>(column:)(v107, v105);
            outlined consume of Result<_DataTable, Error>(v180, 0);
            uint64_t v54 = v107;
            uint64_t v55 = v156;
            uint64_t v56 = v157;
            goto LABEL_39;
          }
          uint64_t v179 = 0;
        }
        outlined consume of Result<_DataTable, Error>(v99, v97);
        outlined consume of Result<_DataTable, Error>(v181, v179);
        BUG();
      case 5:
        if ((_BYTE)v179)
        {
          uint64_t v146 = v181;
          outlined copy of Result<_DataTable, Error>(v181, 1);
          outlined copy of Result<_DataTable, Error>(v146, 1);
          swift_willThrow();
          v177._uint64_t countAndFlagsBits = 0;
          v177._char object = (void *)0xE000000000000000;
          _StringGuts.grow(_:)(34);
          swift_bridgeObjectRelease(v177._object);
          v177._uint64_t countAndFlagsBits = 0xD00000000000001FLL;
          v177._char object = "ml.activityclassifier" + 0x8000000000000000;
          v147._uint64_t countAndFlagsBits = v176._countAndFlagsBits;
          v147._char object = v33;
          String.append(_:)(v147);
          v147._char object = (void *)0xE100000000000000;
          v147._uint64_t countAndFlagsBits = 34;
          String.append(_:)(v147);
          Swift::String v176 = v177;
          uint64_t v148 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          uint64_t v113 = swift_allocError(&type metadata for MLCreateError, v148, 0, 0);
          *(Swift::String *)uint64_t v149 = v176;
          *(_OWORD *)(v149 + 16) = 0;
          *(_OWORD *)(v149 + 32) = 0;
          *(unsigned char *)(v149 + 48) = 1;
          outlined consume of Result<_DataTable, Error>(v181, v179);
          char v111 = 1;
        }
        else
        {
          uint64_t v108 = v181;
          uint64_t v180 = *(void *)(v181 + 16);
          outlined copy of Result<_DataTable, Error>(v181, 0);
          uint64_t v109 = v108;
          uint64_t v110 = v180;
          outlined copy of Result<_DataTable, Error>(v109, 0);
          swift_retain();
          uint64_t v178 = specialized String.withCString<A>(_:)((uint64_t (*)(void))partial apply for closure #1 in CMLTable.column(name:), v110, v176._countAndFlagsBits, (uint64_t)v33);
          uint64_t v175 = 0;
          swift_release();
          char v111 = 0;
          uint64_t v112 = type metadata accessor for _UntypedColumn();
          uint64_t v113 = swift_allocObject(v112, 24, 7);
          *(void *)(v113 + 16) = v178;
          outlined consume of Result<_DataTable, Error>(v181, 0);
          outlined copy of Result<_DataTable, Error>(v113, 0);
          _UntypedColumn.type.getter();
          outlined consume of Result<_DataTable, Error>(v113, 0);
          if (LOBYTE(v177._countAndFlagsBits) == 5)
          {
            outlined consume of Result<_DataTable, Error>(v181, 0);
            uint64_t v114 = v113;
            outlined copy of Result<_DataTable, Error>(v113, 0);
            uint64_t v115 = CMLColumn.size.getter();
            uint64_t v180 = v114;
            outlined consume of Result<_DataTable, Error>(v114, 0);
            if (v115 < 0) {
              BUG();
            }
            uint64_t v116 = v180;
            outlined copy of Result<_DataTable, Error>(v180, 0);
            uint64_t v117 = v116;
            uint64_t v29 = v175;
            v177._uint64_t countAndFlagsBits = (uint64_t)_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSnySiG_So12MLMultiArrayCSgs5NeverOTg5059_s11TabularData0B5FrameV8CreateMLEyAcD11MLDataTableVcfcSo12dE11CSgSiXEfU4_0M2ML0Q6ColumnVyAM0Q5ValueO05MultiE4TypeVGTf1cn_n(0, v115, v117, 0, v32);
            uint64_t v118 = type metadata accessor for MLMultiArray();
            uint64_t v178 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLMultiArray?]);
            uint64_t v119 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [MLMultiArray?] and conformance [A], &demangling cache variable for type metadata for [MLMultiArray?], (uint64_t)&protocol conformance descriptor for [A]);
            Column.init<A>(name:contents:)(v176._countAndFlagsBits, v33, &v177, v118, v178, v119);
            double v120 = v172;
            DataFrame.append<A>(column:)(v172, v118);
            outlined consume of Result<_DataTable, Error>(v180, 0);
            uint64_t v54 = v120;
            uint64_t v55 = v154;
            uint64_t v56 = v155;
            goto LABEL_39;
          }
          uint64_t v179 = 0;
        }
        outlined consume of Result<_DataTable, Error>(v113, v111);
        outlined consume of Result<_DataTable, Error>(v181, v179);
        BUG();
      case 6:
        goto LABEL_17;
    }
  }
}

uint64_t DataFrame.randomSplit(strategy:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v39 = a2;
  uint64_t v40 = a1;
  uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame.Slice, DataFrame.Slice));
  int64_t v5 = *(void *)(*(void *)(v41 - 8) + 64);
  int64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  unint64_t v37 = &v36;
  unint64_t v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v38 = &v36;
  int64_t v10 = alloca(v5);
  uint64_t v11 = alloca(v5);
  uint64_t v42 = &v36;
  uint64_t v12 = type metadata accessor for DataFrame.Rows(0);
  uint64_t v13 = *(void *)(v12 - 8);
  int64_t v14 = *(void *)(v13 + 64);
  uint64_t v15 = alloca(v14);
  int64_t v16 = alloca(v14);
  double v45 = *(double *)a3;
  uint64_t v44 = *(char **)(a3 + 8);
  char v46 = *(unsigned char *)(a3 + 16);
  LOBYTE(a3) = *(unsigned char *)(a3 + 17);
  uint64_t v43 = v3;
  DataFrame.rows.getter();
  uint64_t v17 = DataFrame.Rows.count.getter();
  (*(void (**)(uint64_t *, uint64_t))(v13 + 8))(&v36, v12);
  if ((_BYTE)a3 != 1)
  {
    uint64_t v18 = 1;
    if ((v46 & 1) == 0) {
      uint64_t v18 = (uint64_t)v44;
    }
    if (v45 != 0.0) {
      goto LABEL_8;
    }
LABEL_7:
    uint64_t v19 = type metadata accessor for DataFrame.Slice(0);
    __swift_storeEnumTagSinglePayload(v40, 1, 1, v19);
    return specialized DataFrameProtocol.subscript.getter(0);
  }
  if (v17 < 50) {
    goto LABEL_7;
  }
  double v45 = dbl_348EB0[(unint64_t)v17 < 0xC8];
  uint64_t v18 = 1;
LABEL_8:
  uint64_t v21 = v41;
  uint64_t v22 = v42;
  uint64_t v44 = (char *)v42 + *(int *)(v41 + 48);
  uint64_t v23 = v44;
  uint64_t v24 = type metadata accessor for DataFrame(0);
  DataFrameProtocol.randomSplit(by:seed:)(v22, v23, v18, 0, v24, &protocol witness table for DataFrame, v45);
  uint64_t v25 = *(int *)(v21 + 48);
  uint64_t v26 = v38;
  uint64_t v27 = (char *)v38 + v25;
  double v45 = *(double *)&v27;
  uint64_t v28 = type metadata accessor for DataFrame.Slice(0);
  uint64_t v29 = *(void *)(v28 - 8);
  uint64_t v30 = *(void (**)(uint64_t *, uint64_t *, uint64_t))(v29 + 16);
  uint64_t v43 = v29;
  v30(v26, v42, v28);
  v30((uint64_t *)v27, (uint64_t *)v44, v28);
  Swift::String v31 = *(void (**)(uint64_t, uint64_t *, uint64_t))(v29 + 32);
  uint64_t v32 = v40;
  v31(v40, v26, v28);
  __swift_storeEnumTagSinglePayload(v32, 0, 1, v28);
  __m128 v33 = v37;
  uint64_t v34 = (char *)v37 + *(int *)(v41 + 48);
  v31((uint64_t)v37, v42, v28);
  v31((uint64_t)v34, (uint64_t *)v44, v28);
  v31(v39, (uint64_t *)v34, v28);
  uint64_t v35 = *(void (**)(uint64_t *, uint64_t))(v43 + 8);
  v35(v33, v28);
  return ((uint64_t (*)(void, uint64_t))v35)(*(void *)&v45, v28);
}

uint64_t MLUntypedColumn.init(_:convertArraysToShapedArrays:)(uint64_t a1, int a2, __m128 a3)
{
  uint64_t v618 = v4;
  int v612 = a2;
  v535 = v3;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Int32>?)
                             - 8)
                 + 64);
  int64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  v582 = &v520;
  unint64_t v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  v572 = &v520;
  uint64_t v596 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLShapedArray<Int32>>);
  uint64_t v554 = *(void *)(v596 - 8);
  int64_t v10 = *(void *)(v554 + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  v597 = &v520;
  int64_t v13 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>?)
                              - 8)
                  + 64);
  int64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  v583 = &v520;
  int64_t v16 = alloca(v13);
  uint64_t v17 = alloca(v13);
  v573 = &v520;
  uint64_t v598 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLShapedArray<Double>>);
  uint64_t v555 = *(void *)(v598 - 8);
  int64_t v18 = *(void *)(v555 + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  v599 = &v520;
  int64_t v21 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>?)
                              - 8)
                  + 64);
  uint64_t v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  v584 = &v520;
  uint64_t v24 = alloca(v21);
  uint64_t v25 = alloca(v21);
  v574 = &v520;
  uint64_t v600 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLShapedArray<Float>>);
  uint64_t v556 = *(void *)(v600 - 8);
  int64_t v26 = *(void *)(v556 + 64);
  uint64_t v27 = alloca(v26);
  uint64_t v28 = alloca(v26);
  v601 = &v520;
  uint64_t v594 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<MLMultiArray>);
  uint64_t v557 = *(void *)(v594 - 8);
  int64_t v29 = *(void *)(v557 + 64);
  uint64_t v30 = alloca(v29);
  Swift::String v31 = alloca(v29);
  v595 = &v520;
  uint64_t v604 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[AnyHashable : Any?]>);
  uint64_t v571 = *(void *)(v604 - 8);
  int64_t v32 = *(void *)(v571 + 64);
  __m128 v33 = alloca(v32);
  uint64_t v34 = alloca(v32);
  v605 = &v520;
  int64_t v35 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Any]>)
                              - 8)
                  + 64);
  uint64_t v36 = alloca(v35);
  unint64_t v37 = alloca(v35);
  v559 = &v520;
  int64_t v38 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Any?]>)
                              - 8)
                  + 64);
  uint64_t v39 = alloca(v38);
  uint64_t v40 = alloca(v38);
  v553 = &v520;
  int64_t v41 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : String]>)
                              - 8)
                  + 64);
  uint64_t v42 = alloca(v41);
  uint64_t v43 = alloca(v41);
  v552 = &v520;
  int64_t v44 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Float]>)
                              - 8)
                  + 64);
  double v45 = alloca(v44);
  char v46 = alloca(v44);
  v551 = &v520;
  int64_t v47 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Double]>)
                              - 8)
                  + 64);
  uint64_t v48 = alloca(v47);
  uint64_t v49 = alloca(v47);
  v550 = &v520;
  int64_t v50 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String : Int]>)
                              - 8)
                  + 64);
  uint64_t v51 = alloca(v50);
  uint64_t v52 = alloca(v50);
  v549 = &v520;
  int64_t v53 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Any]>)
                              - 8)
                  + 64);
  uint64_t v54 = alloca(v53);
  uint64_t v55 = alloca(v53);
  v548 = &v520;
  int64_t v56 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Any?]>)
                              - 8)
                  + 64);
  uint64_t v57 = alloca(v56);
  uint64_t v58 = alloca(v56);
  v547 = &v520;
  int64_t v59 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String]>)
                              - 8)
                  + 64);
  char v60 = alloca(v59);
  uint64_t v61 = alloca(v59);
  v546 = &v520;
  uint64_t v593 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  uint64_t v580 = *(void *)(v593 - 8);
  int64_t v62 = *(void *)(v580 + 64);
  uint64_t v63 = alloca(v62);
  uint64_t v64 = alloca(v62);
  v575 = &v520;
  uint64_t v65 = alloca(v62);
  uint64_t v66 = alloca(v62);
  v541 = &v520;
  uint64_t v67 = alloca(v62);
  uint64_t v68 = alloca(v62);
  v568 = &v520;
  uint64_t v581 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Double]>);
  uint64_t v570 = *(void *)(v581 - 8);
  int64_t v69 = *(void *)(v570 + 64);
  uint64_t v70 = alloca(v69);
  uint64_t v71 = alloca(v69);
  v545 = &v520;
  uint64_t v72 = alloca(v69);
  char v73 = alloca(v69);
  v609 = &v520;
  uint64_t v592 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  uint64_t v579 = *(void *)(v592 - 8);
  int64_t v74 = *(void *)(v579 + 64);
  uint64_t v75 = alloca(v74);
  uint64_t v76 = alloca(v74);
  v576 = &v520;
  uint64_t v77 = alloca(v74);
  uint64_t v78 = alloca(v74);
  v540 = &v520;
  uint64_t v79 = alloca(v74);
  uint64_t v80 = alloca(v74);
  v566 = &v520;
  uint64_t v565 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Float]>);
  uint64_t v569 = *(void *)(v565 - 8);
  int64_t v81 = *(void *)(v569 + 64);
  uint64_t v82 = alloca(v81);
  uint64_t v83 = alloca(v81);
  v544 = &v520;
  uint64_t v84 = alloca(v81);
  char v85 = alloca(v81);
  v588 = &v520;
  uint64_t v563 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int32]>);
  uint64_t v543 = *(void *)(v563 - 8);
  int64_t v86 = *(void *)(v543 + 64);
  uint64_t v87 = alloca(v86);
  uint64_t v88 = alloca(v86);
  v587 = &v520;
  uint64_t v603 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Int32>);
  uint64_t v577 = *(void *)(v603 - 8);
  int64_t v89 = *(void *)(v577 + 64);
  uint64_t v90 = alloca(v89);
  uint64_t v91 = alloca(v89);
  v558 = &v520;
  uint64_t v92 = alloca(v89);
  unint64_t v93 = alloca(v89);
  v564 = &v520;
  uint64_t v94 = alloca(v89);
  uint64_t v95 = alloca(v89);
  v586 = &v520;
  uint64_t v578 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int]>);
  uint64_t v567 = *(void *)(v578 - 8);
  int64_t v96 = *(void *)(v567 + 64);
  char v97 = alloca(v96);
  uint64_t v98 = alloca(v96);
  v542 = &v520;
  uint64_t v99 = alloca(v96);
  uint64_t v100 = alloca(v96);
  v536 = &v520;
  uint64_t v101 = alloca(v96);
  uint64_t v102 = alloca(v96);
  v591 = &v520;
  int64_t v103 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Date?)
                               - 8)
                   + 64);
  uint64_t v104 = alloca(v103);
  uint64_t v105 = alloca(v103);
  v537 = &v520;
  uint64_t v106 = alloca(v103);
  uint64_t v107 = alloca(v103);
  v538 = &v520;
  uint64_t v561 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Date>);
  uint64_t v562 = *(void *)(v561 - 8);
  int64_t v108 = *(void *)(v562 + 64);
  uint64_t v109 = alloca(v108);
  uint64_t v110 = alloca(v108);
  v613 = &v520;
  uint64_t v610 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v539 = *(void *)(v610 - 8);
  int64_t v111 = *(void *)(v539 + 64);
  uint64_t v112 = alloca(v111);
  uint64_t v113 = alloca(v111);
  *(void *)&long long v589 = &v520;
  uint64_t v617 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Double>);
  *(void *)&long long v585 = *(void *)(v617 - 8);
  int64_t v114 = *(void *)(v585 + 64);
  uint64_t v115 = alloca(v114);
  uint64_t v116 = alloca(v114);
  uint64_t v619 = (uint64_t)&v520;
  uint64_t v117 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Float>);
  int64_t v118 = *(void *)(v117 - 8);
  int64_t v119 = *(void *)(v118 + 64);
  double v120 = alloca(v119);
  uint64_t v121 = alloca(v119);
  v608 = &v520;
  uint64_t v122 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  int64_t v611 = *(void *)(v122 - 8);
  int64_t v123 = *(void *)(v611 + 64);
  uint64_t v124 = alloca(v123);
  uint64_t v125 = alloca(v123);
  *(void *)&long long v621 = &v520;
  uint64_t v616 = AnyColumn.wrappedElementType.getter();
  uint64_t v126 = swift_dynamicCastMetatype(v616, &type metadata for Int);
  uint64_t v622 = a1;
  if (v126)
  {
    double v127 = AnyColumn.assumingType<A>(_:)(&type metadata for Int, &type metadata for Int);
    uint64_t v128 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Int> and conformance Column<A>, &demangling cache variable for type metadata for Column<Int>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v129 = dispatch thunk of Collection.count.getter(v122, v128);
    unint64_t v623 = v122;
    if (v129)
    {
      uint64_t v130 = v129;
      v607[0] = _swiftEmptyArrayStorage;
      int64_t v131 = 0;
      if (v129 > 0) {
        int64_t v131 = v129;
      }
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v131, 0);
      uint64_t v617 = v607[0];
      dispatch thunk of Collection.startIndex.getter(v122, v128);
      uint64_t v619 = v130;
      if (v130 < 0) {
        BUG();
      }
      uint64_t v620 = v128;
      Swift::String v132 = (void *)v617;
      do
      {
        uint64_t v133 = (void (*)(_OWORD *, void, double))dispatch thunk of Collection.subscript.read(v614, v590, v623, v620);
        uint64_t v135 = *(void *)v134;
        if (*(unsigned char *)(v134 + 8)) {
          uint64_t v135 = 0;
        }
        char v136 = 0;
        if (*(unsigned char *)(v134 + 8)) {
          char v136 = 6;
        }
        v133(v614, 0, v127);
        v607[0] = v132;
        unint64_t v137 = v132[2];
        unint64_t v138 = v132[3];
        unint64_t v139 = v137 + 1;
        if (v138 >> 1 <= v137)
        {
          uint64_t v617 = v135;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v138 >= 2, v137 + 1, 1);
          unint64_t v139 = v137 + 1;
          uint64_t v135 = v617;
          Swift::String v132 = (void *)v607[0];
        }
        v132[2] = v139;
        uint64_t v140 = 3 * v137;
        v132[v140 + 4] = v135;
        v132[v140 + 5] = 0;
        LOBYTE(v132[v140 + 6]) = v136;
        dispatch thunk of Collection.formIndex(after:)(v590, v623, v620);
        --v619;
      }
      while (v619);
    }
    else
    {
      Swift::String v132 = _swiftEmptyArrayStorage;
    }
    (*(void (**)(void, unint64_t))(v611 + 8))(v621, v623);
    *(void *)&v614[0] = v132;
    uint64_t v162 = alloca(24);
    uint64_t v163 = alloca(32);
    *((void *)&v521[0] + 1) = v614;
    uint64_t v164 = (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
LABEL_44:
    *(void *)&long long v621 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5(v164);
    char v189 = v188 & 1;
    uint64_t v190 = *(void *)&v614[0];
LABEL_45:
    swift_bridgeObjectRelease(v190);
    uint64_t v191 = type metadata accessor for AnyColumn(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v191 - 8) + 8))(v622, v191);
LABEL_46:
    uint64_t result = (uint64_t)v535;
    void *v535 = v621;
    *(unsigned char *)(result + 8) = v189 & 1;
    return result;
  }
  uint64_t v141 = v608;
  int64_t v611 = v118;
  uint64_t v142 = v117;
  Swift::String v143 = v536;
  uint64_t v144 = v616;
  if (swift_dynamicCastMetatype(v616, &type metadata for Float))
  {
    AnyColumn.assumingType<A>(_:)(&type metadata for Float, &type metadata for Float);
    uint64_t v145 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Float> and conformance Column<A>, &demangling cache variable for type metadata for Column<Float>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v146 = dispatch thunk of Collection.count.getter(v142, v145);
    if (v146)
    {
      v607[0] = _swiftEmptyArrayStorage;
      int64_t v147 = 0;
      if (v146 > 0) {
        int64_t v147 = v146;
      }
      *(void *)&long long v621 = v146;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v147, 0);
      unint64_t v623 = v607[0];
      uint64_t v148 = v145;
      dispatch thunk of Collection.startIndex.getter(v142, v145);
      uint64_t v149 = v621;
      if ((uint64_t)v621 < 0) {
        BUG();
      }
      Swift::String v150 = (void *)v623;
      uint64_t v151 = v608;
      uint64_t v620 = v142;
      do
      {
        *(void *)&long long v621 = v149;
        Swift::String v152 = v151;
        uint64_t v153 = (void (*)(_OWORD *, void))dispatch thunk of Collection.subscript.read(v614, v590, v142, v148);
        LOBYTE(v623) = *(unsigned char *)(v154 + 4) != 0;
        double v155 = 0.0;
        if (!(_BYTE)v623) {
          double v155 = *(float *)v154;
        }
        v153(v614, 0);
        v607[0] = v150;
        uint64_t v156 = v148;
        unint64_t v157 = v150[2];
        unint64_t v158 = v150[3];
        int64_t v159 = v157 + 1;
        if (v158 >> 1 <= v157)
        {
          uint64_t v619 = v156;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v158 >= 2, v159, 1);
          uint64_t v156 = v619;
          Swift::String v152 = v608;
          Swift::String v150 = (void *)v607[0];
        }
        char v160 = 5 * v623 + 1;
        v150[2] = v159;
        uint64_t v161 = 3 * v157;
        *(double *)&v150[v161 + 4] = v155;
        v150[v161 + 5] = 0;
        LOBYTE(v150[v161 + 6]) = v160;
        uint64_t v142 = v620;
        uint64_t v148 = v156;
        dispatch thunk of Collection.formIndex(after:)(v590, v620, v156);
        uint64_t v149 = v621 - 1;
        uint64_t v151 = v152;
      }
      while ((void)v621 != 1);
    }
    else
    {
      Swift::String v150 = _swiftEmptyArrayStorage;
      uint64_t v151 = v141;
    }
    (*(void (**)(uint64_t *, uint64_t))(v611 + 8))(v151, v142);
    *(void *)&v614[0] = v150;
    uint64_t v186 = alloca(24);
    uint64_t v187 = alloca(32);
    *((void *)&v521[0] + 1) = v614;
    uint64_t v164 = (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
    goto LABEL_44;
  }
  if (swift_dynamicCastMetatype(v144, &type metadata for Double))
  {
    double v165 = AnyColumn.assumingType<A>(_:)(&type metadata for Double, &type metadata for Double);
    uint64_t v166 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Double> and conformance Column<A>, &demangling cache variable for type metadata for Column<Double>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v167 = v617;
    uint64_t v168 = dispatch thunk of Collection.count.getter(v617, v166);
    if (v168)
    {
      uint64_t v169 = v168;
      v607[0] = _swiftEmptyArrayStorage;
      int64_t v170 = 0;
      if (v168 > 0) {
        int64_t v170 = v168;
      }
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v170, 0);
      uint64_t v171 = v166;
      *(void *)&long long v621 = v607[0];
      uint64_t v172 = v167;
      unint64_t v623 = v171;
      dispatch thunk of Collection.startIndex.getter(v167, v171);
      uint64_t v620 = v169;
      if (v169 < 0) {
        BUG();
      }
      uint64_t v173 = v623;
      do
      {
        uint64_t v174 = (void (*)(_OWORD *, void, double))dispatch thunk of Collection.subscript.read(v614, v590, v172, v173);
        if (*((unsigned char *)v175 + 8)) {
          uint64_t v176 = 0;
        }
        else {
          uint64_t v176 = *v175;
        }
        uint64_t v177 = v621;
        BOOL v178 = *((unsigned char *)v175 + 8) != 0;
        v174(v614, 0, v165);
        v607[0] = v177;
        unint64_t v179 = *(void *)(v177 + 16);
        unint64_t v180 = *(void *)(v177 + 24);
        unint64_t v181 = v179 + 1;
        if (v180 >> 1 <= v179)
        {
          LOBYTE(v621) = v178;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v180 >= 2, v179 + 1, 1);
          unint64_t v181 = v179 + 1;
          BOOL v178 = v621;
          uint64_t v177 = v607[0];
        }
        *(void *)(v177 + 16) = v181;
        uint64_t v182 = 24 * v179;
        *(void *)(v177 + v182 + 32) = v176;
        *(void *)(v177 + v182 + 40) = 0;
        *(void *)&long long v621 = v177;
        *(unsigned char *)(v177 + v182 + 48) = 5 * v178 + 1;
        uint64_t v183 = v619;
        uint64_t v172 = v617;
        uint64_t v173 = v623;
        dispatch thunk of Collection.formIndex(after:)(v590, v617, v623);
        BOOL v184 = v620-- == 1;
        uint64_t v185 = v585;
      }
      while (!v184);
      uint64_t v193 = v183;
      uint64_t v167 = v172;
      char v194 = (void *)v621;
    }
    else
    {
      char v194 = _swiftEmptyArrayStorage;
      uint64_t v185 = v585;
      uint64_t v193 = v619;
    }
    (*(void (**)(uint64_t, uint64_t))(v185 + 8))(v193, v167);
    *(void *)&v614[0] = v194;
    uint64_t v212 = alloca(24);
    v213 = alloca(32);
    *((void *)&v521[0] + 1) = v614;
    uint64_t v164 = (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
    goto LABEL_44;
  }
  if (swift_dynamicCastMetatype(v144, &type metadata for String))
  {
    uint64_t v195 = v589;
    double v196 = AnyColumn.assumingType<A>(_:)(&type metadata for String, &type metadata for String);
    uint64_t v197 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v198 = v610;
    uint64_t v199 = dispatch thunk of Collection.count.getter(v610, v197);
    if (v199)
    {
      v607[0] = _swiftEmptyArrayStorage;
      int64_t v200 = 0;
      if (v199 > 0) {
        int64_t v200 = v199;
      }
      *(void *)&long long v621 = v199;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v200, 0);
      unint64_t v623 = v607[0];
      dispatch thunk of Collection.startIndex.getter(v198, v197);
      uint64_t v201 = v621;
      if ((uint64_t)v621 < 0) {
        BUG();
      }
      uint64_t v619 = v197;
      do
      {
        *(void *)&long long v621 = v201;
        uint64_t v203 = (void (*)(_OWORD *, void, double))dispatch thunk of Collection.subscript.read(v614, v590, v198, v197);
        uint64_t v204 = v202[1];
        uint64_t v205 = v204;
        if (v204) {
          uint64_t v205 = *v202;
        }
        uint64_t v620 = v205;
        swift_bridgeObjectRetain(v204);
        v203(v614, 0, v196);
        uint64_t v206 = v623;
        v607[0] = v623;
        unint64_t v207 = *(void *)(v623 + 16);
        unint64_t v208 = *(void *)(v623 + 24);
        int64_t v209 = v207 + 1;
        if (v208 >> 1 <= v207)
        {
          unint64_t v623 = v207 + 1;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v208 >= 2, v209, 1);
          int64_t v209 = v623;
          uint64_t v206 = v607[0];
        }
        *(void *)(v206 + 16) = v209;
        uint64_t v210 = 24 * v207;
        *(void *)(v206 + v210 + 32) = v620;
        *(void *)(v206 + v210 + 40) = v204;
        unint64_t v623 = v206;
        *(unsigned char *)(v206 + v210 + 48) = (4 * (v204 == 0)) | 2;
        uint64_t v211 = v589;
        uint64_t v198 = v610;
        uint64_t v197 = v619;
        dispatch thunk of Collection.formIndex(after:)(v590, v610, v619);
        uint64_t v201 = v621 - 1;
      }
      while ((void)v621 != 1);
      uint64_t v214 = (void *)v623;
      uint64_t v195 = v211;
    }
    else
    {
      uint64_t v214 = _swiftEmptyArrayStorage;
    }
    (*(void (**)(uint64_t, uint64_t))(v539 + 8))(v195, v198);
    *(void *)&v614[0] = v214;
    uint64_t v233 = alloca(24);
    v234 = alloca(32);
    *((void *)&v521[0] + 1) = v614;
    uint64_t v164 = (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
    goto LABEL_44;
  }
  uint64_t v215 = type metadata accessor for Date(0);
  if (swift_dynamicCastMetatype(v144, v215))
  {
    uint64_t v620 = v215;
    double v216 = AnyColumn.assumingType<A>(_:)(v215, v215);
    uint64_t v217 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Date> and conformance Column<A>, &demangling cache variable for type metadata for Column<Date>, (uint64_t)&protocol conformance descriptor for Column<A>);
    uint64_t v218 = v561;
    uint64_t v219 = dispatch thunk of Collection.count.getter(v561, v217);
    if (v219)
    {
      uint64_t v220 = v219;
      v607[0] = _swiftEmptyArrayStorage;
      int64_t v221 = 0;
      if (v219 > 0) {
        int64_t v221 = v219;
      }
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v221, 0);
      unint64_t v623 = v217;
      dispatch thunk of Collection.startIndex.getter(v218, v217);
      uint64_t v619 = v220;
      if (v220 < 0) {
        BUG();
      }
      uint64_t v222 = v623;
      do
      {
        uint64_t v223 = (void (*)(_OWORD *, void, double))dispatch thunk of Collection.subscript.read(v614, v590, v218, v222);
        uint64_t v224 = (uint64_t)v538;
        outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v225, (uint64_t)v538, &demangling cache variable for type metadata for Date?);
        v223(v614, 0, v216);
        uint64_t v226 = (uint64_t)v537;
        outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v224, (uint64_t)v537, &demangling cache variable for type metadata for Date?);
        uint64_t v227 = v620;
        if (__swift_getEnumTagSinglePayload(v226, 1, v620) == 1)
        {
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v226, &demangling cache variable for type metadata for Date?);
          char v228 = 6;
          *(void *)&long long v621 = 0;
        }
        else
        {
          *(void *)&long long v621 = Date.timeIntervalSince1970.getter(v226);
          (*(void (**)(uint64_t, uint64_t))(*(void *)(v227 - 8) + 8))(v226, v227);
          char v228 = 1;
        }
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v224, &demangling cache variable for type metadata for Date?);
        v229 = (void *)v607[0];
        if (!swift_isUniquelyReferenced_nonNull_native(v607[0]))
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v229[2] + 1, 1);
          v229 = (void *)v607[0];
        }
        unint64_t v230 = v229[2];
        if (v229[3] >> 1 <= v230)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v229[3] >= 2uLL, v230 + 1, 1);
          v229 = (void *)v607[0];
        }
        v229[2] = v230 + 1;
        uint64_t v231 = 3 * v230;
        double v216 = *(double *)&v621;
        v229[v231 + 4] = v621;
        v229[v231 + 5] = 0;
        LOBYTE(v229[v231 + 6]) = v228;
        uint64_t v218 = v561;
        uint64_t v222 = v623;
        dispatch thunk of Collection.formIndex(after:)(v590, v561, v623);
        BOOL v184 = v619-- == 1;
        uint64_t v232 = v562;
      }
      while (!v184);
    }
    else
    {
      v229 = _swiftEmptyArrayStorage;
      uint64_t v232 = v562;
    }
    (*(void (**)(uint64_t *, uint64_t))(v232 + 8))(v613, v218);
    *(void *)&v614[0] = v229;
    v279 = alloca(24);
    v280 = alloca(32);
    *((void *)&v521[0] + 1) = v614;
    uint64_t v164 = (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
    goto LABEL_44;
  }
  uint64_t v235 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int]);
  if (!swift_dynamicCastMetatype(v144, v235))
  {
    uint64_t v619 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int32]);
    if (swift_dynamicCastMetatype(v144, v619))
    {
      if (v612)
      {
        double v281 = AnyColumn.assumingType<A>(_:)(v619, v619);
        uint64_t v282 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Int32]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Int32]>, (uint64_t)&protocol conformance descriptor for Column<A>);
        uint64_t v283 = v563;
        uint64_t v284 = dispatch thunk of Collection.count.getter(v563, v282);
        if (v284)
        {
          v607[0] = _swiftEmptyArrayStorage;
          int64_t v285 = 0;
          if (v284 > 0) {
            int64_t v285 = v284;
          }
          *(void *)&long long v621 = v284;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v285, 0);
          uint64_t v286 = v283;
          uint64_t v287 = v283;
          uint64_t v288 = v282;
          dispatch thunk of Collection.startIndex.getter(v287, v282);
          uint64_t v289 = v621;
          if ((uint64_t)v621 < 0) {
            BUG();
          }
          uint64_t v290 = v286;
          uint64_t v620 = v288;
          do
          {
            *(void *)&long long v621 = v289;
            v291 = (void (*)(_OWORD *, void, double))dispatch thunk of Collection.subscript.read(v614, v590, v290, v288);
            uint64_t v293 = *v292;
            swift_bridgeObjectRetain(*v292);
            v291(v614, 0, v281);
            if (v293)
            {
              *(void *)&v614[0] = v293;
              uint64_t v294 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
              v295 = (void *)swift_allocObject(v294, 40, 7);
              v295[2] = 1;
              v295[3] = 2;
              v295[4] = *(void *)(v293 + 16);
              uint64_t v296 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Int32] and conformance [A], &demangling cache variable for type metadata for [Int32], (uint64_t)&protocol conformance descriptor for [A]);
              swift_bridgeObjectRetain(v293);
              v297 = v586;
              MLShapedArray.init<A>(scalars:shape:)(v614, v295, &type metadata for Int32, v619, &protocol witness table for Int32, v296);
              unint64_t v623 = type metadata accessor for MLMultiArray();
              v298 = v564;
              v299 = v297;
              uint64_t v300 = v603;
              uint64_t v301 = v577;
              (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v577 + 16))(v564, v299, v603);
              uint64_t v302 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Int32> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Int32>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
              v303.super.Class isa = (Class)MLMultiArray.init<A>(_:)(v298, v300, v302);
              MLDataValue.MultiArrayType.init(_:)(v303);
              (*(void (**)(uint64_t *, uint64_t))(v301 + 8))(v586, v300);
              swift_bridgeObjectRelease(v293);
              uint64_t v304 = *(void *)&v614[0];
              char v305 = 5;
            }
            else
            {
              char v305 = 6;
              uint64_t v304 = 0;
            }
            v306 = (void *)v607[0];
            if (!swift_isUniquelyReferenced_nonNull_native(v607[0]))
            {
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v306[2] + 1, 1);
              v306 = (void *)v607[0];
            }
            uint64_t v307 = v620;
            unint64_t v308 = v306[2];
            unint64_t v309 = v306[3];
            int64_t v310 = v308 + 1;
            if (v309 >> 1 <= v308)
            {
              LOBYTE(v623) = v305;
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v309 >= 2, v310, 1);
              uint64_t v307 = v620;
              char v305 = v623;
              v306 = (void *)v607[0];
            }
            v306[2] = v310;
            uint64_t v311 = 3 * v308;
            v306[v311 + 4] = v304;
            v306[v311 + 5] = 0;
            LOBYTE(v306[v311 + 6]) = v305;
            uint64_t v290 = v563;
            uint64_t v288 = v307;
            dispatch thunk of Collection.formIndex(after:)(v590, v563, v307);
            uint64_t v289 = v621 - 1;
          }
          while ((void)v621 != 1);
          uint64_t v283 = v290;
        }
        else
        {
          v306 = _swiftEmptyArrayStorage;
        }
        (*(void (**)(uint64_t *, uint64_t))(v543 + 8))(v587, v283);
        *(void *)&v614[0] = v306;
        v382 = alloca(24);
        v383 = alloca(32);
        *((void *)&v521[0] + 1) = v614;
LABEL_172:
        *(void *)&long long v621 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
        char v189 = v387 & 1;
        uint64_t v190 = *(void *)&v614[0];
        goto LABEL_45;
      }
      v348 = v542;
      uint64_t v349 = v235;
      uint64_t v350 = v235;
      uint64_t v314 = v622;
      *(double *)a3.i64 = AnyColumn.assumingType<A>(_:)(v349, v350);
      uint64_t v315 = (uint64_t)v348;
      goto LABEL_146;
    }
    uint64_t v619 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
    if (swift_dynamicCastMetatype(v144, v619))
    {
      if (v612)
      {
        double v321 = AnyColumn.assumingType<A>(_:)(v619, v619);
        uint64_t v322 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Float]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Float]>, (uint64_t)&protocol conformance descriptor for Column<A>);
        uint64_t v323 = v565;
        uint64_t v324 = dispatch thunk of Collection.count.getter(v565, v322);
        if (v324)
        {
          v607[0] = _swiftEmptyArrayStorage;
          int64_t v327 = 0;
          if (v324 > 0) {
            int64_t v327 = v324;
          }
          *(void *)&long long v621 = v324;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v327, 0);
          uint64_t v620 = v322;
          dispatch thunk of Collection.startIndex.getter(v323, v322);
          uint64_t v328 = v621;
          if ((uint64_t)v621 < 0) {
            BUG();
          }
          uint64_t v329 = v620;
          do
          {
            *(void *)&long long v621 = v328;
            v330 = (void (*)(_OWORD *, void, double))dispatch thunk of Collection.subscript.read(v614, v590, v323, v329);
            uint64_t v332 = *v331;
            swift_bridgeObjectRetain(*v331);
            v330(v614, 0, v321);
            if (v332)
            {
              *(void *)&v614[0] = v332;
              uint64_t v333 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
              v334 = (void *)swift_allocObject(v333, 40, 7);
              v334[2] = 1;
              v334[3] = 2;
              v334[4] = *(void *)(v332 + 16);
              uint64_t v335 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float], (uint64_t)&protocol conformance descriptor for [A]);
              swift_bridgeObjectRetain(v332);
              v336 = v566;
              MLShapedArray.init<A>(scalars:shape:)(v614, v334, &type metadata for Float, v619, &protocol witness table for Float, v335);
              unint64_t v623 = type metadata accessor for MLMultiArray();
              v337 = v540;
              uint64_t v338 = v592;
              (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v579 + 16))(v540, v336, v592);
              uint64_t v339 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
              v340.super.Class isa = (Class)MLMultiArray.init<A>(_:)(v337, v338, v339);
              MLDataValue.MultiArrayType.init(_:)(v340);
              (*(void (**)(uint64_t *, uint64_t))(v579 + 8))(v336, v338);
              swift_bridgeObjectRelease(v332);
              uint64_t v341 = *(void *)&v614[0];
              char v342 = 5;
            }
            else
            {
              char v342 = 6;
              uint64_t v341 = 0;
            }
            v343 = (void *)v607[0];
            if (!swift_isUniquelyReferenced_nonNull_native(v607[0]))
            {
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v343[2] + 1, 1);
              v343 = (void *)v607[0];
            }
            unint64_t v344 = v343[2];
            unint64_t v345 = v343[3];
            unint64_t v346 = v344 + 1;
            if (v345 >> 1 <= v344)
            {
              unint64_t v623 = v341;
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v345 >= 2, v344 + 1, 1);
              unint64_t v346 = v344 + 1;
              uint64_t v341 = v623;
              v343 = (void *)v607[0];
            }
            v343[2] = v346;
            uint64_t v347 = 3 * v344;
            v343[v347 + 4] = v341;
            v343[v347 + 5] = 0;
            LOBYTE(v343[v347 + 6]) = v342;
            uint64_t v323 = v565;
            uint64_t v329 = v620;
            dispatch thunk of Collection.formIndex(after:)(v590, v565, v620);
            uint64_t v328 = v621 - 1;
            v326 = v614;
          }
          while ((void)v621 != 1);
        }
        else
        {
          v343 = _swiftEmptyArrayStorage;
        }
        (*(void (**)(uint64_t *, uint64_t, uint64_t, _OWORD *))(v569 + 8))(v588, v323, v325, v326);
        *(void *)&v614[0] = v343;
        v391 = alloca(24);
        v392 = alloca(32);
        *((void *)&v521[0] + 1) = v614;
        uint64_t v164 = (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
        goto LABEL_44;
      }
      uint64_t v384 = (uint64_t)v544;
      uint64_t v314 = v622;
      *(double *)a3.i64 = AnyColumn.assumingType<A>(_:)(v619, v619);
      uint64_t v351 = v618;
      specialized MLUntypedColumn.init<A>(_:)(v384, a3);
      goto LABEL_147;
    }
    uint64_t v617 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
    BOOL v184 = swift_dynamicCastMetatype(v144, v617) == 0;
    uint64_t v358 = v622;
    if (!v184)
    {
      if (v612)
      {
        double v359 = AnyColumn.assumingType<A>(_:)(v617, v617);
        uint64_t v360 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Double]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Double]>, (uint64_t)&protocol conformance descriptor for Column<A>);
        uint64_t v361 = v581;
        uint64_t v362 = dispatch thunk of Collection.count.getter(v581, v360);
        if (v362)
        {
          uint64_t v363 = v362;
          v607[0] = _swiftEmptyArrayStorage;
          int64_t v364 = 0;
          if (v362 > 0) {
            int64_t v364 = v362;
          }
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v364, 0);
          uint64_t v620 = v360;
          dispatch thunk of Collection.startIndex.getter(v361, v360);
          uint64_t v619 = v363;
          if (v363 < 0) {
            BUG();
          }
          uint64_t v365 = v620;
          uint64_t v366 = v581;
          do
          {
            v367 = (void (*)(_OWORD *, void, double))dispatch thunk of Collection.subscript.read(v614, v590, v366, v365);
            uint64_t v369 = *v368;
            swift_bridgeObjectRetain(*v368);
            v367(v614, 0, v359);
            if (v369)
            {
              *(void *)&v614[0] = v369;
              uint64_t v370 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
              v371 = (void *)swift_allocObject(v370, 40, 7);
              v371[2] = 1;
              v371[3] = 2;
              v371[4] = *(void *)(v369 + 16);
              uint64_t v372 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Double] and conformance [A], &demangling cache variable for type metadata for [Double], (uint64_t)&protocol conformance descriptor for [A]);
              swift_bridgeObjectRetain(v369);
              v373 = v568;
              MLShapedArray.init<A>(scalars:shape:)(v614, v371, &type metadata for Double, v617, &protocol witness table for Double, v372);
              *(void *)&long long v621 = type metadata accessor for MLMultiArray();
              v374 = v541;
              uint64_t v375 = v593;
              (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v580 + 16))(v541, v373, v593);
              uint64_t v376 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Double> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Double>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
              v377.super.Class isa = (Class)MLMultiArray.init<A>(_:)(v374, v375, v376);
              MLDataValue.MultiArrayType.init(_:)(v377);
              (*(void (**)(uint64_t *, uint64_t))(v580 + 8))(v373, v375);
              swift_bridgeObjectRelease(v369);
              unint64_t v623 = *(void *)&v614[0];
              LOBYTE(v621) = 5;
            }
            else
            {
              LOBYTE(v621) = 6;
              unint64_t v623 = 0;
            }
            v378 = (void *)v607[0];
            if (!swift_isUniquelyReferenced_nonNull_native(v607[0]))
            {
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v378[2] + 1, 1);
              v378 = (void *)v607[0];
            }
            unint64_t v379 = v378[2];
            unint64_t v380 = v379 + 1;
            if (v378[3] >> 1 <= v379)
            {
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v378[3] >= 2uLL, v379 + 1, 1);
              unint64_t v380 = v379 + 1;
              v378 = (void *)v607[0];
            }
            v378[2] = v380;
            uint64_t v381 = 3 * v379;
            v378[v381 + 4] = v623;
            v378[v381 + 5] = 0;
            LOBYTE(v378[v381 + 6]) = v621;
            uint64_t v366 = v581;
            uint64_t v365 = v620;
            dispatch thunk of Collection.formIndex(after:)(v590, v581, v620);
            --v619;
          }
          while (v619);
          uint64_t v394 = v366;
        }
        else
        {
          uint64_t v394 = v361;
          v378 = _swiftEmptyArrayStorage;
        }
        (*(void (**)(uint64_t *, uint64_t))(v570 + 8))(v609, v394);
        *(void *)&v614[0] = v378;
        v400 = alloca(24);
        v401 = alloca(32);
        *((void *)&v521[0] + 1) = v614;
        uint64_t v164 = (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
        goto LABEL_44;
      }
      uint64_t v393 = (uint64_t)v545;
      *(double *)a3.i64 = AnyColumn.assumingType<A>(_:)(v617, v617);
      uint64_t v390 = v618;
      specialized MLUntypedColumn.init<A>(_:)(v393, a3);
      goto LABEL_179;
    }
    uint64_t v388 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
    if (swift_dynamicCastMetatype(v144, v388))
    {
      uint64_t v389 = (uint64_t)v546;
      *(double *)a3.i64 = AnyColumn.assumingType<A>(_:)(v388, v388);
      uint64_t v390 = v618;
      specialized MLUntypedColumn.init<A>(_:)(v389, a3);
LABEL_179:
      if (v390)
      {
        uint64_t v352 = type metadata accessor for AnyColumn(0);
        uint64_t v353 = *(void *)(v352 - 8);
        uint64_t v354 = v358;
        return (*(uint64_t (**)(uint64_t, uint64_t))(v353 + 8))(v354, v352);
      }
      uint64_t v355 = type metadata accessor for AnyColumn(0);
      uint64_t v356 = *(void *)(v355 - 8);
      uint64_t v357 = v358;
LABEL_151:
      (*(void (**)(uint64_t, uint64_t))(v356 + 8))(v357, v355);
      *(void *)&long long v621 = *(void *)&v614[0];
      char v189 = BYTE8(v614[0]);
      goto LABEL_46;
    }
    uint64_t v395 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Any?]);
    if (swift_dynamicCastMetatype(v144, v395))
    {
      uint64_t v396 = (uint64_t)v547;
      AnyColumn.assumingType<A>(_:)(v395, v395);
      v397 = &demangling cache variable for type metadata for Column<[Any?]>;
      v398 = (uint64_t *)&lazy protocol witness table cache variable for type Column<[Any?]> and conformance Column<A>;
      v399 = (void (*)(uint64_t))specialized closure #1 in MLUntypedColumn.init<A>(_:);
    }
    else
    {
      uint64_t v402 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Any]);
      if (!swift_dynamicCastMetatype(v616, v402))
      {
        uint64_t v404 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Int]);
        if (swift_dynamicCastMetatype(v616, v404))
        {
          uint64_t v405 = (uint64_t)v549;
          AnyColumn.assumingType<A>(_:)(v404, v404);
          v406 = &demangling cache variable for type metadata for Column<[String : Int]>;
          v407 = (uint64_t *)&lazy protocol witness table cache variable for type Column<[String : Int]> and conformance Column<A>;
          v408 = (uint64_t (*)(uint64_t))_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSSiG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSi_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_Si_TG5Tf3nnnpf_nTf1cn_n;
        }
        else
        {
          uint64_t v409 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Double]);
          if (swift_dynamicCastMetatype(v616, v409))
          {
            uint64_t v405 = (uint64_t)v550;
            AnyColumn.assumingType<A>(_:)(v409, v409);
            v406 = &demangling cache variable for type metadata for Column<[String : Double]>;
            v407 = (uint64_t *)&lazy protocol witness table cache variable for type Column<[String : Double]> and conformance Column<A>;
            v408 = (uint64_t (*)(uint64_t))_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSSdG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSd_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_Sd_TG5Tf3nnnpf_nTf1cn_n;
          }
          else
          {
            uint64_t v410 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Float]);
            if (swift_dynamicCastMetatype(v616, v410))
            {
              uint64_t v405 = (uint64_t)v551;
              AnyColumn.assumingType<A>(_:)(v410, v410);
              v406 = &demangling cache variable for type metadata for Column<[String : Float]>;
              v407 = (uint64_t *)&lazy protocol witness table cache variable for type Column<[String : Float]> and conformance Column<A>;
              v408 = (uint64_t (*)(uint64_t))_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSSfG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSf_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_Sf_TG5Tf3nnnpf_nTf1cn_n;
            }
            else
            {
              uint64_t v411 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : String]);
              if (swift_dynamicCastMetatype(v616, v411))
              {
                uint64_t v405 = (uint64_t)v552;
                AnyColumn.assumingType<A>(_:)(v411, v411);
                v406 = &demangling cache variable for type metadata for Column<[String : String]>;
                v407 = (uint64_t *)&lazy protocol witness table cache variable for type Column<[String : String]> and conformance Column<A>;
                v408 = (uint64_t (*)(uint64_t))_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDyS2SG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRSS_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_SS_TG5Tf3nnnpf_nTf1cn_n;
              }
              else
              {
                uint64_t v412 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any?]);
                if (swift_dynamicCastMetatype(v616, v412))
                {
                  uint64_t v405 = (uint64_t)v553;
                  AnyColumn.assumingType<A>(_:)(v412, v412);
                  v406 = &demangling cache variable for type metadata for Column<[String : Any?]>;
                  v407 = (uint64_t *)&lazy protocol witness table cache variable for type Column<[String : Any?]> and conformance Column<A>;
                  v408 = (uint64_t (*)(uint64_t))_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSypSgG_8CreateML11MLDataValueO_AJtsAE_pTg5022_sSS3key_xSg5valuetSg8d4ML11fg5OAGs5c138_pIgnrrzo_SSAA_AbCtAG_AGtsAH_pIegnrzr_lTRyp_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l20SDySSxSgGGKclufcAA11ef33OAHSgKXEfU_AK_AKtI31_AG5valuetsW8U_yp_Tg5Tf3nnnpf_nTf1cn_n;
                }
                else
                {
                  uint64_t v413 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : Any]);
                  if (!swift_dynamicCastMetatype(v616, v413))
                  {
                    uint64_t v414 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyHashable : Any?]);
                    if (swift_dynamicCastMetatype(v616, v414))
                    {
                      AnyColumn.assumingType<A>(_:)(v414, v414);
                      uint64_t v616 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[AnyHashable : Any?]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[AnyHashable : Any?]>, (uint64_t)&protocol conformance descriptor for Column<A>);
                      v608 = (uint64_t *)dispatch thunk of Collection.count.getter(v604, v616);
                      if (v608)
                      {
                        v602 = _swiftEmptyArrayStorage;
                        int64_t v415 = 0;
                        uint64_t v416 = (uint64_t)v608;
                        if ((uint64_t)v608 > 0) {
                          int64_t v415 = (int64_t)v608;
                        }
                        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v415, 0);
                        dispatch thunk of Collection.startIndex.getter(v604, v616);
                        if (v416 < 0) {
                          BUG();
                        }
                        v613 = 0;
                        do
                        {
                          if (v613 == v608) {
                            BUG();
                          }
                          v417 = (void (*)(_OWORD *, void))dispatch thunk of Collection.subscript.read(v614, v560, v604, v616);
                          uint64_t v419 = *v418;
                          swift_bridgeObjectRetain(*v418);
                          v417(v614, 0);
                          unint64_t v623 = v419;
                          if (v419)
                          {
                            int64_t v611 = *(void *)(v623 + 16);
                            if (v611)
                            {
                              v606 = _swiftEmptyArrayStorage;
                              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v611, 0);
                              uint64_t v420 = v623;
                              uint64_t v421 = specialized Dictionary.startIndex.getter(v623);
                              uint64_t v619 = v422;
                              uint64_t v423 = 1 << *(unsigned char *)(v420 + 32);
                              *(void *)&long long v621 = v421;
                              if (v421 < 0 || (uint64_t)v621 >= v423) {
LABEL_316:
                              }
                                BUG();
                              uint64_t v620 = v623 + 64;
                              while (1)
                              {
                                unint64_t v424 = (unint64_t)v621 >> 6;
                                uint64_t v425 = *(void *)(v620 + 8 * ((unint64_t)v621 >> 6));
                                uint64_t v617 = 1 << v621;
                                if (!_bittest64(&v425, v621)) {
                                  BUG();
                                }
                                if (*(_DWORD *)(v623 + 36) != v619) {
                                  BUG();
                                }
                                uint64_t v426 = v621;
                                uint64_t v427 = v623;
                                outlined init with copy of AnyHashable(*(void *)(v623 + 48) + 40 * v621, (uint64_t)v614);
                                outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v427 + 56) + 32 * v426, (uint64_t)v615, &demangling cache variable for type metadata for Any?);
                                outlined init with copy of AnyHashable((uint64_t)v614, (uint64_t)v607);
                                outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v615, (uint64_t)&v607[5], &demangling cache variable for type metadata for Any?);
                                qmemcpy(v590, v607, sizeof(v590));
                                outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v614, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?));
                                outlined init with copy of AnyHashable((uint64_t)v590, (uint64_t)v521);
                                outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v590[40], (uint64_t)v523, &demangling cache variable for type metadata for Any?);
                                v524[0] = v521[0];
                                v524[1] = v521[1];
                                uint64_t v525 = v522;
                                outlined init with take of Any?((uint64_t)v523, (uint64_t)v526);
                                uint64_t v428 = v618;
                                closure #1 in closure #10 in MLUntypedColumn.init(_:convertArraysToShapedArrays:)((uint64_t)&v531, (uint64_t)&v533, (uint64_t)v524);
                                uint64_t v618 = v428;
                                if (v428)
                                {
                                  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v524, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?)?);
                                  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v590, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?));
                                  v452 = v606;
                                  swift_bridgeObjectRelease(v623);
                                  swift_release(v452);
                                  swift_release(v602);
                                  uint64_t v453 = type metadata accessor for AnyColumn(0);
                                  (*(void (**)(uint64_t, uint64_t))(*(void *)(v453 - 8) + 8))(v622, v453);
                                  return (*(uint64_t (**)(uint64_t *, uint64_t))(v571 + 8))(v605, v604);
                                }
                                outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v524, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?)?);
                                outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v590, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?));
                                long long v585 = v531;
                                char v429 = v532;
                                long long v589 = v533;
                                LOBYTE(v610) = v534;
                                v430 = v606;
                                if (!swift_isUniquelyReferenced_nonNull_native(v606))
                                {
                                  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v430[2] + 1, 1);
                                  v430 = v606;
                                }
                                uint64_t v431 = v430[2];
                                specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)(v431);
                                long long v527 = v585;
                                char v528 = v429;
                                long long v529 = v589;
                                char v530 = v610;
                                specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)(v431, (uint64_t)&v527);
                                MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
                                uint64_t v432 = -1 << *(unsigned char *)(v623 + 32);
                                if ((uint64_t)v621 >= -v432) {
                                  BUG();
                                }
                                if ((v617 & *(void *)(v620 + 8 * v424)) == 0) {
                                  BUG();
                                }
                                if (*(_DWORD *)(v623 + 36) != v619) {
                                  BUG();
                                }
                                *(void *)&long long v621 = _HashTable.occupiedBucket(after:)(v621, v620, ~v432);
                                if (!--v611) {
                                  break;
                                }
                                uint64_t v433 = 1 << *(unsigned char *)(v623 + 32);
                                if ((uint64_t)v621 >= 0)
                                {
                                  uint64_t v619 = *(unsigned int *)(v623 + 36);
                                  if ((uint64_t)v621 < v433) {
                                    continue;
                                  }
                                }
                                goto LABEL_316;
                              }
                              v434 = v606;
                            }
                            else
                            {
                              v434 = _swiftEmptyArrayStorage;
                            }
                            uint64_t v435 = v434[2];
                            v436 = &_swiftEmptyDictionarySingleton;
                            if (v435)
                            {
                              __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _DictionaryStorage<MLDataValue, MLDataValue>);
                              v436 = (void *)static _DictionaryStorage.allocate(capacity:)(v435);
                            }
                            *(void *)&v614[0] = v436;
                            swift_bridgeObjectRetain(v434);
                            uint64_t v437 = v618;
                            specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)((uint64_t)v434, 1, v614);
                            uint64_t v618 = v437;
                            if (v437)
                            {
                              swift_unexpectedError(v618, "Swift/Dictionary.swift", 22, 1, 489);
                              BUG();
                            }
                            swift_bridgeObjectRelease(v623);
                            swift_bridgeObjectRelease(v434);
                            uint64_t v620 = *(void *)&v614[0];
                            LOBYTE(v623) = 4;
                          }
                          else
                          {
                            unint64_t v623 = 6;
                            uint64_t v620 = 0;
                          }
                          v438 = v602;
                          if (!swift_isUniquelyReferenced_nonNull_native(v602))
                          {
                            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v438[2] + 1, 1);
                            v438 = v602;
                          }
                          unint64_t v439 = v438[2];
                          unint64_t v440 = v438[3];
                          *(void *)&long long v621 = v439 + 1;
                          if (v440 >> 1 <= v439)
                          {
                            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v440 >= 2, v621, 1);
                            v438 = v602;
                          }
                          v441 = (uint64_t *)((char *)v613 + 1);
                          v438[2] = v621;
                          uint64_t v442 = 3 * v439;
                          v438[v442 + 4] = v620;
                          v438[v442 + 5] = 0;
                          LOBYTE(v438[v442 + 6]) = v623;
                          dispatch thunk of Collection.formIndex(after:)(v560, v604, v616);
                          v613 = v441;
                        }
                        while (v441 != v608);
                      }
                      else
                      {
                        v438 = _swiftEmptyArrayStorage;
                      }
                      (*(void (**)(uint64_t *, uint64_t))(v571 + 8))(v605, v604);
                      *(void *)&v614[0] = v438;
                      v454 = alloca(24);
                      v455 = alloca(32);
                      *((void *)&v521[0] + 1) = v614;
                      uint64_t v164 = (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
                      goto LABEL_44;
                    }
                    uint64_t v619 = type metadata accessor for MLMultiArray();
                    if (swift_dynamicCastMetatype(v616, v619))
                    {
                      AnyColumn.assumingType<A>(_:)(v619, v619);
                      *(void *)&long long v621 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<MLMultiArray> and conformance Column<A>, &demangling cache variable for type metadata for Column<MLMultiArray>, (uint64_t)&protocol conformance descriptor for Column<A>);
                      uint64_t v619 = dispatch thunk of Collection.count.getter(v594, v621);
                      if (v619)
                      {
                        v607[0] = _swiftEmptyArrayStorage;
                        int64_t v443 = 0;
                        uint64_t v444 = v619;
                        if (v619 > 0) {
                          int64_t v443 = v619;
                        }
                        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v443, 0);
                        v445 = (void *)v607[0];
                        dispatch thunk of Collection.startIndex.getter(v594, v621);
                        if (v444 < 0) {
                          BUG();
                        }
                        do
                        {
                          v446 = (void (*)(_OWORD *, void))dispatch thunk of Collection.subscript.read(v614, v590, v594, v621);
                          id v448 = *v447;
                          id v449 = *v447;
                          v446(v614, 0);
                          if (v448)
                          {
                            MLDataValue.MultiArrayType.init(_:)((MLMultiArray)v449);
                            uint64_t v620 = *(void *)&v614[0];
                            LOBYTE(v623) = 5;
                          }
                          else
                          {
                            LOBYTE(v623) = 6;
                            uint64_t v620 = 0;
                          }
                          v607[0] = v445;
                          unint64_t v450 = v445[2];
                          if (v445[3] >> 1 <= v450)
                          {
                            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v445[3] >= 2uLL, v450 + 1, 1);
                            v445 = (void *)v607[0];
                          }
                          v445[2] = v450 + 1;
                          uint64_t v451 = 3 * v450;
                          v445[v451 + 4] = v620;
                          v445[v451 + 5] = 0;
                          LOBYTE(v445[v451 + 6]) = v623;
                          dispatch thunk of Collection.formIndex(after:)(v590, v594, v621);
                          --v619;
                        }
                        while (v619);
                      }
                      else
                      {
                        v445 = _swiftEmptyArrayStorage;
                      }
                      (*(void (**)(uint64_t *, uint64_t))(v557 + 8))(v595, v594);
                      *(void *)&v614[0] = v445;
                      v473 = alloca(24);
                      v474 = alloca(32);
                      *((void *)&v521[0] + 1) = v614;
                      uint64_t v164 = (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
                      goto LABEL_44;
                    }
                    if (swift_dynamicCastMetatype(v616, v592))
                    {
                      AnyColumn.assumingType<A>(_:)(v592, v592);
                      *(void *)&long long v621 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<MLShapedArray<Float>> and conformance Column<A>, &demangling cache variable for type metadata for Column<MLShapedArray<Float>>, (uint64_t)&protocol conformance descriptor for Column<A>);
                      uint64_t v617 = dispatch thunk of Collection.count.getter(v600, v621);
                      if (v617)
                      {
                        v607[0] = _swiftEmptyArrayStorage;
                        int64_t v456 = 0;
                        uint64_t v457 = v617;
                        if (v617 > 0) {
                          int64_t v456 = v617;
                        }
                        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v456, 0);
                        dispatch thunk of Collection.startIndex.getter(v600, v621);
                        if (v457 < 0) {
                          BUG();
                        }
                        do
                        {
                          v458 = (void (*)(_OWORD *, void))dispatch thunk of Collection.subscript.read(v614, v590, v600, v621);
                          uint64_t v459 = (uint64_t)v574;
                          outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v460, (uint64_t)v574, &demangling cache variable for type metadata for MLShapedArray<Float>?);
                          v458(v614, 0);
                          uint64_t v461 = (uint64_t)v584;
                          outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v459, (uint64_t)v584, &demangling cache variable for type metadata for MLShapedArray<Float>?);
                          if (__swift_getEnumTagSinglePayload(v461, 1, v592) == 1)
                          {
                            outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v584, &demangling cache variable for type metadata for MLShapedArray<Float>?);
                            char v462 = 6;
                            uint64_t v620 = 0;
                          }
                          else
                          {
                            v463 = v576;
                            uint64_t v464 = v592;
                            uint64_t v465 = v579;
                            (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v579 + 32))(v576, v584, v592);
                            v466 = v566;
                            (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v465 + 16))(v566, v463, v464);
                            uint64_t v467 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
                            v468.super.Class isa = (Class)MLMultiArray.init<A>(_:)(v466, v464, v467);
                            MLDataValue.MultiArrayType.init(_:)(v468);
                            uint64_t v620 = *(void *)&v614[0];
                            (*(void (**)(uint64_t *, uint64_t))(v465 + 8))(v576, v464);
                            char v462 = 5;
                          }
                          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v574, &demangling cache variable for type metadata for MLShapedArray<Float>?);
                          v469 = (void *)v607[0];
                          if (!swift_isUniquelyReferenced_nonNull_native(v607[0]))
                          {
                            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v469[2] + 1, 1);
                            v469 = (void *)v607[0];
                          }
                          unint64_t v470 = v469[2];
                          unint64_t v471 = v469[3];
                          unint64_t v623 = v470 + 1;
                          if (v471 >> 1 <= v470)
                          {
                            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v471 >= 2, v623, 1);
                            v469 = (void *)v607[0];
                          }
                          v469[2] = v623;
                          uint64_t v472 = 3 * v470;
                          v469[v472 + 4] = v620;
                          v469[v472 + 5] = 0;
                          LOBYTE(v469[v472 + 6]) = v462;
                          dispatch thunk of Collection.formIndex(after:)(v590, v600, v621);
                          --v617;
                        }
                        while (v617);
                      }
                      else
                      {
                        v469 = _swiftEmptyArrayStorage;
                      }
                      (*(void (**)(uint64_t *, uint64_t))(v556 + 8))(v601, v600);
                      *(void *)&v614[0] = v469;
                      v492 = alloca(24);
                      v493 = alloca(32);
                      *((void *)&v521[0] + 1) = v614;
                      uint64_t v164 = (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
                      goto LABEL_44;
                    }
                    if (swift_dynamicCastMetatype(v616, v593))
                    {
                      AnyColumn.assumingType<A>(_:)(v593, v593);
                      *(void *)&long long v621 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<MLShapedArray<Double>> and conformance Column<A>, &demangling cache variable for type metadata for Column<MLShapedArray<Double>>, (uint64_t)&protocol conformance descriptor for Column<A>);
                      uint64_t v617 = dispatch thunk of Collection.count.getter(v598, v621);
                      if (v617)
                      {
                        v607[0] = _swiftEmptyArrayStorage;
                        int64_t v475 = 0;
                        uint64_t v476 = v617;
                        if (v617 > 0) {
                          int64_t v475 = v617;
                        }
                        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v475, 0);
                        dispatch thunk of Collection.startIndex.getter(v598, v621);
                        if (v476 < 0) {
                          BUG();
                        }
                        do
                        {
                          v477 = (void (*)(_OWORD *, void))dispatch thunk of Collection.subscript.read(v614, v590, v598, v621);
                          uint64_t v478 = (uint64_t)v573;
                          outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v479, (uint64_t)v573, &demangling cache variable for type metadata for MLShapedArray<Double>?);
                          v477(v614, 0);
                          uint64_t v480 = (uint64_t)v583;
                          outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v478, (uint64_t)v583, &demangling cache variable for type metadata for MLShapedArray<Double>?);
                          if (__swift_getEnumTagSinglePayload(v480, 1, v593) == 1)
                          {
                            outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v583, &demangling cache variable for type metadata for MLShapedArray<Double>?);
                            char v481 = 6;
                            uint64_t v620 = 0;
                          }
                          else
                          {
                            v482 = v575;
                            uint64_t v483 = v593;
                            uint64_t v484 = v580;
                            (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v580 + 32))(v575, v583, v593);
                            v485 = v568;
                            (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v484 + 16))(v568, v482, v483);
                            uint64_t v486 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Double> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Double>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
                            v487.super.Class isa = (Class)MLMultiArray.init<A>(_:)(v485, v483, v486);
                            MLDataValue.MultiArrayType.init(_:)(v487);
                            uint64_t v620 = *(void *)&v614[0];
                            (*(void (**)(uint64_t *, uint64_t))(v484 + 8))(v575, v483);
                            char v481 = 5;
                          }
                          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v573, &demangling cache variable for type metadata for MLShapedArray<Double>?);
                          v488 = (void *)v607[0];
                          if (!swift_isUniquelyReferenced_nonNull_native(v607[0]))
                          {
                            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v488[2] + 1, 1);
                            v488 = (void *)v607[0];
                          }
                          unint64_t v489 = v488[2];
                          unint64_t v490 = v488[3];
                          unint64_t v623 = v489 + 1;
                          if (v490 >> 1 <= v489)
                          {
                            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v490 >= 2, v623, 1);
                            v488 = (void *)v607[0];
                          }
                          v488[2] = v623;
                          uint64_t v491 = 3 * v489;
                          v488[v491 + 4] = v620;
                          v488[v491 + 5] = 0;
                          LOBYTE(v488[v491 + 6]) = v481;
                          dispatch thunk of Collection.formIndex(after:)(v590, v598, v621);
                          --v617;
                        }
                        while (v617);
                      }
                      else
                      {
                        v488 = _swiftEmptyArrayStorage;
                      }
                      (*(void (**)(uint64_t *, uint64_t))(v555 + 8))(v599, v598);
                      *(void *)&v614[0] = v488;
                      v509 = alloca(24);
                      v510 = alloca(32);
                      *((void *)&v521[0] + 1) = v614;
                      uint64_t v164 = (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply;
                      goto LABEL_44;
                    }
                    if (swift_dynamicCastMetatype(v616, v603))
                    {
                      AnyColumn.assumingType<A>(_:)(v603, v603);
                      *(void *)&long long v621 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<MLShapedArray<Int32>> and conformance Column<A>, &demangling cache variable for type metadata for Column<MLShapedArray<Int32>>, (uint64_t)&protocol conformance descriptor for Column<A>);
                      uint64_t v620 = dispatch thunk of Collection.count.getter(v596, v621);
                      if (v620)
                      {
                        v607[0] = _swiftEmptyArrayStorage;
                        int64_t v494 = 0;
                        uint64_t v495 = v620;
                        if (v620 > 0) {
                          int64_t v494 = v620;
                        }
                        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v494, 0);
                        dispatch thunk of Collection.startIndex.getter(v596, v621);
                        if (v495 < 0) {
                          BUG();
                        }
                        do
                        {
                          v496 = (void (*)(_OWORD *, void))dispatch thunk of Collection.subscript.read(v614, v590, v596, v621);
                          uint64_t v497 = (uint64_t)v572;
                          outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v498, (uint64_t)v572, &demangling cache variable for type metadata for MLShapedArray<Int32>?);
                          v496(v614, 0);
                          uint64_t v499 = (uint64_t)v582;
                          outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v497, (uint64_t)v582, &demangling cache variable for type metadata for MLShapedArray<Int32>?);
                          if (__swift_getEnumTagSinglePayload(v499, 1, v603) == 1)
                          {
                            outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v582, &demangling cache variable for type metadata for MLShapedArray<Int32>?);
                            char v500 = 6;
                            unint64_t v623 = 0;
                          }
                          else
                          {
                            v501 = v558;
                            uint64_t v502 = v603;
                            uint64_t v503 = v577;
                            (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v577 + 32))(v558, v582, v603);
                            v504 = v586;
                            (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v503 + 16))(v586, v501, v502);
                            uint64_t v505 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Int32> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Int32>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
                            v506.super.Class isa = (Class)MLMultiArray.init<A>(_:)(v504, v502, v505);
                            MLDataValue.MultiArrayType.init(_:)(v506);
                            unint64_t v623 = *(void *)&v614[0];
                            (*(void (**)(uint64_t *, uint64_t))(v503 + 8))(v501, v502);
                            char v500 = 5;
                          }
                          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v572, &demangling cache variable for type metadata for MLShapedArray<Int32>?);
                          uint64_t v507 = v607[0];
                          if (!swift_isUniquelyReferenced_nonNull_native(v607[0]))
                          {
                            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(v507 + 16) + 1, 1);
                            uint64_t v507 = v607[0];
                          }
                          unint64_t v508 = *(void *)(v507 + 16);
                          if (*(void *)(v507 + 24) >> 1 <= v508) {
                            specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(*(void *)(v507 + 24) >= 2uLL, v508 + 1, 1);
                          }
                          specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)(v508, v623, 0, v500);
                          MLBoostedTreeRegressor.ModelParameters.maxDepth.modify();
                          dispatch thunk of Collection.formIndex(after:)(v590, v596, v621);
                          --v620;
                        }
                        while (v620);
                        v511 = (void *)v607[0];
                      }
                      else
                      {
                        v511 = _swiftEmptyArrayStorage;
                      }
                      (*(void (**)(uint64_t *, uint64_t))(v554 + 8))(v597, v596);
                      *(void *)&v614[0] = v511;
                      v518 = alloca(24);
                      v519 = alloca(32);
                      *((void *)&v521[0] + 1) = v614;
                      uint64_t v164 = (void (*)(void *))_s8CreateML15MLUntypedColumnVyACxcSTRzAA11MLDataValueO7ElementRtzlufcAA08_UntypedD0CyKXEfU_SayAEG_TG5TA_0;
                      goto LABEL_44;
                    }
                    static String._createEmpty(withInitialCapacity:)(25);
                    swift_bridgeObjectRelease(v512);
                    *(void *)&v614[0] = 0xD000000000000016;
                    *((void *)&v614[0] + 1) = "or Int labels, got " + 0x8000000000000000;
                    uint64_t v513 = AnyColumn.wrappedElementType.getter();
                    v514._uint64_t countAndFlagsBits = _typeName(_:qualified:)(v513, 0);
                    char object = v514._object;
                    String.append(_:)(v514);
                    swift_bridgeObjectRelease(object);
                    v516._uint64_t countAndFlagsBits = 46;
                    v516._char object = (void *)0xE100000000000000;
                    String.append(_:)(v516);
                    long long v621 = v614[0];
                    v516._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
                    swift_allocError(&type metadata for MLCreateError, v516._object, 0, 0);
                    *(_OWORD *)uint64_t v517 = v621;
                    *(_OWORD *)(v517 + 16) = 0;
                    *(_OWORD *)(v517 + 32) = 0;
                    *(unsigned char *)(v517 + 48) = 1;
                    swift_willThrow();
                    goto LABEL_192;
                  }
                  uint64_t v405 = (uint64_t)v559;
                  AnyColumn.assumingType<A>(_:)(v413, v413);
                  v406 = &demangling cache variable for type metadata for Column<[String : Any]>;
                  v407 = (uint64_t *)&lazy protocol witness table cache variable for type Column<[String : Any]> and conformance Column<A>;
                  v408 = (uint64_t (*)(uint64_t))_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSDySSypG_8CreateML11MLDataValueO_AItsAE_pTg5020_sSS3key_x5valuetSg8d4ML11fg5OAFs5c136_pIgnrrzo_SSAA_xABtAF_AFtsAG_pIegnrzr_lTRyp_TG503_s8c39ML15MLUntypedColumnVyAC11TabularData0D0l18SDySSxGGKclufcAA11ef34OAGSgKXEfU_AJ_AJti1_J22SgV8U_yp_Tg5Tf3nnnpf_nTf1cn_n;
                }
              }
            }
          }
        }
        uint64_t v403 = v618;
        specialized MLUntypedColumn.init<A>(_:)(v405, v406, v407, (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply, v408);
LABEL_191:
        if (!v403)
        {
          uint64_t v355 = type metadata accessor for AnyColumn(0);
          uint64_t v356 = *(void *)(v355 - 8);
          uint64_t v357 = v622;
          goto LABEL_151;
        }
LABEL_192:
        uint64_t v352 = type metadata accessor for AnyColumn(0);
        uint64_t v353 = *(void *)(v352 - 8);
        uint64_t v354 = v622;
        return (*(uint64_t (**)(uint64_t, uint64_t))(v353 + 8))(v354, v352);
      }
      uint64_t v396 = (uint64_t)v548;
      AnyColumn.assumingType<A>(_:)(v402, v402);
      v397 = &demangling cache variable for type metadata for Column<[Any]>;
      v398 = (uint64_t *)&lazy protocol witness table cache variable for type Column<[Any]> and conformance Column<A>;
      v399 = (void (*)(uint64_t))specialized closure #1 in MLUntypedColumn.init<A>(_:);
    }
    uint64_t v403 = v618;
    specialized MLUntypedColumn.init<A>(_:)(v396, v397, v398, (void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply, v399);
    goto LABEL_191;
  }
  if ((v612 & 1) == 0)
  {
    uint64_t v312 = v235;
    uint64_t v313 = v235;
    uint64_t v314 = v622;
    *(double *)a3.i64 = AnyColumn.assumingType<A>(_:)(v312, v313);
    uint64_t v315 = (uint64_t)v143;
LABEL_146:
    uint64_t v351 = v618;
    specialized MLUntypedColumn.init<A>(_:)(v315, a3);
LABEL_147:
    if (v351)
    {
      uint64_t v352 = type metadata accessor for AnyColumn(0);
      uint64_t v353 = *(void *)(v352 - 8);
      uint64_t v354 = v314;
      return (*(uint64_t (**)(uint64_t, uint64_t))(v353 + 8))(v354, v352);
    }
    uint64_t v355 = type metadata accessor for AnyColumn(0);
    uint64_t v356 = *(void *)(v355 - 8);
    uint64_t v357 = v314;
    goto LABEL_151;
  }
  v236 = v591;
  double v237 = AnyColumn.assumingType<A>(_:)(v235, v235);
  uint64_t v238 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Int]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Int]>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v239 = v578;
  uint64_t v240 = dispatch thunk of Collection.count.getter(v578, v238);
  if (!v240)
  {
    v267 = _swiftEmptyArrayStorage;
LABEL_171:
    (*(void (**)(uint64_t *, uint64_t, double))(v567 + 8))(v236, v239, v237);
    *(void *)&v614[0] = v267;
    v385 = alloca(24);
    v386 = alloca(32);
    *((void *)&v521[0] + 1) = v614;
    goto LABEL_172;
  }
  v607[0] = _swiftEmptyArrayStorage;
  int64_t v241 = 0;
  if (v240 > 0) {
    int64_t v241 = v240;
  }
  uint64_t v617 = v240;
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v241, 0);
  uint64_t v620 = v238;
  dispatch thunk of Collection.startIndex.getter(v239, v238);
  uint64_t v242 = v617;
  if (v617 < 0) {
    BUG();
  }
  uint64_t v243 = 0;
  while (1)
  {
    uint64_t v619 = v243;
    if (v243 == v242) {
      BUG();
    }
    v244 = (void (*)(_OWORD *, void, double))dispatch thunk of Collection.subscript.read(v614, v590, v239, v620);
    uint64_t v246 = *v245;
    swift_bridgeObjectRetain(*v245);
    v244(v614, 0, v237);
    if (!v246)
    {
      char v266 = 6;
      uint64_t v265 = 0;
      goto LABEL_95;
    }
    unint64_t v247 = *(void *)(v246 + 16);
    uint64_t v248 = _swiftEmptyArrayStorage;
    uint64_t v249 = v246;
    if (v247) {
      break;
    }
LABEL_93:
    *(void *)&long long v585 = v249;
    *(void *)&v614[0] = v248;
    uint64_t v255 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
    uint64_t v256 = (void *)swift_allocObject(v255, 40, 7);
    v256[2] = 1;
    v256[3] = 2;
    v256[4] = v247;
    uint64_t v257 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int32]);
    uint64_t v258 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Int32] and conformance [A], &demangling cache variable for type metadata for [Int32], (uint64_t)&protocol conformance descriptor for [A]);
    uint64_t v259 = v586;
    MLShapedArray.init<A>(scalars:shape:)(v614, v256, &type metadata for Int32, v257, &protocol witness table for Int32, v258);
    *(void *)&long long v621 = type metadata accessor for MLMultiArray();
    v260 = v564;
    uint64_t v261 = v603;
    uint64_t v262 = v577;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v577 + 16))(v564, v259, v603);
    uint64_t v263 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Int32> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Int32>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
    v264.super.Class isa = (Class)MLMultiArray.init<A>(_:)(v260, v261, v263);
    MLDataValue.MultiArrayType.init(_:)(v264);
    (*(void (**)(uint64_t *, uint64_t))(v262 + 8))(v259, v261);
    swift_bridgeObjectRelease(v585);
    uint64_t v265 = *(void *)&v614[0];
    char v266 = 5;
LABEL_95:
    v267 = (void *)v607[0];
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v607[0]);
    *(void *)&long long v621 = v265;
    if (!isUniquelyReferenced_nonNull_native)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v267[2] + 1, 1);
      v267 = (void *)v607[0];
    }
    unint64_t v269 = v267[2];
    unint64_t v270 = v269 + 1;
    if (v267[3] >> 1 <= v269)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v267[3] >= 2uLL, v269 + 1, 1);
      unint64_t v270 = v269 + 1;
      v267 = (void *)v607[0];
    }
    uint64_t v243 = v619 + 1;
    v267[2] = v270;
    uint64_t v271 = 3 * v269;
    v267[v271 + 4] = v621;
    v267[v271 + 5] = 0;
    LOBYTE(v267[v271 + 6]) = v266;
    uint64_t v239 = v578;
    dispatch thunk of Collection.formIndex(after:)(v590, v578, v620);
    uint64_t v242 = v617;
    if (v243 == v617)
    {
      v236 = v591;
      goto LABEL_171;
    }
  }
  *(void *)&v614[0] = _swiftEmptyArrayStorage;
  *(void *)&long long v589 = v247;
  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v247, 0);
  unint64_t v247 = v589;
  uint64_t v250 = *(void *)(v246 + 32);
  uint64_t v251 = v249;
  if ((unint64_t)(v250 - 0x80000000) < 0xFFFFFFFF00000000) {
    goto LABEL_127;
  }
  uint64_t v248 = *(void **)&v614[0];
  unint64_t v252 = *(void *)(*(void *)&v614[0] + 16);
  unint64_t v253 = *(void *)(*(void *)&v614[0] + 24);
  unint64_t v254 = v252 + 1;
  if (v253 >> 1 <= v252)
  {
    uint64_t v278 = v251;
    uint64_t v610 = *(void *)(*(void *)&v614[0] + 16);
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v253 >= 2, v252 + 1, 1);
    unint64_t v252 = v610;
    unint64_t v247 = v589;
    uint64_t v251 = v278;
    uint64_t v248 = *(void **)&v614[0];
  }
  v248[2] = v254;
  *((_DWORD *)v248 + v252 + 8) = v250;
  if (v247 == 1)
  {
LABEL_92:
    uint64_t v249 = v251;
    goto LABEL_93;
  }
  uint64_t v272 = 4 * v252 + 36;
  v273 = (uint64_t *)(v252 + 2);
  unint64_t v623 = v247 - 1;
  uint64_t v274 = 0;
  while (1)
  {
    uint64_t v275 = v274 + 1;
    if (v274 + 1 >= v247) {
      BUG();
    }
    uint64_t v276 = *(void *)(v251 + 8 * v274 + 40);
    if ((unint64_t)(v276 - 0x80000000) < 0xFFFFFFFF00000000) {
      break;
    }
    *(void *)&v614[0] = v248;
    unint64_t v277 = v248[3];
    *(void *)&long long v621 = (char *)v273 + v274;
    if (v277 >> 1 <= v274 + v252 + 1)
    {
      *(void *)&long long v585 = v251;
      uint64_t v610 = v252;
      int64_t v611 = v272;
      v613 = v273;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v277 >= 2, v621, 1);
      v273 = v613;
      uint64_t v272 = v611;
      unint64_t v252 = v610;
      unint64_t v247 = v589;
      uint64_t v251 = v585;
      uint64_t v248 = *(void **)&v614[0];
    }
    v248[2] = v621;
    *(_DWORD *)((char *)v248 + 4 * v274++ + v272) = v276;
    if (v623 == v275) {
      goto LABEL_92;
    }
  }
LABEL_127:
  uint64_t v316 = v251;
  uint64_t v317 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  swift_allocError(&type metadata for MLCreateError, v317, 0, 0);
  *(void *)uint64_t v318 = 0xD00000000000001FLL;
  *(void *)(v318 + 8) = "Unsupported data type " + 0x8000000000000000;
  *(_OWORD *)(v318 + 16) = 0;
  *(_OWORD *)(v318 + 32) = 0;
  *(unsigned char *)(v318 + 48) = 1;
  swift_willThrow();
  uint64_t v319 = *(void *)&v614[0];
  swift_bridgeObjectRelease(v316);
  swift_release(v319);
  swift_release(v607[0]);
  uint64_t v320 = type metadata accessor for AnyColumn(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v320 - 8) + 8))(v622, v320);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v567 + 8))(v591, v578);
}

uint64_t specialized DataFrameProtocol.subscript.getter(uint64_t a1)
{
  uint64_t v17 = a1;
  uint64_t v20 = v1;
  uint64_t v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DefaultIndices<DataFrame.Rows>);
  int64_t v3 = *(void *)(*(void *)(v23 - 8) + 64);
  uint64_t v4 = alloca(v3);
  int64_t v5 = alloca(v3);
  int64_t v18 = &v17;
  uint64_t v6 = type metadata accessor for DataFrame.Rows(0);
  uint64_t v22 = *(void *)(v6 - 8);
  int64_t v7 = *(void *)(v22 + 64);
  unint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v10 = type metadata accessor for DataFrame(0);
  uint64_t v19 = v2;
  uint64_t v21 = v10;
  dispatch thunk of DataFrameProtocol.rows.getter(v10, &protocol witness table for DataFrame);
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v22 + 16))(&v17, &v17, v6);
  uint64_t v11 = v23;
  uint64_t v12 = lazy protocol witness table accessor for type DataFrame.Rows and conformance DataFrame.Rows();
  dispatch thunk of Collection.startIndex.getter(v6, v12);
  uint64_t v23 = *(int *)(v11 + 40);
  uint64_t v13 = (uint64_t)v18;
  dispatch thunk of Collection.endIndex.getter(v6, v12);
  uint64_t v14 = v17;
  (*(void (**)(uint64_t *, uint64_t))(v22 + 8))(&v17, v6);
  uint64_t v15 = *(void *)(v13 + v23);
  if (v15 < v14) {
    BUG();
  }
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v13, &demangling cache variable for type metadata for DefaultIndices<DataFrame.Rows>);
  return dispatch thunk of DataFrameProtocol.subscript.getter(v14, v15, v21, &protocol witness table for DataFrame);
}

uint64_t specialized MLUntypedColumn.init<A>(_:)(uint64_t a1, __m128 a2)
{
  uint64_t v51 = v3;
  uint64_t v42 = v2;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Int]>);
  uint64_t v5 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Int]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Int]>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v6 = dispatch thunk of Collection.count.getter(v4, v5);
  uint64_t v47 = a1;
  uint64_t v48 = v4;
  if (v6)
  {
    double v45 = _swiftEmptyArrayStorage;
    int64_t v7 = 0;
    if (v6 > 0) {
      int64_t v7 = v6;
    }
    uint64_t v44 = v6;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v7, 0);
    int64_t v50 = v45;
    dispatch thunk of Collection.startIndex.getter(v4, v5);
    uint64_t v8 = v44;
    if (v44 < 0) {
      BUG();
    }
    uint64_t v9 = 0;
    uint64_t v10 = v5;
    uint64_t v41 = v5;
    while (1)
    {
      if (v9 == v8) {
        BUG();
      }
      uint64_t v40 = v9;
      uint64_t v11 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v38, v43, v48, v10);
      uint64_t v13 = *v12;
      swift_bridgeObjectRetain(*v12);
      v11(v38, 0);
      if (v13)
      {
        int64_t v14 = *(void *)(v13 + 16);
        if (v14)
        {
          uint64_t v49 = _swiftEmptyArrayStorage;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v14, 0);
          uint64_t v15 = v49;
          uint64_t v16 = 0;
          uint64_t v17 = v51;
          uint64_t v46 = v13;
          int64_t v39 = v14;
          while (1)
          {
            uint64_t v18 = *(void *)(v13 + 8 * v16 + 32);
            v38[3] = &type metadata for Int;
            v38[0] = v18;
            MLDataValue.init(fromAny:)(v38, *(double *)a2.i64);
            if (v17) {
              break;
            }
            a2 = v36;
            char v19 = v37;
            uint64_t v49 = v15;
            unint64_t v20 = v15[2];
            unint64_t v21 = v15[3];
            if (v21 >> 1 <= v20)
            {
              char v52 = v37;
              uint64_t v51 = 0;
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v21 >= 2, v20 + 1, 1);
              char v19 = v52;
              a2 = v36;
              uint64_t v17 = v51;
              uint64_t v15 = v49;
            }
            ++v16;
            v15[2] = v20 + 1;
            uint64_t v22 = 3 * v20;
            *(__m128 *)&v15[v22 + 4] = a2;
            LOBYTE(v15[v22 + 6]) = v19;
            uint64_t v13 = v46;
            if (v39 == v16)
            {
              uint64_t v51 = v17;
              goto LABEL_17;
            }
          }
          uint64_t v51 = v17;
          swift_release(v50);
          swift_bridgeObjectRelease(v13);
          swift_release(v15);
          return (*(uint64_t (**)(uint64_t))(*(void *)(v48 - 8) + 8))(v47);
        }
        uint64_t v15 = _swiftEmptyArrayStorage;
LABEL_17:
        specialized MLDataValue.SequenceType.init<A>(_:)((uint64_t)v15, *(double *)a2.i64);
        swift_bridgeObjectRelease(v13);
        uint64_t v24 = v38[0];
        char v23 = 3;
      }
      else
      {
        char v23 = 6;
        uint64_t v24 = 0;
      }
      uint64_t v25 = v50;
      double v45 = v50;
      unint64_t v26 = v50[2];
      unint64_t v27 = v50[3];
      if (v27 >> 1 <= v26)
      {
        uint64_t v46 = v24;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v27 >= 2, v26 + 1, 1);
        uint64_t v24 = v46;
        uint64_t v25 = v45;
      }
      uint64_t v9 = v40 + 1;
      v25[2] = v26 + 1;
      uint64_t v28 = 3 * v26;
      v25[v28 + 4] = v24;
      v25[v28 + 5] = 0;
      int64_t v50 = v25;
      LOBYTE(v25[v28 + 6]) = v23;
      uint64_t v10 = v41;
      dispatch thunk of Collection.formIndex(after:)(v43, v48, v41);
      uint64_t v8 = v44;
      if (v9 == v44)
      {
        int64_t v35 = v50;
        goto LABEL_24;
      }
    }
  }
  int64_t v35 = _swiftEmptyArrayStorage;
LABEL_24:
  v38[0] = v35;
  uint64_t v30 = alloca(24);
  Swift::String v31 = alloca(32);
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
  char v34 = v33;
  swift_bridgeObjectRelease(v38[0]);
  (*(void (**)(uint64_t))(*(void *)(v48 - 8) + 8))(v47);
  uint64_t result = (uint64_t)v42;
  uint64_t *v42 = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(result + 8) = v34 & 1;
  return result;
}

{
  uint64_t *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  int64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void (*v11)(void *, void);
  void *v12;
  uint64_t v13;
  int64_t v14;
  void *v15;
  uint64_t v16;
  uint64_t v17;
  double v18;
  char v19;
  unint64_t v20;
  unint64_t v21;
  uint64_t v22;
  char v23;
  uint64_t v24;
  void *v25;
  unint64_t v26;
  unint64_t v27;
  uint64_t v28;
  uint64_t result;
  void *v30;
  void *v31;
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5;
  char v33;
  char v34;
  void *v35;
  __m128 v36;
  char v37;
  void v38[4];
  int64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t *v42;
  char v43[8];
  uint64_t v44;
  void *v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  void *v50;
  uint64_t v51;
  char v52;

  uint64_t v51 = v3;
  uint64_t v42 = v2;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Float]>);
  uint64_t v5 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Float]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Float]>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v6 = dispatch thunk of Collection.count.getter(v4, v5);
  uint64_t v47 = a1;
  uint64_t v48 = v4;
  if (v6)
  {
    double v45 = _swiftEmptyArrayStorage;
    int64_t v7 = 0;
    if (v6 > 0) {
      int64_t v7 = v6;
    }
    uint64_t v44 = v6;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v7, 0);
    int64_t v50 = v45;
    dispatch thunk of Collection.startIndex.getter(v4, v5);
    uint64_t v8 = v44;
    if (v44 < 0) {
      BUG();
    }
    uint64_t v9 = 0;
    uint64_t v10 = v5;
    uint64_t v41 = v5;
    while (1)
    {
      if (v9 == v8) {
        BUG();
      }
      uint64_t v40 = v9;
      uint64_t v11 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v38, v43, v48, v10);
      uint64_t v13 = *v12;
      swift_bridgeObjectRetain(*v12);
      v11(v38, 0);
      if (v13)
      {
        int64_t v14 = *(void *)(v13 + 16);
        if (v14)
        {
          uint64_t v49 = _swiftEmptyArrayStorage;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v14, 0);
          uint64_t v15 = v49;
          uint64_t v16 = 0;
          uint64_t v17 = v51;
          uint64_t v46 = v13;
          int64_t v39 = v14;
          while (1)
          {
            *(void *)&uint64_t v18 = *(unsigned int *)(v13 + 4 * v16 + 32);
            v38[3] = &type metadata for Float;
            LODWORD(v38[0]) = LODWORD(v18);
            MLDataValue.init(fromAny:)(v38, v18);
            if (v17) {
              break;
            }
            a2 = v36;
            char v19 = v37;
            uint64_t v49 = v15;
            unint64_t v20 = v15[2];
            unint64_t v21 = v15[3];
            if (v21 >> 1 <= v20)
            {
              char v52 = v37;
              uint64_t v51 = 0;
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v21 >= 2, v20 + 1, 1);
              char v19 = v52;
              a2 = v36;
              uint64_t v17 = v51;
              uint64_t v15 = v49;
            }
            ++v16;
            v15[2] = v20 + 1;
            uint64_t v22 = 3 * v20;
            *(__m128 *)&v15[v22 + 4] = a2;
            LOBYTE(v15[v22 + 6]) = v19;
            uint64_t v13 = v46;
            if (v39 == v16)
            {
              uint64_t v51 = v17;
              goto LABEL_17;
            }
          }
          uint64_t v51 = v17;
          swift_release(v50);
          swift_bridgeObjectRelease(v13);
          swift_release(v15);
          return (*(uint64_t (**)(uint64_t))(*(void *)(v48 - 8) + 8))(v47);
        }
        uint64_t v15 = _swiftEmptyArrayStorage;
LABEL_17:
        specialized MLDataValue.SequenceType.init<A>(_:)((uint64_t)v15, *(double *)a2.i64);
        swift_bridgeObjectRelease(v13);
        uint64_t v24 = v38[0];
        char v23 = 3;
      }
      else
      {
        char v23 = 6;
        uint64_t v24 = 0;
      }
      uint64_t v25 = v50;
      double v45 = v50;
      unint64_t v26 = v50[2];
      unint64_t v27 = v50[3];
      if (v27 >> 1 <= v26)
      {
        uint64_t v46 = v24;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v27 >= 2, v26 + 1, 1);
        uint64_t v24 = v46;
        uint64_t v25 = v45;
      }
      uint64_t v9 = v40 + 1;
      v25[2] = v26 + 1;
      uint64_t v28 = 3 * v26;
      v25[v28 + 4] = v24;
      v25[v28 + 5] = 0;
      int64_t v50 = v25;
      LOBYTE(v25[v28 + 6]) = v23;
      uint64_t v10 = v41;
      dispatch thunk of Collection.formIndex(after:)(v43, v48, v41);
      uint64_t v8 = v44;
      if (v9 == v44)
      {
        int64_t v35 = v50;
        goto LABEL_24;
      }
    }
  }
  int64_t v35 = _swiftEmptyArrayStorage;
LABEL_24:
  v38[0] = v35;
  uint64_t v30 = alloca(24);
  Swift::String v31 = alloca(32);
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
  char v34 = v33;
  swift_bridgeObjectRelease(v38[0]);
  (*(void (**)(uint64_t))(*(void *)(v48 - 8) + 8))(v47);
  uint64_t result = (uint64_t)v42;
  uint64_t *v42 = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(result + 8) = v34 & 1;
  return result;
}

{
  uint64_t *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  int64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  void (*v11)(void *, void);
  void *v12;
  uint64_t v13;
  int64_t v14;
  void *v15;
  uint64_t v16;
  uint64_t v17;
  double v18;
  char v19;
  unint64_t v20;
  unint64_t v21;
  uint64_t v22;
  char v23;
  uint64_t v24;
  void *v25;
  unint64_t v26;
  unint64_t v27;
  uint64_t v28;
  uint64_t result;
  void *v30;
  void *v31;
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5;
  char v33;
  char v34;
  void *v35;
  __m128 v36;
  char v37;
  void v38[4];
  int64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t *v42;
  char v43[8];
  uint64_t v44;
  void *v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  void *v49;
  void *v50;
  uint64_t v51;
  char v52;

  uint64_t v51 = v3;
  uint64_t v42 = v2;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[Double]>);
  uint64_t v5 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[Double]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[Double]>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v6 = dispatch thunk of Collection.count.getter(v4, v5);
  uint64_t v47 = a1;
  uint64_t v48 = v4;
  if (v6)
  {
    double v45 = _swiftEmptyArrayStorage;
    int64_t v7 = 0;
    if (v6 > 0) {
      int64_t v7 = v6;
    }
    uint64_t v44 = v6;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v7, 0);
    int64_t v50 = v45;
    dispatch thunk of Collection.startIndex.getter(v4, v5);
    uint64_t v8 = v44;
    if (v44 < 0) {
      BUG();
    }
    uint64_t v9 = 0;
    uint64_t v10 = v5;
    uint64_t v41 = v5;
    while (1)
    {
      if (v9 == v8) {
        BUG();
      }
      uint64_t v40 = v9;
      uint64_t v11 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v38, v43, v48, v10);
      uint64_t v13 = *v12;
      swift_bridgeObjectRetain(*v12);
      v11(v38, 0);
      if (v13)
      {
        int64_t v14 = *(void *)(v13 + 16);
        if (v14)
        {
          uint64_t v49 = _swiftEmptyArrayStorage;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v14, 0);
          uint64_t v15 = v49;
          uint64_t v16 = 0;
          uint64_t v17 = v51;
          uint64_t v46 = v13;
          int64_t v39 = v14;
          while (1)
          {
            uint64_t v18 = *(double *)(v13 + 8 * v16 + 32);
            v38[3] = &type metadata for Double;
            *(double *)int64_t v38 = v18;
            MLDataValue.init(fromAny:)(v38, v18);
            if (v17) {
              break;
            }
            a2 = v36;
            char v19 = v37;
            uint64_t v49 = v15;
            unint64_t v20 = v15[2];
            unint64_t v21 = v15[3];
            if (v21 >> 1 <= v20)
            {
              char v52 = v37;
              uint64_t v51 = 0;
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v21 >= 2, v20 + 1, 1);
              char v19 = v52;
              a2 = v36;
              uint64_t v17 = v51;
              uint64_t v15 = v49;
            }
            ++v16;
            v15[2] = v20 + 1;
            uint64_t v22 = 3 * v20;
            *(__m128 *)&v15[v22 + 4] = a2;
            LOBYTE(v15[v22 + 6]) = v19;
            uint64_t v13 = v46;
            if (v39 == v16)
            {
              uint64_t v51 = v17;
              goto LABEL_17;
            }
          }
          uint64_t v51 = v17;
          swift_release(v50);
          swift_bridgeObjectRelease(v13);
          swift_release(v15);
          return (*(uint64_t (**)(uint64_t))(*(void *)(v48 - 8) + 8))(v47);
        }
        uint64_t v15 = _swiftEmptyArrayStorage;
LABEL_17:
        specialized MLDataValue.SequenceType.init<A>(_:)((uint64_t)v15, *(double *)a2.i64);
        swift_bridgeObjectRelease(v13);
        uint64_t v24 = v38[0];
        char v23 = 3;
      }
      else
      {
        char v23 = 6;
        uint64_t v24 = 0;
      }
      uint64_t v25 = v50;
      double v45 = v50;
      unint64_t v26 = v50[2];
      unint64_t v27 = v50[3];
      if (v27 >> 1 <= v26)
      {
        uint64_t v46 = v24;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v27 >= 2, v26 + 1, 1);
        uint64_t v24 = v46;
        uint64_t v25 = v45;
      }
      uint64_t v9 = v40 + 1;
      v25[2] = v26 + 1;
      uint64_t v28 = 3 * v26;
      v25[v28 + 4] = v24;
      v25[v28 + 5] = 0;
      int64_t v50 = v25;
      LOBYTE(v25[v28 + 6]) = v23;
      uint64_t v10 = v41;
      dispatch thunk of Collection.formIndex(after:)(v43, v48, v41);
      uint64_t v8 = v44;
      if (v9 == v44)
      {
        int64_t v35 = v50;
        goto LABEL_24;
      }
    }
  }
  int64_t v35 = _swiftEmptyArrayStorage;
LABEL_24:
  v38[0] = v35;
  uint64_t v30 = alloca(24);
  Swift::String v31 = alloca(32);
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
  char v34 = v33;
  swift_bridgeObjectRelease(v38[0]);
  (*(void (**)(uint64_t))(*(void *)(v48 - 8) + 8))(v47);
  uint64_t result = (uint64_t)v42;
  uint64_t *v42 = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(result + 8) = v34 & 1;
  return result;
}

{
  uint64_t *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  int64_t v7;
  uint64_t v8;
  uint64_t v9;
  void (*v10)(void *, void);
  void *v11;
  uint64_t v12;
  int64_t v13;
  void *v14;
  uint64_t *v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  char v19;
  unint64_t v20;
  unint64_t v21;
  int64_t v22;
  uint64_t v23;
  char v24;
  void *v25;
  void *v26;
  unint64_t v27;
  unint64_t v28;
  uint64_t v29;
  uint64_t result;
  void *v31;
  void *v32;
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5;
  char v34;
  char v35;
  void *v36;
  __m128 v37;
  char v38;
  void v39[4];
  uint64_t v40;
  uint64_t v41;
  uint64_t *v42;
  char v43[8];
  uint64_t v44;
  uint64_t v45;
  int64_t v46;
  void *v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  void *v51;
  void *v52;
  char v53;

  uint64_t v48 = v3;
  uint64_t v42 = v2;
  uint64_t v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<[String]>);
  uint64_t v5 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<[String]> and conformance Column<A>, &demangling cache variable for type metadata for Column<[String]>, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v6 = dispatch thunk of Collection.count.getter(v4, v5);
  uint64_t v49 = a1;
  int64_t v50 = v4;
  if (v6)
  {
    uint64_t v47 = _swiftEmptyArrayStorage;
    int64_t v7 = 0;
    if (v6 > 0) {
      int64_t v7 = v6;
    }
    uint64_t v44 = v6;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v7, 0);
    char v52 = v47;
    dispatch thunk of Collection.startIndex.getter(v4, v5);
    uint64_t v8 = v44;
    if (v44 < 0) {
      BUG();
    }
    uint64_t v9 = 0;
    uint64_t v41 = v5;
    while (1)
    {
      if (v9 == v8) {
        BUG();
      }
      uint64_t v40 = v9;
      uint64_t v10 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v39, v43, v50, v5);
      uint64_t v12 = *v11;
      swift_bridgeObjectRetain(*v11);
      v10(v39, 0);
      if (v12)
      {
        uint64_t v13 = *(void *)(v12 + 16);
        if (v13)
        {
          uint64_t v51 = _swiftEmptyArrayStorage;
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v13, 0);
          int64_t v14 = v51;
          double v45 = v12;
          uint64_t v15 = (uint64_t *)(v12 + 40);
          while (1)
          {
            uint64_t v16 = *(v15 - 1);
            uint64_t v17 = *v15;
            v39[3] = &type metadata for String;
            v39[0] = v16;
            v39[1] = v17;
            swift_bridgeObjectRetain_n(v17, 2);
            uint64_t v18 = v48;
            MLDataValue.init(fromAny:)(v39, *(double *)a2.i64);
            uint64_t v48 = v18;
            if (v18) {
              break;
            }
            swift_bridgeObjectRelease(v17);
            a2 = v37;
            char v19 = v38;
            uint64_t v51 = v14;
            unint64_t v20 = v14[2];
            unint64_t v21 = v14[3];
            uint64_t v22 = v20 + 1;
            if (v21 >> 1 <= v20)
            {
              uint64_t v46 = v20 + 1;
              int64_t v53 = v38;
              specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v21 >= 2, v22, 1);
              uint64_t v22 = v46;
              char v19 = v53;
              a2 = v37;
              int64_t v14 = v51;
            }
            void v14[2] = v22;
            char v23 = 3 * v20;
            *(__m128 *)&v14[v23 + 4] = a2;
            LOBYTE(v14[v23 + 6]) = v19;
            v15 += 2;
            if (!--v13)
            {
              uint64_t v12 = v45;
              goto LABEL_17;
            }
          }
          swift_release(v52);
          swift_bridgeObjectRelease(v45);
          swift_release(v14);
          swift_bridgeObjectRelease(v17);
          return (*(uint64_t (**)(uint64_t))(*(void *)(v50 - 8) + 8))(v49);
        }
        int64_t v14 = _swiftEmptyArrayStorage;
LABEL_17:
        specialized MLDataValue.SequenceType.init<A>(_:)((uint64_t)v14, *(double *)a2.i64);
        swift_bridgeObjectRelease(v12);
        uint64_t v25 = (void *)v39[0];
        uint64_t v24 = 3;
      }
      else
      {
        uint64_t v24 = 6;
        uint64_t v25 = 0;
      }
      unint64_t v26 = v52;
      uint64_t v47 = v52;
      unint64_t v27 = v52[2];
      uint64_t v28 = v52[3];
      if (v28 >> 1 <= v27)
      {
        char v52 = v25;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v28 >= 2, v27 + 1, 1);
        uint64_t v25 = v52;
        unint64_t v26 = v47;
      }
      uint64_t v9 = v40 + 1;
      void v26[2] = v27 + 1;
      int64_t v29 = 3 * v27;
      v26[v29 + 4] = v25;
      v26[v29 + 5] = 0;
      char v52 = v26;
      LOBYTE(v26[v29 + 6]) = v24;
      uint64_t v5 = v41;
      dispatch thunk of Collection.formIndex(after:)(v43, v50, v41);
      uint64_t v8 = v44;
      if (v9 == v44)
      {
        __m128 v36 = v52;
        goto LABEL_24;
      }
    }
  }
  __m128 v36 = _swiftEmptyArrayStorage;
LABEL_24:
  v39[0] = v36;
  Swift::String v31 = alloca(24);
  int64_t v32 = alloca(32);
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
  int64_t v35 = v34;
  swift_bridgeObjectRelease(v39[0]);
  (*(void (**)(uint64_t))(*(void *)(v50 - 8) + 8))(v49);
  uint64_t result = (uint64_t)v42;
  uint64_t *v42 = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(result + 8) = v35 & 1;
  return result;
}

uint64_t specialized MLUntypedColumn.init<A>(_:)(uint64_t a1, uint64_t *a2, uint64_t *a3, void (*a4)(void *), void (*a5)(uint64_t))
{
  __m128 v36 = a5;
  uint64_t v40 = a4;
  uint64_t v42 = v6;
  char v37 = v5;
  uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(a2);
  uint64_t v9 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(a3, a2, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v44 = v8;
  uint64_t v10 = dispatch thunk of Collection.count.getter(v8, v9);
  uint64_t v43 = a1;
  if (v10)
  {
    uint64_t v11 = v10;
    uint64_t v41 = _swiftEmptyArrayStorage;
    int64_t v12 = 0;
    if (v10 > 0) {
      int64_t v12 = v10;
    }
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v12, 0);
    uint64_t v13 = v9;
    int64_t v14 = v41;
    uint64_t v39 = v13;
    dispatch thunk of Collection.startIndex.getter(v44, v13);
    if (v11 < 0) {
      BUG();
    }
    while (1)
    {
      if (v11-- == 0) {
        BUG();
      }
      uint64_t v16 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v32, v38, v44, v39);
      uint64_t v18 = *v17;
      swift_bridgeObjectRetain(*v17);
      v16(v32, 0);
      uint64_t v19 = v42;
      v36(v18);
      if (v19) {
        break;
      }
      uint64_t v42 = 0;
      swift_bridgeObjectRelease(v18);
      long long v20 = v34;
      char v21 = v35;
      uint64_t v41 = v14;
      unint64_t v22 = v14[2];
      unint64_t v23 = v14[3];
      int64_t v24 = v22 + 1;
      if (v23 >> 1 <= v22)
      {
        char v45 = v35;
        long long v33 = v34;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v23 >= 2, v24, 1);
        char v21 = v45;
        long long v20 = v33;
        int64_t v14 = v41;
      }
      void v14[2] = v24;
      uint64_t v25 = 3 * v22;
      *(_OWORD *)&v14[v25 + 4] = v20;
      LOBYTE(v14[v25 + 6]) = v21;
      dispatch thunk of Collection.formIndex(after:)(v38, v44, v39);
      if (!v11) {
        goto LABEL_12;
      }
    }
    swift_release(v14);
    swift_bridgeObjectRelease(v18);
    return (*(uint64_t (**)(uint64_t))(*(void *)(v44 - 8) + 8))(v43);
  }
  else
  {
    int64_t v14 = _swiftEmptyArrayStorage;
LABEL_12:
    v32[0] = v14;
    unint64_t v26 = alloca(24);
    unint64_t v27 = alloca(32);
    void v32[2] = v32;
    uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5(v40);
    char v30 = v29;
    swift_bridgeObjectRelease(v32[0]);
    (*(void (**)(uint64_t))(*(void *)(v44 - 8) + 8))(v43);
    uint64_t result = (uint64_t)v37;
    *char v37 = ML14_UntypedColumnC_s5Error_pTgm5;
    *(unsigned char *)(result + 8) = v30 & 1;
  }
  return result;
}

uint64_t specialized MLUntypedColumn.init<A>(_:)(uint64_t a1, uint64_t *a2, uint64_t *a3, void (*a4)(void *), uint64_t (*a5)(uint64_t))
{
  uint64_t v40 = a5;
  uint64_t v44 = a4;
  uint64_t v50 = v6;
  uint64_t v41 = v5;
  uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(a2);
  uint64_t v10 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(a3, a2, (uint64_t)&protocol conformance descriptor for Column<A>);
  uint64_t v11 = dispatch thunk of Collection.count.getter(v9, v10);
  uint64_t v47 = a1;
  uint64_t v48 = v9;
  if (v11)
  {
    char v45 = _swiftEmptyArrayStorage;
    int64_t v12 = 0;
    if (v11 > 0) {
      int64_t v12 = v11;
    }
    uint64_t v46 = v11;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v12, 0);
    uint64_t v13 = v10;
    int64_t v14 = v45;
    uint64_t v43 = v13;
    dispatch thunk of Collection.startIndex.getter(v9, v13);
    uint64_t v15 = v46;
    if (v46 < 0) {
      BUG();
    }
    while (1)
    {
      BOOL v16 = v15 == 0;
      uint64_t v17 = v15 - 1;
      if (v16) {
        BUG();
      }
      uint64_t v49 = v14;
      uint64_t v46 = v17;
      uint64_t v18 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v39, v42, v9, v43);
      uint64_t v20 = *v19;
      swift_bridgeObjectRetain(*v19);
      v18(v39, 0);
      if (v20)
      {
        uint64_t v21 = v50;
        uint64_t v22 = v40(v20);
        int64_t v14 = v49;
        if (v21)
        {
          swift_release(v49);
          swift_bridgeObjectRelease(v20);
          return (*(uint64_t (**)(uint64_t))(*(void *)(v48 - 8) + 8))(v47);
        }
        uint64_t v23 = v22;
        uint64_t v50 = 0;
        uint64_t v24 = *(void *)(v22 + 16);
        uint64_t v25 = &_swiftEmptyDictionarySingleton;
        if (v24)
        {
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _DictionaryStorage<MLDataValue, MLDataValue>);
          uint64_t v25 = (void *)static _DictionaryStorage.allocate(capacity:)(v24);
        }
        v39[0] = v25;
        swift_bridgeObjectRetain(v23);
        uint64_t v26 = v50;
        specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)(v23, 1, v39);
        uint64_t v50 = v26;
        if (v26)
        {
          swift_unexpectedError(v50, "Swift/Dictionary.swift", 22, 1, 489);
          BUG();
        }
        swift_bridgeObjectRelease(v20);
        swift_bridgeObjectRelease(v23);
        unint64_t v27 = (void *)v39[0];
        char v28 = 4;
      }
      else
      {
        char v28 = 6;
        unint64_t v27 = 0;
        int64_t v14 = v49;
      }
      char v45 = v14;
      unint64_t v29 = v14[2];
      unint64_t v30 = v14[3];
      if (v30 >> 1 <= v29)
      {
        uint64_t v49 = v27;
        char v32 = v28;
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v30 >= 2, v29 + 1, 1);
        unint64_t v27 = v49;
        char v28 = v32;
        int64_t v14 = v45;
      }
      void v14[2] = v29 + 1;
      uint64_t v31 = 3 * v29;
      v14[v31 + 4] = v27;
      v14[v31 + 5] = 0;
      LOBYTE(v14[v31 + 6]) = v28;
      uint64_t v9 = v48;
      dispatch thunk of Collection.formIndex(after:)(v42, v48, v43);
      uint64_t v15 = v46;
      if (!v46) {
        goto LABEL_18;
      }
    }
  }
  int64_t v14 = _swiftEmptyArrayStorage;
LABEL_18:
  v39[0] = v14;
  long long v33 = alloca(24);
  long long v34 = alloca(32);
  v39[1] = v39;
  uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5(v44);
  char v37 = v36;
  swift_bridgeObjectRelease(v39[0]);
  (*(void (**)(uint64_t))(*(void *)(v48 - 8) + 8))(v47);
  uint64_t result = (uint64_t)v41;
  uint64_t *v41 = ML14_UntypedColumnC_s5Error_pTgm5;
  *(unsigned char *)(result + 8) = v37 & 1;
  return result;
}

char closure #1 in closure #10 in MLUntypedColumn.init(_:convertArraysToShapedArrays:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a3, (uint64_t)&v14, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?)?);
  if (*((void *)&v15 + 1))
  {
    uint64_t v19 = a1;
    uint64_t v20 = (_OWORD *)a2;
    uint64_t v11 = v16;
    double v4 = *(double *)&v14;
    v10[1] = v15;
    v10[0] = v14;
    outlined init with take of Any?((uint64_t)&v17, (uint64_t)v12);
    outlined init with copy of AnyHashable((uint64_t)v10, (uint64_t)&v14);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v12, (uint64_t)&v17, &demangling cache variable for type metadata for Any?);
    if (v18)
    {
      outlined init with take of Any(&v17, v13);
      outlined destroy of AnyHashable((uint64_t)&v14);
      outlined init with copy of AnyHashable((uint64_t)v10, (uint64_t)&v14);
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v12, (uint64_t)&v17, &demangling cache variable for type metadata for Any?);
      AnyHashable.base.getter();
      outlined destroy of AnyHashable((uint64_t)&v14);
      MLDataValue.init(fromAny:)(v9, v4);
      if (v3)
      {
        __swift_destroy_boxed_opaque_existential_1Tm(v13);
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v10, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?));
        uint64_t v5 = &demangling cache variable for type metadata for Any?;
        uint64_t v6 = &v17;
      }
      else
      {
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v17, &demangling cache variable for type metadata for Any?);
        outlined init with copy of Any((uint64_t)v13, (uint64_t)&v14);
        MLDataValue.init(fromAny:)(&v14, v4);
        __swift_destroy_boxed_opaque_existential_1Tm(v13);
        uint64_t v5 = &demangling cache variable for type metadata for (key: AnyHashable, value: Any?);
        uint64_t v6 = v10;
      }
      LOBYTE(v7) = outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v6, v5);
    }
    else
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v17, &demangling cache variable for type metadata for Any?);
      outlined destroy of AnyHashable((uint64_t)&v14);
      outlined init with copy of AnyHashable((uint64_t)v10, (uint64_t)&v14);
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v12, (uint64_t)&v17, &demangling cache variable for type metadata for Any?);
      AnyHashable.base.getter();
      outlined destroy of AnyHashable((uint64_t)&v14);
      MLDataValue.init(fromAny:)(v13, v4);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v10, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?));
      LOBYTE(v7) = outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v17, &demangling cache variable for type metadata for Any?);
      if (!v3)
      {
        int64_t v7 = v20;
        _OWORD *v20 = 0;
        *((unsigned char *)v7 + 16) = 6;
      }
    }
  }
  else
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v14, &demangling cache variable for type metadata for (key: AnyHashable, value: Any?)?);
    *(_OWORD *)a1 = 0;
    LOBYTE(v7) = 6;
    *(unsigned char *)(a1 + 16) = 6;
    *(_OWORD *)a2 = 0;
    *(unsigned char *)(a2 + 16) = 6;
  }
  return (char)v7;
}

uint64_t specialized closure #1 in MLUntypedColumn.init<A>(_:)(uint64_t a1, double a2)
{
  uint64_t v4 = v3;
  uint64_t v5 = result;
  if (a1)
  {
    int64_t v6 = *(void *)(a1 + 16);
    if (v6)
    {
      uint64_t v21 = result;
      uint64_t v23 = _swiftEmptyArrayStorage;
      int64_t v20 = v6;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v6, 0);
      uint64_t v7 = a1 + 32;
      uint64_t v19 = (char *)&type metadata for Any + 8;
      while (1)
      {
        outlined init with copy of Any(v7, (uint64_t)v14);
        v15[3] = v19;
        v15[0] = swift_allocObject(&unk_399590, 48, 7);
        outlined init with copy of Any((uint64_t)v14, v15[0] + 16);
        MLDataValue.init(fromAny:)(v15, a2);
        __swift_destroy_boxed_opaque_existential_1Tm(v14);
        if (v4) {
          return swift_release(v23);
        }
        long long v16 = v17;
        char v24 = v18;
        uint64_t v8 = v23;
        char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v23);
        uint64_t v22 = 0;
        if (!isUniquelyReferenced_nonNull_native)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v8[2] + 1, 1);
          uint64_t v8 = v23;
        }
        unint64_t v10 = v8[2];
        unint64_t v11 = v10 + 1;
        if (v8[3] >> 1 <= v10)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v8[3] >= 2uLL, v10 + 1, 1);
          unint64_t v11 = v10 + 1;
          uint64_t v8 = v23;
        }
        _OWORD v8[2] = v11;
        uint64_t v12 = 3 * v10;
        a2 = *(double *)&v16;
        *(_OWORD *)&v8[v12 + 4] = v16;
        LOBYTE(v8[v12 + 6]) = v24;
        v7 += 32;
        BOOL v13 = v20-- == 1;
        uint64_t v4 = v22;
        if (v13)
        {
          uint64_t v5 = v21;
          goto LABEL_14;
        }
      }
    }
    else
    {
      uint64_t v22 = v3;
      uint64_t v8 = _swiftEmptyArrayStorage;
LABEL_14:
      specialized MLDataValue.SequenceType.init<A>(_:)((uint64_t)v8, a2);
      uint64_t result = v14[0];
      *(void *)uint64_t v5 = v14[0];
      *(void *)(v5 + 8) = 0;
      *(unsigned char *)(v5 + 16) = 3;
    }
  }
  else
  {
    *(_OWORD *)uint64_t result = 0;
    *(unsigned char *)(result + 16) = 6;
  }
  return result;
}

{
  uint64_t result;
  uint64_t v3;
  uint64_t v4;
  int64_t v5;
  uint64_t v6;
  uint64_t v7;
  char v8;
  void *v9;
  char isUniquelyReferenced_nonNull_native;
  unint64_t v11;
  uint64_t v12;
  _OWORD v13[2];
  void v14[4];
  long long v15;
  char *v16;
  long long v17;
  long long v18;
  char v19;
  uint64_t v20;
  int64_t v21;
  char *v22;
  uint64_t v23;
  uint64_t v24;
  void *v25;

  uint64_t v4 = result;
  if (!a1)
  {
    *(_OWORD *)uint64_t result = 0;
    *(unsigned char *)(result + 16) = 6;
    return result;
  }
  uint64_t v5 = *(void *)(a1 + 16);
  if (v5)
  {
    uint64_t v23 = result;
    char v24 = v3;
    uint64_t v25 = _swiftEmptyArrayStorage;
    uint64_t v21 = v5;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v5, 0);
    int64_t v6 = a1 + 32;
    uint64_t v22 = (char *)&type metadata for Any + 8;
    while (1)
    {
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v6, (uint64_t)v14, &demangling cache variable for type metadata for Any?);
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v14, (uint64_t)&v15, &demangling cache variable for type metadata for Any?);
      if (v16)
      {
        outlined init with take of Any(&v15, v13);
        long long v16 = v22;
        *(void *)&long long v15 = swift_allocObject(&unk_399590, 48, 7);
        outlined init with copy of Any((uint64_t)v13, v15 + 16);
        uint64_t v7 = v24;
        MLDataValue.init(fromAny:)(&v15, a2);
        __swift_destroy_boxed_opaque_existential_1Tm(v13);
        char v24 = v7;
        if (v7)
        {
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v14, &demangling cache variable for type metadata for Any?);
          return swift_release(v25);
        }
        long long v17 = v18;
        uint64_t v8 = v19;
      }
      else
      {
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v15, &demangling cache variable for type metadata for Any?);
        char v18 = 0;
        long long v17 = 0;
        uint64_t v8 = 6;
      }
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v14, &demangling cache variable for type metadata for Any?);
      uint64_t v9 = v25;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v25);
      int64_t v20 = v6;
      if (!isUniquelyReferenced_nonNull_native)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v9[2] + 1, 1);
        uint64_t v9 = v25;
      }
      unint64_t v11 = v9[2];
      if (v9[3] >> 1 <= v11)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v9[3] >= 2uLL, v11 + 1, 1);
        uint64_t v9 = v25;
      }
      v9[2] = v11 + 1;
      uint64_t v12 = 3 * v11;
      a2 = *(double *)&v17;
      *(_OWORD *)&v9[v12 + 4] = v17;
      LOBYTE(v9[v12 + 6]) = v8;
      int64_t v6 = v20 + 32;
      if (!--v21)
      {
        uint64_t v4 = v23;
        goto LABEL_16;
      }
    }
  }
  uint64_t v9 = _swiftEmptyArrayStorage;
LABEL_16:
  specialized MLDataValue.SequenceType.init<A>(_:)((uint64_t)v9, a2);
  uint64_t result = v14[0];
  *(void *)uint64_t v4 = v14[0];
  *(void *)(v4 + 8) = 0;
  *(unsigned char *)(v4 + 16) = 3;
  return result;
}

uint64_t *specialized MLDataValue.SequenceType.init<A>(_:)(uint64_t a1, double a2)
{
  uint64_t v3 = a1;
  long long v17 = v2;
  uint64_t v4 = tc_v1_flex_list_create(0);
  if (!v4) {
    BUG();
  }
  uint64_t v5 = v4;
  uint64_t v6 = type metadata accessor for CMLSequence();
  uint64_t v7 = swift_allocObject(v6, 25, 7);
  *(void *)(v7 + 16) = v5;
  uint64_t v18 = v7;
  *(unsigned char *)(v7 + 24) = 1;
  uint64_t v8 = *(void *)(a1 + 16);
  if (v8)
  {
    swift_bridgeObjectRetain(a1);
    uint64_t v9 = (char *)(a1 + 48);
    while (2)
    {
      unint64_t v10 = (void *)*((void *)v9 - 2);
      uint64_t v19 = (void *)*((void *)v9 - 1);
      char v16 = *v9;
      switch(*v9)
      {
        case 0:
          uint64_t v11 = specialized handling<A, B>(_:_:)((uint64_t)v10);
          if (!v11) {
            BUG();
          }
          goto LABEL_11;
        case 1:
          a2 = *((double *)v9 - 2);
          uint64_t v11 = specialized handling<A, B>(_:_:)();
          if (!v11) {
            BUG();
          }
LABEL_11:
          uint64_t v14 = type metadata accessor for CMLFeatureValue();
          swift_allocObject(v14, 25, 7);
          uint64_t v12 = CMLFeatureValue.init(rawValue:ownsValue:)(v11, 1);
          goto LABEL_14;
        case 2:
          type metadata accessor for CMLFeatureValue();
          outlined copy of MLDataValue(v10, v19, 2u);
          swift_bridgeObjectRetain_n(v19, 2);
          uint64_t v13 = CMLFeatureValue.__allocating_init(_:)((uint64_t)v10, (uint64_t)v19);
          outlined consume of MLDataValue(v10, v19, 2);
          goto LABEL_15;
        case 3:
          swift_retain(v10);
          uint64_t v12 = MLDataValue.SequenceType.featureValue.getter(a2);
          goto LABEL_14;
        case 4:
          swift_bridgeObjectRetain(v10);
          uint64_t v12 = MLDataValue.DictionaryType.featureValue.getter();
          goto LABEL_14;
        case 5:
          v10;
          uint64_t v12 = MLDataValue.MultiArrayType.featureValue.getter();
          goto LABEL_14;
        case 6:
          type metadata accessor for CMLFeatureValue();
          uint64_t v12 = CMLFeatureValue.__allocating_init()(0);
LABEL_14:
          uint64_t v13 = v12;
LABEL_15:
          CMLSequence.append(_:)(v13);
          swift_release(v13);
          outlined consume of MLDataValue(v10, v19, v16);
          v9 += 24;
          if (--v8) {
            continue;
          }
          uint64_t v3 = a1;
          swift_bridgeObjectRelease(a1);
          break;
      }
      break;
    }
  }
  swift_bridgeObjectRelease(v3);
  uint64_t result = v17;
  *long long v17 = v18;
  return result;
}

char specialized closure #1 in closure #1 in MLUntypedColumn.init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, double a4)
{
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a3, (uint64_t)&v14, &demangling cache variable for type metadata for (key: String, value: Any?)?);
  uint64_t v4 = *((void *)&v14 + 1);
  if (*((void *)&v14 + 1))
  {
    uint64_t v19 = (void *)a1;
    uint64_t v18 = (_OWORD *)a2;
    uint64_t v5 = v14;
    long long v12 = v14;
    outlined init with take of Any?((uint64_t)&v15, (uint64_t)v13);
    *(void *)&long long v14 = v5;
    *((void *)&v14 + 1) = v4;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v13, (uint64_t)&v15, &demangling cache variable for type metadata for Any?);
    if (v16)
    {
      outlined init with take of Any(&v15, v17);
      *(void *)&long long v14 = v5;
      *((void *)&v14 + 1) = v4;
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v13, (uint64_t)&v15, &demangling cache variable for type metadata for Any?);
      uint64_t v6 = v19;
      *uint64_t v19 = v5;
      v6[1] = v4;
      *((unsigned char *)v6 + 16) = 2;
      v11[3] = (char *)&type metadata for Any + 8;
      v11[0] = swift_allocObject(&unk_399590, 48, 7);
      outlined init with copy of Any((uint64_t)v17, v11[0] + 16);
      swift_bridgeObjectRetain(v4);
      uint64_t v7 = v20;
      MLDataValue.init(fromAny:)(v11, a4);
      uint64_t v20 = v7;
      if (v7) {
        swift_bridgeObjectRelease(v4);
      }
      __swift_destroy_boxed_opaque_existential_1Tm(v17);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v12, &demangling cache variable for type metadata for (key: String, value: Any?));
    }
    else
    {
      swift_bridgeObjectRetain(v4);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v15, &demangling cache variable for type metadata for Any?);
      *(void *)&long long v14 = v5;
      *((void *)&v14 + 1) = v4;
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v13, (uint64_t)&v15, &demangling cache variable for type metadata for Any?);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v12, &demangling cache variable for type metadata for (key: String, value: Any?));
      uint64_t v9 = v19;
      *(_OWORD *)uint64_t v19 = v14;
      *((unsigned char *)v9 + 16) = 2;
      unint64_t v10 = v18;
      *uint64_t v18 = 0;
      *((unsigned char *)v10 + 16) = 6;
    }
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v15, &demangling cache variable for type metadata for Any?);
  }
  else
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v14, &demangling cache variable for type metadata for (key: String, value: Any?)?);
    *(_OWORD *)a1 = 0;
    char result = 6;
    *(unsigned char *)(a1 + 16) = 6;
    *(_OWORD *)a2 = 0;
    *(unsigned char *)(a2 + 16) = 6;
  }
  return result;
}

char *specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)(uint64_t a1)
{
  char result = *(char **)(*(void *)v1 + 24);
  if ((uint64_t)((unint64_t)result >> 1) < a1 + 1) {
    return specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)((unint64_t)result >= 2, a1 + 1, 1);
  }
  return result;
}

uint64_t specialized _NativeDictionary.merge<A>(_:isUnique:uniquingKeysWith:)(uint64_t a1, int a2, void *a3)
{
  uint64_t v41 = v3;
  uint64_t v47 = a3;
  int v51 = a2;
  uint64_t v4 = *(void *)(a1 + 16);
  uint64_t v49 = a1;
  swift_bridgeObjectRetain(a1);
  uint64_t v40 = v4;
  if (v4)
  {
    uint64_t v42 = (unsigned __int8 *)(v49 + 72);
    unint64_t v6 = 0;
    do
    {
      if (v6 >= *(void *)(v49 + 16)) {
        BUG();
      }
      unsigned __int8 v8 = *(v42 - 24);
      unsigned __int8 v53 = *v42;
      uint64_t v9 = (void *)*((void *)v42 - 1);
      unint64_t v39 = v6;
      char v45 = (void *)*((void *)v42 - 2);
      unint64_t v10 = (void *)*((void *)v42 - 5);
      uint64_t v11 = (void *)*((void *)v42 - 4);
      unsigned __int8 v52 = v8;
      int v12 = v8;
      outlined copy of MLDataValue(v10, v11, v8);
      int v44 = v53;
      outlined copy of MLDataValue(v45, v9, v53);
      if ((_BYTE)v12 == 0xFF) {
        break;
      }
      uint64_t v43 = v9;
      v36[0] = v10;
      v36[1] = v11;
      char v37 = v12;
      *(void *)&long long v13 = v10;
      long long v14 = (void *)*v47;
      uint64_t v48 = (void *)v13;
      uint64_t v46 = v11;
      *((void *)&v13 + 1) = v11;
      int v50 = v12;
      unint64_t v16 = specialized __RawDictionaryStorage.find<A>(_:)(v13, v12);
      *(void *)&long long v13 = (v15 & 1) == 0;
      BOOL v17 = __OFADD__(v14[2], (void)v13);
      uint64_t v18 = v14[2] + v13;
      if (v17) {
        BUG();
      }
      char v19 = v15;
      if (v14[3] >= v18)
      {
        if ((v51 & 1) == 0)
        {
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<MLDataValue, MLDataValue>);
          _NativeDictionary.copy()();
        }
      }
      else
      {
        specialized _NativeDictionary._copyOrMoveAndResize(capacity:moveElements:)(v18, v51);
        *(void *)&long long v20 = v48;
        *((void *)&v20 + 1) = v46;
        unint64_t v16 = specialized __RawDictionaryStorage.find<A>(_:)(v20, v50);
        if ((v19 & 1) != (v21 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for MLDataValue);
          BUG();
        }
      }
      uint64_t v22 = v48;
      if (v19)
      {
        uint64_t v30 = swift_allocError(&type metadata for _MergeError, &protocol witness table for _MergeError, 0, 0);
        swift_willThrow();
        uint64_t v38 = v30;
        swift_errorRetain(v30);
        uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
        if (swift_dynamicCast(&demangling cache variable for type metadata for Error, &v38, v31, &type metadata for _MergeError, 0))
        {
          uint64_t v34 = 0;
          unint64_t v35 = 0xE000000000000000;
          _StringGuts.grow(_:)(30);
          v33._char object = "Swift/NativeDictionary.swift" + 0x8000000000000000;
          v33._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
          String.append(_:)(v33);
          _print_unlocked<A, B>(_:_:)(v36, &v34, &type metadata for MLDataValue, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
          v33._uint64_t countAndFlagsBits = 39;
          v33._char object = (void *)0xE100000000000000;
          String.append(_:)(v33);
          _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v34, v35, "Swift/NativeDictionary.swift", 28, 2, 783, 0);
          BUG();
        }
        uint64_t v32 = v49;
        swift_bridgeObjectRelease(v49);
        outlined consume of MLDataValue(v45, v43, v44);
        outlined consume of MLDataValue(v22, v46, v50);
        swift_bridgeObjectRelease(v32);
        return swift_errorRelease(v38);
      }
      uint64_t v23 = (void *)*v47;
      v23[(v16 >> 6) + 8] |= 1 << v16;
      uint64_t v24 = v23[6];
      uint64_t v25 = 24 * v16;
      *(void *)(v24 + v25) = v22;
      *(void *)(v24 + v25 + 8) = v46;
      *(unsigned char *)(v24 + v25 + 16) = v52;
      uint64_t v26 = v23[7];
      *(void *)(v26 + v25) = v45;
      *(void *)(v26 + v25 + 8) = v43;
      *(unsigned char *)(v26 + v25 + 16) = v53;
      uint64_t v27 = v23[2];
      BOOL v17 = __OFADD__(1, v27);
      uint64_t v28 = v27 + 1;
      if (v17) {
        BUG();
      }
      unint64_t v5 = v39 + 1;
      long long v23[2] = v28;
      v42 += 48;
      LOBYTE(v23) = 1;
      int v51 = (int)v23;
      unint64_t v6 = v5;
    }
    while (v40 != v5);
  }
  return swift_bridgeObjectRelease_n(v49, 2, v5, v6, v7);
}

{
  uint64_t v3;
  uint64_t v4;
  int64_t v5;
  void *v6;
  void *v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  void *v11;
  void *v12;
  uint64_t *v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  void *v17;
  char v18;
  unint64_t v19;
  BOOL v20;
  BOOL v21;
  uint64_t v22;
  char v23;
  char v24;
  void *v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  BOOL v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  Swift::String v39;
  unsigned char v40[8];
  uint64_t v41;
  unint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  void (*v46)(unsigned char *, unsigned char *, uint64_t);
  uint64_t v47;
  unsigned char *v48;
  uint64_t *v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  unsigned char *v56;
  uint64_t v57;
  void *v58;
  int v59;

  uint64_t v58 = a3;
  int64_t v59 = a2;
  uint64_t v4 = type metadata accessor for CSVType(0);
  uint64_t v55 = *(void *)(v4 - 8);
  unint64_t v5 = *(void *)(v55 + 64);
  unint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  int64_t v56 = v40;
  unsigned __int8 v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, CSVType));
  uint64_t v9 = *(void *)(v8 - 8);
  unint64_t v10 = *(void *)(v9 + 64);
  uint64_t v11 = alloca(v10);
  int v12 = alloca(v10);
  long long v13 = (uint64_t *)v40;
  if (!*(void *)(a1 + 16)) {
    return swift_bridgeObjectRelease(a1);
  }
  int v50 = *(void *)(a1 + 16);
  unsigned __int8 v52 = v3;
  uint64_t v48 = &v40[*(int *)(v8 + 48)];
  long long v14 = a1 + ((*(unsigned __int8 *)(v9 + 80) + 32) & ~*(unsigned __int8 *)(v9 + 80));
  int v51 = *(void *)(v9 + 72);
  uint64_t v54 = a1;
  swift_bridgeObjectRetain(a1);
  uint64_t v57 = v4;
  uint64_t v49 = (uint64_t *)v40;
  while (1)
  {
    uint64_t v47 = v14;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v14, (uint64_t)v13, &demangling cache variable for type metadata for (String, CSVType));
    char v15 = *v13;
    unint64_t v16 = v13[1];
    uint64_t v43 = v15;
    int v44 = v16;
    uint64_t v46 = *(void (**)(unsigned char *, unsigned char *, uint64_t))(v55 + 32);
    v46(v56, v48, v4);
    BOOL v17 = (void *)*v58;
    unsigned __int8 v53 = v15;
    char v19 = specialized __RawDictionaryStorage.find<A>(_:)(v15, v16);
    long long v20 = (v18 & 1) == 0;
    char v21 = __OFADD__(v17[2], v20);
    uint64_t v22 = v17[2] + v20;
    if (v21) {
      BUG();
    }
    uint64_t v23 = v18;
    if (v17[3] < v22)
    {
      specialized _NativeDictionary._copyOrMoveAndResize(capacity:moveElements:)(v22, v59);
      char v19 = specialized __RawDictionaryStorage.find<A>(_:)(v53, v16);
      if ((v23 & 1) != (v24 & 1))
      {
        KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
        BUG();
      }
      goto LABEL_6;
    }
    uint64_t v4 = v57;
    if ((v59 & 1) == 0)
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, CSVType>);
      _NativeDictionary.copy()();
LABEL_6:
      uint64_t v4 = v57;
    }
    if (v23) {
      break;
    }
    uint64_t v25 = (void *)*v58;
    v25[(v19 >> 6) + 8] |= 1 << v19;
    uint64_t v26 = v25[6];
    uint64_t v27 = 16 * v19;
    *(void *)(v26 + v27) = v53;
    *(void *)(v26 + v27 + 8) = v16;
    v46((unsigned char *)(v25[7] + *(void *)(v55 + 72) * v19), v56, v4);
    uint64_t v31 = v25[2];
    char v21 = __OFADD__(1, v31);
    uint64_t v32 = v31 + 1;
    if (v21) {
      BUG();
    }
    v25[2] = v32;
    long long v14 = v51 + v47;
    LOBYTE(v32) = 1;
    int64_t v59 = v32;
    Swift::String v33 = v50-- == 1;
    long long v13 = v49;
    if (v33) {
      return swift_bridgeObjectRelease_n(v54, 2, v28, v29, v30);
    }
  }
  uint64_t v34 = swift_allocError(&type metadata for _MergeError, &protocol witness table for _MergeError, 0, 0);
  swift_willThrow();
  char v45 = v34;
  swift_errorRetain(v34);
  unint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
  if (swift_dynamicCast(&demangling cache variable for type metadata for Error, &v45, v35, &type metadata for _MergeError, 0))
  {
    uint64_t v41 = 0;
    uint64_t v42 = 0xE000000000000000;
    _StringGuts.grow(_:)(30);
    v39._char object = "Swift/NativeDictionary.swift" + 0x8000000000000000;
    v39._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
    String.append(_:)(v39);
    _print_unlocked<A, B>(_:_:)(&v43, &v41, &type metadata for String, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    v39._uint64_t countAndFlagsBits = 39;
    v39._char object = (void *)0xE100000000000000;
    String.append(_:)(v39);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v41, v42, "Swift/NativeDictionary.swift", 28, 2, 783, 0);
    BUG();
  }
  char v36 = v54;
  swift_bridgeObjectRelease(v54);
  (*(void (**)(unsigned char *, uint64_t))(v55 + 8))(v56, v4);
  char v37 = v44;
  swift_bridgeObjectRelease(v36);
  swift_bridgeObjectRelease(v37);
  return swift_errorRelease(v45);
}

{
  uint64_t v3;
  uint64_t v4;
  int64_t v5;
  void *v6;
  void *v7;
  uint64_t v8;
  uint64_t v9;
  int64_t v10;
  void *v11;
  void *v12;
  uint64_t *v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  void *v17;
  char v18;
  unint64_t v19;
  BOOL v20;
  BOOL v21;
  uint64_t v22;
  char v23;
  char v24;
  void *v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  BOOL v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  Swift::String v39;
  unsigned char v40[8];
  uint64_t v41;
  unint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  void (*v46)(unsigned char *, unsigned char *, uint64_t);
  uint64_t v47;
  unsigned char *v48;
  uint64_t *v49;
  uint64_t v50;
  uint64_t v51;
  uint64_t v52;
  uint64_t v53;
  uint64_t v54;
  uint64_t v55;
  unsigned char *v56;
  uint64_t v57;
  void *v58;
  int v59;

  uint64_t v58 = a3;
  int64_t v59 = a2;
  uint64_t v4 = type metadata accessor for JSONType(0);
  uint64_t v55 = *(void *)(v4 - 8);
  unint64_t v5 = *(void *)(v55 + 64);
  unint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  int64_t v56 = v40;
  unsigned __int8 v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, JSONType));
  uint64_t v9 = *(void *)(v8 - 8);
  unint64_t v10 = *(void *)(v9 + 64);
  uint64_t v11 = alloca(v10);
  int v12 = alloca(v10);
  long long v13 = (uint64_t *)v40;
  if (!*(void *)(a1 + 16)) {
    return swift_bridgeObjectRelease(a1);
  }
  int v50 = *(void *)(a1 + 16);
  unsigned __int8 v52 = v3;
  uint64_t v48 = &v40[*(int *)(v8 + 48)];
  long long v14 = a1 + ((*(unsigned __int8 *)(v9 + 80) + 32) & ~*(unsigned __int8 *)(v9 + 80));
  int v51 = *(void *)(v9 + 72);
  uint64_t v54 = a1;
  swift_bridgeObjectRetain(a1);
  uint64_t v57 = v4;
  uint64_t v49 = (uint64_t *)v40;
  while (1)
  {
    uint64_t v47 = v14;
    outlined init with copy of (String, JSONType)(v14, (uint64_t)v13);
    char v15 = *v13;
    unint64_t v16 = v13[1];
    uint64_t v43 = v15;
    int v44 = v16;
    uint64_t v46 = *(void (**)(unsigned char *, unsigned char *, uint64_t))(v55 + 32);
    v46(v56, v48, v4);
    BOOL v17 = (void *)*v58;
    unsigned __int8 v53 = v15;
    char v19 = specialized __RawDictionaryStorage.find<A>(_:)(v15, v16);
    long long v20 = (v18 & 1) == 0;
    char v21 = __OFADD__(v17[2], v20);
    uint64_t v22 = v17[2] + v20;
    if (v21) {
      BUG();
    }
    uint64_t v23 = v18;
    if (v17[3] < v22)
    {
      specialized _NativeDictionary._copyOrMoveAndResize(capacity:moveElements:)(v22, v59);
      char v19 = specialized __RawDictionaryStorage.find<A>(_:)(v53, v16);
      if ((v23 & 1) != (v24 & 1))
      {
        KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
        BUG();
      }
      goto LABEL_6;
    }
    uint64_t v4 = v57;
    if ((v59 & 1) == 0)
    {
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, JSONType>);
      _NativeDictionary.copy()();
LABEL_6:
      uint64_t v4 = v57;
    }
    if (v23) {
      break;
    }
    uint64_t v25 = (void *)*v58;
    v25[(v19 >> 6) + 8] |= 1 << v19;
    uint64_t v26 = v25[6];
    uint64_t v27 = 16 * v19;
    *(void *)(v26 + v27) = v53;
    *(void *)(v26 + v27 + 8) = v16;
    v46((unsigned char *)(v25[7] + *(void *)(v55 + 72) * v19), v56, v4);
    uint64_t v31 = v25[2];
    char v21 = __OFADD__(1, v31);
    uint64_t v32 = v31 + 1;
    if (v21) {
      BUG();
    }
    v25[2] = v32;
    long long v14 = v51 + v47;
    LOBYTE(v32) = 1;
    int64_t v59 = v32;
    Swift::String v33 = v50-- == 1;
    long long v13 = v49;
    if (v33) {
      return swift_bridgeObjectRelease_n(v54, 2, v28, v29, v30);
    }
  }
  uint64_t v34 = swift_allocError(&type metadata for _MergeError, &protocol witness table for _MergeError, 0, 0);
  swift_willThrow();
  char v45 = v34;
  swift_errorRetain(v34);
  unint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
  if (swift_dynamicCast(&demangling cache variable for type metadata for Error, &v45, v35, &type metadata for _MergeError, 0))
  {
    uint64_t v41 = 0;
    uint64_t v42 = 0xE000000000000000;
    _StringGuts.grow(_:)(30);
    v39._char object = "Swift/NativeDictionary.swift" + 0x8000000000000000;
    v39._uint64_t countAndFlagsBits = 0xD00000000000001BLL;
    String.append(_:)(v39);
    _print_unlocked<A, B>(_:_:)(&v43, &v41, &type metadata for String, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    v39._uint64_t countAndFlagsBits = 39;
    v39._char object = (void *)0xE100000000000000;
    String.append(_:)(v39);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v41, v42, "Swift/NativeDictionary.swift", 28, 2, 783, 0);
    BUG();
  }
  char v36 = v54;
  swift_bridgeObjectRelease(v54);
  (*(void (**)(unsigned char *, uint64_t))(v55 + 8))(v56, v4);
  char v37 = v44;
  swift_bridgeObjectRelease(v36);
  swift_bridgeObjectRelease(v37);
  return swift_errorRelease(v45);
}

uint64_t _s8CreateML15MLUntypedColumnVyACxcSTRzAA11MLDataValueO7ElementRtzlufcAA08_UntypedD0CyKXEfU_SayAEG_TG5TA_0(void *a1)
{
  return specialized closure #1 in MLUntypedColumn.init<A>(_:)(*(void **)(v1 + 16), a1);
}

uint64_t sub_127E17()
{
  __swift_destroy_boxed_opaque_existential_1Tm((void *)(v0 + 16));
  return swift_deallocObject(v0, 48, 7);
}

uint64_t MLDataColumn.dropDuplicates()(uint64_t a1)
{
  return MLDataColumn.dropDuplicates()(a1, specialized handling<A, B>(_:_:));
}

uint64_t Array<A>.init(_:)(uint64_t a1, uint64_t a2, uint64_t a3, double a4)
{
  int64_t v5 = *(void *)(*(void *)(a2 - 8) + 64);
  unint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v8 = *(void *)a1;
  if (*(unsigned char *)(a1 + 8))
  {
    outlined consume of Result<_DataTable, Error>(*(void *)a1, 1);
    return static Array._allocateUninitialized(_:)(0, a2);
  }
  else
  {
    uint64_t v20 = Array.init()(a2);
    uint64_t v17 = v20;
    uint64_t v18 = v8;
    char v19 = 0;
    uint64_t v11 = type metadata accessor for MLDataColumn(0, a2, a3, v10);
    uint64_t v12 = MLDataColumn.count.getter(0);
    if (v12 < 0) {
      BUG();
    }
    if (v12)
    {
      uint64_t v13 = 0;
      uint64_t v16 = v11;
      uint64_t v20 = v8;
      do
      {
        uint64_t v18 = v20;
        char v19 = 0;
        uint64_t v14 = v12;
        MLDataColumn.subscript.getter(v13, v16, a4);
        uint64_t v15 = type metadata accessor for Array(0, a2);
        Array.append(_:)(&v16, v15);
        uint64_t v12 = v14;
        ++v13;
      }
      while (v14 != v13);
      outlined consume of Result<_DataTable, Error>(v20, 0);
      return v17;
    }
    else
    {
      outlined consume of Result<_DataTable, Error>(v8, 0);
      return v20;
    }
  }
}

uint64_t MLDataColumn.dropMissing()(uint64_t a1)
{
  return MLDataColumn.dropDuplicates()(a1, specialized handling<A, B>(_:_:));
}

uint64_t MLDataColumn.count.getter()
{
  if (*(unsigned char *)(v0 + 8)) {
    return -1;
  }
  uint64_t v2 = *(void *)v0;
  outlined copy of Result<_DataTable, Error>(*(void *)v0, 0);
  uint64_t v3 = CMLColumn.size.getter();
  outlined consume of Result<_DataTable, Error>(v2, 0);
  return v3;
}

uint64_t MLDataColumn.init(repeating:count:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v16 = a4;
  uint64_t v17 = a2;
  uint64_t v15 = v4;
  uint64_t v6 = *(void *)(a3 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  (*(void (**)(uint64_t *, uint64_t))(v6 + 16))(&v13, a1);
  MLUntypedColumn.init<A>(repeating:count:)((uint64_t)&v13, v17, a3, v16);
  (*(void (**)(uint64_t, uint64_t))(v6 + 8))(a1, a3);
  uint64_t result = v13;
  char v11 = v14;
  uint64_t v12 = v15;
  void *v15 = v13;
  *((unsigned char *)v12 + 8) = v11;
  return result;
}

uint64_t MLDataColumn.subscript.getter(uint64_t a1, uint64_t a2, double a3)
{
  uint64_t v15 = v3;
  uint64_t v5 = *(void *)(a2 + 16);
  uint64_t v14 = type metadata accessor for Optional(0, v5);
  uint64_t v13 = *(void *)(v14 - 8);
  int64_t v6 = *(void *)(v13 + 64);
  int64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  char v9 = *((unsigned char *)v4 + 8);
  uint64_t v11 = *v4;
  char v12 = v9;
  MLDataColumn.element(at:)(a1, a2, a3);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v11, 1, v5) != 1) {
    return (*(uint64_t (**)(uint64_t, uint64_t *, uint64_t))(*(void *)(v5 - 8) + 32))(v15, &v11, v5);
  }
  (*(void (**)(uint64_t))(*(void *)(a2 + 24) + 24))(v5);
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v13 + 8))(&v11, v14);
}

uint64_t MLDataColumn.init(from:)(uint64_t a1)
{
  char v2 = *(unsigned char *)(a1 + 8);
  *(void *)uint64_t result = *(void *)a1;
  *(unsigned char *)(result + 8) = v2;
  return result;
}

uint64_t MLDataColumn.init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v18 = a5;
  uint64_t v17 = a4;
  uint64_t v16 = v5;
  uint64_t v7 = *(void *)(a3 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  char v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  (*(void (**)(uint64_t *, uint64_t))(v7 + 16))(&v14, a1);
  MLUntypedColumn.init<A>(_:)((uint64_t)&v14, a3);
  (*(void (**)(uint64_t, uint64_t))(v7 + 8))(a1, a3);
  uint64_t result = v14;
  char v12 = v15;
  uint64_t v13 = v16;
  *uint64_t v16 = v14;
  *((unsigned char *)v13 + 8) = v12;
  return result;
}

uint64_t MLDataColumn.element(at:)(uint64_t a1, uint64_t a2, double a3)
{
  if (*(unsigned char *)(v3 + 8))
  {
    long long v5 = 0;
    char v6 = 6;
  }
  else
  {
    uint64_t v7 = *(void *)v3;
    outlined copy of Result<_DataTable, Error>(v7, 0);
    _UntypedColumn.valueAtIndex(index:)(a1, a3);
    outlined consume of Result<_DataTable, Error>(v7, 0);
    long long v5 = v10;
    char v6 = v11;
  }
  uint64_t v8 = *(void *)(a2 + 16);
  long long v10 = v5;
  char v11 = v6;
  return (*(uint64_t (**)(long long *, uint64_t, void))(*(void *)(a2 + 24) + 16))(&v10, v8, *(void *)(a2 + 24));
}

uint64_t MLDataColumn.init<A>(column:type:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v6 = v5;
  uint64_t v7 = *(void *)a1;
  char v8 = *(unsigned char *)(a1 + 8);
  MLDataColumn.map<A>(to:)(a2, a2, a3, a5);
  outlined consume of Result<_DataTable, Error>(v7, v8);
  uint64_t result = v10;
  *(void *)uint64_t v6 = v10;
  *(unsigned char *)(v6 + 8) = v11;
  return result;
}

uint64_t MLDataColumn.map<A>(to:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MLUntypedColumn.map<A>(to:)(a1, a3, a4);
}

BOOL MLDataColumn.isEmpty.getter(uint64_t a1)
{
  return MLDataColumn.count.getter(a1) <= 0;
}

uint64_t MLDataColumn.error.getter()
{
  if (*(unsigned char *)(v0 + 8) != 1) {
    return 0;
  }
  uint64_t v1 = *(void *)v0;
  outlined copy of Result<_DataTable, Error>(*(void *)v0, 1);
  return v1;
}

char MLDataColumn.isValid.getter()
{
  return *(unsigned char *)(v0 + 8) ^ 1;
}

uint64_t MLDataColumn.init(repeating:count:)(long long *a1, uint64_t a2)
{
  uint64_t v3 = v2;
  char v4 = *((unsigned char *)a1 + 16);
  long long v7 = *a1;
  char v8 = v4;
  uint64_t v5 = type metadata accessor for _UntypedColumn();
  swift_allocObject(v5, 24, 7);
  uint64_t result = _UntypedColumn.init(repeating:count:)((uint64_t)&v7, a2, *(double *)&v7);
  *(void *)uint64_t v3 = result;
  *(unsigned char *)(v3 + 8) = 0;
  return result;
}

uint64_t MLDataColumn.init()()
{
  uint64_t v1 = v0;
  uint64_t v2 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t result = swift_allocError(&type metadata for MLCreateError, v2, 0, 0);
  *(void *)uint64_t v4 = 0xD00000000000001DLL;
  *(void *)(v4 + 8) = "id column named '" + 0x8000000000000000;
  *(_OWORD *)(v4 + 16) = 0;
  *(_OWORD *)(v4 + 32) = 0;
  *(unsigned char *)(v4 + 48) = 1;
  *(void *)uint64_t v1 = result;
  *(unsigned char *)(v1 + 8) = 1;
  return result;
}

void MLDataColumn.append(contentsOf:)(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t v3 = *v1;
  char v4 = 1;
  if (*((unsigned char *)v2 + 8))
  {
    uint64_t v5 = v3;
  }
  else
  {
    uint64_t v5 = *(void *)a1;
    if (*(unsigned char *)(a1 + 8))
    {
      outlined copy of Result<_DataTable, Error>(*(void *)a1, 1);
      outlined consume of Result<_DataTable, Error>(v3, 0);
    }
    else
    {
      outlined copy of Result<_DataTable, Error>(*(void *)a1, 0);
      outlined copy of Result<_DataTable, Error>(v3, 0);
      uint64_t v6 = _UntypedColumn.appending(contentsOf:)(v5);
      outlined consume of Result<_DataTable, Error>(v5, 0);
      outlined consume of Result<_DataTable, Error>(v3, 0);
      outlined consume of Result<_DataTable, Error>(v3, 0);
      char v4 = 0;
      uint64_t v5 = v6;
    }
  }
  *uint64_t v2 = v5;
  *((unsigned char *)v2 + 8) = v4;
}

uint64_t MLDataColumn.subscript.getter(uint64_t a1)
{
  uint64_t v2 = v1;
  char v3 = *(unsigned char *)(a1 + 8);
  uint64_t v7 = *(void *)a1;
  char v8 = v3;
  MLUntypedColumn.subscript.getter(&v7);
  uint64_t result = v5;
  *(void *)uint64_t v2 = v5;
  *(unsigned char *)(v2 + 8) = v6;
  return result;
}

{
  uint64_t v1;
  uint64_t v2;
  char v3;
  uint64_t result;
  uint64_t v5;
  char v6;
  uint64_t v7;
  char v8;

  uint64_t v2 = v1;
  char v3 = *(unsigned char *)(a1 + 8);
  uint64_t v7 = *(void *)a1;
  char v8 = v3;
  MLUntypedColumn.subscript.getter(&v7);
  uint64_t result = v5;
  *(void *)uint64_t v2 = v5;
  *(unsigned char *)(v2 + 8) = v6;
  return result;
}

char MLDataColumn.map<A>(skipUndefined:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v28 = a3;
  uint64_t v26 = v6;
  uint64_t v27 = a2;
  uint64_t v31 = *(void *)v7;
  char v11 = *(unsigned char *)(v7 + 8);
  char v12 = (void *)swift_allocObject(&unk_399670, 64, 7);
  uint64_t v13 = *(void *)(a4 + 16);
  uint64_t v14 = *(void *)(a4 + 24);
  v12[2] = v13;
  uint64_t v29 = a5;
  void v12[3] = a5;
  uint64_t v15 = v28;
  uint64_t v12[4] = v14;
  uint64_t v30 = a6;
  void v12[5] = a6;
  v12[6] = v27;
  v12[7] = v15;
  if (v11)
  {
    uint64_t v16 = v31;
    v32[0] = v31;
    outlined copy of Result<_DataTable, Error>(v31, 1);
    swift_retain();
    outlined copy of Result<_DataTable, Error>(v31, 1);
    uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v18 = _getErrorEmbeddedNSError<A>(_:)(v32, v17, &protocol self-conformance witness table for Error);
    if (v18)
    {
      uint64_t v19 = v18;
      outlined consume of Result<_DataTable, Error>(v31, 1);
    }
    else
    {
      uint64_t v19 = swift_allocError(v17, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v23 = v32[0];
    }
    outlined consume of Result<_DataTable, Error>(v16, 1);
    swift_release();
    char result = 1;
  }
  else
  {
    uint64_t v20 = v31;
    uint64_t v25 = v31;
    uint64_t v21 = v13;
    swift_retain();
    outlined copy of Result<_DataTable, Error>(v31, 0);
    closure #2 in MLDataColumn.map<A>(skipUndefined:_:)((uint64_t)&v25, (uint64_t)partial apply for closure #1 in MLDataColumn.map<A>(skipUndefined:_:), (uint64_t)v12, v21, v29, v14, v30);
    outlined consume of Result<_DataTable, Error>(v20, 0);
    swift_release();
    uint64_t v19 = v32[0];
    char result = 0;
  }
  uint64_t v24 = v26;
  *uint64_t v26 = v19;
  *((unsigned char *)v24 + 8) = result;
  return result;
}

uint64_t closure #1 in MLDataColumn.map<A>(skipUndefined:_:)(uint64_t a1, void (*a2)(uint64_t *), uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, double a7, uint64_t a8)
{
  uint64_t v31 = a6;
  uint64_t v26 = a3;
  uint64_t v25 = a2;
  uint64_t v28 = type metadata accessor for Optional(0, a5);
  uint64_t v29 = *(void *)(v28 - 8);
  int64_t v10 = *(void *)(v29 + 64);
  char v11 = alloca(v10);
  char v12 = alloca(v10);
  uint64_t v27 = *(void *)(a5 - 8);
  int64_t v13 = *(void *)(v27 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v30 = &v23;
  uint64_t v23 = type metadata accessor for Optional(0, a4);
  uint64_t v24 = *(void *)(v23 - 8);
  int64_t v16 = *(void *)(v24 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  if (CMLFeatureValue.isUndefined.getter()) {
    __swift_storeEnumTagSinglePayload((uint64_t)&v23, 1, 1, a4);
  }
  else {
    static MLDataValueConvertible.makeInstance(featureValue:)(a1, a4, v31, a7);
  }
  v25(&v23);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v23, 1, a5) == 1)
  {
    (*(void (**)(uint64_t *, uint64_t))(v29 + 8))(&v23, v28);
    type metadata accessor for CMLFeatureValue();
    uint64_t v19 = CMLFeatureValue.__allocating_init()(0);
  }
  else
  {
    uint64_t v20 = v30;
    uint64_t v21 = v27;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v27 + 32))(v30, &v23, a5);
    uint64_t v19 = MLDataValueConvertible.featureValue.getter(a5, a8);
    (*(void (**)(uint64_t *, uint64_t))(v21 + 8))(v20, a5);
  }
  (*(void (**)(uint64_t *, uint64_t))(v24 + 8))(&v23, v23);
  return v19;
}

uint64_t closure #2 in MLDataColumn.map<A>(skipUndefined:_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  int64_t v10 = v7;
  (*(void (**)(uint64_t))(a7 + 8))(a5);
  uint64_t result = _UntypedColumn.map(_:skipUndefined:outputType:)(a2, a3, 0, v11);
  *int64_t v10 = result;
  return result;
}

uint64_t MLDataColumn.map<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return MLDataColumn.map<A>(_:)(a1, a2, a3, a4, a5, (uint64_t)&unk_3995B8, (uint64_t)partial apply for closure #1 in MLDataColumn.map<A>(_:));
}

{
  return MLDataColumn.map<A>(_:)(a1, a2, a3, a4, a5, (uint64_t)&unk_3995E0, (uint64_t)partial apply for closure #1 in MLDataColumn.map<A>(_:));
}

uint64_t closure #1 in MLDataColumn.map<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v11[0] = a2;
  uint64_t v5 = type metadata accessor for Optional(0, a4);
  uint64_t v6 = *(void *)(v5 - 8);
  int64_t v7 = *(void *)(v6 + 64);
  char v8 = alloca(v7);
  char v9 = alloca(v7);
  (*(void (**)(void *, uint64_t, uint64_t))(v6 + 16))(v11, a1, v5);
  if (__swift_getEnumTagSinglePayload((uint64_t)v11, 1, a4) == 1) {
    BUG();
  }
  ((void (*)(void *))v11[0])(v11);
  return (*(uint64_t (**)(void *, uint64_t))(*(void *)(a4 - 8) + 8))(v11, a4);
}

uint64_t MLDataColumn.map<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7)
{
  char v9 = (void *)swift_allocObject(a6, 64, 7);
  uint64_t v10 = *(void *)(a3 + 24);
  v9[2] = *(void *)(a3 + 16);
  v9[3] = a4;
  void v9[4] = v10;
  double v9[5] = a5;
  void v9[6] = a1;
  v9[7] = a2;
  swift_retain();
  MLDataColumn.map<A>(skipUndefined:_:)(1, a7, (uint64_t)v9, a3, a4, a5);
  return swift_release();
}

uint64_t closure #1 in MLDataColumn.map<A>(_:)(uint64_t a1, void (*a2)(uint64_t *), uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v15 = a5;
  int64_t v16 = a2;
  uint64_t v7 = v5;
  uint64_t v8 = type metadata accessor for Optional(0, a4);
  uint64_t v9 = *(void *)(v8 - 8);
  int64_t v10 = *(void *)(v9 + 64);
  char v11 = alloca(v10);
  char v12 = alloca(v10);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v9 + 16))(&v14, a1, v8);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v14, 1, a4) == 1) {
    BUG();
  }
  v16(&v14);
  (*(void (**)(uint64_t *, uint64_t))(*(void *)(a4 - 8) + 8))(&v14, a4);
  return __swift_storeEnumTagSinglePayload(v7, 0, 1, v15);
}

char MLDataColumn.mapMissing<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  return MLDataColumn.map<A>(skipUndefined:_:)(0, a1, a2, a3, a4, a5);
}

char MLDataColumn.fillMissing(with:)(uint64_t a1, uint64_t a2)
{
  uint64_t v4 = v2;
  uint64_t v5 = *(void *)v3;
  if (*(unsigned char *)(v3 + 8))
  {
    v12[0] = *(void *)v3;
    swift_errorRetain(v5);
    outlined copy of Result<_DataTable, Error>(v5, 1);
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v7 = _getErrorEmbeddedNSError<A>(_:)(v12, v6, &protocol self-conformance witness table for Error);
    if (v7)
    {
      uint64_t v8 = v7;
      outlined consume of Result<_DataTable, Error>(v5, 1);
    }
    else
    {
      uint64_t v8 = swift_allocError(v6, &protocol self-conformance witness table for Error, 0, 0);
      *int64_t v10 = v12[0];
    }
    outlined consume of Result<_DataTable, Error>(v5, 1);
    char result = 1;
  }
  else
  {
    uint64_t v11 = *(void *)v3;
    outlined copy of Result<_DataTable, Error>(v5, 0);
    closure #1 in MLDataColumn.fillMissing(with:)(&v11, a1, *(void *)(a2 + 16), *(void *)(a2 + 24));
    outlined consume of Result<_DataTable, Error>(v5, 0);
    uint64_t v8 = v12[0];
    char result = 0;
  }
  *(void *)uint64_t v4 = v8;
  *(unsigned char *)(v4 + 8) = result;
  return result;
}

uint64_t closure #1 in MLDataColumn.fillMissing(with:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v15 = v4;
  uint64_t v6 = *a1;
  uint64_t v7 = MLDataValueConvertible.featureValue.getter(a3, a4);
  uint64_t v8 = specialized handling<A, B, C>(_:_:_:)(*(void *)(*(void *)(v6 + 16) + 16), *(void *)(v7 + 16));
  if (v5) {
    return swift_release();
  }
  uint64_t v10 = v8;
  if (!v8) {
    BUG();
  }
  uint64_t v11 = type metadata accessor for CMLColumn();
  uint64_t v12 = swift_allocObject(v11, 24, 7);
  *(void *)(v12 + 16) = v10;
  uint64_t v13 = type metadata accessor for _UntypedColumn();
  uint64_t v14 = swift_allocObject(v13, 24, 7);
  *(void *)(v14 + 16) = v12;
  swift_release();
  uint64_t result = (uint64_t)v15;
  uint64_t *v15 = v14;
  return result;
}

char *MLDataColumn.prefix(_:)(uint64_t a1, uint64_t a2)
{
  return MLDataColumn.prefix(_:)(a1, a2, specialized handling<A, B, C>(_:_:_:));
}

char *MLDataColumn.suffix(_:)(uint64_t a1, uint64_t a2)
{
  return MLDataColumn.prefix(_:)(a1, a2, specialized handling<A, B, C>(_:_:_:));
}

char *MLDataColumn.prefix(_:)(uint64_t a1, uint64_t a2, uint64_t (*a3)(uint64_t, uint64_t))
{
  uint64_t v5 = v3;
  if (a1 <= 0)
  {
    uint64_t v10 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    uint64_t v9 = swift_allocError(&type metadata for MLCreateError, v10, 0, 0);
    *(void *)uint64_t v11 = 0xD00000000000002BLL;
    uint64_t result = "Column initialized as invalid" + 0x8000000000000000;
    *(void *)(v11 + 8) = "Column initialized as invalid" + 0x8000000000000000;
    *(_OWORD *)(v11 + 16) = 0;
    *(_OWORD *)(v11 + 32) = 0;
    *(unsigned char *)(v11 + 48) = 0;
LABEL_9:
    char v17 = 1;
    goto LABEL_10;
  }
  uint64_t v6 = *(void *)v4;
  if (*(unsigned char *)(v4 + 8))
  {
    v23[0] = *(void *)v4;
    swift_errorRetain(v6);
    outlined copy of Result<_DataTable, Error>(v6, 1);
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v8 = _getErrorEmbeddedNSError<A>(_:)(v23, v7, &protocol self-conformance witness table for Error);
    if (v8)
    {
      uint64_t v9 = v8;
      outlined consume of Result<_DataTable, Error>(v6, 1);
    }
    else
    {
      uint64_t v9 = swift_allocError(v7, &protocol self-conformance witness table for Error, 0, 0);
      *int64_t v16 = v23[0];
    }
    uint64_t result = (char *)outlined consume of Result<_DataTable, Error>(v6, 1);
    goto LABEL_9;
  }
  uint64_t v14 = *(void *)(*(void *)(v6 + 16) + 16);
  outlined copy of Result<_DataTable, Error>(v6, 0);
  uint64_t v15 = a3(v14, a1);
  uint64_t v18 = v15;
  if (!v15) {
    BUG();
  }
  char v17 = 0;
  uint64_t v19 = type metadata accessor for CMLColumn();
  uint64_t v20 = swift_allocObject(v19, 24, 7);
  *(void *)(v20 + 16) = v18;
  uint64_t v21 = v20;
  uint64_t v22 = type metadata accessor for _UntypedColumn();
  uint64_t v9 = swift_allocObject(v22, 24, 7);
  *(void *)(v9 + 16) = v21;
  uint64_t result = (char *)outlined consume of Result<_DataTable, Error>(v6, 0);
LABEL_10:
  *(void *)uint64_t v5 = v9;
  *(unsigned char *)(v5 + 8) = v17;
  return result;
}

uint64_t MLDataColumn.sort(byIncreasingOrder:)(char a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = *(void *)v2;
  if (*(unsigned char *)(v2 + 8))
  {
    v18[0] = *(void *)v2;
    swift_errorRetain(v4);
    outlined copy of Result<_DataTable, Error>(v4, 1);
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v6 = _getErrorEmbeddedNSError<A>(_:)(v18, v5, &protocol self-conformance witness table for Error);
    if (v6)
    {
      uint64_t v7 = v6;
      outlined consume of Result<_DataTable, Error>(v4, 1);
    }
    else
    {
      uint64_t v7 = swift_allocError(v5, &protocol self-conformance witness table for Error, 0, 0);
      *uint64_t v10 = v18[0];
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v4, 1);
    char v12 = 1;
  }
  else
  {
    uint64_t v8 = *(void *)(*(void *)(v4 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(*(void *)v2, 0);
    uint64_t v9 = specialized handling<A, B, C>(_:_:_:)(v8, a1);
    uint64_t v13 = v9;
    if (!v9) {
      BUG();
    }
    char v12 = 0;
    uint64_t v14 = type metadata accessor for CMLColumn();
    uint64_t v15 = swift_allocObject(v14, 24, 7);
    *(void *)(v15 + 16) = v13;
    uint64_t v16 = v15;
    uint64_t v17 = type metadata accessor for _UntypedColumn();
    uint64_t v7 = swift_allocObject(v17, 24, 7);
    *(void *)(v7 + 16) = v16;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v4, 0);
  }
  *(void *)uint64_t v3 = v7;
  *(unsigned char *)(v3 + 8) = v12;
  return result;
}

uint64_t MLDataColumn.copy()(uint64_t a1)
{
  return MLDataColumn.dropDuplicates()(a1, specialized handling<A, B>(_:_:));
}

uint64_t MLDataColumn.dropDuplicates()(uint64_t a1, uint64_t (*a2)(uint64_t))
{
  uint64_t v4 = v2;
  uint64_t v5 = *(void *)v3;
  if (*(unsigned char *)(v3 + 8))
  {
    v19[0] = *(void *)v3;
    swift_errorRetain(v5);
    outlined copy of Result<_DataTable, Error>(v5, 1);
    uint64_t v6 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    uint64_t v7 = _getErrorEmbeddedNSError<A>(_:)(v19, v6, &protocol self-conformance witness table for Error);
    if (v7)
    {
      uint64_t v8 = v7;
      outlined consume of Result<_DataTable, Error>(v5, 1);
    }
    else
    {
      uint64_t v8 = swift_allocError(v6, &protocol self-conformance witness table for Error, 0, 0);
      uint64_t *v11 = v19[0];
    }
    uint64_t result = outlined consume of Result<_DataTable, Error>(v5, 1);
    char v13 = 1;
  }
  else
  {
    uint64_t v9 = *(void *)(*(void *)(v5 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(*(void *)v3, 0);
    uint64_t v10 = a2(v9);
    uint64_t v14 = v10;
    if (!v10) {
      BUG();
    }
    char v13 = 0;
    uint64_t v15 = type metadata accessor for CMLColumn();
    uint64_t v16 = swift_allocObject(v15, 24, 7);
    *(void *)(v16 + 16) = v14;
    uint64_t v17 = v16;
    uint64_t v18 = type metadata accessor for _UntypedColumn();
    uint64_t v8 = swift_allocObject(v18, 24, 7);
    *(void *)(v8 + 16) = v17;
    uint64_t result = outlined consume of Result<_DataTable, Error>(v5, 0);
  }
  *(void *)uint64_t v4 = v8;
  *(unsigned char *)(v4 + 8) = v13;
  return result;
}

uint64_t MLDataColumn.materialize()()
{
  uint64_t v2 = *(void *)v1;
  if (*(unsigned char *)(v1 + 8))
  {
    uint64_t v3 = *(void *)v1;
    outlined copy of Result<_DataTable, Error>(*(void *)v1, 1);
    return swift_willThrow(v3, 1, v4, v5, v6, v7);
  }
  else
  {
    uint64_t v9 = v0;
    outlined copy of Result<_DataTable, Error>(v2, 0);
    CMLColumn.materialize()();
    uint64_t result = outlined consume of Result<_DataTable, Error>(v2, 0);
    if (!v10)
    {
      *(void *)uint64_t v9 = v2;
      *(unsigned char *)(v9 + 8) = 0;
      return outlined copy of Result<_DataTable, Error>(v2, 0);
    }
  }
  return result;
}

uint64_t MLDataColumn.subscript.getter(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  MLUntypedColumn.subscript.getter(a1, a2);
  uint64_t result = v5;
  *(void *)uint64_t v3 = v5;
  *(unsigned char *)(v3 + 8) = v6;
  return result;
}

uint64_t MLDataColumn.subscript.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v19 = a3;
  uint64_t v20 = a1;
  uint64_t v7 = v4;
  uint64_t v8 = *(void *)v5;
  char v9 = *(unsigned char *)(v5 + 8);
  uint64_t v17 = *(void *)v5;
  LOBYTE(v18) = v9;
  uint64_t v10 = MLDataColumn.count.getter(a1);
  if (v10 < 0) {
    BUG();
  }
  v16[0] = 0;
  v16[1] = v10;
  uint64_t v21 = v7;
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Range<Int>);
  uint64_t v12 = lazy protocol witness table accessor for type Range<Int> and conformance <> Range<A>();
  ((void (*)(void *, uint64_t, uint64_t, uint64_t, uint64_t))dispatch thunk of RangeExpression.relative<A>(to:))(v16, v11, v12, v19, a4);
  uint64_t v13 = v17;
  uint64_t v14 = v18;
  uint64_t v17 = v8;
  LOBYTE(v18) = v9;
  return MLDataColumn.subscript.getter(v13, v14);
}

uint64_t MLDataColumn.show()()
{
  uint64_t v2 = v0;
  uint64_t v3 = 0;
  if (!*(unsigned char *)(v1 + 8))
  {
    uint64_t v4 = *(void *)v1;
    uint64_t v5 = *(void *)(*(void *)(*(void *)v1 + 16) + 16);
    outlined copy of Result<_DataTable, Error>(*(void *)v1, 0);
    outlined copy of Result<_DataTable, Error>(v4, 0);
    swift_retain();
    uint64_t v6 = specialized handling<A, B, C, D, E, F>(_:_:_:_:_:_:)(v5, (uint64_t)"", (uint64_t)"", (uint64_t)"", 0);
    if (!v6) {
      BUG();
    }
    uint64_t v7 = type metadata accessor for CMLPlot();
    uint64_t v3 = swift_allocObject(v7, 24, 7);
    *(void *)(v3 + 16) = v6;
    outlined consume of Result<_DataTable, Error>(v4, 0);
    swift_release();
    outlined consume of Result<_DataTable, Error>(v4, 0);
  }
  v2[3] = (uint64_t)&type metadata for ML1DVisualization;
  uint64_t result = lazy protocol witness table accessor for type ML1DVisualization and conformance ML1DVisualization();
  v2[4] = result;
  *uint64_t v2 = v3;
  return result;
}

uint64_t MLDataColumn<>.init<A>(column:)(uint64_t *a1, uint64_t a2, uint64_t a3)
{
  return MLDataColumn<>.init<A>(column:)(a1, a2, a3, (uint64_t)&type metadata for Int, (uint64_t)&protocol witness table for Int);
}

{
  return MLDataColumn<>.init<A>(column:)(a1, a2, a3, (uint64_t)&type metadata for Double, (uint64_t)&protocol witness table for Double);
}

{
  return MLDataColumn<>.init<A>(column:)(a1, a2, a3, (uint64_t)&type metadata for String, (uint64_t)&protocol witness table for String);
}

{
  return MLDataColumn<>.init<A>(column:)(a1, a2, a3, (uint64_t)&type metadata for MLDataValue.SequenceType, (uint64_t)&protocol witness table for MLDataValue.SequenceType);
}

{
  return MLDataColumn<>.init<A>(column:)(a1, a2, a3, &demangling cache variable for type metadata for [Int], &lazy protocol witness table cache variable for type [Int] and conformance <A> [A]);
}

{
  return MLDataColumn<>.init<A>(column:)(a1, a2, a3, &demangling cache variable for type metadata for [Double], &lazy protocol witness table cache variable for type [Double] and conformance <A> [A]);
}

{
  return MLDataColumn<>.init<A>(column:)(a1, a2, a3, &demangling cache variable for type metadata for [String], &lazy protocol witness table cache variable for type [String] and conformance <A> [A]);
}

{
  return MLDataColumn<>.init<A>(column:)(a1, a2, a3, (uint64_t)&type metadata for MLDataValue.DictionaryType, (uint64_t)&protocol witness table for MLDataValue.DictionaryType);
}

uint64_t MLDataColumn<>.sum()()
{
  uint64_t v1 = 0;
  if (!*(unsigned char *)(v0 + 8))
  {
    uint64_t v2 = *(void *)v0;
    uint64_t v3 = *(void *)v0;
    outlined copy of Result<_DataTable, Error>(*(void *)v0, 0);
    uint64_t v4 = CMLColumn.sum()();
    if (CMLFeatureValue.isInt64.getter(v3))
    {
      uint64_t v1 = specialized handling<A, B>(_:_:)(*(void *)(v4 + 16));
      swift_release();
      outlined consume of Result<_DataTable, Error>(v2, 0);
    }
    else
    {
      uint64_t v1 = 0;
      outlined consume of Result<_DataTable, Error>(v2, 0);
      swift_release();
    }
  }
  return v1;
}

uint64_t MLDataColumn<>.min()()
{
  return MLDataColumn<>.min()(CMLColumn.min());
}

uint64_t MLDataColumn<>.max()()
{
  return MLDataColumn<>.min()(CMLColumn.max());
}

uint64_t MLDataColumn<>.min()(uint64_t (*a1)(void))
{
  uint64_t v2 = 0;
  if (!*(unsigned char *)(v1 + 8))
  {
    uint64_t v3 = *(void *)v1;
    outlined copy of Result<_DataTable, Error>(*(void *)v1, 0);
    uint64_t v4 = a1();
    if (CMLFeatureValue.isInt64.getter(v3))
    {
      uint64_t v2 = specialized handling<A, B>(_:_:)(*(void *)(v4 + 16));
      swift_release();
      outlined consume of Result<_DataTable, Error>(v3, 0);
    }
    else
    {
      uint64_t v2 = 0;
      outlined consume of Result<_DataTable, Error>(v3, 0);
      swift_release();
    }
  }
  return v2;
}

uint64_t MLDataColumn<>.std()(double a1)
{
  return MLDataColumn<>.std()(CMLColumn.stdev(), a1);
}

{
  return MLDataColumn<>.std()(CMLColumn.stdev(), a1);
}

uint64_t MLDataColumn<>.mean()(double a1)
{
  return MLDataColumn<>.std()(CMLColumn.mean(), a1);
}

{
  return MLDataColumn<>.std()(CMLColumn.mean(), a1);
}

uint64_t MLDataColumn<>.sum()(double a1)
{
  return MLDataColumn<>.std()(CMLColumn.sum(), a1);
}

uint64_t MLDataColumn<>.min()(double a1)
{
  return MLDataColumn<>.min()(CMLColumn.min(), a1);
}

uint64_t MLDataColumn<>.max()(double a1)
{
  return MLDataColumn<>.min()(CMLColumn.max(), a1);
}

uint64_t MLDataColumn<>.min()(uint64_t (*a1)(void), double a2)
{
  uint64_t v3 = 0;
  if (!*(unsigned char *)(v2 + 8))
  {
    uint64_t v4 = *(void *)v2;
    outlined copy of Result<_DataTable, Error>(*(void *)v2, 0);
    uint64_t v5 = a1();
    if (CMLFeatureValue.isDouble.getter())
    {
      specialized handling<A, B>(_:_:)(*(void *)(v5 + 16));
      swift_release();
      outlined consume of Result<_DataTable, Error>(v4, 0);
      return *(void *)&a2;
    }
    else
    {
      uint64_t v3 = 0;
      outlined consume of Result<_DataTable, Error>(v4, 0);
      swift_release();
    }
  }
  return v3;
}

uint64_t MLDataColumn<>.std()(uint64_t (*a1)(void), double a2)
{
  uint64_t v3 = 0;
  if (!*(unsigned char *)(v2 + 8))
  {
    uint64_t v4 = *(void *)v2;
    outlined copy of Result<_DataTable, Error>(*(void *)v2, 0);
    uint64_t v5 = a1();
    if (CMLFeatureValue.isDouble.getter())
    {
      specialized handling<A, B>(_:_:)(*(void *)(v5 + 16));
      swift_release();
      outlined consume of Result<_DataTable, Error>(v4, 0);
      return *(void *)&a2;
    }
    else
    {
      uint64_t v3 = 0;
      outlined consume of Result<_DataTable, Error>(v4, 0);
      swift_release();
    }
  }
  return v3;
}

uint64_t MLDataColumn<>.stdev()(double a1)
{
  return MLDataColumn<>.stdev()(a1);
}

{
  return MLDataColumn<>.stdev()(a1);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;

  uint64_t v2 = 0;
  if (!*(unsigned char *)(v1 + 8))
  {
    uint64_t v3 = *(void *)v1;
    outlined copy of Result<_DataTable, Error>(*(void *)v1, 0);
    uint64_t v4 = CMLColumn.stdev()();
    if (CMLFeatureValue.isDouble.getter())
    {
      specialized handling<A, B>(_:_:)(*(void *)(v4 + 16));
      swift_release();
      outlined consume of Result<_DataTable, Error>(v3, 0);
      return *(void *)&a1;
    }
    else
    {
      uint64_t v2 = 0;
      outlined consume of Result<_DataTable, Error>(v3, 0);
      swift_release();
    }
  }
  return v2;
}

uint64_t MLDataColumn<>.init<A>(column:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t *a4, uint64_t *a5)
{
  uint64_t v17 = a3;
  uint64_t v7 = v5;
  uint64_t v18 = a2;
  char v9 = *((unsigned char *)a1 + 8);
  uint64_t v15 = *a1;
  char v16 = v9;
  uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(a4);
  uint64_t v11 = lazy protocol witness table accessor for type [String] and conformance <A> [A](a5, a4);
  MLDataColumn.init<A>(column:type:)((uint64_t)&v15, v10, v10, a2, v11);
  uint64_t result = v13;
  *(void *)uint64_t v7 = v13;
  *(unsigned char *)(v7 + 8) = v14;
  return result;
}

uint64_t MLDataColumn<>.init<A>(column:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v6 = v5;
  char v7 = *((unsigned char *)a1 + 8);
  uint64_t v11 = *a1;
  char v12 = v7;
  MLDataColumn.init<A>(column:type:)((uint64_t)&v11, a4, a4, a2, a5);
  uint64_t result = v9;
  *(void *)uint64_t v6 = v9;
  *(unsigned char *)(v6 + 8) = v10;
  return result;
}

uint64_t MLDataColumn.customMirror.getter(uint64_t a1)
{
  uint64_t v26 = a1;
  uint64_t v22 = v1;
  uint64_t v23 = type metadata accessor for Mirror.AncestorRepresentation(0);
  uint64_t v24 = *(void *)(v23 - 8);
  int64_t v3 = *(void *)(v24 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v25 = &v20;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Mirror.DisplayStyle?)
                             - 8)
                 + 64);
  char v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v9 = *v2;
  char v10 = *((unsigned char *)v2 + 8);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, Any)>);
  char v12 = (void *)swift_allocObject(v11, 128, 7);
  v12[2] = 2;
  void v12[3] = 4;
  uint64_t v12[4] = 0x746E756F63;
  void v12[5] = 0xE500000000000000;
  uint64_t v20 = v9;
  char v21 = v10;
  uint64_t v13 = MLDataColumn.count.getter(v11);
  v12[9] = &type metadata for Int;
  v12[6] = v13;
  v12[10] = 1701869940;
  v12[11] = 0xE400000000000000;
  uint64_t v14 = v26;
  uint64_t v15 = *(void *)(v26 + 16);
  v12[15] = swift_getMetatypeMetadata(v15);
  v12[12] = v15;
  uint64_t v20 = v14;
  LODWORD(v15) = enum case for Mirror.DisplayStyle.dictionary(_:);
  uint64_t v16 = type metadata accessor for Mirror.DisplayStyle(0);
  (*(void (**)(uint64_t *, void, uint64_t))(*(void *)(v16 - 8) + 104))(&v20, v15, v16);
  __swift_storeEnumTagSinglePayload((uint64_t)&v20, 0, 1, v16);
  uint64_t v17 = v25;
  (*(void (**)(uint64_t *, void, uint64_t))(v24 + 104))(v25, enum case for Mirror.AncestorRepresentation.suppressed(_:), v23);
  uint64_t MetatypeMetadata = swift_getMetatypeMetadata(v14);
  return Mirror.init<A>(_:children:displayStyle:ancestorRepresentation:)(&v20, v12, &v20, v17, MetatypeMetadata);
}

uint64_t protocol witness for CustomReflectable.customMirror.getter in conformance MLDataColumn<A>(uint64_t a1)
{
  return MLDataColumn.customMirror.getter(a1);
}

uint64_t MLDataColumn.description.getter(uint64_t a1, double a2)
{
  uint64_t v3 = a1;
  uint64_t v26 = *(void *)(a1 + 16);
  int64_t v4 = *(void *)(*(void *)(v26 - 8) + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v27 = &v23;
  uint64_t v7 = *(void *)v2;
  if (*(unsigned char *)(v2 + 8))
  {
    uint64_t v28 = 0;
    unint64_t v29 = 0xE000000000000000;
    v30._uint64_t countAndFlagsBits = v7;
    uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Error);
    _print_unlocked<A, B>(_:_:)(&v30, &v28, v8, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
    return v28;
  }
  else
  {
    uint64_t v28 = 91;
    unint64_t v29 = 0xE100000000000000;
    v30._uint64_t countAndFlagsBits = v7;
    LOBYTE(v30._object) = 0;
    outlined copy of Result<_DataTable, Error>(v7, 0);
    uint64_t v10 = MLDataColumn.count.getter(v7);
    uint64_t v11 = 10;
    if (v10 < 10) {
      uint64_t v11 = v10;
    }
    uint64_t v23 = v11;
    if (v11 < 0) {
      BUG();
    }
    uint64_t v25 = v10;
    if (v11)
    {
      uint64_t v12 = 0;
      uint64_t v24 = a1;
      do
      {
        if (v12)
        {
          v13._uint64_t countAndFlagsBits = 8236;
          v13._char object = (void *)0xE200000000000000;
          String.append(_:)(v13);
        }
        _UntypedColumn.type.getter();
        if (LOBYTE(v30._countAndFlagsBits) == 2)
        {
          v30._uint64_t countAndFlagsBits = v7;
          LOBYTE(v30._object) = 0;
          uint64_t v14 = v27;
          MLDataColumn.subscript.getter(v12, v3, a2);
          v15._uint64_t countAndFlagsBits = String.init<A>(describing:)(v14, v26);
          LOBYTE(v14) = v15._object;
          v30._uint64_t countAndFlagsBits = 34;
          v30._char object = (void *)0xE100000000000000;
          String.append(_:)(v15);
          swift_bridgeObjectRelease((_BYTE)v14);
          LOBYTE(v14) = v30._object;
          swift_bridgeObjectRetain(v30._object);
          v16._uint64_t countAndFlagsBits = 34;
          v16._char object = (void *)0xE100000000000000;
          uint64_t v3 = v24;
          String.append(_:)(v16);
          swift_bridgeObjectRelease((_BYTE)v14);
          Swift::String v17 = v30;
          char object = (char)v30._object;
        }
        else
        {
          v30._uint64_t countAndFlagsBits = v7;
          LOBYTE(v30._object) = 0;
          uint64_t v19 = v27;
          MLDataColumn.subscript.getter(v12, v3, a2);
          v20._uint64_t countAndFlagsBits = String.init<A>(describing:)(v19, v26);
          char object = (char)v20._object;
          Swift::String v17 = v20;
        }
        String.append(_:)(v17);
        ++v12;
        swift_bridgeObjectRelease(object);
      }
      while (v23 != v12);
    }
    if (v25 >= 11)
    {
      v21._uint64_t countAndFlagsBits = 0x2E2E2E202CLL;
      v21._char object = (void *)0xE500000000000000;
      String.append(_:)(v21);
    }
    v22._uint64_t countAndFlagsBits = 93;
    v22._char object = (void *)0xE100000000000000;
    String.append(_:)(v22);
    outlined consume of Result<_DataTable, Error>(v7, 0);
    return v28;
  }
}

uint64_t MLDataColumn.debugDescription.getter(uint64_t a1, double a2)
{
  return MLDataColumn.description.getter(a1, a2);
}

uint64_t MLDataColumn.playgroundDescription.getter(uint64_t a1, double a2)
{
  uint64_t v3 = v2;
  uint64_t v4 = MLDataColumn.description.getter(a1, a2);
  char v6 = v5;
  objc_allocWithZone((Class)NSAttributedString);
  id v7 = @nonobjc NSAttributedString.init(string:attributes:)(v4, v6, 0);
  uint64_t result = type metadata accessor for NSAttributedString();
  void v3[3] = result;
  *uint64_t v3 = v7;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLDataColumn<A>(uint64_t a1, double a2)
{
  return MLDataColumn.description.getter(a1, a2);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLDataColumn<A>(uint64_t a1, double a2)
{
  return MLDataColumn.debugDescription.getter(a1, a2);
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLDataColumn<A>(uint64_t a1, double a2)
{
  return MLDataColumn.playgroundDescription.getter(a1, a2);
}

uint64_t type metadata accessor for MLDataColumn(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for MLDataColumn);
}

uint64_t sub_129EB7()
{
  swift_release(*(void *)(v0 + 56));
  return swift_deallocObject(v0, 64, 7);
}

uint64_t partial apply for closure #1 in MLDataColumn.map<A>(_:)(uint64_t a1)
{
  return partial apply for closure #1 in MLDataColumn.map<A>(_:)(a1, (uint64_t (*)(uint64_t, void, void, void, void, void, void))closure #1 in MLDataColumn.map<A>(_:));
}

{
  return partial apply for closure #1 in MLDataColumn.map<A>(_:)(a1, (uint64_t (*)(uint64_t, void, void, void, void, void, void))closure #1 in MLDataColumn.map<A>(_:));
}

uint64_t partial apply for closure #1 in MLDataColumn.map<A>(_:)(uint64_t a1, uint64_t (*a2)(uint64_t, void, void, void, void, void, void))
{
  return a2(a1, v2[6], v2[7], v2[2], v2[3], v2[4], v2[5]);
}

uint64_t type metadata instantiation function for MLDataColumn(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_allocateGenericValueMetadata(a1, a2, a3, 24);
}

uint64_t partial apply for closure #1 in MLDataColumn.map<A>(skipUndefined:_:)(uint64_t a1, double a2)
{
  return closure #1 in MLDataColumn.map<A>(skipUndefined:_:)(a1, *(void (**)(uint64_t *))(v2 + 48), *(void *)(v2 + 56), *(void *)(v2 + 16), *(void *)(v2 + 24), *(void *)(v2 + 32), a2, *(void *)(v2 + 40));
}

uint64_t __swift_instantiateGenericMetadata(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  v6[0] = a2;
  v6[1] = a3;
  v6[2] = a4;
  return swift_getGenericMetadata(a1, v6, a5);
}

uint64_t sub_129F9E()
{
  return sub_129EB7();
}

uint64_t sub_129FA8()
{
  return sub_129EB7();
}

uint64_t specialized Sequence.allSatisfy(_:)(void (*a1)(void, void))
{
  int v50 = a1;
  uint64_t v48 = type metadata accessor for AnyColumn(0);
  uint64_t v1 = *(void *)(v48 - 8);
  int64_t v2 = *(void *)(v1 + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v49 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
  int64_t v5 = *(void *)(*(void *)(v49 - 8) + 64);
  char v6 = alloca(v5);
  id v7 = alloca(v5);
  uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>.Iterator);
  int64_t v8 = *(void *)(*(void *)(v45 - 8) + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v46 = v32;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v50, (uint64_t)v32, &demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
  uint64_t v39 = v1;
  int v50 = *(void (**)(void, void))(v1 + 32);
  uint64_t v11 = v48;
  ((void (*)(unsigned char *, unsigned char *, uint64_t))v50)(v32, v32, v48);
  uint64_t v12 = lazy protocol witness table accessor for type AnyColumn and conformance AnyColumn(&lazy protocol witness table cache variable for type AnyColumn and conformance AnyColumn, (uint64_t)&protocol conformance descriptor for AnyColumn);
  dispatch thunk of Sequence.makeIterator()(v11, v12);
  ((void (*)(unsigned char *, unsigned char *, uint64_t))v50)(v32, &v46[*(int *)(v49 + 52)], v11);
  uint64_t v13 = v45;
  uint64_t v40 = &v32[*(int *)(v45 + 52)];
  uint64_t v43 = v32;
  dispatch thunk of Sequence.makeIterator()(v48, v12);
  uint64_t v44 = *(int *)(v13 + 56);
  v32[v44] = 0;
  uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<AnyColumn>);
  uint64_t v14 = &v32[*(int *)(v41 + 36)];
  Swift::String v15 = v32;
  uint64_t v16 = lazy protocol witness table accessor for type AnyColumn and conformance AnyColumn(&lazy protocol witness table cache variable for type AnyColumn and conformance AnyColumn, (uint64_t)&protocol conformance descriptor for AnyColumn);
  uint64_t v47 = v32;
  uint64_t v42 = v14;
  uint64_t v49 = v16;
  while (1)
  {
    Swift::String v17 = v36;
    int v50 = *(void (**)(void, void))v14;
    dispatch thunk of Collection.endIndex.getter(v48, v16);
    if (v50 == (void (*)(void, void))v38[0]) {
      goto LABEL_8;
    }
    uint64_t v18 = (void (*)(void *, void))dispatch thunk of Collection.subscript.read(v38, v14, v48, v49);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v19, (uint64_t)v36, &demangling cache variable for type metadata for Any?);
    v18(v38, 0);
    uint64_t v20 = v39;
    Swift::String v21 = v43;
    Swift::String v22 = v15;
    uint64_t v23 = v48;
    uint64_t v45 = *(void *)(v39 + 16);
    ((void (*)(unsigned char *, unsigned char *, uint64_t))v45)(v43, v22, v48);
    uint64_t v24 = v14;
    uint64_t v25 = v23;
    uint64_t v26 = v23;
    uint64_t v27 = v49;
    dispatch thunk of Collection.formIndex(after:)(v24, v25, v49);
    uint64_t v46 = *(unsigned char **)(v20 + 8);
    ((void (*)(unsigned char *, uint64_t))v46)(v21, v26);
    outlined init with take of DataFrame?((uint64_t)v36, (uint64_t)v35, &demangling cache variable for type metadata for Any?);
    Swift::String v17 = (unsigned char *)*(int *)(v41 + 36);
    uint64_t v28 = v40;
    int v50 = *(void (**)(void, void))&v17[(void)v40];
    dispatch thunk of Collection.endIndex.getter(v26, v27);
    if (v50 == (void (*)(void, void))v37[0])
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v35, &demangling cache variable for type metadata for Any?);
LABEL_8:
      Swift::String v15 = v47;
      v47[v44] = 1;
      LOBYTE(v17) = 1;
      goto LABEL_10;
    }
    Swift::String v17 = &v17[(void)v28];
    int v50 = (void (*)(void, void))dispatch thunk of Collection.subscript.read(v37, v17, v26, v49);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v29, (uint64_t)v38, &demangling cache variable for type metadata for Any?);
    v50(v37, 0);
    Swift::String v30 = v43;
    ((void (*)(unsigned char *, unsigned char *, uint64_t))v45)(v43, v28, v26);
    dispatch thunk of Collection.formIndex(after:)(v17, v26, v49);
    ((void (*)(unsigned char *, uint64_t))v46)(v30, v26);
    outlined init with take of DataFrame?((uint64_t)v38, (uint64_t)v36, &demangling cache variable for type metadata for Any?);
    outlined init with take of DataFrame?((uint64_t)v35, (uint64_t)v33, &demangling cache variable for type metadata for Any?);
    outlined init with take of DataFrame?((uint64_t)v36, (uint64_t)v34, &demangling cache variable for type metadata for Any?);
    LODWORD(v17) = closure #1 in HandPoseClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)((uint64_t)v33, (uint64_t)v34);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v33, &demangling cache variable for type metadata for (Any?, Any?));
    if ((v17 & 1) == 0) {
      break;
    }
    Swift::String v15 = v47;
    uint64_t v14 = v42;
    uint64_t v16 = v49;
    if (v47[v44]) {
      goto LABEL_10;
    }
  }
  Swift::String v15 = v47;
LABEL_10:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v15, &demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>.Iterator);
  return v17;
}

uint64_t (*HandPoseClassifierTrainingSessionDelegate.sourceTable.modify(uint64_t a1))()
{
  swift_beginAccess(OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable + v1, a1, 33, 0);
  return HandPoseClassifierTrainingSessionDelegate.sourceTable.modify;
}

uint64_t HandPoseClassifierTrainingSessionDelegate.sourceTable.modify()
{
  return swift_endAccess();
}

uint64_t HandPoseClassifierTrainingSessionDelegate.init(sessionParameters:)(uint64_t a1)
{
  uint64_t v2 = v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  uint64_t v3 = type metadata accessor for MLHandPoseClassifier.PersistentParameters(0);
  __swift_storeEnumTagSinglePayload(v2, 1, 1, v3);
  uint64_t v4 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable) = 0;
  *(unsigned char *)(v1 + v4 + 8) = -1;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount) = 0;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceValidationRowCount) = 0;
  static MLHandPoseClassifier.buildFeatureTable(features:labels:sessionIds:imageFiles:)((uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage);
  static MLHandPoseClassifier.buildFeatureTable(features:labels:sessionIds:imageFiles:)((uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage);
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model) = 0;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels) = 0;
  *(void *)(v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_metricsAttributesDictionary) = _swiftEmptyDictionarySingleton;
  outlined init with take of MLClassifierMetrics(a1, v1 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  return v1;
}

uint64_t HandPoseClassifierTrainingSessionDelegate.init(trainingData:modelParameters:sessionParameters:)(uint64_t a1, uint64_t a2, uint64_t a3, __m128 a4)
{
  uint64_t v183 = v4;
  uint64_t v182 = a3;
  uint64_t v177 = a2;
  uint64_t v174 = (long long *)a1;
  uint64_t v154 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  int64_t v6 = *(void *)(*(void *)(v154 - 8) + 64);
  id v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  uint64_t v153 = &v146;
  uint64_t v160 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v159 = *(void *)(v160 - 8);
  int64_t v9 = *(void *)(v159 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  uint64_t v162 = &v146;
  uint64_t v150 = type metadata accessor for AnyColumn(0);
  uint64_t v149 = *(void *)(v150 - 8);
  int64_t v12 = *(void *)(v149 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  unint64_t v158 = &v146;
  Swift::String v15 = alloca(v12);
  uint64_t v16 = alloca(v12);
  uint64_t v151 = &v146;
  uint64_t v169 = type metadata accessor for DataFrame(0);
  uint64_t v171 = *(void *)(v169 - 8);
  int64_t v17 = *(void *)(v171 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  Swift::String v152 = &v146;
  uint64_t v20 = alloca(v17);
  Swift::String v21 = alloca(v17);
  unint64_t v180 = &v146;
  Swift::String v22 = (int *)type metadata accessor for MLHandPoseClassifier.PersistentParameters(0);
  uint64_t v23 = *((void *)v22 - 1);
  uint64_t v172 = v22;
  int64_t v24 = *(void *)(v23 + 64);
  uint64_t v25 = alloca(v24);
  uint64_t v26 = alloca(v24);
  uint64_t v175 = &v146;
  unint64_t v181 = (int *)type metadata accessor for MLHandPoseClassifier.ModelParameters(0);
  int64_t v27 = *(void *)(*((void *)v181 - 1) + 64);
  uint64_t v28 = alloca(v27);
  uint64_t v29 = alloca(v27);
  uint64_t v176 = (char *)&v146;
  uint64_t v168 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
  int64_t v30 = *(void *)(*(void *)(v168 - 8) + 64);
  uint64_t v31 = alloca(v30);
  uint64_t v32 = alloca(v30);
  uint64_t v148 = &v146;
  Swift::String v33 = alloca(v30);
  uint64_t v34 = alloca(v30);
  unint64_t v179 = &v146;
  unint64_t v35 = alloca(v30);
  char v36 = alloca(v30);
  int64_t v37 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  uint64_t v38 = alloca(v37);
  uint64_t v39 = alloca(v37);
  uint64_t v173 = &v146;
  int64_t v170 = (void *)(v5 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters);
  __swift_storeEnumTagSinglePayload(v5 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters, 1, 1, (uint64_t)v22);
  uint64_t v40 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable;
  *(void *)(v5 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable) = 0;
  *(unsigned char *)(v5 + v40 + 8) = -1;
  *(void *)(v5 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount) = 0;
  *(void *)(v5 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceValidationRowCount) = 0;
  uint64_t v163 = v5 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
  static MLHandPoseClassifier.buildFeatureTable(features:labels:sessionIds:imageFiles:)((uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage);
  uint64_t v155 = v5 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures;
  static MLHandPoseClassifier.buildFeatureTable(features:labels:sessionIds:imageFiles:)((uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage, (uint64_t)_swiftEmptyArrayStorage);
  *(void *)(v5 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model) = 0;
  uint64_t v164 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels;
  *(void *)(v5 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels) = 0;
  uint64_t v178 = v5;
  *(void *)(v5 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_metricsAttributesDictionary) = _swiftEmptyDictionarySingleton;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v174, (uint64_t)&v146, type metadata accessor for MLHandPoseClassifier.DataSource);
  uint64_t v41 = v176;
  outlined init with copy of MLTrainingSessionParameters(v177, (uint64_t)v176, type metadata accessor for MLHandPoseClassifier.ModelParameters);
  uint64_t v42 = v172;
  uint64_t v161 = v172[6];
  uint64_t v165 = v172[7];
  uint64_t v43 = (uint64_t)v175;
  outlined init with take of MLClassifierMetrics((uint64_t)&v146, (uint64_t)v175, type metadata accessor for MLHandPoseClassifier.DataSource);
  uint64_t v44 = v43 + v42[5];
  uint64_t v45 = v43;
  uint64_t v46 = (uint64_t)v41;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v41, v44, type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
  uint64_t v47 = v181;
  *(void *)(v45 + v161) = *(void *)&v41[v181[5]];
  *(void *)(v45 + v165) = *(void *)&v41[v47[6]];
  uint64_t v48 = v174;
  *(void *)(v45 + v42[8]) = *(void *)(v46 + v47[7]);
  outlined destroy of MLHandPoseClassifier.DataSource(v46, type metadata accessor for MLHandPoseClassifier.ModelParameters);
  uint64_t v49 = (uint64_t)v173;
  outlined init with take of MLClassifierMetrics(v45, (uint64_t)v173, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
  __swift_storeEnumTagSinglePayload(v49, 0, 1, (uint64_t)v42);
  uint64_t v50 = (uint64_t)v170;
  swift_beginAccess(v170, &v166, 33, 0);
  uint64_t v51 = v49;
  uint64_t v52 = v50;
  uint64_t v53 = v168;
  uint64_t v54 = v179;
  outlined assign with take of MLHandPoseClassifier.PersistentParameters?(v51, v52);
  swift_endAccess(&v166);
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v48, (uint64_t)v54, type metadata accessor for MLHandPoseClassifier.DataSource);
  if (swift_getEnumCaseMultiPayload(v54, v53) != 3)
  {
    outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v54, type metadata accessor for MLHandPoseClassifier.DataSource);
    uint64_t v67 = (uint64_t)v148;
    outlined init with copy of MLTrainingSessionParameters((uint64_t)v48, (uint64_t)v148, type metadata accessor for MLHandPoseClassifier.DataSource);
    if (swift_getEnumCaseMultiPayload(v67, v53) == 5)
    {
      uint64_t v68 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      uint64_t v69 = v68[12];
      uint64_t v165 = *(void *)(v67 + v69);
      unint64_t v181 = *(int **)(v67 + v69 + 8);
      uint64_t v70 = v68[16];
      uint64_t v173 = *(uint64_t **)(v67 + v70);
      unint64_t v179 = *(uint64_t **)(v67 + v70 + 8);
      uint64_t v71 = v68[20];
      uint64_t v72 = *(uint64_t **)(v67 + v71);
      char v73 = *(char **)(v67 + v71 + 8);
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v171 + 32))(v180, v67, v169);
      int64_t v74 = v151;
      uint64_t v175 = v72;
      DataFrame.subscript.getter(v72, v73);
      uint64_t v75 = (void *)AnyColumn.wrappedElementType.getter();
      (*(void (**)(uint64_t *, uint64_t))(v149 + 8))(v74, v150);
      if (v75 == &type metadata for String)
      {
        uint64_t v91 = v175;
        DataFrame.subscript.getter(v175, v73, &type metadata for String);
        uint64_t v92 = v183;
        Column<A>.parseAsJSONArrays()();
        if (v92)
        {
          swift_bridgeObjectRelease((_BYTE)v73);
          swift_bridgeObjectRelease((_BYTE)v179);
          swift_bridgeObjectRelease((_BYTE)v181);
          outlined destroy of MLHandPoseClassifier.DataSource(v182, type metadata accessor for MLTrainingSessionParameters);
          outlined destroy of MLHandPoseClassifier.DataSource(v177, type metadata accessor for MLHandPoseClassifier.ModelParameters);
          outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v174, type metadata accessor for MLHandPoseClassifier.DataSource);
          (*(void (**)(uint64_t *, uint64_t))(v159 + 8))(v162, v160);
LABEL_28:
          (*(void (**)(uint64_t *, uint64_t))(v171 + 8))(v180, v169);
          goto LABEL_29;
        }
        uint64_t v183 = 0;
        (*(void (**)(uint64_t *, uint64_t))(v159 + 8))(v162, v160);
        swift_bridgeObjectRetain((_BYTE)v73);
        uint64_t v176 = v73;
        int64_t v123 = v180;
        DataFrame.subscript.setter(v158, v91, v73);
        uint64_t v76 = v171;
        char v77 = (char)v179;
        uint64_t v78 = v123;
      }
      else
      {
        uint64_t v176 = v73;
        uint64_t v76 = v171;
        char v77 = (char)v179;
        uint64_t v78 = v180;
      }
      uint64_t v79 = (uint64_t)v152;
      uint64_t v80 = v169;
      *(double *)a4.i64 = (*(double (**)(uint64_t *, uint64_t *, uint64_t))(v76 + 16))(v152, v78, v169);
      uint64_t v81 = v183;
      MLDataTable.init(_:convertArraysToShapedArrays:)(v79, 0, a4);
      if (v81)
      {
        swift_bridgeObjectRelease((_BYTE)v176);
        swift_bridgeObjectRelease(v77);
        swift_bridgeObjectRelease((_BYTE)v181);
        outlined destroy of MLHandPoseClassifier.DataSource(v182, type metadata accessor for MLTrainingSessionParameters);
        outlined destroy of MLHandPoseClassifier.DataSource(v177, type metadata accessor for MLHandPoseClassifier.ModelParameters);
        outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v174, type metadata accessor for MLHandPoseClassifier.DataSource);
        (*(void (**)(uint64_t *, uint64_t))(v76 + 8))(v180, v80);
LABEL_29:
        uint64_t v89 = v178;
        goto LABEL_30;
      }
      uint64_t v95 = v166;
      uint64_t v183 = 0;
      char v96 = v167;
      uint64_t v97 = v163;
      swift_beginAccess(v163, v147, 1, 0);
      uint64_t v98 = *(void *)v97;
      *(void *)uint64_t v97 = v95;
      int v99 = *(_DWORD *)(v97 + 8);
      *(unsigned char *)(v97 + 8) = v96;
      outlined consume of Result<_DataTable, Error>(v98, v99);
      swift_beginAccess(v97, &v166, 33, 0);
      uint64_t v100 = v175;
      uint64_t v101 = v176;
      uint64_t v102 = v183;
      static MLHandPoseClassifier.reformatKeypointsDataTable(table:featureColumn:)((unsigned char *)v97, (uint64_t)v175, v176, *(double *)a4.i64);
      if (v102)
      {
        swift_endAccess(&v166);
        swift_bridgeObjectRelease((_BYTE)v101);
        swift_bridgeObjectRelease((_BYTE)v179);
        swift_bridgeObjectRelease((_BYTE)v181);
        outlined destroy of MLHandPoseClassifier.DataSource(v182, type metadata accessor for MLTrainingSessionParameters);
        outlined destroy of MLHandPoseClassifier.DataSource(v177, type metadata accessor for MLHandPoseClassifier.ModelParameters);
        outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v174, type metadata accessor for MLHandPoseClassifier.DataSource);
        goto LABEL_28;
      }
      swift_endAccess(&v166);
      swift_beginAccess(v97, &v166, 33, 0);
      uint64_t v125 = v100;
      uint64_t v126 = v101;
      char v127 = (char)v101;
      char v128 = (char)v179;
      static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(v97, v165, v181, v125, v126, (uint64_t)v173, v179);
      uint64_t v183 = 0;
      swift_endAccess(&v166);
      swift_bridgeObjectRelease(v127);
      swift_bridgeObjectRelease(v128);
      swift_bridgeObjectRelease((_BYTE)v181);
      swift_beginAccess(v97, &v166, 32, 0);
      v140._uint64_t countAndFlagsBits = 0x6C6562616CLL;
      v140._char object = (void *)0xE500000000000000;
      specialized MLDataTable.subscript.getter(v140, *(void *)v97, *(unsigned __int8 *)(v97 + 8), v141, v142);
      uint64_t v143 = v156;
      char v144 = v157;
      swift_endAccess(&v166);
      specialized MLDataColumn.dropDuplicates()(v143, v144);
      outlined consume of Result<_DataTable, Error>(v143, v144);
      int64_t v108 = specialized Array<A>.init(_:)(v166, v167, *(double *)a4.i64);
      (*(void (**)(uint64_t *, uint64_t))(v171 + 8))(v180, v169);
    }
    else
    {
      outlined destroy of MLHandPoseClassifier.DataSource(v67, type metadata accessor for MLHandPoseClassifier.DataSource);
      uint64_t v82 = v183;
      unsigned __int8 v83 = static _ImageUtilities.getDataSourceSynopsisForHandPoseClassifier(from:)(v48, a4);
      if (v82)
      {
        char v66 = 0;
        goto LABEL_12;
      }
      unsigned __int8 v93 = v83;
      uint64_t v94 = v84;
      uint64_t v183 = 0;
      swift_bridgeObjectRelease(v85);
      swift_bridgeObjectRelease(v93);
      int64_t v108 = specialized _copyCollectionToContiguousArray<A>(_:)(v94);
      swift_bridgeObjectRelease(v94);
    }
LABEL_20:
    uint64_t v89 = v178;
    uint64_t v109 = v164;
    uint64_t v110 = *(void *)(v178 + v164);
    *(void *)(v178 + v164) = v108;
    swift_bridgeObjectRelease(v110);
    int64_t v111 = v170;
    uint64_t v112 = v172;
    if (!__swift_getEnumTagSinglePayload((uint64_t)v170, 1, (uint64_t)v172))
    {
      uint64_t v113 = (uint64_t)v111 + v112[5];
      uint64_t v114 = (uint64_t)v153;
      outlined init with copy of MLTrainingSessionParameters(v113, (uint64_t)v153, type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
      if (swift_getEnumCaseMultiPayload(v114, v154) == 1)
      {
        if (swift_getEnumCaseMultiPayload(v114, v168) == 3)
        {
          uint64_t v115 = *(void *)v114;
          int v116 = *(_DWORD *)(v114 + 8);
          uint64_t v173 = *(uint64_t **)(v114 + 16);
          int64_t v170 = *(void **)(v114 + 24);
          uint64_t v176 = *(char **)(v114 + 32);
          unint64_t v179 = *(uint64_t **)(v114 + 40);
          unint64_t v181 = *(int **)(v114 + 48);
          uint64_t v172 = *(int **)(v114 + 56);
          uint64_t v117 = v155;
          swift_beginAccess(v155, &v166, 1, 0);
          uint64_t v175 = *(uint64_t **)v117;
          *(void *)uint64_t v117 = v115;
          int v118 = *(_DWORD *)(v117 + 8);
          *(unsigned char *)(v117 + 8) = v116 & 1;
          uint64_t v168 = v115;
          uint64_t v119 = v115;
          int v120 = v116;
          outlined copy of Result<_DataTable, Error>(v119, v116);
          outlined consume of Result<_DataTable, Error>((uint64_t)v175, v118);
          swift_beginAccess(v117, &v156, 33, 0);
          uint64_t v121 = v181;
          uint64_t v122 = v183;
          static MLHandPoseClassifier.reformatKeypointsDataTable(table:featureColumn:)((unsigned char *)v117, (uint64_t)v181, v172, *(double *)a4.i64);
          if (v122)
          {
            swift_endAccess(&v156);
            swift_bridgeObjectRelease((_BYTE)v170);
            swift_bridgeObjectRelease((_BYTE)v179);
            swift_bridgeObjectRelease((_BYTE)v172);
            outlined consume of Result<_DataTable, Error>(v168, v120);
            outlined destroy of MLHandPoseClassifier.DataSource(v182, type metadata accessor for MLTrainingSessionParameters);
            outlined destroy of MLHandPoseClassifier.DataSource(v177, type metadata accessor for MLHandPoseClassifier.ModelParameters);
            outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v174, type metadata accessor for MLHandPoseClassifier.DataSource);
            uint64_t v89 = v178;
            goto LABEL_30;
          }
          LODWORD(v183) = v120;
          swift_endAccess(&v156);
          swift_beginAccess(v117, &v156, 33, 0);
          char v145 = (char)v179;
          static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(v117, (uint64_t)v173, v170, v121, v172, (uint64_t)v176, v179);
          uint64_t v89 = v178;
          swift_endAccess(&v156);
          swift_bridgeObjectRelease((_BYTE)v170);
          swift_bridgeObjectRelease(v145);
          swift_bridgeObjectRelease((_BYTE)v172);
          outlined consume of Result<_DataTable, Error>(v168, v183);
          uint64_t v130 = v182;
          uint64_t v109 = v164;
          goto LABEL_34;
        }
        uint64_t v124 = type metadata accessor for MLHandPoseClassifier.DataSource;
      }
      else
      {
        uint64_t v124 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData;
      }
      outlined destroy of MLHandPoseClassifier.DataSource(v114, v124);
    }
    uint64_t v130 = v182;
LABEL_34:
    outlined init with copy of MLTrainingSessionParameters(v130, v89 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
    uint64_t v131 = *(void *)(v89 + v109);
    if (v131)
    {
      uint64_t v132 = type metadata accessor for MLHandActionClassifier.GraphCNN(0);
      swift_allocObject(v132, *(unsigned int *)(v132 + 48), *(unsigned __int16 *)(v132 + 52));
      swift_bridgeObjectRetain(v131);
      uint64_t v133 = MLHandActionClassifier.GraphCNN.init(classLabels:export:numOfKeypoints:numOfKeypointsChannels:windowSize:)(v131, 0, 21, 3, 1);
      outlined destroy of MLHandPoseClassifier.DataSource(v182, type metadata accessor for MLTrainingSessionParameters);
      outlined destroy of MLHandPoseClassifier.DataSource(v177, type metadata accessor for MLHandPoseClassifier.ModelParameters);
      outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v174, type metadata accessor for MLHandPoseClassifier.DataSource);
      *(void *)(v89 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model) = v133;
LABEL_36:
      swift_release();
      return v89;
    }
    uint64_t v135 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v135, 0, 0);
    *(void *)uint64_t v136 = 0xD00000000000003DLL;
    *(void *)(v136 + 8) = "ng a feature checkpoint." + 0x8000000000000000;
    *(_OWORD *)(v136 + 16) = 0;
    *(_OWORD *)(v136 + 32) = 0;
    *(unsigned char *)(v136 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v135, v136, v137, v138, v139);
    char v66 = 1;
    goto LABEL_13;
  }
  uint64_t v55 = *v54;
  int v56 = *((_DWORD *)v54 + 2);
  uint64_t v161 = v54[2];
  uint64_t v175 = (uint64_t *)v54[3];
  uint64_t v165 = v54[4];
  uint64_t v176 = (char *)v54[5];
  unint64_t v181 = (int *)v54[6];
  unint64_t v179 = (uint64_t *)v54[7];
  uint64_t v57 = v163;
  swift_beginAccess(v163, v147, 1, 0);
  uint64_t v58 = *(void *)v57;
  *(void *)uint64_t v57 = v55;
  int v59 = v56;
  char v60 = v56 & 1;
  int v61 = *(_DWORD *)(v57 + 8);
  *(unsigned char *)(v57 + 8) = v60;
  uint64_t v173 = (uint64_t *)v55;
  uint64_t v62 = v55;
  int v63 = v59;
  outlined copy of Result<_DataTable, Error>(v62, v59);
  outlined consume of Result<_DataTable, Error>(v58, v61);
  swift_beginAccess(v57, &v166, 33, 0);
  uint64_t v64 = v179;
  uint64_t v65 = v183;
  static MLHandPoseClassifier.reformatKeypointsDataTable(table:featureColumn:)((unsigned char *)v57, (uint64_t)v181, v179, *(double *)a4.i64);
  if (!v65)
  {
    LODWORD(v180) = v63;
    swift_endAccess(&v166);
    uint64_t v86 = v163;
    swift_beginAccess(v163, &v166, 33, 0);
    uint64_t v87 = v86;
    LOBYTE(v86) = (_BYTE)v175;
    char v88 = (char)v176;
    static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(v87, v161, v175, v181, v64, v165, v176);
    uint64_t v183 = 0;
    swift_endAccess(&v166);
    swift_bridgeObjectRelease((_BYTE)v64);
    swift_bridgeObjectRelease(v88);
    swift_bridgeObjectRelease(v86);
    uint64_t v103 = v163;
    swift_beginAccess(v163, &v166, 32, 0);
    v104._uint64_t countAndFlagsBits = 0x6C6562616CLL;
    v104._char object = (void *)0xE500000000000000;
    specialized MLDataTable.subscript.getter(v104, *(void *)v103, *(unsigned __int8 *)(v103 + 8), v105, v106);
    uint64_t v107 = v156;
    LOBYTE(v103) = v157;
    swift_endAccess(&v166);
    specialized MLDataColumn.dropDuplicates()(v107, v103);
    outlined consume of Result<_DataTable, Error>(v107, v103);
    int64_t v108 = specialized Array<A>.init(_:)(v166, v167, *(double *)a4.i64);
    outlined consume of Result<_DataTable, Error>((uint64_t)v173, (char)v180);
    goto LABEL_20;
  }
  char v66 = 0;
  swift_endAccess(&v166);
  swift_bridgeObjectRelease((_BYTE)v64);
  swift_bridgeObjectRelease((_BYTE)v176);
  swift_bridgeObjectRelease((_BYTE)v175);
  outlined consume of Result<_DataTable, Error>((uint64_t)v173, v63);
LABEL_12:
  uint64_t v89 = v178;
LABEL_13:
  uint64_t v90 = v177;
  outlined destroy of MLHandPoseClassifier.DataSource(v182, type metadata accessor for MLTrainingSessionParameters);
  outlined destroy of MLHandPoseClassifier.DataSource(v90, type metadata accessor for MLHandPoseClassifier.ModelParameters);
  outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v174, type metadata accessor for MLHandPoseClassifier.DataSource);
  if (v66) {
    goto LABEL_36;
  }
LABEL_30:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v89 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  outlined consume of MLDataTable?(*(void *)(v89 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable), *(_DWORD *)(v89 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable + 8));
  outlined consume of Result<_DataTable, Error>(*(void *)(v89 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures), *(_DWORD *)(v89 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures + 8));
  outlined consume of Result<_DataTable, Error>(*(void *)(v89 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures), *(_DWORD *)(v89 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures + 8));
  swift_release();
  swift_bridgeObjectRelease(*(void *)(v89
                                      + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels));
  swift_bridgeObjectRelease(*(void *)(v89
                                      + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_metricsAttributesDictionary));
  uint64_t v129 = type metadata accessor for HandPoseClassifierTrainingSessionDelegate(0);
  swift_deallocPartialClassInstance(v89, v129, *(unsigned int *)(*(void *)v89 + 48), *(unsigned __int16 *)(*(void *)v89 + 52));
  return v89;
}

char HandPoseClassifierTrainingSessionDelegate.populateSourceTable(parameters:)(__m128 a1)
{
  type metadata accessor for MLHandPoseClassifier.PersistentParameters(0);
  char result = MLHandPoseClassifier.ModelParameters.ValidationData.extractAnnotations(trainingData:)(&v29, &v27, a1);
  if (!v1)
  {
    uint64_t v35 = v2;
    uint64_t v39 = v29;
    unsigned __int8 v4 = v30;
    uint64_t v5 = v27;
    char v6 = v30;
    int v40 = v28;
    uint64_t v31 = 0;
    if (v30 == 0xFF)
    {
      if (v28 != 0xFF)
      {
        int v41 = v30;
        uint64_t v15 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable;
        uint64_t v16 = v35;
        unsigned __int8 v17 = v28;
        swift_beginAccess(v35 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable, &v29, 1, 0);
        uint64_t v37 = *(void *)(v16 + v15);
        *(void *)(v16 + v15) = v5;
        int v38 = *(_DWORD *)(v16 + v15 + 8);
        *(unsigned char *)(v16 + v15 + 8) = v17;
        char v18 = v17 & 1;
        outlined copy of Result<_DataTable, Error>(v5, v18);
        outlined consume of MLDataTable?(v37, v38);
        *(void *)(v16 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount) = 0;
LABEL_13:
        uint64_t v32 = v5;
        char v33 = v18 != 0;
        Swift::Int v26 = MLDataTable.size.getter();
        outlined consume of MLDataTable?(v39, v41);
        outlined consume of MLDataTable?(v5, v40);
LABEL_16:
        char result = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceValidationRowCount;
        *(void *)(v16 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceValidationRowCount) = v26;
        return result;
      }
      uint64_t v16 = v35;
      *(void *)(v35 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount) = 0;
LABEL_15:
      outlined consume of MLDataTable?(v39, v6);
      Swift::Int v26 = 0;
      goto LABEL_16;
    }
    uint64_t v37 = v27;
    int v41 = v30;
    char v7 = v30 & 1;
    uint64_t v8 = v35 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable;
    unsigned __int8 v42 = v28;
    LOBYTE(v38) = v30 & 1;
    if (v28 == 0xFF)
    {
      char v19 = v7 != 0;
      swift_beginAccess(v35 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable, &v29, 1, 0);
      uint64_t v20 = *(void *)v8;
      uint64_t v21 = v39;
      *(void *)uint64_t v8 = v39;
      LODWORD(v36) = *(_DWORD *)(v8 + 8);
      *(unsigned char *)(v8 + 8) = v4;
      uint64_t v10 = v21;
      outlined copy of MLDataTable?(v21, v41);
      outlined copy of Result<_DataTable, Error>(v10, v19);
      outlined consume of MLDataTable?(v20, v36);
    }
    else
    {
      swift_beginAccess(v35 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable, &v27, 1, 0);
      uint64_t v36 = *(void *)v8;
      uint64_t v9 = v39;
      *(void *)uint64_t v8 = v39;
      LODWORD(v34) = *(_DWORD *)(v8 + 8);
      *(unsigned char *)(v8 + 8) = v7;
      uint64_t v10 = v9;
      outlined copy of Result<_DataTable, Error>(v9, v7 != 0);
      outlined copy of MLDataTable?(v9, v41);
      outlined copy of MLDataTable?(v37, v40);
      outlined consume of MLDataTable?(v36, (char)v34);
      uint64_t v11 = HandPoseClassifierTrainingSessionDelegate.sourceTable.modify((uint64_t)&v29);
      if (*(unsigned char *)(v12 + 8) != 0xFF)
      {
        LODWORD(v36) = v7 != 0;
        uint64_t v13 = v37;
        uint64_t v32 = v37;
        unsigned __int8 v14 = v42;
        uint64_t v34 = v11;
        char v33 = v42 & 1;
        MLDataTable.append(contentsOf:)((uint64_t)&v32);
        ((void (*)(uint64_t *, void))v34)(&v29, 0);
        outlined consume of MLDataTable?(v9, v41);
        outlined consume of MLDataTable?(v13, v40);
        outlined copy of Result<_DataTable, Error>(v9, v36);
        goto LABEL_11;
      }
      ((void (*)(uint64_t *, void))v11)(&v29, 0);
      outlined consume of MLDataTable?(v39, v41);
      outlined consume of MLDataTable?(v37, v40);
      uint64_t v10 = v39;
      outlined copy of Result<_DataTable, Error>(v39, v7 != 0);
    }
    unsigned __int8 v14 = v42;
LABEL_11:
    uint64_t v32 = v10;
    char v33 = (_BYTE)v38 != 0;
    uint64_t v22 = v10;
    Swift::Int v23 = MLDataTable.size.getter();
    char v24 = v41;
    outlined consume of MLDataTable?(v22, v41);
    uint64_t v25 = v35;
    *(void *)(v35 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount) = v23;
    uint64_t v16 = v25;
    char v6 = v24;
    if (v14 != 0xFF)
    {
      char v18 = v14 & 1;
      uint64_t v5 = v37;
      goto LABEL_13;
    }
    goto LABEL_15;
  }
  return result;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> HandPoseClassifierTrainingSessionDelegate.setUp()()
{
  uint64_t v12 = v0;
  int64_t v2 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  uint64_t v3 = alloca(v2);
  unsigned __int8 v4 = alloca(v2);
  uint64_t v5 = type metadata accessor for MLHandPoseClassifier.PersistentParameters(0);
  int64_t v6 = *(void *)(*(void *)(v5 - 8) + 64);
  char v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v9 = v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters, v11, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v9, (uint64_t)&v10, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v10, 1, v5) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v10, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
    BUG();
  }
  outlined init with take of MLClassifierMetrics((uint64_t)&v10, (uint64_t)&v10, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
  HandPoseClassifierTrainingSessionDelegate.populateSourceTable(parameters:)(v1);
  outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)&v10, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> HandPoseClassifierTrainingSessionDelegate.resume(from:)(Swift::OpaquePointer from)
{
  uint64_t v168 = v1;
  uint64_t v182 = v2;
  uint64_t rawValue = (uint64_t)from._rawValue;
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for URL(0) - 8) + 64);
  int64_t v6 = alloca(v5);
  char v7 = alloca(v5);
  uint64_t v174 = &v129;
  uint64_t v8 = alloca(v5);
  uint64_t v9 = alloca(v5);
  uint64_t v173 = &v129;
  uint64_t v10 = alloca(v5);
  uint64_t v11 = alloca(v5);
  uint64_t v172 = &v129;
  uint64_t v12 = alloca(v5);
  uint64_t v13 = alloca(v5);
  uint64_t v169 = &v129;
  int64_t v14 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                              - 8)
                  + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  int64_t v170 = &v129;
  unsigned __int8 v17 = alloca(v14);
  char v18 = alloca(v14);
  uint64_t v183 = (uint64_t)&v129;
  uint64_t v185 = type metadata accessor for MLCheckpoint(0);
  uint64_t v171 = *(void *)(v185 - 8);
  int64_t v19 = *(void *)(v171 + 64);
  uint64_t v20 = alloca(v19);
  uint64_t v21 = alloca(v19);
  BOOL v184 = &v129;
  uint64_t v22 = alloca(v19);
  Swift::Int v23 = alloca(v19);
  uint64_t v177 = &v129;
  char v24 = alloca(v19);
  uint64_t v25 = alloca(v19);
  uint64_t v190 = &v129;
  Swift::Int v26 = alloca(v19);
  uint64_t v27 = alloca(v19);
  uint64_t v186 = &v129;
  int64_t v28 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  uint64_t v29 = alloca(v28);
  unsigned __int8 v30 = alloca(v28);
  uint64_t v31 = type metadata accessor for MLHandPoseClassifier.PersistentParameters(0);
  int64_t v32 = *(void *)(*(void *)(v31 - 8) + 64);
  char v33 = alloca(v32);
  uint64_t v34 = alloca(v32);
  uint64_t v35 = v182 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v182 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters, v164, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v35, (uint64_t)&v129, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v129, 1, v31) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v129, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
    BUG();
  }
  outlined init with take of MLClassifierMetrics((uint64_t)&v129, (uint64_t)&v129, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
  uint64_t v36 = v183;
  specialized BidirectionalCollection.last.getter(rawValue);
  uint64_t v37 = v185;
  if (__swift_getEnumTagSinglePayload(v36, 1, v185) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v36, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v38 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v38, 0, 0);
    *(void *)uint64_t v39 = 0xD00000000000001DLL;
    *(void *)(v39 + 8) = "reated." + 0x8000000000000000;
    *(_OWORD *)(v39 + 16) = 0;
    *(_OWORD *)(v39 + 32) = 0;
    *(unsigned char *)(v39 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v38, v39, v40, v41, v42);
    uint64_t v43 = &v129;
    goto LABEL_69;
  }
  uint64_t v44 = v37;
  uint64_t v187 = &v129;
  unint64_t v45 = 0xEB0000000064657ALL;
  uint64_t v176 = 0x6974636172747865;
  uint64_t v46 = 0x696C616974696E69;
  uint64_t v47 = v36;
  uint64_t v48 = v44;
  uint64_t v49 = (uint64_t)v186;
  outlined init with take of MLClassifierMetrics(v47, (uint64_t)v186, type metadata accessor for MLCheckpoint);
  uint64_t v183 = *(int *)(v48 + 20);
  switch(*(unsigned char *)(v49 + v183))
  {
    case 0:
      goto LABEL_9;
    case 1:
      swift_bridgeObjectRelease(110);
      uint64_t v50 = (uint64_t)v190;
      outlined init with copy of MLTrainingSessionParameters(v49, (uint64_t)v190, type metadata accessor for MLCheckpoint);
      uint64_t v51 = (uint64_t)v187;
      goto LABEL_10;
    case 2:
      uint64_t v46 = 0x676E696E69617274;
      unint64_t v45 = 0xE800000000000000;
      goto LABEL_9;
    case 3:
      uint64_t v46 = 0x697461756C617665;
      unint64_t v45 = 0xEA0000000000676ELL;
      goto LABEL_9;
    case 4:
      uint64_t v46 = 0x636E657265666E69;
      unint64_t v45 = 0xEB00000000676E69;
LABEL_9:
      char v52 = _stringCompareWithSmolCheck(_:_:expecting:)(v46, v45, 0x6974636172747865, 0xEA0000000000676ELL, 0);
      swift_bridgeObjectRelease(v45);
      uint64_t v50 = (uint64_t)v190;
      outlined init with copy of MLTrainingSessionParameters(v49, (uint64_t)v190, type metadata accessor for MLCheckpoint);
      uint64_t v51 = (uint64_t)v187;
      if ((v52 & 1) == 0)
      {
        switch(*(unsigned char *)(v50 + *(int *)(v185 + 20)))
        {
          case 0:
            uint64_t v54 = 0x696C616974696E69;
            unint64_t v55 = 0xEB0000000064657ALL;
            goto LABEL_20;
          case 1:
            uint64_t v54 = 0x6974636172747865;
            goto LABEL_19;
          case 2:
            swift_bridgeObjectRelease(0);
            break;
          case 3:
            uint64_t v54 = 0x697461756C617665;
LABEL_19:
            unint64_t v55 = 0xEA0000000000676ELL;
LABEL_20:
            _stringCompareWithSmolCheck(_:_:expecting:)(v54, v55, 0x676E696E69617274, 0xE800000000000000, 0);
            swift_bridgeObjectRelease(v55);
            JUMPOUT(0x12BE31);
          case 4:
            JUMPOUT(0x12BDBFLL);
        }
      }
LABEL_10:
      outlined destroy of MLHandPoseClassifier.DataSource(v50, type metadata accessor for MLCheckpoint);
      uint64_t v53 = v168;
      HandPoseClassifierTrainingSessionDelegate.populateSourceTable(parameters:)(v3);
      if (v53) {
        goto LABEL_68;
      }
      break;
  }
  uint64_t v56 = 0x676E696E69617274;
  uint64_t v57 = (uint64_t)v186;
  uint64_t v58 = *((unsigned __int8 *)v186 + v183);
  uint64_t v190 = 0;
  switch(v58)
  {
    case 0:
      unint64_t v59 = 0xEB0000000064657ALL;
      uint64_t v56 = 0x696C616974696E69;
      goto LABEL_26;
    case 1:
      swift_bridgeObjectRelease(110);
      goto LABEL_27;
    case 2:
      unint64_t v59 = 0xE800000000000000;
      goto LABEL_26;
    case 3:
      uint64_t v56 = 0x697461756C617665;
      unint64_t v59 = 0xEA0000000000676ELL;
      goto LABEL_26;
    case 4:
      uint64_t v56 = 0x636E657265666E69;
      unint64_t v59 = 0xEB00000000676E69;
LABEL_26:
      char v60 = _stringCompareWithSmolCheck(_:_:expecting:)(v56, v59, 0x6974636172747865, 0xEA0000000000676ELL, 0);
      swift_bridgeObjectRelease(v59);
      uint64_t v61 = (uint64_t)v177;
      if (v60)
      {
LABEL_27:
        uint64_t v62 = v169;
        URL.appendingPathComponent(_:)(0x676E696E69617274, 0xE800000000000000);
        char v188 = 1;
        LOBYTE(v147) = 1;
        uint64_t v148 = 44;
        unint64_t v149 = 0xE100000000000000;
        uint64_t v150 = 0;
        unint64_t v151 = 0xE000000000000000;
        uint64_t v152 = 92;
        unint64_t v153 = 0xE100000000000000;
        char v154 = 1;
        uint64_t v155 = 34;
        unint64_t v156 = 0xE100000000000000;
        char v157 = 1;
        unint64_t v158 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
        uint64_t v159 = 10;
        unint64_t v160 = 0xE100000000000000;
        long long v161 = 0;
        char v162 = 1;
        uint64_t v163 = 0;
        uint64_t v63 = (uint64_t)v190;
        MLDataTable.init(contentsOf:options:)(v62, &v147);
        if (v63)
        {
          uint64_t v64 = v57;
        }
        else
        {
          BOOL v184 = v178;
          LOBYTE(v185) = v179;
          uint64_t v75 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
          uint64_t v190 = 0;
          uint64_t v76 = v182;
          swift_beginAccess(v182 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures, v165, 1, 0);
          uint64_t v77 = *(void *)(v76 + v75);
          *(void *)(v76 + v75) = v184;
          int v78 = *(_DWORD *)(v76 + v75 + 8);
          *(unsigned char *)(v76 + v75 + 8) = v185;
          outlined consume of Result<_DataTable, Error>(v77, v78);
          uint64_t v79 = v172;
          URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEA00000000006E6FLL);
          LOBYTE(v130) = 1;
          uint64_t v131 = (void *)(&stru_20 + 12);
          unint64_t v132 = 0xE100000000000000;
          uint64_t v133 = 0;
          char v189 = 1;
          unint64_t v134 = 0xE000000000000000;
          uint64_t v135 = 92;
          unint64_t v136 = 0xE100000000000000;
          char v137 = 1;
          uint64_t v138 = 34;
          unint64_t v139 = 0xE100000000000000;
          char v140 = 1;
          uint64_t v141 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
          uint64_t v142 = 10;
          unint64_t v143 = 0xE100000000000000;
          v3.i64[0] = 0;
          long long v144 = 0;
          char v145 = 1;
          uint64_t v146 = 0;
          uint64_t v80 = (uint64_t)v190;
          MLDataTable.init(contentsOf:options:)(v79, &v130);
          uint64_t v190 = (uint64_t *)v80;
          if (!v80)
          {
            uint64_t v81 = v180;
            LOBYTE(v185) = v181;
            uint64_t v82 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures;
            swift_beginAccess(v76 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures, v166, 1, 0);
            uint64_t v83 = *(void *)(v76 + v82);
            *(void *)(v76 + v82) = v81;
            int v84 = *(_DWORD *)(v76 + v82 + 8);
            *(unsigned char *)(v76 + v82 + 8) = v185;
            outlined consume of Result<_DataTable, Error>(v83, v84);
            uint64_t v51 = (uint64_t)v187;
            unint64_t v85 = 0xEA0000000000676ELL;
            switch(*(unsigned char *)(v57 + v183))
            {
              case 0:
                goto LABEL_48;
              case 1:
                goto LABEL_58;
              case 2:
                goto LABEL_55;
              case 3:
                goto LABEL_56;
              case 4:
                goto LABEL_57;
            }
          }
          uint64_t v64 = v57;
        }
        goto LABEL_66;
      }
      uint64_t v147 = rawValue;
      uint64_t v65 = *(void *)(rawValue + 16);
      char v66 = 1;
      if (!v65)
      {
        uint64_t v67 = 0;
        goto LABEL_45;
      }
      uint64_t v67 = v65 - 1;
      uint64_t v68 = v67 * *(void *)(v171 + 72)
          + ((*(unsigned __int8 *)(v171 + 80) + 32) & ~*(unsigned __int8 *)(v171 + 80))
          + rawValue;
      uint64_t rawValue = -*(void *)(v171 + 72);
      break;
  }
  while (2)
  {
    uint64_t v69 = (uint64_t)v184;
    outlined init with copy of MLTrainingSessionParameters(v68, (uint64_t)v184, type metadata accessor for MLCheckpoint);
    switch(*(unsigned char *)(v69 + *(int *)(v185 + 20)))
    {
      case 0:
        JUMPOUT(0x12C0A0);
      case 1:
        swift_bridgeObjectRelease(110);
        outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v184, type metadata accessor for MLCheckpoint);
        char v66 = 0;
        goto LABEL_45;
      case 2:
        uint64_t v70 = v68;
        unint64_t v71 = 0xE800000000000000;
        uint64_t v72 = 0x676E696E69617274;
        goto LABEL_36;
      case 3:
        uint64_t v70 = v68;
        unint64_t v71 = 0xEA0000000000676ELL;
        uint64_t v72 = 0x697461756C617665;
        goto LABEL_36;
      case 4:
        uint64_t v70 = v68;
        unint64_t v71 = 0xEB00000000676E69;
        uint64_t v72 = 0x636E657265666E69;
LABEL_36:
        char v73 = _stringCompareWithSmolCheck(_:_:expecting:)(v72, v71, 0x6974636172747865, 0xEA0000000000676ELL, 0);
        swift_bridgeObjectRelease(v71);
        outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v184, type metadata accessor for MLCheckpoint);
        if ((v73 & 1) == 0)
        {
          uint64_t v68 = rawValue + v70;
          BOOL v74 = v67-- != 0;
          uint64_t v61 = (uint64_t)v177;
          if (!v74)
          {
            uint64_t v67 = 0;
            char v66 = 1;
            goto LABEL_45;
          }
          continue;
        }
        char v66 = 0;
        uint64_t v61 = (uint64_t)v177;
LABEL_45:
        uint64_t v86 = alloca(24);
        uint64_t v87 = alloca(32);
        uint64_t v131 = &v147;
        uint64_t v88 = (uint64_t)v170;
        uint64_t v89 = (uint64_t)v190;
        _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5((uint64_t (*)(void))partial apply for specialized closure #1 in BidirectionalCollection.last(where:), (uint64_t)&v129, v67, v66, (uint64_t)v167);
        int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v88, 1, v185);
        uint64_t v190 = (uint64_t *)v89;
        if (EnumTagSinglePayload == 1)
        {
          outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v88, &demangling cache variable for type metadata for MLCheckpoint?);
          uint64_t v91 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
          uint64_t v92 = v182;
          swift_beginAccess(v182 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures, &v147, 0, 0);
          char v93 = *(unsigned char *)(v92 + v91 + 8);
          uint64_t v130 = *(void *)(v92 + v91);
          LOBYTE(v131) = v93;
          if (MLDataTable.size.getter())
          {
            uint64_t v51 = (uint64_t)v187;
            unint64_t v85 = 0xEA0000000000676ELL;
            switch(*((unsigned char *)v186 + v183))
            {
              case 0:
                goto LABEL_48;
              case 1:
                goto LABEL_58;
              case 2:
                goto LABEL_55;
              case 3:
                goto LABEL_56;
              case 4:
                goto LABEL_57;
            }
          }
          uint64_t v96 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
          swift_allocError(&type metadata for MLCreateError, v96, 0, 0);
          *(void *)uint64_t v97 = 0xD000000000000028;
          uint64_t v101 = "erly initialized.";
LABEL_65:
          *(void *)(v97 + 8) = (unint64_t)v101 | 0x8000000000000000;
          *(_OWORD *)(v97 + 16) = 0;
          *(_OWORD *)(v97 + 32) = 0;
          *(unsigned char *)(v97 + 48) = 0;
          swift_willThrow(&type metadata for MLCreateError, v96, v97, v98, v99, v100);
          uint64_t v64 = (uint64_t)v186;
LABEL_66:
          outlined destroy of MLHandPoseClassifier.DataSource(v64, type metadata accessor for MLCheckpoint);
          uint64_t v43 = v187;
LABEL_69:
          outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v43, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
        }
        else
        {
          outlined init with take of MLClassifierMetrics(v88, v61, type metadata accessor for MLCheckpoint);
          uint64_t v94 = v173;
          URL.appendingPathComponent(_:)(0x676E696E69617274, 0xE800000000000000);
          char v188 = 1;
          LOBYTE(v147) = 1;
          uint64_t v148 = 44;
          unint64_t v149 = 0xE100000000000000;
          uint64_t v150 = 0;
          unint64_t v151 = 0xE000000000000000;
          uint64_t v152 = 92;
          unint64_t v153 = 0xE100000000000000;
          char v154 = 1;
          uint64_t v155 = 34;
          unint64_t v156 = 0xE100000000000000;
          char v157 = 1;
          unint64_t v158 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
          uint64_t v159 = 10;
          unint64_t v160 = 0xE100000000000000;
          long long v161 = 0;
          char v162 = 1;
          uint64_t v163 = 0;
          uint64_t v95 = (uint64_t)v190;
          MLDataTable.init(contentsOf:options:)(v94, &v147);
          if (!v95)
          {
            BOOL v184 = v178;
            LOBYTE(v185) = v179;
            uint64_t v190 = 0;
            uint64_t v102 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
            uint64_t v103 = v182;
            swift_beginAccess(v182 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures, v165, 1, 0);
            uint64_t v104 = *(void *)(v103 + v102);
            *(void *)(v103 + v102) = v184;
            int v105 = *(_DWORD *)(v103 + v102 + 8);
            *(unsigned char *)(v103 + v102 + 8) = v185;
            outlined consume of Result<_DataTable, Error>(v104, v105);
            uint64_t v106 = v174;
            URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEA00000000006E6FLL);
            LOBYTE(v130) = 1;
            uint64_t v131 = (void *)(&stru_20 + 12);
            unint64_t v132 = 0xE100000000000000;
            uint64_t v133 = 0;
            char v189 = 1;
            unint64_t v134 = 0xE000000000000000;
            uint64_t v135 = 92;
            unint64_t v136 = 0xE100000000000000;
            char v137 = 1;
            uint64_t v138 = 34;
            unint64_t v139 = 0xE100000000000000;
            char v140 = 1;
            uint64_t v141 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
            uint64_t v142 = 10;
            unint64_t v143 = 0xE100000000000000;
            v3.i64[0] = 0;
            long long v144 = 0;
            char v145 = 1;
            uint64_t v146 = 0;
            uint64_t v107 = (uint64_t)v190;
            MLDataTable.init(contentsOf:options:)(v106, &v130);
            uint64_t v190 = (uint64_t *)v107;
            if (v107)
            {
              outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v177, type metadata accessor for MLCheckpoint);
              uint64_t v64 = (uint64_t)v186;
              goto LABEL_66;
            }
            outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v177, type metadata accessor for MLCheckpoint);
            uint64_t v108 = v180;
            char v109 = v181;
            uint64_t v110 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures;
            swift_beginAccess(v103 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures, v166, 1, 0);
            uint64_t v111 = *(void *)(v103 + v110);
            *(void *)(v103 + v110) = v108;
            int v112 = *(_DWORD *)(v103 + v110 + 8);
            *(unsigned char *)(v103 + v110 + 8) = v109;
            unint64_t v85 = 0xEA0000000000676ELL;
            outlined consume of Result<_DataTable, Error>(v111, v112);
            uint64_t v51 = (uint64_t)v187;
            switch(*((unsigned char *)v186 + v183))
            {
              case 0:
LABEL_48:
                uint64_t v176 = 0x696C616974696E69;
                unint64_t v85 = 0xEB0000000064657ALL;
                goto LABEL_58;
              case 1:
                goto LABEL_58;
              case 2:
LABEL_55:
                swift_bridgeObjectRelease(0);
                goto LABEL_59;
              case 3:
LABEL_56:
                uint64_t v176 = 0x697461756C617665;
                goto LABEL_58;
              case 4:
LABEL_57:
                uint64_t v176 = 0x636E657265666E69;
                unint64_t v85 = 0xEB00000000676E69;
LABEL_58:
                char v113 = _stringCompareWithSmolCheck(_:_:expecting:)(v176, v85, 0x676E696E69617274, 0xE800000000000000, 0);
                swift_bridgeObjectRelease(v85);
                if ((v113 & 1) == 0) {
                  break;
                }
LABEL_59:
                uint64_t v114 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
                uint64_t v115 = v182;
                swift_beginAccess(OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures + v182, &v130, 0, 0);
                uint64_t v116 = *(void *)(v115 + v114);
                LODWORD(v114) = *(unsigned __int8 *)(v115 + v114 + 8);
                outlined copy of Result<_DataTable, Error>(v116, v114);
                v117._uint64_t countAndFlagsBits = 0x6C6562616CLL;
                v117._char object = (void *)0xE500000000000000;
                specialized MLDataTable.subscript.getter(v117, v116, v114, v118, v119);
                outlined consume of Result<_DataTable, Error>(v116, v114);
                uint64_t v120 = v180;
                LOBYTE(v114) = v181;
                specialized MLDataColumn.dropDuplicates()(v180, v181);
                outlined consume of Result<_DataTable, Error>(v120, v114);
                uint64_t v121 = specialized Array<A>.init(_:)((uint64_t)v178, v179, *(double *)v3.i64);
                uint64_t v122 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels;
                v117._uint64_t countAndFlagsBits = *(void *)(v115
                                                    + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels);
                *(void *)(v115 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels) = v121;
                swift_bridgeObjectRelease(v117._countAndFlagsBits);
                uint64_t v123 = *(void *)(v115 + v122);
                if (!v123)
                {
                  uint64_t v96 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
                  swift_allocError(&type metadata for MLCreateError, v96, 0, 0);
                  *(void *)uint64_t v97 = 0xD00000000000002ELL;
                  uint64_t v101 = "re not properly constructed.";
                  goto LABEL_65;
                }
                uint64_t v124 = type metadata accessor for MLHandActionClassifier.GraphCNN(0);
                swift_allocObject(v124, *(unsigned int *)(v124 + 48), *(unsigned __int16 *)(v124 + 52));
                swift_bridgeObjectRetain(v123);
                uint64_t v125 = MLHandActionClassifier.GraphCNN.init(classLabels:export:numOfKeypoints:numOfKeypointsChannels:windowSize:)(v123, 0, 21, 3, 1);
                uint64_t v126 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model;
                *(void *)(v115 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model) = v125;
                swift_release();
                if (!*(void *)(v115 + v126))
                {
                  uint64_t v96 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
                  swift_allocError(&type metadata for MLCreateError, v96, 0, 0);
                  *(void *)uint64_t v97 = 0xD000000000000031;
                  uint64_t v101 = "ning checkpoints are supported.";
                  goto LABEL_65;
                }
                swift_retain();
                uint64_t v127 = (uint64_t)v186;
                uint64_t v128 = (uint64_t)v190;
                MLHandActionClassifier.GraphCNN.updateGraphCNN(from:)((uint64_t)v186, *(double *)v3.i64, v4);
                uint64_t v190 = (uint64_t *)v128;
                if (v128)
                {
                  swift_release();
                  uint64_t v64 = v127;
                  goto LABEL_66;
                }
                MLHandActionClassifier.GraphCNN.initDevice()();
                swift_release();
                uint64_t v51 = (uint64_t)v187;
                break;
            }
LABEL_68:
            outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v186, type metadata accessor for MLCheckpoint);
            uint64_t v43 = (uint64_t *)v51;
            goto LABEL_69;
          }
          outlined destroy of MLHandPoseClassifier.DataSource(v61, type metadata accessor for MLCheckpoint);
          outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v186, type metadata accessor for MLCheckpoint);
          outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v187, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
        }
        return;
    }
  }
}

Swift::Int_optional __swiftcall HandPoseClassifierTrainingSessionDelegate.itemCount(phase:)(CreateML::MLPhase phase)
{
  switch(*(unsigned char *)phase)
  {
    case 0:
    case 3:
    case 4:
      char v2 = 1;
      Swift::Int v3 = 0;
      break;
    case 1:
      uint64_t v4 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable;
      int64_t v5 = (uint64_t *)(OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable + v1);
      Swift::Int v3 = 0;
      swift_beginAccess(OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable + v1, v9, 0, 0);
      char v6 = *(unsigned char *)(v1 + v4 + 8);
      if (v6 != -1)
      {
        uint64_t v10 = *v5;
        char v11 = v6 & 1;
        Swift::Int v3 = MLDataTable.size.getter();
      }
      char v2 = 0;
      break;
    case 2:
      uint64_t v7 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sessionParameters + v1;
      char v2 = 0;
      Swift::Int v3 = *(void *)(*(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 28) + v7);
      break;
  }
  v8.value = v3;
  v8.is_nil = v2;
  return v8;
}

Swift::tuple_Int_finished_Bool __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> HandPoseClassifierTrainingSessionDelegate.extractFeatures(from:)(Swift::Int from)
{
  uint64_t v48 = v1;
  uint64_t v3 = v2;
  Swift::Int v42 = from;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  int64_t v5 = alloca(v4);
  char v6 = alloca(v4);
  uint64_t v7 = v2 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v3 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters, v34, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v7, (uint64_t)&v33, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v8 = type metadata accessor for MLHandPoseClassifier.PersistentParameters(0);
  LODWORD(v7) = __swift_getEnumTagSinglePayload((uint64_t)&v33, 1, v8);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v33, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  if (v7 == 1) {
    BUG();
  }
  uint64_t v9 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable;
  swift_beginAccess(v3 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable, v35, 0, 0);
  unsigned __int8 v10 = *(unsigned char *)(v3 + v9 + 8);
  v11.finished = 1;
  uint64_t v12 = 1;
  if (v10 != 0xFF)
  {
    uint64_t v13 = *(void *)(v3 + v9);
    uint64_t v39 = v13;
    int v14 = v10;
    char v15 = v10 & 1;
    char v40 = v15;
    int v49 = v14;
    outlined copy of Result<_DataTable, Error>(v13, v14);
    MLDataTable.size.getter();
    if (v16 <= 0)
    {
      outlined consume of MLDataTable?(v13, v49);
      v11.finished = 1;
      uint64_t v12 = 1;
    }
    else
    {
      uint64_t v47 = v13;
      Swift::Int v17 = *(void *)(v3 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount);
      uint64_t v18 = *(void *)(v3
                      + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceValidationRowCount);
      BOOL v24 = __OFADD__(v17, v18);
      Swift::Int v19 = v17 + v18;
      if (v24) {
        BUG();
      }
      if (v19 <= v42)
      {
        outlined consume of MLDataTable?(v47, v49);
        uint64_t v12 = 0;
        v11.finished = 1;
      }
      else
      {
        uint64_t v37 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceValidationRowCount;
        uint64_t v36 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTrainingRowCount;
        uint64_t v44 = v3;
        uint64_t v20 = v3 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sessionParameters;
        Swift::Int v41 = v17;
        uint64_t v21 = type metadata accessor for MLTrainingSessionParameters(0);
        uint64_t v22 = v42;
        uint64_t v23 = *(void *)(*(int *)(v21 + 20) + v20);
        BOOL v24 = __OFADD__(v42, v23);
        uint64_t v25 = v42 + v23;
        if (v41 <= v42)
        {
          if (v24) {
            BUG();
          }
        }
        else
        {
          Swift::Int v19 = v41;
          if (v24) {
            BUG();
          }
        }
        if (v19 < v25) {
          uint64_t v25 = v19;
        }
        if (v25 < v42) {
          BUG();
        }
        uint64_t v45 = v47;
        char v46 = v15;
        uint64_t v38 = v25;
        MLDataTable.subscript.getter(v42, v25);
        uint64_t v26 = v39;
        char v27 = v40;
        type metadata accessor for MLHandPoseClassifier.FeatureExtractor();
        uint64_t v43 = v26;
        uint64_t v45 = v26;
        char v46 = v27;
        uint64_t v28 = v48;
        static MLHandPoseClassifier.FeatureExtractor.extractFeatures(from:startingSessionId:)((uint64_t)&v45, v22);
        if (v28)
        {
          outlined consume of MLDataTable?(v47, v49);
          uint64_t v12 = v43;
          outlined consume of Result<_DataTable, Error>(v43, v27);
        }
        else
        {
          LOBYTE(v48) = v27;
          uint64_t v29 = v39;
          uint64_t v45 = v39;
          if (v41 <= v22)
          {
            char v30 = v40;
            char v46 = v40 & 1;
            uint64_t v31 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures;
          }
          else
          {
            char v30 = v40;
            char v46 = v40 & 1;
            uint64_t v31 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
          }
          swift_beginAccess(v44 + v31, &v39, 33, 0);
          MLDataTable.append(contentsOf:)((uint64_t)&v45);
          swift_endAccess(&v39);
          outlined consume of MLDataTable?(v47, v49);
          outlined consume of Result<_DataTable, Error>(v43, v48);
          outlined consume of Result<_DataTable, Error>(v29, v30);
          uint64_t v12 = v38 - v42;
          if (__OFSUB__(v38, v42)) {
            BUG();
          }
          uint64_t v32 = *(void *)(v44 + v36);
          BOOL v24 = __OFADD__(*(void *)(v44 + v37), v32);
          v11._0 = *(void *)(v44 + v37) + v32;
          if (v24) {
            BUG();
          }
          v11.finished = v38 == v11._0;
        }
      }
    }
  }
  v11._0 = v12;
  return v11;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> HandPoseClassifierTrainingSessionDelegate.transitionTo(phase:)(CreateML::MLPhase phase)
{
  uint64_t v4 = v2;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  char v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  if (*(unsigned char *)phase != 2) {
    return;
  }
  uint64_t v36 = v1;
  uint64_t v8 = v2 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v4 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters, v30, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v8, (uint64_t)&v29, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v9 = type metadata accessor for MLHandPoseClassifier.PersistentParameters(0);
  LODWORD(v8) = __swift_getEnumTagSinglePayload((uint64_t)&v29, 1, v9);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v29, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  if (v8 == 1) {
    BUG();
  }
  uint64_t v10 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
  swift_beginAccess(v4 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures, v31, 0, 0);
  uint64_t v11 = *(void *)(v4 + v10);
  LODWORD(v10) = *(unsigned __int8 *)(v4 + v10 + 8);
  outlined copy of Result<_DataTable, Error>(v11, v10);
  v12._uint64_t countAndFlagsBits = 0x6C6562616CLL;
  v12._char object = (void *)0xE500000000000000;
  specialized MLDataTable.subscript.getter(v12, v11, v10, v13, v14);
  outlined consume of Result<_DataTable, Error>(v11, v10);
  uint64_t v15 = v34;
  LOBYTE(v10) = v35;
  specialized MLDataColumn.dropDuplicates()(v34, v35);
  outlined consume of Result<_DataTable, Error>(v15, v10);
  uint64_t v16 = specialized Array<A>.init(_:)(v32, v33, v3);
  uint64_t v17 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels;
  v12._uint64_t countAndFlagsBits = *(void *)(v4
                                     + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels);
  *(void *)(v4 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels) = v16;
  swift_bridgeObjectRelease(v12._countAndFlagsBits);
  uint64_t v18 = *(void *)(v4 + v17);
  if (!v18)
  {
    uint64_t v23 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v23, 0, 0);
    *(void *)uint64_t v24 = 0xD00000000000002ELL;
    uint64_t v28 = "re not properly constructed.";
LABEL_10:
    *(void *)(v24 + 8) = (unint64_t)v28 | 0x8000000000000000;
    *(_OWORD *)(v24 + 16) = 0;
    *(_OWORD *)(v24 + 32) = 0;
    *(unsigned char *)(v24 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v23, v24, v25, v26, v27);
    return;
  }
  uint64_t v19 = type metadata accessor for MLHandActionClassifier.GraphCNN(0);
  swift_allocObject(v19, *(unsigned int *)(v19 + 48), *(unsigned __int16 *)(v19 + 52));
  swift_bridgeObjectRetain_n(v18, 2);
  uint64_t v20 = MLHandActionClassifier.GraphCNN.init(classLabels:export:numOfKeypoints:numOfKeypointsChannels:windowSize:)(v18, 0, 21, 3, 1);
  uint64_t v21 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model;
  *(void *)(v4 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model) = v20;
  swift_release();
  if (!*(void *)(v4 + v21))
  {
    swift_bridgeObjectRelease(v18);
    uint64_t v23 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v23, 0, 0);
    *(void *)uint64_t v24 = 0xD00000000000003CLL;
    uint64_t v28 = "ve training parameters";
    goto LABEL_10;
  }
  swift_retain();
  MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel()();
  if (!v22) {
    MLHandActionClassifier.GraphCNN.initDevice()();
  }
  swift_bridgeObjectRelease(v18);
  swift_release();
}

Swift::tuple_Int_metrics_OpaquePointer_finished_Bool __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> HandPoseClassifierTrainingSessionDelegate.train(from:)(Swift::Int from)
{
  uint64_t v105 = v1;
  double v117 = *(double *)&from;
  uint64_t v100 = type metadata accessor for Tensor(0);
  uint64_t v101 = *(void *)(v100 - 8);
  int64_t v4 = *(void *)(v101 + 64);
  int64_t v5 = alloca(v4);
  char v6 = alloca(v4);
  uint64_t v102 = &v92;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?)
                             - 8)
                 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v111 = &v92;
  uint64_t v99 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
  uint64_t v98 = *(void *)(v99 - 8);
  int64_t v10 = *(void *)(v98 + 64);
  uint64_t v11 = alloca(v10);
  Swift::String v12 = alloca(v10);
  int v112 = &v92;
  double v113 = COERCE_DOUBLE(type metadata accessor for MLHandActionClassifier.ModelParameters(0));
  int64_t v13 = *(void *)(*(void *)(*(void *)&v113 - 8) + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v104 = &v92;
  uint64_t v16 = (int *)type metadata accessor for MLHandPoseClassifier.PersistentParameters(0);
  int64_t v17 = *(void *)(*((void *)v16 - 1) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v118 = &v92;
  int64_t v20 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?)
                              - 8)
                  + 64);
  uint64_t v21 = alloca(v20);
  uint64_t v22 = alloca(v20);
  uint64_t v23 = (uint64_t)&v92;
  uint64_t v114 = type metadata accessor for MLHandPoseClassifier.ModelParameters(0);
  int64_t v24 = *(void *)(*(void *)(v114 - 8) + 64);
  uint64_t v25 = alloca(v24);
  uint64_t v26 = alloca(v24);
  uint64_t v120 = &v92;
  uint64_t v27 = alloca(v24);
  uint64_t v28 = alloca(v24);
  uint64_t v110 = &v92;
  uint64_t v29 = v2 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sessionParameters;
  uint64_t v30 = type metadata accessor for MLTrainingSessionParameters(0);
  uint64_t v31 = *(int **)(*(int *)(v30 + 20) + v29);
  if (__OFADD__(v31, *(void *)&v117)) {
    BUG();
  }
  uint64_t v119 = v2;
  uint64_t v32 = *(void *)(v29 + *(int *)(v30 + 28));
  char v33 = (int *)(v32 - *(void *)&v117);
  if (__OFSUB__(v32, *(void *)&v117)) {
    BUG();
  }
  uint64_t v97 = v32;
  uint64_t v96 = (char *)v31 + *(void *)&v117;
  if ((uint64_t)v31 < (uint64_t)v33) {
    char v33 = v31;
  }
  uint64_t v34 = v119 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
  swift_beginAccess(v119 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters, v93, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v34, (uint64_t)&v92, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v92, 1, (uint64_t)v16))
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v92, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
    swift_bridgeObjectRelease(_swiftEmptyDictionarySingleton);
    uint64_t v35 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v35, 0, 0);
    *(void *)uint64_t v36 = 0xD000000000000026;
    *(void *)(v36 + 8) = "Augmentation options" + 0x8000000000000000;
    *(_OWORD *)(v36 + 16) = 0;
    *(_OWORD *)(v36 + 32) = 0;
    *(unsigned char *)(v36 + 48) = 0;
    Swift::Int v40 = swift_willThrow(&type metadata for MLCreateError, v35, v36, v37, v38, v39);
    goto LABEL_12;
  }
  uint64_t v106 = (uint64_t)v33;
  uint64_t v41 = (uint64_t)v118;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)&v92, (uint64_t)v118, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v92, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  uint64_t v23 = (uint64_t)v120;
  outlined init with copy of MLTrainingSessionParameters(v41 + v16[5], (uint64_t)v120, type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
  uint64_t v42 = *(void *)(v41 + v16[7]);
  uint64_t v43 = *(void *)(v41 + v16[8]);
  char v33 = (int *)v114;
  *(void *)(v23 + *(int *)(v114 + 20)) = *(void *)(v41 + v16[6]);
  *(void *)(v23 + v33[6]) = v42;
  *(void *)(v23 + v33[7]) = v43;
  outlined destroy of MLHandPoseClassifier.DataSource(v41, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
  uint64_t v44 = (uint64_t)v110;
  outlined init with take of MLClassifierMetrics(v23, (uint64_t)v110, type metadata accessor for MLHandPoseClassifier.ModelParameters);
  uint64_t v45 = v119;
  uint64_t v46 = *(void *)(v119 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model);
  if (!v46
    || (uint64_t v47 = *(void *)(v119 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels)) == 0)
  {
    swift_bridgeObjectRelease(_swiftEmptyDictionarySingleton);
    uint64_t v59 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v59, 0, 0);
    *(void *)uint64_t v60 = 0xD00000000000003CLL;
    *(void *)(v60 + 8) = "ve training parameters" + 0x8000000000000000;
    *(_OWORD *)(v60 + 16) = 0;
    *(_OWORD *)(v60 + 32) = 0;
    *(unsigned char *)(v60 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v59, v60, v61, v62, v63);
    Swift::Int v40 = outlined destroy of MLHandPoseClassifier.DataSource(v44, type metadata accessor for MLHandPoseClassifier.ModelParameters);
    goto LABEL_12;
  }
  uint64_t v120 = *(uint64_t **)(v44 + v33[7]);
  uint64_t v48 = *(void *)(v44 + v33[5]);
  uint64_t v49 = v33[6];
  uint64_t v114 = v46;
  uint64_t v50 = *(void *)(v44 + v49);
  double v51 = 0.0;
  uint64_t v52 = (uint64_t)v104;
  *(_OWORD *)uint64_t v104 = 0;
  *(_WORD *)(v52 + 16) = 256;
  uint64_t v118 = (uint64_t *)v47;
  uint64_t v53 = type metadata accessor for MLHandActionClassifier.ModelParameters.ValidationData(0);
  swift_storeEnumTagMultiPayload(v52, v53, 0);
  uint64_t v54 = *(int **)&v113;
  *(void *)(v52 + *(int *)(*(void *)&v113 + 20)) = v48;
  *(void *)(v52 + v54[6]) = v50;
  *(void *)(v52 + v54[7]) = 1;
  *(void *)(v52 + v54[8]) = v120;
  *(void *)(v52 + v54[10]) = 0x403E000000000000;
  uint64_t v55 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
  swift_beginAccess(v45 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures, v94, 0, 0);
  uint64_t v120 = *(uint64_t **)(v45 + v55);
  LODWORD(v113) = *(_DWORD *)(v45 + v55 + 8);
  uint64_t v107 = v120;
  char v108 = LOBYTE(v113) & 1;
  uint64_t v23 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures;
  swift_beginAccess(v45 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures, v95, 0, 0);
  uint64_t v56 = *(void *)(v45 + v23);
  LODWORD(v23) = *(_DWORD *)(v45 + v23 + 8);
  uint64_t v115 = v56;
  char v116 = v23 & 1;
  swift_retain();
  uint64_t v57 = v118;
  swift_bridgeObjectRetain((_BYTE)v118);
  outlined copy of Result<_DataTable, Error>((uint64_t)v120, SLOBYTE(v113));
  uint64_t v103 = v56;
  outlined copy of Result<_DataTable, Error>(v56, v23);
  uint64_t v58 = v105;
  static MLHandActionClassifier.prepareDataset(classLabels:trainingFeatures:validationFeatures:parameters:)((uint64_t)v112, (uint64_t)v111, v57, (uint64_t)&v107, (uint64_t)&v115, v52, 0.0);
  char v33 = (int *)LOBYTE(v113);
  if (v58)
  {
    swift_bridgeObjectRelease((_BYTE)v118);
    swift_release();
    outlined consume of Result<_DataTable, Error>(v103, v23);
    outlined consume of Result<_DataTable, Error>((uint64_t)v120, (char)v33);
    outlined destroy of MLHandPoseClassifier.DataSource(v52, type metadata accessor for MLHandActionClassifier.ModelParameters);
    outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v110, type metadata accessor for MLHandPoseClassifier.ModelParameters);
    Swift::Int v40 = swift_bridgeObjectRelease(_swiftEmptyDictionarySingleton);
    goto LABEL_12;
  }
  outlined consume of Result<_DataTable, Error>(v103, v23);
  outlined consume of Result<_DataTable, Error>((uint64_t)v120, (char)v33);
  uint64_t v66 = v106;
  if (v106 < 0) {
    BUG();
  }
  uint64_t v67 = (uint64_t)v111;
  uint64_t v68 = (uint64_t)v112;
  uint64_t v69 = v119;
  if (v106)
  {
    uint64_t v70 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_metricsAttributesDictionary;
    uint64_t v71 = 0;
    do
    {
      if (v66 == v71) {
        BUG();
      }
      if (__OFADD__(v71, *(void *)&v117)) {
        BUG();
      }
      uint64_t v72 = MLHandActionClassifier.GraphCNN.iterateTraining(trainingData:validationData:epochCount:)(v68, v67, v71 + *(void *)&v117, 0.0);
      ++v71;
      uint64_t v69 = v119;
      uint64_t v73 = *(void *)(v119 + v70);
      *(void *)(v119 + v70) = v72;
      swift_bridgeObjectRelease(v73);
      uint64_t v66 = v106;
      uint64_t v67 = (uint64_t)v111;
      uint64_t v68 = (uint64_t)v112;
    }
    while (v106 != v71);
  }
  double v117 = *(double *)&OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_metricsAttributesDictionary;
  uint64_t v74 = *(void *)(v69
                  + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_metricsAttributesDictionary);
  swift_bridgeObjectRetain(v74);
  specialized Dictionary.subscript.getter(0x676E696E69617274, 0xED000073736F6C5FLL, v74);
  swift_bridgeObjectRelease(v74);
  if (!v109)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v107, &demangling cache variable for type metadata for Any?);
    goto LABEL_23;
  }
  if (!swift_dynamicCast(&v115, &v107, (char *)&type metadata for Any + 8, &type metadata for Double, 6))
  {
LABEL_23:
    uint64_t v76 = _swiftEmptyDictionarySingleton;
    goto LABEL_24;
  }
  uint64_t v120 = (uint64_t *)v115;
  char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
  uint64_t v107 = _swiftEmptyDictionarySingleton;
  double v51 = *(double *)&v120;
  specialized _NativeDictionary.setValue(_:forKey:isUnique:)(0, isUniquelyReferenced_nonNull_native, *(double *)&v120);
  uint64_t v76 = v107;
  uint64_t v69 = v119;
  swift_bridgeObjectRelease(0);
LABEL_24:
  uint64_t v77 = *(void *)(v69 + *(void *)&v117);
  swift_bridgeObjectRetain(v77);
  specialized Dictionary.subscript.getter(0x69746164696C6176, 0xEF73736F6C5F6E6FLL, v77);
  swift_bridgeObjectRelease(v77);
  if (v109)
  {
    if (swift_dynamicCast(&v115, &v107, (char *)&type metadata for Any + 8, &type metadata for Double, 6))
    {
      uint64_t v120 = (uint64_t *)v115;
      char v78 = swift_isUniquelyReferenced_nonNull_native(v76);
      uint64_t v107 = v76;
      double v51 = *(double *)&v120;
      specialized _NativeDictionary.setValue(_:forKey:isUnique:)(4, v78, *(double *)&v120);
      uint64_t v120 = v107;
      swift_bridgeObjectRelease(0);
    }
    else
    {
      uint64_t v120 = v76;
    }
  }
  else
  {
    uint64_t v120 = v76;
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v107, &demangling cache variable for type metadata for Any?);
  }
  uint64_t v79 = *(void *)(v119 + *(void *)&v117);
  swift_bridgeObjectRetain(v79);
  specialized Dictionary.subscript.getter(0xD000000000000012, (uint64_t)("oseClassifier.swift" + 0x8000000000000000), v79);
  swift_bridgeObjectRelease(v79);
  if (v109)
  {
    uint64_t v80 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
    if (swift_dynamicCast(&v115, &v107, (char *)&type metadata for Any + 8, v80, 6))
    {
      uint64_t v105 = v115;
      uint64_t v81 = (uint64_t)v102;
      _MetricUtilities.ConfusionMatrixMeter.value(normalized:)(0, v51, v3);
      double v113 = static _MetricUtilities.top1Accuracy(confusionMatrix:classCount:)(v81, v118[2]);
      (*(void (**)(uint64_t, uint64_t))(v101 + 8))(v81, v100);
      uint64_t v82 = (uint64_t)v120;
      char v83 = swift_isUniquelyReferenced_nonNull_native(v120);
      uint64_t v107 = (void *)v82;
      double v51 = v113;
      specialized _NativeDictionary.setValue(_:forKey:isUnique:)(3, v83, v113);
      uint64_t v120 = v107;
      swift_release();
      swift_bridgeObjectRelease(0);
    }
  }
  else
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v107, &demangling cache variable for type metadata for Any?);
  }
  uint64_t v84 = *(void *)(v119 + *(void *)&v117);
  swift_bridgeObjectRetain(v84);
  specialized Dictionary.subscript.getter(0xD000000000000014, (uint64_t)("ve training confusion matrix" + 0x8000000000000000), v84);
  swift_bridgeObjectRelease(v84);
  if (v109)
  {
    uint64_t v85 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
    if (swift_dynamicCast(&v115, &v107, (char *)&type metadata for Any + 8, v85, 6))
    {
      uint64_t v119 = v115;
      uint64_t v86 = (uint64_t)v102;
      _MetricUtilities.ConfusionMatrixMeter.value(normalized:)(0, v51, v3);
      uint64_t v87 = v118[2];
      swift_bridgeObjectRelease((_BYTE)v118);
      double v117 = static _MetricUtilities.top1Accuracy(confusionMatrix:classCount:)(v86, v87);
      (*(void (**)(uint64_t, uint64_t))(v101 + 8))(v86, v100);
      uint64_t v88 = (uint64_t)v120;
      char v89 = swift_isUniquelyReferenced_nonNull_native(v120);
      uint64_t v107 = (void *)v88;
      specialized _NativeDictionary.setValue(_:forKey:isUnique:)(5, v89, v117);
      uint64_t v120 = v107;
      swift_release();
      char v90 = 0;
    }
    else
    {
      char v90 = (char)v118;
    }
    swift_bridgeObjectRelease(v90);
  }
  else
  {
    swift_bridgeObjectRelease((_BYTE)v118);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v107, &demangling cache variable for type metadata for Any?);
  }
  LOBYTE(v23) = (uint64_t)v96 >= v97;
  char v91 = (char)v120;
  char v33 = (int *)specialized _dictionaryUpCast<A, B, C, D>(_:)((uint64_t)v120);
  swift_bridgeObjectRelease(v91);
  swift_release();
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v111, &demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);
  (*(void (**)(uint64_t *, uint64_t))(v98 + 8))(v112, v99);
  outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v104, type metadata accessor for MLHandActionClassifier.ModelParameters);
  outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)v110, type metadata accessor for MLHandPoseClassifier.ModelParameters);
  Swift::Int v40 = v106;
LABEL_12:
  uint64_t v64 = v33;
  Swift::Bool v65 = v23;
  result.metrics._uint64_t rawValue = v64;
  result._0 = v40;
  result.finished = v65;
  return result;
}

Swift::tuple_Int_finished_Bool __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> HandPoseClassifierTrainingSessionDelegate.evaluate(from:)(Swift::Int from)
{
  v1._0 = 1;
  v1.finished = 1;
  return v1;
}

uint64_t HandPoseClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)(uint64_t a1, unsigned __int8 *a2)
{
  char v90 = v2;
  uint64_t v88 = a1;
  LODWORD(v4) = 0;
  uint64_t v5 = type metadata accessor for URL(0);
  int64_t v6 = *(void *)(*(void *)(v5 - 8) + 64);
  int64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v9 = alloca(v6);
  int64_t v10 = alloca(v6);
  uint64_t v11 = alloca(v6);
  Swift::String v12 = alloca(v6);
  int64_t v13 = alloca(v6);
  uint64_t v14 = alloca(v6);
  int v15 = *a2;
  if (v15 == 2)
  {
    LOBYTE(v4) = 1;
    if (*(void *)(v3 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_model))
    {
      swift_retain();
      specialized _ModelCheckpoint<>.save(to:)(v88);
      swift_release();
    }
  }
  else if (v15 == 1)
  {
    uint64_t v87 = *(void *)(v5 - 8);
    uint64_t v72 = v33;
    uint64_t v86 = v5;
    uint64_t v73 = v33;
    uint64_t v74 = v33;
    uint64_t v16 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures;
    uint64_t v75 = (uint64_t *)(v3 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures);
    swift_beginAccess(v3 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures, v50, 1, 0);
    uint64_t v17 = *(void *)(v3 + v16);
    char v18 = *(unsigned char *)(v3 + v16 + 8);
    int64_t v4 = &v52;
    uint64_t v52 = v17;
    LOBYTE(v53) = v18;
    outlined copy of Result<_DataTable, Error>(v17, v18);
    URL.appendingPathComponent(_:)(0x676E696E69617274, 0xE800000000000000);
    uint64_t v19 = v90;
    MLDataTable.write(to:)((uint64_t)v33);
    if (v19)
    {
      (*(void (**)(char *, uint64_t))(v87 + 8))(v33, v86);
      outlined consume of Result<_DataTable, Error>(v52, v53);
    }
    else
    {
      char v90 = *(void (**)(void, void))(v87 + 8);
      v90(v33, v86);
      outlined consume of Result<_DataTable, Error>(v52, v53);
      uint64_t v20 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures;
      uint64_t v87 = v3 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures;
      swift_beginAccess(v3 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures, v51, 1, 0);
      char v21 = *(unsigned char *)(v3 + v20 + 8);
      uint64_t v84 = *(void *)(v3 + v20);
      LOBYTE(v85) = v21;
      outlined copy of Result<_DataTable, Error>(v84, v21);
      uint64_t v22 = (uint64_t)v72;
      URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEA00000000006E6FLL);
      MLDataTable.write(to:)(v22);
      v90(v22, v86);
      outlined consume of Result<_DataTable, Error>(v84, v85);
      int64_t v4 = (uint64_t *)v73;
      char v90 = 0;
      URL.appendingPathComponent(_:)(0x676E696E69617274, 0xE800000000000000);
      LOBYTE(v52) = 1;
      *(_DWORD *)((char *)&v52 + 1) = *(_DWORD *)v76;
      HIDWORD(v52) = *(_DWORD *)&v76[3];
      uint64_t v53 = 44;
      unint64_t v54 = 0xE100000000000000;
      uint64_t v55 = 0;
      char v91 = 1;
      unint64_t v56 = 0xE000000000000000;
      uint64_t v57 = 92;
      unint64_t v58 = 0xE100000000000000;
      char v59 = 1;
      *(_DWORD *)uint64_t v60 = *(_DWORD *)v77;
      *(_DWORD *)&v60[3] = *(_DWORD *)&v77[3];
      uint64_t v61 = 34;
      unint64_t v62 = 0xE100000000000000;
      char v63 = 1;
      *(_DWORD *)&v64[3] = *(_DWORD *)&v78[3];
      *(_DWORD *)uint64_t v64 = *(_DWORD *)v78;
      Swift::Bool v65 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
      uint64_t v66 = 10;
      unint64_t v67 = 0xE100000000000000;
      long long v68 = 0;
      char v69 = 1;
      *(_DWORD *)uint64_t v70 = *(_DWORD *)v79;
      *(_DWORD *)&v70[3] = *(_DWORD *)&v79[3];
      uint64_t v71 = 0;
      int64_t v24 = v90;
      MLDataTable.init(contentsOf:options:)(v4, &v52);
      if (!v24)
      {
        char v25 = v81;
        uint64_t v26 = v75;
        uint64_t v27 = *v75;
        *uint64_t v75 = v80;
        int v28 = *((_DWORD *)v26 + 2);
        *((unsigned char *)v26 + 8) = v25;
        outlined consume of Result<_DataTable, Error>(v27, v28);
        int64_t v4 = (uint64_t *)v74;
        URL.appendingPathComponent(_:)(0x69746164696C6176, 0xEA00000000006E6FLL);
        v33[0] = 1;
        uint64_t v34 = 44;
        unint64_t v35 = 0xE100000000000000;
        uint64_t v36 = 0;
        char v89 = 1;
        unint64_t v37 = 0xE000000000000000;
        uint64_t v38 = 92;
        unint64_t v39 = 0xE100000000000000;
        char v40 = 1;
        uint64_t v41 = 34;
        unint64_t v42 = 0xE100000000000000;
        char v43 = 1;
        uint64_t v44 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
        uint64_t v45 = 10;
        unint64_t v46 = 0xE100000000000000;
        long long v47 = 0;
        char v48 = 1;
        uint64_t v49 = 0;
        MLDataTable.init(contentsOf:options:)(v4, v33);
        char v29 = v83;
        uint64_t v30 = v87;
        uint64_t v31 = *(void *)v87;
        *(void *)uint64_t v87 = v82;
        int v32 = *(_DWORD *)(v30 + 8);
        *(unsigned char *)(v30 + 8) = v29;
        outlined consume of Result<_DataTable, Error>(v31, v32);
        LOBYTE(v4) = 1;
      }
    }
  }
  return v4;
}

uint64_t HandPoseClassifierTrainingSessionDelegate.save(to:)(uint64_t a1, __m128 a2)
{
  uint64_t v20 = v2;
  uint64_t v21 = a1;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v7 = type metadata accessor for MLHandPoseClassifier.PersistentParameters(0);
  int64_t v8 = *(void *)(*(void *)(v7 - 8) + 64);
  uint64_t v9 = alloca(v8);
  int64_t v10 = alloca(v8);
  uint64_t v11 = OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters + v3;
  swift_beginAccess(v11, v19, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v11, (uint64_t)&v18, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v18, 1, v7) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v18, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
    uint64_t v12 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v12, 0, 0);
    *(void *)uint64_t v13 = 0xD000000000000030;
    *(void *)(v13 + 8) = "Feature Extractor" + 0x8000000000000000;
    *(_OWORD *)(v13 + 16) = 0;
    *(_OWORD *)(v13 + 32) = 0;
    *(unsigned char *)(v13 + 48) = 2;
    return swift_willThrow(&type metadata for MLCreateError, v12, v13, v14, v15, v16);
  }
  else
  {
    outlined init with take of MLClassifierMetrics((uint64_t)&v18, (uint64_t)&v18, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
    MLHandPoseClassifier.PersistentParameters.save(toSessionDirectory:)(v21, a2);
    return outlined destroy of MLHandPoseClassifier.DataSource((uint64_t)&v18, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
  }
}

NSURL *HandPoseClassifierTrainingSessionDelegate.restore(from:phase:)(uint64_t a1, __m128 a2)
{
  char v40 = (uint64_t *)v2;
  uint64_t v38 = v3;
  uint64_t v33 = a1;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?)
                             - 8)
                 + 64);
  uint64_t v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  unint64_t v35 = v31;
  uint64_t v7 = alloca(v4);
  int64_t v8 = alloca(v4);
  uint64_t v36 = v31;
  uint64_t v9 = alloca(v4);
  int64_t v10 = alloca(v4);
  unint64_t v39 = v31;
  uint64_t v11 = type metadata accessor for URL(0);
  uint64_t v12 = *(void *)(v11 - 8);
  int64_t v13 = *(void *)(v12 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v34 = type metadata accessor for MLHandPoseClassifier.PersistentParameters(0);
  int64_t v16 = *(void *)(*(void *)(v34 - 8) + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  unint64_t v37 = v31;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  (*(void (**)(uint64_t *, uint64_t, uint64_t))(v12 + 16))(v31, v33, v11);
  uint64_t v21 = (uint64_t)v40;
  Swift::tuple_Int_metrics_OpaquePointer_finished_Bool result = MLHandPoseClassifier.PersistentParameters.init(sessionDirectory:)(v31);
  if (!v21)
  {
    char v40 = v31;
    uint64_t v23 = v38 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters;
    swift_beginAccess(v38 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters, v31, 0, 0);
    uint64_t v24 = (uint64_t)v39;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v23, (uint64_t)v39, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
    uint64_t v25 = v24;
    uint64_t v26 = v34;
    if (__swift_getEnumTagSinglePayload(v25, 1, v34) == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v39, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
      uint64_t v27 = (uint64_t)v36;
      outlined init with take of MLClassifierMetrics((uint64_t)v40, (uint64_t)v36, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
      __swift_storeEnumTagSinglePayload(v27, 0, 1, v26);
      uint64_t v28 = (uint64_t)v35;
      outlined init with take of DataFrame?(v27, (uint64_t)v35, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
      swift_beginAccess(v23, v32, 33, 0);
      outlined assign with take of MLHandPoseClassifier.PersistentParameters?(v28, v23);
      return (NSURL *)swift_endAccess(v32);
    }
    else
    {
      uint64_t v29 = (uint64_t)v37;
      outlined init with take of MLClassifierMetrics((uint64_t)v39, (uint64_t)v37, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
      uint64_t v30 = (uint64_t)v40;
      HandPoseClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)((uint64_t)v40, v29, a2);
      outlined destroy of MLHandPoseClassifier.DataSource(v29, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
      return (NSURL *)outlined destroy of MLHandPoseClassifier.DataSource(v30, type metadata accessor for MLHandPoseClassifier.PersistentParameters);
    }
  }
  return result;
}

uint64_t HandPoseClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)(uint64_t a1, uint64_t a2, __m128 a3)
{
  uint64_t v159 = v3;
  v142._char object = (void *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
  int64_t v6 = *(void *)(*((void *)v142._object - 1) + 64);
  uint64_t v7 = alloca(v6);
  int64_t v8 = alloca(v6);
  char v140 = &v139;
  uint64_t v9 = type metadata accessor for DataFrame(0);
  v151._uint64_t countAndFlagsBits = *(void *)(v9 - 8);
  int64_t v10 = *(void *)(v151._countAndFlagsBits + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  v143._uint64_t countAndFlagsBits = (uint64_t)&v139;
  int64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  char v154 = &v139;
  uint64_t v156 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
  int64_t v15 = *(void *)(*(void *)(v156 - 8) + 64);
  int64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  v141._char object = &v139;
  uint64_t v18 = alloca(v15);
  uint64_t v19 = alloca(v15);
  char v145 = &v139;
  uint64_t v20 = alloca(v15);
  uint64_t v21 = alloca(v15);
  unint64_t v149 = &v139;
  uint64_t v22 = alloca(v15);
  uint64_t v23 = alloca(v15);
  unint64_t v153 = &v139;
  uint64_t v24 = (int *)type metadata accessor for MLHandPoseClassifier.PersistentParameters(0);
  uint64_t v25 = v24[6];
  uint64_t v26 = *(void *)(a2 + v25);
  if (*(void *)(a1 + v25) != v26)
  {
    uint64_t v157 = *(void *)(a1 + v25);
    uint64_t v33 = lazy protocol witness table accessor for type Int and conformance Int();
    uint64_t v159 = BinaryInteger.description.getter(&type metadata for Int, v33);
    uint64_t v156 = v34;
    uint64_t v157 = v26;
    uint64_t v35 = BinaryInteger.description.getter(&type metadata for Int, v33);
    uint64_t v37 = v36;
    uint64_t v38 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v38, 0, 0);
    *(void *)uint64_t v39 = 0x6953206863746142;
    char v43 = (char *)0xEA0000000000657ALL;
LABEL_8:
    *(void *)(v39 + 8) = v43;
    *(void *)(v39 + 16) = v159;
    *(void *)(v39 + 24) = v156;
    *(void *)(v39 + 32) = v35;
    *(void *)(v39 + 40) = v37;
LABEL_9:
    *(unsigned char *)(v39 + 48) = 3;
    return swift_willThrow(&type metadata for MLCreateError, v38, v39, v40, v41, v42);
  }
  uint64_t v27 = v24[7];
  uint64_t v28 = *(void *)(a2 + v27);
  if (*(void *)(a1 + v27) != v28)
  {
    uint64_t v157 = *(void *)(a1 + v27);
    uint64_t v44 = lazy protocol witness table accessor for type Int and conformance Int();
    uint64_t v159 = BinaryInteger.description.getter(&type metadata for Int, v44);
    uint64_t v156 = v45;
    uint64_t v157 = v28;
    uint64_t v35 = BinaryInteger.description.getter(&type metadata for Int, v44);
    uint64_t v37 = v46;
    uint64_t v38 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v38, 0, 0);
    *(void *)uint64_t v39 = 0xD000000000000012;
    char v43 = "metricsAttributesDictionary" + 0x8000000000000000;
    goto LABEL_8;
  }
  uint64_t v29 = v24[8];
  uint64_t v30 = *(void *)(a2 + v29);
  if (*(void *)(a1 + v29) != v30)
  {
    uint64_t v157 = *(void *)(a1 + v29);
    uint64_t v47 = lazy protocol witness table accessor for type Int and conformance Int();
    uint64_t v159 = BinaryInteger.description.getter(&type metadata for Int, v47);
    uint64_t v156 = v48;
    uint64_t v157 = v30;
    uint64_t v49 = BinaryInteger.description.getter(&type metadata for Int, v47);
    uint64_t v51 = v50;
    uint64_t v38 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v38, 0, 0);
    *(void *)uint64_t v39 = 0xD000000000000014;
    *(void *)(v39 + 8) = "Maximum Iterations" + 0x8000000000000000;
    *(void *)(v39 + 16) = v159;
    *(void *)(v39 + 24) = v156;
    *(void *)(v39 + 32) = v49;
    *(void *)(v39 + 40) = v51;
    goto LABEL_9;
  }
  uint64_t v146 = v9;
  uint64_t v31 = v159;
  uint64_t result = MLHandPoseClassifier.DataSource.imagesWithAnnotations()(a3);
  if (v31) {
    return result;
  }
  uint64_t v159 = v157;
  char v160 = object;
  MLHandPoseClassifier.DataSource.imagesWithAnnotations()(a3);
  uint64_t v150 = 0;
  uint64_t v155 = v157;
  char v161 = object;
  uint64_t v157 = v159;
  char v52 = v160 & 1;
  char object = v160 & 1;
  if (MLDataTable.size.getter() > 0)
  {
    uint64_t v157 = v155;
    LOBYTE(v151._object) = v161 & 1;
    char object = v161 & 1;
    if (MLDataTable.size.getter() > 0)
    {
      uint64_t v53 = v159;
      uint64_t v157 = v159;
      char object = v52;
      uint64_t v54 = v150;
      uint64_t v55 = HandPoseClassifierTrainingSessionDelegate.pathsByLabel(for:)((uint64_t)&v157, *(double *)a3.i64);
      uint64_t v157 = v155;
      char object = (char)v151._object;
      unint64_t v56 = HandPoseClassifierTrainingSessionDelegate.pathsByLabel(for:)((uint64_t)&v157, *(double *)a3.i64);
      char v57 = (char)v56;
      uint64_t v150 = v54;
      char v58 = specialized static Dictionary<>.== infix(_:_:)((uint64_t)v55, (uint64_t)v56);
      swift_bridgeObjectRelease((_BYTE)v55);
      swift_bridgeObjectRelease(v57);
      if (v58)
      {
        outlined consume of Result<_DataTable, Error>(v53, v160);
        char v59 = v161;
        uint64_t v60 = v155;
      }
      else
      {
        uint64_t v84 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v84, 0, 0);
        *(void *)uint64_t v85 = 1;
        *(_OWORD *)(v85 + 8) = 0;
        *(_OWORD *)(v85 + 24) = 0;
        *(void *)(v85 + 40) = 0;
        *(unsigned char *)(v85 + 48) = 4;
        swift_willThrow(&type metadata for MLCreateError, v84, v85, v86, v87, v88);
        outlined consume of Result<_DataTable, Error>(v155, v161);
        char v59 = v160;
        uint64_t v60 = v53;
      }
      return outlined consume of Result<_DataTable, Error>(v60, v59);
    }
  }
  uint64_t v61 = (uint64_t)v153;
  outlined init with copy of MLTrainingSessionParameters(a1, (uint64_t)v153, type metadata accessor for MLHandPoseClassifier.DataSource);
  uint64_t v62 = v156;
  if (swift_getEnumCaseMultiPayload(v61, v156) == 3)
  {
    uint64_t v152 = *(void *)v61;
    LOBYTE(v151._object) = *(unsigned char *)(v61 + 8);
    v141._uint64_t countAndFlagsBits = *(void *)(v61 + 16);
    v143._char object = *(void **)(v61 + 24);
    v142._uint64_t countAndFlagsBits = *(void *)(v61 + 32);
    long long v144 = *(void **)(v61 + 40);
    swift_bridgeObjectRelease(*(void *)(v61 + 56));
    uint64_t v63 = (uint64_t)v149;
    outlined init with copy of MLTrainingSessionParameters(a2, (uint64_t)v149, type metadata accessor for MLHandPoseClassifier.DataSource);
    if (swift_getEnumCaseMultiPayload(v63, v62) == 3)
    {
      uint64_t v156 = *(void *)v63;
      LODWORD(v154) = *(_DWORD *)(v63 + 8);
      v143._uint64_t countAndFlagsBits = *(void *)(v63 + 16);
      char v145 = *(uint64_t **)(v63 + 24);
      v151._uint64_t countAndFlagsBits = *(void *)(v63 + 32);
      v141._char object = *(void **)(v63 + 40);
      swift_bridgeObjectRelease(*(void *)(v63 + 56));
      uint64_t v64 = v152;
      uint64_t v147 = v152;
      int object_low = LOBYTE(v151._object);
      LOBYTE(v151._object) &= 1u;
      char v148 = (char)v151._object;
      outlined copy of Result<_DataTable, Error>(v152, object_low);
      v66._uint64_t countAndFlagsBits = v142._countAndFlagsBits;
      char v67 = (char)v144;
      v66._char object = v144;
      MLDataTable.subscript.getter(v66);
      swift_bridgeObjectRelease(v67);
      LODWORD(v153) = object_low;
      outlined consume of Result<_DataTable, Error>(v64, object_low);
      uint64_t v147 = v157;
      char v148 = object;
      unint64_t v149 = Array<A>.init(_:)((uint64_t)&v147, *(double *)a3.i64);
      uint64_t v68 = v156;
      uint64_t v147 = v156;
      char v69 = (char)v154;
      LOBYTE(v142._object) = v154 & 1;
      char v148 = v154 & 1;
      outlined copy of Result<_DataTable, Error>(v156, (char)v154);
      v66._uint64_t countAndFlagsBits = v151._countAndFlagsBits;
      LOBYTE(object_low) = v141._object;
      v66._char object = v141._object;
      MLDataTable.subscript.getter(v66);
      swift_bridgeObjectRelease(object_low);
      outlined consume of Result<_DataTable, Error>(v68, v69);
      uint64_t v147 = v157;
      char v148 = object;
      uint64_t v70 = Array<A>.init(_:)((uint64_t)&v147, *(double *)a3.i64);
      LOBYTE(object_low) = (_BYTE)v70;
      LOBYTE(v68) = (_BYTE)v149;
      char v71 = specialized static Array<A>.== infix(_:_:)((uint64_t)v149, (uint64_t)v70);
      swift_bridgeObjectRelease(v68);
      swift_bridgeObjectRelease(object_low);
      if (v71)
      {
        uint64_t v72 = v152;
        uint64_t v147 = v152;
        char v148 = (char)v151._object;
        char v73 = (char)v153;
        outlined copy of Result<_DataTable, Error>(v152, (char)v153);
        v74._uint64_t countAndFlagsBits = v141._countAndFlagsBits;
        char v75 = (char)v143._object;
        v74._char object = v143._object;
        MLDataTable.subscript.getter(v74);
        swift_bridgeObjectRelease(v75);
        outlined consume of Result<_DataTable, Error>(v72, v73);
        uint64_t v147 = v157;
        char v148 = object;
        v151._uint64_t countAndFlagsBits = (uint64_t)Array<A>.init(_:)((uint64_t)&v147, *(double *)a3.i64);
        uint64_t v76 = v156;
        uint64_t v147 = v156;
        char v148 = (char)v142._object;
        char v77 = (char)v154;
        outlined copy of Result<_DataTable, Error>(v156, (char)v154);
        v74._uint64_t countAndFlagsBits = v143._countAndFlagsBits;
        LOBYTE(v72) = (_BYTE)v145;
        v74._char object = v145;
        MLDataTable.subscript.getter(v74);
        swift_bridgeObjectRelease(v72);
        v74._uint64_t countAndFlagsBits = v76;
        char v78 = v77;
        outlined consume of Result<_DataTable, Error>(v74._countAndFlagsBits, v77);
        uint64_t v147 = v157;
        char v148 = object;
        uint64_t v79 = Array<A>.init(_:)((uint64_t)&v147, *(double *)a3.i64);
        char v80 = (char)v79;
        LOBYTE(v72) = v151._countAndFlagsBits;
        char v81 = specialized static Array<A>.== infix(_:_:)(v151._countAndFlagsBits, (uint64_t)v79);
        swift_bridgeObjectRelease(v72);
        swift_bridgeObjectRelease(v80);
        if (v81)
        {
          outlined consume of Result<_DataTable, Error>(v159, v160);
          outlined consume of Result<_DataTable, Error>(v155, v161);
          outlined consume of Result<_DataTable, Error>(v156, v78);
          uint64_t v60 = v152;
          char v59 = (char)v153;
          return outlined consume of Result<_DataTable, Error>(v60, v59);
        }
        uint64_t v134 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v134, 0, 0);
        *(void *)uint64_t v135 = 1;
        *(_OWORD *)(v135 + 8) = 0;
        *(_OWORD *)(v135 + 24) = 0;
        *(void *)(v135 + 40) = 0;
        *(unsigned char *)(v135 + 48) = 4;
        swift_willThrow(&type metadata for MLCreateError, v134, v135, v136, v137, v138);
        uint64_t v127 = v156;
        char v126 = v78;
      }
      else
      {
        swift_bridgeObjectRelease((_BYTE)v145);
        swift_bridgeObjectRelease(v143._object);
        uint64_t v121 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v121, 0, 0);
        *(void *)uint64_t v122 = 1;
        *(_OWORD *)(v122 + 8) = 0;
        *(_OWORD *)(v122 + 24) = 0;
        *(void *)(v122 + 40) = 0;
        *(unsigned char *)(v122 + 48) = 4;
        swift_willThrow(&type metadata for MLCreateError, v121, v122, v123, v124, v125);
        char v126 = (char)v154;
        uint64_t v127 = v156;
      }
      outlined consume of Result<_DataTable, Error>(v127, v126);
      outlined consume of Result<_DataTable, Error>(v152, (char)v153);
      outlined consume of Result<_DataTable, Error>(v155, v161);
      char v59 = v160;
      uint64_t v60 = v159;
      return outlined consume of Result<_DataTable, Error>(v60, v59);
    }
    outlined consume of Result<_DataTable, Error>(v152, (char)v151._object);
    swift_bridgeObjectRelease((_BYTE)v144);
    swift_bridgeObjectRelease(v143._object);
    uint64_t v82 = v63;
    uint64_t v83 = v155;
  }
  else
  {
    uint64_t v82 = v61;
    uint64_t v83 = v155;
  }
  outlined destroy of MLHandPoseClassifier.DataSource(v82, type metadata accessor for MLHandPoseClassifier.DataSource);
  uint64_t v89 = a1;
  uint64_t v90 = (uint64_t)v145;
  outlined init with copy of MLTrainingSessionParameters(v89, (uint64_t)v145, type metadata accessor for MLHandPoseClassifier.DataSource);
  uint64_t v91 = v156;
  if (swift_getEnumCaseMultiPayload(v90, v156) != 5)
  {
    outlined consume of Result<_DataTable, Error>(v159, v160);
    outlined consume of Result<_DataTable, Error>(v83, v161);
    uint64_t v120 = v90;
    return outlined destroy of MLHandPoseClassifier.DataSource(v120, type metadata accessor for MLHandPoseClassifier.DataSource);
  }
  uint64_t v92 = v91;
  char v93 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
  uint64_t v94 = v93[12];
  uint64_t v152 = *(void *)(v90 + v94);
  unint64_t v149 = *(uint64_t **)(v90 + v94 + 8);
  uint64_t v95 = v93[16];
  v151._char object = *(void **)(v90 + v95);
  unint64_t v153 = *(uint64_t **)(v90 + v95 + 8);
  swift_bridgeObjectRelease(*(void *)(v90 + v93[20] + 8));
  uint64_t v96 = v90;
  uint64_t countAndFlagsBits = v151._countAndFlagsBits;
  char v145 = *(uint64_t **)(v151._countAndFlagsBits + 32);
  ((void (*)(uint64_t *, uint64_t, uint64_t))v145)(v154, v96, v146);
  uint64_t v98 = a2;
  uint64_t v99 = (char *)v141._object;
  outlined init with copy of MLTrainingSessionParameters(v98, (uint64_t)v141._object, type metadata accessor for MLHandPoseClassifier.DataSource);
  if (swift_getEnumCaseMultiPayload(v99, v92) != 5)
  {
    (*(void (**)(uint64_t *, uint64_t))(countAndFlagsBits + 8))(v154, v146);
    outlined consume of Result<_DataTable, Error>(v159, v160);
    outlined consume of Result<_DataTable, Error>(v155, v161);
    swift_bridgeObjectRelease((_BYTE)v153);
    swift_bridgeObjectRelease((_BYTE)v149);
    uint64_t v120 = (uint64_t)v99;
    return outlined destroy of MLHandPoseClassifier.DataSource(v120, type metadata accessor for MLHandPoseClassifier.DataSource);
  }
  uint64_t v100 = v93[12];
  v142._uint64_t countAndFlagsBits = *(void *)&v99[v100];
  long long v144 = *(void **)&v99[v100 + 8];
  uint64_t v101 = v93[16];
  uint64_t v156 = *(void *)&v99[v101];
  v143._char object = *(void **)&v99[v101 + 8];
  swift_bridgeObjectRelease(*(void *)&v99[v93[20] + 8]);
  ((void (*)(uint64_t, char *, uint64_t))v145)(v143._countAndFlagsBits, v99, v146);
  uint64_t v102 = v140;
  char v103 = (char)v153;
  DataFrame.subscript.getter(v151._object, v153);
  swift_bridgeObjectRelease(v103);
  char v104 = (char)v143._object;
  DataFrame.subscript.getter(v156, v143._object);
  swift_bridgeObjectRelease(v104);
  char v105 = specialized Sequence.allSatisfy(_:)((void (*)(void, void))v102);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v102, &demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
  if (v105)
  {
    char v106 = (char)v149;
    DataFrame.subscript.getter(v152, v149);
    swift_bridgeObjectRelease(v106);
    char v107 = (char)v144;
    uint64_t v108 = v143._countAndFlagsBits;
    DataFrame.subscript.getter(v142._countAndFlagsBits, v144);
    swift_bridgeObjectRelease(v107);
    char v109 = specialized Sequence.allSatisfy(_:)((void (*)(void, void))v102);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v102, &demangling cache variable for type metadata for Zip2Sequence<AnyColumn, AnyColumn>);
    BOOL v110 = (v109 & 1) == 0;
    uint64_t v111 = v159;
    char v112 = v160;
    if (v110)
    {
      uint64_t v113 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v113, 0, 0);
      *(void *)uint64_t v114 = 1;
      *(_OWORD *)(v114 + 8) = 0;
      *(_OWORD *)(v114 + 24) = 0;
      *(void *)(v114 + 40) = 0;
      *(unsigned char *)(v114 + 48) = 4;
      swift_willThrow(&type metadata for MLCreateError, v113, v114, v115, v116, v117);
    }
    outlined consume of Result<_DataTable, Error>(v155, v161);
    outlined consume of Result<_DataTable, Error>(v111, v112);
    uint64_t v118 = *(void (**)(uint64_t, uint64_t))(v151._countAndFlagsBits + 8);
    uint64_t v119 = v108;
  }
  else
  {
    swift_bridgeObjectRelease((_BYTE)v144);
    swift_bridgeObjectRelease((_BYTE)v149);
    uint64_t v128 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v128, 0, 0);
    *(void *)uint64_t v129 = 1;
    *(_OWORD *)(v129 + 8) = 0;
    *(_OWORD *)(v129 + 24) = 0;
    *(void *)(v129 + 40) = 0;
    *(unsigned char *)(v129 + 48) = 4;
    swift_willThrow(&type metadata for MLCreateError, v128, v129, v130, v131, v132);
    outlined consume of Result<_DataTable, Error>(v155, v161);
    outlined consume of Result<_DataTable, Error>(v159, v160);
    uint64_t v118 = *(void (**)(uint64_t, uint64_t))(v151._countAndFlagsBits + 8);
    uint64_t v119 = v143._countAndFlagsBits;
  }
  uint64_t v133 = v146;
  v118(v119, v146);
  return ((uint64_t (*)(uint64_t *, uint64_t))v118)(v154, v133);
}

uint64_t closure #1 in HandPoseClassifierTrainingSessionDelegate.verifyThatParametersAreCompatible(_:_:)(uint64_t a1, uint64_t a2)
{
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, (uint64_t)v7, &demangling cache variable for type metadata for Any?);
  if (v8)
  {
    if (swift_dynamicCast(&v12, v7, (char *)&type metadata for Any + 8, &type metadata for AnyHashable, 6))goto LABEL_6; {
    long long v13 = 0;
    }
    long long v12 = 0;
  }
  else
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v7, &demangling cache variable for type metadata for Any?);
    long long v12 = 0;
    long long v13 = 0;
  }
  uint64_t v14 = 0;
LABEL_6:
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a2, (uint64_t)v7, &demangling cache variable for type metadata for Any?);
  if (v8)
  {
    if (swift_dynamicCast(&v15, v7, (char *)&type metadata for Any + 8, &type metadata for AnyHashable, 6))goto LABEL_11; {
    long long v16 = 0;
    }
    long long v15 = 0;
  }
  else
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v7, &demangling cache variable for type metadata for Any?);
    long long v15 = 0;
    long long v16 = 0;
  }
  uint64_t v17 = 0;
LABEL_11:
  uint64_t v2 = &v9;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v12, (uint64_t)v7, &demangling cache variable for type metadata for AnyHashable?);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v15, (uint64_t)&v9, &demangling cache variable for type metadata for AnyHashable?);
  if (!v8)
  {
    if (!*((void *)&v10 + 1))
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v7, &demangling cache variable for type metadata for AnyHashable?);
      LOBYTE(v2) = 1;
      goto LABEL_18;
    }
LABEL_17:
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v7, &demangling cache variable for type metadata for (AnyHashable?, AnyHashable?));
    LODWORD(v2) = 0;
    goto LABEL_18;
  }
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v7, (uint64_t)v6, &demangling cache variable for type metadata for AnyHashable?);
  if (!*((void *)&v10 + 1))
  {
    outlined destroy of AnyHashable((uint64_t)v6);
    goto LABEL_17;
  }
  uint64_t v5 = v11;
  v4[1] = v10;
  v4[0] = v9;
  LODWORD(v2) = static AnyHashable.== infix(_:_:)(v6, v4);
  outlined destroy of AnyHashable((uint64_t)v4);
  outlined destroy of AnyHashable((uint64_t)v6);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v7, &demangling cache variable for type metadata for AnyHashable?);
LABEL_18:
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v15, &demangling cache variable for type metadata for AnyHashable?);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v12, &demangling cache variable for type metadata for AnyHashable?);
  return v2;
}

void *HandPoseClassifierTrainingSessionDelegate.pathsByLabel(for:)(uint64_t a1, double a2)
{
  int v2 = *(_DWORD *)(a1 + 8);
  uint64_t v42 = *(void *)a1;
  uint64_t v48 = *(void *)a1;
  outlined copy of Result<_DataTable, Error>(*(void *)a1, v2);
  v3._uint64_t countAndFlagsBits = 0x7461506F65646976;
  v3._char object = (void *)0xE900000000000068;
  MLDataTable.subscript.getter(v3);
  if ((_BYTE)v46
    || (outlined copy of Result<_DataTable, Error>((uint64_t)v45, 0),
        _UntypedColumn.type.getter(),
        outlined consume of Result<_DataTable, Error>((uint64_t)v45, 0),
        (_BYTE)v42 != 2))
  {
    outlined consume of Result<_DataTable, Error>((uint64_t)v45, (char)v46);
    char v32 = v2;
    uint64_t v33 = v48;
LABEL_27:
    outlined consume of Result<_DataTable, Error>(v33, v32);
    uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
    return (void *)Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, v34, &protocol witness table for String);
  }
  uint64_t v41 = v45;
  outlined consume of Result<_DataTable, Error>(v48, v2);
  outlined copy of Result<_DataTable, Error>(v48, v2);
  v4._uint64_t countAndFlagsBits = 0x6C6562616CLL;
  v4._char object = (void *)0xE500000000000000;
  MLDataTable.subscript.getter(v4);
  uint64_t v5 = (uint64_t)v45;
  outlined copy of Result<_DataTable, Error>((uint64_t)v45, 0);
  _UntypedColumn.type.getter();
  outlined consume of Result<_DataTable, Error>((uint64_t)v45, 0);
  if ((_BYTE)v48 != 2)
  {
    outlined consume of Result<_DataTable, Error>((uint64_t)v45, (char)v46);
    outlined consume of Result<_DataTable, Error>(v48, v2);
    uint64_t v33 = (uint64_t)v45;
    char v32 = 0;
    goto LABEL_27;
  }
  uint64_t v40 = v45;
  outlined consume of Result<_DataTable, Error>(v48, v2);
  uint64_t v6 = (uint64_t)v45;
  outlined copy of Result<_DataTable, Error>((uint64_t)v45, 0);
  uint64_t v7 = CMLColumn.size.getter();
  outlined consume of Result<_DataTable, Error>((uint64_t)v45, 0);
  if (v7 < 0) {
    BUG();
  }
  if (v7)
  {
    uint64_t v8 = v7;
    long long v9 = 0;
    uint64_t v10 = 0;
    uint64_t v37 = v8;
    do
    {
      if (v8 == v10) {
        BUG();
      }
      uint64_t v11 = v10;
      uint64_t v12 = (uint64_t)v9;
      outlined copy of Result<_DataTable, Error>(v5, 0);
      _UntypedColumn.valueAtIndex(index:)(v11, a2);
      uint64_t v13 = (uint64_t)v46;
      if (v47 == 2)
      {
        uint64_t v43 = (uint64_t)v45;
      }
      else
      {
        outlined consume of MLDataValue(v45, v46, v47);
        uint64_t v43 = 0;
        uint64_t v13 = 0xE000000000000000;
      }
      outlined consume of Result<_DataTable, Error>(v5, 0);
      outlined copy of Result<_DataTable, Error>(v6, 0);
      _UntypedColumn.valueAtIndex(index:)(v11, a2);
      uint64_t v36 = v11;
      if (v47 == 2)
      {
        unint64_t v39 = (unint64_t)v46;
        uint64_t v38 = v45;
      }
      else
      {
        outlined consume of MLDataValue(v45, v46, v47);
        uint64_t v38 = 0;
        unint64_t v39 = 0xE000000000000000;
      }
      outlined consume of Result<_DataTable, Error>(v6, 0);
      _sxRi_zRi0_zlySaySdGIsegr_SgWOe(v12, 0);
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(_swiftEmptyDictionarySingleton);
      uint64_t v45 = _swiftEmptyDictionarySingleton;
      unint64_t v44 = specialized __RawDictionaryStorage.find<A>(_:)(v43, v13);
      BOOL v16 = (v15 & 1) == 0;
      BOOL v17 = __OFADD__(_swiftEmptyDictionarySingleton[2], v16);
      Swift::Int v18 = _swiftEmptyDictionarySingleton[2] + v16;
      if (v17) {
        BUG();
      }
      char v19 = v15;
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [String]>);
      if (_NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v18))
      {
        unint64_t v44 = specialized __RawDictionaryStorage.find<A>(_:)(v43, v13);
        if ((v19 & 1) != (v20 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
          BUG();
        }
      }
      swift_bridgeObjectRelease(0);
      unsigned __int8 v21 = _swiftEmptyDictionarySingleton;
      if ((v19 & 1) == 0)
      {
        _swiftEmptyDictionarySingleton[(v44 >> 6) + 8] |= 1 << v44;
        uint64_t v22 = _swiftEmptyDictionarySingleton[6];
        uint64_t v23 = 16 * v44;
        *(void *)(v22 + v23) = v43;
        *(void *)(v22 + v23 + 8) = v13;
        *(void *)(_swiftEmptyDictionarySingleton[7] + 8 * v44) = _swiftEmptyArrayStorage;
        uint64_t v24 = _swiftEmptyDictionarySingleton[2];
        swift_bridgeObjectRetain(_swiftEmptyDictionarySingleton);
        BOOL v17 = __OFADD__(1, v24);
        uint64_t v25 = v24 + 1;
        if (v17) {
          BUG();
        }
        _swiftEmptyDictionarySingleton[2] = v25;
        unsigned __int8 v21 = v13;
      }
      swift_bridgeObjectRetain(v21);
      uint64_t v26 = _swiftEmptyDictionarySingleton[7];
      swift_bridgeObjectRelease(_swiftEmptyDictionarySingleton);
      uint64_t v27 = *(void **)(v26 + 8 * v44);
      char v28 = swift_isUniquelyReferenced_nonNull_native(v27);
      *(void *)(v26 + 8 * v44) = v27;
      if (!v28)
      {
        uint64_t v27 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v27[2] + 1, 1, (uint64_t)v27);
        *(void *)(v26 + 8 * v44) = v27;
      }
      unint64_t v29 = v27[2];
      if (v27[3] >> 1 <= v29)
      {
        uint64_t v27 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v27[3] >= 2uLL, v29 + 1, 1, (uint64_t)v27);
        *(void *)(v26 + 8 * v44) = v27;
      }
      uint64_t v10 = v36 + 1;
      void v27[2] = v29 + 1;
      uint64_t v30 = 2 * v29;
      v27[v30 + 4] = v38;
      v27[v30 + 5] = v39;
      swift_bridgeObjectRelease(v13);
      uint64_t v31 = specialized thunk for @callee_guaranteed () -> (@owned [Double]);
      long long v9 = specialized thunk for @callee_guaranteed () -> (@owned [Double]);
      uint64_t v8 = v37;
      uint64_t v6 = (uint64_t)v41;
      uint64_t v5 = (uint64_t)v40;
    }
    while (v37 != v36 + 1);
  }
  else
  {
    uint64_t v31 = 0;
  }
  outlined consume of Result<_DataTable, Error>(v6, 0);
  outlined consume of Result<_DataTable, Error>(v5, 0);
  _sxRi_zRi0_zlySaySdGIsegr_SgWOe((uint64_t)v31, 0);
  return _swiftEmptyDictionarySingleton;
}

uint64_t HandPoseClassifierTrainingSessionDelegate.deinit()
{
  outlined destroy of MLHandPoseClassifier.DataSource(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sessionParameters, type metadata accessor for MLTrainingSessionParameters);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingParameters, &demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  outlined consume of MLDataTable?(*(void *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable), *(_DWORD *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_sourceTable + 8));
  outlined consume of Result<_DataTable, Error>(*(void *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures), *(_DWORD *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_trainingFeatures + 8));
  outlined consume of Result<_DataTable, Error>(*(void *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures), *(_DWORD *)(v0 + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_validationFeatures + 8));
  swift_release();
  swift_bridgeObjectRelease(*(void *)(v0
                                      + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_classLabels));
  swift_bridgeObjectRelease(*(void *)(v0
                                      + OBJC_IVAR____TtC8CreateML41HandPoseClassifierTrainingSessionDelegate_metricsAttributesDictionary));
  return v0;
}

uint64_t HandPoseClassifierTrainingSessionDelegate.__deallocating_deinit()
{
  HandPoseClassifierTrainingSessionDelegate.deinit();
  return swift_deallocClassInstance(v0, *(unsigned int *)(*(void *)v0 + 48), *(unsigned __int16 *)(*(void *)v0 + 52));
}

uint64_t ObjC metadata update function for HandPoseClassifierTrainingSessionDelegate()
{
  return type metadata accessor for HandPoseClassifierTrainingSessionDelegate(0);
}

uint64_t type metadata accessor for HandPoseClassifierTrainingSessionDelegate(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for HandPoseClassifierTrainingSessionDelegate;
  if (!type metadata singleton initialization cache for HandPoseClassifierTrainingSessionDelegate) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for HandPoseClassifierTrainingSessionDelegate);
  }
  return result;
}

uint64_t type metadata completion function for HandPoseClassifierTrainingSessionDelegate(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLTrainingSessionParameters(319);
  if (v2 <= 0x3F)
  {
    v4[0] = *(void *)(result - 8) + 64;
    uint64_t result = type metadata accessor for MLHandPoseClassifier.PersistentParameters?(319);
    if (v3 <= 0x3F)
    {
      v4[1] = *(void *)(result - 8) + 64;
      _OWORD v4[2] = "\t";
      v4[3] = (char *)&value witness table for Builtin.Int64 + 64;
      v4[4] = (char *)&value witness table for Builtin.Int64 + 64;
      void v4[5] = &unk_34AF78;
      void v4[6] = &unk_34AF78;
      void v4[7] = &unk_34AF90;
      v4[8] = &unk_34AF90;
      v4[9] = (char *)&value witness table for Builtin.BridgeObject + 64;
      uint64_t result = swift_updateClassMetadata2(a1, 256, 10, v4, a1 + 80);
      if (!result) {
        return 0;
      }
    }
  }
  return result;
}

uint64_t type metadata accessor for MLHandPoseClassifier.PersistentParameters?(uint64_t a1)
{
  uint64_t result = lazy cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?;
  if (!lazy cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?)
  {
    uint64_t v2 = type metadata accessor for MLHandPoseClassifier.PersistentParameters(255);
    uint64_t result = type metadata accessor for Optional(a1, v2);
    if (!v3) {
      lazy cache variable for type metadata for MLHandPoseClassifier.PersistentParameters? = result;
    }
  }
  return result;
}

void protocol witness for TrainingSessionDelegate.setUp() in conformance HandPoseClassifierTrainingSessionDelegate()
{
}

void protocol witness for TrainingSessionDelegate.resume(from:) in conformance HandPoseClassifierTrainingSessionDelegate(Swift::OpaquePointer a1)
{
}

unint64_t protocol witness for TrainingSessionDelegate.itemCount(phase:) in conformance HandPoseClassifierTrainingSessionDelegate(CreateML::MLPhase a1)
{
  return (unint64_t)HandPoseClassifierTrainingSessionDelegate.itemCount(phase:)(a1);
}

void protocol witness for TrainingSessionDelegate.transitionTo(phase:) in conformance HandPoseClassifierTrainingSessionDelegate(CreateML::MLPhase a1)
{
}

uint64_t protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance HandPoseClassifierTrainingSessionDelegate(Swift::Int a1)
{
  *(Swift::tuple_Int_finished_Bool *)&long long v2 = HandPoseClassifierTrainingSessionDelegate.extractFeatures(from:)(a1);
  if (v4)
  {
    uint64_t v5 = v1;
  }
  else
  {
    unsigned int v3 = BYTE8(v2);
    uint64_t v5 = v1;
    *((void *)&v2 + 1) = v2;
  }
  return protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(*(uint64_t (**)(uint64_t, void))(v1 + 8), v5, *((uint64_t *)&v2 + 1), v3);
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance HandPoseClassifierTrainingSessionDelegate(Swift::Int a1)
{
  Swift::tuple_Int_metrics_OpaquePointer_finished_Bool v9 = HandPoseClassifierTrainingSessionDelegate.train(from:)(a1);
  if (v4)
  {
    uint64_t v5 = *(uint64_t (**)(uint64_t, uint64_t, void))(v1 + 8);
    uint64_t v6 = v1;
  }
  else
  {
    uint64_t rawValue = v9.metrics._rawValue;
    uint64_t v5 = *(uint64_t (**)(uint64_t, uint64_t, void))(v1 + 8);
    BOOL finished = v9.finished;
    uint64_t v6 = v1;
    v9.metrics._uint64_t rawValue = (void *)v9._0;
    *(void *)&v9.BOOL finished = rawValue;
  }
  return protocol witness for TrainingSessionDelegate.train(from:) in conformance HandPoseClassifierTrainingSessionDelegate(v5, v6, (uint64_t)v9.metrics._rawValue, *(uint64_t *)&v9.finished, finished);
}

uint64_t protocol witness for TrainingSessionDelegate.evaluate(from:) in conformance HandPoseClassifierTrainingSessionDelegate()
{
  return protocol witness for TrainingSessionDelegate.extractFeatures(from:) in conformance SoundClassifierTrainingSessionDelegate(*(uint64_t (**)(uint64_t, void))(v0 + 8), v0, 1, 1u);
}

uint64_t protocol witness for TrainingSessionDelegate.saveCheckpoint(to:phase:iteration:) in conformance HandPoseClassifierTrainingSessionDelegate(uint64_t a1, unsigned __int8 *a2)
{
  return HandPoseClassifierTrainingSessionDelegate.saveCheckpoint(to:phase:iteration:)(a1, a2);
}

uint64_t protocol witness for TrainingSessionCodable.save(to:) in conformance HandPoseClassifierTrainingSessionDelegate(uint64_t a1, __m128 a2)
{
  return HandPoseClassifierTrainingSessionDelegate.save(to:)(a1, a2);
}

NSURL *protocol witness for TrainingSessionCodable.restore(from:phase:) in conformance HandPoseClassifierTrainingSessionDelegate(uint64_t a1, __m128 a2)
{
  return HandPoseClassifierTrainingSessionDelegate.restore(from:phase:)(a1, a2);
}

uint64_t protocol witness for TrainingSessionDelegate.train(from:) in conformance HandPoseClassifierTrainingSessionDelegate(uint64_t (*a1)(uint64_t, uint64_t, void), uint64_t a2, uint64_t a3, uint64_t a4, unsigned int a5)
{
  return a1(a3, a4, a5);
}

uint64_t lazy protocol witness table accessor for type Int and conformance Int()
{
  uint64_t result = lazy protocol witness table cache variable for type Int and conformance Int;
  if (!lazy protocol witness table cache variable for type Int and conformance Int)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for Int, &type metadata for Int);
    lazy protocol witness table cache variable for type Int and conformance Int = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type Int and conformance Int;
  if (!lazy protocol witness table cache variable for type Int and conformance Int)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for Int, &type metadata for Int);
    lazy protocol witness table cache variable for type Int and conformance Int = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type AnyColumn and conformance AnyColumn(uint64_t *a1, uint64_t a2)
{
  uint64_t result = *a1;
  if (!*a1)
  {
    uint64_t v3 = type metadata accessor for AnyColumn(255);
    uint64_t result = swift_getWitnessTable(a2, v3);
    *a1 = result;
  }
  return result;
}

uint64_t outlined assign with take of MLHandPoseClassifier.PersistentParameters?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLHandPoseClassifier.PersistentParameters?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 40))(a2, a1, v2);
  return a2;
}

uint64_t outlined destroy of MLHandPoseClassifier.DataSource(uint64_t a1, uint64_t (*a2)(void))
{
  uint64_t v2 = a2(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  return a1;
}

uint64_t static _TextUtilities.getTextLabels(from:)(void *a1, uint64_t a2)
{
  *(void *)&long long v142 = v2;
  uint64_t v124 = a1;
  int64_t v3 = *(void *)(*(void *)(type metadata accessor for String.Encoding(0) - 8) + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v115 = v110;
  uint64_t v129 = type metadata accessor for UTType(0);
  uint64_t v130 = *(void *)(v129 - 8);
  int64_t v6 = *(void *)(v130 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v119 = v110;
  int64_t v9 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  char v126 = v110;
  uint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v128 = v110;
  uint64_t v141 = type metadata accessor for URL(0);
  uint64_t v14 = *(void *)(v141 - 8);
  int64_t v15 = *(void *)(v14 + 64);
  BOOL v16 = alloca(v15);
  BOOL v17 = alloca(v15);
  v133._char object = v110;
  Swift::Int v18 = alloca(v15);
  char v19 = alloca(v15);
  uint64_t v134 = v110;
  char v20 = alloca(v15);
  unsigned __int8 v21 = alloca(v15);
  int64_t v22 = *(void *)(*(void *)(type metadata accessor for MLTextClassifier.DataSource(0) - 8) + 64);
  uint64_t v23 = alloca(v22);
  uint64_t v24 = alloca(v22);
  outlined init with copy of MLTextClassifier.DataSource(a2, (uint64_t)v110);
  uint64_t v25 = *(void (**)(unsigned char *, uint64_t, uint64_t))(v14 + 32);
  uint64_t v26 = v141;
  v25(v110, (uint64_t)v110, v141);
  uint64_t v27 = v142;
  char v28 = static _FileUtilities.getReadableSubdirectoriesOfDirectory(at:)();
  *(void *)&long long v142 = v27;
  if (v27)
  {
    (*(void (**)(unsigned char *, uint64_t))(v14 + 8))(v110, v26);
    return 0x6C6562616CLL;
  }
  uint64_t v127 = v25;
  uint64_t v143 = v14;
  uint64_t v131 = v28[2];
  uint64_t v136 = v110;
  if (v131)
  {
    uint64_t v29 = v141;
    uint64_t v30 = v143;
  }
  else
  {
    swift_bridgeObjectRelease((_BYTE)v28);
    uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<URL>);
    uint64_t v30 = v143;
    uint64_t v32 = *(unsigned __int8 *)(v143 + 80);
    uint64_t v33 = ((int)v32 + 32) & ~*(unsigned __int8 *)(v143 + 80);
    uint64_t v34 = swift_allocObject(v31, v33 + *(void *)(v143 + 72), v32 | 7);
    uint64_t v138 = (void *)v34;
    *(void *)(v34 + 16) = 1;
    *(void *)(v34 + 24) = 2;
    uint64_t v29 = v141;
    (*(void (**)(uint64_t, unsigned char *))(v30 + 16))(v34 + v33, v110);
    char v28 = v138;
    uint64_t v131 = v138[2];
    if (!v131)
    {
      char v79 = (char)v138;
      char v145 = _swiftEmptyArrayStorage;
      long long v144 = _swiftEmptyArrayStorage;
LABEL_39:
      __swift_storeEnumTagSinglePayload((uint64_t)v128, 1, 1, v29);
      char v80 = v79;
LABEL_40:
      swift_bridgeObjectRelease(v80);
      uint64_t v94 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MLUntypedColumn)>);
      uint64_t inited = swift_initStackObject(v94, v110);
      char v140 = (void (__cdecl *)(id))v110;
      *(void *)(inited + 16) = 2;
      *(void *)(inited + 24) = 4;
      *(void *)(inited + 32) = 1954047348;
      *(void *)(inited + 40) = 0xE400000000000000;
      *(void *)&long long v139 = v145;
      uint64_t v96 = alloca(24);
      uint64_t v97 = alloca(32);
      uint64_t v111 = &v139;
      uint64_t ML14_UntypedColumnC_s5Error_pTgm5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
      char v100 = v99;
      swift_bridgeObjectRelease(v139);
      char v140 = (void (__cdecl *)(id))v110;
      *(void *)(inited + 48) = ML14_UntypedColumnC_s5Error_pTgm5;
      *(unsigned char *)(inited + 56) = v100 & 1;
      *(void *)(inited + 64) = 0x6C6562616CLL;
      *(void *)(inited + 72) = 0xE500000000000000;
      *(void *)&long long v139 = v144;
      uint64_t v101 = alloca(24);
      uint64_t v102 = alloca(32);
      uint64_t v111 = &v139;
      uint64_t v103 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTgm5((void (*)(void *))closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
      LOBYTE(ML14_UntypedColumnC_s5Error_pTgm5) = v104;
      swift_bridgeObjectRelease(v139);
      *(void *)(inited + 80) = v103;
      *(unsigned char *)(inited + 88) = ML14_UntypedColumnC_s5Error_pTgm5 & 1;
      uint64_t v105 = Dictionary.init(dictionaryLiteral:)(inited, &type metadata for String, &type metadata for MLUntypedColumn, &protocol witness table for String);
      uint64_t v106 = v142;
      specialized MLDataTable.init<A>(uniqueKeysWithValues:)(v105);
      *(void *)&long long v142 = v106;
      if (!v106)
      {
        char v107 = BYTE8(v139);
        uint64_t v108 = v124;
        *uint64_t v124 = v139;
        *((unsigned char *)v108 + 8) = v107;
      }
      (*(void (**)(unsigned char *, uint64_t))(v143 + 8))(v136, v141);
      return 0x6C6562616CLL;
    }
  }
  uint64_t v123 = (*(unsigned __int8 *)(v30 + 80) + 32) & ~*(unsigned __int8 *)(v30 + 80);
  uint64_t v120 = (char *)v28 + v123;
  unint64_t v35 = 0;
  uint64_t v117 = "No data found for label '" + 0x8000000000000000;
  char v145 = _swiftEmptyArrayStorage;
  long long v144 = _swiftEmptyArrayStorage;
  uint64_t v138 = v28;
  while (1)
  {
    if (v35 >= v28[2]) {
      BUG();
    }
    uint64_t v36 = *(void (**)(unsigned char *, char *, uint64_t))(v30 + 16);
    uint64_t v125 = *(void *)(v30 + 72);
    unint64_t v118 = v35;
    uint64_t v37 = (uint64_t)v128;
    uint64_t v114 = v36;
    v36(v128, &v120[v35 * v125], v29);
    __swift_storeEnumTagSinglePayload(v37, 0, 1, v29);
    if (__swift_getEnumTagSinglePayload(v37, 1, v29) == 1)
    {
      char v80 = (char)v138;
      goto LABEL_40;
    }
    uint64_t v38 = (uint64_t)v134;
    v127(v134, v37, v29);
    v133._uint64_t countAndFlagsBits = URL.lastPathComponent.getter();
    uint64_t v137 = v39;
    uint64_t v40 = (uint64_t)v119;
    static UTType.text.getter();
    uint64_t v41 = v142;
    uint64_t v42 = static _FileUtilities.readableFiles(at:type:)(v38, v40);
    *(void *)&long long v142 = v41;
    if (v41)
    {
      (*(void (**)(uint64_t, uint64_t))(v130 + 8))(v40, v129);
      swift_bridgeObjectRelease((_BYTE)v137);
      char v81 = *(void (**)(unsigned char *, uint64_t))(v143 + 8);
      v81(v134, v29);
      swift_bridgeObjectRelease((_BYTE)v145);
      swift_bridgeObjectRelease((_BYTE)v144);
      swift_bridgeObjectRelease((_BYTE)v138);
      uint64_t v82 = v136;
      uint64_t v83 = v29;
      goto LABEL_37;
    }
    (*(void (**)(uint64_t, uint64_t))(v130 + 8))(v40, v129);
    uint64_t v43 = v42[2];
    uint64_t v30 = v143;
    uint64_t v132 = v42;
    if (v43)
    {
      uint64_t v121 = (void (__cdecl *)(id))((char *)v43 - 1);
      unint64_t v44 = (char *)v42 + v123;
      uint64_t v135 = 0;
      uint64_t v45 = 0;
      uint64_t v116 = v43;
      uint64_t v122 = v44;
      while (2)
      {
        uint64_t v46 = &v44[(void)v45 * v125];
        while (1)
        {
          if ((unint64_t)v45 >= (unint64_t)v132[2]) {
            BUG();
          }
          char v140 = v45;
          uint64_t v47 = (uint64_t)v126;
          char v112 = v46;
          uint64_t v48 = v29;
          v114(v126, v46, v29);
          __swift_storeEnumTagSinglePayload(v47, 0, 1, v29);
          if (__swift_getEnumTagSinglePayload(v47, 1, v29) == 1)
          {
            swift_bridgeObjectRelease((_BYTE)v132);
            uint64_t v30 = v143;
            if (v135) {
              goto LABEL_32;
            }
            goto LABEL_36;
          }
          char object = v133._object;
          v127((unsigned char *)v133._object, v47, v29);
          uint64_t v50 = v115;
          static String.Encoding.utf8.getter();
          uint64_t v51 = v142;
          uint64_t v53 = String.init(contentsOf:encoding:)(object, v50);
          *(void *)&long long v142 = v51;
          if (!v51) {
            break;
          }
          char v140 = (void (__cdecl *)(id))((char *)v140 + 1);
          swift_errorRelease(v142);
          *(void *)&long long v139 = 0;
          *((void *)&v139 + 1) = 0xE000000000000000;
          _StringGuts.grow(_:)(34);
          uint64_t v54 = *((void *)&v139 + 1);
          swift_bridgeObjectRelease(BYTE8(v139));
          *(void *)&long long v139 = 0xD00000000000001FLL;
          *((void *)&v139 + 1) = v117;
          v55._uint64_t countAndFlagsBits = URL.path.getter(v54);
          char v56 = (char)v55._object;
          String.append(_:)(v55);
          swift_bridgeObjectRelease(v56);
          v57._uint64_t countAndFlagsBits = 46;
          v57._char object = (void *)0xE100000000000000;
          String.append(_:)(v57);
          unsigned long long v60 = v139;
          unint64_t v59 = v60 >> 64;
          unint64_t v58 = v60;
          uint64_t v113 = v139;
          LOBYTE(v142) = static os_log_type_t.info.getter();
          uint64_t v61 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
          uint64_t v62 = swift_allocObject(v61, 64, 7);
          *(void *)(v62 + 16) = 1;
          *(void *)(v62 + 24) = 2;
          *(void *)(v62 + 56) = &type metadata for String;
          *(_OWORD *)(v62 + 32) = __PAIR128__(v59, v58);
          swift_bridgeObjectRetain(v59);
          print(_:separator:terminator:)(v62, 32, 0xE100000000000000, 10, 0xE100000000000000);
          swift_bridgeObjectRelease(v62);
          type metadata accessor for OS_os_log();
          uint64_t v63 = (void *)static OS_os_log.default.getter(0);
          uint64_t v64 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
          Swift::Bool v65 = (void *)swift_allocObject(v64, 72, 7);
          v65[2] = 1;
          v65[3] = 2;
          v65[7] = &type metadata for String;
          v65[8] = lazy protocol witness table accessor for type String and conformance String();
          void v65[4] = v113;
          uint64_t v66 = v141;
          v65[5] = v59;
          swift_bridgeObjectRetain(v59);
          os_log(_:dso:log:type:_:)("%@\n", 3, 2, &dword_0, v63, v142, v65);
          swift_bridgeObjectRelease(v59);

          swift_bridgeObjectRelease((_BYTE)v65);
          uint64_t v29 = v66;
          uint64_t v30 = v143;
          (*(void (**)(void *, uint64_t))(v143 + 8))(v133._object, v66);
          uint64_t v45 = v140;
          uint64_t v46 = &v112[v125];
          *(void *)&long long v142 = 0;
          if (v116 == v140)
          {
            *(void *)&long long v142 = 0;
            goto LABEL_31;
          }
        }
        uint64_t v67 = v52;
        if (!swift_isUniquelyReferenced_nonNull_native(v145)) {
          char v145 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v145[2] + 1, 1, (uint64_t)v145);
        }
        unint64_t v68 = v145[2];
        if (v145[3] >> 1 <= v68) {
          char v145 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v145[3] >= 2uLL, v68 + 1, 1, (uint64_t)v145);
        }
        char v69 = v145;
        v145[2] = v68 + 1;
        uint64_t v70 = 2 * v68;
        v69[v70 + 4] = v53;
        v69[v70 + 5] = v67;
        swift_bridgeObjectRetain((_BYTE)v137);
        if (!swift_isUniquelyReferenced_nonNull_native(v144)) {
          long long v144 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v144[2] + 1, 1, (uint64_t)v144);
        }
        unint64_t v71 = v144[2];
        uint64_t v72 = v133._object;
        if (v144[3] >> 1 <= v71)
        {
          char v77 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v144[3] >= 2uLL, v71 + 1, 1, (uint64_t)v144);
          uint64_t v72 = v133._object;
          long long v144 = v77;
        }
        char v73 = v140;
        uint64_t v45 = (void (__cdecl *)(id))((char *)v140 + 1);
        Swift::String v74 = v144;
        v144[2] = v71 + 1;
        uint64_t v75 = 2 * v71;
        v74[v75 + 4] = v133._countAndFlagsBits;
        v74[v75 + 5] = v137;
        uint64_t v29 = v141;
        uint64_t v30 = v143;
        uint64_t v76 = (*(uint64_t (**)(void *))(v143 + 8))(v72);
        LOBYTE(v76) = 1;
        uint64_t v135 = v76;
        unint64_t v44 = v122;
        if (v121 != v73) {
          continue;
        }
        break;
      }
    }
    else
    {
      uint64_t v135 = 0;
    }
LABEL_31:
    uint64_t v48 = v29;
    __swift_storeEnumTagSinglePayload((uint64_t)v126, 1, 1, v29);
    swift_bridgeObjectRelease((_BYTE)v132);
    if ((v135 & 1) == 0) {
      break;
    }
LABEL_32:
    unint64_t v78 = v118 + 1;
    uint64_t v29 = v48;
    (*(void (**)(unsigned char *, uint64_t))(v30 + 8))(v134, v48);
    swift_bridgeObjectRelease((_BYTE)v137);
    unint64_t v35 = v78;
    char v28 = v138;
    if (v78 == v131)
    {
      char v79 = (char)v138;
      goto LABEL_39;
    }
  }
LABEL_36:
  swift_bridgeObjectRelease((_BYTE)v145);
  swift_bridgeObjectRelease((_BYTE)v144);
  swift_bridgeObjectRelease((_BYTE)v138);
  *(void *)&long long v139 = 0;
  *((void *)&v139 + 1) = 0xE000000000000000;
  _StringGuts.grow(_:)(29);
  swift_bridgeObjectRelease(BYTE8(v139));
  *(void *)&long long v139 = 0xD000000000000019;
  *((void *)&v139 + 1) = "are not properly constructed." + 0x8000000000000000;
  v84._uint64_t countAndFlagsBits = v133._countAndFlagsBits;
  v84._char object = v137;
  String.append(_:)(v84);
  v84._char object = (void *)0xE200000000000000;
  v84._uint64_t countAndFlagsBits = 11815;
  String.append(_:)(v84);
  unint64_t v85 = *((void *)&v139 + 1);
  unint64_t v86 = v139;
  os_log_type_t v87 = static os_log_type_t.error.getter(11815, 0xE200000000000000);
  log(_:type:)((Swift::String)__PAIR128__(v85, v86), v87);
  swift_bridgeObjectRelease(v85);
  *(void *)&long long v139 = 0;
  *((void *)&v139 + 1) = 0xE000000000000000;
  _StringGuts.grow(_:)(29);
  swift_bridgeObjectRelease(BYTE8(v139));
  *(void *)&long long v139 = 0xD000000000000019;
  *((void *)&v139 + 1) = "are not properly constructed." + 0x8000000000000000;
  v84._uint64_t countAndFlagsBits = v133._countAndFlagsBits;
  LOBYTE(v85) = (_BYTE)v137;
  v84._char object = v137;
  String.append(_:)(v84);
  swift_bridgeObjectRelease(v85);
  v84._uint64_t countAndFlagsBits = 11815;
  v84._char object = (void *)0xE200000000000000;
  String.append(_:)(v84);
  long long v142 = v139;
  v84._char object = (void *)lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v88 = swift_allocError(&type metadata for MLCreateError, v84._object, 0, 0);
  *(_OWORD *)uint64_t v89 = v142;
  *(_OWORD *)(v89 + 16) = 0;
  *(_OWORD *)(v89 + 32) = 0;
  *(unsigned char *)(v89 + 48) = 0;
  *(void *)&long long v142 = v88;
  swift_willThrow(&type metadata for MLCreateError, v84._object, v89, v90, v91, v92);
  char v81 = *(void (**)(unsigned char *, uint64_t))(v143 + 8);
  uint64_t v93 = v141;
  v81(v134, v141);
  uint64_t v82 = v136;
  uint64_t v83 = v93;
LABEL_37:
  v81(v82, v83);
  return 0x6C6562616CLL;
}

void *static _TextUtilities.getTextLabeledDictionary(from:)(uint64_t a1, double a2)
{
  uint64_t v4 = static _TextUtilities.getTextLabels(from:)(&v72, a1);
  if (!v2)
  {
    v75._uint64_t countAndFlagsBits = v4;
    uint64_t v8 = (uint64_t)v72;
    char v9 = (char)v73;
    v66._char object = v7;
    v66._uint64_t countAndFlagsBits = v6;
    uint64_t v10 = v5;
    char v69 = (char)v5;
    outlined copy of Result<_DataTable, Error>((uint64_t)v72, (char)v73);
    v11._uint64_t countAndFlagsBits = v75._countAndFlagsBits;
    v11._char object = v10;
    MLDataTable.subscript.getter(v11);
    swift_bridgeObjectRelease(v69);
    outlined consume of Result<_DataTable, Error>(v8, v9);
    uint64_t v64 = (uint64_t)v72;
    LOBYTE(v75._countAndFlagsBits) = (_BYTE)v73;
    outlined copy of Result<_DataTable, Error>(v8, v9);
    MLDataTable.subscript.getter(v66);
    swift_bridgeObjectRelease(v66._object);
    uint64_t v60 = v8;
    char v62 = v9;
    LOBYTE(v11._object) = v9;
    uint64_t v12 = v64;
    outlined consume of Result<_DataTable, Error>(v8, (char)v11._object);
    if (LOBYTE(v75._countAndFlagsBits)
      || (uint64_t v63 = (uint64_t)v72,
          BYTE6(v75._object) = (_BYTE)v73,
          outlined copy of Result<_DataTable, Error>(v64, 0),
          uint64_t v13 = CMLColumn.size.getter(),
          outlined consume of Result<_DataTable, Error>(v64, 0),
          v13 < 0))
    {
      BUG();
    }
    int64_t v3 = _swiftEmptyDictionarySingleton;
    if (v13)
    {
      uint64_t v14 = 0;
      uint64_t v61 = v13;
      do
      {
        if (v13 == v14) {
          BUG();
        }
        unint64_t v68 = v3;
        outlined copy of Result<_DataTable, Error>(v12, 0);
        uint64_t v67 = v14;
        _UntypedColumn.valueAtIndex(index:)(v14, a2);
        outlined consume of Result<_DataTable, Error>(v12, 0);
        int64_t v15 = v72;
        BOOL v16 = v73;
        if (v74 != 2)
        {
          outlined consume of MLDataValue(v72, v73, v74);
          BUG();
        }
        if (v3[2] && (unint64_t v17 = specialized __RawDictionaryStorage.find<A>(_:)((uint64_t)v72, (uint64_t)v73), (v18 & 1) != 0))
        {
          v75._uint64_t countAndFlagsBits = *(void *)(v3[7] + 8 * v17);
          swift_bridgeObjectRetain(v75._countAndFlagsBits);
          outlined consume of MLDataValue(v15, v16, 2);
          swift_retain();
          _UntypedColumn.valueAtIndex(index:)(v67, a2);
          outlined consume of Result<_DataTable, Error>(v12, 0);
          uint64_t v70 = v72;
          if (v74 != 2)
          {
            outlined consume of MLDataValue(v72, v73, v74);
            BUG();
          }
          uint64_t v65 = (uint64_t)v73;
          if (BYTE6(v75._object)) {
            goto LABEL_49;
          }
          outlined copy of Result<_DataTable, Error>(v63, 0);
          _UntypedColumn.valueAtIndex(index:)(v67, a2);
          outlined consume of Result<_DataTable, Error>(v63, 0);
          char v19 = v72;
          char v20 = v73;
          if (v74 != 2)
          {
            outlined consume of MLDataValue(v72, v73, v74);
LABEL_49:
            BUG();
          }
          swift_bridgeObjectRetain((_BYTE)v73);
          if (!swift_isUniquelyReferenced_nonNull_native(v75._countAndFlagsBits)) {
            v75._uint64_t countAndFlagsBits = (uint64_t)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(void *)(v75._countAndFlagsBits + 16) + 1, 1, v75._countAndFlagsBits);
          }
          unint64_t v21 = *(void *)(v75._countAndFlagsBits + 16);
          if (*(void *)(v75._countAndFlagsBits + 24) >> 1 <= v21) {
            v75._uint64_t countAndFlagsBits = (uint64_t)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*(void *)(v75._countAndFlagsBits + 24) >= 2uLL, v21 + 1, 1, v75._countAndFlagsBits);
          }
          uint64_t countAndFlagsBits = v75._countAndFlagsBits;
          *(void *)(v75._countAndFlagsBits + 16) = v21 + 1;
          uint64_t v23 = 16 * v21;
          *(void *)(countAndFlagsBits + v23 + 32) = v19;
          *(void *)(countAndFlagsBits + v23 + 40) = v20;
          outlined consume of MLDataValue(v19, v20, 2);
          char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v68);
          uint64_t v72 = v68;
          unint64_t v25 = specialized __RawDictionaryStorage.find<A>(_:)((uint64_t)v70, v65);
          HIBYTE(v75._object) = v26;
          BOOL v27 = (v26 & 1) == 0;
          BOOL v28 = __OFADD__(v68[2], v27);
          Swift::Int v29 = v68[2] + v27;
          if (v28) {
            BUG();
          }
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [String]>);
          Swift::Bool v30 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v29);
          uint64_t v12 = v64;
          uint64_t v31 = (void *)v65;
          if (v30)
          {
            unint64_t v25 = specialized __RawDictionaryStorage.find<A>(_:)((uint64_t)v70, v65);
            if ((HIBYTE(v75._object) & 1) != (v32 & 1)) {
              goto LABEL_52;
            }
          }
          int64_t v3 = v72;
          if (HIBYTE(v75._object))
          {
            uint64_t v33 = *((void *)v72 + 7);
            swift_bridgeObjectRelease(*(void *)(v33 + 8 * v25));
            *(void *)(v33 + 8 * v25) = v75._countAndFlagsBits;
            uint64_t v31 = (void *)v65;
          }
          else
          {
            *((void *)v72 + (v25 >> 6) + 8) |= 1 << v25;
            uint64_t v55 = v3[6];
            uint64_t v56 = 16 * v25;
            *(void *)(v55 + v56) = v70;
            *(void *)(v55 + v56 + 8) = v65;
            *(void *)(v3[7] + 8 * v25) = v75._countAndFlagsBits;
            uint64_t v57 = v3[2];
            BOOL v28 = __OFADD__(1, v57);
            uint64_t v58 = v57 + 1;
            if (v28) {
              BUG();
            }
            v3[2] = v58;
            swift_bridgeObjectRetain(v65);
          }
          swift_bridgeObjectRelease(0);
          uint64_t v53 = v70;
          uint64_t v54 = v31;
        }
        else
        {
          outlined consume of MLDataValue(v15, v16, 2);
          swift_retain();
          _UntypedColumn.valueAtIndex(index:)(v67, a2);
          outlined consume of Result<_DataTable, Error>(v12, 0);
          v75._uint64_t countAndFlagsBits = (uint64_t)v72;
          uint64_t v34 = (uint64_t)v73;
          if (v74 != 2)
          {
            outlined consume of MLDataValue((void *)v75._countAndFlagsBits, v73, v74);
            BUG();
          }
          uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
          uint64_t v36 = swift_allocObject(v35, 48, 7);
          *(void *)(v36 + 16) = 1;
          *(void *)(v36 + 24) = 2;
          if (BYTE6(v75._object)) {
            goto LABEL_47;
          }
          uint64_t v37 = v36;
          outlined copy of Result<_DataTable, Error>(v63, 0);
          _UntypedColumn.valueAtIndex(index:)(v67, a2);
          outlined consume of Result<_DataTable, Error>(v63, 0);
          uint64_t v38 = v73;
          if (v74 != 2)
          {
            outlined consume of MLDataValue(v72, v73, v74);
LABEL_47:
            BUG();
          }
          *(void *)(v37 + 32) = v72;
          *(void *)(v37 + 40) = v38;
          char v39 = swift_isUniquelyReferenced_nonNull_native(v3);
          uint64_t v72 = v3;
          uint64_t v71 = v34;
          unint64_t v40 = specialized __RawDictionaryStorage.find<A>(_:)(v75._countAndFlagsBits, v34);
          HIBYTE(v75._object) = v41;
          BOOL v42 = (v41 & 1) == 0;
          BOOL v28 = __OFADD__(v68[2], v42);
          Swift::Int v43 = v68[2] + v42;
          if (v28) {
            BUG();
          }
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, [String]>);
          Swift::Bool v44 = _NativeDictionary.ensureUnique(isUnique:capacity:)(v39, v43);
          char object_high = HIBYTE(v75._object);
          if (v44)
          {
            unint64_t v40 = specialized __RawDictionaryStorage.find<A>(_:)(v75._countAndFlagsBits, v71);
            if ((object_high & 1) != (v46 & 1))
            {
LABEL_52:
              KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
              BUG();
            }
          }
          int64_t v3 = v72;
          if (object_high)
          {
            uint64_t v47 = *((void *)v72 + 7);
            swift_bridgeObjectRelease(*(void *)(v47 + 8 * v40));
            *(void *)(v47 + 8 * v40) = v37;
            uint64_t v12 = v64;
            uint64_t v48 = (void *)v71;
          }
          else
          {
            *((void *)v72 + (v40 >> 6) + 8) |= 1 << v40;
            uint64_t v49 = v3[6];
            uint64_t v50 = 16 * v40;
            *(void *)(v49 + v50) = v75._countAndFlagsBits;
            uint64_t v48 = (void *)v71;
            *(void *)(v49 + v50 + 8) = v71;
            *(void *)(v3[7] + 8 * v40) = v37;
            uint64_t v51 = v3[2];
            BOOL v28 = __OFADD__(1, v51);
            uint64_t v52 = v51 + 1;
            uint64_t v12 = v64;
            if (v28) {
              BUG();
            }
            v3[2] = v52;
            swift_bridgeObjectRetain(v71);
          }
          swift_bridgeObjectRelease(0);
          uint64_t v53 = (void *)v75._countAndFlagsBits;
          uint64_t v54 = v48;
        }
        outlined consume of MLDataValue(v53, v54, 2);
        uint64_t v13 = v61;
        uint64_t v14 = v67 + 1;
      }
      while (v61 != v67 + 1);
    }
    outlined consume of Result<_DataTable, Error>(v60, v62);
    outlined consume of Result<_DataTable, Error>(v12, 0);
    outlined consume of Result<_DataTable, Error>(v63, SBYTE6(v75._object));
  }
  return v3;
}

uint64_t static _TextUtilities.optionsDictionary(from:)(uint64_t *a1)
{
  uint64_t v1 = *a1;
  uint64_t v2 = a1[1];
  uint64_t v70 = a1[2];
  uint64_t v3 = a1[3];
  int64_t v71 = a1[4];
  uint64_t v69 = a1[5];
  uint64_t v68 = a1[6];
  uint64_t v67 = a1[7];
  uint64_t v4 = a1[8];
  uint64_t v5 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, (char *)&type metadata for Any + 8, &protocol witness table for String);
  if (!v2)
  {
    uint64_t v51 = NSFullUserName();
    uint64_t v52 = v51;
    uint64_t v53 = static String._unconditionallyBridgeFromObjectiveC(_:)(v52);
    uint64_t v55 = v54;

    char v62 = &type metadata for String;
    *(void *)&long long v61 = v53;
    *((void *)&v61 + 1) = v55;
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v5);
    uint64_t v72 = v5;
    specialized _NativeDictionary.updateValue(_:forKey:isUnique:)(&v61, 0x726F68747561, 0xE600000000000000, isUniquelyReferenced_nonNull_native);
    uint64_t v57 = v72;
    goto LABEL_35;
  }
  uint64_t v65 = v4;
  char v62 = &type metadata for String;
  *(void *)&long long v61 = v1;
  *((void *)&v61 + 1) = v2;
  swift_bridgeObjectRetain(v2);
  char v6 = swift_isUniquelyReferenced_nonNull_native(v5);
  uint64_t v72 = v5;
  specialized _NativeDictionary.updateValue(_:forKey:isUnique:)(&v61, 0x726F68747561, 0xE600000000000000, v6);
  uint64_t v7 = v72;
  swift_bridgeObjectRelease(0);
  outlined destroy of Any?((uint64_t)v63);
  char v62 = &type metadata for String;
  *(void *)&long long v61 = v70;
  *((void *)&v61 + 1) = v3;
  swift_bridgeObjectRetain(v3);
  char v8 = swift_isUniquelyReferenced_nonNull_native(v7);
  uint64_t v72 = v7;
  specialized _NativeDictionary.updateValue(_:forKey:isUnique:)(&v61, 0xD000000000000011, (uint64_t)("tted text file " + 0x8000000000000000), v8);
  uint64_t v9 = v72;
  swift_bridgeObjectRelease(0);
  outlined destroy of Any?((uint64_t)v63);
  if (v69)
  {
    char v62 = &type metadata for String;
    *(void *)&long long v61 = v71;
    *((void *)&v61 + 1) = v69;
    swift_bridgeObjectRetain(v69);
    char v10 = swift_isUniquelyReferenced_nonNull_native(v9);
    uint64_t v72 = v9;
    specialized _NativeDictionary.updateValue(_:forKey:isUnique:)(&v61, 0x65736E6563696CLL, 0xE700000000000000, v10);
    uint64_t v9 = v72;
    swift_bridgeObjectRelease(0);
    outlined destroy of Any?((uint64_t)v63);
  }
  char v62 = &type metadata for String;
  *(void *)&long long v61 = v68;
  *((void *)&v61 + 1) = v67;
  swift_bridgeObjectRetain(v67);
  char v11 = swift_isUniquelyReferenced_nonNull_native(v9);
  uint64_t v72 = v9;
  specialized _NativeDictionary.updateValue(_:forKey:isUnique:)(&v61, 0x5F6E6F6973726576, 0xEE00676E69727473, v11);
  uint64_t v66 = v72;
  swift_bridgeObjectRelease(0);
  outlined destroy of Any?((uint64_t)v63);
  uint64_t v12 = v65;
  if (!v65) {
    return v66;
  }
  swift_bridgeObjectRetain(v65);
  uint64_t v13 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for String, &protocol witness table for String);
  uint64_t v14 = 1 << *(unsigned char *)(v12 + 32);
  int64_t v15 = (void *)v13;
  uint64_t v16 = ~(-1 << v14);
  if (v14 >= 64) {
    uint64_t v16 = -1;
  }
  unint64_t v17 = *(void *)(v12 + 64) & v16;
  int64_t v73 = (unint64_t)(v14 + 63) >> 6;
  int64_t v18 = 0;
  while (1)
  {
    if (v17)
    {
      _BitScanForward64(&v19, v17);
      uint64_t v64 = (v17 - 1) & v17;
      unint64_t v20 = v19 | (v18 << 6);
      int64_t v71 = v18;
      goto LABEL_19;
    }
    BOOL v21 = __OFADD__(1, v18);
    int64_t v22 = v18 + 1;
    if (v21) {
      BUG();
    }
    if (v22 >= v73) {
      break;
    }
    unint64_t i = *(void *)(v12 + 8 * v22 + 64);
    if (i)
    {
      int64_t v24 = v22;
    }
    else
    {
      int64_t v24 = v22 + 1;
      if (v22 + 1 >= v73) {
        break;
      }
      unint64_t i = *(void *)(v12 + 8 * v22 + 72);
      if (!i)
      {
        int64_t v24 = v22 + 2;
        if (v22 + 2 >= v73) {
          break;
        }
        unint64_t i = *(void *)(v12 + 8 * v22 + 80);
        if (!i)
        {
          int64_t v24 = v22 + 3;
          if (v22 + 3 >= v73) {
            break;
          }
          for (unint64_t i = *(void *)(v12 + 8 * v22 + 88); !i; unint64_t i = *(void *)(v12 + 8 * v24 + 64))
          {
            BOOL v21 = __OFADD__(1, v24++);
            if (v21) {
              BUG();
            }
            if (v24 >= v73) {
              goto LABEL_34;
            }
          }
        }
      }
    }
    _BitScanForward64(&v25, i);
    uint64_t v64 = i & (i - 1);
    int64_t v71 = v24;
    unint64_t v20 = v25 + (v24 << 6);
LABEL_19:
    uint64_t v26 = 16 * v20;
    uint64_t v27 = *(void *)(v12 + 48);
    uint64_t v28 = *(void *)(v12 + 56);
    uint64_t v29 = *(void *)(v27 + v26);
    uint64_t v30 = *(void *)(v27 + v26 + 8);
    uint64_t v69 = *(void *)(v28 + v26);
    uint64_t v31 = *(void *)(v28 + v26 + 8);
    swift_bridgeObjectRetain(v30);
    uint64_t v68 = v31;
    swift_bridgeObjectRetain(v31);
    char v32 = swift_isUniquelyReferenced_nonNull_native(v15);
    v63[0] = v15;
    uint64_t v70 = v29;
    uint64_t v33 = v29;
    uint64_t v67 = v30;
    uint64_t v34 = v15;
    unint64_t v36 = specialized __RawDictionaryStorage.find<A>(_:)(v33, v30);
    BOOL v37 = (v35 & 1) == 0;
    BOOL v21 = __OFADD__(v34[2], v37);
    Swift::Int v38 = v34[2] + v37;
    if (v21) {
      BUG();
    }
    char v39 = v35;
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, String>);
    Swift::Bool v40 = _NativeDictionary.ensureUnique(isUnique:capacity:)(v32, v38);
    uint64_t v41 = v67;
    if (v40)
    {
      unint64_t v36 = specialized __RawDictionaryStorage.find<A>(_:)(v70, v67);
      if ((v39 & 1) != (v42 & 1))
      {
        KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
        BUG();
      }
    }
    int64_t v15 = (void *)v63[0];
    if (v39)
    {
      uint64_t v43 = *(void *)(v63[0] + 56);
      uint64_t v44 = 16 * v36;
      uint64_t v45 = *(void *)(v43 + v44 + 8);
      *(void *)(v43 + v44) = v69;
      *(void *)(v43 + v44 + 8) = v68;
    }
    else
    {
      *(void *)(v63[0] + 8 * (v36 >> 6) + 64) |= 1 << v36;
      uint64_t v46 = v15[6];
      uint64_t v47 = 16 * v36;
      *(void *)(v46 + v47) = v70;
      *(void *)(v46 + v47 + 8) = v41;
      uint64_t v48 = v15[7];
      *(void *)(v48 + v47) = v69;
      *(void *)(v48 + v47 + 8) = v68;
      uint64_t v49 = v15[2];
      BOOL v21 = __OFADD__(1, v49);
      uint64_t v50 = v49 + 1;
      if (v21) {
        BUG();
      }
      v15[2] = v50;
      swift_bridgeObjectRetain(v41);
      LOBYTE(v45) = 0;
    }
    swift_bridgeObjectRelease(v41);
    swift_bridgeObjectRelease(v45);
    swift_bridgeObjectRelease(0);
    int64_t v18 = v71;
    uint64_t v12 = v65;
    unint64_t v17 = v64;
  }
LABEL_34:
  swift_release();
  char v62 = (void *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String : String]);
  *(void *)&long long v61 = v15;
  uint64_t v58 = v66;
  char v59 = swift_isUniquelyReferenced_nonNull_native(v66);
  uint64_t v72 = v58;
  specialized _NativeDictionary.updateValue(_:forKey:isUnique:)(&v61, 0x6665645F72657375, 0xEC00000064656E69, v59);
  uint64_t v57 = v72;
LABEL_35:
  swift_bridgeObjectRelease(0);
  outlined destroy of Any?((uint64_t)v63);
  return v57;
}

uint64_t outlined init with copy of MLTextClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLTextClassifier.DataSource(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

_OWORD *specialized _NativeDictionary.updateValue(_:forKey:isUnique:)(long long *a1, uint64_t a2, uint64_t a3, Swift::Bool a4)
{
  char v6 = (void **)v5;
  int64_t v18 = v4;
  uint64_t v7 = (void *)*v5;
  unint64_t v9 = specialized __RawDictionaryStorage.find<A>(_:)(a2, a3);
  BOOL v10 = (v8 & 1) == 0;
  BOOL v11 = __OFADD__(v7[2], v10);
  Swift::Int v12 = v7[2] + v10;
  if (v11) {
    BUG();
  }
  char v13 = v8;
  __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, Any>);
  if (_NativeDictionary.ensureUnique(isUnique:capacity:)(a4, v12))
  {
    unint64_t v9 = specialized __RawDictionaryStorage.find<A>(_:)(a2, a3);
    if ((v13 & 1) != (v14 & 1))
    {
      KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for String);
      BUG();
    }
  }
  int64_t v15 = *v6;
  if (v13)
  {
    uint64_t v16 = 32 * v9;
    outlined init with take of Any((long long *)(v16 + v15[7]), v18);
    return outlined init with take of Any(a1, (_OWORD *)(v15[7] + v16));
  }
  else
  {
    specialized _NativeDictionary._insert(at:key:value:)(v9, a2, a3, a1, v15);
    v18[1] = 0;
    *int64_t v18 = 0;
    return (_OWORD *)swift_bridgeObjectRetain(a3);
  }
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML23MLBoostedTreeClassifierV15ModelParametersV010ValidationD0OTg503_s8g4ML23ijk3V15lm75V13configuration10validationAE0A12MLComponents07BoostedD13ConfigurationV_11c7Data0N5e12VSgtcfcAE010N21N0OAMcAPmcfu_ApMcfu0_AOXMtTf1ncn_n(uint64_t a1)
{
  uint64_t v21 = v1;
  uint64_t v2 = type metadata accessor for DataFrame(0);
  uint64_t v18 = *(void *)(v2 - 8);
  int64_t v3 = *(void *)(v18 + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  unint64_t v19 = &v17;
  int64_t v6 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                             - 8)
                 + 64);
  uint64_t v7 = alloca(v6);
  char v8 = alloca(v6);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, (uint64_t)&v17, &demangling cache variable for type metadata for DataFrame?);
  if (__swift_getEnumTagSinglePayload((uint64_t)&v17, 1, v2) == 1)
  {
    uint64_t v9 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
    uint64_t v10 = v21;
    uint64_t v11 = 1;
    uint64_t v12 = v9;
  }
  else
  {
    char v13 = v19;
    uint64_t v14 = v18;
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v18 + 32))(v19, &v17, v2);
    uint64_t v15 = v21;
    (*(void (**)(uint64_t, uint64_t *, uint64_t))(v14 + 16))(v21, v13, v2);
    uint64_t v20 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
    swift_storeEnumTagMultiPayload(v15, v20, 2);
    (*(void (**)(uint64_t *, uint64_t))(v14 + 8))(v13, v2);
    uint64_t v10 = v15;
    uint64_t v11 = 0;
    uint64_t v12 = v20;
  }
  return __swift_storeEnumTagSinglePayload(v10, v11, 1, v12);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.validationData.getter(__m128 a1)
{
  uint64_t v2 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
  int64_t v3 = *(void *)(*(void *)(v2 - 8) + 64);
  uint64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, (uint64_t)&v9, &demangling cache variable for type metadata for Any?);
  if (!v10) {
    BUG();
  }
  outlined init with take of Any(&v9, v8);
  swift_dynamicCast(&v7, v8, (char *)&type metadata for Any + 8, v2, 7);
  MLBoostedTreeClassifier.ModelParameters.ValidationData.asTable()(a1);
  return outlined destroy of MLBoostedTreeClassifier.ModelParameters.ValidationData((uint64_t)&v7);
}

uint64_t key path getter for MLBoostedTreeClassifier.ModelParameters.validationData : MLBoostedTreeClassifier.ModelParameters(__m128 a1)
{
  uint64_t v2 = v1;
  MLBoostedTreeClassifier.ModelParameters.validationData.getter(a1);
  uint64_t result = v4;
  *(void *)uint64_t v2 = v4;
  *(unsigned char *)(v2 + 8) = v5;
  return result;
}

uint64_t key path setter for MLBoostedTreeClassifier.ModelParameters.validationData : MLBoostedTreeClassifier.ModelParameters(uint64_t a1)
{
  int v1 = *(_DWORD *)(a1 + 8);
  uint64_t v3 = *(void *)a1;
  char v4 = v1;
  outlined copy of MLDataTable?(v3, v1);
  return MLBoostedTreeClassifier.ModelParameters.validationData.setter((uint64_t)&v3);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.validationData.setter(uint64_t a1)
{
  uint64_t v20 = v1;
  unsigned int v2 = 0;
  uint64_t v3 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
  int64_t v4 = *(void *)(*(void *)(v3 - 8) + 64);
  char v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  uint64_t v19 = *(void *)a1;
  char v7 = *(unsigned char *)(a1 + 8);
  uint64_t v15 = v3;
  char v8 = __swift_allocate_boxed_opaque_existential_1(&v13);
  uint64_t v9 = (uint64_t)v8;
  if (v7 == -1)
  {
    long long v13 = 0;
    __int16 v14 = 256;
    uint64_t v10 = v20;
  }
  else
  {
    uint64_t v18 = v8;
    uint64_t v16 = v19;
    char v17 = v7 & 1;
    if (MLDataTable.size.getter())
    {
      *(void *)&long long v13 = v19;
      BYTE8(v13) = v7 & 1;
      int v12 = 1;
    }
    else
    {
      outlined consume of MLDataTable?(v19, v7);
      int v12 = 3;
    }
    unsigned int v2 = v12;
    uint64_t v10 = v20;
    uint64_t v9 = (uint64_t)v18;
  }
  swift_storeEnumTagMultiPayload(&v13, v3, v2);
  outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData((uint64_t)&v13, v9);
  return outlined assign with take of Any?((uint64_t)&v13, v10);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.validation.getter()
{
  uint64_t v2 = v0;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, (uint64_t)&v6, &demangling cache variable for type metadata for Any?);
  if (!v7) {
    BUG();
  }
  outlined init with take of Any(&v6, v5);
  uint64_t v3 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
  return swift_dynamicCast(v2, v5, (char *)&type metadata for Any + 8, v3, 7);
}

uint64_t outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t (*MLBoostedTreeClassifier.ModelParameters.validationData.modify(uint64_t a1, __m128 a2))(uint64_t a1, char a2)
{
  *(void *)(a1 + 16) = v2;
  MLBoostedTreeClassifier.ModelParameters.validationData.getter(a2);
  return MLBoostedTreeClassifier.ModelParameters.validationData.modify;
}

uint64_t MLBoostedTreeClassifier.ModelParameters.validationData.modify(uint64_t a1, char a2)
{
  uint64_t v2 = *(void *)a1;
  char v3 = *(unsigned char *)(a1 + 8);
  uint64_t v6 = *(void *)a1;
  char v7 = v3;
  if ((a2 & 1) == 0) {
    return MLBoostedTreeClassifier.ModelParameters.validationData.setter((uint64_t)&v6);
  }
  char v4 = v3;
  outlined copy of MLDataTable?(v2, v3);
  MLBoostedTreeClassifier.ModelParameters.validationData.setter((uint64_t)&v6);
  return outlined consume of MLDataTable?(v2, v4);
}

uint64_t key path setter for MLBoostedTreeClassifier.ModelParameters.validation : MLBoostedTreeClassifier.ModelParameters(uint64_t a1)
{
  v6[0] = v1;
  int64_t v2 = *(void *)(*(void *)(type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0) - 8)
                 + 64);
  char v3 = alloca(v2);
  char v4 = alloca(v2);
  outlined init with copy of MLBoostedTreeClassifier.ModelParameters.ValidationData(a1, (uint64_t)v6);
  return MLBoostedTreeClassifier.ModelParameters.validation.setter((uint64_t)v6);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.validation.setter(uint64_t a1)
{
  v4[3] = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v4);
  outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData(a1, (uint64_t)boxed_opaque_existential_1);
  return outlined assign with take of Any?((uint64_t)v4, v1);
}

void (*MLBoostedTreeClassifier.ModelParameters.validation.modify(void *a1))(uint64_t a1, char a2)
{
  int64_t v2 = malloc(0xA0uLL);
  *a1 = v2;
  *((void *)v2 + 16) = v1;
  uint64_t v3 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
  *((void *)v2 + 17) = v3;
  size_t v4 = *(void *)(*(void *)(v3 - 8) + 64);
  *((void *)v2 + 18) = malloc(v4);
  char v5 = malloc(v4);
  *((void *)v2 + 19) = v5;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v1, (uint64_t)(v2 + 2), &demangling cache variable for type metadata for Any?);
  if (!*((void *)v2 + 7)) {
    BUG();
  }
  outlined init with take of Any(v2 + 2, v2);
  swift_dynamicCast(v5, v2, (char *)&type metadata for Any + 8, v3, 7);
  return MLBoostedTreeClassifier.ModelParameters.validation.modify;
}

void MLBoostedTreeClassifier.ModelParameters.validation.modify(uint64_t a1, char a2)
{
  int64_t v2 = *(void **)a1;
  uint64_t v3 = *(void **)(*(void *)a1 + 152);
  size_t v4 = *(void **)(*(void *)a1 + 144);
  uint64_t v8 = *(void *)(*(void *)a1 + 128);
  uint64_t v5 = *(void *)(*(void *)a1 + 136);
  if (a2)
  {
    outlined init with copy of MLBoostedTreeClassifier.ModelParameters.ValidationData((uint64_t)v3, (uint64_t)v4);
    v2[11] = v5;
    boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v2 + 8);
    outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData((uint64_t)v4, (uint64_t)boxed_opaque_existential_1);
    outlined assign with take of Any?((uint64_t)(v2 + 8), v8);
    outlined destroy of MLBoostedTreeClassifier.ModelParameters.ValidationData((uint64_t)v3);
  }
  else
  {
    v2[15] = v5;
    char v7 = __swift_allocate_boxed_opaque_existential_1(v2 + 12);
    outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData((uint64_t)v3, (uint64_t)v7);
    outlined assign with take of Any?((uint64_t)(v2 + 12), v8);
  }
  free(v3);
  free(v4);
  free(v2);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.maxDepth.getter()
{
  return *(void *)(v0 + 32);
}

void MLBoostedTreeClassifier.ModelParameters.maxDepth.setter(uint64_t a1)
{
  *(void *)(v1 + 32) = a1;
}

void (*MLBoostedTreeClassifier.ModelParameters.maxDepth.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLBoostedTreeClassifier.ModelParameters.maxIterations.getter()
{
  return *(void *)(v0 + 40);
}

void MLBoostedTreeClassifier.ModelParameters.maxIterations.setter(uint64_t a1)
{
  *(void *)(v1 + 40) = a1;
}

void (*MLBoostedTreeClassifier.ModelParameters.maxIterations.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLBoostedTreeClassifier.ModelParameters.minLossReduction.getter()
{
  return *(double *)(v0 + 48);
}

void MLBoostedTreeClassifier.ModelParameters.minLossReduction.setter(double a1)
{
  *(double *)(v1 + 48) = a1;
}

void (*MLBoostedTreeClassifier.ModelParameters.minLossReduction.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLBoostedTreeClassifier.ModelParameters.minChildWeight.getter()
{
  return *(double *)(v0 + 56);
}

void MLBoostedTreeClassifier.ModelParameters.minChildWeight.setter(double a1)
{
  *(double *)(v1 + 56) = a1;
}

void (*MLBoostedTreeClassifier.ModelParameters.minChildWeight.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLBoostedTreeClassifier.ModelParameters.randomSeed.getter()
{
  return *(void *)(v0 + 64);
}

void MLBoostedTreeClassifier.ModelParameters.randomSeed.setter(uint64_t a1)
{
  *(void *)(v1 + 64) = a1;
}

void (*MLBoostedTreeClassifier.ModelParameters.randomSeed.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLBoostedTreeClassifier.ModelParameters.stepSize.getter()
{
  return *(double *)(v0 + 72);
}

void MLBoostedTreeClassifier.ModelParameters.stepSize.setter(double a1)
{
  *(double *)(v1 + 72) = a1;
}

void (*MLBoostedTreeClassifier.ModelParameters.stepSize.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLBoostedTreeClassifier.ModelParameters.earlyStoppingRounds.getter()
{
  return *(void *)(v0 + 80);
}

void MLBoostedTreeClassifier.ModelParameters.earlyStoppingRounds.setter(uint64_t a1, char a2)
{
  *(void *)(v2 + 80) = a1;
  *(unsigned char *)(v2 + 88) = a2 & 1;
}

void (*MLBoostedTreeClassifier.ModelParameters.earlyStoppingRounds.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLBoostedTreeClassifier.ModelParameters.rowSubsample.getter()
{
  return *(double *)(v0 + 96);
}

void MLBoostedTreeClassifier.ModelParameters.rowSubsample.setter(double a1)
{
  *(double *)(v1 + 96) = a1;
}

void (*MLBoostedTreeClassifier.ModelParameters.rowSubsample.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

double MLBoostedTreeClassifier.ModelParameters.columnSubsample.getter()
{
  return *(double *)(v0 + 104);
}

void MLBoostedTreeClassifier.ModelParameters.columnSubsample.setter(double a1)
{
  *(double *)(v1 + 104) = a1;
}

void (*MLBoostedTreeClassifier.ModelParameters.columnSubsample.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLBoostedTreeClassifier.ModelParameters.init(validation:maxDepth:maxIterations:minLossReduction:minChildWeight:randomSeed:stepSize:earlyStoppingRounds:rowSubsample:columnSubsample:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, char a6, double a7, double a8, double a9, double a10, double a11)
{
  uint64_t v23 = a4;
  uint64_t v26 = a3;
  uint64_t v12 = v11;
  double v22 = a11;
  double v24 = a10;
  uint64_t v27 = a5;
  double v28 = a9;
  double v29 = a8;
  double v30 = a7;
  uint64_t v25 = a1;
  uint64_t v14 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
  int64_t v15 = *(void *)(*(void *)(v14 - 8) + 64);
  uint64_t v16 = alloca(v15);
  char v17 = alloca(v15);
  *(_OWORD *)(v12 + 16) = 0;
  *(_OWORD *)uint64_t v12 = 0;
  *(void *)(v12 + 32) = a2;
  *(void *)(v12 + 40) = v26;
  *(double *)(v12 + 48) = v30;
  *(double *)(v12 + 56) = v29;
  *(void *)(v12 + 64) = v23;
  *(double *)(v12 + 72) = v28;
  *(void *)(v12 + 80) = v27;
  *(unsigned char *)(v12 + 88) = a6 & 1;
  *(double *)(v12 + 96) = v24;
  *(double *)(v12 + 104) = v22;
  uint64_t v18 = v25;
  outlined init with copy of MLBoostedTreeClassifier.ModelParameters.ValidationData(v25, (uint64_t)v21);
  v21[3] = v14;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v21);
  outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData((uint64_t)v21, (uint64_t)boxed_opaque_existential_1);
  outlined assign with take of Any?((uint64_t)v21, v12);
  return outlined destroy of MLBoostedTreeClassifier.ModelParameters.ValidationData(v18);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.init(validationData:maxDepth:maxIterations:minLossReduction:minChildWeight:randomSeed:stepSize:earlyStoppingRounds:rowSubsample:columnSubsample:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, char a6, double a7, double a8, double a9, double a10, double a11)
{
  uint64_t v12 = *a1;
  char v13 = *((unsigned char *)a1 + 8);
  *(_OWORD *)(v11 + 16) = 0;
  *(_OWORD *)uint64_t v11 = 0;
  *(void *)(v11 + 32) = a2;
  *(void *)(v11 + 40) = a3;
  *(double *)(v11 + 48) = a7;
  *(double *)(v11 + 56) = a8;
  *(void *)(v11 + 64) = a4;
  *(double *)(v11 + 72) = a9;
  *(void *)(v11 + 80) = a5;
  *(unsigned char *)(v11 + 88) = a6 & 1;
  *(double *)(v11 + 96) = a10;
  *(double *)(v11 + 104) = a11;
  uint64_t v15 = v12;
  char v16 = v13;
  return MLBoostedTreeClassifier.ModelParameters.validationData.setter((uint64_t)&v15);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.init(configuration:validation:)(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLBoostedTreeClassifier.ModelParameters.ValidationData?)
                             - 8)
                 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v7 = type metadata accessor for MLBoostedTreeClassifier.ModelParameters.ValidationData(0);
  int64_t v8 = *(void *)(*(void *)(v7 - 8) + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v19 = v16;
  *(_OWORD *)(v3 + 16) = 0;
  *(_OWORD *)uint64_t v3 = 0;
  *(void *)(v3 + 32) = BoostedTreeConfiguration.maximumDepth.getter();
  *(void *)(v3 + 40) = BoostedTreeConfiguration.maximumIterations.getter();
  *(double *)(v3 + 48) = BoostedTreeConfiguration.minimumLossReduction.getter();
  *(double *)(v3 + 56) = BoostedTreeConfiguration.minimumChildWeight.getter();
  *(void *)(v3 + 64) = BoostedTreeConfiguration.randomSeed.getter();
  *(double *)(v3 + 72) = BoostedTreeConfiguration.learningRate.getter();
  *(void *)(v3 + 80) = BoostedTreeConfiguration.earlyStoppingIterationCount.getter();
  *(unsigned char *)(v3 + 88) = v11 & 1;
  *(double *)(v3 + 96) = BoostedTreeConfiguration.rowSubsample.getter();
  *(double *)(v3 + 104) = BoostedTreeConfiguration.columnSubsample.getter();
  uint64_t v18 = a2;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lF11TabularData0D5FrameV_s5NeverO8CreateML23MLBoostedTreeClassifierV15ModelParametersV010ValidationD0OTg503_s8g4ML23ijk3V15lm75V13configuration10validationAE0A12MLComponents07BoostedD13ConfigurationV_11c7Data0N5e12VSgtcfcAE010N21N0OAMcAPmcfu_ApMcfu0_AOXMtTf1ncn_n(a2);
  if (__swift_getEnumTagSinglePayload((uint64_t)v16, 1, v7) == 1)
  {
    uint64_t v12 = (uint64_t)v19;
    swift_storeEnumTagMultiPayload(v19, v7, 3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v16, &demangling cache variable for type metadata for MLBoostedTreeClassifier.ModelParameters.ValidationData?);
  }
  else
  {
    uint64_t v12 = (uint64_t)v19;
    outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData((uint64_t)v16, (uint64_t)v19);
  }
  v17[3] = v7;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v17);
  outlined init with take of MLBoostedTreeClassifier.ModelParameters.ValidationData(v12, (uint64_t)boxed_opaque_existential_1);
  outlined assign with take of Any?((uint64_t)v17, v3);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for DataFrame?);
  uint64_t v14 = type metadata accessor for BoostedTreeConfiguration(0);
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v14 - 8) + 8))(a1, v14);
}

uint64_t MLBoostedTreeClassifier.ModelParameters.description.getter()
{
  v0._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  char object = v0._object;
  String.append(_:)(v0);
  swift_bridgeObjectRelease(object);
  v2._char object = (void *)0xE100000000000000;
  v2._uint64_t countAndFlagsBits = 10;
  String.append(_:)(v2);
  _StringGuts.grow(_:)(19);
  swift_bridgeObjectRelease(0xE000000000000000);
  v3._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  int64_t v4 = v3._object;
  String.append(_:)(v3);
  swift_bridgeObjectRelease(v4);
  v2._uint64_t countAndFlagsBits = 10;
  v2._char object = (void *)0xE100000000000000;
  String.append(_:)(v2);
  v2._uint64_t countAndFlagsBits = 0xD000000000000010;
  v2._char object = "ansformer have different types." + 0x8000000000000000;
  String.append(_:)(v2);
  swift_bridgeObjectRelease("ansformer have different types." + 0x8000000000000000);
  v14._uint64_t countAndFlagsBits = 0;
  v14._char object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(23);
  v2._uint64_t countAndFlagsBits = 0xD000000000000014;
  v2._char object = "Max Iterations: " + 0x8000000000000000;
  String.append(_:)(v2);
  Double.write<A>(to:)(&v14, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v2._uint64_t countAndFlagsBits = 10;
  v2._char object = (void *)0xE100000000000000;
  String.append(_:)(v2);
  uint64_t v5 = v14._object;
  String.append(_:)(v14);
  swift_bridgeObjectRelease(v5);
  v14._uint64_t countAndFlagsBits = 0;
  v14._char object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(21);
  v2._char object = "Min Loss Reduction: " + 0x8000000000000000;
  v2._uint64_t countAndFlagsBits = 0xD000000000000012;
  String.append(_:)(v2);
  Double.write<A>(to:)(&v14, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v2._uint64_t countAndFlagsBits = 10;
  v2._char object = (void *)0xE100000000000000;
  String.append(_:)(v2);
  uint64_t v6 = v14._object;
  String.append(_:)(v14);
  swift_bridgeObjectRelease(v6);
  v14._uint64_t countAndFlagsBits = 0;
  v14._char object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(16);
  swift_bridgeObjectRelease(v14._object);
  strcpy((char *)&v14, "Random Seed: ");
  HIWORD(v14._object) = -4864;
  v7._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  int64_t v8 = v7._object;
  String.append(_:)(v7);
  swift_bridgeObjectRelease(v8);
  v2._uint64_t countAndFlagsBits = 10;
  v2._char object = (void *)0xE100000000000000;
  String.append(_:)(v2);
  uint64_t v9 = v14._object;
  String.append(_:)(v14);
  swift_bridgeObjectRelease(v9);
  v14._uint64_t countAndFlagsBits = 0;
  v14._char object = (void *)0xE000000000000000;
  v2._uint64_t countAndFlagsBits = 0x7A69532070657453;
  v2._char object = (void *)0xEB00000000203A65;
  String.append(_:)(v2);
  Double.write<A>(to:)(&v14, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v2._uint64_t countAndFlagsBits = 10;
  v2._char object = (void *)0xE100000000000000;
  String.append(_:)(v2);
  uint64_t v10 = v14._object;
  String.append(_:)(v14);
  swift_bridgeObjectRelease(v10);
  v14._uint64_t countAndFlagsBits = 0;
  v14._char object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(18);
  v2._uint64_t countAndFlagsBits = 0x7362755320776F52;
  v2._char object = (void *)0xEF203A656C706D61;
  String.append(_:)(v2);
  Double.write<A>(to:)(&v14, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v2._uint64_t countAndFlagsBits = 10;
  v2._char object = (void *)0xE100000000000000;
  String.append(_:)(v2);
  char v11 = v14._object;
  String.append(_:)(v14);
  swift_bridgeObjectRelease(v11);
  v14._uint64_t countAndFlagsBits = 0;
  v14._char object = (void *)0xE000000000000000;
  _StringGuts.grow(_:)(21);
  v2._char object = "Min Child Weight: " + 0x8000000000000000;
  v2._uint64_t countAndFlagsBits = 0xD000000000000012;
  String.append(_:)(v2);
  Double.write<A>(to:)(&v14, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
  v2._uint64_t countAndFlagsBits = 10;
  v2._char object = (void *)0xE100000000000000;
  String.append(_:)(v2);
  uint64_t v12 = v14._object;
  String.append(_:)(v14);
  swift_bridgeObjectRelease(v12);
  return 0x747065442078614DLL;
}

uint64_t MLBoostedTreeClassifier.ModelParameters.debugDescription.getter()
{
  return MLBoostedTreeClassifier.ModelParameters.description.getter();
}

uint64_t MLBoostedTreeClassifier.ModelParameters.playgroundDescription.getter()
{
  uint64_t v1 = v0;
  uint64_t result = MLBoostedTreeClassifier.ModelParameters.description.getter();
  v1[3] = (uint64_t)&type metadata for String;
  *uint64_t v1 = result;
  v1[1] = v3;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLBoostedTreeClassifier.ModelParameters()
{
  return MLBoostedTreeClassifier.ModelParameters.description.getter();
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLBoostedTreeClassifier.ModelParameters()
{
  return MLBoostedTreeClassifier.ModelParameters.debugDescription.getter();
}

uint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLBoostedTreeClassifier.ModelParameters()
{
  return MLBoostedTreeClassifier.ModelParameters.playgroundDescription.getter();
}

uint64_t sub_1326EB(__m128 a1)
{
  return key path getter for MLBoostedTreeClassifier.ModelParameters.validationData : MLBoostedTreeClassifier.ModelParameters(a1);
}

uint64_t sub_1326F5(uint64_t a1)
{
  return key path setter for MLBoostedTreeClassifier.ModelParameters.validationData : MLBoostedTreeClassifier.ModelParameters(a1);
}

uint64_t sub_1326FF(uint64_t a1)
{
  return MLBoostedTreeClassifier.ModelParameters.validation.getter(a1);
}

uint64_t sub_132716(uint64_t a1)
{
  return key path setter for MLBoostedTreeClassifier.ModelParameters.validation : MLBoostedTreeClassifier.ModelParameters(a1);
}

ValueMetadata *type metadata accessor for MLBoostedTreeClassifier.ModelParameters()
{
  return &type metadata for MLBoostedTreeClassifier.ModelParameters;
}

uint64_t type metadata completion function for RecommendationMetrics(uint64_t a1)
{
  uint64_t v1 = swift_checkMetadataState(319, *(void *)(a1 + 16));
  uint64_t v2 = v1;
  if (v3 <= 0x3F)
  {
    v5[0] = *(void *)(v1 - 8) + 64;
    v5[1] = (char *)&value witness table for Builtin.Int64 + 64;
    _OWORD v5[2] = (char *)&value witness table for Builtin.Int64 + 64;
    void v5[3] = (char *)&value witness table for Builtin.Int64 + 64;
    void v5[4] = (char *)&value witness table for Builtin.Int64 + 64;
    uint64_t v2 = 0;
    swift_initStructMetadata(a1, 0, 5, v5, a1 + 24);
  }
  return v2;
}

uint64_t *initializeBufferWithCopyOfBuffer for RecommendationMetrics(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  unint64_t v3 = a1;
  uint64_t v4 = *(void *)(*(void *)(a3 + 16) - 8);
  int v5 = *(_DWORD *)(v4 + 80);
  if ((v5 & 0x1000F8) != 0
    || (uint64_t v6 = *(void *)(v4 + 64),
        ((((((((v6 + 7) & 0xFFFFFFFFFFFFFFF8) + 15) & 0xFFFFFFFFFFFFFFF8) + 15) & 0xFFFFFFFFFFFFFFF8) + 15) & 0xFFFFFFFFFFFFFFF8)
      + 8 > 0x18))
  {
    uint64_t v13 = *a2;
    *unint64_t v3 = *a2;
    uint64_t v14 = v13 + (((v5 | 7) + 16) & ~(v5 | 7u));
    swift_retain(v13);
    return (uint64_t *)v14;
  }
  else
  {
    (*(void (**)(uint64_t *, uint64_t *))(v4 + 16))(a1, a2);
    Swift::String v7 = (void *)(((unint64_t)a1 + v6 + 7) & 0xFFFFFFFFFFFFFFF8);
    int64_t v8 = (void *)(((unint64_t)a2 + v6 + 7) & 0xFFFFFFFFFFFFFFF8);
    void *v7 = *v8;
    uint64_t v9 = (void *)(((unint64_t)v7 + 15) & 0xFFFFFFFFFFFFFFF8);
    uint64_t v10 = (void *)(((unint64_t)v8 + 15) & 0xFFFFFFFFFFFFFFF8);
    *uint64_t v9 = *v10;
    char v11 = (void *)(((unint64_t)v9 + 15) & 0xFFFFFFFFFFFFFFF8);
    uint64_t v12 = (void *)(((unint64_t)v10 + 15) & 0xFFFFFFFFFFFFFFF8);
    void *v11 = *v12;
    *(void *)(((unint64_t)v11 + 15) & 0xFFFFFFFFFFFFFFF8) = *(void *)(((unint64_t)v12 + 15) & 0xFFFFFFFFFFFFFFF8);
  }
  return v3;
}

uint64_t destroy for RecommendationMetrics(uint64_t a1, uint64_t a2)
{
  return (*(uint64_t (**)(void))(*(void *)(*(void *)(a2 + 16) - 8) + 8))();
}

uint64_t initializeWithCopy for RecommendationMetrics(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(*(void *)(a3 + 16) - 8);
  (*(void (**)(uint64_t))(v3 + 16))(a1);
  uint64_t v4 = *(void *)(v3 + 64);
  int v5 = (void *)((v4 + a1 + 7) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v6 = (void *)((a2 + v4 + 7) & 0xFFFFFFFFFFFFFFF8);
  void *v5 = *v6;
  Swift::String v7 = (void *)(((unint64_t)v5 + 15) & 0xFFFFFFFFFFFFFFF8);
  int64_t v8 = (void *)(((unint64_t)v6 + 15) & 0xFFFFFFFFFFFFFFF8);
  void *v7 = *v8;
  uint64_t v9 = (void *)(((unint64_t)v7 + 15) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v10 = (void *)(((unint64_t)v8 + 15) & 0xFFFFFFFFFFFFFFF8);
  *uint64_t v9 = *v10;
  *(void *)(((unint64_t)v9 + 15) & 0xFFFFFFFFFFFFFFF8) = *(void *)(((unint64_t)v10 + 15) & 0xFFFFFFFFFFFFFFF8);
  return a1;
}

uint64_t assignWithCopy for RecommendationMetrics(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(*(void *)(a3 + 16) - 8);
  (*(void (**)(uint64_t))(v3 + 24))(a1);
  uint64_t v4 = *(void *)(v3 + 64);
  int v5 = (void *)((v4 + a1 + 7) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v6 = (void *)((a2 + v4 + 7) & 0xFFFFFFFFFFFFFFF8);
  void *v5 = *v6;
  Swift::String v7 = (void *)(((unint64_t)v5 + 15) & 0xFFFFFFFFFFFFFFF8);
  int64_t v8 = (void *)(((unint64_t)v6 + 15) & 0xFFFFFFFFFFFFFFF8);
  void *v7 = *v8;
  uint64_t v9 = (void *)(((unint64_t)v7 + 15) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v10 = (void *)(((unint64_t)v8 + 15) & 0xFFFFFFFFFFFFFFF8);
  *uint64_t v9 = *v10;
  *(void *)(((unint64_t)v9 + 15) & 0xFFFFFFFFFFFFFFF8) = *(void *)(((unint64_t)v10 + 15) & 0xFFFFFFFFFFFFFFF8);
  return a1;
}

uint64_t initializeWithTake for RecommendationMetrics(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(*(void *)(a3 + 16) - 8);
  (*(void (**)(uint64_t))(v3 + 32))(a1);
  uint64_t v4 = *(void *)(v3 + 64);
  int v5 = (void *)((v4 + a1 + 7) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v6 = (void *)((a2 + v4 + 7) & 0xFFFFFFFFFFFFFFF8);
  void *v5 = *v6;
  Swift::String v7 = (void *)(((unint64_t)v5 + 15) & 0xFFFFFFFFFFFFFFF8);
  int64_t v8 = (void *)(((unint64_t)v6 + 15) & 0xFFFFFFFFFFFFFFF8);
  void *v7 = *v8;
  uint64_t v9 = (void *)(((unint64_t)v7 + 15) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v10 = (void *)(((unint64_t)v8 + 15) & 0xFFFFFFFFFFFFFFF8);
  *uint64_t v9 = *v10;
  *(void *)(((unint64_t)v9 + 15) & 0xFFFFFFFFFFFFFFF8) = *(void *)(((unint64_t)v10 + 15) & 0xFFFFFFFFFFFFFFF8);
  return a1;
}

uint64_t assignWithTake for RecommendationMetrics(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = *(void *)(*(void *)(a3 + 16) - 8);
  (*(void (**)(uint64_t))(v3 + 40))(a1);
  uint64_t v4 = *(void *)(v3 + 64);
  int v5 = (void *)((v4 + a1 + 7) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v6 = (void *)((a2 + v4 + 7) & 0xFFFFFFFFFFFFFFF8);
  void *v5 = *v6;
  Swift::String v7 = (void *)(((unint64_t)v5 + 15) & 0xFFFFFFFFFFFFFFF8);
  int64_t v8 = (void *)(((unint64_t)v6 + 15) & 0xFFFFFFFFFFFFFFF8);
  void *v7 = *v8;
  uint64_t v9 = (void *)(((unint64_t)v7 + 15) & 0xFFFFFFFFFFFFFFF8);
  uint64_t v10 = (void *)(((unint64_t)v8 + 15) & 0xFFFFFFFFFFFFFFF8);
  *uint64_t v9 = *v10;
  *(void *)(((unint64_t)v9 + 15) & 0xFFFFFFFFFFFFFFF8) = *(void *)(((unint64_t)v10 + 15) & 0xFFFFFFFFFFFFFFF8);
  return a1;
}

uint64_t getEnumTagSinglePayload for RecommendationMetrics(int *a1, unsigned int a2, uint64_t a3)
{
  uint64_t result = 0;
  if (a2)
  {
    uint64_t v5 = *(void *)(a3 + 16);
    uint64_t v6 = *(void *)(v5 - 8);
    uint64_t v7 = *(unsigned int *)(v6 + 84);
    if (v7 >= a2)
    {
LABEL_17:
      if (v7) {
        return __swift_getEnumTagSinglePayload((uint64_t)a1, v7, v5);
      }
    }
    else
    {
      unint64_t v8 = ((((((((*(void *)(v6 + 64) + 7) & 0xFFFFFFFFFFFFFFF8) + 15) & 0xFFFFFFFFFFFFFFF8) + 15) & 0xFFFFFFFFFFFFFFF8)
           + 15) & 0xFFFFFFFFFFFFFFF8)
         + 8;
      unsigned int v9 = a2 - v7 + 1;
      unsigned int v10 = 2;
      if ((v8 & 0xFFFFFFF8) == 0) {
        unsigned int v10 = v9;
      }
      unsigned int v11 = 1;
      if (v10 >= 0x100) {
        unsigned int v11 = 2 * (v10 >= 0x10000) + 2;
      }
      uint64_t v12 = 0;
      if (v10 >= 2) {
        uint64_t v12 = v11;
      }
      switch(v12)
      {
        case 0:
          goto LABEL_17;
        case 1:
          int v13 = *((unsigned __int8 *)a1 + v8);
          goto LABEL_13;
        case 2:
          int v13 = *(unsigned __int16 *)((char *)a1 + v8);
          goto LABEL_13;
        case 3:
          BUG();
        case 4:
          int v13 = *(int *)((char *)a1 + v8);
LABEL_13:
          if (!v13) {
            goto LABEL_17;
          }
          int v14 = v13 - 1;
          int v15 = 0;
          if ((v8 & 0xFFFFFFF8) != 0)
          {
            int v14 = 0;
            int v15 = *a1;
          }
          uint64_t result = v7 + (v14 | v15) + 1;
          break;
      }
    }
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for RecommendationMetrics(_DWORD *a1, uint64_t a2, unsigned int a3, uint64_t a4)
{
  uint64_t v4 = *(void *)(a4 + 16);
  uint64_t v5 = *(void *)(v4 - 8);
  unsigned int v6 = *(_DWORD *)(v5 + 84);
  unint64_t v7 = ((((((((*(void *)(v5 + 64) + 7) & 0xFFFFFFFFFFFFFFF8) + 15) & 0xFFFFFFFFFFFFFFF8) + 15) & 0xFFFFFFFFFFFFFFF8)
       + 15) & 0xFFFFFFFFFFFFFFF8)
     + 8;
  unsigned int v8 = 0;
  int v9 = 1;
  if (v6 < a3)
  {
    int v10 = a3 - v6 + 1;
    unsigned int v11 = 2;
    if (!v7) {
      unsigned int v11 = v10;
    }
    int v12 = 2 * (v11 >= 0x10000) + 2;
    if (v11 < 0x100) {
      int v12 = 1;
    }
    unsigned int v8 = 0;
    if (v11 >= 2) {
      unsigned int v8 = v12;
    }
  }
  if (a2 > v6)
  {
    if (v7)
    {
      __bzero(a1, v7);
      *a1 = a2 + ~v6;
    }
    else
    {
      int v9 = a2 - v6;
    }
    uint64_t result = v8;
    switch(v8)
    {
      case 0u:
        return result;
      case 1u:
        *((unsigned char *)a1 + v7) = v9;
        return result;
      case 2u:
        *(_WORD *)((char *)a1 + v7) = v9;
        return result;
      case 3u:
        goto LABEL_23;
      case 4u:
        *(_DWORD *)((char *)a1 + v7) = v9;
        return result;
    }
  }
  uint64_t result = v8;
  switch(v8)
  {
    case 0u:
      break;
    case 1u:
      *((unsigned char *)a1 + v7) = 0;
      break;
    case 2u:
      *(_WORD *)((char *)a1 + v7) = 0;
      break;
    case 3u:
LABEL_23:
      BUG();
    case 4u:
      *(_DWORD *)((char *)a1 + v7) = 0;
      break;
  }
  if (a2) {
    return __swift_storeEnumTagSinglePayload((uint64_t)a1, a2, v6, v4);
  }
  return result;
}

uint64_t type metadata accessor for RecommendationMetrics(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for RecommendationMetrics);
}

uint64_t specialized RandomAccessCollection<>.indices.getter()
{
  return specialized RandomAccessCollection<>.indices.getter(CMLDictionary.size.getter);
}

{
  if (CMLSequence.size.getter() < 0) {
    BUG();
  }
  return 0;
}

{
  if (MLDataTable.size.getter() < 0) {
    BUG();
  }
  return 0;
}

{
  return specialized RandomAccessCollection<>.indices.getter();
}

{
  uint64_t v0;
  uint64_t v1;

  swift_retain();
  Swift::String v0 = CMLSequence.size.getter();
  uint64_t v1 = specialized RandomAccessCollection<>.distance(from:to:)(0, v0);
  swift_release();
  if (v1 < 0) {
    BUG();
  }
  return 0;
}

uint64_t specialized RandomAccessCollection<>.indices.getter(uint64_t (__cdecl *a1)())
{
  if (a1() < 0) {
    BUG();
  }
  return 0;
}

uint64_t CMLSequence.subscript.getter(uint64_t a1)
{
  return CMLSequence.value(at:)(a1);
}

uint64_t specialized RandomAccessCollection<>.index(_:offsetBy:)(uint64_t a1, uint64_t a2)
{
  return specialized RandomAccessCollection<>.index(_:offsetBy:)(a1, a2, CMLDictionary.size.getter);
}

{
  uint64_t v2;
  uint64_t v3;

  uint64_t v2 = a2 + a1;
  if (__OFADD__(a2, a1)) {
    BUG();
  }
  uint64_t v3 = CMLSequence.size.getter();
  if (v2 < 0 || v3 < v2) {
    BUG();
  }
  return a2 + a1;
}

{
  uint64_t v2;
  Swift::Int v3;

  uint64_t v2 = a2 + a1;
  if (__OFADD__(a2, a1)) {
    BUG();
  }
  uint64_t v3 = MLDataTable.size.getter();
  if (v2 < 0 || v3 < v2) {
    BUG();
  }
  return a2 + a1;
}

{
  return specialized RandomAccessCollection<>.index(_:offsetBy:)(a1, a2);
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;

  uint64_t v2 = a2 + a1;
  if (__OFADD__(a2, a1)) {
    BUG();
  }
  swift_retain();
  uint64_t v3 = CMLSequence.size.getter();
  uint64_t v4 = specialized RandomAccessCollection<>.distance(from:to:)(0, v3);
  swift_release();
  if (v2 < 0 || v4 < v2) {
    BUG();
  }
  return a2 + a1;
}

uint64_t specialized RandomAccessCollection<>.index(_:offsetBy:)(uint64_t a1, uint64_t a2, uint64_t (__cdecl *a3)())
{
  uint64_t v3 = a2 + a1;
  if (__OFADD__(a2, a1)) {
    BUG();
  }
  uint64_t v4 = a3();
  if (v3 < 0 || v4 < v3) {
    BUG();
  }
  return a2 + a1;
}

uint64_t specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(a1, a2, a3, specialized RandomAccessCollection<>.distance(from:to:), CMLDictionary.size.getter);
}

{
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;

  uint64_t v3 = specialized RandomAccessCollection<>.distance(from:to:)(a1, a3);
  if (a2 <= 0)
  {
    if (v3 > 0 || v3 <= a2) {
      goto LABEL_8;
    }
    return 0;
  }
  if (v3 >= 0 && v3 < a2) {
    return 0;
  }
LABEL_8:
  uint64_t v4 = a2 + a1;
  if (__OFADD__(a2, a1)) {
    BUG();
  }
  uint64_t v5 = CMLSequence.size.getter();
  if (v4 < 0 || v5 < v4) {
    BUG();
  }
  return v4;
}

{
  uint64_t v3;
  uint64_t v4;
  Swift::Int v5;

  uint64_t v3 = specialized RandomAccessCollection<>.distance(from:to:)(a1, a3);
  if (a2 <= 0)
  {
    if (v3 > 0 || v3 <= a2) {
      goto LABEL_8;
    }
    return 0;
  }
  if (v3 >= 0 && v3 < a2) {
    return 0;
  }
LABEL_8:
  uint64_t v4 = a2 + a1;
  if (__OFADD__(a2, a1)) {
    BUG();
  }
  uint64_t v5 = MLDataTable.size.getter();
  if (v4 < 0 || v5 < v4) {
    BUG();
  }
  return v4;
}

{
  return specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(a1, a2, a3);
}

{
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;

  swift_retain();
  uint64_t v4 = CMLSequence.size.getter();
  uint64_t v5 = specialized RandomAccessCollection<>.distance(from:to:)(0, v4);
  swift_release();
  if (a1 < 0 || v5 < a1) {
    BUG();
  }
  swift_retain();
  unsigned int v6 = CMLSequence.size.getter();
  unint64_t v7 = specialized RandomAccessCollection<>.distance(from:to:)(0, v6);
  swift_release();
  if (a3 < 0 || v7 < a3) {
    BUG();
  }
  unsigned int v8 = a3 - a1;
  if (a2 <= 0)
  {
    if (v8 > 0 || v8 <= a2) {
      goto LABEL_12;
    }
    return 0;
  }
  if (v8 >= 0 && v8 < a2) {
    return 0;
  }
LABEL_12:
  int v9 = a2 + a1;
  if (__OFADD__(a2, a1)) {
    BUG();
  }
  swift_retain();
  int v10 = CMLSequence.size.getter();
  unsigned int v11 = specialized RandomAccessCollection<>.distance(from:to:)(0, v10);
  swift_release();
  if (v9 < 0 || v11 < v9) {
    BUG();
  }
  return v9;
}

uint64_t specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t (*a4)(uint64_t a1, uint64_t a2), uint64_t (__cdecl *a5)())
{
  uint64_t v6 = a4(a1, a3);
  if (a2 <= 0)
  {
    if (v6 > 0 || v6 <= a2) {
      return specialized RandomAccessCollection<>.index(_:offsetBy:)(a1, a2, a5);
    }
    return 0;
  }
  if (v6 >= 0 && v6 < (unint64_t)a2) {
    return 0;
  }
  return specialized RandomAccessCollection<>.index(_:offsetBy:)(a1, a2, a5);
}

uint64_t specialized RandomAccessCollection<>.index(before:)(uint64_t a1)
{
  return specialized RandomAccessCollection<>.index(before:)(a1);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v1 = a1 - 1;
  if (__OFSUB__(a1, 1)) {
    BUG();
  }
  swift_retain();
  uint64_t v2 = CMLSequence.size.getter();
  uint64_t v3 = specialized RandomAccessCollection<>.distance(from:to:)(0, v2);
  swift_release();
  if (v1 < 0 || v1 >= v3) {
    BUG();
  }
  return a1 - 1;
}

{
  uint64_t v1;
  Swift::Int v2;

  uint64_t v1 = a1 - 1;
  if (__OFSUB__(a1, 1)) {
    BUG();
  }
  uint64_t v2 = MLDataTable.size.getter();
  if (v1 < 0 || v1 >= v2) {
    BUG();
  }
  return a1 - 1;
}

{
  uint64_t v1;
  uint64_t v2;

  uint64_t v1 = a1 - 1;
  if (__OFSUB__(a1, 1)) {
    BUG();
  }
  uint64_t v2 = CMLSequence.size.getter();
  if (v1 < 0 || v1 >= v2) {
    BUG();
  }
  return a1 - 1;
}

{
  return specialized RandomAccessCollection<>.index(before:)(a1, CMLDictionary.size.getter);
}

uint64_t specialized RandomAccessCollection<>.index(before:)(uint64_t a1, uint64_t (__cdecl *a2)())
{
  uint64_t v2 = a1 - 1;
  if (__OFSUB__(a1, 1)) {
    BUG();
  }
  uint64_t v3 = a2();
  if (v2 < 0 || v2 >= v3) {
    BUG();
  }
  return a1 - 1;
}

uint64_t specialized Collection<>.subscript.getter(uint64_t a1, uint64_t a2)
{
  return specialized Collection<>.subscript.getter(a1, a2, CMLDictionary.size.getter);
}

{
  uint64_t v2;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  char v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  int v11;
  char v12;
  uint64_t v13;
  unsigned char v15[24];
  unsigned char v16[24];
  long long v17;
  char v18;
  long long v19;
  char v20;
  uint64_t v21;
  int v22;
  char v23;
  uint64_t v24;
  int v25;
  char v26;
  long long v27;
  char v28;
  long long v29;
  char v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;

  uint64_t v4 = v2;
  uint64_t v5 = specialized Dictionary.startIndex.getter(a2);
  if (v7) {
    BUG();
  }
  unsigned int v8 = *(unsigned int *)(a2 + 36);
  int v9 = 1 << *(unsigned char *)(a2 + 32);
  if (v8 != v6) {
    BUG();
  }
  if (v9 < v5) {
    BUG();
  }
  uint64_t v34 = v5;
  uint64_t v31 = v6;
  uint64_t v33 = v4;
  char v32 = a2;
  double v28 = *(unsigned char *)(a1 + 16);
  uint64_t v27 = *(_OWORD *)a1;
  char v17 = *(_OWORD *)a1;
  uint64_t v18 = *(unsigned char *)(a1 + 16);
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)&v17, (uint64_t)v15);
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)v15, (uint64_t)&v24);
  if (v26) {
    BUG();
  }
  if (v25 != v8) {
    BUG();
  }
  if (v24 < v34) {
    BUG();
  }
  double v30 = *(unsigned char *)(a1 + 40);
  double v29 = *(_OWORD *)(a1 + 24);
  uint64_t v19 = *(_OWORD *)(a1 + 24);
  uint64_t v20 = *(unsigned char *)(a1 + 40);
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)&v19, (uint64_t)v16);
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)v16, (uint64_t)&v21);
  if (v23) {
    BUG();
  }
  int v10 = v21;
  unsigned int v11 = v22;
  outlined consume of [MLDataValue : MLDataValue].Index._Variant(v34, v31, 0);
  outlined consume of [MLDataValue : MLDataValue].Index._Variant(v9, v8, 0);
  if (v8 != v11) {
    BUG();
  }
  if (v9 < v10) {
    BUG();
  }
  int v12 = v32;
  int v13 = v33;
  *(void *)(v33 + 48) = v32;
  *(_OWORD *)int v13 = v27;
  *(unsigned char *)(v13 + 16) = v28;
  *(_OWORD *)(v13 + 24) = v29;
  *(unsigned char *)(v13 + 40) = v30;
  swift_bridgeObjectRetain(v12);
  return outlined retain of Range<MLDataValue.DictionaryType.Index>(a1);
}

uint64_t specialized Collection<>.subscript.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v5 = v3;
  uint64_t v6 = CMLSequence.size.getter();
  if (v6 < 0) {
    BUG();
  }
  if (a1 < 0) {
    BUG();
  }
  if (v6 < a2) {
    BUG();
  }
  _OWORD v5[2] = a3;
  uint64_t *v5 = a1;
  v5[1] = a2;
  return swift_retain();
}

{
  return specialized Collection<>.subscript.getter(a1, a2, a3);
}

{
  uint64_t *v3;
  uint64_t *v5;
  uint64_t v6;
  uint64_t v7;

  uint64_t v5 = v3;
  swift_retain();
  uint64_t v6 = CMLSequence.size.getter();
  unint64_t v7 = specialized RandomAccessCollection<>.distance(from:to:)(0, v6);
  swift_release();
  if (v7 < 0) {
    BUG();
  }
  if (a1 < 0) {
    BUG();
  }
  if (v7 < a2) {
    BUG();
  }
  _OWORD v5[2] = a3;
  uint64_t *v5 = a1;
  v5[1] = a2;
  return swift_retain();
}

uint64_t specialized Collection<>.subscript.getter(uint64_t a1, Swift::Int a2, uint64_t a3, char a4)
{
  uint64_t v7 = v4;
  Swift::Int v8 = MLDataTable.size.getter();
  if (v8 < 0) {
    BUG();
  }
  if (a1 < 0) {
    BUG();
  }
  if (v8 < a2) {
    BUG();
  }
  *(void *)(v7 + 16) = a3;
  *(unsigned char *)(v7 + 24) = a4 & 1;
  *(void *)uint64_t v7 = a1;
  *(void *)(v7 + 8) = a2;
  return outlined copy of Result<_DataTable, Error>(a3, a4);
}

uint64_t specialized Collection<>.subscript.getter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  Swift::Int v8 = v5;
  swift_retain();
  swift_bridgeObjectRetain(a4);
  swift_retain_n(a5);
  uint64_t v9 = CMLSequence.size.getter();
  uint64_t v10 = specialized RandomAccessCollection<>.distance(from:to:)(0, v9);
  swift_retain();
  uint64_t v11 = CMLSequence.size.getter();
  uint64_t v12 = specialized RandomAccessCollection<>.distance(from:to:)(0, v11);
  swift_release();
  if (v12 < 0) {
    BUG();
  }
  swift_retain();
  uint64_t v13 = CMLSequence.size.getter();
  uint64_t v14 = specialized RandomAccessCollection<>.distance(from:to:)(0, v13);
  swift_bridgeObjectRelease(a4);
  swift_release();
  swift_release_n(a5);
  if (v10 < 0 || v14 < v10) {
    BUG();
  }
  if (a1 < 0) {
    BUG();
  }
  if (v10 < a2) {
    BUG();
  }
  _OWORD v8[2] = a3;
  v8[3] = a4;
  v8[4] = a5;
  uint64_t *v8 = a1;
  v8[1] = a2;
  swift_retain();
  swift_bridgeObjectRetain(a4);
  return swift_retain();
}

uint64_t specialized Collection<>.subscript.getter(uint64_t a1, uint64_t a2, uint64_t (__cdecl *a3)())
{
  uint64_t v3 = a3();
  if (v3 < 0) {
    BUG();
  }
  if (a1 < 0) {
    BUG();
  }
  if (v3 < a2) {
    BUG();
  }
  swift_retain();
  return a1;
}

void specialized Collection._failEarlyRangeCheck(_:bounds:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a1 < a3 || a4 < a2) {
    BUG();
  }
}

{
  specialized Collection._failEarlyRangeCheck(_:bounds:)(a1, a2, a3, a4);
}

uint64_t specialized Collection._failEarlyRangeCheck(_:bounds:)(long long *a1, long long *a2)
{
  long long v10 = *a1;
  char v11 = *((unsigned char *)a1 + 16);
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)&v10, (uint64_t)v6);
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)v6, (uint64_t)&v27);
  if (v29
    || (uint64_t v30 = v27,
        int v2 = v28,
        long long v12 = *a2,
        char v13 = *((unsigned char *)a2 + 16),
        outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)&v12, (uint64_t)v7),
        outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)v7, (uint64_t)&v24),
        v26))
  {
    BUG();
  }
  if (v2 != v25) {
    BUG();
  }
  if (v30 < v24) {
    BUG();
  }
  char v15 = *((unsigned char *)a2 + 40);
  long long v14 = *(long long *)((char *)a2 + 24);
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)&v14, (uint64_t)v8);
  outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)v8, (uint64_t)&v21);
  if (v23
    || (uint64_t v3 = v21,
        int v4 = v22,
        long long v16 = *(long long *)((char *)a1 + 24),
        char v17 = *((unsigned char *)a1 + 40),
        outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)&v16, (uint64_t)v9),
        uint64_t result = outlined init with take of [MLDataValue : MLDataValue].Index._Variant((uint64_t)v9, (uint64_t)&v18),
        v20))
  {
    BUG();
  }
  if (v4 != v19) {
    BUG();
  }
  if (v3 < v18) {
    BUG();
  }
  return result;
}

uint64_t specialized Collection.underestimatedCount.getter()
{
  uint64_t v0 = CMLDictionary.size.getter();
  return specialized RandomAccessCollection<>.distance(from:to:)(0, v0);
}

{
  return specialized Collection.underestimatedCount.getter();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;

  swift_retain();
  uint64_t v0 = CMLSequence.size.getter();
  uint64_t v1 = specialized RandomAccessCollection<>.distance(from:to:)(0, v0);
  swift_release();
  swift_retain();
  int v2 = CMLSequence.size.getter();
  uint64_t v3 = specialized RandomAccessCollection<>.distance(from:to:)(0, v2);
  swift_release();
  if (v3 < 0) {
    BUG();
  }
  swift_retain();
  int v4 = CMLSequence.size.getter();
  uint64_t v5 = specialized RandomAccessCollection<>.distance(from:to:)(0, v4);
  swift_release();
  if (v1 < 0 || v5 < v1) {
    BUG();
  }
  return v1;
}

{
  uint64_t v0;

  uint64_t v0 = CMLSequence.size.getter();
  return specialized RandomAccessCollection<>.distance(from:to:)(0, v0);
}

uint64_t specialized Collection.underestimatedCount.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  swift_retain();
  uint64_t v4 = CMLSequence.size.getter();
  uint64_t v5 = specialized RandomAccessCollection<>.distance(from:to:)(0, v4);
  swift_retain();
  uint64_t v6 = CMLSequence.size.getter();
  uint64_t v7 = specialized RandomAccessCollection<>.distance(from:to:)(0, v6);
  swift_release();
  if (v7 < 0) {
    BUG();
  }
  swift_retain();
  uint64_t v8 = CMLSequence.size.getter();
  uint64_t v9 = specialized RandomAccessCollection<>.distance(from:to:)(0, v8);
  swift_release_n(a3);
  if (v5 < 0 || v9 < v5) {
    BUG();
  }
  return v5;
}

uint64_t *specialized Collection._copyToContiguousArray()()
{
  uint64_t v0 = specialized _copyCollectionToContiguousArray<A>(_:)();
  swift_release();
  return v0;
}

void *specialized Collection._copyToContiguousArray()(uint64_t a1)
{
  uint64_t v1 = specialized _copyCollectionToContiguousArray<A>(_:)(a1);
  swift_bridgeObjectRelease(a1);
  return v1;
}

void *specialized Collection._copyToContiguousArray()(uint64_t a1, double a2)
{
  int v2 = specialized _copyCollectionToContiguousArray<A>(_:)(a1, a2);
  swift_release();
  return v2;
}

{
  void *v2;

  int v2 = specialized _copyCollectionToContiguousArray<A>(_:)(a1, a2);
  swift_release();
  return v2;
}

void *specialized Collection._copyToContiguousArray()(uint64_t a1, char a2)
{
  char v2 = a2 & 1;
  uint64_t v3 = specialized _copyCollectionToContiguousArray<A>(_:)(a1, v2);
  outlined consume of Result<_DataTable, Error>(a1, v2);
  return v3;
}

void *specialized Collection._copyToContiguousArray()(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = specialized _copyCollectionToContiguousArray<A>(_:)(a1, a2, a3);
  swift_release();
  swift_bridgeObjectRelease(a2);
  swift_release();
  return v3;
}

uint64_t *specialized Collection._copyToContiguousArray()(uint64_t a1)
{
  uint64_t v1 = specialized _copyCollectionToContiguousArray<A>(_:)(a1);
  swift_release();
  return v1;
}

void *specialized Collection._copyToContiguousArray()()
{
  uint64_t v0 = specialized _copyCollectionToContiguousArray<A>(_:)();
  swift_release();
  return v0;
}

uint64_t specialized Sequence._copyContents(initializing:)(void *a1, uint64_t *a2, uint64_t a3)
{
  return specialized Sequence._copySequenceContents(initializing:)(a1, a2, a3);
}

uint64_t specialized Sequence._copyContents(initializing:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return specialized Sequence._copySequenceContents(initializing:)(a1, a2, a3, a4);
}

uint64_t specialized Sequence._copyContents(initializing:)(void *a1, uint64_t a2, uint64_t a3, uint64_t a4, double a5)
{
  return specialized Sequence._copySequenceContents(initializing:)(a1, a2, a3, a4, a5);
}

{
  return specialized Sequence._copySequenceContents(initializing:)(a1, a2, a3, a4, a5);
}

Swift::Int specialized Sequence._copyContents(initializing:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, char a5)
{
  return specialized Sequence._copySequenceContents(initializing:)(a1, a2, a3, a4, a5 & 1);
}

uint64_t specialized Sequence._copyContents(initializing:)(void *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  return specialized Sequence._copySequenceContents(initializing:)(a1, a2, a3, a4, a5, a6);
}

uint64_t specialized Sequence._copyContents(initializing:)(void *a1, uint64_t *a2, uint64_t a3, uint64_t a4)
{
  return specialized Sequence._copySequenceContents(initializing:)(a1, a2, a3, a4);
}

uint64_t specialized Sequence._copyContents(initializing:)(uint64_t a1, unsigned char *a2, uint64_t a3)
{
  return specialized Sequence._copySequenceContents(initializing:)(a1, a2, a3);
}

uint64_t specialized Sequence._copyContents(initializing:)(void *a1, uint64_t a2, uint64_t a3)
{
  return specialized Sequence._copySequenceContents(initializing:)(a1, a2, a3);
}

uint64_t Array<A>.featureValue.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  type metadata accessor for CMLFeatureValue();
  uint64_t v4 = Array<A>.featureSequence.getter(a1, a2, a3);
  return CMLFeatureValue.__allocating_init(_:)(v4);
}

uint64_t MLDataValue.SequenceType.description.getter()
{
  return MLDataValue.SequenceType.description.getter();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  void *v3;
  void *v4;
  Swift::String v5;

  swift_retain();
  uint64_t v0 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LazyMapSequence<MLDataValue.SequenceType, String>);
  uint64_t v1 = lazy protocol witness table accessor for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>(&lazy protocol witness table cache variable for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>, &demangling cache variable for type metadata for LazyMapSequence<MLDataValue.SequenceType, String>, (void (*)(void))lazy protocol witness table accessor for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType, (uint64_t)&protocol conformance descriptor for <> LazyMapSequence<A, B>);
  char v2 = BidirectionalCollection<>.joined(separator:)(8236, 0xE200000000000000, v0, v1);
  uint64_t v4 = v3;
  swift_release();
  v5._uint64_t countAndFlagsBits = v2;
  v5._char object = v4;
  String.append(_:)(v5);
  swift_bridgeObjectRelease((_BYTE)v4);
  swift_bridgeObjectRetain(0);
  v5._uint64_t countAndFlagsBits = 93;
  v5._char object = (void *)0xE100000000000000;
  String.append(_:)(v5);
  swift_bridgeObjectRelease(0);
  return 91;
}

uint64_t *MLDataValue.SequenceType.init<A>(_:)(uint64_t a1, uint64_t a2, void *a3, double a4)
{
  uint64_t v40 = a1;
  unint64_t v36 = v4;
  uint64_t v5 = *(void *)(a2 - 8);
  int64_t v6 = *(void *)(v5 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t AssociatedConformanceWitness = v33;
  uint64_t v46 = a3;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, a2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v37 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v10 = *(void *)(v37 + 64);
  char v11 = alloca(v10);
  long long v12 = alloca(v10);
  uint64_t v45 = v33;
  uint64_t v13 = tc_v1_flex_list_create(0);
  if (!v13) {
    BUG();
  }
  uint64_t v14 = v13;
  uint64_t v15 = type metadata accessor for CMLSequence();
  uint64_t v16 = swift_allocObject(v15, 25, 7);
  *(void *)(v16 + 16) = v14;
  uint64_t v39 = v16;
  *(unsigned char *)(v16 + 24) = 1;
  uint64_t v38 = v5;
  (*(void (**)(void *, uint64_t, uint64_t))(v5 + 16))(AssociatedConformanceWitness, v40, a2);
  char v17 = v46;
  dispatch thunk of Sequence.makeIterator()(a2, v46);
  uint64_t AssociatedConformanceWitness = (void *)swift_getAssociatedConformanceWitness(v17, a2, AssociatedTypeWitness, &protocol requirements base descriptor for Sequence, &associated conformance descriptor for Sequence.Sequence.Iterator: IteratorProtocol);
  v33[1] = a2;
  for (uint64_t i = AssociatedTypeWitness; ; AssociatedTypeWitness = i)
  {
    dispatch thunk of IteratorProtocol.next()(AssociatedTypeWitness, AssociatedConformanceWitness);
    char v18 = v44;
    double v19 = v42;
    char v20 = v43;
    uint64_t v46 = v43;
    switch(v44)
    {
      case 0:
        double v21 = v42;
        uint64_t v22 = specialized handling<A, B>(_:_:)(*(uint64_t *)&v42);
        if (!v22) {
          BUG();
        }
        uint64_t v23 = type metadata accessor for CMLFeatureValue();
        swift_allocObject(v23, 25, 7);
        uint64_t v24 = CMLFeatureValue.init(rawValue:ownsValue:)(v22, 1);
        double v25 = v21;
        char v26 = v46;
        char v27 = 0;
        goto LABEL_15;
      case 1:
        double v21 = v42;
        a4 = v42;
        uint64_t v29 = specialized handling<A, B>(_:_:)();
        if (!v29) {
          BUG();
        }
        uint64_t v30 = type metadata accessor for CMLFeatureValue();
        swift_allocObject(v30, 25, 7);
        uint64_t v24 = CMLFeatureValue.init(rawValue:ownsValue:)(v29, 1);
        double v25 = v21;
        char v26 = v46;
        char v32 = 1;
        goto LABEL_14;
      case 2:
        uint64_t v35 = type metadata accessor for CMLFeatureValue();
        outlined copy of MLDataValue(*(void **)&v19, v20, 2u);
        outlined copy of MLDataValue(*(void **)&v19, v20, 2u);
        char v26 = v20;
        double v25 = v19;
        uint64_t v24 = CMLFeatureValue.__allocating_init(_:)(*(uint64_t *)&v19, (uint64_t)v20);
        double v21 = v25;
        char v32 = 2;
        goto LABEL_14;
      case 3:
        double v21 = v42;
        uint64_t v28 = MLDataValue.SequenceType.featureValue.getter(a4);
        goto LABEL_12;
      case 4:
        double v21 = v42;
        uint64_t v28 = MLDataValue.DictionaryType.featureValue.getter();
        goto LABEL_12;
      case 5:
        double v21 = v42;
        uint64_t v28 = MLDataValue.MultiArrayType.featureValue.getter();
LABEL_12:
        uint64_t v24 = v28;
        break;
      case 6:
        type metadata accessor for CMLFeatureValue();
        char v26 = v20;
        double v25 = v19;
        uint64_t v24 = CMLFeatureValue.__allocating_init()(0);
        double v21 = v25;
        char v32 = 6;
LABEL_14:
        char v27 = v32;
LABEL_15:
        outlined consume of MLDataValue?(*(void **)&v25, v26, v27);
        break;
      default:
        (*(void (**)(uint64_t, void *))(v38 + 8))(v40, v43);
        (*(void (**)(void *, double))(v37 + 8))(v45, COERCE_DOUBLE(*(void *)&v19));
        uint64_t result = v36;
        *unint64_t v36 = v39;
        return result;
    }
    CMLSequence.append(_:)(v24);
    swift_release();
    outlined consume of MLDataValue?(*(void **)&v21, v46, v18);
  }
}

uint64_t MLDataValue.SequenceType.init()()
{
  uint64_t v1 = v0;
  uint64_t v2 = tc_v1_flex_list_create(0);
  if (!v2) {
    BUG();
  }
  uint64_t v3 = v2;
  uint64_t v4 = type metadata accessor for CMLSequence();
  uint64_t result = swift_allocObject(v4, 25, 7);
  *(void *)(result + 16) = v3;
  *(unsigned char *)(result + 24) = 1;
  *uint64_t v1 = result;
  return result;
}

uint64_t *MLDataValue.SequenceType.init<A>(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v42 = a4;
  uint64_t v51 = a1;
  uint64_t v43 = v4;
  uint64_t v7 = 0;
  uint64_t AssociatedTypeWitness = swift_getAssociatedTypeWitness(0, a3, a2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Element);
  uint64_t v50 = *(void *)(AssociatedTypeWitness - 8);
  int64_t v9 = *(void *)(v50 + 64);
  int64_t v10 = alloca(v9);
  char v11 = alloca(v9);
  uint64_t v48 = v41;
  uint64_t v56 = AssociatedTypeWitness;
  int64_t v12 = *(void *)(*(void *)(type metadata accessor for Optional(0, AssociatedTypeWitness) - 8) + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  uint64_t v45 = v41;
  uint64_t v15 = *(void *)(a2 - 8);
  int64_t v16 = *(void *)(v15 + 64);
  char v17 = alloca(v16);
  char v18 = alloca(v16);
  uint64_t v55 = v41;
  uint64_t v54 = a3;
  uint64_t v52 = swift_getAssociatedTypeWitness(0, a3, a2, &protocol requirements base descriptor for Sequence, &associated type descriptor for Sequence.Iterator);
  uint64_t v44 = *(void *)(v52 - 8);
  int64_t v19 = *(void *)(v44 + 64);
  char v20 = alloca(v19);
  double v21 = alloca(v19);
  uint64_t v53 = v41;
  uint64_t v22 = tc_v1_flex_list_create(0);
  if (!v22) {
    BUG();
  }
  uint64_t v23 = v22;
  uint64_t v24 = type metadata accessor for CMLSequence();
  uint64_t v25 = swift_allocObject(v24, 25, 7);
  *(void *)(v25 + 16) = v23;
  uint64_t v49 = v25;
  *(unsigned char *)(v25 + 24) = 1;
  uint64_t v47 = v15;
  (*(void (**)(unsigned char *, uint64_t, uint64_t))(v15 + 16))(v55, v51, a2);
  uint64_t v26 = v54;
  dispatch thunk of Sequence.makeIterator()(a2, v54);
  uint64_t v27 = v26;
  uint64_t v46 = a2;
  uint64_t v28 = v52;
  uint64_t AssociatedConformanceWitness = swift_getAssociatedConformanceWitness(v27, a2, v52, &protocol requirements base descriptor for Sequence, &associated conformance descriptor for Sequence.Sequence.Iterator: IteratorProtocol);
  uint64_t v30 = (uint64_t)v45;
  uint64_t v54 = AssociatedConformanceWitness;
  dispatch thunk of IteratorProtocol.next()(v28, AssociatedConformanceWitness);
  uint64_t v31 = v56;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v30, 1, v56);
  uint64_t v34 = v48;
  uint64_t v35 = v53;
  if (EnumTagSinglePayload != 1)
  {
    uint64_t v36 = v30;
    uint64_t v55 = *(unsigned char **)(v50 + 32);
    do
    {
      ((void (*)(unsigned char *, uint64_t, uint64_t))v55)(v34, v36, v31);
      uint64_t v37 = MLDataValueConvertible.featureValue.getter(v31, v42);
      CMLSequence.append(_:)(v37);
      uint64_t v56 = v7;
      if (v7)
      {
        swift_release();
        swift_unexpectedError(v56, "CreateML/SequenceType.swift", 27, 1);
        BUG();
      }
      uint64_t v38 = v48;
      (*(void (**)(unsigned char *, uint64_t))(v50 + 8))(v48, v31);
      swift_release();
      uint64_t v35 = v53;
      dispatch thunk of IteratorProtocol.next()(v52, v54);
      int v39 = __swift_getEnumTagSinglePayload(v36, 1, v31);
      uint64_t v34 = v38;
      uint64_t v7 = v56;
    }
    while (v39 != 1);
  }
  (*(void (**)(uint64_t, uint64_t, uint64_t, unsigned char *))(v47 + 8))(v51, v46, v33, v34);
  (*(void (**)(unsigned char *, uint64_t))(v44 + 8))(v35, v52);
  uint64_t result = v43;
  *uint64_t v43 = v49;
  return result;
}

uint64_t MLDataValue.SequenceType.startIndex.getter()
{
  return 0;
}

uint64_t MLDataValue.SequenceType.endIndex.getter()
{
  return CMLSequence.size.getter();
}

uint64_t CMLSequence.endIndex.getter()
{
  return CMLSequence.size.getter();
}

char MLDataValue.SequenceType.subscript.getter(uint64_t a1, double a2)
{
  swift_retain();
  uint64_t v2 = CMLSequence.value(at:)(a1);
  swift_release();
  return MLDataValue.init(_:)(v2, a2);
}

uint64_t protocol witness for RandomAccessCollection.index(_:offsetBy:limitedBy:) in conformance MLDataValue.SequenceType(uint64_t *a1, uint64_t a2, uint64_t *a3)
{
  return protocol witness for RandomAccessCollection.index(_:offsetBy:limitedBy:) in conformance MLDataValue.SequenceType(a1, a2, a3);
}

{
  uint64_t v3;
  uint64_t v4;
  uint64_t result;
  char v6;

  uint64_t v4 = v3;
  uint64_t result = specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(*a1, a2, *a3);
  *(void *)uint64_t v4 = result;
  *(unsigned char *)(v4 + 8) = v6 & 1;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.index(before:) in conformance MLDataValue.SequenceType(uint64_t *a1)
{
  uint64_t v2 = v1;
  uint64_t result = specialized RandomAccessCollection<>.index(before:)(*a1);
  *uint64_t v2 = result;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.formIndex(before:) in conformance MLDataValue.SequenceType(uint64_t *a1)
{
  uint64_t v1 = *a1 - 1;
  if (__OFSUB__(*a1, 1)) {
    BUG();
  }
  uint64_t result = CMLSequence.size.getter();
  if (v1 < 0 || v1 >= result) {
    BUG();
  }
  *a1 = v1;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance MLDataValue.SequenceType(uint64_t *a1, uint64_t a2)
{
  uint64_t v3 = v2;
  uint64_t result = specialized RandomAccessCollection<>.index(_:offsetBy:)(*a1, a2);
  *uint64_t v3 = result;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.distance(from:to:) in conformance MLDataValue.SequenceType(uint64_t *a1, uint64_t *a2)
{
  return specialized RandomAccessCollection<>.distance(from:to:)(*a1, *a2);
}

uint64_t protocol witness for Collection.endIndex.getter in conformance MLDataValue.SequenceType()
{
  uint64_t v1 = v0;
  uint64_t result = MLDataValue.SequenceType.endIndex.getter();
  *uint64_t v1 = result;
  return result;
}

void (*protocol witness for Collection.subscript.read in conformance MLDataValue.SequenceType(double a1, uint64_t a2, uint64_t *a3))(uint64_t a1)
{
  return protocol witness for Collection.subscript.read in conformance MLDataValue.SequenceType;
}

void protocol witness for Collection.subscript.read in conformance MLDataValue.SequenceType(uint64_t a1)
{
}

uint64_t protocol witness for Collection.subscript.getter in conformance MLDataValue.SequenceType(uint64_t *a1)
{
  return specialized Collection<>.subscript.getter(*a1, a1[1], *v1);
}

uint64_t protocol witness for Collection.indices.getter in conformance MLDataValue.SequenceType()
{
  uint64_t v1 = v0;
  uint64_t result = specialized RandomAccessCollection<>.indices.getter();
  *uint64_t v1 = result;
  v1[1] = v3;
  return result;
}

BOOL protocol witness for Collection.isEmpty.getter in conformance MLDataValue.SequenceType()
{
  return specialized Collection.isEmpty.getter();
}

uint64_t protocol witness for Collection.count.getter in conformance MLDataValue.SequenceType()
{
  return specialized Collection.count.getter();
}

void protocol witness for Collection._failEarlyRangeCheck(_:bounds:) in conformance MLDataValue.SequenceType(uint64_t *a1, uint64_t *a2)
{
}

{
  specialized Collection._failEarlyRangeCheck(_:bounds:)(*a1, *a2, a2[1]);
}

uint64_t protocol witness for Collection.index(after:) in conformance MLDataValue.SequenceType(uint64_t *a1)
{
  uint64_t v2 = v1;
  uint64_t result = specialized RandomAccessCollection<>.index(after:)(*a1);
  *uint64_t v2 = result;
  return result;
}

uint64_t protocol witness for Collection.formIndex(after:) in conformance MLDataValue.SequenceType(uint64_t *a1)
{
  uint64_t v1 = *a1;
  uint64_t result = CMLSequence.size.getter();
  if (v1 < 0 || v1 >= result) {
    BUG();
  }
  *a1 = v1 + 1;
  return result;
}

void *protocol witness for Sequence._copyToContiguousArray() in conformance MLDataValue.SequenceType(double a1)
{
  return specialized Collection._copyToContiguousArray()(*v1, a1);
}

uint64_t protocol witness for Sequence._copyContents(initializing:) in conformance MLDataValue.SequenceType(void *a1, uint64_t a2, uint64_t a3, double a4)
{
  return specialized Sequence._copyContents(initializing:)(a1, a2, a3, *v4, a4);
}

uint64_t *MLDataValue.SequenceType.init(arrayLiteral:)(uint64_t a1, double a2)
{
  int64_t v16 = v2;
  uint64_t v3 = tc_v1_flex_list_create(0);
  if (!v3) {
    BUG();
  }
  uint64_t v4 = v3;
  uint64_t v5 = type metadata accessor for CMLSequence();
  uint64_t v6 = swift_allocObject(v5, 25, 7);
  *(void *)(v6 + 16) = v4;
  uint64_t v17 = v6;
  *(unsigned char *)(v6 + 24) = 1;
  uint64_t v7 = *(void *)(a1 + 16);
  if (v7)
  {
    uint64_t v8 = (char *)(a1 + 48);
    while (2)
    {
      int64_t v9 = (void *)*((void *)v8 - 2);
      char v18 = (void *)*((void *)v8 - 1);
      char v15 = *v8;
      switch(*v8)
      {
        case 0:
          uint64_t v10 = specialized handling<A, B>(_:_:)((uint64_t)v9);
          if (!v10) {
            BUG();
          }
          goto LABEL_11;
        case 1:
          a2 = *((double *)v8 - 2);
          uint64_t v10 = specialized handling<A, B>(_:_:)();
          if (!v10) {
            BUG();
          }
LABEL_11:
          uint64_t v13 = type metadata accessor for CMLFeatureValue();
          swift_allocObject(v13, 25, 7);
          uint64_t v11 = CMLFeatureValue.init(rawValue:ownsValue:)(v10, 1);
          goto LABEL_14;
        case 2:
          type metadata accessor for CMLFeatureValue();
          outlined copy of MLDataValue(v9, v18, 2u);
          swift_bridgeObjectRetain_n(v18, 2);
          uint64_t v12 = CMLFeatureValue.__allocating_init(_:)((uint64_t)v9, (uint64_t)v18);
          outlined consume of MLDataValue(v9, v18, 2);
          goto LABEL_15;
        case 3:
          swift_retain();
          uint64_t v11 = MLDataValue.SequenceType.featureValue.getter(a2);
          goto LABEL_14;
        case 4:
          swift_bridgeObjectRetain((_BYTE)v9);
          uint64_t v11 = MLDataValue.DictionaryType.featureValue.getter();
          goto LABEL_14;
        case 5:
          v9;
          uint64_t v11 = MLDataValue.MultiArrayType.featureValue.getter();
          goto LABEL_14;
        case 6:
          type metadata accessor for CMLFeatureValue();
          uint64_t v11 = CMLFeatureValue.__allocating_init()(0);
LABEL_14:
          uint64_t v12 = v11;
LABEL_15:
          CMLSequence.append(_:)(v12);
          swift_release();
          outlined consume of MLDataValue(v9, v18, v15);
          v8 += 24;
          if (!--v7) {
            break;
          }
          continue;
      }
      break;
    }
  }
  swift_bridgeObjectRelease(a1);
  uint64_t result = v16;
  *int64_t v16 = v17;
  return result;
}

uint64_t *protocol witness for ExpressibleByArrayLiteral.init(arrayLiteral:) in conformance MLDataValue.SequenceType(uint64_t a1, double a2)
{
  return MLDataValue.SequenceType.init(arrayLiteral:)(a1, a2);
}

uint64_t static MLDataValue.SequenceType.== infix(_:_:)(void *a1, uint64_t *a2)
{
  uint64_t v2 = *a1;
  uint64_t v3 = *a2;
  swift_retain(*a1);
  uint64_t v4 = CMLSequence.size.getter();
  uint64_t v37 = (void *)specialized RandomAccessCollection<>.distance(from:to:)(0, v4);
  swift_release(v2);
  swift_retain(v3);
  uint64_t v5 = CMLSequence.size.getter();
  uint64_t v6 = (void *)specialized RandomAccessCollection<>.distance(from:to:)(0, v5);
  uint64_t v33 = v3;
  swift_release(v3);
  unsigned int v7 = 0;
  if (v37 == v6)
  {
    swift_retain(v2);
    unsigned int v7 = v2;
    uint64_t v8 = CMLSequence.size.getter();
    uint64_t v9 = specialized RandomAccessCollection<>.distance(from:to:)(0, v8);
    uint64_t v36 = v2;
    swift_release(v2);
    uint64_t v35 = v9;
    if (v9 < 0) {
      BUG();
    }
    if (v9)
    {
      uint64_t v34 = v35 - 1;
      uint64_t v10 = 0;
      uint64_t v11 = v36;
      do
      {
        if (v35 == v10) {
          BUG();
        }
        uint64_t v12 = v11;
        swift_retain_n(v11, 2);
        uint64_t v13 = CMLSequence.value(at:)(v10);
        swift_release(v12);
        MLDataValue.init(_:)(v13);
        swift_release(v12);
        uint64_t v37 = v21;
        v24[0] = v21;
        uint64_t v31 = v22;
        v24[1] = v22;
        char v38 = v23;
        char v25 = v23;
        uint64_t v14 = v33;
        swift_retain_n(v33, 2);
        uint64_t v32 = v10;
        uint64_t v15 = CMLSequence.value(at:)(v10);
        swift_release(v14);
        MLDataValue.init(_:)(v15);
        swift_release(v14);
        int64_t v16 = v26;
        uint64_t v17 = v27;
        char v18 = v28;
        v29[0] = v26;
        v29[1] = v27;
        char v30 = v28;
        LOBYTE(v19) = static MLDataValue.== infix(_:_:)((uint64_t)v24, (uint64_t)v29);
        unsigned int v7 = v19;
        outlined consume of MLDataValue(v16, v17, v18);
        outlined consume of MLDataValue(v37, v31, v38);
        if ((v7 & 1) == 0) {
          break;
        }
        uint64_t v10 = v32 + 1;
        uint64_t v11 = v36;
      }
      while (v34 != v32);
    }
    else
    {
      LOBYTE(v7) = 1;
    }
  }
  return v7;
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance MLDataValue.SequenceType(void *a1, uint64_t *a2)
{
  return static MLDataValue.SequenceType.== infix(_:_:)(a1, a2);
}

uint64_t closure #1 in MLDataValue.SequenceType.description.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = v3;
  uint64_t result = MLDataValue.description.getter(a1, a2, a3);
  uint64_t *v4 = result;
  v4[1] = v6;
  return result;
}

uint64_t MLDataValue.SequenceType.debugDescription.getter()
{
  return MLDataValue.SequenceType.description.getter();
}

uint64_t closure #1 in MLDataValue.SequenceType.debugDescription.getter(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t v3 = *(void **)(a1 + 8);
  int v4 = *(_DWORD *)(a1 + 16);
  v7[0] = *(void **)a1;
  v7[1] = v3;
  char v8 = v4;
  outlined copy of MLDataValue(v7[0], v3, v4);
  uint64_t result = String.init<A>(reflecting:)(v7, &type metadata for MLDataValue);
  *uint64_t v2 = result;
  v2[1] = v6;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLDataValue.SequenceType()
{
  return MLDataValue.SequenceType.description.getter();
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLDataValue.SequenceType()
{
  return MLDataValue.SequenceType.debugDescription.getter();
}

uint64_t protocol witness for RandomAccessCollection.index(_:offsetBy:limitedBy:) in conformance CMLSequence(uint64_t *a1, uint64_t a2, uint64_t *a3)
{
  return protocol witness for RandomAccessCollection.index(_:offsetBy:limitedBy:) in conformance CMLSequence(a1, a2, a3);
}

{
  uint64_t v3;
  uint64_t v4;
  uint64_t result;
  char v6;

  int v4 = v3;
  uint64_t result = specialized RandomAccessCollection.index(_:offsetBy:limitedBy:)(*a1, a2, *a3, specialized RandomAccessCollection<>.distance(from:to:), CMLSequence.size.getter);
  *(void *)int v4 = result;
  *(unsigned char *)(v4 + 8) = v6 & 1;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.index(before:) in conformance CMLSequence(uint64_t *a1)
{
  uint64_t v2 = v1;
  uint64_t result = specialized RandomAccessCollection<>.index(before:)(*a1, CMLSequence.size.getter);
  *uint64_t v2 = result;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.formIndex(before:) in conformance CMLSequence(uint64_t *a1)
{
  uint64_t result = specialized RandomAccessCollection<>.index(before:)(*a1, CMLSequence.size.getter);
  *a1 = result;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance CMLSequence(uint64_t *a1, uint64_t a2)
{
  uint64_t v3 = v2;
  uint64_t result = specialized RandomAccessCollection<>.index(_:offsetBy:)(*a1, a2, CMLSequence.size.getter);
  *uint64_t v3 = result;
  return result;
}

uint64_t protocol witness for BidirectionalCollection.distance(from:to:) in conformance CMLSequence(uint64_t *a1, uint64_t *a2)
{
  return specialized RandomAccessCollection<>.distance(from:to:)(*a1, *a2);
}

uint64_t protocol witness for Collection.endIndex.getter in conformance CMLSequence()
{
  uint64_t v1 = v0;
  uint64_t result = CMLSequence.endIndex.getter();
  *uint64_t v1 = result;
  return result;
}

uint64_t (*protocol witness for Collection.subscript.read in conformance CMLSequence(uint64_t *a1, uint64_t *a2))(uint64_t a1)
{
  uint64_t v2 = CMLSequence.subscript.getter(*a2);
  a1[1] = v2;
  *a1 = v2;
  return protocol witness for Collection.subscript.read in conformance CMLSequence;
}

uint64_t protocol witness for Collection.subscript.read in conformance CMLSequence(uint64_t a1)
{
  return swift_release(*(void *)(a1 + 8));
}

uint64_t protocol witness for Collection.subscript.getter in conformance CMLSequence(uint64_t *a1)
{
  uint64_t v2 = v1;
  uint64_t result = specialized Collection<>.subscript.getter(*a1, a1[1], CMLSequence.size.getter);
  *uint64_t v2 = result;
  v2[1] = v4;
  v2[2] = v5;
  return result;
}

uint64_t protocol witness for Collection.indices.getter in conformance CMLSequence()
{
  uint64_t v1 = v0;
  uint64_t result = specialized RandomAccessCollection<>.indices.getter(CMLSequence.size.getter);
  *uint64_t v1 = result;
  v1[1] = v3;
  return result;
}

BOOL protocol witness for Collection.isEmpty.getter in conformance CMLSequence()
{
  return specialized Collection.isEmpty.getter();
}

uint64_t protocol witness for Collection.count.getter in conformance CMLSequence()
{
  return specialized Collection.count.getter();
}

void protocol witness for Collection._failEarlyRangeCheck(_:bounds:) in conformance CMLSequence(uint64_t *a1, uint64_t *a2)
{
}

{
  specialized Collection._failEarlyRangeCheck(_:bounds:)(*a1, *a2, a2[1]);
}

{
  specialized Collection._failEarlyRangeCheck(_:bounds:)(*a1, a1[1], *a2, a2[1]);
}

uint64_t protocol witness for Collection.index(after:) in conformance CMLSequence(uint64_t *a1)
{
  uint64_t v2 = v1;
  uint64_t result = specialized RandomAccessCollection<>.index(after:)(*a1);
  *uint64_t v2 = result;
  return result;
}

uint64_t protocol witness for Collection.formIndex(after:) in conformance CMLSequence(uint64_t *a1)
{
  uint64_t result = specialized RandomAccessCollection<>.index(after:)(*a1);
  *a1 = result;
  return result;
}

uint64_t protocol witness for Sequence.underestimatedCount.getter in conformance CMLSequence()
{
  return specialized Collection.underestimatedCount.getter();
}

void *protocol witness for Sequence._copyToContiguousArray() in conformance CMLSequence()
{
  return specialized Collection._copyToContiguousArray()();
}

uint64_t protocol witness for Sequence._copyContents(initializing:) in conformance CMLSequence(void *a1, uint64_t a2, uint64_t a3)
{
  return specialized Sequence._copyContents(initializing:)(a1, a2, a3);
}

unsigned char *static MLDataValue.SequenceType.dataValueType.getter()
{
  *uint64_t result = 3;
  return result;
}

void MLDataValue.SequenceType.init(from:)(uint64_t a1)
{
  uint64_t v3 = v1;
  uint64_t v4 = *(void **)a1;
  char v5 = *(unsigned char *)(a1 + 16);
  if (v5 != 3)
  {
    outlined consume of MLDataValue(v4, *(void **)(a1 + 8), v5);
    uint64_t v4 = 0;
  }
  *uint64_t v3 = v4;
}

uint64_t MLDataValue.SequenceType.dataValue.getter()
{
  uint64_t v2 = *v1;
  *(void *)uint64_t v0 = *v1;
  *(void *)(v0 + 8) = 0;
  *(unsigned char *)(v0 + 16) = 3;
  return swift_retain(v2);
}

uint64_t MLDataValue.SequenceType.init(from:)(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t v3 = specialized handling<A, B>(_:_:)(*(void *)(a1 + 16));
  if (!v3) {
    BUG();
  }
  uint64_t v4 = type metadata accessor for CMLSequence();
  uint64_t v5 = swift_allocObject(v4, 25, 7);
  *(void *)(v5 + 16) = v3;
  *(unsigned char *)(v5 + 24) = 1;
  uint64_t result = swift_release();
  *uint64_t v2 = v5;
  return result;
}

uint64_t MLDataValue.SequenceType.featureValue.getter(double a1)
{
  uint64_t v2 = *v1;
  uint64_t v3 = tc_v1_flex_list_create(0);
  if (!v3) {
    BUG();
  }
  uint64_t v4 = v3;
  uint64_t v5 = type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject(v5, v25);
  *(void *)(inited + 16) = v4;
  uint64_t v27 = inited;
  *(unsigned char *)(inited + 24) = 1;
  swift_retain(v2);
  if (CMLSequence.size.getter())
  {
    uint64_t v7 = 0;
    uint64_t v34 = v2;
    while (2)
    {
      swift_retain(v2);
      uint64_t v8 = v2;
      uint64_t v9 = CMLSequence.value(at:)(v7);
      swift_release(v2);
      MLDataValue.init(_:)(v9, a1);
      uint64_t v33 = v30;
      uint64_t v29 = v31;
      int v10 = v32;
      swift_retain(v8);
      uint64_t v11 = CMLSequence.size.getter();
      swift_release(v8);
      if (v7 < v11)
      {
        uint64_t v26 = v7;
        int v28 = v10;
        switch(v10)
        {
          case 0:
            uint64_t v12 = specialized handling<A, B>(_:_:)((uint64_t)v33);
            uint64_t v2 = v34;
            uint64_t v13 = v12;
            if (!v12) {
              BUG();
            }
            goto LABEL_12;
          case 1:
            a1 = *(double *)&v33;
            uint64_t v19 = specialized handling<A, B>(_:_:)();
            uint64_t v2 = v34;
            uint64_t v13 = v19;
            if (!v19) {
              BUG();
            }
LABEL_12:
            uint64_t v20 = type metadata accessor for CMLFeatureValue();
            swift_allocObject(v20, 25, 7);
            uint64_t v18 = CMLFeatureValue.init(rawValue:ownsValue:)(v13, 1);
            goto LABEL_16;
          case 2:
            type metadata accessor for CMLFeatureValue();
            uint64_t v15 = (uint64_t)v29;
            swift_bridgeObjectRetain_n(v29, 2);
            int64_t v16 = v33;
            uint64_t v17 = CMLFeatureValue.__allocating_init(_:)((uint64_t)v33, v15);
            uint64_t v2 = v34;
            uint64_t v18 = v17;
            outlined consume of MLDataValue(v16, v29, 2);
            goto LABEL_16;
          case 3:
            char v30 = v33;
            uint64_t v14 = MLDataValue.SequenceType.featureValue.getter();
            goto LABEL_15;
          case 4:
            char v30 = v33;
            uint64_t v14 = MLDataValue.DictionaryType.featureValue.getter();
            goto LABEL_15;
          case 5:
            char v30 = v33;
            uint64_t v14 = MLDataValue.MultiArrayType.featureValue.getter();
            goto LABEL_15;
          case 6:
            type metadata accessor for CMLFeatureValue();
            uint64_t v14 = CMLFeatureValue.__allocating_init()(0);
LABEL_15:
            uint64_t v18 = v14;
            uint64_t v2 = v34;
LABEL_16:
            CMLSequence.append(_:)(v18);
            swift_release(v18);
            uint64_t v7 = v26 + 1;
            outlined consume of MLDataValue(v33, v29, v28);
            if (v7 == CMLSequence.size.getter()) {
              goto LABEL_17;
            }
            continue;
        }
      }
      break;
    }
    BUG();
  }
LABEL_17:
  swift_release(v2);
  type metadata accessor for CMLFeatureValue();
  uint64_t v21 = v27;
  swift_retain(v27);
  uint64_t v22 = CMLFeatureValue.__allocating_init(_:)(v21);
  swift_setDeallocating(v21);
  uint64_t v23 = CMLFeatureValue.deinit();
  swift_deallocClassInstance(v23, 25, 7);
  return v22;
}

unsigned char *protocol witness for static MLDataValueConvertible.dataValueType.getter in conformance MLDataValue.SequenceType()
{
  return static MLDataValue.SequenceType.dataValueType.getter();
}

void protocol witness for MLDataValueConvertible.init(from:) in conformance MLDataValue.SequenceType(uint64_t a1)
{
}

uint64_t protocol witness for MLDataValueConvertible.init() in conformance MLDataValue.SequenceType()
{
  return MLDataValue.SequenceType.init()();
}

uint64_t protocol witness for MLDataValueConvertible.dataValue.getter in conformance MLDataValue.SequenceType()
{
  return MLDataValue.SequenceType.dataValue.getter();
}

uint64_t protocol witness for FeatureValueConvertible.init(from:) in conformance MLDataValue.SequenceType(uint64_t a1)
{
  return MLDataValue.SequenceType.init(from:)(a1);
}

uint64_t protocol witness for FeatureValueConvertible.featureValue.getter in conformance MLDataValue.SequenceType(double a1)
{
  return MLDataValue.SequenceType.featureValue.getter(a1);
}

unsigned char *static Array<A>.dataValueType.getter()
{
  *uint64_t result = 3;
  return result;
}

uint64_t Array<A>.init(from:)(uint64_t a1, uint64_t a2, uint64_t a3, double a4)
{
  uint64_t v41 = a3;
  uint64_t v5 = 0;
  uint64_t v6 = type metadata accessor for Optional(0, a2);
  uint64_t v7 = *(void *)(v6 - 8);
  int64_t v8 = *(void *)(v7 + 64);
  uint64_t v9 = alloca(v8);
  int v10 = alloca(v8);
  uint64_t v40 = &v39;
  uint64_t v42 = *(void *)(a2 - 8);
  int64_t v11 = *(void *)(v42 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v43 = &v39;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  uint64_t v44 = &v39;
  int64_t v16 = *(void **)a1;
  uint64_t v17 = *(void **)(a1 + 8);
  char v18 = *(unsigned char *)(a1 + 16);
  if (v18 != 3)
  {
    outlined consume of MLDataValue(*(void **)a1, v17, v18);
    return 0;
  }
  uint64_t v46 = v6;
  uint64_t v57 = v17;
  uint64_t v45 = a2;
  uint64_t v19 = Array.init()(a2);
  uint64_t v53 = v19;
  swift_retain();
  if (CMLSequence.size.getter())
  {
    uint64_t v47 = v7;
    uint64_t v20 = 0;
    uint64_t v49 = v16;
    while (1)
    {
      swift_retain();
      uint64_t v21 = CMLSequence.value(at:)(v20);
      swift_release();
      uint64_t v48 = v5;
      if (v5)
      {
        swift_unexpectedError(v48, "CreateML/SequenceType.swift", 27, 1);
        BUG();
      }
      MLDataValue.init(_:)(v21, a4);
      uint64_t v55 = v50;
      uint64_t v54 = v51;
      unsigned __int8 v22 = v52;
      swift_retain();
      uint64_t v23 = CMLSequence.size.getter();
      swift_release();
      if (v20 >= v23) {
        BUG();
      }
      uint64_t v50 = v55;
      uint64_t v51 = v54;
      unsigned __int8 v52 = v22;
      uint64_t v24 = v41;
      uint64_t v56 = *(void (**)(void **, uint64_t, uint64_t))(v41 + 16);
      char v25 = v22;
      outlined copy of MLDataValue(v55, v54, v22);
      uint64_t v26 = (uint64_t)v40;
      uint64_t v27 = v24;
      uint64_t v28 = v45;
      v56(&v50, v45, v27);
      if (__swift_getEnumTagSinglePayload(v26, 1, v28) == 1) {
        break;
      }
      uint64_t v56 = (void (*)(void **, uint64_t, uint64_t))(v20 + 1);
      uint64_t v29 = v44;
      uint64_t v30 = v26;
      uint64_t v31 = v42;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v42 + 32))(v44, v30, v28);
      unsigned __int8 v32 = v43;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v31 + 16))(v43, v29, v28);
      uint64_t v33 = type metadata accessor for Array(0, v28);
      Array.append(_:)(v32, v33);
      outlined consume of MLDataValue(v55, v54, v25);
      uint64_t v34 = v29;
      uint64_t v20 = (uint64_t)v56;
      (*(void (**)(uint64_t *, uint64_t))(v31 + 8))(v34, v28);
      uint64_t v35 = v49;
      uint64_t v36 = CMLSequence.size.getter();
      uint64_t v5 = v48;
      if (v20 == v36)
      {
        swift_release();
        outlined consume of MLDataValue(v35, v57, 3);
        return v53;
      }
    }
    outlined consume of MLDataValue(v55, v54, v25);
    outlined consume of MLDataValue(v49, v57, 3);
    swift_release();
    swift_bridgeObjectRelease(v53);
    (*(void (**)(uint64_t, uint64_t))(v47 + 8))(v26, v46);
    return 0;
  }
  uint64_t v37 = v57;
  outlined consume of MLDataValue(v16, v57, 3);
  outlined consume of MLDataValue(v16, v37, 3);
  return v19;
}

{
  uint64_t v4;
  int64_t v5;
  void *v6;
  void *v7;
  uint64_t v8;
  int64_t v9;
  void *v10;
  void *v11;
  void *v12;
  void *v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t inited;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  unsigned char *v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  unsigned char *v29;
  uint64_t v30;
  uint64_t v31;
  unsigned char *v32;
  uint64_t v33;
  unsigned char *v34;
  uint64_t v35;
  unsigned char v37[16];
  char v38[32];
  uint64_t v39;
  unsigned char *v40;
  uint64_t v41;
  unsigned char *v42;
  unsigned char *v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;
  uint64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;

  uint64_t v41 = a3;
  uint64_t v45 = type metadata accessor for Optional(0, a2);
  uint64_t v4 = *(void *)(v45 - 8);
  uint64_t v5 = *(void *)(v4 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  uint64_t v40 = v37;
  int64_t v8 = *(void *)(a2 - 8);
  uint64_t v9 = *(void *)(v8 + 64);
  int v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v42 = v37;
  uint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  uint64_t v43 = v37;
  uint64_t v14 = 0;
  uint64_t v15 = specialized handling<A, B>(_:_:)(*(void *)(a1 + 16));
  uint64_t v51 = a1;
  uint64_t v44 = v8;
  uint64_t v49 = a2;
  uint64_t v46 = v4;
  if (!v15) {
    BUG();
  }
  int64_t v16 = v15;
  uint64_t v17 = type metadata accessor for CMLSequence();
  uint64_t inited = swift_initStackObject(v17, v38);
  *(void *)(inited + 16) = v16;
  *(unsigned char *)(inited + 24) = 1;
  uint64_t v19 = Array.init()(v49);
  uint64_t v50 = v19;
  swift_retain();
  if (CMLSequence.size.getter())
  {
    uint64_t v20 = 0;
    while (1)
    {
      uint64_t v21 = CMLSequence.value(at:)(v20);
      uint64_t v48 = v14;
      if (v14)
      {
        swift_unexpectedError(v48, "CreateML/SequenceType.swift", 27, 1);
        BUG();
      }
      unsigned __int8 v22 = v21;
      swift_retain();
      uint64_t v23 = specialized RandomAccessCollection<>.index(after:)(v20);
      swift_release();
      uint64_t v24 = inited;
      char v25 = v40;
      uint64_t v47 = v22;
      uint64_t v26 = v49;
      static MLDataValueConvertible.makeInstance(featureValue:)(v22, v49, v41, a4);
      uint64_t v27 = (uint64_t)v25;
      uint64_t v28 = v26;
      if (__swift_getEnumTagSinglePayload(v27, 1, v26) == 1) {
        break;
      }
      uint64_t v39 = v23;
      uint64_t v29 = v43;
      uint64_t v30 = v27;
      uint64_t v31 = v44;
      (*(void (**)(unsigned char *, uint64_t, uint64_t))(v44 + 32))(v43, v30, v26);
      unsigned __int8 v32 = v42;
      (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v31 + 16))(v42, v29, v28);
      uint64_t v33 = type metadata accessor for Array(0, v28);
      Array.append(_:)(v32, v33);
      swift_release();
      uint64_t v34 = v29;
      uint64_t v20 = v39;
      (*(void (**)(unsigned char *, uint64_t))(v31 + 8))(v34, v28);
      uint64_t inited = v24;
      uint64_t v35 = CMLSequence.size.getter();
      uint64_t v14 = v48;
      if (v20 == v35)
      {
        swift_release();
        swift_release();
        uint64_t v19 = v50;
        goto LABEL_9;
      }
    }
    swift_release_n(v24);
    swift_release();
    swift_release();
    swift_bridgeObjectRelease(v50);
    (*(void (**)(uint64_t, uint64_t))(v46 + 8))(v27, v45);
    return 0;
  }
  else
  {
    swift_release();
    swift_release();
LABEL_9:
    swift_release();
  }
  return v19;
}

uint64_t Array<A>.dataValue.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v19 = a3;
  char v18 = v3;
  *(void *)&long long v13 = a1;
  uint64_t v4 = type metadata accessor for Array(0, a2);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for [A], v4);
  uint64_t v20 = WitnessTable;
  Sequence.lazy.getter(v4, WitnessTable);
  uint64_t v17 = v15;
  uint64_t v6 = swift_allocObject(&unk_399820, 32, 7);
  *(void *)(v6 + 16) = a2;
  *(void *)(v6 + 24) = v19;
  uint64_t v7 = type metadata accessor for LazySequence(0, v4, WitnessTable);
  uint64_t v8 = swift_getWitnessTable(&protocol conformance descriptor for LazySequence<A>, v7);
  LazySequenceProtocol.map<A>(_:)(partial apply for closure #1 in Array<A>.dataValue.getter, v6, v7, &type metadata for MLDataValue, v8);
  swift_release();
  swift_bridgeObjectRelease(v17);
  long long v15 = v13;
  uint64_t v16 = v14;
  uint64_t v9 = type metadata accessor for LazyMapSequence(0, v4, &type metadata for MLDataValue, v20);
  int v10 = (void *)swift_getWitnessTable(&protocol conformance descriptor for LazyMapSequence<A, B>, v9);
  MLDataValue.SequenceType.init<A>(_:)((uint64_t)&v15, v9, v10, *(double *)&a1);
  uint64_t result = v17;
  uint64_t v12 = v18;
  *char v18 = v17;
  v12[1] = 0;
  *((unsigned char *)v12 + 16) = 3;
  return result;
}

uint64_t Array<A>.featureSequence.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v30 = a3;
  uint64_t v3 = a1;
  uint64_t v38 = 0;
  uint64_t v37 = *(void *)(a2 - 8);
  int64_t v4 = *(void *)(v37 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v31 = &v28;
  int64_t v33 = v4;
  uint64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  uint64_t v9 = &v28;
  uint64_t v10 = tc_v1_flex_list_create(0);
  if (!v10) {
    BUG();
  }
  uint64_t v11 = v10;
  uint64_t v12 = type metadata accessor for CMLSequence();
  uint64_t v13 = swift_allocObject(v12, 25, 7);
  *(void *)(v13 + 16) = v11;
  uint64_t v35 = v13;
  *(unsigned char *)(v13 + 24) = 1;
  swift_bridgeObjectRetain(a1);
  uint64_t v14 = Array.startIndex.getter(a1, a2);
  Swift::Int after = v14;
  if (v14 != Array.endIndex.getter(a1, a2))
  {
    uint64_t v36 = a1;
    unsigned __int8 v32 = &v28;
    do
    {
      Swift::Bool IsNativeType = Array._hoistableIsNativeTypeChecked()();
      Array._checkSubscript(_:wasNativeTypeChecked:)(v14, IsNativeType, v3, a2);
      if (IsNativeType)
      {
        uint64_t v17 = v37;
        (*(void (**)(uint64_t *, uint64_t, uint64_t))(v37 + 16))(v9, v3 + ((*(unsigned __int8 *)(v37 + 80) + 32) & ~*(unsigned __int8 *)(v37 + 80)) + *(void *)(v37 + 72) * v14, a2);
        char v18 = v9;
      }
      else
      {
        uint64_t v23 = _ArrayBuffer._getElementSlowPath(_:)(v14, v3, a2);
        if (v33 != 8) {
          BUG();
        }
        uint64_t v24 = v23;
        uint64_t v29 = v23;
        char v25 = v9;
        char v18 = v9;
        uint64_t v26 = v37;
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v37 + 16))(v25, &v29, a2);
        uint64_t v27 = v24;
        uint64_t v17 = v26;
        swift_unknownObjectRelease(v27);
        LOBYTE(v3) = v36;
      }
      swift_bridgeObjectRetain(v3);
      Array.formIndex(after:)(&after);
      swift_bridgeObjectRelease(v3);
      uint64_t v19 = v31;
      (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v17 + 32))(v31, v18, a2);
      uint64_t v20 = MLDataValueConvertible.featureValue.getter(a2, v30);
      uint64_t v21 = v38;
      CMLSequence.append(_:)(v20);
      uint64_t v38 = v21;
      if (v21)
      {
        swift_release();
        swift_unexpectedError(v38, "CreateML/SequenceType.swift", 27, 1);
        BUG();
      }
      (*(void (**)(uint64_t *, uint64_t))(v37 + 8))(v19, a2);
      swift_release();
      uint64_t v14 = after;
      uint64_t v3 = v36;
      uint64_t v22 = Array.endIndex.getter(v36, a2);
      uint64_t v9 = v32;
    }
    while (v14 != v22);
  }
  swift_bridgeObjectRelease(v3);
  return v35;
}

uint64_t Array<A>.featureColumn.getter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = Array<A>.featureSequence.getter(a1, a2, a3);
  (*(void (**)(uint64_t, uint64_t))(a3 + 8))(a2, a3);
  type metadata accessor for CMLColumn();
  return CMLColumn.__allocating_init(_:type:)(v4, 0x5060403020100uLL >> (8 * v6));
}

unsigned char *protocol witness for static MLDataValueConvertible.dataValueType.getter in conformance <A> [A]()
{
  return static Array<A>.dataValueType.getter();
}

uint64_t protocol witness for MLDataValueConvertible.init(from:) in conformance <A> [A](uint64_t a1, uint64_t a2, uint64_t a3, double a4)
{
  uint64_t v5 = v4;
  uint64_t result = Array<A>.init(from:)(a1, *(void *)(a2 + 16), *(void *)(a3 - 8), a4);
  uint64_t *v5 = result;
  return result;
}

uint64_t protocol witness for MLDataValueConvertible.init() in conformance <A> [A](uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t result = Array.init()(*(void *)(a1 + 16));
  *uint64_t v2 = result;
  return result;
}

uint64_t protocol witness for MLDataValueConvertible.dataValue.getter in conformance <A> [A](uint64_t a1, uint64_t a2)
{
  return Array<A>.dataValue.getter(*v2, *(void *)(a1 + 16), *(void *)(a2 - 8));
}

uint64_t protocol witness for FeatureValueConvertible.init(from:) in conformance <A> [A](uint64_t a1, uint64_t a2, uint64_t a3, double a4)
{
  uint64_t v5 = v4;
  uint64_t result = Array<A>.init(from:)(a1, *(void *)(a2 + 16), *(void *)(a3 - 8), a4);
  uint64_t *v5 = result;
  return result;
}

uint64_t protocol witness for FeatureValueConvertible.featureValue.getter in conformance <A> [A](uint64_t a1, uint64_t a2)
{
  return Array<A>.featureValue.getter(*v2, *(void *)(a1 + 16), *(void *)(a2 - 8));
}

uint64_t protocol witness for CMLColumnConvertible.featureColumn.getter in conformance <A> [A](uint64_t a1, uint64_t a2)
{
  return Array<A>.featureColumn.getter(*v2, *(void *)(a1 + 16), *(void *)(a2 - 8));
}

uint64_t outlined copy of MLDataValue(void *a1, void *a2, unsigned __int8 a3)
{
  uint64_t result = a3 - 2;
  switch(a3)
  {
    case 2u:
      a1 = a2;
      goto LABEL_3;
    case 3u:
      uint64_t result = swift_retain(a1);
      break;
    case 4u:
LABEL_3:
      uint64_t result = swift_bridgeObjectRetain(a1);
      break;
    case 5u:
      uint64_t result = a1;
      break;
    default:
      return result;
  }
  return result;
}

uint64_t sub_135DD7()
{
  return swift_deallocObject(v0, 32, 7);
}

uint64_t partial apply for closure #1 in Array<A>.dataValue.getter()
{
  return (*(uint64_t (**)(void))(*(void *)(v0 + 24) + 32))(*(void *)(v0 + 16));
}

uint64_t base witness table accessor for BidirectionalCollection in MLDataValue.SequenceType()
{
  return lazy protocol witness table accessor for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType();
}

uint64_t associated type witness table accessor for Collection.SubSequence : RandomAccessCollection in MLDataValue.SequenceType()
{
  return lazy protocol witness table accessor for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>(&lazy protocol witness table cache variable for type Slice<MLDataValue.SequenceType> and conformance <> Slice<A>, &demangling cache variable for type metadata for Slice<MLDataValue.SequenceType>, (void (*)(void))lazy protocol witness table accessor for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType, (uint64_t)&protocol conformance descriptor for <> Slice<A>);
}

uint64_t lazy protocol witness table accessor for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>(uint64_t *a1, uint64_t *a2, void (*a3)(void), uint64_t a4)
{
  uint64_t result = *a1;
  if (!*a1)
  {
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledNameAbstract(a2);
    a3();
    uint64_t result = swift_getWitnessTable(a4, v7);
    *a1 = result;
  }
  return result;
}

uint64_t base witness table accessor for Collection in MLDataValue.SequenceType()
{
  return lazy protocol witness table accessor for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType();
}

uint64_t associated type witness table accessor for Collection.SubSequence : BidirectionalCollection in MLDataValue.SequenceType()
{
  return lazy protocol witness table accessor for type LazyMapSequence<MLDataValue.SequenceType, String> and conformance <> LazyMapSequence<A, B>(&lazy protocol witness table cache variable for type Slice<MLDataValue.SequenceType> and conformance <> Slice<A>, &demangling cache variable for type metadata for Slice<MLDataValue.SequenceType>, (void (*)(void))lazy protocol witness table accessor for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType, (uint64_t)&protocol conformance descriptor for <> Slice<A>);
}

uint64_t base witness table accessor for Sequence in MLDataValue.SequenceType()
{
  return lazy protocol witness table accessor for type MLDataValue.SequenceType and conformance MLDataValue.SequenceType();
}

uint64_t associated type witness table accessor for Collection.SubSequence : Collection in MLDataValue.SequenceType()
{
  return lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Slice<MLDataValue.SequenceType> and conformance Slice<A>, &demangling cache variable for type metadata for Slice<MLDataValue.SequenceType>, (uint64_t)&protocol conformance descriptor for Slice<A>);
}

uint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in MLDataValue.SequenceType()
{
  return lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type IndexingIterator<MLDataValue.SequenceType> and conformance IndexingIterator<A>, &demangling cache variable for type metadata for IndexingIterator<MLDataValue.SequenceType>, (uint64_t)&protocol conformance descriptor for IndexingIterator<A>);
}

uint64_t instantiation function for generic protocol witness table for <A> [A](uint64_t a1, uint64_t a2)
{
  uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for <A> [A], a2);
  *(void *)(a1 + 8) = result;
  return result;
}

uint64_t associated type witness table accessor for Sequence.Iterator : IteratorProtocol in CMLSequence()
{
  return lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type IndexingIterator<CMLSequence> and conformance IndexingIterator<A>, &demangling cache variable for type metadata for IndexingIterator<CMLSequence>, (uint64_t)&protocol conformance descriptor for IndexingIterator<A>);
}

uint64_t base witness table accessor for Sequence in CMLSequence()
{
  return lazy protocol witness table accessor for type CMLSequence and conformance CMLSequence(&lazy protocol witness table cache variable for type CMLSequence and conformance CMLSequence, (uint64_t)&protocol conformance descriptor for CMLSequence);
}

uint64_t associated type witness table accessor for Collection.SubSequence : Collection in CMLSequence()
{
  return lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Slice<CMLSequence> and conformance Slice<A>, &demangling cache variable for type metadata for Slice<CMLSequence>, (uint64_t)&protocol conformance descriptor for Slice<A>);
}

uint64_t base witness table accessor for Collection in CMLSequence()
{
  return lazy protocol witness table accessor for type CMLSequence and conformance CMLSequence(&lazy protocol witness table cache variable for type CMLSequence and conformance CMLSequence, (uint64_t)&protocol conformance descriptor for CMLSequence);
}

uint64_t associated type witness table accessor for Collection.SubSequence : BidirectionalCollection in CMLSequence()
{
  return lazy protocol witness table accessor for type Slice<CMLSequence> and conformance <> Slice<A>(&lazy protocol witness table cache variable for type Slice<CMLSequence> and conformance <> Slice<A>, &lazy protocol witness table cache variable for type CMLSequence and conformance CMLSequence, (uint64_t)&protocol conformance descriptor for CMLSequence, (uint64_t)&protocol conformance descriptor for <> Slice<A>);
}

uint64_t lazy protocol witness table accessor for type Slice<CMLSequence> and conformance <> Slice<A>(uint64_t *a1, uint64_t *a2, uint64_t a3, uint64_t a4)
{
  uint64_t result = *a1;
  if (!*a1)
  {
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for Slice<CMLSequence>);
    lazy protocol witness table accessor for type CMLSequence and conformance CMLSequence(a2, a3);
    uint64_t result = swift_getWitnessTable(a4, v7);
    *a1 = result;
  }
  return result;
}

uint64_t base witness table accessor for BidirectionalCollection in CMLSequence()
{
  return lazy protocol witness table accessor for type CMLSequence and conformance CMLSequence(&lazy protocol witness table cache variable for type CMLSequence and conformance CMLSequence, (uint64_t)&protocol conformance descriptor for CMLSequence);
}

uint64_t associated type witness table accessor for Collection.SubSequence : RandomAccessCollection in CMLSequence()
{
  return lazy protocol witness table accessor for type Slice<CMLSequence> and conformance <> Slice<A>(&lazy protocol witness table cache variable for type Slice<CMLSequence> and conformance <> Slice<A>, &lazy protocol witness table cache variable for type CMLSequence and conformance CMLSequence, (uint64_t)&protocol conformance descriptor for CMLSequence, (uint64_t)&protocol conformance descriptor for <> Slice<A>);
}

uint64_t lazy protocol witness table accessor for type CMLSequence and conformance CMLSequence(uint64_t *a1, uint64_t a2)
{
  uint64_t result = *a1;
  if (!*a1)
  {
    uint64_t v3 = type metadata accessor for CMLSequence();
    uint64_t result = swift_getWitnessTable(a2, v3);
    *a1 = result;
  }
  return result;
}

uint64_t outlined retain of Range<MLDataValue.DictionaryType.Index>(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 24);
  uint64_t v2 = *(void *)(a1 + 32);
  int v3 = *(_DWORD *)(a1 + 40);
  outlined copy of [A : B].Index._Variant<A, B>(*(void *)a1, *(void *)(a1 + 8), *(_DWORD *)(a1 + 16));
  outlined copy of [A : B].Index._Variant<A, B>(v1, v2, v3);
  return a1;
}

uint64_t protocol witness for RandomAccessCollection.distance(from:to:) in conformance MLDataValue.SequenceType(uint64_t *a1, uint64_t *a2)
{
  return protocol witness for BidirectionalCollection.distance(from:to:) in conformance MLDataValue.SequenceType(a1, a2);
}

uint64_t protocol witness for RandomAccessCollection.distance(from:to:) in conformance CMLSequence(uint64_t *a1, uint64_t *a2)
{
  return protocol witness for BidirectionalCollection.distance(from:to:) in conformance CMLSequence(a1, a2);
}

uint64_t protocol witness for RandomAccessCollection.index(_:offsetBy:) in conformance MLDataValue.SequenceType(uint64_t *a1, uint64_t a2)
{
  return protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance MLDataValue.SequenceType(a1, a2);
}

uint64_t protocol witness for RandomAccessCollection.index(_:offsetBy:) in conformance CMLSequence(uint64_t *a1, uint64_t a2)
{
  return protocol witness for BidirectionalCollection.index(_:offsetBy:) in conformance CMLSequence(a1, a2);
}

uint64_t protocol witness for Collection._customLastIndexOfEquatableElement(_:) in conformance CMLSequence()
{
  return protocol witness for Collection._customIndexOfEquatableElement(_:) in conformance MLDataTable.ColumnNames();
}

void *initializeBufferWithCopyOfBuffer for MLLogisticRegressionClassifier.Model(void *a1, void *a2, uint64_t a3)
{
  int v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v9 = *a2;
    *int v3 = *a2;
    int v3 = (void *)(v9 + ((v4 + 16) & ~v4));
    swift_retain(v9);
  }
  else
  {
    *a1 = *a2;
    uint64_t v6 = a2[1];
    v3[1] = v6;
    uint64_t v7 = a2[2];
    swift_bridgeObjectRetain(v6);
    if (v7)
    {
      v3[2] = v7;
      void v3[3] = a2[3];
      uint64_t v8 = a2[4];
      void v3[4] = v8;
      swift_bridgeObjectRetain(v7);
      swift_bridgeObjectRetain(v8);
    }
    else
    {
      void v3[4] = a2[4];
      *((_OWORD *)v3 + 1) = *((_OWORD *)a2 + 1);
    }
    uint64_t v10 = *(int *)(a3 + 24);
    uint64_t v11 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 16))((char *)v3 + v10, (char *)a2 + v10, v11);
    uint64_t v12 = *(int *)(a3 + 28);
    uint64_t v13 = *(void *)((char *)a2 + v12);
    char v14 = *((unsigned char *)a2 + v12 + 8);
    *(void *)((char *)v3 + v12) = v13;
    *((unsigned char *)v3 + v12 + 8) = v14;
    swift_bridgeObjectRetain(v13);
  }
  return v3;
}

uint64_t destroy for MLLogisticRegressionClassifier.Model(void *a1, uint64_t a2)
{
  swift_bridgeObjectRelease(a1[1]);
  uint64_t v3 = a1[2];
  if (v3)
  {
    swift_bridgeObjectRelease(v3);
    swift_bridgeObjectRelease(a1[4]);
  }
  int v4 = (char *)a1 + *(int *)(a2 + 24);
  uint64_t v5 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  (*(void (**)(char *, uint64_t))(*(void *)(v5 - 8) + 8))(v4, v5);
  return swift_bridgeObjectRelease(*(void *)((char *)a1 + *(int *)(a2 + 28)));
}

void *initializeWithCopy for MLLogisticRegressionClassifier.Model(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v5 = a2[1];
  a1[1] = v5;
  uint64_t v6 = a2[2];
  swift_bridgeObjectRetain(v5);
  if (v6)
  {
    a1[2] = v6;
    a1[3] = a2[3];
    uint64_t v7 = a2[4];
    a1[4] = v7;
    swift_bridgeObjectRetain(v6);
    swift_bridgeObjectRetain(v7);
  }
  else
  {
    a1[4] = a2[4];
    *((_OWORD *)a1 + 1) = *((_OWORD *)a2 + 1);
  }
  uint64_t v8 = *(int *)(a3 + 24);
  uint64_t v9 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))((char *)a1 + v8, (char *)a2 + v8, v9);
  uint64_t v10 = *(int *)(a3 + 28);
  uint64_t v11 = *(void *)((char *)a2 + v10);
  char v12 = *((unsigned char *)a2 + v10 + 8);
  *(void *)((char *)a1 + v10) = v11;
  *((unsigned char *)a1 + v10 + 8) = v12;
  swift_bridgeObjectRetain(v11);
  return a1;
}

void *assignWithCopy for MLLogisticRegressionClassifier.Model(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v4 = a2[1];
  uint64_t v5 = a1[1];
  a1[1] = v4;
  swift_bridgeObjectRetain(v4);
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = a1 + 2;
  uint64_t v7 = a2 + 2;
  uint64_t v8 = a1[2];
  uint64_t v9 = a2[2];
  if (v8)
  {
    if (v9)
    {
      a1[2] = v9;
      swift_bridgeObjectRetain(v9);
      swift_bridgeObjectRelease(v8);
      a1[3] = a2[3];
      uint64_t v10 = a2[4];
      uint64_t v11 = a1[4];
      a1[4] = v10;
      swift_bridgeObjectRetain(v10);
      swift_bridgeObjectRelease(v11);
    }
    else
    {
      outlined destroy of FeatureVectorizer<Double>.Transformer((uint64_t)(a1 + 2));
      _OWORD *v6 = *v7;
      a1[4] = a2[4];
    }
  }
  else if (v9)
  {
    a1[2] = v9;
    a1[3] = a2[3];
    uint64_t v12 = a2[4];
    a1[4] = v12;
    swift_bridgeObjectRetain(v9);
    swift_bridgeObjectRetain(v12);
  }
  else
  {
    a1[4] = a2[4];
    _OWORD *v6 = *v7;
  }
  uint64_t v13 = *(int *)(a3 + 24);
  uint64_t v14 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 24))((char *)a1 + v13, (char *)a2 + v13, v14);
  uint64_t v15 = *(int *)(a3 + 28);
  uint64_t v16 = *(void *)((char *)a2 + v15);
  char v17 = *((unsigned char *)a2 + v15 + 8);
  uint64_t v18 = *(void *)((char *)a1 + v15);
  *(void *)((char *)a1 + v15) = v16;
  *((unsigned char *)a1 + v15 + 8) = v17;
  swift_bridgeObjectRetain(v16);
  swift_bridgeObjectRelease(v18);
  return a1;
}

uint64_t outlined destroy of FeatureVectorizer<Double>.Transformer(uint64_t a1)
{
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t initializeWithTake for MLLogisticRegressionClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(_OWORD *)(a1 + 16) = *(_OWORD *)(a2 + 16);
  *(void *)(a1 + 32) = *(void *)(a2 + 32);
  uint64_t v4 = *(int *)(a3 + 24);
  uint64_t v5 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 32))(a1 + v4, a2 + v4, v5);
  uint64_t v6 = *(int *)(a3 + 28);
  *(unsigned char *)(a1 + v6 + 8) = *(unsigned char *)(a2 + v6 + 8);
  *(void *)(a1 + v6) = *(void *)(a2 + v6);
  return a1;
}

void *assignWithTake for MLLogisticRegressionClassifier.Model(void *a1, void *a2, uint64_t a3)
{
  *a1 = *a2;
  uint64_t v5 = a1[1];
  a1[1] = a2[1];
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = a1 + 2;
  uint64_t v7 = a2 + 2;
  uint64_t v8 = a1[2];
  if (v8)
  {
    uint64_t v9 = a2[2];
    if (v9)
    {
      a1[2] = v9;
      swift_bridgeObjectRelease(v8);
      a1[3] = a2[3];
      uint64_t v10 = a1[4];
      a1[4] = a2[4];
      swift_bridgeObjectRelease(v10);
    }
    else
    {
      outlined destroy of FeatureVectorizer<Double>.Transformer((uint64_t)(a1 + 2));
      _OWORD *v6 = *v7;
      a1[4] = a2[4];
    }
  }
  else
  {
    a1[4] = a2[4];
    _OWORD *v6 = *v7;
  }
  uint64_t v11 = *(int *)(a3 + 24);
  uint64_t v12 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 40))((char *)a1 + v11, (char *)a2 + v11, v12);
  uint64_t v13 = *(int *)(a3 + 28);
  char v14 = *((unsigned char *)a2 + v13 + 8);
  uint64_t v15 = *(void *)((char *)a1 + v13);
  *(void *)((char *)a1 + v13) = *(void *)((char *)a2 + v13);
  *((unsigned char *)a1 + v13 + 8) = v14;
  swift_bridgeObjectRelease(v15);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLogisticRegressionClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_136703);
}

uint64_t sub_136703(uint64_t a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t result = 0;
    if ((*(void *)(a1 + 8) & 0xFFFFFFFF00000001) == 0) {
      return (*(void *)(a1 + 8) >> 1) + 1;
    }
  }
  else
  {
    uint64_t v5 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
    return __swift_getEnumTagSinglePayload(*(int *)(a3 + 24) + a1, a2, v5);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLLogisticRegressionClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_13678B);
}

uint64_t sub_13678B(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(a1 + 8) = 2 * (a2 - 1);
  }
  else
  {
    uint64_t v5 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
    return __swift_storeEnumTagSinglePayload(*(int *)(a4 + 24) + a1, a2, a2, v5);
  }
  return result;
}

uint64_t type metadata accessor for MLLogisticRegressionClassifier.Model(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLLogisticRegressionClassifier.Model;
  if (!type metadata singleton initialization cache for MLLogisticRegressionClassifier.Model) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLLogisticRegressionClassifier.Model);
  }
  return result;
}

uint64_t type metadata completion function for MLLogisticRegressionClassifier.Model(uint64_t a1)
{
  v3[0] = &unk_34B5E8;
  v3[1] = &unk_34B600;
  uint64_t result = type metadata accessor for BaseLogisticRegressionClassifierModel(319);
  if (v2 <= 0x3F)
  {
    v3[2] = *(void *)(result - 8) + 64;
    void v3[3] = &unk_34B618;
    swift_initStructMetadata(a1, 256, 4, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t MLLogisticRegressionClassifier.Model.computeMetrics(on:)(uint64_t a1)
{
  v14[0] = v1;
  int64_t v4 = *(void *)(*(void *)(type metadata accessor for AnyColumn(0) - 8) + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v15 = v14;
  uint64_t v7 = alloca(v4);
  uint64_t v8 = alloca(v4);
  uint64_t v20 = v14;
  uint64_t v17 = type metadata accessor for DataFrame(0);
  uint64_t v16 = *(void *)(v17 - 8);
  int64_t v9 = *(void *)(v16 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  v14[1] = a1;
  uint64_t result = MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)(a1, 0, 0);
  if (!v2)
  {
    uint64_t v18 = *v3;
    uint64_t v19 = v3[1];
    DataFrame.subscript.getter(v18, v19);
    uint64_t v13 = (uint64_t)v15;
    DataFrame.subscript.getter(v18, v19);
    AnyClassificationMetrics.init(_:_:)((uint64_t)v20, v13);
    return (*(uint64_t (**)(void *, uint64_t))(v16 + 8))(v14, v17);
  }
  return result;
}

uint64_t MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  uint64_t v29 = v4;
  uint64_t v6 = v5;
  uint64_t v30 = a3;
  uint64_t v25 = a2;
  uint64_t v27 = v3;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  uint64_t v24 = *(void *)(v7 - 8);
  int64_t v8 = *(void *)(v24 + 64);
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v11 = v6[2];
  if (!v11)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000001CLL, "ressorModel.swift" + 0x8000000000000000, "CreateML/MLLogisticRegressionClassifier.Model.swift", 51, 2, 28, 0);
    BUG();
  }
  uint64_t result = specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(a1, 1u, v11, v6[3], v6[4]);
  if (!v29)
  {
    uint64_t v28 = 0;
    uint64_t v29 = v7;
    uint64_t v13 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
    uint64_t v26 = &v21;
    uint64_t v14 = BaseLogisticRegressionClassifierModel.applied(features:eventHandler:)(&v21, v25, v30);
    uint64_t v30 = &v21;
    uint64_t v15 = *(int *)(v13 + 28);
    uint64_t v16 = *(void *)((char *)v6 + v15);
    uint64_t v17 = alloca(32);
    uint64_t v18 = alloca(32);
    BOOL v19 = *((unsigned char *)v6 + v15 + 8) == 0;
    uint64_t v23 = v6;
    uint64_t v24 = v16;
    if (v19)
    {
      MLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5((void (*)(uint64_t))partial apply for closure #1 in MLLogisticRegressionClassifier.Model.applied(to:eventHandler:), (uint64_t)&v21, v14);
      swift_bridgeObjectRelease(v14);
      specialized MLLogisticRegressionClassifier.Model.buildDataFrame<A>(_:)((uint64_t)MLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5);
    }
    else
    {
      MLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_AHySSGs5NeverOTg5((void (*)(uint64_t))partial apply for closure #2 in MLLogisticRegressionClassifier.Model.applied(to:eventHandler:), &v21, v14, (uint64_t)v22);
      swift_bridgeObjectRelease(v14);
      specialized MLLogisticRegressionClassifier.Model.buildDataFrame<A>(_:)((uint64_t)MLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5);
    }
    swift_bridgeObjectRelease((_BYTE)MLComponents26ClassificationDistributionVySiGG_AIs5NeverOTg5);
    return (*(uint64_t (**)(uint64_t *, uint64_t))(v24 + 8))(v26, v29);
  }
  return result;
}

uint64_t specialized MLLogisticRegressionClassifier.Model.buildDataFrame<A>(_:)(uint64_t a1)
{
  v28[6] = v1;
  uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  uint64_t v29 = *(void *)(v31 - 8);
  int64_t v4 = *(void *)(v29 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v40 = v28;
  uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<ClassificationDistribution<Int>>);
  uint64_t v30 = *(void *)(v32 - 8);
  int64_t v7 = *(void *)(v30 + 64);
  int64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  int64_t v33 = v28;
  uint64_t v34 = (void *)*v2;
  uint64_t v10 = v2[1];
  uint64_t v38 = v34;
  uint64_t v39 = v10;
  swift_bridgeObjectRetain(v10);
  v11._uint64_t countAndFlagsBits = 0x6C696261626F7250;
  v11._char object = (void *)0xEB00000000797469;
  String.append(_:)(v11);
  uint64_t v36 = v38;
  uint64_t v37 = v39;
  uint64_t v35 = a1;
  uint64_t v38 = (void *)a1;
  swift_bridgeObjectRetain(a1);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<Int>);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [ClassificationDistribution<Int>]);
  uint64_t v14 = lazy protocol witness table accessor for type [String] and conformance [A](&lazy protocol witness table cache variable for type [ClassificationDistribution<Int>] and conformance [A], &demangling cache variable for type metadata for [ClassificationDistribution<Int>]);
  Column.init<A>(name:contents:)(v36, v37, &v38, v12, v13, v14);
  void v28[2] = &type metadata for Int;
  v28[3] = &protocol witness table for Int;
  uint64_t KeyPath = swift_getKeyPath(&unk_34B690);
  swift_bridgeObjectRetain(v10);
  swift_retain();
  MLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n(v35, KeyPath);
  swift_release();
  uint64_t v38 = MLComponents26ClassificationDistributionVySiGG_SiSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_Si_TG5s7KeyPathCyAiKGTf1cn_n;
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Int?]);
  uint64_t v18 = lazy protocol witness table accessor for type [String] and conformance [A](&lazy protocol witness table cache variable for type [Int?] and conformance [A], &demangling cache variable for type metadata for [Int?]);
  Column.init<A>(name:contents:)(v34, v10, &v38, &type metadata for Int, v17, v18);
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  uint64_t v20 = *(void *)(type metadata accessor for AnyColumn(0) - 8);
  uint64_t v21 = swift_allocObject(v19, ((*(unsigned __int8 *)(v20 + 80) + 32) & ~*(unsigned __int8 *)(v20 + 80)) + 2 * *(void *)(v20 + 72), *(unsigned __int8 *)(v20 + 80) | 7);
  *(void *)(v21 + 16) = 2;
  *(void *)(v21 + 24) = 4;
  uint64_t v22 = v31;
  Column.eraseToAnyColumn()(v31);
  uint64_t v23 = v32;
  uint64_t v24 = v33;
  Column.eraseToAnyColumn()(v32);
  uint64_t v38 = (void *)v21;
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  uint64_t v26 = lazy protocol witness table accessor for type [String] and conformance [A](&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn]);
  DataFrame.init<A>(columns:)(&v38, v25, v26);
  (*(void (**)(void *, uint64_t))(v29 + 8))(v40, v22);
  return (*(uint64_t (**)(void *, uint64_t))(v30 + 8))(v24, v23);
}

{
  uint64_t v1;
  void *v2;
  int64_t v4;
  void *v5;
  void *v6;
  int64_t v7;
  void *v8;
  void *v9;
  uint64_t v10;
  Swift::String v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t KeyPath;
  void *MLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  void *v24;
  uint64_t v25;
  uint64_t v26;
  void v28[7];
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  void *v33;
  void *v34;
  uint64_t v35;
  void *v36;
  uint64_t v37;
  void *v38;
  uint64_t v39;
  void *v40;

  v28[6] = v1;
  uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  uint64_t v29 = *(void *)(v31 - 8);
  int64_t v4 = *(void *)(v29 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v40 = v28;
  uint64_t v32 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<ClassificationDistribution<String>>);
  uint64_t v30 = *(void *)(v32 - 8);
  int64_t v7 = *(void *)(v30 + 64);
  int64_t v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  int64_t v33 = v28;
  uint64_t v34 = (void *)*v2;
  uint64_t v10 = v2[1];
  uint64_t v38 = v34;
  uint64_t v39 = v10;
  swift_bridgeObjectRetain(v10);
  v11._uint64_t countAndFlagsBits = 0x6C696261626F7250;
  v11._char object = (void *)0xEB00000000797469;
  String.append(_:)(v11);
  uint64_t v36 = v38;
  uint64_t v37 = v39;
  uint64_t v35 = a1;
  uint64_t v38 = (void *)a1;
  swift_bridgeObjectRetain(a1);
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ClassificationDistribution<String>);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [ClassificationDistribution<String>]);
  uint64_t v14 = lazy protocol witness table accessor for type [String] and conformance [A](&lazy protocol witness table cache variable for type [ClassificationDistribution<String>] and conformance [A], &demangling cache variable for type metadata for [ClassificationDistribution<String>]);
  Column.init<A>(name:contents:)(v36, v37, &v38, v12, v13, v14);
  void v28[2] = &type metadata for String;
  v28[3] = &protocol witness table for String;
  uint64_t KeyPath = swift_getKeyPath(&unk_34B690);
  swift_bridgeObjectRetain(v10);
  swift_retain();
  MLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n(v35, KeyPath);
  swift_release();
  uint64_t v38 = MLComponents26ClassificationDistributionVySSGG_SSSgs5NeverOTg503_s8d81ML22AnyTreeClassifierModelV14buildDataFramey07TabularH00hI0VSay0A12MLComponents26fG26VyxGGSHRzlFxSgAKcfu_SS_TG5s7KeyPathCyAiKGTf1cn_n;
  uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String?]);
  uint64_t v18 = lazy protocol witness table accessor for type [String] and conformance [A](&lazy protocol witness table cache variable for type [String?] and conformance [A], &demangling cache variable for type metadata for [String?]);
  Column.init<A>(name:contents:)(v34, v10, &v38, &type metadata for String, v17, v18);
  uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<AnyColumn>);
  uint64_t v20 = *(void *)(type metadata accessor for AnyColumn(0) - 8);
  uint64_t v21 = swift_allocObject(v19, ((*(unsigned __int8 *)(v20 + 80) + 32) & ~*(unsigned __int8 *)(v20 + 80)) + 2 * *(void *)(v20 + 72), *(unsigned __int8 *)(v20 + 80) | 7);
  *(void *)(v21 + 16) = 2;
  *(void *)(v21 + 24) = 4;
  uint64_t v22 = v31;
  Column.eraseToAnyColumn()(v31);
  uint64_t v23 = v32;
  uint64_t v24 = v33;
  Column.eraseToAnyColumn()(v32);
  uint64_t v38 = (void *)v21;
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnyColumn]);
  uint64_t v26 = lazy protocol witness table accessor for type [String] and conformance [A](&lazy protocol witness table cache variable for type [AnyColumn] and conformance [A], &demangling cache variable for type metadata for [AnyColumn]);
  DataFrame.init<A>(columns:)(&v38, v25, v26);
  (*(void (**)(void *, uint64_t))(v29 + 8))(v40, v22);
  return (*(uint64_t (**)(void *, uint64_t))(v30 + 8))(v24, v23);
}

uint64_t closure #1 in MLLogisticRegressionClassifier.Model.convertDistribution(_:labels:)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 16);
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Classification<Int>);
  Classification.label.getter(v3);
  if (v5[0] < 0 || v5[0] >= v2)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000029, "ClassifierModel.swift" + 0x8000000000000000, "CreateML/MLLogisticRegressionClassifier.Model.swift", 51, 2, 47, 0);
    BUG();
  }
  Classification.label.getter(v3);
  if (v5[0] >= v2) {
    BUG();
  }
  v5[0] = *(void *)(a2 + 8 * v5[0] + 32);
  Classification.probability.getter(v3);
  return Classification.init(label:probability:)(v5, &type metadata for Int, &protocol witness table for Int);
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  void v6[6];

  uint64_t v2 = *(void *)(a2 + 16);
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Classification<Int>);
  Classification.label.getter(v3);
  if (v6[0] < 0 || v6[0] >= v2)
  {
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD000000000000029, "ClassifierModel.swift" + 0x8000000000000000, "CreateML/MLLogisticRegressionClassifier.Model.swift", 51, 2, 57, 0);
    BUG();
  }
  Classification.label.getter(v3);
  if (v6[0] >= v2) {
    BUG();
  }
  int64_t v4 = *(void *)(a2 + 16 * v6[0] + 40);
  v6[0] = *(void *)(a2 + 16 * v6[0] + 32);
  v6[1] = v4;
  swift_bridgeObjectRetain(v4);
  Classification.probability.getter(v3);
  return Classification.init(label:probability:)(v6, &type metadata for String, &protocol witness table for String);
}

uint64_t protocol witness for Transformer.applied(to:eventHandler:) in conformance MLLogisticRegressionClassifier.Model(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4)
{
  MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)(a2, a3, a4);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(*(uint64_t (**)(void))(v4 + 8));
}

uint64_t base witness table accessor for Transformer in MLLogisticRegressionClassifier.Model()
{
  return lazy protocol witness table accessor for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model();
}

uint64_t lazy protocol witness table accessor for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model()
{
  uint64_t result = lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model;
  if (!lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model)
  {
    uint64_t v1 = type metadata accessor for MLLogisticRegressionClassifier.Model(255);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLLogisticRegressionClassifier.Model, v1);
    lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model = result;
  }
  return result;
}

uint64_t partial apply for closure #2 in MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)(uint64_t a1, uint64_t a2)
{
  return closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:)(a1, *(void *)(v2 + 16), *(void *)(v2 + 24), a2, (uint64_t)partial apply for closure #1 in MLLogisticRegressionClassifier.Model.convertDistribution(_:labels:), (uint64_t)&type metadata for String, (uint64_t)&protocol witness table for String);
}

uint64_t partial apply for closure #1 in MLLogisticRegressionClassifier.Model.applied(to:eventHandler:)(uint64_t a1, uint64_t a2)
{
  return closure #1 in AnyTreeClassifierModel.applied(to:eventHandler:)(a1, *(void *)(v2 + 16), *(void *)(v2 + 24), a2, (uint64_t)partial apply for closure #1 in MLLogisticRegressionClassifier.Model.convertDistribution(_:labels:), (uint64_t)&type metadata for Int, (uint64_t)&protocol witness table for Int);
}

uint64_t sub_1373EC(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return key path getter for ClassificationDistribution.mostLikelyLabel : <A>ClassificationDistribution<A>(a1, a2, a3);
}

uint64_t sub_1373F6()
{
  return 16;
}

void sub_137410(_OWORD *a1, _OWORD *a2)
{
  *a2 = *a1;
}

uint64_t partial apply for closure #1 in MLLogisticRegressionClassifier.Model.convertDistribution(_:labels:)(uint64_t a1)
{
  return closure #1 in MLLogisticRegressionClassifier.Model.convertDistribution(_:labels:)(a1, *(void *)(v1 + 16));
}

{
  uint64_t v1;

  return closure #1 in MLLogisticRegressionClassifier.Model.convertDistribution(_:labels:)(a1, *(void *)(v1 + 16));
}

uint64_t *initializeBufferWithCopyOfBuffer for ClassificationMetricsContainer(uint64_t *a1, uint64_t *a2)
{
  return initializeBufferWithCopyOfBuffer for ClassificationMetricsContainer(a1, a2);
}

{
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;

  uint64_t v3 = *a2;
  *a1 = *a2;
  uint64_t v4 = a2[1];
  a1[1] = v4;
  uint64_t v5 = a2[2];
  a1[2] = v5;
  swift_retain(v3);
  swift_retain(v4);
  swift_bridgeObjectRetain(v5);
  return a1;
}

uint64_t destroy for ClassificationMetricsContainer(void *a1)
{
  return swift_bridgeObjectRelease(a1[2]);
}

uint64_t *assignWithCopy for ClassificationMetricsContainer(uint64_t *a1, uint64_t *a2)
{
  uint64_t v3 = *a2;
  uint64_t v4 = *a1;
  *a1 = *a2;
  swift_retain(v3);
  swift_release(v4);
  uint64_t v5 = a2[1];
  uint64_t v6 = a1[1];
  a1[1] = v5;
  swift_retain(v5);
  swift_release(v6);
  uint64_t v7 = a2[2];
  uint64_t v8 = a1[2];
  a1[2] = v7;
  swift_bridgeObjectRetain(v7);
  swift_bridgeObjectRelease(v8);
  return a1;
}

void *assignWithTake for ClassificationMetricsContainer(void *a1, uint64_t a2)
{
  swift_release(*a1);
  uint64_t v3 = a1[1];
  *(_OWORD *)a1 = *(_OWORD *)a2;
  swift_release(v3);
  uint64_t v4 = a1[2];
  a1[2] = *(void *)(a2 + 16);
  swift_bridgeObjectRelease(v4);
  return a1;
}

ValueMetadata *type metadata accessor for ClassificationMetricsContainer()
{
  return &type metadata for ClassificationMetricsContainer;
}

uint64_t ClassificationMetricsContainer.init(classLabels:)(uint64_t a1)
{
  char v2 = a1;
  uint64_t v3 = *(void *)(a1 + 16);
  uint64_t v4 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
  uint64_t v5 = swift_allocObject(v4, *(unsigned int *)(v4 + 48), *(unsigned __int16 *)(v4 + 52));
  swift_bridgeObjectRetain(a1);
  uint64_t v6 = _MetricUtilities.ConfusionMatrixMeter.init(classCount:)(v3);
  if (v1)
  {
    swift_bridgeObjectRelease_n(a1, 2, v7, v8, v9);
  }
  else
  {
    uint64_t v10 = v6;
    swift_allocObject(v4, *(unsigned int *)(v4 + 48), *(unsigned __int16 *)(v4 + 52));
    swift_retain();
    _MetricUtilities.ConfusionMatrixMeter.init(classCount:)(v3);
    swift_bridgeObjectRelease(v2);
    uint64_t v5 = v10;
    swift_release();
  }
  return v5;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> ClassificationMetricsContainer.resetIteration()()
{
  uint64_t v9 = v1;
  uint64_t v2 = v1[2];
  uint64_t v3 = *(void *)(v2 + 16);
  uint64_t v4 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
  swift_allocObject(v4, *(unsigned int *)(v4 + 48), *(unsigned __int16 *)(v4 + 52));
  uint64_t v5 = _MetricUtilities.ConfusionMatrixMeter.init(classCount:)(v3);
  if (!v0)
  {
    uint64_t v8 = v5;
    swift_release();
    *uint64_t v9 = v8;
    uint64_t v6 = *(void *)(v2 + 16);
    swift_allocObject(v4, *(unsigned int *)(v4 + 48), *(unsigned __int16 *)(v4 + 52));
    uint64_t v7 = _MetricUtilities.ConfusionMatrixMeter.init(classCount:)(v6);
    swift_release();
    v9[1] = v7;
  }
}

void *initializeBufferWithCopyOfBuffer for MLLogisticRegressionClassifier.Classifier(void *a1, uint64_t *a2, uint64_t a3)
{
  uint64_t v3 = a1;
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v9 = *a2;
    *uint64_t v3 = *a2;
    uint64_t v3 = (void *)(v9 + ((v4 + 16) & ~v4));
    swift_retain(v9);
  }
  else
  {
    *a1 = *a2;
    uint64_t v6 = a2[1];
    v3[1] = v6;
    uint64_t v7 = a2[2];
    v3[2] = v7;
    void v3[3] = a2[3];
    uint64_t v19 = v3 + 4;
    uint64_t v21 = (long long *)(a2 + 4);
    uint64_t v8 = a2[7];
    swift_bridgeObjectRetain(v6);
    swift_bridgeObjectRetain(v7);
    if (v8)
    {
      v3[7] = v8;
      (**(void (***)(_OWORD *, long long *, uint64_t))(v8 - 8))(v19, v21, v8);
    }
    else
    {
      long long v10 = *v21;
      *((_OWORD *)v3 + 3) = *((_OWORD *)a2 + 3);
      *uint64_t v19 = v10;
    }
    *((_OWORD *)v3 + 4) = *((_OWORD *)a2 + 4);
    *((_OWORD *)v3 + 5) = *((_OWORD *)a2 + 5);
    *((unsigned char *)v3 + 96) = *((unsigned char *)a2 + 96);
    uint64_t v11 = a2[13];
    char v12 = *((unsigned char *)a2 + 112);
    v3[13] = v11;
    *((unsigned char *)v3 + 112) = v12;
    uint64_t v13 = a2[15];
    v3[15] = v13;
    v3[16] = a2[16];
    uint64_t v22 = a2[17];
    v3[17] = v22;
    uint64_t v14 = *(int *)(a3 + 36);
    uint64_t v20 = (char *)v3 + v14;
    uint64_t v15 = (uint64_t)a2 + v14;
    uint64_t v16 = type metadata accessor for BaseLogisticRegressionClassifier(0);
    uint64_t v18 = *(void (**)(char *, uint64_t, uint64_t))(*(void *)(v16 - 8) + 16);
    swift_bridgeObjectRetain(v11);
    swift_bridgeObjectRetain(v13);
    swift_bridgeObjectRetain(v22);
    v18(v20, v15, v16);
  }
  return v3;
}

uint64_t destroy for MLLogisticRegressionClassifier.Classifier(void *a1, uint64_t a2)
{
  swift_bridgeObjectRelease(a1[1]);
  swift_bridgeObjectRelease(a1[2]);
  if (a1[7]) {
    __swift_destroy_boxed_opaque_existential_1Tm(a1 + 4);
  }
  swift_bridgeObjectRelease(a1[13]);
  swift_bridgeObjectRelease(a1[15]);
  swift_bridgeObjectRelease(a1[17]);
  uint64_t v2 = (char *)a1 + *(int *)(a2 + 36);
  uint64_t v3 = type metadata accessor for BaseLogisticRegressionClassifier(0);
  return (*(uint64_t (**)(char *, uint64_t))(*(void *)(v3 - 8) + 8))(v2, v3);
}

uint64_t initializeWithCopy for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v4 = *(void *)(a2 + 8);
  *(void *)(a1 + 8) = v4;
  uint64_t v5 = *(void *)(a2 + 16);
  *(void *)(a1 + 16) = v5;
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  uint64_t v18 = (_OWORD *)(a1 + 32);
  uint64_t v6 = *(void *)(a2 + 56);
  swift_bridgeObjectRetain(v4);
  swift_bridgeObjectRetain(v5);
  if (v6)
  {
    *(void *)(a1 + 56) = v6;
    (**(void (***)(_OWORD *, uint64_t, uint64_t))(v6 - 8))(v18, a2 + 32, v6);
  }
  else
  {
    long long v7 = *(_OWORD *)(a2 + 32);
    *(_OWORD *)(a1 + 48) = *(_OWORD *)(a2 + 48);
    *uint64_t v18 = v7;
  }
  *(_OWORD *)(a1 + 64) = *(_OWORD *)(a2 + 64);
  *(_OWORD *)(a1 + 80) = *(_OWORD *)(a2 + 80);
  *(unsigned char *)(a1 + 96) = *(unsigned char *)(a2 + 96);
  uint64_t v19 = *(void *)(a2 + 104);
  char v8 = *(unsigned char *)(a2 + 112);
  *(void *)(a1 + 104) = v19;
  *(unsigned char *)(a1 + 112) = v8;
  uint64_t v9 = *(void *)(a2 + 120);
  *(void *)(a1 + 120) = v9;
  *(void *)(a1 + 128) = *(void *)(a2 + 128);
  uint64_t v10 = *(void *)(a2 + 136);
  *(void *)(a1 + 136) = v10;
  uint64_t v11 = *(int *)(a3 + 36);
  uint64_t v17 = a1 + v11;
  uint64_t v12 = v11 + a2;
  uint64_t v13 = type metadata accessor for BaseLogisticRegressionClassifier(0);
  uint64_t v15 = *(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v13 - 8) + 16);
  swift_bridgeObjectRetain(v19);
  swift_bridgeObjectRetain(v9);
  swift_bridgeObjectRetain(v10);
  v15(v17, v12, v13);
  return a1;
}

uint64_t assignWithCopy for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v5 = *(void *)(a2 + 8);
  uint64_t v6 = *(void *)(a1 + 8);
  *(void *)(a1 + 8) = v5;
  swift_bridgeObjectRetain(v5);
  swift_bridgeObjectRelease(v6);
  uint64_t v7 = *(void *)(a2 + 16);
  uint64_t v8 = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = v7;
  swift_bridgeObjectRetain(v7);
  swift_bridgeObjectRelease(v8);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  uint64_t v9 = *(void *)(a2 + 56);
  if (!*(void *)(a1 + 56))
  {
    if (v9)
    {
      *(void *)(a1 + 56) = v9;
      (**(void (***)(uint64_t, uint64_t))(v9 - 8))(a1 + 32, a2 + 32);
      goto LABEL_8;
    }
LABEL_7:
    long long v10 = *(_OWORD *)(a2 + 32);
    *(_OWORD *)(a1 + 48) = *(_OWORD *)(a2 + 48);
    *(_OWORD *)(a1 + 32) = v10;
    goto LABEL_8;
  }
  if (!v9)
  {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 32));
    goto LABEL_7;
  }
  __swift_assign_boxed_opaque_existential_0((uint64_t *)(a1 + 32), (uint64_t *)(a2 + 32));
LABEL_8:
  *(void *)(a1 + 64) = *(void *)(a2 + 64);
  *(void *)(a1 + 72) = *(void *)(a2 + 72);
  *(void *)(a1 + 80) = *(void *)(a2 + 80);
  *(void *)(a1 + 88) = *(void *)(a2 + 88);
  *(unsigned char *)(a1 + 96) = *(unsigned char *)(a2 + 96);
  uint64_t v11 = *(void *)(a2 + 104);
  char v12 = *(unsigned char *)(a2 + 112);
  uint64_t v13 = *(void *)(a1 + 104);
  *(void *)(a1 + 104) = v11;
  *(unsigned char *)(a1 + 112) = v12;
  swift_bridgeObjectRetain(v11);
  swift_bridgeObjectRelease(v13);
  uint64_t v14 = *(void *)(a2 + 120);
  uint64_t v15 = *(void *)(a1 + 120);
  *(void *)(a1 + 120) = v14;
  swift_bridgeObjectRetain(v14);
  swift_bridgeObjectRelease(v15);
  *(void *)(a1 + 128) = *(void *)(a2 + 128);
  uint64_t v16 = *(void *)(a2 + 136);
  uint64_t v17 = *(void *)(a1 + 136);
  *(void *)(a1 + 136) = v16;
  swift_bridgeObjectRetain(v16);
  swift_bridgeObjectRelease(v17);
  uint64_t v18 = *(int *)(a3 + 36);
  uint64_t v19 = a1 + v18;
  uint64_t v20 = v18 + a2;
  uint64_t v21 = type metadata accessor for BaseLogisticRegressionClassifier(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v21 - 8) + 24))(v19, v20, v21);
  return a1;
}

uint64_t initializeWithTake for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(_OWORD *)a1 = *(_OWORD *)a2;
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  qmemcpy((void *)(a1 + 24), (const void *)(a2 + 24), 0x49uLL);
  *(unsigned char *)(a1 + 112) = *(unsigned char *)(a2 + 112);
  *(void *)(a1 + 104) = *(void *)(a2 + 104);
  *(_OWORD *)(a1 + 120) = *(_OWORD *)(a2 + 120);
  *(void *)(a1 + 136) = *(void *)(a2 + 136);
  uint64_t v3 = *(int *)(a3 + 36);
  uint64_t v4 = type metadata accessor for BaseLogisticRegressionClassifier(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a1 + v3, a2 + v3, v4);
  return a1;
}

uint64_t assignWithTake for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)a1 = *(void *)a2;
  uint64_t v5 = *(void *)(a1 + 8);
  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  swift_bridgeObjectRelease(v5);
  uint64_t v6 = *(void *)(a1 + 16);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  swift_bridgeObjectRelease(v6);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  if (*(void *)(a1 + 56)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 32));
  }
  long long v7 = *(_OWORD *)(a2 + 32);
  *(_OWORD *)(a1 + 48) = *(_OWORD *)(a2 + 48);
  *(_OWORD *)(a1 + 32) = v7;
  *(_OWORD *)(a1 + 64) = *(_OWORD *)(a2 + 64);
  *(_OWORD *)(a1 + 80) = *(_OWORD *)(a2 + 80);
  *(unsigned char *)(a1 + 96) = *(unsigned char *)(a2 + 96);
  char v8 = *(unsigned char *)(a2 + 112);
  uint64_t v9 = *(void *)(a1 + 104);
  *(void *)(a1 + 104) = *(void *)(a2 + 104);
  *(unsigned char *)(a1 + 112) = v8;
  swift_bridgeObjectRelease(v9);
  uint64_t v10 = *(void *)(a1 + 120);
  *(void *)(a1 + 120) = *(void *)(a2 + 120);
  swift_bridgeObjectRelease(v10);
  *(void *)(a1 + 128) = *(void *)(a2 + 128);
  uint64_t v11 = *(void *)(a1 + 136);
  *(void *)(a1 + 136) = *(void *)(a2 + 136);
  swift_bridgeObjectRelease(v11);
  uint64_t v12 = *(int *)(a3 + 36);
  uint64_t v13 = a1 + v12;
  uint64_t v14 = v12 + a2;
  uint64_t v15 = type metadata accessor for BaseLogisticRegressionClassifier(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v15 - 8) + 40))(v13, v14, v15);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_137D24);
}

uint64_t sub_137D24(uint64_t a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t result = 0;
    if ((*(void *)(a1 + 8) & 0xFFFFFFFF00000001) == 0) {
      return (*(void *)(a1 + 8) >> 1) + 1;
    }
  }
  else
  {
    uint64_t v5 = type metadata accessor for BaseLogisticRegressionClassifier(0);
    return __swift_getEnumTagSinglePayload(*(int *)(a3 + 36) + a1, a2, v5);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_137DAC);
}

uint64_t sub_137DAC(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 0x7FFFFFFF)
  {
    *(void *)(a1 + 8) = 2 * (a2 - 1);
  }
  else
  {
    uint64_t v5 = type metadata accessor for BaseLogisticRegressionClassifier(0);
    return __swift_storeEnumTagSinglePayload(*(int *)(a4 + 36) + a1, a2, a2, v5);
  }
  return result;
}

uint64_t type metadata accessor for MLLogisticRegressionClassifier.Classifier(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLLogisticRegressionClassifier.Classifier;
  if (!type metadata singleton initialization cache for MLLogisticRegressionClassifier.Classifier) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLLogisticRegressionClassifier.Classifier);
  }
  return result;
}

uint64_t type metadata completion function for MLLogisticRegressionClassifier.Classifier(uint64_t a1)
{
  v3[0] = &unk_34B730;
  v3[1] = (char *)&value witness table for Builtin.BridgeObject + 64;
  v3[2] = &unk_34B748;
  void v3[3] = &unk_34B760;
  void v3[4] = &unk_34B778;
  uint64_t result = type metadata accessor for BaseLogisticRegressionClassifier(319);
  if (v2 <= 0x3F)
  {
    void v3[5] = *(void *)(result - 8) + 64;
    swift_initStructMetadata(a1, 256, 6, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t associated type witness table accessor for SupervisedTabularEstimator.Transformer : TabularTransformer in MLLogisticRegressionClassifier.Classifier()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Model and conformance MLLogisticRegressionClassifier.Model, type metadata accessor for MLLogisticRegressionClassifier.Model, (uint64_t)&protocol conformance descriptor for MLLogisticRegressionClassifier.Model);
}

uint64_t MLLogisticRegressionClassifier.Classifier.init(trainingLabelsColumn:validationLabelsColumn:annotationColumnName:featureColumnNames:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, double *a5, uint64_t a6)
{
  uint64_t v10 = v6;
  uint64_t v36 = a2;
  uint64_t v35 = v7;
  uint64_t v43 = a6;
  uint64_t v44 = a5;
  uint64_t v42 = a1;
  uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Double, Int>.Configuration);
  uint64_t v41 = *(void *)(v40 - 8);
  int64_t v11 = *(void *)(v41 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v37 = v34;
  uint64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  *uint64_t v10 = a3;
  v10[1] = a4;
  uint64_t v16 = v44;
  _OWORD v10[2] = v44;
  uint64_t v17 = v43;
  uint64_t v38 = v10 + 3;
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v43, (uint64_t)(v10 + 3));
  v10[15] = v16;
  unsigned char v10[16] = 0xD000000000000013;
  v10[17] = "raining samples." + 0x8000000000000000;
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters(v17, (uint64_t)v34);
  uint64_t v18 = lazy protocol witness table accessor for type Double and conformance Double();
  swift_bridgeObjectRetain((_BYTE)v44);
  LogisticRegressionClassifier.Configuration.init()(&type metadata for Double, &type metadata for Int, &protocol witness table for Double, v18, &protocol witness table for Int, &protocol witness table for Int, &protocol witness table for Int, &protocol witness table for Int);
  uint64_t v19 = v40;
  LogisticRegressionClassifier.Configuration.maximumIterations.setter(*(void *)&v34[0], v40);
  LogisticRegressionClassifier.Configuration.l1Penalty.setter(v19, v34[5]);
  LogisticRegressionClassifier.Configuration.l2Penalty.setter(v19, v34[6]);
  LogisticRegressionClassifier.Configuration.stepSize.setter(v19, v34[7]);
  LogisticRegressionClassifier.Configuration.convergenceThreshold.setter(v19, v34[8]);
  outlined destroy of MLLogisticRegressionClassifier.ModelParameters((uint64_t)v34);
  uint64_t v20 = v37;
  uint64_t v44 = v34;
  (*(void (**)(double *, double *, uint64_t))(v41 + 16))(v37, v34, v19);
  uint64_t v21 = *(int *)(type metadata accessor for MLLogisticRegressionClassifier.Classifier(0) + 36);
  uint64_t v39 = v10;
  uint64_t v22 = (char *)v10 + v21;
  BaseLogisticRegressionClassifier.init(configuration:)(v20);
  uint64_t v23 = v36;
  uint64_t v24 = v35;
  uint64_t v25 = static Labels.collected(from:_:)(v42, v36);
  if (v24)
  {
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v43);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v23, &demangling cache variable for type metadata for AnyColumn?);
    uint64_t v27 = type metadata accessor for AnyColumn(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v27 - 8) + 8))(v42, v27);
    (*(void (**)(double *, uint64_t))(v41 + 8))(v44, v40);
    uint64_t v28 = v39;
    swift_bridgeObjectRelease(v39[1]);
    swift_bridgeObjectRelease(v28[2]);
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters((uint64_t)v38);
    swift_bridgeObjectRelease(v28[15]);
    swift_bridgeObjectRelease(v28[17]);
    uint64_t v29 = type metadata accessor for BaseLogisticRegressionClassifier(0);
    return (*(uint64_t (**)(char *, uint64_t))(*(void *)(v29 - 8) + 8))(v22, v29);
  }
  else
  {
    char v31 = v26;
    uint64_t v32 = v25;
    outlined destroy of MLLogisticRegressionClassifier.ModelParameters(v43);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v23, &demangling cache variable for type metadata for AnyColumn?);
    uint64_t v33 = type metadata accessor for AnyColumn(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v33 - 8) + 8))(v42, v33);
    (*(void (**)(double *, uint64_t))(v41 + 8))(v44, v40);
    uint64_t result = (uint64_t)v39;
    v39[13] = v32;
    *(unsigned char *)(result + 112) = v31 & 1;
  }
  return result;
}

uint64_t MLLogisticRegressionClassifier.Classifier.fitted(to:validateOn:eventHandler:)(void *a1, void *a2, uint64_t a3, uint64_t a4, double a5)
{
  char v79 = v6;
  char v8 = v7;
  uint64_t v66 = a4;
  uint64_t v67 = a3;
  uint64_t v82 = a2;
  Swift::String v84 = a1;
  uint64_t v60 = v5;
  uint64_t v62 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  uint64_t v61 = *(void *)(v62 - 8);
  int64_t v9 = *(void *)(v61 + 64);
  uint64_t v10 = alloca(v9);
  int64_t v11 = alloca(v9);
  uint64_t v68 = v58;
  uint64_t v12 = alloca(v9);
  uint64_t v13 = alloca(v9);
  char v74 = v58;
  int64_t v14 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?)
                              - 8)
                  + 64);
  uint64_t v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v72 = v58;
  uint64_t v71 = type metadata accessor for DataFrame(0);
  uint64_t v73 = *(void *)(v71 - 8);
  int64_t v17 = *(void *)(v73 + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  char v80 = v58;
  uint64_t v64 = type metadata accessor for AnyColumn(0);
  uint64_t v20 = *(void (**)(uint64_t, uint64_t))(v64 - 8);
  int64_t v21 = *((void *)v20 + 8);
  uint64_t v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  uint64_t v65 = v58;
  uint64_t v75 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  uint64_t v24 = *(void *)(v75 - 8);
  int64_t v25 = *(void *)(v24 + 64);
  char v26 = alloca(v25);
  uint64_t v27 = alloca(v25);
  uint64_t v76 = v58;
  uint64_t v28 = alloca(v25);
  uint64_t v29 = alloca(v25);
  char v81 = v58;
  uint64_t v63 = v8;
  uint64_t v30 = v8[2];
  char v59 = v84;
  swift_bridgeObjectRetain(v30);
  char v31 = v79;
  ML16ColumnDescriptorVsAE_pTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_8CreateML16ColumnDescriptorVsAE_pTg5((void (*)(void *, uint64_t *))closure #1 in FeatureVectorizer.fitted(to:)partial apply, (uint64_t)v58, v30);
  uint64_t result = swift_bridgeObjectRelease(v30);
  if (!v31)
  {
    char v79 = v20;
    uint64_t v77 = v24;
    specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)((uint64_t)v84, 1u, (uint64_t)ML16ColumnDescriptorVsAE_pTg5, 0xD000000000000013, (uint64_t)("raining samples." + 0x8000000000000000));
    uint64_t v69 = "raining samples." + 0x8000000000000000;
    uint64_t v83 = 0;
    unint64_t v78 = ML16ColumnDescriptorVsAE_pTg5;
    uint64_t v34 = v63;
    uint64_t v35 = v63[13];
    int v70 = *((unsigned __int8 *)v63 + 112);
    uint64_t v36 = (uint64_t)v65;
    DataFrame.subscript.getter(*v63, v63[1]);
    Swift::String v84 = Labels.encodeAnnotations(_:)(v36, v35, v70, a5);
    uint64_t v37 = (void (*)(uint64_t, uint64_t))*((void *)v79 + 1);
    v37(v36, v64);
    uint64_t v38 = (uint64_t)v72;
    outlined init with copy of DataFrame?((uint64_t)v82, (uint64_t)v72);
    uint64_t v39 = v71;
    if (__swift_getEnumTagSinglePayload(v38, 1, v71) == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v38, &demangling cache variable for type metadata for DataFrame?);
      uint64_t v40 = *(void *)(v34[13] + 16);
      type metadata accessor for MLLogisticRegressionClassifier.Classifier(0);
      uint64_t v41 = v81;
      uint64_t v42 = v83;
      BaseLogisticRegressionClassifier.fitted(features:annotations:classCount:eventHandler:)(v81, v84, v40, v67, v66);
      (*(void (**)(unsigned char *, uint64_t))(v77 + 8))(v41, v75);
      swift_bridgeObjectRelease((_BYTE)v84);
      uint64_t v83 = v42;
      if (v42) {
        return swift_bridgeObjectRelease((_BYTE)v78);
      }
      char v74 = v68;
    }
    else
    {
      char v79 = v37;
      uint64_t v43 = (uint64_t)v80;
      uint64_t v44 = v73;
      (*(void (**)(unsigned char *, uint64_t, uint64_t))(v73 + 32))(v80, v38, v39);
      char v45 = (char)v78;
      uint64_t v46 = v83;
      specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(v43, 1u, (uint64_t)v78, 0xD000000000000013, (uint64_t)v69);
      if (v46)
      {
        swift_bridgeObjectRelease(v45);
        swift_bridgeObjectRelease((_BYTE)v84);
        (*(void (**)(unsigned char *, uint64_t))(v44 + 8))(v80, v39);
        return (*(uint64_t (**)(unsigned char *, uint64_t))(v77 + 8))(v81, v75);
      }
      uint64_t v34 = v63;
      uint64_t v82 = (void *)v63[13];
      LODWORD(v72) = *((unsigned __int8 *)v63 + 112);
      uint64_t v47 = (uint64_t)v65;
      DataFrame.subscript.getter(*v63, v63[1]);
      uint64_t v82 = Labels.encodeAnnotations(_:)(v47, (uint64_t)v82, (char)v72, a5);
      v79(v47, v64);
      uint64_t v48 = *(void *)(v34[13] + 16);
      type metadata accessor for MLLogisticRegressionClassifier.Classifier(0);
      char v49 = (char)v84;
      BaseLogisticRegressionClassifier.fitted(trainingFeatures:trainingAnnotations:validationFeatures:validationAnnotations:classCount:eventHandler:)(v81, v84, v76, v82, v48, v67, v66);
      uint64_t v83 = 0;
      swift_bridgeObjectRelease((_BYTE)v82);
      swift_bridgeObjectRelease(v49);
      uint64_t v50 = *(void (**)(unsigned char *, uint64_t))(v77 + 8);
      uint64_t v51 = v75;
      v50(v76, v75);
      (*(void (**)(unsigned char *, uint64_t))(v73 + 8))(v80, v71);
      v50(v81, v51);
    }
    Swift::String v84 = (void *)*v34;
    uint64_t v52 = v34[1];
    uint64_t v53 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
    uint64_t v54 = v60;
    (*(void (**)(char *, unsigned char *, uint64_t))(v61 + 32))((char *)v60 + *(int *)(v53 + 24), v74, v62);
    uint64_t v55 = v34[13];
    char v56 = *((unsigned char *)v34 + 112);
    *uint64_t v54 = v84;
    v54[1] = v52;
    v54[2] = v78;
    v54[3] = 0xD000000000000013;
    v54[4] = v69;
    uint64_t v57 = *(int *)(v53 + 28);
    *(void *)((char *)v54 + v57) = v55;
    *((unsigned char *)v54 + v57 + 8) = v56;
    swift_bridgeObjectRetain(v55);
    return swift_bridgeObjectRetain(v52);
  }
  return result;
}

uint64_t MLLogisticRegressionClassifier.Classifier.init(labels:annotationColumnName:featureColumnNames:)(uint64_t a1, int a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  uint64_t v43 = a5;
  uint64_t v46 = a4;
  uint64_t v42 = a3;
  int v45 = a2;
  uint64_t v41 = a1;
  uint64_t v7 = v5;
  uint64_t v35 = type metadata accessor for BaseLogisticRegressionClassifier(0);
  uint64_t v36 = *(void *)(v35 - 8);
  int64_t v8 = *(void *)(v36 + 64);
  int64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v37 = &v32;
  uint64_t v38 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifier<Double, Int>.Configuration);
  uint64_t v39 = *(void *)(v38 - 8);
  int64_t v11 = *(void *)(v39 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v40 = &v32;
  int64_t v14 = alloca(v11);
  uint64_t v15 = alloca(v11);
  uint64_t v44 = &v32;
  uint64_t v16 = type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData(0);
  int64_t v17 = *(void *)(*(void *)(v16 - 8) + 64);
  uint64_t v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v20 = alloca(v17);
  int64_t v21 = alloca(v17);
  *(void *)uint64_t v7 = v42;
  *(void *)(v7 + 8) = v46;
  *(void *)(v7 + 16) = a5;
  long long v32 = 0;
  __int16 v33 = 256;
  swift_storeEnumTagMultiPayload(&v32, v16, 0);
  uint64_t v46 = v7 + 32;
  *(_OWORD *)(v7 + 48) = 0;
  *(_OWORD *)(v7 + 32) = 0;
  *(void *)(v7 + 24) = 10;
  *(__m128 *)(v7 + 64) = _mm_loadh_ps((const double *)&qword_349108);
  *(_OWORD *)(v7 + 80) = xmmword_349110;
  *(unsigned char *)(v7 + 96) = 1;
  outlined init with copy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)&v32, (uint64_t)&v32);
  uint64_t v34 = v16;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1((void *)&v32 + 1);
  outlined init with take of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)&v32, (uint64_t)boxed_opaque_existential_1);
  uint64_t v23 = v43;
  swift_bridgeObjectRetain(v43);
  outlined assign with take of Any?((uint64_t)&v32 + 8, v46);
  outlined destroy of MLLogisticRegressionClassifier.ModelParameters.ValidationData((uint64_t)&v32);
  *(void *)(v7 + 104) = v41;
  *(unsigned char *)(v7 + 112) = v45 & 1;
  *(void *)(v7 + 120) = v23;
  *(void *)(v7 + 128) = 0xD000000000000013;
  *(void *)(v7 + 136) = "raining samples." + 0x8000000000000000;
  uint64_t v24 = lazy protocol witness table accessor for type Double and conformance Double();
  int64_t v25 = v44;
  LogisticRegressionClassifier.Configuration.init()(&type metadata for Double, &type metadata for Int, &protocol witness table for Double, v24, &protocol witness table for Int, &protocol witness table for Int, &protocol witness table for Int, &protocol witness table for Int);
  char v26 = v40;
  uint64_t v27 = v38;
  uint64_t v28 = v39;
  (*(void (**)(long long *, long long *, uint64_t))(v39 + 16))(v40, v25, v38);
  uint64_t v29 = v37;
  BaseLogisticRegressionClassifier.init(configuration:)(v26);
  (*(void (**)(long long *, uint64_t))(v28 + 8))(v44, v27);
  uint64_t v30 = type metadata accessor for MLLogisticRegressionClassifier.Classifier(0);
  return (*(uint64_t (**)(uint64_t, long long *, uint64_t))(v36 + 32))(v7 + *(int *)(v30 + 36), v29, v35);
}

uint64_t MLLogisticRegressionClassifier.Classifier.annotationColumnID.getter()
{
  uint64_t v1 = *v0;
  uint64_t v2 = v0[1];
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<String, Int>);
  swift_bridgeObjectRetain(v2);
  return ColumnID.init(_:_:)(v1, v2, v3);
}

uint64_t MLLogisticRegressionClassifier.Classifier.annotationColumnID.setter(uint64_t a1)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<Either<String, Int>>);
  uint64_t v3 = ColumnID.name.getter(v2);
  uint64_t v5 = v4;
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  uint64_t result = swift_bridgeObjectRelease(v1[1]);
  *uint64_t v1 = v3;
  v1[1] = v5;
  return result;
}

uint64_t protocol witness for SupervisedTabularEstimator.annotationColumnID.getter in conformance MLLogisticRegressionClassifier.Classifier()
{
  return MLLogisticRegressionClassifier.Classifier.annotationColumnID.getter();
}

uint64_t protocol witness for SupervisedTabularEstimator.annotationColumnID.setter in conformance MLLogisticRegressionClassifier.Classifier(uint64_t a1)
{
  return MLLogisticRegressionClassifier.Classifier.annotationColumnID.setter(a1);
}

void (*protocol witness for SupervisedTabularEstimator.annotationColumnID.modify in conformance MLLogisticRegressionClassifier.Classifier(void *a1))(uint64_t a1, char a2)
{
  uint64_t v2 = malloc(0x28uLL);
  *a1 = v2;
  *uint64_t v2 = v1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ColumnID<Either<String, Int>>);
  v2[1] = v3;
  uint64_t v4 = *(void *)(v3 - 8);
  v2[2] = v4;
  size_t v5 = *(void *)(v4 + 64);
  v2[3] = malloc(v5);
  v2[4] = malloc(v5);
  MLLogisticRegressionClassifier.Classifier.annotationColumnID.getter();
  return protocol witness for SupervisedTabularEstimator.annotationColumnID.modify in conformance MLLogisticRegressionClassifier.Classifier;
}

void protocol witness for SupervisedTabularEstimator.annotationColumnID.modify in conformance MLLogisticRegressionClassifier.Classifier(uint64_t a1, char a2)
{
  uint64_t v2 = *(void **)a1;
  uint64_t v3 = *(void **)(*(void *)a1 + 24);
  uint64_t v4 = *(void **)(*(void *)a1 + 32);
  if (a2)
  {
    uint64_t v5 = v2[2];
    uint64_t v6 = v2[1];
    (*(void (**)(void *, void *))(v5 + 16))(v3, v4);
    MLLogisticRegressionClassifier.Classifier.annotationColumnID.setter((uint64_t)v3);
    (*(void (**)(void *, uint64_t))(v5 + 8))(v4, v6);
  }
  else
  {
    MLLogisticRegressionClassifier.Classifier.annotationColumnID.setter(*(void *)(*(void *)a1 + 32));
  }
  free(v4);
  free(v3);
  free(v2);
}

uint64_t protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance MLLogisticRegressionClassifier.Classifier(double a1, uint64_t a2, void *a3, void *a4, uint64_t a5, uint64_t a6)
{
  MLLogisticRegressionClassifier.Classifier.fitted(to:validateOn:eventHandler:)(a3, a4, a5, a6, a1);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(*(uint64_t (**)(void))(v6 + 8));
}

uint64_t protocol witness for SupervisedTabularEstimator.encode(_:to:) in conformance MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2)
{
  return MLLogisticRegressionClassifier.Classifier.encode(_:to:)(a1, a2);
}

uint64_t MLLogisticRegressionClassifier.Classifier.encode(_:to:)(uint64_t a1, uint64_t a2)
{
  uint64_t v16 = v2;
  uint64_t v3 = *(void *)(a1 + 32);
  uint64_t v15 = a1;
  long long v13 = *(_OWORD *)(a1 + 16);
  uint64_t v14 = v3;
  uint64_t v4 = *(void *)(a2 + 24);
  uint64_t v17 = *(void *)(a2 + 32);
  __swift_mutable_project_boxed_opaque_existential_1(a2, v4);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer?);
  uint64_t v6 = lazy protocol witness table accessor for type FeatureVectorizer<Double>.Transformer? and conformance <A> A?();
  uint64_t result = ((uint64_t (*)(long long *, uint64_t, uint64_t, uint64_t, uint64_t, uint64_t))dispatch thunk of EstimatorEncoder.encode<A>(_:))(&v13, v5, v6, v4, v17, v7);
  if (!v2)
  {
    uint64_t v9 = *(int *)(type metadata accessor for MLLogisticRegressionClassifier.Model(0) + 24) + v15;
    uint64_t v17 = *(void *)(a2 + 24);
    uint64_t v16 = *(void *)(a2 + 32);
    __swift_mutable_project_boxed_opaque_existential_1(a2, v17);
    uint64_t v10 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
    uint64_t v11 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type BaseLogisticRegressionClassifierModel and conformance BaseLogisticRegressionClassifierModel, (uint64_t (*)(uint64_t))&type metadata accessor for BaseLogisticRegressionClassifierModel, (uint64_t)&protocol conformance descriptor for BaseLogisticRegressionClassifierModel);
    return dispatch thunk of EstimatorEncoder.encode<A>(_:)(v9, v10, v11, v17, v16, v12, v13, *((void *)&v13 + 1), v14);
  }
  return result;
}

uint64_t protocol witness for SupervisedTabularEstimator.decode(from:) in conformance MLLogisticRegressionClassifier.Classifier(uint64_t a1)
{
  return MLLogisticRegressionClassifier.Classifier.decode(from:)(a1);
}

uint64_t base witness table accessor for SupervisedTabularEstimator in MLLogisticRegressionClassifier.Classifier()
{
  return lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLLogisticRegressionClassifier.Classifier and conformance MLLogisticRegressionClassifier.Classifier, type metadata accessor for MLLogisticRegressionClassifier.Classifier, (uint64_t)&protocol conformance descriptor for MLLogisticRegressionClassifier.Classifier);
}

uint64_t MLLogisticRegressionClassifier.Classifier.decode(from:)(uint64_t a1)
{
  uint64_t v29 = v2;
  uint64_t v22 = v3;
  int64_t v21 = v1;
  uint64_t v26 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  uint64_t v23 = *(void *)(v26 - 8);
  int64_t v4 = *(void *)(v23 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v27 = v20;
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
  uint64_t v8 = *(void *)(a1 + 24);
  uint64_t v30 = *(void *)(a1 + 32);
  __swift_mutable_project_boxed_opaque_existential_1(a1, v8);
  uint64_t v9 = lazy protocol witness table accessor for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer(&lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer, (uint64_t)&protocol conformance descriptor for FeatureVectorizer<A>.Transformer);
  uint64_t v10 = v29;
  uint64_t result = dispatch thunk of EstimatorDecoder.decode<A>(_:)(v7, v7, v9, v8, v30);
  if (!v10)
  {
    uint64_t v29 = v20[1];
    uint64_t v24 = v20[2];
    uint64_t v30 = v20[3];
    uint64_t v12 = *(void *)(a1 + 24);
    uint64_t v28 = *(void *)(a1 + 32);
    __swift_mutable_project_boxed_opaque_existential_1(a1, v12);
    uint64_t v13 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type BaseLogisticRegressionClassifierModel and conformance BaseLogisticRegressionClassifierModel, (uint64_t (*)(uint64_t))&type metadata accessor for BaseLogisticRegressionClassifierModel, (uint64_t)&protocol conformance descriptor for BaseLogisticRegressionClassifierModel);
    dispatch thunk of EstimatorDecoder.decode<A>(_:)(v26, v26, v13, v12, v28);
    uint64_t v14 = v22;
    uint64_t v28 = *v22;
    uint64_t v25 = v22[1];
    uint64_t v15 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
    uint64_t v16 = v21;
    (*(void (**)(char *, void *, uint64_t))(v23 + 32))((char *)v21 + *(int *)(v15 + 24), v27, v26);
    uint64_t v17 = v14[13];
    char v18 = *((unsigned char *)v14 + 112);
    *uint64_t v16 = v28;
    LOBYTE(v14) = v25;
    v16[1] = v25;
    void v16[2] = v29;
    void v16[3] = v24;
    void v16[4] = v30;
    uint64_t v19 = *(int *)(v15 + 28);
    *(void *)((char *)v16 + v19) = v17;
    *((unsigned char *)v16 + v19 + 8) = v18;
    swift_bridgeObjectRetain(v17);
    return swift_bridgeObjectRetain((_BYTE)v14);
  }
  return result;
}

uint64_t MLLogisticRegressionClassifier.Classifier.makeTransformer()()
{
  uint64_t v2 = v0;
  uint64_t v11 = type metadata accessor for BaseLogisticRegressionClassifierModel(0);
  uint64_t v12 = *(void *)(v11 - 8);
  int64_t v3 = *(void *)(v12 + 64);
  int64_t v4 = alloca(v3);
  uint64_t v5 = alloca(v3);
  uint64_t v13 = *v1;
  uint64_t v6 = v1[1];
  uint64_t v7 = v1[13];
  char v15 = *((unsigned char *)v1 + 112);
  uint64_t v14 = *(void *)(v7 + 16);
  type metadata accessor for MLLogisticRegressionClassifier.Classifier(0);
  swift_bridgeObjectRetain(v6);
  BaseLogisticRegressionClassifier.makeTransformer(classCount:)(v14);
  *(void *)uint64_t v2 = v13;
  *(void *)(v2 + 8) = v6;
  uint64_t v8 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  *(void *)(v2 + 32) = 0;
  *(_OWORD *)(v2 + 16) = 0;
  (*(void (**)(uint64_t, uint64_t *, uint64_t))(v12 + 32))(v2 + *(int *)(v8 + 24), &v11, v11);
  uint64_t v9 = *(int *)(v8 + 28);
  *(void *)(v2 + v9) = v7;
  *(unsigned char *)(v2 + v9 + 8) = v15;
  return swift_bridgeObjectRetain(v7);
}

uint64_t MLLogisticRegressionClassifier.Classifier.update(_:with:eventHandler:)(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, double a5)
{
  uint64_t v58 = v5;
  uint64_t v46 = a4;
  uint64_t v47 = a3;
  uint64_t v7 = a1;
  uint64_t v44 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  uint64_t v45 = *(void *)(v44 - 8);
  int64_t v8 = *(void *)(v45 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  uint64_t v51 = &v43;
  int64_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?)
                              - 8)
                  + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v43 = (uint64_t)&v43;
  uint64_t v55 = type metadata accessor for AnyColumn(0);
  uint64_t v54 = *(void *)(v55 - 8);
  int64_t v14 = *(void *)(v54 + 64);
  char v15 = alloca(v14);
  uint64_t v16 = alloca(v14);
  uint64_t v48 = &v43;
  uint64_t v17 = alloca(v14);
  char v18 = alloca(v14);
  char v56 = &v43;
  ML16ColumnDescriptorVsAE_pTg5 = (void *)a1[2];
  uint64_t v53 = v6;
  uint64_t v52 = a2;
  if (ML16ColumnDescriptorVsAE_pTg5)
  {
    uint64_t v20 = v58;
  }
  else
  {
    uint64_t v57 = &v43;
    uint64_t v30 = v6[2];
    char v31 = alloca(24);
    long long v32 = alloca(32);
    uint64_t v45 = v52;
    swift_bridgeObjectRetain(v30);
    uint64_t v33 = v58;
    ML16ColumnDescriptorVsAE_pTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_8CreateML16ColumnDescriptorVsAE_pTg5((void (*)(void *, uint64_t *))partial apply for closure #1 in FeatureVectorizer.fitted(to:), (uint64_t)&v43, v30);
    uint64_t v20 = v33;
    uint64_t result = swift_bridgeObjectRelease(v30);
    if (v33) {
      return result;
    }
    outlined consume of FeatureVectorizer<Double>.Transformer?(a1[2], a1[3], a1[4]);
    a1[2] = (uint64_t)ML16ColumnDescriptorVsAE_pTg5;
    a1[3] = 0xD000000000000013;
    a1[4] = (uint64_t)("raining samples." + 0x8000000000000000);
  }
  uint64_t v49 = type metadata accessor for MLLogisticRegressionClassifier.Model(0);
  uint64_t v21 = *(int *)(v49 + 28);
  uint64_t v22 = *(uint64_t *)((char *)a1 + v21);
  if (*(void *)(v22 + 16))
  {
    char v23 = *((unsigned char *)a1 + v21 + 8);
  }
  else
  {
    uint64_t v50 = a1;
    uint64_t v34 = *v53;
    uint64_t v35 = v53[1];
    uint64_t v36 = (uint64_t)v56;
    uint64_t v58 = v20;
    DataFrame.subscript.getter(v34, v35);
    uint64_t v37 = v43;
    __swift_storeEnumTagSinglePayload(v43, 1, 1, v55);
    uint64_t v38 = v58;
    uint64_t v39 = static Labels.collected(from:_:)(v36, v37);
    uint64_t v20 = v38;
    if (v38)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v37, &demangling cache variable for type metadata for AnyColumn?);
      return (*(uint64_t (**)(uint64_t *, uint64_t))(v54 + 8))(v56, v55);
    }
    uint64_t v57 = (uint64_t *)v39;
    uint64_t v41 = v37;
    char v42 = v40;
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v41, &demangling cache variable for type metadata for AnyColumn?);
    (*(void (**)(uint64_t *, uint64_t))(v54 + 8))(v56, v55);
    uint64_t v7 = v50;
    swift_bridgeObjectRelease(*(uint64_t *)((char *)v50 + v21));
    char v23 = v42;
    uint64_t v22 = (uint64_t)v57;
    *(uint64_t *)((char *)v7 + v21) = (uint64_t)v57;
    *((unsigned char *)v7 + v21 + 8) = v42 & 1;
    ML16ColumnDescriptorVsAE_pTg5 = (void *)v7[2];
  }
  LOBYTE(v56) = v23;
  uint64_t v57 = (uint64_t *)v22;
  if (!ML16ColumnDescriptorVsAE_pTg5) {
    BUG();
  }
  uint64_t result = specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(v52, 1u, (uint64_t)ML16ColumnDescriptorVsAE_pTg5, v7[3], v7[4]);
  if (!v20)
  {
    uint64_t v25 = *v53;
    uint64_t v26 = v53[1];
    uint64_t v27 = (uint64_t)v48;
    uint64_t v58 = 0;
    DataFrame.subscript.getter(v25, v26);
    uint64_t v28 = Labels.encodeAnnotations(_:)(v27, (uint64_t)v57, v56 & 1, a5);
    (*(void (**)(uint64_t, uint64_t))(v54 + 8))(v27, v55);
    type metadata accessor for MLLogisticRegressionClassifier.Classifier(0);
    uint64_t v29 = v51;
    BaseLogisticRegressionClassifier.update(_:features:annotations:eventHandler:)((char *)v7 + *(int *)(v49 + 24), v51, v28, v47, v46);
    (*(void (**)(uint64_t *, uint64_t))(v45 + 8))(v29, v44);
    return swift_bridgeObjectRelease((_BYTE)v28);
  }
  return result;
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.makeTransformer() in conformance MLLogisticRegressionClassifier.Classifier()
{
  return MLLogisticRegressionClassifier.Classifier.makeTransformer()();
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.update(_:with:eventHandler:) in conformance MLLogisticRegressionClassifier.Classifier(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, double a5)
{
  MLLogisticRegressionClassifier.Classifier.update(_:with:eventHandler:)(a1, a2, a3, a4, a5);
  return protocol witness for SupervisedTabularEstimator.fitted(to:validateOn:eventHandler:) in conformance TreeRegressor(*(uint64_t (**)(void))(v5 + 8));
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.encodeWithOptimizer(_:to:) in conformance MLLogisticRegressionClassifier.Classifier(uint64_t a1, uint64_t a2)
{
  return protocol witness for SupervisedTabularEstimator.encode(_:to:) in conformance MLLogisticRegressionClassifier.Classifier(a1, a2);
}

uint64_t protocol witness for UpdatableSupervisedTabularEstimator.decodeWithOptimizer(from:) in conformance MLLogisticRegressionClassifier.Classifier(uint64_t a1)
{
  return protocol witness for SupervisedTabularEstimator.decode(from:) in conformance MLLogisticRegressionClassifier.Classifier(a1);
}

uint64_t __swift_mutable_project_boxed_opaque_existential_1(uint64_t a1, uint64_t a2)
{
  int v2 = *(_DWORD *)(*(void *)(a2 - 8) + 80);
  if ((v2 & 0x20000) != 0)
  {
    swift_makeBoxUnique(a1, a2, v2);
    return v3;
  }
  return a1;
}

uint64_t lazy protocol witness table accessor for type FeatureVectorizer<Double>.Transformer? and conformance <A> A?()
{
  uint64_t result = lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer? and conformance <A> A?;
  if (!lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer? and conformance <A> A?)
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer?);
    lazy protocol witness table accessor for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer(&lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer, (uint64_t)&protocol conformance descriptor for FeatureVectorizer<A>.Transformer);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for <A> A?, v1);
    lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer? and conformance <A> A? = result;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer(uint64_t *a1, uint64_t a2)
{
  uint64_t result = *a1;
  if (!*a1)
  {
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
    uint64_t result = swift_getWitnessTable(a2, v3);
    *a1 = result;
  }
  return result;
}

uint64_t outlined init with copy of MLLogisticRegressionClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined init with take of MLLogisticRegressionClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLLogisticRegressionClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t outlined destroy of MLLogisticRegressionClassifier.ModelParameters(uint64_t a1)
{
  (*(void (**)(uint64_t))(*((void *)&type metadata for MLLogisticRegressionClassifier.ModelParameters - 1)
                                  + 8))(a1);
  return a1;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay10Foundation3URLVG_18CreateMLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n(void *a1, uint64_t a2, uint64_t a3)
{
  uint64_t v33 = a3;
  uint64_t v21 = a2;
  uint64_t v22 = type metadata accessor for URL(0);
  uint64_t v4 = *(void *)(v22 - 8);
  int64_t v5 = *(void *)(v4 + 64);
  uint64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  char v23 = &v19;
  uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v25 = *(void *)(v24 - 8);
  int64_t v8 = *(void *)(v25 + 64);
  uint64_t v9 = alloca(v8);
  uint64_t v10 = alloca(v8);
  long long v32 = a1;
  int64_t v11 = a1[2];
  if (v11)
  {
    uint64_t v30 = v3;
    char v31 = _swiftEmptyArrayStorage;
    int64_t v26 = v11;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v11, 0);
    uint64_t v12 = v31;
    uint64_t v13 = (uint64_t)v32 + ((*(unsigned __int8 *)(v4 + 80) + 32) & ~*(unsigned __int8 *)(v4 + 80));
    uint64_t v27 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v4 + 16);
    uint64_t v28 = *(void *)(v4 + 72);
    uint64_t v29 = &v19;
    do
    {
      long long v32 = v12;
      int64_t v14 = v23;
      uint64_t v15 = v22;
      v27(v23, v13, v22);
      v20[0] = v21;
      v20[1] = v33;
      swift_bridgeObjectRetain(v33);
      uint64_t v16 = v14;
      uint64_t v12 = v32;
      AnnotatedFeature.init(feature:annotation:)(v16, v20, v15, &type metadata for String);
      char v31 = v12;
      unint64_t v17 = v12[2];
      if (v12[3] >> 1 <= v17)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v12[3] >= 2uLL, v17 + 1, 1);
        uint64_t v12 = v31;
      }
      v12[2] = v17 + 1;
      (*(void (**)(char *, uint64_t *, uint64_t))(v25 + 32))((char *)v12+ ((*(unsigned __int8 *)(v25 + 80) + 32) & ~*(unsigned __int8 *)(v25 + 80))+ *(void *)(v25 + 72) * v17, v29, v24);
      v13 += v28;
      --v26;
    }
    while (v26);
    swift_bridgeObjectRelease(v33);
  }
  else
  {
    swift_bridgeObjectRelease(v33);
    return _swiftEmptyArrayStorage;
  }
  return v12;
}

void *specialized Sequence.flatMap<A>(_:)(uint64_t a1)
{
  uint64_t v2 = v1;
  specialized _NativeDictionary.makeIterator()(a1);
  int64_t v43 = v39;
  unint64_t v3 = v40;
  int64_t v45 = (unint64_t)(v38 + 64) >> 6;
  swift_bridgeObjectRetain(a1);
  uint64_t v44 = _swiftEmptyArrayStorage;
  while (1)
  {
    if (v3)
    {
      _BitScanForward64(&v4, v3);
      uint64_t v42 = (v3 - 1) & v3;
      unint64_t v5 = v4 | (v43 << 6);
      goto LABEL_18;
    }
    int64_t v6 = v43 + 1;
    if (__OFADD__(1, v43)) {
      BUG();
    }
    if (v6 >= v45) {
      goto LABEL_37;
    }
    unint64_t v7 = *(void *)(v37 + 8 * v6);
    if (!v7) {
      break;
    }
    int64_t v8 = v43 + 1;
LABEL_17:
    _BitScanForward64(&v10, v7);
    uint64_t v42 = v7 & (v7 - 1);
    int64_t v43 = v8;
    unint64_t v5 = v10 + (v8 << 6);
LABEL_18:
    uint64_t v11 = *(void *)(v36 + 48);
    uint64_t v12 = *(void *)(v11 + 16 * v5);
    uint64_t v13 = *(void *)(v11 + 16 * v5 + 8);
    int64_t v14 = *(void **)(*(void *)(v36 + 56) + 8 * v5);
    swift_bridgeObjectRetain_n(v13, 2);
    swift_bridgeObjectRetain((_BYTE)v14);
    uint64_t v15 = v2;
    MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay10Foundation3URLVG_18CreateMLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n(v14, v12, v13);
    swift_bridgeObjectRelease((_BYTE)v14);
    swift_bridgeObjectRelease(v13);
    uint64_t v17 = MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n[2];
    int64_t v18 = v44[2];
    int64_t v19 = v17 + v18;
    if (__OFADD__(v17, v18)) {
      BUG();
    }
    uint64_t v41 = MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n;
    uint64_t v20 = v44;
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v44);
    if (!isUniquelyReferenced_nonNull_native || v44[3] >> 1 < v19)
    {
      if (v18 > v19) {
        int64_t v19 = v18;
      }
      uint64_t v20 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(isUniquelyReferenced_nonNull_native, v19, 1, (uint64_t)v44);
    }
    char v22 = (char)v41;
    uint64_t v44 = v20;
    if (v41[2])
    {
      uint64_t v23 = v20[2];
      uint64_t v24 = (v20[3] >> 1) - v23;
      uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
      if (v24 < v17) {
        BUG();
      }
      uint64_t v26 = *(void *)(v25 - 8);
      uint64_t v27 = (*(unsigned __int8 *)(v26 + 80) + 32) & ~*(unsigned __int8 *)(v26 + 80);
      uint64_t v28 = *(void *)(v26 + 72);
      uint64_t v29 = (char *)v20 + v28 * v23 + v27;
      char v22 = (char)v41;
      uint64_t v30 = (char *)v41 + v27;
      uint64_t v31 = v17 * v28;
      if ((char *)v41 + v27 < &v29[v31] && v29 < &v30[v31])
      {
        _fatalErrorMessage(_:_:file:line:flags:)("Fatal error", 11, 2, "UnsafeMutablePointer.initialize overlapping range", 49, 2, "Swift/UnsafePointer.swift", 25, 2, 1092, 1);
        BUG();
      }
      swift_arrayInitWithCopy(v29, v30, v17, v25);
      if (v17)
      {
        BOOL v32 = __OFADD__(v20[2], v17);
        uint64_t v33 = v20[2] + v17;
        if (v32) {
          BUG();
        }
        void v20[2] = v33;
      }
    }
    else if (v17)
    {
      BUG();
    }
    swift_bridgeObjectRelease(v22);
    uint64_t v2 = v15;
    unint64_t v3 = v42;
  }
  int64_t v9 = v43 + 2;
  if (v43 + 2 >= v45) {
    goto LABEL_37;
  }
  unint64_t v7 = *(void *)(v37 + 8 * v6 + 8);
  if (v7) {
    goto LABEL_16;
  }
  int64_t v9 = v43 + 3;
  if (v43 + 3 >= v45) {
    goto LABEL_37;
  }
  unint64_t v7 = *(void *)(v37 + 8 * v6 + 16);
  if (v7) {
    goto LABEL_16;
  }
  int64_t v9 = v43 + 4;
  if (v43 + 4 >= v45) {
    goto LABEL_37;
  }
  unint64_t v7 = *(void *)(v37 + 8 * v6 + 24);
  if (v7) {
    goto LABEL_16;
  }
  int64_t v9 = v43 + 5;
  if (v43 + 5 >= v45) {
    goto LABEL_37;
  }
  unint64_t v7 = *(void *)(v37 + 8 * v6 + 32);
  if (v7)
  {
LABEL_16:
    int64_t v8 = v9;
    goto LABEL_17;
  }
  int64_t v34 = v43 + 6;
  while (v34 < v45)
  {
    unint64_t v7 = *(void *)(v37 + 8 * v34++);
    if (v7)
    {
      int64_t v8 = v34 - 1;
      goto LABEL_17;
    }
  }
LABEL_37:
  swift_release();
  return v44;
}

{
  uint64_t v1;
  unint64_t v2;
  void *v3;
  unint64_t v4;
  unint64_t v5;
  int64_t v6;
  unint64_t v7;
  int64_t v8;
  int64_t v9;
  unint64_t v10;
  uint64_t v11;
  int64_t v12;
  void *v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  void *v18;
  uint64_t *v19;
  uint64_t v20;
  unint64_t v21;
  char v22;
  int64_t v23;
  uint64_t v24;
  void *v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  int64_t v30;
  int64_t v31;
  char isUniquelyReferenced_nonNull_native;
  void *v33;
  char v34;
  uint64_t v35;
  void *v36;
  unint64_t v37;
  uint64_t v38;
  BOOL v39;
  uint64_t v40;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  unint64_t v46;
  int64_t v47;
  uint64_t v48;
  uint64_t v49;
  uint64_t v50;
  uint64_t v51;
  unint64_t v52;
  char v53;
  uint64_t v54;
  int64_t v55;
  void *v56;
  void *v57;
  void *v58;
  int64_t v59;

  specialized _NativeDictionary.makeIterator()(a1);
  uint64_t v1 = v42;
  uint64_t v55 = v45;
  uint64_t v2 = v46;
  char v59 = (unint64_t)(v44 + 64) >> 6;
  swift_bridgeObjectRetain(a1);
  unint64_t v3 = _swiftEmptyArrayStorage;
  while (1)
  {
    if (v2)
    {
      _BitScanForward64(&v4, v2);
      uint64_t v54 = (v2 - 1) & v2;
      unint64_t v5 = v4 | (v55 << 6);
      goto LABEL_21;
    }
    int64_t v6 = v55 + 1;
    if (__OFADD__(1, v55)) {
      BUG();
    }
    if (v6 >= v59) {
      goto LABEL_42;
    }
    unint64_t v7 = *(void *)(v43 + 8 * v6);
    if (!v7) {
      break;
    }
    int64_t v8 = v55 + 1;
LABEL_20:
    _BitScanForward64(&v10, v7);
    uint64_t v54 = v7 & (v7 - 1);
    unint64_t v5 = v10 + (v8 << 6);
    uint64_t v55 = v8;
LABEL_21:
    uint64_t v11 = *(void *)(*(void *)(v1 + 56) + 8 * v5);
    uint64_t v12 = *(void *)(v11 + 16);
    uint64_t v13 = _swiftEmptyArrayStorage;
    if (v12)
    {
      int64_t v14 = 16 * v5;
      uint64_t v15 = *(void *)(v1 + 48);
      uint64_t v50 = *(void *)(v15 + v14);
      uint64_t v16 = *(void *)(v15 + v14 + 8);
      swift_bridgeObjectRetain_n(v16, 2);
      swift_bridgeObjectRetain(v11);
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v12, 0);
      uint64_t v17 = v16;
      int64_t v18 = _swiftEmptyArrayStorage;
      uint64_t v53 = v11;
      int64_t v19 = (uint64_t *)(v11 + 40);
      uint64_t v51 = v17;
      do
      {
        char v56 = v18;
        uint64_t v47 = v12;
        uint64_t v48 = *(v19 - 1);
        uint64_t v20 = *v19;
        uint64_t v58 = v18;
        uint64_t v21 = v18[2];
        uint64_t v52 = v18[3];
        swift_bridgeObjectRetain(v17);
        uint64_t v49 = v20;
        char v22 = v20;
        uint64_t v23 = v21 + 1;
        swift_bridgeObjectRetain(v22);
        int64_t v18 = v56;
        if (v52 >> 1 <= v21)
        {
          specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v52 >= 2, v23, 1);
          int64_t v18 = v58;
        }
        v18[2] = v23;
        uint64_t v24 = 4 * v21;
        v18[v24 + 4] = v48;
        v18[v24 + 5] = v49;
        v18[v24 + 6] = v50;
        LOBYTE(v17) = v51;
        v18[v24 + 7] = v51;
        v19 += 2;
        uint64_t v12 = v47 - 1;
      }
      while (v47 != 1);
      uint64_t v25 = v18;
      swift_bridgeObjectRelease(v53);
      swift_bridgeObjectRelease_n(v51, 2, v26, v27, v28);
      uint64_t v13 = v25;
    }
    uint64_t v29 = v13[2];
    uint64_t v30 = v3[2];
    uint64_t v31 = v29 + v30;
    if (__OFADD__(v29, v30)) {
      BUG();
    }
    uint64_t v57 = v13;
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v3);
    uint64_t v33 = v3;
    if (!isUniquelyReferenced_nonNull_native || v3[3] >> 1 < v31)
    {
      if (v30 > v31) {
        uint64_t v31 = v30;
      }
      uint64_t v33 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(isUniquelyReferenced_nonNull_native, v31, 1, (uint64_t)v3);
    }
    int64_t v34 = (char)v57;
    if (v57[2])
    {
      uint64_t v35 = v33[2];
      if ((v33[3] >> 1) - v35 < v29) {
        BUG();
      }
      uint64_t v36 = v33;
      uint64_t v37 = (unint64_t)&v33[4 * v35 + 4];
      if ((unint64_t)(v57 + 4) < v37 + 32 * v29 && v37 < (unint64_t)&v57[4 * v29 + 4])
      {
        _fatalErrorMessage(_:_:file:line:flags:)("Fatal error", 11, 2, "UnsafeMutablePointer.initialize overlapping range", 49, 2, "Swift/UnsafePointer.swift", 25, 2, 1092, 1);
        BUG();
      }
      uint64_t v38 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (predicted: String, label: String));
      swift_arrayInitWithCopy(v37, v57 + 4, v29, v38);
      int64_t v34 = (char)v57;
      if (v29)
      {
        uint64_t v39 = __OFADD__(v36[2], v29);
        unint64_t v40 = v36[2] + v29;
        if (v39) {
          BUG();
        }
        void v36[2] = v40;
      }
    }
    else
    {
      uint64_t v36 = v33;
      if (v29) {
        BUG();
      }
    }
    swift_bridgeObjectRelease(v34);
    unint64_t v3 = v36;
    uint64_t v1 = v42;
    uint64_t v2 = v54;
  }
  int64_t v8 = v55 + 2;
  if (v55 + 2 >= v59) {
    goto LABEL_42;
  }
  unint64_t v7 = *(void *)(v43 + 8 * v6 + 8);
  if (v7) {
    goto LABEL_20;
  }
  int64_t v8 = v55 + 3;
  if (v55 + 3 >= v59) {
    goto LABEL_42;
  }
  unint64_t v7 = *(void *)(v43 + 8 * v6 + 16);
  if (v7) {
    goto LABEL_20;
  }
  int64_t v8 = v55 + 4;
  if (v55 + 4 >= v59) {
    goto LABEL_42;
  }
  unint64_t v7 = *(void *)(v43 + 8 * v6 + 24);
  if (v7) {
    goto LABEL_20;
  }
  int64_t v8 = v55 + 5;
  if (v55 + 5 >= v59) {
    goto LABEL_42;
  }
  unint64_t v7 = *(void *)(v43 + 8 * v6 + 32);
  if (v7) {
    goto LABEL_20;
  }
  int64_t v9 = v55 + 6;
  while (v9 < v59)
  {
    unint64_t v7 = *(void *)(v43 + 8 * v9++);
    if (v7)
    {
      int64_t v8 = v9 - 1;
      goto LABEL_20;
    }
  }
LABEL_42:
  swift_release();
  return v3;
}

{
  uint64_t v1;
  uint64_t v2;
  unint64_t v3;
  unint64_t v4;
  unint64_t v5;
  int64_t v6;
  unint64_t v7;
  int64_t v8;
  int64_t v9;
  unint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  void *v14;
  uint64_t v15;
  void *MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n;
  uint64_t v17;
  int64_t v18;
  int64_t v19;
  void *v20;
  char isUniquelyReferenced_nonNull_native;
  char v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  char *v29;
  char *v30;
  uint64_t v31;
  BOOL v32;
  uint64_t v33;
  int64_t v34;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  unint64_t v40;
  void *v41;
  uint64_t v42;
  int64_t v43;
  void *v44;
  int64_t v45;

  uint64_t v2 = v1;
  specialized _NativeDictionary.makeIterator()(a1);
  int64_t v43 = v39;
  unint64_t v3 = v40;
  int64_t v45 = (unint64_t)(v38 + 64) >> 6;
  swift_bridgeObjectRetain(a1);
  uint64_t v44 = _swiftEmptyArrayStorage;
  while (1)
  {
    if (v3)
    {
      _BitScanForward64(&v4, v3);
      uint64_t v42 = (v3 - 1) & v3;
      unint64_t v5 = v4 | (v43 << 6);
      goto LABEL_18;
    }
    int64_t v6 = v43 + 1;
    if (__OFADD__(1, v43)) {
      BUG();
    }
    if (v6 >= v45) {
      goto LABEL_37;
    }
    unint64_t v7 = *(void *)(v37 + 8 * v6);
    if (!v7) {
      break;
    }
    int64_t v8 = v43 + 1;
LABEL_17:
    _BitScanForward64(&v10, v7);
    uint64_t v42 = v7 & (v7 - 1);
    int64_t v43 = v8;
    unint64_t v5 = v10 + (v8 << 6);
LABEL_18:
    uint64_t v11 = *(void *)(v36 + 48);
    uint64_t v12 = *(void *)(v11 + 16 * v5);
    uint64_t v13 = *(void *)(v11 + 16 * v5 + 8);
    int64_t v14 = *(void **)(*(void *)(v36 + 56) + 8 * v5);
    swift_bridgeObjectRetain_n(v13, 2);
    swift_bridgeObjectRetain((_BYTE)v14);
    uint64_t v15 = v2;
    MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay10Foundation3URLVG_18CreateMLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n(v14, v12, v13);
    swift_bridgeObjectRelease((_BYTE)v14);
    swift_bridgeObjectRelease(v13);
    uint64_t v17 = MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n[2];
    int64_t v18 = v44[2];
    int64_t v19 = v17 + v18;
    if (__OFADD__(v17, v18)) {
      BUG();
    }
    uint64_t v41 = MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n;
    uint64_t v20 = v44;
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v44);
    if (!isUniquelyReferenced_nonNull_native || v44[3] >> 1 < v19)
    {
      if (v18 > v19) {
        int64_t v19 = v18;
      }
      uint64_t v20 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(isUniquelyReferenced_nonNull_native, v19, 1, (uint64_t)v44);
    }
    char v22 = (char)v41;
    uint64_t v44 = v20;
    if (v41[2])
    {
      uint64_t v23 = v20[2];
      uint64_t v24 = (v20[3] >> 1) - v23;
      uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
      if (v24 < v17) {
        BUG();
      }
      uint64_t v26 = *(void *)(v25 - 8);
      uint64_t v27 = (*(unsigned __int8 *)(v26 + 80) + 32) & ~*(unsigned __int8 *)(v26 + 80);
      uint64_t v28 = *(void *)(v26 + 72);
      uint64_t v29 = (char *)v20 + v28 * v23 + v27;
      char v22 = (char)v41;
      uint64_t v30 = (char *)v41 + v27;
      uint64_t v31 = v17 * v28;
      if ((char *)v41 + v27 < &v29[v31] && v29 < &v30[v31])
      {
        _fatalErrorMessage(_:_:file:line:flags:)("Fatal error", 11, 2, "UnsafeMutablePointer.initialize overlapping range", 49, 2, "Swift/UnsafePointer.swift", 25, 2, 1092, 1);
        BUG();
      }
      swift_arrayInitWithCopy(v29, v30, v17, v25);
      if (v17)
      {
        BOOL v32 = __OFADD__(v20[2], v17);
        uint64_t v33 = v20[2] + v17;
        if (v32) {
          BUG();
        }
        void v20[2] = v33;
      }
    }
    else if (v17)
    {
      BUG();
    }
    swift_bridgeObjectRelease(v22);
    uint64_t v2 = v15;
    unint64_t v3 = v42;
  }
  int64_t v9 = v43 + 2;
  if (v43 + 2 >= v45) {
    goto LABEL_37;
  }
  unint64_t v7 = *(void *)(v37 + 8 * v6 + 8);
  if (v7) {
    goto LABEL_16;
  }
  int64_t v9 = v43 + 3;
  if (v43 + 3 >= v45) {
    goto LABEL_37;
  }
  unint64_t v7 = *(void *)(v37 + 8 * v6 + 16);
  if (v7) {
    goto LABEL_16;
  }
  int64_t v9 = v43 + 4;
  if (v43 + 4 >= v45) {
    goto LABEL_37;
  }
  unint64_t v7 = *(void *)(v37 + 8 * v6 + 24);
  if (v7) {
    goto LABEL_16;
  }
  int64_t v9 = v43 + 5;
  if (v43 + 5 >= v45) {
    goto LABEL_37;
  }
  unint64_t v7 = *(void *)(v37 + 8 * v6 + 32);
  if (v7)
  {
LABEL_16:
    int64_t v8 = v9;
    goto LABEL_17;
  }
  int64_t v34 = v43 + 6;
  while (v34 < v45)
  {
    unint64_t v7 = *(void *)(v37 + 8 * v34++);
    if (v7)
    {
      int64_t v8 = v34 - 1;
      goto LABEL_17;
    }
  }
LABEL_37:
  swift_release();
  return v44;
}

{
  uint64_t v1;
  void *v2;
  unint64_t v3;
  uint64_t v4;
  unint64_t v5;
  int64_t v6;
  unint64_t v7;
  int64_t v8;
  int64_t v9;
  unint64_t v10;
  uint64_t v11;
  uint64_t v12;
  int64_t v13;
  int64_t v14;
  char isUniquelyReferenced_nonNull_native;
  uint64_t v16;
  void *v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  char *v23;
  unint64_t v24;
  uint64_t v25;
  BOOL v26;
  uint64_t v27;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  unint64_t v33;
  unint64_t v34;
  int64_t v35;
  int64_t v36;

  specialized _NativeDictionary.makeIterator()(a1);
  uint64_t v1 = v32;
  int64_t v34 = v33;
  uint64_t v36 = (unint64_t)(v31 + 64) >> 6;
  swift_bridgeObjectRetain(a1);
  uint64_t v2 = _swiftEmptyArrayStorage;
  while (1)
  {
    if (v34)
    {
      _BitScanForward64(&v3, v34);
      unint64_t v4 = (v34 - 1) & v34;
      uint64_t v35 = v1;
      unint64_t v5 = v3 | (v1 << 6);
      goto LABEL_21;
    }
    int64_t v6 = v1 + 1;
    if (__OFADD__(1, v1)) {
      BUG();
    }
    if (v6 >= v36) {
      goto LABEL_36;
    }
    unint64_t v7 = *(void *)(v30 + 8 * v6);
    if (!v7) {
      break;
    }
    int64_t v8 = v1 + 1;
LABEL_20:
    _BitScanForward64(&v10, v7);
    unint64_t v4 = v7 & (v7 - 1);
    unint64_t v5 = v10 + (v8 << 6);
    uint64_t v35 = v8;
LABEL_21:
    uint64_t v11 = *(void *)(*(void *)(v29 + 56) + 8 * v5);
    uint64_t v12 = *(void *)(v11 + 16);
    uint64_t v13 = v2[2];
    int64_t v14 = v12 + v13;
    if (__OFADD__(v12, v13)) {
      BUG();
    }
    int64_t v34 = v4;
    swift_bridgeObjectRetain(v11);
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v2);
    if (!isUniquelyReferenced_nonNull_native || v2[3] >> 1 < v14)
    {
      if (v13 > v14) {
        int64_t v14 = v13;
      }
      uint64_t v2 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(isUniquelyReferenced_nonNull_native, v14, 1, (uint64_t)v2);
    }
    if (*(void *)(v11 + 16))
    {
      uint64_t v16 = v2[2];
      uint64_t v17 = v2;
      int64_t v18 = (v2[3] >> 1) - v16;
      int64_t v19 = type metadata accessor for URL(0);
      if (v18 < v12) {
        BUG();
      }
      uint64_t v20 = *(void *)(v19 - 8);
      uint64_t v21 = (*(unsigned __int8 *)(v20 + 80) + 32) & ~*(unsigned __int8 *)(v20 + 80);
      char v22 = *(void *)(v20 + 72);
      uint64_t v23 = (char *)v17 + v22 * v16 + v21;
      uint64_t v24 = v11 + v21;
      uint64_t v25 = v12 * v22;
      uint64_t v2 = v17;
      if (v24 < (unint64_t)&v23[v25] && (unint64_t)v23 < v24 + v25)
      {
        _fatalErrorMessage(_:_:file:line:flags:)("Fatal error", 11, 2, "UnsafeMutablePointer.initialize overlapping range", 49, 2, "Swift/UnsafePointer.swift", 25, 2, 1092, 1);
        BUG();
      }
      swift_arrayInitWithCopy(v23, v24, v12, v19);
      if (v12)
      {
        uint64_t v26 = __OFADD__(v17[2], v12);
        uint64_t v27 = v17[2] + v12;
        if (v26) {
          BUG();
        }
        _OWORD v17[2] = v27;
      }
    }
    else if (v12)
    {
      BUG();
    }
    swift_bridgeObjectRelease(v11);
    uint64_t v1 = v35;
  }
  int64_t v8 = v1 + 2;
  if (v1 + 2 >= v36) {
    goto LABEL_36;
  }
  unint64_t v7 = *(void *)(v30 + 8 * v6 + 8);
  if (v7) {
    goto LABEL_20;
  }
  int64_t v8 = v1 + 3;
  if (v1 + 3 >= v36) {
    goto LABEL_36;
  }
  unint64_t v7 = *(void *)(v30 + 8 * v6 + 16);
  if (v7) {
    goto LABEL_20;
  }
  int64_t v8 = v1 + 4;
  if (v1 + 4 >= v36) {
    goto LABEL_36;
  }
  unint64_t v7 = *(void *)(v30 + 8 * v6 + 24);
  if (v7) {
    goto LABEL_20;
  }
  int64_t v8 = v1 + 5;
  if (v1 + 5 >= v36) {
    goto LABEL_36;
  }
  unint64_t v7 = *(void *)(v30 + 8 * v6 + 32);
  if (v7) {
    goto LABEL_20;
  }
  int64_t v9 = v1 + 6;
  while (v9 < v36)
  {
    unint64_t v7 = *(void *)(v30 + 8 * v9++);
    if (v7)
    {
      int64_t v8 = v9 - 1;
      goto LABEL_20;
    }
  }
LABEL_36:
  swift_release();
  return v2;
}

{
  uint64_t v1;
  uint64_t v2;
  unint64_t v3;
  unint64_t v4;
  unint64_t v5;
  int64_t v6;
  unint64_t v7;
  int64_t v8;
  int64_t v9;
  unint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  void *v14;
  uint64_t v15;
  void *MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n;
  uint64_t v17;
  int64_t v18;
  int64_t v19;
  void *v20;
  char isUniquelyReferenced_nonNull_native;
  char v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  char *v29;
  char *v30;
  uint64_t v31;
  BOOL v32;
  uint64_t v33;
  int64_t v34;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  unint64_t v40;
  void *v41;
  uint64_t v42;
  int64_t v43;
  void *v44;
  int64_t v45;

  uint64_t v2 = v1;
  specialized _NativeDictionary.makeIterator()(a1);
  int64_t v43 = v39;
  unint64_t v3 = v40;
  int64_t v45 = (unint64_t)(v38 + 64) >> 6;
  swift_bridgeObjectRetain(a1);
  uint64_t v44 = _swiftEmptyArrayStorage;
  while (1)
  {
    if (v3)
    {
      _BitScanForward64(&v4, v3);
      uint64_t v42 = (v3 - 1) & v3;
      unint64_t v5 = v4 | (v43 << 6);
      goto LABEL_18;
    }
    int64_t v6 = v43 + 1;
    if (__OFADD__(1, v43)) {
      BUG();
    }
    if (v6 >= v45) {
      goto LABEL_37;
    }
    unint64_t v7 = *(void *)(v37 + 8 * v6);
    if (!v7) {
      break;
    }
    int64_t v8 = v43 + 1;
LABEL_17:
    _BitScanForward64(&v10, v7);
    uint64_t v42 = v7 & (v7 - 1);
    int64_t v43 = v8;
    unint64_t v5 = v10 + (v8 << 6);
LABEL_18:
    uint64_t v11 = *(void *)(v36 + 48);
    uint64_t v12 = *(void *)(v11 + 16 * v5);
    uint64_t v13 = *(void *)(v11 + 16 * v5 + 8);
    int64_t v14 = *(void **)(*(void *)(v36 + 56) + 8 * v5);
    swift_bridgeObjectRetain_n(v13, 2);
    swift_bridgeObjectRetain((_BYTE)v14);
    uint64_t v15 = v2;
    MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay10Foundation3URLVG_18CreateMLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n(v14, v12, v13);
    swift_bridgeObjectRelease((_BYTE)v14);
    swift_bridgeObjectRelease(v13);
    uint64_t v17 = MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n[2];
    int64_t v18 = v44[2];
    int64_t v19 = v17 + v18;
    if (__OFADD__(v17, v18)) {
      BUG();
    }
    uint64_t v41 = MLComponents16AnnotatedFeatureVyAHSSGs5NeverOTg503_s8f24ML17MLSoundClassifierV16i143ExtractorC12filesByLabel7optionsAESDySSSay10Foundation3URLVGG_AE13ConfigurationVtKc33_EF88DE97863F019753745A6AAFDAF1B0LlfcSay0A12MLComponents09H29E0VyAJSSGGSS_AKtXEfU_AsJXEfU_SSTf1cn_n;
    uint64_t v20 = v44;
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v44);
    if (!isUniquelyReferenced_nonNull_native || v44[3] >> 1 < v19)
    {
      if (v18 > v19) {
        int64_t v19 = v18;
      }
      uint64_t v20 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(isUniquelyReferenced_nonNull_native, v19, 1, (uint64_t)v44);
    }
    char v22 = (char)v41;
    uint64_t v44 = v20;
    if (v41[2])
    {
      uint64_t v23 = v20[2];
      uint64_t v24 = (v20[3] >> 1) - v23;
      uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
      if (v24 < v17) {
        BUG();
      }
      uint64_t v26 = *(void *)(v25 - 8);
      uint64_t v27 = (*(unsigned __int8 *)(v26 + 80) + 32) & ~*(unsigned __int8 *)(v26 + 80);
      uint64_t v28 = *(void *)(v26 + 72);
      uint64_t v29 = (char *)v20 + v28 * v23 + v27;
      char v22 = (char)v41;
      uint64_t v30 = (char *)v41 + v27;
      uint64_t v31 = v17 * v28;
      if ((char *)v41 + v27 < &v29[v31] && v29 < &v30[v31])
      {
        _fatalErrorMessage(_:_:file:line:flags:)("Fatal error", 11, 2, "UnsafeMutablePointer.initialize overlapping range", 49, 2, "Swift/UnsafePointer.swift", 25, 2, 1092, 1);
        BUG();
      }
      swift_arrayInitWithCopy(v29, v30, v17, v25);
      if (v17)
      {
        BOOL v32 = __OFADD__(v20[2], v17);
        uint64_t v33 = v20[2] + v17;
        if (v32) {
          BUG();
        }
        void v20[2] = v33;
      }
    }
    else if (v17)
    {
      BUG();
    }
    swift_bridgeObjectRelease(v22);
    uint64_t v2 = v15;
    unint64_t v3 = v42;
  }
  int64_t v9 = v43 + 2;
  if (v43 + 2 >= v45) {
    goto LABEL_37;
  }
  unint64_t v7 = *(void *)(v37 + 8 * v6 + 8);
  if (v7) {
    goto LABEL_16;
  }
  int64_t v9 = v43 + 3;
  if (v43 + 3 >= v45) {
    goto LABEL_37;
  }
  unint64_t v7 = *(void *)(v37 + 8 * v6 + 16);
  if (v7) {
    goto LABEL_16;
  }
  int64_t v9 = v43 + 4;
  if (v43 + 4 >= v45) {
    goto LABEL_37;
  }
  unint64_t v7 = *(void *)(v37 + 8 * v6 + 24);
  if (v7) {
    goto LABEL_16;
  }
  int64_t v9 = v43 + 5;
  if (v43 + 5 >= v45) {
    goto LABEL_37;
  }
  unint64_t v7 = *(void *)(v37 + 8 * v6 + 32);
  if (v7)
  {
LABEL_16:
    int64_t v8 = v9;
    goto LABEL_17;
  }
  int64_t v34 = v43 + 6;
  while (v34 < v45)
  {
    unint64_t v7 = *(void *)(v37 + 8 * v34++);
    if (v7)
    {
      int64_t v8 = v34 - 1;
      goto LABEL_17;
    }
  }
LABEL_37:
  swift_release();
  return v44;
}

void *static MLSoundClassifier.FeatureExtractor.extractFeatures(from:options:)(uint64_t a1, long long *a2)
{
  uint64_t v14 = v3;
  long long v4 = *a2;
  long long v5 = a2[1];
  *(_OWORD *)((char *)v13 + 9) = *(long long *)((char *)a2 + 25);
  v13[0] = v5;
  long long v12 = v4;
  swift_bridgeObjectRetain(a1);
  int64_t v6 = specialized Sequence.flatMap<A>(_:)(a1);
  swift_bridgeObjectRelease(a1);
  swift_allocObject(v3, 88, 7);
  specialized MLSoundClassifier.FeatureExtractor.init<A>(files:options:)((uint64_t)v6, &v12);
  if (!v2)
  {
    int64_t v6 = (void *)MLSoundClassifier.FeatureExtractor.extractFeatures()(v6, &v12, v7, v8, v9, v10);
    swift_release();
  }
  return v6;
}

uint64_t MLSoundClassifier.FeatureExtractor.extractFeatures()()
{
  uint64_t v142 = v0;
  uint64_t v2 = *v1;
  long long v139 = v1;
  uint64_t v126 = v2;
  unint64_t v3 = 0;
  uint64_t v107 = type metadata accessor for URL(0);
  uint64_t v108 = *(void *)(v107 - 8);
  int64_t v4 = *(void *)(v108 + 64);
  long long v5 = alloca(v4);
  int64_t v6 = alloca(v4);
  char v109 = &v107;
  uint64_t v143 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v135 = *(void *)(v143 - 8);
  int64_t v7 = *(void *)(v135 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v116 = &v107;
  int64_t v118 = v7;
  uint64_t v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  uint64_t v141 = &v107;
  uint64_t v131 = type metadata accessor for Date(0);
  unint64_t v132 = *(void *)(v131 - 8);
  int64_t v12 = *(void *)(v132 + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  Swift::String v133 = &v107;
  id v137 = (id)type metadata accessor for _TablePrinter(0);
  BOOL v110 = (uint64_t *)*((void *)v137 - 1);
  int64_t v15 = v110[8];
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  uint64_t v117 = &v107;
  int64_t v119 = v15;
  int64_t v18 = alloca(v15);
  int64_t v19 = alloca(v15);
  uint64_t v138 = &v107;
  uint64_t v20 = v1[8];
  uint64_t v21 = *(void *)(v20 + 16);
  char v22 = objc_opt_self(NSProgress);
  id v23 = [v22 progressWithTotalUnitCount:v21];
  id v24 = v23;
  *(void *)&long long aBlock = 0;
  id v129 = v24;
  *((void *)&aBlock + 1) = 0xE000000000000000;
  _StringGuts.grow(_:)(19);
  swift_bridgeObjectRelease(BYTE8(aBlock));
  *(void *)&long long aBlock = 0x69737365636F7250;
  *((void *)&aBlock + 1) = 0xEB0000000020676ELL;
  uint64_t v120 = v20;
  uint64_t v145 = *(void *)(v20 + 16);
  v25._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  LOBYTE(v21) = v25._object;
  String.append(_:)(v25);
  swift_bridgeObjectRelease(v21);
  v26._uint64_t countAndFlagsBits = 0x73656C696620;
  v26._char object = (void *)0xE600000000000000;
  String.append(_:)(v26);
  unint64_t v28 = *((void *)&aBlock + 1);
  unint64_t v27 = aBlock;
  os_log_type_t v29 = static os_log_type_t.info.getter();
  log(_:type:)((Swift::String)__PAIR128__(v28, v27), v29);
  swift_bridgeObjectRelease(v28);
  uint64_t v130 = swift_allocObject(&unk_399A18, 24, 7);
  *(void *)(v130 + 16) = 0;
  id v30 = objc_allocWithZone((Class)NSOperationQueue);
  id v31 = [v30 init];
  v26._char object = (void *)type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for NSOperationQueue, NSOperationQueue_ptr);
  uint64_t v32 = static Array._allocateBufferUninitialized(minimumCapacity:)(8);
  uint64_t v33 = (void *)(v32 & 0xFFFFFFFFFFFFF8);
  void v33[2] = 8;
  *(void *)&long long aBlock = v32;
  v33[4] = v31;
  v33[5] = v31;
  v33[6] = v31;
  v33[7] = v31;
  char v33[8] = v31;
  v33[9] = v31;
  v33[10] = v31;
  v33[11] = v31;
  id v34 = v31;
  id v35 = v34;
  id v36 = v35;
  id v37 = v36;
  id v38 = v37;
  v26._uint64_t countAndFlagsBits = (uint64_t)v38;
  (id)v26._countAndFlagsBits;
  specialized Array._endMutation()(v26._countAndFlagsBits, v26._object);
  uint64_t v145 = aBlock;
  uint64_t v136 = swift_allocObject(&unk_399A40, 24, 7);
  uint64_t v146 = (uint64_t *)(v136 + 16);
  long long v115 = *((_OWORD *)v139 + 1);
  uint64_t v39 = (uint64_t (*)(uint64_t))v139[4];
  unint64_t v40 = (void (*)(void, void, void))v139[5];
  uint64_t v41 = (void (*)())v139[6];
  LOBYTE(v26._object) = *((unsigned char *)v139 + 56);
  long long aBlock = v115;
  uint64_t v144 = (uint64_t)v39;
  uint64_t v122 = v39;
  char v140 = v40;
  uint64_t v123 = v40;
  uint64_t v127 = v41;
  uint64_t v124 = v41;
  LOBYTE(v134) = v26._object;
  LOBYTE(v125) = v26._object;
  id v42 = static MLSoundClassifier.FeatureExtractor.getFeaturePrintRequest(options:)((uint64_t)&aBlock);
  v26._char object = (void *)type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for SNCreateFeaturePrintRequest, SNCreateFeaturePrintRequest_ptr);
  uint64_t v43 = static Array._allocateBufferUninitialized(minimumCapacity:)(8);
  uint64_t v44 = (void *)(v43 & 0xFFFFFFFFFFFFF8);
  v44[2] = 8;
  *(void *)&long long aBlock = v43;
  v44[4] = v42;
  v44[5] = v42;
  v44[6] = v42;
  v44[7] = v42;
  v44[8] = v42;
  v44[9] = v42;
  v44[10] = v42;
  v44[11] = v42;
  id v45 = v42;
  id v46 = v45;
  id v47 = v46;
  id v48 = v47;
  id v49 = v48;
  v26._uint64_t countAndFlagsBits = (uint64_t)v49;
  (id)v26._countAndFlagsBits;
  specialized Array._endMutation()(v26._countAndFlagsBits, v26._object);
  uint64_t v50 = aBlock;
  float v51 = *(double *)&v115;
  *(float *)&uint64_t v128 = v51;
  *(void *)(v136 + 16) = aBlock;
  uint64_t v52 = v145;
  do
  {
    id v53 = objc_allocWithZone((Class)NSOperationQueue);
    id v54 = [v53 init];
    if (!swift_isUniquelyReferenced_nonNull_bridgeObject(v52) || (v52 & 0x4000000000000001) != 0)
    {
      uint64_t v52 = specialized _ArrayBuffer._consumeAndCreateNew()(v52);
      uint64_t v145 = v52;
    }
    uint64_t v55 = v52 & 0xFFFFFFFFFFFFF8;
    if (v3 >= *(void *)(v55 + 16)) {
      BUG();
    }
    char v56 = *(void **)(v55 + 8 * v3 + 32);
    *(void *)(v55 + 8 * v3 + 32) = v54;

    specialized Array._endMutation()(v56, "init");
    uint64_t v52 = v145;
    if ((v145 & 0xC000000000000003) != 0)
    {
      id v57 = (id)specialized _ArrayBuffer._getElementSlowPath(_:)(v3, v145);
    }
    else
    {
      if (v3 >= *(void *)((char *)&dword_10 + (v145 & 0xFFFFFFFFFFFFF8))) {
        BUG();
      }
      id v57 = *(id *)(v145 + 8 * v3 + 32);
    }
    uint64_t v58 = v57;
    [v57 setMaxConcurrentOperationCount:1];

    long long aBlock = v115;
    uint64_t v122 = (uint64_t (*)(uint64_t))v144;
    uint64_t v123 = v140;
    uint64_t v124 = v127;
    LOBYTE(v125) = v134;
    id v59 = static MLSoundClassifier.FeatureExtractor.getFeaturePrintRequest(options:)((uint64_t)&aBlock);
    char isUniquelyReferenced_nonNull_bridgeObject = swift_isUniquelyReferenced_nonNull_bridgeObject(v50);
    uint64_t *v146 = v50;
    if (!isUniquelyReferenced_nonNull_bridgeObject || (v50 & 0x4000000000000001) != 0)
    {
      uint64_t v50 = specialized _ArrayBuffer._consumeAndCreateNew()(v50);
      uint64_t *v146 = v50;
    }
    uint64_t v61 = v50 & 0xFFFFFFFFFFFFF8;
    if (v3 >= *(void *)(v61 + 16)) {
      BUG();
    }
    uint64_t v62 = *(void **)(v61 + 8 * v3 + 32);
    *(void *)(v61 + 8 * v3 + 32) = v59;

    uint64_t v63 = v146;
    specialized Array._endMutation()(v62, "setMaxConcurrentOperationCount:");
    uint64_t v50 = *v63;
    if ((*v63 & 0xC000000000000003) != 0)
    {
      id v64 = (id)specialized _ArrayBuffer._getElementSlowPath(_:)(v3, *v63);
    }
    else
    {
      if (v3 >= *(void *)((char *)&dword_10 + (v50 & 0xFFFFFFFFFFFFF8))) {
        BUG();
      }
      id v64 = *(id *)(v50 + 8 * v3 + 32);
    }
    uint64_t v65 = v64;
    ++v3;
    [v64 setOverlapFactor:COERCE_DOUBLE((unint64_t)v128)];
  }
  while (v3 != 8);
  uint64_t v66 = (int *)v137;
  uint64_t v67 = v138;
  uint64_t v68 = (char *)v138 + *((int *)v137 + 5);
  Date.init()(v65);
  uint64_t *v67 = (uint64_t)v140;
  type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for OS_os_log, OS_os_log_ptr);
  uint64_t v69 = OS_os_log.init(subsystem:category:)(0xD000000000000022, "n" + 0x8000000000000000, 0x72705F656C626174, 0xED00007265746E69);
  uint64_t v114 = v66[6];
  *(uint64_t *)((char *)v67 + v114) = v69;
  uint64_t v70 = v66[7];
  *(uint64_t *)((char *)v67 + v70) = 0x73656C6946;
  *(uint64_t *)((char *)v67 + v70 + 8) = 0xE500000000000000;
  uint64_t v71 = v133;
  Date.init()(0xD000000000000022);
  (*(void (**)(char *, uint64_t *, uint64_t))(v132 + 40))(v68, v71, v131);
  _TablePrinter.beginTable()();
  _TablePrinter.printRow(currentFileIndex:)(0);
  uint64_t v72 = swift_allocObject(&unk_399A68, 24, 7);
  uint64_t v144 = v72;
  *(void *)(v72 + 16) = _swiftEmptyArrayStorage;
  uint64_t v73 = *(uint64_t **)(v120 + 16);
  if (v73)
  {
    uint64_t v127 = (void (*)())v139[10];
    uint64_t v74 = *(unsigned __int8 *)(v135 + 80);
    uint64_t v112 = ~v74;
    uint64_t v75 = v120 + ((v74 + 32) & ~v74);
    char v140 = *(void (**)(void, void, void))(v135 + 16);
    uint64_t v128 = *(void *)(v135 + 72);
    v119 += 7;
    uint64_t v111 = v74;
    uint64_t v113 = v74 + 8;
    v118 += 7;
    swift_bridgeObjectRetain(v120);
    uint64_t v134 = 0;
    uint64_t v76 = v143;
    uint64_t v77 = v141;
    do
    {
      uint64_t v146 = v73;
      *(void *)&long long v115 = v75;
      v140(v77, v75, v76);
      unint64_t v78 = v109;
      AnnotatedFeature.feature.getter(v76);
      char v79 = alloca(32);
      char v80 = alloca(32);
      char v109 = v139;
      BOOL v110 = v78;
      uint64_t v81 = v142;
      unsigned __int8 v82 = specialized NSLocking.withLock<A>(_:)((void (*)(void))partial apply for closure #1 in MLSoundClassifier.FeatureExtractor.isProcessed(url:));
      (*(void (**)(uint64_t *, uint64_t))(v108 + 8))(v78, v107);
      uint64_t v142 = v81;
      if (v82)
      {
        uint64_t v77 = v141;
        uint64_t v76 = v143;
        (*(void (**)(uint64_t *, uint64_t))(v135 + 8))(v141, v143);
      }
      else
      {
        uint64_t v83 = v134 % 8;
        uint64_t v131 = v134 % 8;
        if ((v145 & 0xC000000000000003) != 0)
        {
          id v137 = (id)specialized _ArrayBuffer._getElementSlowPath(_:)(v134 % 8, v145);
          uint64_t v84 = v143;
          unint64_t v85 = v141;
        }
        else
        {
          uint64_t v84 = v143;
          unint64_t v85 = v141;
          if (v83 < 0) {
            BUG();
          }
          if ((unint64_t)v83 >= *(void *)((char *)&dword_10 + (v145 & 0xFFFFFFFFFFFFF8))) {
            BUG();
          }
          id v137 = *(id *)(v145 + 8 * v83 + 32);
        }
        outlined init with copy of _TablePrinter((uint64_t)v138, (uint64_t)v117);
        v140(v116, v85, v84);
        uint64_t v86 = *((unsigned __int8 *)v110 + 80);
        uint64_t v87 = ~*((unsigned __int8 *)v110 + 80) & (v86 + 48);
        unint64_t v132 = (v87 + v119) & 0xFFFFFFFFFFFFFFF8;
        Swift::String v133 = (uint64_t *)((v132 + 15) & 0xFFFFFFFFFFFFFFF8);
        unint64_t v88 = v112 & ((unint64_t)v133 + v113);
        unint64_t v89 = (v118 + v88) & 0xFFFFFFFFFFFFFFF8;
        uint64_t v90 = (char *)swift_allocObject(&unk_399A90, v89 + 8, v111 | v86 | 7);
        *((void *)v90 + 2) = v139;
        *((void *)v90 + 3) = v144;
        *((void *)v90 + 4) = v130;
        *((void *)v90 + 5) = v129;
        outlined init with take of _TablePrinter((uint64_t)v117, (uint64_t)&v90[v87]);
        *(void *)&v90[v132] = v136;
        *(uint64_t *)((char *)v133 + (void)v90) = v131;
        (*(void (**)(char *, uint64_t *, uint64_t))(v135 + 32))(&v90[v88], v116, v143);
        *(void *)&v90[v89] = v126;
        uint64_t v76 = v143;
        uint64_t v124 = partial apply for closure #1 in MLSoundClassifier.FeatureExtractor.extractFeatures();
        uint64_t v125 = v90;
        uint64_t v77 = v141;
        *(void *)&long long aBlock = _NSConcreteStackBlock;
        *((void *)&aBlock + 1) = 1107296256;
        uint64_t v122 = thunk for @escaping @callee_guaranteed @Sendable () -> ();
        uint64_t v123 = &block_descriptor_6;
        uint64_t v91 = _Block_copy(&aBlock);
        swift_retain();
        swift_retain();
        swift_retain();
        v129;
        swift_retain();
        swift_release();
        id v92 = v137;
        [v137 addOperationWithBlock:v91];
        _Block_release(v91);

        (*(void (**)(uint64_t *, uint64_t))(v135 + 8))(v77, v76);
        if (__OFADD__(1, v134++)) {
          BUG();
        }
      }
      uint64_t v75 = v128 + v115;
      uint64_t v73 = (uint64_t *)((char *)v146 - 1);
    }
    while (v146 != (uint64_t *)((char *)&dword_0 + 1));
    swift_bridgeObjectRelease(v120);
  }
  uint64_t v94 = v142;
  uint64_t v95 = v145;
  if ((v145 & 0x4000000000000001) != 0)
  {
    uint64_t v106 = v145 & 0xFFFFFFFFFFFFF8;
    if (v145) {
      uint64_t v106 = v145;
    }
    swift_bridgeObjectRetain(v145);
    uint64_t v96 = _CocoaArrayWrapper.endIndex.getter(v106);
  }
  else
  {
    uint64_t v96 = *(void *)((char *)&dword_10 + (v145 & 0xFFFFFFFFFFFFF8));
    swift_bridgeObjectRetain(v145);
  }
  uint64_t v142 = v94;
  if (v96)
  {
    if (v96 <= 0) {
      BUG();
    }
    for (uint64_t i = 0; i != v96; ++i)
    {
      if ((v95 & 0xC000000000000003) != 0) {
        id v98 = (id)specialized _ArrayBuffer._getElementSlowPath(_:)(i, v95);
      }
      else {
        id v98 = *(id *)(v95 + 8 * i + 32);
      }
      char v99 = v98;
      [v98 waitUntilAllOperationsAreFinished];
    }
  }
  uint64_t v100 = v144 + 16;
  swift_bridgeObjectRelease(v95);
  uint64_t v146 = *(uint64_t **)((char *)v138 + v114);
  static os_log_type_t.info.getter();
  uint64_t v101 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v102 = (void *)swift_allocObject(v101, 72, 7);
  char v103 = (char)v102;
  v102[2] = 1;
  v102[3] = 2;
  v102[7] = &type metadata for Int;
  v102[8] = &protocol witness table for Int;
  v102[4] = 3;
  os_log(_:dso:log:type:_:)("event: %lu", 10);

  swift_bridgeObjectRelease(v103);
  outlined destroy of _TablePrinter((uint64_t)v138);
  swift_beginAccess(v100, &aBlock, 0, 0);
  uint64_t v104 = *(void *)(v144 + 16);
  swift_bridgeObjectRetain(v104);
  swift_release();
  swift_bridgeObjectRelease(v95);
  swift_release();
  swift_release();
  return v104;
}

id static MLSoundClassifier.FeatureExtractor.getFeaturePrintRequest(options:)(uint64_t a1)
{
  char v1 = *(unsigned char *)(a1 + 40);
  if (v1 == -1)
  {
    id v2 = objc_allocWithZone((Class)SNCreateFeaturePrintRequest);
  }
  else
  {
    Swift::Double seconds = *(double *)(a1 + 8);
    id v2 = objc_allocWithZone((Class)SNCreateFeaturePrintRequest);
    if (v1)
    {
      id v3 = [v2 initWithFeaturePrintType:3];
      CMTime v9 = CMTime.init(seconds:preferredTimescale:)(seconds, 16000);
      LODWORD(v7) = v9.timescale;
      *(void *)&v9.timescale >>= 32;
      HIDWORD(v7) = v9.timescale;
      [v3 setWindowDuration:v9.timescale, v9.epoch, v4, v5, v9.value, v7, v9.epoch, v9.value, v7, v9.epoch];
      return v3;
    }
  }
  return [v2 init];
}

void trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, void *a6, long long a7)
{
}

NSURL *closure #1 in trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(uint64_t a1, uint64_t *a2, uint64_t a3, uint64_t a4, void *a5, void *a6)
{
  id v51 = a6;
  uint64_t v43 = a5;
  uint64_t v49 = a4;
  uint64_t v46 = a3;
  char v56 = a2;
  uint64_t v45 = type metadata accessor for URL(0);
  uint64_t v44 = *(void *)(v45 - 8);
  int64_t v7 = *(void *)(v44 + 64);
  uint64_t v8 = alloca(v7);
  CMTime v9 = alloca(v7);
  id v48 = &v42;
  uint64_t v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  id v47 = &v42;
  int64_t v12 = alloca(v7);
  uint64_t v13 = alloca(v7);
  uint64_t v50 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  AnnotatedFeature.feature.getter(v50);
  objc_allocWithZone((Class)SNAudioFileAnalyzer);
  id v14 = @nonobjc SNAudioFileAnalyzer.init(url:)((uint64_t)&v42);
  uint64_t v57 = v6;
  if (v6)
  {
    uint64_t v34 = 123;
    uint64_t v35 = v57;
    goto LABEL_12;
  }
  int64_t v15 = v14;
  id v16 = objc_allocWithZone((Class)SNResultsCollector);
  id v17 = [v16 init];
  v60[0] = 0;
  unsigned __int8 v18 = [v15 addRequest:v56 withObserver:v17 error:v60];
  id v19 = v60[0];
  if (!v18)
  {
    id v36 = v60[0];
    uint64_t v37 = _convertNSErrorToError(_:)(v19);

    swift_willThrow(v36, "addRequest:withObserver:error:", v38, v39, v40, v41);
    uint64_t v34 = 125;
    uint64_t v35 = v37;
LABEL_12:
    swift_unexpectedError(v35, "CreateML/MLSoundClassifier.FeatureExtractor.swift", 49, 1, v34);
    BUG();
  }
  v60[0];
  id v53 = v15;
  [v15 analyze];
  uint64_t v20 = v46;
  uint64_t v52 = *(void *)(v46 + 32);
  id v54 = v17;
  uint64_t v21 = static MLSoundClassifier.FeatureExtractor.convertResultsToShapedArrays(resultsCollector:options:)(v17);
  id v55 = *(id *)(v20 + 80);
  [v55 lock];
  char v56 = &v42;
  char v22 = alloca(24);
  id v23 = alloca(32);
  uint64_t v44 = a1;
  uint64_t v24 = v57;
  Swift::String v25 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay6CoreML13MLShapedArrayVySfGG_18CreateMLComponents16AnnotatedFeatureVyAISSGs5NeverOTg5((void (*)(uint64_t))partial apply for closure #1 in closure #1 in trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures(), &v42, (uint64_t)v21, (uint64_t)v58);
  uint64_t v57 = v24;
  swift_bridgeObjectRelease((_BYTE)v21);
  swift_beginAccess(v49, v60, 33, 0);
  specialized Array.append<A>(contentsOf:)((uint64_t)v25);
  swift_endAccess(v60);
  Swift::String v26 = v48;
  AnnotatedFeature.feature.getter(v50);
  swift_beginAccess(v20 + 72, v60, 33, 0);
  unint64_t v27 = v47;
  specialized Set._Variant.insert(_:)(v47, v26);
  swift_endAccess(v60);
  (*(void (**)(uint64_t *, uint64_t))(v44 + 8))(v27, v45);
  unint64_t v28 = v43;
  swift_beginAccess(v43, v60, 1, 0);
  if (__OFADD__(1, *v28)) {
    BUG();
  }
  ++*v28;
  id v29 = v51;
  id v30 = (char *)[v51 completedUnitCount];
  BOOL v31 = __OFADD__(1, v30);
  uint64_t v32 = v30 + 1;
  if (v31) {
    BUG();
  }
  [v29 setCompletedUnitCount:v32];
  swift_beginAccess(v28, v59, 0, 0);
  if (__OFADD__(*v28, v52)) {
    BUG();
  }
  _TablePrinter.printRow(currentFileIndex:)(*v28 + v52);
  [v55 unlock];

  return __stack_chk_guard;
}

void *static MLSoundClassifier.FeatureExtractor.convertResultsToShapedArrays(resultsCollector:options:)(id a1)
{
  uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  uint64_t v35 = *(void *)(v34 - 8);
  int64_t v1 = *(void *)(v35 + 64);
  id v2 = alloca(v1);
  id v3 = alloca(v1);
  uint64_t v33 = v26;
  uint64_t v4 = alloca(v1);
  uint64_t v5 = alloca(v1);
  id v36 = v26;
  id v6 = [a1 results];
  id v7 = v6;
  uint64_t v8 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v7, (char *)&type metadata for Any + 8);

  int64_t v9 = *(void *)(v8 + 16);
  swift_bridgeObjectRelease(v8);
  uint64_t v37 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v9, 0, (uint64_t)_swiftEmptyArrayStorage);
  id v10 = [a1 results];
  id v11 = v10;
  BOOL v31 = (char *)&type metadata for Any + 8;
  uint64_t v12 = static Array._unconditionallyBridgeFromObjectiveC(_:)(v11, (char *)&type metadata for Any + 8);

  uint64_t v13 = *(void *)(v12 + 16);
  if (v13)
  {
    uint64_t v14 = v35;
    uint64_t v32 = v12;
    uint64_t v15 = v12 + 32;
    uint64_t v16 = v34;
    id v17 = v36;
    unsigned __int8 v18 = v37;
    do
    {
      uint64_t v37 = v18;
      uint64_t v28 = v13;
      uint64_t v29 = v15;
      outlined init with copy of Any(v15, (uint64_t)v26);
      uint64_t v19 = type metadata accessor for OS_os_log(0, &lazy cache variable for type metadata for SNFeaturePrint, SNFeaturePrint_ptr);
      swift_dynamicCast(&v27, v26, v31, v19, 7);
      id v30 = v27;
      id v20 = [v27 featureVector];
      id v21 = v20;
      static MLSoundClassifier.FeatureExtractor.convertVector(_:)(v21);
      ((void (*)(id))objc_release)(v21);
      (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v14 + 16))(v33, v17, v16);
      char v22 = v37;
      unint64_t v23 = v37[2];
      if (v37[3] >> 1 <= v23) {
        char v22 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v37[3] >= 2uLL, v23 + 1, 1, (uint64_t)v37);
      }
      v22[2] = v23 + 1;
      uint64_t v14 = v35;
      uint64_t v16 = v34;
      unsigned __int8 v18 = v22;
      (*(void (**)(char *, unsigned char *, uint64_t))(v35 + 32))((char *)v22+ ((*(unsigned __int8 *)(v35 + 80) + 32) & ~*(unsigned __int8 *)(v35 + 80))+ *(void *)(v35 + 72) * v23, v33, v34);

      id v17 = v36;
      (*(void (**)(unsigned char *, uint64_t))(v14 + 8))(v36, v16);
      uint64_t v15 = v29 + 32;
      uint64_t v13 = v28 - 1;
    }
    while (v28 != 1);
    uint64_t v37 = v18;
    char v24 = v32;
  }
  else
  {
    char v24 = v12;
  }
  swift_bridgeObjectRelease(v24);
  return v37;
}

uint64_t closure #1 in closure #1 in trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(uint64_t a1)
{
  uint64_t v11 = v1;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  uint64_t v3 = *(void *)(v2 - 8);
  int64_t v4 = *(void *)(v3 + 64);
  uint64_t v5 = alloca(v4);
  id v6 = alloca(v4);
  (*(void (**)(long long *, uint64_t, uint64_t))(v3 + 16))(&v9, a1, v2);
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  AnnotatedFeature.annotation.getter(v7);
  long long v10 = v9;
  return AnnotatedFeature.init(feature:annotation:)(&v9, &v10, v2, &type metadata for String);
}

void closure #1 in MLSoundClassifier.FeatureExtractor.extractFeatures()(uint64_t a1, uint64_t a2, uint64_t a3, void *a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9)
{
  uint64_t v15 = a5;
  uint64_t v16 = a4;
  uint64_t v17 = a3;
  swift_beginAccess(a6 + 16, v14, 32, 0);
  uint64_t v10 = *(void *)(a6 + 16);
  specialized Array._checkSubscript(_:wasNativeTypeChecked:)(a7, (v10 & 0xC000000000000003) == 0, v10);
  if ((v10 & 0xC000000000000003) != 0) {
    uint64_t v11 = (uint64_t *)specialized _ArrayBuffer._getElementSlowPath(_:)(a7, v10);
  }
  else {
    uint64_t v11 = (uint64_t *)*(id *)(v10 + 8 * a7 + 32);
  }
  uint64_t v12 = v11;
  swift_endAccess(v14);
  *((void *)&v13 + 1) = a9;
  *(void *)&long long v13 = v15;
  trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(v12, a8, a1, a2, v17, v16, v13);
}

uint64_t thunk for @escaping @callee_guaranteed @Sendable () -> ()(uint64_t a1)
{
  uint64_t v1 = *(void (**)(void))(a1 + 32);
  uint64_t v2 = *(void *)(a1 + 40);
  swift_retain(v2);
  v1();
  return swift_release(v2);
}

uint64_t closure #1 in MLSoundClassifier.FeatureExtractor.isProcessed(url:)(uint64_t a1, uint64_t a2)
{
  uint64_t v3 = v2;
  swift_beginAccess(a1 + 72, v7, 0, 0);
  uint64_t v4 = *(void *)(a1 + 72);
  swift_bridgeObjectRetain(v4);
  char v5 = specialized Set.contains(_:)(a2, v4);
  uint64_t result = swift_bridgeObjectRelease(v4);
  *uint64_t v3 = v5 & 1;
  return result;
}

uint64_t static MLSoundClassifier.FeatureExtractor.extractFeatures(from:options:)(uint64_t a1, long long *a2)
{
  uint64_t v77 = v2;
  uint64_t v79 = a1;
  uint64_t v4 = type metadata accessor for URL(0);
  uint64_t v5 = *(void *)(v4 - 8);
  int64_t v6 = *(void *)(v5 + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v76 = &v65;
  long long v9 = alloca(v6);
  uint64_t v10 = alloca(v6);
  uint64_t v69 = &v65;
  uint64_t v11 = alloca(v6);
  uint64_t v12 = alloca(v6);
  char v80 = &v65;
  int64_t v13 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                              - 8)
                  + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v74 = &v65;
  uint64_t v16 = *((void *)a2 + 4);
  char v17 = *((unsigned char *)a2 + 40);
  long long v75 = *a2;
  long long v85 = v75;
  long long v86 = a2[1];
  HIDWORD(v18) = DWORD1(v86);
  uint64_t v87 = v16;
  char v88 = v17;
  uint64_t v70 = v3;
  id v19 = static MLSoundClassifier.FeatureExtractor.getFeaturePrintRequest(options:)((uint64_t)&v85);
  *(float *)&double v18 = *(double *)&v75;
  id v78 = v19;
  [v19 setOverlapFactor:v18];
  uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLShapedArray<Float>]);
  uint64_t v21 = lazy protocol witness table accessor for type URL and conformance URL();
  uint64_t v83 = v4;
  uint64_t v81 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, v4, v20, v21);
  uint64_t v22 = *(void *)(v79 + 16);
  if (v22)
  {
    uint64_t v23 = v79 + ((*(unsigned __int8 *)(v5 + 80) + 32) & ~*(unsigned __int8 *)(v5 + 80));
    *(void *)&long long v75 = *(void *)(v5 + 16);
    uint64_t v73 = *(void *)(v5 + 72);
    uint64_t v24 = v23;
    swift_bridgeObjectRetain(v79);
    uint64_t v25 = v83;
    uint64_t v82 = v5;
    while (1)
    {
      uint64_t v66 = v22;
      uint64_t v26 = (uint64_t)v74;
      id v27 = (void (*)(uint64_t *, uint64_t *, uint64_t))v75;
      ((void (*)(uint64_t *, uint64_t, uint64_t))v75)(v74, v24, v25);
      __swift_storeEnumTagSinglePayload(v26, 0, 1, v83);
      uint64_t v28 = v83;
      if (__swift_getEnumTagSinglePayload(v26, 1, v83) == 1) {
        break;
      }
      uint64_t v29 = v26;
      id v30 = v80;
      (*(void (**)(uint64_t *, uint64_t, uint64_t))(v82 + 32))(v80, v29, v28);
      uint64_t v31 = v28;
      uint64_t v32 = (uint64_t)v69;
      v27(v69, v30, v31);
      objc_allocWithZone((Class)SNAudioFileAnalyzer);
      uint64_t v33 = v77;
      id v34 = @nonobjc SNAudioFileAnalyzer.init(url:)(v32);
      uint64_t v77 = v33;
      if (v33)
      {

        (*(void (**)(uint64_t *, uint64_t))(v82 + 8))(v80, v83);
        swift_bridgeObjectRelease(v81);
        return swift_bridgeObjectRelease(v79);
      }
      uint64_t v35 = v34;
      id v36 = objc_allocWithZone((Class)SNResultsCollector);
      id v37 = [v36 init];
      *(void *)&long long v85 = 0;
      unsigned __int8 v38 = [v35 addRequest:v78 withObserver:v37 error:&v85];
      uint64_t v39 = v85;
      if (!v38)
      {
        id v59 = (id)v85;
        swift_bridgeObjectRelease(v81);
        swift_bridgeObjectRelease(v79);
        uint64_t v60 = _convertNSErrorToError(_:)(v39);

        uint64_t v77 = v60;
        swift_willThrow(v59, "addRequest:withObserver:error:", v61, v62, v63, v64);

        return (*(uint64_t (**)(uint64_t *, uint64_t))(v82 + 8))(v80, v83);
      }
      uint64_t v68 = v24;
      (id)v85;
      id v67 = v35;
      [v35 analyze];
      uint64_t v40 = (uint64_t)v76;
      ((void (*)(uint64_t *, uint64_t *, uint64_t))v75)(v76, v80, v83);
      id v71 = v37;
      uint64_t v72 = static MLSoundClassifier.FeatureExtractor.convertResultsToShapedArrays(resultsCollector:options:)(v37);
      uint64_t v41 = v81;
      char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v81);
      *(void *)&long long v85 = v41;
      unint64_t v43 = specialized __RawDictionaryStorage.find<A>(_:)(v40);
      char v84 = v44;
      BOOL v45 = (v44 & 1) == 0;
      BOOL v46 = __OFADD__(*(void *)(v41 + 16), v45);
      Swift::Int v47 = *(void *)(v41 + 16) + v45;
      if (v46) {
        BUG();
      }
      __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<URL, [MLShapedArray<Float>]>);
      Swift::Bool v48 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v47);
      id v49 = v67;
      if (v48)
      {
        unint64_t v43 = specialized __RawDictionaryStorage.find<A>(_:)((uint64_t)v76);
        if ((v84 & 1) != (v50 & 1))
        {
          KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(v83);
          BUG();
        }
      }
      id v51 = (void *)v85;
      uint64_t v81 = v85;
      if (v84)
      {
        uint64_t v52 = *(void *)(v85 + 56);
        swift_bridgeObjectRelease(*(void *)(v52 + 8 * v43));
        *(void *)(v52 + 8 * v43) = v72;
        uint64_t v53 = v82;
        id v54 = v71;
      }
      else
      {
        *(void *)(v85 + 8 * (v43 >> 6) + 64) |= 1 << v43;
        ((void (*)(unint64_t, uint64_t *, uint64_t))v75)(v51[6] + v73 * v43, v76, v83);
        *(void *)(v51[7] + 8 * v43) = v72;
        uint64_t v55 = v51[2];
        BOOL v46 = __OFADD__(1, v55);
        uint64_t v56 = v55 + 1;
        uint64_t v53 = v82;
        id v54 = v71;
        if (v46) {
          BUG();
        }
        v51[2] = v56;
      }
      swift_bridgeObjectRelease(0);
      uint64_t v57 = *(void (**)(uint64_t *, uint64_t))(v53 + 8);
      uint64_t v25 = v83;
      v57(v76, v83);

      v57(v80, v25);
      uint64_t v24 = v73 + v68;
      uint64_t v22 = v66 - 1;
      if (v66 == 1) {
        goto LABEL_16;
      }
    }
  }
  else
  {
    swift_bridgeObjectRetain(v79);
    uint64_t v25 = v83;
LABEL_16:
    __swift_storeEnumTagSinglePayload((uint64_t)v74, 1, 1, v25);
  }

  swift_bridgeObjectRelease(v79);
  return v81;
}

uint64_t static MLSoundClassifier.FeatureExtractor.convertVector(_:)(id a1)
{
  uint64_t v2 = v1;
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Float>);
  uint64_t v4 = *(void *)(v3 - 8);
  int64_t v5 = *(void *)(v4 + 64);
  int64_t v6 = alloca(v5);
  uint64_t v7 = alloca(v5);
  id v8 = a1;
  MLShapedArray.init(_:)(v8, &type metadata for Float, &protocol witness table for Float);
  uint64_t v9 = MLShapedArray.shape.getter(v3);
  uint64_t v10 = *(void *)(v9 + 16);
  uint64_t result = swift_bridgeObjectRelease(v9);
  if (v10 == 2)
  {
    uint64_t v12 = MLShapedArray.shape.getter(v3);
    if (!*(void *)(v12 + 16)) {
      BUG();
    }
    uint64_t v13 = *(void *)(v12 + 32);
    uint64_t result = swift_bridgeObjectRelease(v12);
    if (v13 == 1)
    {
      uint64_t v14 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type MLShapedArray<Float> and conformance MLShapedArray<A>, &demangling cache variable for type metadata for MLShapedArray<Float>, (uint64_t)&protocol conformance descriptor for MLShapedArray<A>);
      uint64_t v21 = MLShapedArrayProtocol.scalars.getter(v3, v14);
      uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
      uint64_t v16 = (void *)swift_allocObject(v15, 40, 7);
      void v16[2] = 1;
      void v16[3] = 2;
      uint64_t v17 = MLShapedArray.shape.getter(v3);
      if (*(void *)(v17 + 16) < 2uLL) {
        BUG();
      }
      uint64_t v22 = &v21;
      uint64_t v18 = *(void *)(v17 + 40);
      swift_bridgeObjectRelease(v17);
      void v16[4] = v18;
      uint64_t v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Float]);
      uint64_t v19 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [Float] and conformance [A], &demangling cache variable for type metadata for [Float], (uint64_t)&protocol conformance descriptor for [A]);
      uint64_t v20 = v22;
      MLShapedArray.init<A>(scalars:shape:)(&v21, v16, &type metadata for Float, v23, &protocol witness table for Float, v19);
      (*(void (**)(uint64_t, uint64_t))(v4 + 8))(v2, v3);
      return (*(uint64_t (**)(uint64_t, uint64_t *, uint64_t))(v4 + 32))(v2, v20, v3);
    }
  }
  return result;
}

uint64_t MLSoundClassifier.FeatureExtractor.deinit()
{
  swift_bridgeObjectRelease(*(void *)(v0 + 64));
  swift_bridgeObjectRelease(*(void *)(v0 + 72));

  return v0;
}

uint64_t MLSoundClassifier.FeatureExtractor.__deallocating_deinit()
{
  MLSoundClassifier.FeatureExtractor.deinit();
  return swift_deallocClassInstance(v0, 88, 7);
}

uint64_t type metadata accessor for MLSoundClassifier.FeatureExtractor()
{
  return objc_opt_self(_TtCV8CreateML17MLSoundClassifier16FeatureExtractor);
}

_OWORD *__swift_memcpy41_8(_OWORD *a1, long long *a2)
{
  uint64_t result = a1;
  long long v3 = *a2;
  long long v4 = a2[1];
  *(_OWORD *)((char *)a1 + 25) = *(long long *)((char *)a2 + 25);
  a1[1] = v4;
  *a1 = v3;
  return result;
}

uint64_t getEnumTagSinglePayload for MLSoundClassifier.FeatureExtractor.Configuration(uint64_t a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 >= 0xFE && *(unsigned char *)(a1 + 41))
    {
      int v2 = *(_DWORD *)a1 + 253;
    }
    else
    {
      int v2 = -1;
      if (*(unsigned __int8 *)(a1 + 40) >= 2u) {
        int v2 = (*(unsigned __int8 *)(a1 + 40) ^ 0xFF) - 1;
      }
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for MLSoundClassifier.FeatureExtractor.Configuration(uint64_t a1, unsigned int a2, unsigned int a3)
{
  if (a2 > 0xFD)
  {
    *(_OWORD *)(a1 + 24) = 0;
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 - 254;
    *(unsigned char *)(a1 + 40) = 0;
    if (a3 >= 0xFE) {
      *(unsigned char *)(a1 + 41) = 1;
    }
  }
  else
  {
    if (a3 >= 0xFE) {
      *(unsigned char *)(a1 + 41) = 0;
    }
    if (a2) {
      *(unsigned char *)(a1 + 40) = ~(_BYTE)a2;
    }
  }
}

ValueMetadata *type metadata accessor for MLSoundClassifier.FeatureExtractor.Configuration()
{
  return &type metadata for MLSoundClassifier.FeatureExtractor.Configuration;
}

id @nonobjc SNAudioFileAnalyzer.init(url:)(uint64_t a1)
{
  URL._bridgeToObjectiveC()(__stack_chk_guard);
  long long v3 = v2;
  id v12 = 0;
  id v4 = [v1 initWithURL:v2 error:&v12];

  id v5 = v12;
  id v11 = v4;
  if (v4)
  {
    uint64_t v6 = type metadata accessor for URL(0);
    uint64_t v7 = *(void (**)(uint64_t, uint64_t))(*(void *)(v6 - 8) + 8);
    v5;
    v7(a1, v6);
  }
  else
  {
    id v8 = v12;
    _convertNSErrorToError(_:)(v5);

    swift_willThrow();
    uint64_t v9 = type metadata accessor for URL(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(a1, v9);
  }
  return v11;
}

uint64_t sub_13B982()
{
  return swift_deallocObject(v0, 24, 7);
}

uint64_t sub_13B9A3()
{
  swift_bridgeObjectRelease(*(void *)(v0 + 16));
  return swift_deallocObject(v0, 24, 7);
}

uint64_t partial apply for closure #1 in MLSoundClassifier.FeatureExtractor.isProcessed(url:)()
{
  return closure #1 in MLSoundClassifier.FeatureExtractor.isProcessed(url:)(*(void *)(v0 + 16), *(void *)(v0 + 24));
}

uint64_t outlined init with copy of _TablePrinter(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for _TablePrinter(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t sub_13B9FE()
{
  uint64_t v15 = (int *)type metadata accessor for _TablePrinter(0);
  uint64_t v1 = *((void *)v15 - 1);
  uint64_t v2 = *(unsigned __int8 *)(v1 + 80);
  uint64_t v3 = ~*(unsigned __int8 *)(v1 + 80) & (v2 + 48);
  unint64_t v4 = (((v3 + *(void *)(v1 + 64) + 7) & 0xFFFFFFFFFFFFFFF8) + 15) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>);
  uint64_t v5 = *(void *)(v12 - 8);
  uint64_t v6 = *(unsigned __int8 *)(v5 + 80);
  uint64_t v14 = v5;
  uint64_t v7 = ~v6 & (v6 + v4 + 8);
  uint64_t v13 = v6 | v2 | 7;
  unint64_t v16 = ((v7 + *(void *)(v5 + 64) + 7) & 0xFFFFFFFFFFFFFFF8) + 8;
  swift_release();
  swift_release();
  swift_release();

  uint64_t v8 = v0 + v3;
  uint64_t v9 = v8 + v15[5];
  uint64_t v10 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v10 - 8) + 8))(v9, v10);

  swift_bridgeObjectRelease(*(void *)(v15[7] + v8 + 8));
  swift_release();
  (*(void (**)(uint64_t, uint64_t))(v14 + 8))(v0 + v7, v12);
  return swift_deallocObject(v0, v16, v13);
}

uint64_t outlined init with take of _TablePrinter(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for _TablePrinter(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

void partial apply for closure #1 in MLSoundClassifier.FeatureExtractor.extractFeatures()()
{
  uint64_t v1 = *(void *)(type metadata accessor for _TablePrinter(0) - 8);
  uint64_t v2 = ~*(unsigned __int8 *)(v1 + 80) & (*(unsigned __int8 *)(v1 + 80) + 48);
  unint64_t v3 = (*(void *)(v1 + 64) + v2 + 7) & 0xFFFFFFFFFFFFFFF8;
  unint64_t v4 = (v3 + 15) & 0xFFFFFFFFFFFFFFF8;
  uint64_t v5 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<URL, String>)
                 - 8);
  unint64_t v6 = (*(unsigned __int8 *)(v5 + 80) + v4 + 8) & ~(unint64_t)*(unsigned __int8 *)(v5 + 80);
  closure #1 in MLSoundClassifier.FeatureExtractor.extractFeatures()(*(void *)(v0 + 16), *(void *)(v0 + 24), *(void *)(v0 + 32), *(void **)(v0 + 40), v0 + v2, *(void *)(v0 + v3), *(void *)(v0 + v4), v0 + v6, *(void *)(v0 + ((v6 + *(void *)(v5 + 64) + 7) & 0xFFFFFFFFFFFFFFF8)));
}

uint64_t block_copy_helper_4(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 40);
  *(_OWORD *)(a1 + 32) = *(_OWORD *)(a2 + 32);
  return swift_retain(v2);
}

uint64_t block_destroy_helper_4(uint64_t a1)
{
  return swift_release(*(void *)(a1 + 40));
}

uint64_t outlined destroy of _TablePrinter(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for _TablePrinter(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v1 - 8) + 8))(a1, v1);
  return a1;
}

void specialized trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(uint64_t *a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, void *a6, long long a7)
{
  uint64_t v7 = a4 + 16;
  uint64_t v8 = (void *)(a5 + 16);
  closure #1 in trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(a2, a1, a3, v7, v8, a6);
}

uint64_t partial apply for closure #1 in closure #1 in trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(uint64_t a1)
{
  return closure #1 in closure #1 in trainWork #1 (_:annotatedFeature:) in MLSoundClassifier.FeatureExtractor.extractFeatures()(a1);
}

uint64_t sub_13BD1E()
{
  return sub_13B9A3();
}

uint64_t MLHandPoseClassifier.ModelParameters.init(validation:batchSize:maximumIterations:augmentationOptions:algorithm:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4)
{
  uint64_t v6 = v4;
  uint64_t v7 = *a4;
  outlined init with take of MLClassifierMetrics(a1, v4, type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
  uint64_t v8 = (int *)type metadata accessor for MLHandPoseClassifier.ModelParameters(0);
  *(void *)(v6 + v8[5]) = a2;
  *(void *)(v6 + v8[6]) = a3;
  uint64_t result = v8[7];
  *(void *)(v6 + result) = v7;
  return result;
}

uint64_t type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLHandPoseClassifier.ModelParameters.ValidationData, (uint64_t)&nominal type descriptor for MLHandPoseClassifier.ModelParameters.ValidationData);
}

uint64_t type metadata accessor for MLHandPoseClassifier.ModelParameters(uint64_t a1)
{
  return type metadata accessor for MLImageClassifier.CustomFeatureExtractor(a1, (uint64_t *)&type metadata singleton initialization cache for MLHandPoseClassifier.ModelParameters, (uint64_t)&nominal type descriptor for MLHandPoseClassifier.ModelParameters);
}

char MLHandPoseClassifier.ModelParameters.ValidationData.extractAnnotations(trainingData:)(uint64_t *a1, void *a2, __m128 a3)
{
  uint64_t v55 = v3;
  uint64_t v51 = v4;
  uint64_t v53 = a2;
  id v54 = a1;
  uint64_t v5 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
  int64_t v6 = *(void *)(*(void *)(v5 - 8) + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  *(void *)&long long v46 = &v41;
  uint64_t v9 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  int64_t v10 = *(void *)(*(void *)(v9 - 8) + 64);
  id v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v13 = v55;
  LOBYTE(v14) = MLHandPoseClassifier.DataSource.imagesWithAnnotations()(a3);
  if (v13) {
    return (char)v14;
  }
  uint64_t v47 = v5;
  uint64_t v52 = v48;
  LOBYTE(v55) = BYTE8(v48);
  outlined init with copy of MLHandPoseClassifier.ModelParameters.ValidationData(v51, (uint64_t)&v41);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v41, v9);
  if (!EnumCaseMultiPayload)
  {
    uint64_t v51 = 0;
    long long v46 = v41;
    char v20 = BYTE1(v42);
    LOBYTE(v47) = v42;
    uint64_t v21 = v52;
    *(void *)&long long v48 = v52;
    char v22 = v55;
    BYTE8(v48) = v55;
    if (MLDataTable.size.getter() > 0)
    {
      uint64_t v42 = v21;
      char v43 = v22;
      long long v48 = v46;
      char v49 = v47;
      char v50 = v20 & 1;
      MLDataTable.randomSplitBySequence(strategy:by:on:)(&v41, &v44, (uint64_t)&v48, 0x7461506567616D69, (void *)0xE900000000000068, 0x6C6562616CLL, (void *)0xE500000000000000);
      outlined consume of Result<_DataTable, Error>(v21, v22);
      uint64_t v14 = (void *)v41;
      char v23 = BYTE8(v41);
      char v24 = v45;
      uint64_t v25 = v54;
      *id v54 = v44;
      *((unsigned char *)v25 + 8) = v24;
      uint64_t v26 = v53;
      *uint64_t v53 = v14;
      *((unsigned char *)v26 + 8) = v23;
      return (char)v14;
    }
LABEL_11:
    outlined consume of Result<_DataTable, Error>(v21, v22);
    uint64_t v29 = v54;
    *id v54 = 0;
    LOBYTE(v14) = -1;
    *((unsigned char *)v29 + 8) = -1;
    id v30 = v53;
    *uint64_t v53 = 0;
    *((unsigned char *)v30 + 8) = -1;
    return (char)v14;
  }
  if (EnumCaseMultiPayload != 1)
  {
    uint64_t v21 = v52;
    *(void *)&long long v48 = v52;
    char v22 = v55;
    BYTE8(v48) = v55;
    MLDataTable.size.getter();
    if (v27)
    {
      uint64_t v28 = v54;
      *id v54 = v21;
      *((unsigned char *)v28 + 8) = v22;
      uint64_t v14 = v53;
      *uint64_t v53 = 0;
      *((unsigned char *)v14 + 8) = -1;
      return (char)v14;
    }
    goto LABEL_11;
  }
  int v16 = swift_getEnumCaseMultiPayload(&v41, v47);
  if (v16 == 5)
  {
    outlined consume of Result<_DataTable, Error>(v52, v55);
    uint64_t v31 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
    swift_bridgeObjectRelease(*(void *)((char *)&v41 + v31[12] + 8));
    swift_bridgeObjectRelease(*(void *)((char *)&v41 + v31[16] + 8));
    swift_bridgeObjectRelease(*(void *)((char *)&v41 + v31[20] + 8));
    uint64_t v32 = type metadata accessor for DataFrame(0);
    (*(void (**)(long long *, uint64_t))(*(void *)(v32 - 8) + 8))(&v41, v32);
  }
  else
  {
    if (v16 != 3)
    {
      uint64_t v35 = v46;
      outlined init with take of MLClassifierMetrics((uint64_t)&v41, v46, type metadata accessor for MLHandPoseClassifier.DataSource);
      MLHandPoseClassifier.DataSource.imagesWithAnnotations()(a3);
      outlined destroy of MLHandActionClassifier.ModelParameters.ValidationData(v35, type metadata accessor for MLHandPoseClassifier.DataSource);
      char v36 = v55;
      uint64_t v14 = (void *)v48;
      char v37 = BYTE8(v48);
      unsigned __int8 v38 = v54;
      *id v54 = v52;
      *((unsigned char *)v38 + 8) = v36;
      uint64_t v39 = v53;
      *uint64_t v53 = v14;
      *((unsigned char *)v39 + 8) = v37;
      return (char)v14;
    }
    outlined consume of Result<_DataTable, Error>(v52, v55);
    char v17 = v43;
    char v18 = v45;
    char v19 = BYTE8(v46);
    outlined consume of Result<_DataTable, Error>(v41, SBYTE8(v41));
    swift_bridgeObjectRelease(v19);
    swift_bridgeObjectRelease(v18);
    swift_bridgeObjectRelease(v17);
  }
  uint64_t v33 = v54;
  *id v54 = 0;
  LOBYTE(v14) = -1;
  *((unsigned char *)v33 + 8) = -1;
  id v34 = v53;
  *uint64_t v53 = 0;
  *((unsigned char *)v34 + 8) = -1;
  return (char)v14;
}

unint64_t MLHandPoseClassifier.ModelParameters.debugDescription.getter()
{
  return MLHandPoseClassifier.ModelParameters.description.getter();
}

uint64_t MLHandPoseClassifier.ModelParameters.validation.getter()
{
  return outlined init with copy of MLHandPoseClassifier.ModelParameters.ValidationData(v1, v0);
}

uint64_t MLHandPoseClassifier.ModelParameters.validation.setter(uint64_t a1)
{
  return outlined assign with take of MLHandPoseClassifier.ModelParameters.ValidationData(a1, v1);
}

void (*MLHandPoseClassifier.ModelParameters.validation.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLHandPoseClassifier.ModelParameters.batchSize.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLHandPoseClassifier.ModelParameters(0) + 20));
}

uint64_t MLHandPoseClassifier.ModelParameters.batchSize.setter(uint64_t a1)
{
  uint64_t result = *(int *)(type metadata accessor for MLHandPoseClassifier.ModelParameters(0) + 20);
  *(void *)(v1 + result) = a1;
  return result;
}

void (*MLHandPoseClassifier.ModelParameters.batchSize.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLHandPoseClassifier.ModelParameters.maximumIterations.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLHandPoseClassifier.ModelParameters(0) + 24));
}

uint64_t MLHandPoseClassifier.ModelParameters.maximumIterations.setter(uint64_t a1)
{
  uint64_t result = *(int *)(type metadata accessor for MLHandPoseClassifier.ModelParameters(0) + 24);
  *(void *)(v1 + result) = a1;
  return result;
}

void (*MLHandPoseClassifier.ModelParameters.maximumIterations.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLHandPoseClassifier.ModelParameters.augmentationOptions.getter()
{
  uint64_t v2 = v0;
  uint64_t result = *(void *)(v1 + *(int *)(type metadata accessor for MLHandPoseClassifier.ModelParameters(0) + 28));
  *uint64_t v2 = result;
  return result;
}

uint64_t MLHandPoseClassifier.ModelParameters.augmentationOptions.setter(uint64_t *a1)
{
  uint64_t v2 = *a1;
  uint64_t result = *(int *)(type metadata accessor for MLHandPoseClassifier.ModelParameters(0) + 28);
  *(void *)(v1 + result) = v2;
  return result;
}

void (*MLHandPoseClassifier.ModelParameters.augmentationOptions.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

void (*MLHandPoseClassifier.ModelParameters.algorithm.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

void MLHandPoseClassifier.ModelParameters.ModelAlgorithmType.hash(into:)()
{
}

char static MLHandPoseClassifier.ModelParameters.ModelAlgorithmType.== infix(_:_:)()
{
  return 1;
}

Swift::Int MLHandPoseClassifier.ModelParameters.ModelAlgorithmType.hashValue.getter()
{
  return Hasher._finalize()();
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType()
{
  return MLHandPoseClassifier.ModelParameters.ModelAlgorithmType.hashValue.getter();
}

void protocol witness for Hashable.hash(into:) in conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType()
{
}

unint64_t MLHandPoseClassifier.ModelParameters.description.getter()
{
  _StringGuts.grow(_:)(23);
  swift_bridgeObjectRelease(0);
  uint64_t v1 = type metadata accessor for MLHandPoseClassifier.ModelParameters(0);
  v2._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  char object = (char)v2._object;
  String.append(_:)(v2);
  swift_bridgeObjectRelease(object);
  v4._uint64_t countAndFlagsBits = 10;
  v4._char object = (void *)0xE100000000000000;
  String.append(_:)(v4);
  strcpy((char *)&v11, "Batch Size: ");
  BYTE5(v11._object) = 0;
  HIWORD(v11._object) = -5120;
  v5._uint64_t countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  char v6 = (char)v5._object;
  String.append(_:)(v5);
  swift_bridgeObjectRelease(v6);
  v4._uint64_t countAndFlagsBits = 10;
  v8._char object = (void *)0xE100000000000000;
  String.append(_:)(v8);
  String.append(_:)(v11);
  swift_bridgeObjectRelease(v11._object);
  _StringGuts.grow(_:)(25);
  swift_bridgeObjectRelease(0);
  v11._uint64_t countAndFlagsBits = 0xD000000000000016;
  v11._char object = "Target Frame Rate: " + 0x8000000000000000;
  uint64_t v7 = "Model Algorithm: GCN\n" + 0x8000000000000000;
  v8._uint64_t countAndFlagsBits = 0;
  if (*(void *)(v0 + *(int *)(v1 + 28)) == 1) {
    v8._uint64_t countAndFlagsBits = 0xD000000000000011;
  }
  else {
    uint64_t v7 = (char *)0xE000000000000000;
  }
  v8._char object = v7;
  String.append(_:)(v8);
  swift_bridgeObjectRelease((_BYTE)v7);
  v9._uint64_t countAndFlagsBits = 10;
  v9._char object = (void *)0xE100000000000000;
  String.append(_:)(v9);
  String.append(_:)(v11);
  swift_bridgeObjectRelease(v11._object);
  _StringGuts.grow(_:)(20);
  swift_bridgeObjectRelease(0);
  v9._char object = "Augmentation Options: " + 0x8000000000000000;
  v9._uint64_t countAndFlagsBits = 0xD000000000000015;
  String.append(_:)(v9);
  return 0xD000000000000014;
}

uint64_t outlined init with copy of MLHandPoseClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined assign with take of MLHandPoseClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 40))(a2, a1, v2);
  return a2;
}

unint64_t MLHandPoseClassifier.ModelParameters.playgroundDescription.getter()
{
  uint64_t v1 = v0;
  unint64_t result = MLHandPoseClassifier.ModelParameters.description.getter();
  v1[3] = (unint64_t)&type metadata for String;
  *uint64_t v1 = result;
  v1[1] = v3;
  return result;
}

unint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLHandPoseClassifier.ModelParameters()
{
  return MLHandPoseClassifier.ModelParameters.description.getter();
}

unint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLHandPoseClassifier.ModelParameters()
{
  return MLHandPoseClassifier.ModelParameters.debugDescription.getter();
}

unint64_t protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLHandPoseClassifier.ModelParameters()
{
  return MLHandPoseClassifier.ModelParameters.playgroundDescription.getter();
}

uint64_t base witness table accessor for Equatable in MLHandPoseClassifier.ModelParameters.ModelAlgorithmType()
{
  return lazy protocol witness table accessor for type MLHandPoseClassifier.ModelParameters.ModelAlgorithmType and conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType();
}

uint64_t lazy protocol witness table accessor for type MLHandPoseClassifier.ModelParameters.ModelAlgorithmType and conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType()
{
  uint64_t result = lazy protocol witness table cache variable for type MLHandPoseClassifier.ModelParameters.ModelAlgorithmType and conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType;
  if (!lazy protocol witness table cache variable for type MLHandPoseClassifier.ModelParameters.ModelAlgorithmType and conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLHandPoseClassifier.ModelParameters.ModelAlgorithmType, &type metadata for MLHandPoseClassifier.ModelParameters.ModelAlgorithmType);
    lazy protocol witness table cache variable for type MLHandPoseClassifier.ModelParameters.ModelAlgorithmType and conformance MLHandPoseClassifier.ModelParameters.ModelAlgorithmType = result;
  }
  return result;
}

char *initializeBufferWithCopyOfBuffer for MLHandPoseClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  Swift::String v4 = __dst;
  int v5 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v16 = *(void *)__src;
    *(void *)Swift::String v4 = *(void *)__src;
    Swift::String v4 = (char *)(v16 + ((v5 + 16) & ~v5));
    swift_retain();
  }
  else
  {
    uint64_t v7 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
    if (swift_getEnumCaseMultiPayload(__src, v7) == 1)
    {
      uint64_t v8 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v8))
      {
        case 0u:
          uint64_t v41 = type metadata accessor for URL(0);
          uint64_t v44 = *(void (**)(char *, char *, uint64_t))(*(void *)(v41 - 8) + 16);
          v44(__dst, __src, v41);
          uint64_t v42 = v8;
          Swift::String v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
          v44(&__dst[v9[12]], &__src[v9[12]], v41);
          uint64_t v10 = v9[16];
          *(void *)&__dst[v10] = *(void *)&__src[v10];
          uint64_t v11 = *(void *)&__src[v10 + 8];
          *(void *)&v4[v10 + 8] = v11;
          uint64_t v12 = v9[20];
          *(void *)&v4[v12] = *(void *)&__src[v12];
          uint64_t v13 = *(void *)&__src[v12 + 8];
          *(void *)&v4[v12 + 8] = v13;
          swift_bridgeObjectRetain(v11);
          swift_bridgeObjectRetain(v13);
          __dst = v4;
          uint64_t v14 = v42;
          uint64_t v15 = 0;
          goto LABEL_15;
        case 1u:
          uint64_t v17 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 16))(__dst, __src, v17);
          uint64_t v39 = 1;
          goto LABEL_9;
        case 2u:
          uint64_t v18 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 16))(__dst, __src, v18);
          uint64_t v39 = 2;
LABEL_9:
          uint64_t v15 = v39;
          uint64_t v14 = v8;
          goto LABEL_15;
        case 3u:
          uint64_t v43 = v8;
          uint64_t v19 = *(void *)__src;
          char v45 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v45);
          *(void *)__dst = v19;
          __dst[8] = v45;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v20 = *((void *)__src + 3);
          *((void *)v4 + 3) = v20;
          *((void *)v4 + 4) = *((void *)__src + 4);
          uint64_t v21 = *((void *)__src + 5);
          *((void *)v4 + 5) = v21;
          *((void *)v4 + 6) = *((void *)__src + 6);
          uint64_t v46 = *((void *)__src + 7);
          *((void *)v4 + 7) = v46;
          swift_bridgeObjectRetain(v20);
          swift_bridgeObjectRetain(v21);
          swift_bridgeObjectRetain(v46);
          uint64_t v40 = 3;
          goto LABEL_14;
        case 4u:
          uint64_t v43 = v8;
          uint64_t v22 = *(void *)__src;
          char v47 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v47);
          *(void *)__dst = v22;
          __dst[8] = v47;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v23 = *((void *)__src + 3);
          *((void *)v4 + 3) = v23;
          *((void *)v4 + 4) = *((void *)__src + 4);
          uint64_t v24 = *((void *)__src + 5);
          *((void *)v4 + 5) = v24;
          swift_bridgeObjectRetain(v23);
          swift_bridgeObjectRetain(v24);
          uint64_t v40 = 4;
          goto LABEL_14;
        case 5u:
          uint64_t v25 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v25 - 8) + 16))(__dst, __src, v25);
          uint64_t v26 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          uint64_t v27 = v26[12];
          *(void *)&__dst[v27] = *(void *)&__src[v27];
          uint64_t v28 = *(void *)&__src[v27 + 8];
          *(void *)&v4[v27 + 8] = v28;
          uint64_t v29 = v26[16];
          *(void *)&v4[v29] = *(void *)&__src[v29];
          uint64_t v48 = *(void *)&__src[v29 + 8];
          *(void *)&v4[v29 + 8] = v48;
          uint64_t v30 = v26[20];
          *(void *)&v4[v30] = *(void *)&__src[v30];
          uint64_t v43 = v8;
          uint64_t v31 = *(void *)&__src[v30 + 8];
          *(void *)&v4[v30 + 8] = v31;
          swift_bridgeObjectRetain(v28);
          swift_bridgeObjectRetain(v48);
          swift_bridgeObjectRetain(v31);
          uint64_t v40 = 5;
          goto LABEL_14;
        case 6u:
          uint64_t v32 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v32 - 8) + 16))(__dst, __src, v32);
          uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
          uint64_t v34 = *(int *)(v33 + 48);
          *(void *)&__dst[v34] = *(void *)&__src[v34];
          uint64_t v35 = *(void *)&__src[v34 + 8];
          *(void *)&v4[v34 + 8] = v35;
          uint64_t v36 = *(int *)(v33 + 64);
          *(void *)&v4[v36] = *(void *)&__src[v36];
          uint64_t v43 = v8;
          uint64_t v37 = *(void *)&__src[v36 + 8];
          *(void *)&v4[v36 + 8] = v37;
          swift_bridgeObjectRetain(v35);
          swift_bridgeObjectRetain(v37);
          uint64_t v40 = 6;
LABEL_14:
          uint64_t v15 = v40;
          __dst = v4;
          uint64_t v14 = v43;
LABEL_15:
          swift_storeEnumTagMultiPayload(__dst, v14, v15);
          swift_storeEnumTagMultiPayload(v4, v7, 1);
          break;
        case 7u:
          JUMPOUT(0x13C9B4);
      }
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
    }
    *(void *)&v4[a3[5]] = *(void *)&__src[a3[5]];
    *(void *)&v4[a3[6]] = *(void *)&__src[a3[6]];
    *(void *)&v4[a3[7]] = *(void *)&__src[a3[7]];
  }
  return v4;
}

uint64_t destroy for MLHandPoseClassifier.ModelParameters(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  uint64_t result = swift_getEnumCaseMultiPayload(a1, v1);
  if (result == 1)
  {
    uint64_t v3 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
    uint64_t result = swift_getEnumCaseMultiPayload(a1, v3);
    switch((int)result)
    {
      case 0:
        uint64_t v5 = type metadata accessor for URL(0);
        char v6 = *(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8);
        v6(a1, v5);
        uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v6(a1 + v7[12], v5);
        swift_bridgeObjectRelease(*(void *)(a1 + v7[16] + 8));
        uint64_t v8 = v7[20];
        goto LABEL_10;
      case 1:
      case 2:
        uint64_t v4 = type metadata accessor for URL(0);
        return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
      case 3:
        outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + 24));
        swift_bridgeObjectRelease(*(void *)(a1 + 40));
        return swift_bridgeObjectRelease(*(void *)(a1 + 56));
      case 4:
        outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + 24));
        return swift_bridgeObjectRelease(*(void *)(a1 + 40));
      case 5:
        uint64_t v9 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(a1, v9);
        uint64_t v10 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        swift_bridgeObjectRelease(*(void *)(a1 + v10[12] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v10[16] + 8));
        uint64_t v8 = v10[20];
        goto LABEL_10;
      case 6:
        uint64_t v11 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v11 - 8) + 8))(a1, v11);
        uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(v12 + 48) + 8));
        uint64_t v8 = *(int *)(v12 + 64);
LABEL_10:
        uint64_t result = swift_bridgeObjectRelease(*(void *)(a1 + v8 + 8));
        break;
      default:
        return result;
    }
  }
  return result;
}

char *initializeWithCopy for MLHandPoseClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v5 = __dst;
  uint64_t v6 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  if (swift_getEnumCaseMultiPayload(__src, v6) == 1)
  {
    uint64_t v7 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(__src, v7))
    {
      case 0u:
        uint64_t v39 = type metadata accessor for URL(0);
        uint64_t v42 = *(void (**)(char *, char *, uint64_t))(*(void *)(v39 - 8) + 16);
        v42(__dst, __src, v39);
        uint64_t v40 = v7;
        uint64_t v8 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v42(&__dst[v8[12]], &__src[v8[12]], v39);
        uint64_t v9 = v8[16];
        *(void *)&__dst[v9] = *(void *)&__src[v9];
        uint64_t v10 = *(void *)&__src[v9 + 8];
        *(void *)&v5[v9 + 8] = v10;
        uint64_t v11 = v8[20];
        *(void *)&v5[v11] = *(void *)&__src[v11];
        uint64_t v12 = *(void *)&__src[v11 + 8];
        *(void *)&v5[v11 + 8] = v12;
        swift_bridgeObjectRetain(v10);
        swift_bridgeObjectRetain(v12);
        __dst = v5;
        uint64_t v13 = v40;
        uint64_t v14 = 0;
        goto LABEL_13;
      case 1u:
        uint64_t v15 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 16))(__dst, __src, v15);
        uint64_t v37 = 1;
        goto LABEL_7;
      case 2u:
        uint64_t v16 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(__dst, __src, v16);
        uint64_t v37 = 2;
LABEL_7:
        uint64_t v14 = v37;
        uint64_t v13 = v7;
        goto LABEL_13;
      case 3u:
        uint64_t v41 = v7;
        uint64_t v17 = *(void *)__src;
        char v43 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v43);
        *(void *)__dst = v17;
        __dst[8] = v43;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v18 = *((void *)__src + 3);
        *((void *)v5 + 3) = v18;
        *((void *)v5 + 4) = *((void *)__src + 4);
        uint64_t v19 = *((void *)__src + 5);
        *((void *)v5 + 5) = v19;
        *((void *)v5 + 6) = *((void *)__src + 6);
        uint64_t v44 = *((void *)__src + 7);
        *((void *)v5 + 7) = v44;
        swift_bridgeObjectRetain(v18);
        swift_bridgeObjectRetain(v19);
        swift_bridgeObjectRetain(v44);
        uint64_t v38 = 3;
        goto LABEL_12;
      case 4u:
        uint64_t v41 = v7;
        uint64_t v20 = *(void *)__src;
        char v45 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v45);
        *(void *)__dst = v20;
        __dst[8] = v45;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v21 = *((void *)__src + 3);
        *((void *)v5 + 3) = v21;
        *((void *)v5 + 4) = *((void *)__src + 4);
        uint64_t v22 = *((void *)__src + 5);
        *((void *)v5 + 5) = v22;
        swift_bridgeObjectRetain(v21);
        swift_bridgeObjectRetain(v22);
        uint64_t v38 = 4;
        goto LABEL_12;
      case 5u:
        uint64_t v23 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v23 - 8) + 16))(__dst, __src, v23);
        uint64_t v24 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v25 = v24[12];
        *(void *)&__dst[v25] = *(void *)&__src[v25];
        uint64_t v26 = *(void *)&__src[v25 + 8];
        *(void *)&v5[v25 + 8] = v26;
        uint64_t v27 = v24[16];
        *(void *)&v5[v27] = *(void *)&__src[v27];
        uint64_t v46 = *(void *)&__src[v27 + 8];
        *(void *)&v5[v27 + 8] = v46;
        uint64_t v28 = v24[20];
        *(void *)&v5[v28] = *(void *)&__src[v28];
        uint64_t v41 = v7;
        uint64_t v29 = *(void *)&__src[v28 + 8];
        *(void *)&v5[v28 + 8] = v29;
        swift_bridgeObjectRetain(v26);
        swift_bridgeObjectRetain(v46);
        swift_bridgeObjectRetain(v29);
        uint64_t v38 = 5;
        goto LABEL_12;
      case 6u:
        uint64_t v30 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v30 - 8) + 16))(__dst, __src, v30);
        uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        uint64_t v32 = *(int *)(v31 + 48);
        *(void *)&__dst[v32] = *(void *)&__src[v32];
        uint64_t v33 = *(void *)&__src[v32 + 8];
        *(void *)&v5[v32 + 8] = v33;
        uint64_t v34 = *(int *)(v31 + 64);
        *(void *)&v5[v34] = *(void *)&__src[v34];
        uint64_t v41 = v7;
        uint64_t v35 = *(void *)&__src[v34 + 8];
        *(void *)&v5[v34 + 8] = v35;
        swift_bridgeObjectRetain(v33);
        swift_bridgeObjectRetain(v35);
        uint64_t v38 = 6;
LABEL_12:
        uint64_t v14 = v38;
        __dst = v5;
        uint64_t v13 = v41;
LABEL_13:
        swift_storeEnumTagMultiPayload(__dst, v13, v14);
        swift_storeEnumTagMultiPayload(v5, v6, 1);
        break;
    }
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
  }
  *(void *)&v5[a3[5]] = *(void *)&__src[a3[5]];
  *(void *)&v5[a3[6]] = *(void *)&__src[a3[6]];
  *(void *)&v5[a3[7]] = *(void *)&__src[a3[7]];
  return v5;
}

char *assignWithCopy for MLHandPoseClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v5 = __dst;
  if (__dst != __src)
  {
    outlined destroy of MLHandActionClassifier.ModelParameters.ValidationData((uint64_t)__dst, type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
    uint64_t v6 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
    if (swift_getEnumCaseMultiPayload(__src, v6) == 1)
    {
      uint64_t v7 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v7))
      {
        case 0u:
          uint64_t v39 = type metadata accessor for URL(0);
          uint64_t v42 = *(void (**)(char *, char *, uint64_t))(*(void *)(v39 - 8) + 16);
          v42(__dst, __src, v39);
          uint64_t v40 = v7;
          uint64_t v8 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
          v42(&__dst[v8[12]], &__src[v8[12]], v39);
          uint64_t v9 = v8[16];
          *(void *)&__dst[v9] = *(void *)&__src[v9];
          uint64_t v10 = *(void *)&__src[v9 + 8];
          *(void *)&v5[v9 + 8] = v10;
          uint64_t v11 = v8[20];
          *(void *)&v5[v11] = *(void *)&__src[v11];
          uint64_t v12 = *(void *)&__src[v11 + 8];
          *(void *)&v5[v11 + 8] = v12;
          swift_bridgeObjectRetain(v10);
          swift_bridgeObjectRetain(v12);
          __dst = v5;
          uint64_t v13 = v40;
          uint64_t v14 = 0;
          goto LABEL_14;
        case 1u:
          uint64_t v15 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 16))(__dst, __src, v15);
          uint64_t v37 = 1;
          goto LABEL_8;
        case 2u:
          uint64_t v16 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(__dst, __src, v16);
          uint64_t v37 = 2;
LABEL_8:
          uint64_t v14 = v37;
          uint64_t v13 = v7;
          goto LABEL_14;
        case 3u:
          uint64_t v41 = v7;
          uint64_t v17 = *(void *)__src;
          char v43 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v43);
          *(void *)__dst = v17;
          __dst[8] = v43;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v18 = *((void *)__src + 3);
          *((void *)v5 + 3) = v18;
          *((void *)v5 + 4) = *((void *)__src + 4);
          uint64_t v19 = *((void *)__src + 5);
          *((void *)v5 + 5) = v19;
          *((void *)v5 + 6) = *((void *)__src + 6);
          uint64_t v44 = *((void *)__src + 7);
          *((void *)v5 + 7) = v44;
          swift_bridgeObjectRetain(v18);
          swift_bridgeObjectRetain(v19);
          swift_bridgeObjectRetain(v44);
          uint64_t v38 = 3;
          goto LABEL_13;
        case 4u:
          uint64_t v41 = v7;
          uint64_t v20 = *(void *)__src;
          char v45 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v45);
          *(void *)__dst = v20;
          __dst[8] = v45;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v21 = *((void *)__src + 3);
          *((void *)v5 + 3) = v21;
          *((void *)v5 + 4) = *((void *)__src + 4);
          uint64_t v22 = *((void *)__src + 5);
          *((void *)v5 + 5) = v22;
          swift_bridgeObjectRetain(v21);
          swift_bridgeObjectRetain(v22);
          uint64_t v38 = 4;
          goto LABEL_13;
        case 5u:
          uint64_t v23 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v23 - 8) + 16))(__dst, __src, v23);
          uint64_t v24 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          uint64_t v25 = v24[12];
          *(void *)&__dst[v25] = *(void *)&__src[v25];
          uint64_t v26 = *(void *)&__src[v25 + 8];
          *(void *)&v5[v25 + 8] = v26;
          uint64_t v27 = v24[16];
          *(void *)&v5[v27] = *(void *)&__src[v27];
          uint64_t v46 = *(void *)&__src[v27 + 8];
          *(void *)&v5[v27 + 8] = v46;
          uint64_t v28 = v24[20];
          *(void *)&v5[v28] = *(void *)&__src[v28];
          uint64_t v41 = v7;
          uint64_t v29 = *(void *)&__src[v28 + 8];
          *(void *)&v5[v28 + 8] = v29;
          swift_bridgeObjectRetain(v26);
          swift_bridgeObjectRetain(v46);
          swift_bridgeObjectRetain(v29);
          uint64_t v38 = 5;
          goto LABEL_13;
        case 6u:
          uint64_t v30 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v30 - 8) + 16))(__dst, __src, v30);
          uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
          uint64_t v32 = *(int *)(v31 + 48);
          *(void *)&__dst[v32] = *(void *)&__src[v32];
          uint64_t v33 = *(void *)&__src[v32 + 8];
          *(void *)&v5[v32 + 8] = v33;
          uint64_t v34 = *(int *)(v31 + 64);
          *(void *)&v5[v34] = *(void *)&__src[v34];
          uint64_t v41 = v7;
          uint64_t v35 = *(void *)&__src[v34 + 8];
          *(void *)&v5[v34 + 8] = v35;
          swift_bridgeObjectRetain(v33);
          swift_bridgeObjectRetain(v35);
          uint64_t v38 = 6;
LABEL_13:
          uint64_t v14 = v38;
          __dst = v5;
          uint64_t v13 = v41;
LABEL_14:
          swift_storeEnumTagMultiPayload(__dst, v13, v14);
          swift_storeEnumTagMultiPayload(v5, v6, 1);
          break;
      }
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
    }
  }
  *(void *)&v5[a3[5]] = *(void *)&__src[a3[5]];
  *(void *)&v5[a3[6]] = *(void *)&__src[a3[6]];
  *(void *)&v5[a3[7]] = *(void *)&__src[a3[7]];
  return v5;
}

char *initializeWithTake for MLHandPoseClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v5 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  if (swift_getEnumCaseMultiPayload(__src, v5) == 1)
  {
    uint64_t v6 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(__src, v6))
    {
      case 0u:
        uint64_t v19 = type metadata accessor for URL(0);
        uint64_t v20 = *(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 32);
        v20(__dst, __src, v19);
        uint64_t v18 = v6;
        uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v20(&__dst[v7[12]], &__src[v7[12]], v19);
        *(_OWORD *)&__dst[v7[16]] = *(_OWORD *)&__src[v7[16]];
        *(_OWORD *)&__dst[v7[20]] = *(_OWORD *)&__src[v7[20]];
        uint64_t v8 = v18;
        uint64_t v9 = 0;
        goto LABEL_11;
      case 1u:
        uint64_t v10 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
        uint64_t v17 = 1;
        goto LABEL_10;
      case 2u:
        uint64_t v11 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 32))(__dst, __src, v11);
        uint64_t v17 = 2;
        goto LABEL_10;
      case 5u:
        uint64_t v12 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
        uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        *(_OWORD *)&__dst[v13[12]] = *(_OWORD *)&__src[v13[12]];
        *(_OWORD *)&__dst[v13[16]] = *(_OWORD *)&__src[v13[16]];
        *(_OWORD *)&__dst[v13[20]] = *(_OWORD *)&__src[v13[20]];
        uint64_t v17 = 5;
        goto LABEL_10;
      case 6u:
        uint64_t v14 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 32))(__dst, __src, v14);
        uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        *(_OWORD *)&__dst[*(int *)(v15 + 48)] = *(_OWORD *)&__src[*(int *)(v15 + 48)];
        *(_OWORD *)&__dst[*(int *)(v15 + 64)] = *(_OWORD *)&__src[*(int *)(v15 + 64)];
        uint64_t v17 = 6;
LABEL_10:
        uint64_t v9 = v17;
        uint64_t v8 = v6;
LABEL_11:
        swift_storeEnumTagMultiPayload(__dst, v8, v9);
        break;
      default:
        memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
        break;
    }
    swift_storeEnumTagMultiPayload(__dst, v5, 1);
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
  }
  *(void *)&__dst[a3[5]] = *(void *)&__src[a3[5]];
  *(void *)&__dst[a3[6]] = *(void *)&__src[a3[6]];
  *(void *)&__dst[a3[7]] = *(void *)&__src[a3[7]];
  return __dst;
}

char *assignWithTake for MLHandPoseClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLHandActionClassifier.ModelParameters.ValidationData((uint64_t)__dst, type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
    uint64_t v5 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
    if (swift_getEnumCaseMultiPayload(__src, v5) == 1)
    {
      uint64_t v6 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v6))
      {
        case 0u:
          uint64_t v19 = type metadata accessor for URL(0);
          uint64_t v20 = *(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 32);
          v20(__dst, __src, v19);
          uint64_t v18 = v6;
          uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
          v20(&__dst[v7[12]], &__src[v7[12]], v19);
          *(_OWORD *)&__dst[v7[16]] = *(_OWORD *)&__src[v7[16]];
          *(_OWORD *)&__dst[v7[20]] = *(_OWORD *)&__src[v7[20]];
          uint64_t v8 = v18;
          uint64_t v9 = 0;
          goto LABEL_12;
        case 1u:
          uint64_t v10 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
          uint64_t v17 = 1;
          goto LABEL_11;
        case 2u:
          uint64_t v11 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v11 - 8) + 32))(__dst, __src, v11);
          uint64_t v17 = 2;
          goto LABEL_11;
        case 5u:
          uint64_t v12 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
          uint64_t v13 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          *(_OWORD *)&__dst[v13[12]] = *(_OWORD *)&__src[v13[12]];
          *(_OWORD *)&__dst[v13[16]] = *(_OWORD *)&__src[v13[16]];
          *(_OWORD *)&__dst[v13[20]] = *(_OWORD *)&__src[v13[20]];
          uint64_t v17 = 5;
          goto LABEL_11;
        case 6u:
          uint64_t v14 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v14 - 8) + 32))(__dst, __src, v14);
          uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
          *(_OWORD *)&__dst[*(int *)(v15 + 48)] = *(_OWORD *)&__src[*(int *)(v15 + 48)];
          *(_OWORD *)&__dst[*(int *)(v15 + 64)] = *(_OWORD *)&__src[*(int *)(v15 + 64)];
          uint64_t v17 = 6;
LABEL_11:
          uint64_t v9 = v17;
          uint64_t v8 = v6;
LABEL_12:
          swift_storeEnumTagMultiPayload(__dst, v8, v9);
          break;
        default:
          memcpy(__dst, __src, *(void *)(*(void *)(v6 - 8) + 64));
          break;
      }
      swift_storeEnumTagMultiPayload(__dst, v5, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
    }
  }
  *(void *)&__dst[a3[5]] = *(void *)&__src[a3[5]];
  *(void *)&__dst[a3[6]] = *(void *)&__src[a3[6]];
  *(void *)&__dst[a3[7]] = *(void *)&__src[a3[7]];
  return __dst;
}

uint64_t getEnumTagSinglePayload for MLHandPoseClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_13D715);
}

uint64_t sub_13D715(uint64_t a1, unsigned int a2)
{
  uint64_t v2 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  return __swift_getEnumTagSinglePayload(a1, a2, v2);
}

uint64_t storeEnumTagSinglePayload for MLHandPoseClassifier.ModelParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_13D759);
}

uint64_t sub_13D759(uint64_t a1, unsigned int a2)
{
  uint64_t v2 = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(0);
  return __swift_storeEnumTagSinglePayload(a1, a2, a2, v2);
}

uint64_t type metadata completion function for MLHandPoseClassifier.ModelParameters(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData(319);
  if (v2 <= 0x3F)
  {
    v3[0] = *(void *)(result - 8) + 64;
    v3[1] = (char *)&value witness table for Builtin.Int64 + 64;
    v3[2] = (char *)&value witness table for Builtin.Int64 + 64;
    void v3[3] = (char *)&value witness table for Builtin.Int64 + 64;
    void v3[4] = (char *)&value witness table for () + 64;
    swift_initStructMetadata(a1, 256, 5, v3, a1 + 16);
    return 0;
  }
  return result;
}

ValueMetadata *type metadata accessor for MLHandPoseClassifier.ModelParameters.ModelAlgorithmType()
{
  return &type metadata for MLHandPoseClassifier.ModelParameters.ModelAlgorithmType;
}

void *initializeBufferWithCopyOfBuffer for MLHandPoseClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  uint64_t v3 = __dst;
  uint64_t v4 = *(void *)(a3 - 8);
  int v5 = *(_DWORD *)(v4 + 80);
  if ((v5 & 0x20000) != 0)
  {
    uint64_t v17 = *(void *)__src;
    *uint64_t v3 = *(void *)__src;
    uint64_t v3 = (void *)(v17 + ((v5 + 16) & ~v5));
    swift_retain();
  }
  else if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
  {
    uint64_t v7 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(__src, v7))
    {
      case 0u:
        uint64_t v47 = v7;
        uint64_t v8 = type metadata accessor for URL(0);
        uint64_t v46 = *(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 16);
        v46(__dst, __src, v8);
        uint64_t v9 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v46(&__dst[v9[12]], &__src[v9[12]], v8);
        uint64_t v10 = v9[16];
        *(void *)&__dst[v10] = *(void *)&__src[v10];
        uint64_t v11 = *(void *)&__src[v10 + 8];
        *(void *)((char *)v3 + v10 + 8) = v11;
        uint64_t v12 = v9[20];
        *(void *)((char *)v3 + v12) = *(void *)&__src[v12];
        uint64_t v13 = *(void *)&__src[v12 + 8];
        *(void *)((char *)v3 + v12 + 8) = v13;
        swift_bridgeObjectRetain(v11);
        swift_bridgeObjectRetain(v13);
        uint64_t v14 = v3;
        uint64_t v15 = v47;
        uint64_t v16 = 0;
        goto LABEL_15;
      case 1u:
        uint64_t v18 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 16))(__dst, __src, v18);
        uint64_t v44 = 1;
        goto LABEL_14;
      case 2u:
        uint64_t v19 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16))(__dst, __src, v19);
        uint64_t v44 = 2;
        goto LABEL_14;
      case 3u:
        uint64_t v20 = *(void *)__src;
        uint64_t v48 = v7;
        char v21 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v21);
        *(void *)__dst = v20;
        __dst[8] = v21;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v22 = *((void *)__src + 3);
        void v3[3] = v22;
        void v3[4] = *((void *)__src + 4);
        uint64_t v23 = *((void *)__src + 5);
        void v3[5] = v23;
        void v3[6] = *((void *)__src + 6);
        uint64_t v24 = *((void *)__src + 7);
        void v3[7] = v24;
        swift_bridgeObjectRetain(v22);
        swift_bridgeObjectRetain(v23);
        swift_bridgeObjectRetain(v24);
        uint64_t v45 = 3;
        goto LABEL_11;
      case 4u:
        uint64_t v25 = *(void *)__src;
        uint64_t v48 = v7;
        char v26 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v26);
        *(void *)__dst = v25;
        __dst[8] = v26;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v27 = *((void *)__src + 3);
        void v3[3] = v27;
        void v3[4] = *((void *)__src + 4);
        uint64_t v28 = *((void *)__src + 5);
        void v3[5] = v28;
        swift_bridgeObjectRetain(v27);
        swift_bridgeObjectRetain(v28);
        uint64_t v45 = 4;
LABEL_11:
        uint64_t v16 = v45;
        uint64_t v14 = v3;
        uint64_t v15 = v48;
        goto LABEL_15;
      case 5u:
        uint64_t v29 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v29 - 8) + 16))(__dst, __src, v29);
        uint64_t v30 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v31 = v30[12];
        *(void *)&__dst[v31] = *(void *)&__src[v31];
        uint64_t v32 = *(void *)&__src[v31 + 8];
        *(void *)((char *)v3 + v31 + 8) = v32;
        uint64_t v33 = v30[16];
        *(void *)((char *)v3 + v33) = *(void *)&__src[v33];
        uint64_t v34 = *(void *)&__src[v33 + 8];
        *(void *)((char *)v3 + v33 + 8) = v34;
        uint64_t v35 = v30[20];
        *(void *)((char *)v3 + v35) = *(void *)&__src[v35];
        uint64_t v36 = *(void *)&__src[v35 + 8];
        *(void *)((char *)v3 + v35 + 8) = v36;
        swift_bridgeObjectRetain(v32);
        swift_bridgeObjectRetain(v34);
        swift_bridgeObjectRetain(v36);
        uint64_t v44 = 5;
        goto LABEL_14;
      case 6u:
        uint64_t v37 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v37 - 8) + 16))(__dst, __src, v37);
        uint64_t v38 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        uint64_t v39 = *(int *)(v38 + 48);
        *(void *)&__dst[v39] = *(void *)&__src[v39];
        uint64_t v40 = *(void *)&__src[v39 + 8];
        *(void *)((char *)v3 + v39 + 8) = v40;
        uint64_t v41 = *(int *)(v38 + 64);
        *(void *)((char *)v3 + v41) = *(void *)&__src[v41];
        uint64_t v42 = *(void *)&__src[v41 + 8];
        *(void *)((char *)v3 + v41 + 8) = v42;
        swift_bridgeObjectRetain(v40);
        swift_bridgeObjectRetain(v42);
        uint64_t v44 = 6;
LABEL_14:
        uint64_t v16 = v44;
        uint64_t v14 = v3;
        uint64_t v15 = v7;
LABEL_15:
        swift_storeEnumTagMultiPayload(v14, v15, v16);
        swift_storeEnumTagMultiPayload(v3, a3, 1);
        break;
    }
  }
  else
  {
    memcpy(__dst, __src, *(void *)(v4 + 64));
  }
  return v3;
}

uint64_t destroy for MLHandPoseClassifier.ModelParameters.ValidationData(uint64_t a1, uint64_t a2)
{
  uint64_t result = swift_getEnumCaseMultiPayload(a1, a2);
  if (result == 1)
  {
    uint64_t v3 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
    uint64_t result = swift_getEnumCaseMultiPayload(a1, v3);
    switch((int)result)
    {
      case 0:
        uint64_t v5 = type metadata accessor for URL(0);
        uint64_t v6 = *(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8);
        v6(a1, v5);
        uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v6(a1 + v7[12], v5);
        swift_bridgeObjectRelease(*(void *)(a1 + v7[16] + 8));
        uint64_t v8 = v7[20];
        goto LABEL_10;
      case 1:
      case 2:
        uint64_t v4 = type metadata accessor for URL(0);
        return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a1, v4);
      case 3:
        outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + 24));
        swift_bridgeObjectRelease(*(void *)(a1 + 40));
        return swift_bridgeObjectRelease(*(void *)(a1 + 56));
      case 4:
        outlined consume of Result<_DataTable, Error>(*(void *)a1, *(_DWORD *)(a1 + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + 24));
        return swift_bridgeObjectRelease(*(void *)(a1 + 40));
      case 5:
        uint64_t v9 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v9 - 8) + 8))(a1, v9);
        uint64_t v10 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        swift_bridgeObjectRelease(*(void *)(a1 + v10[12] + 8));
        swift_bridgeObjectRelease(*(void *)(a1 + v10[16] + 8));
        uint64_t v8 = v10[20];
        goto LABEL_10;
      case 6:
        uint64_t v11 = type metadata accessor for DataFrame(0);
        (*(void (**)(uint64_t, uint64_t))(*(void *)(v11 - 8) + 8))(a1, v11);
        uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        swift_bridgeObjectRelease(*(void *)(a1 + *(int *)(v12 + 48) + 8));
        uint64_t v8 = *(int *)(v12 + 64);
LABEL_10:
        uint64_t result = swift_bridgeObjectRelease(*(void *)(a1 + v8 + 8));
        break;
      default:
        return result;
    }
  }
  return result;
}

char *initializeWithCopy for MLHandPoseClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
  {
    uint64_t v5 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(__src, v5))
    {
      case 0u:
        uint64_t v44 = v5;
        uint64_t v6 = type metadata accessor for URL(0);
        char v43 = *(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16);
        v43(__dst, __src, v6);
        uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v43(&__dst[v7[12]], &__src[v7[12]], v6);
        uint64_t v8 = v7[16];
        *(void *)&__dst[v8] = *(void *)&__src[v8];
        uint64_t v9 = *(void *)&__src[v8 + 8];
        *(void *)&__dst[v8 + 8] = v9;
        uint64_t v10 = v7[20];
        *(void *)&__dst[v10] = *(void *)&__src[v10];
        uint64_t v11 = *(void *)&__src[v10 + 8];
        *(void *)&__dst[v10 + 8] = v11;
        swift_bridgeObjectRetain(v9);
        swift_bridgeObjectRetain(v11);
        uint64_t v12 = __dst;
        uint64_t v13 = v44;
        uint64_t v14 = 0;
        goto LABEL_13;
      case 1u:
        uint64_t v15 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 16))(__dst, __src, v15);
        uint64_t v41 = 1;
        goto LABEL_12;
      case 2u:
        uint64_t v16 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(__dst, __src, v16);
        uint64_t v41 = 2;
        goto LABEL_12;
      case 3u:
        uint64_t v17 = *(void *)__src;
        uint64_t v45 = v5;
        char v18 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v18);
        *(void *)__dst = v17;
        __dst[8] = v18;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v19 = *((void *)__src + 3);
        *((void *)__dst + 3) = v19;
        *((void *)__dst + 4) = *((void *)__src + 4);
        uint64_t v20 = *((void *)__src + 5);
        *((void *)__dst + 5) = v20;
        *((void *)__dst + 6) = *((void *)__src + 6);
        uint64_t v21 = *((void *)__src + 7);
        *((void *)__dst + 7) = v21;
        swift_bridgeObjectRetain(v19);
        swift_bridgeObjectRetain(v20);
        swift_bridgeObjectRetain(v21);
        uint64_t v42 = 3;
        goto LABEL_9;
      case 4u:
        uint64_t v22 = *(void *)__src;
        uint64_t v45 = v5;
        char v23 = __src[8];
        outlined copy of Result<_DataTable, Error>(*(void *)__src, v23);
        *(void *)__dst = v22;
        __dst[8] = v23;
        *((void *)__dst + 2) = *((void *)__src + 2);
        uint64_t v24 = *((void *)__src + 3);
        *((void *)__dst + 3) = v24;
        *((void *)__dst + 4) = *((void *)__src + 4);
        uint64_t v25 = *((void *)__src + 5);
        *((void *)__dst + 5) = v25;
        swift_bridgeObjectRetain(v24);
        swift_bridgeObjectRetain(v25);
        uint64_t v42 = 4;
LABEL_9:
        uint64_t v14 = v42;
        uint64_t v12 = __dst;
        uint64_t v13 = v45;
        goto LABEL_13;
      case 5u:
        uint64_t v26 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v26 - 8) + 16))(__dst, __src, v26);
        uint64_t v27 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        uint64_t v28 = v27[12];
        *(void *)&__dst[v28] = *(void *)&__src[v28];
        uint64_t v29 = *(void *)&__src[v28 + 8];
        *(void *)&__dst[v28 + 8] = v29;
        uint64_t v30 = v27[16];
        *(void *)&__dst[v30] = *(void *)&__src[v30];
        uint64_t v31 = *(void *)&__src[v30 + 8];
        *(void *)&__dst[v30 + 8] = v31;
        uint64_t v32 = v27[20];
        *(void *)&__dst[v32] = *(void *)&__src[v32];
        uint64_t v33 = *(void *)&__src[v32 + 8];
        *(void *)&__dst[v32 + 8] = v33;
        swift_bridgeObjectRetain(v29);
        swift_bridgeObjectRetain(v31);
        swift_bridgeObjectRetain(v33);
        uint64_t v41 = 5;
        goto LABEL_12;
      case 6u:
        uint64_t v34 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v34 - 8) + 16))(__dst, __src, v34);
        uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        uint64_t v36 = *(int *)(v35 + 48);
        *(void *)&__dst[v36] = *(void *)&__src[v36];
        uint64_t v37 = *(void *)&__src[v36 + 8];
        *(void *)&__dst[v36 + 8] = v37;
        uint64_t v38 = *(int *)(v35 + 64);
        *(void *)&__dst[v38] = *(void *)&__src[v38];
        uint64_t v39 = *(void *)&__src[v38 + 8];
        *(void *)&__dst[v38 + 8] = v39;
        swift_bridgeObjectRetain(v37);
        swift_bridgeObjectRetain(v39);
        uint64_t v41 = 6;
LABEL_12:
        uint64_t v14 = v41;
        uint64_t v12 = __dst;
        uint64_t v13 = v5;
LABEL_13:
        swift_storeEnumTagMultiPayload(v12, v13, v14);
        swift_storeEnumTagMultiPayload(__dst, a3, 1);
        break;
    }
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
  }
  return __dst;
}

char *assignWithCopy for MLHandPoseClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLHandActionClassifier.ModelParameters.ValidationData((uint64_t)__dst, type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
    {
      uint64_t v5 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v5))
      {
        case 0u:
          uint64_t v44 = v5;
          uint64_t v6 = type metadata accessor for URL(0);
          char v43 = *(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16);
          v43(__dst, __src, v6);
          uint64_t v7 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
          v43(&__dst[v7[12]], &__src[v7[12]], v6);
          uint64_t v8 = v7[16];
          *(void *)&__dst[v8] = *(void *)&__src[v8];
          uint64_t v9 = *(void *)&__src[v8 + 8];
          *(void *)&__dst[v8 + 8] = v9;
          uint64_t v10 = v7[20];
          *(void *)&__dst[v10] = *(void *)&__src[v10];
          uint64_t v11 = *(void *)&__src[v10 + 8];
          *(void *)&__dst[v10 + 8] = v11;
          swift_bridgeObjectRetain(v9);
          swift_bridgeObjectRetain(v11);
          uint64_t v12 = __dst;
          uint64_t v13 = v44;
          uint64_t v14 = 0;
          goto LABEL_14;
        case 1u:
          uint64_t v15 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v15 - 8) + 16))(__dst, __src, v15);
          uint64_t v41 = 1;
          goto LABEL_13;
        case 2u:
          uint64_t v16 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 16))(__dst, __src, v16);
          uint64_t v41 = 2;
          goto LABEL_13;
        case 3u:
          uint64_t v17 = *(void *)__src;
          uint64_t v45 = v5;
          char v18 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v18);
          *(void *)__dst = v17;
          __dst[8] = v18;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v19 = *((void *)__src + 3);
          *((void *)__dst + 3) = v19;
          *((void *)__dst + 4) = *((void *)__src + 4);
          uint64_t v20 = *((void *)__src + 5);
          *((void *)__dst + 5) = v20;
          *((void *)__dst + 6) = *((void *)__src + 6);
          uint64_t v21 = *((void *)__src + 7);
          *((void *)__dst + 7) = v21;
          swift_bridgeObjectRetain(v19);
          swift_bridgeObjectRetain(v20);
          swift_bridgeObjectRetain(v21);
          uint64_t v42 = 3;
          goto LABEL_10;
        case 4u:
          uint64_t v22 = *(void *)__src;
          uint64_t v45 = v5;
          char v23 = __src[8];
          outlined copy of Result<_DataTable, Error>(*(void *)__src, v23);
          *(void *)__dst = v22;
          __dst[8] = v23;
          *((void *)__dst + 2) = *((void *)__src + 2);
          uint64_t v24 = *((void *)__src + 3);
          *((void *)__dst + 3) = v24;
          *((void *)__dst + 4) = *((void *)__src + 4);
          uint64_t v25 = *((void *)__src + 5);
          *((void *)__dst + 5) = v25;
          swift_bridgeObjectRetain(v24);
          swift_bridgeObjectRetain(v25);
          uint64_t v42 = 4;
LABEL_10:
          uint64_t v14 = v42;
          uint64_t v12 = __dst;
          uint64_t v13 = v45;
          goto LABEL_14;
        case 5u:
          uint64_t v26 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v26 - 8) + 16))(__dst, __src, v26);
          uint64_t v27 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          uint64_t v28 = v27[12];
          *(void *)&__dst[v28] = *(void *)&__src[v28];
          uint64_t v29 = *(void *)&__src[v28 + 8];
          *(void *)&__dst[v28 + 8] = v29;
          uint64_t v30 = v27[16];
          *(void *)&__dst[v30] = *(void *)&__src[v30];
          uint64_t v31 = *(void *)&__src[v30 + 8];
          *(void *)&__dst[v30 + 8] = v31;
          uint64_t v32 = v27[20];
          *(void *)&__dst[v32] = *(void *)&__src[v32];
          uint64_t v33 = *(void *)&__src[v32 + 8];
          *(void *)&__dst[v32 + 8] = v33;
          swift_bridgeObjectRetain(v29);
          swift_bridgeObjectRetain(v31);
          swift_bridgeObjectRetain(v33);
          uint64_t v41 = 5;
          goto LABEL_13;
        case 6u:
          uint64_t v34 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v34 - 8) + 16))(__dst, __src, v34);
          uint64_t v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
          uint64_t v36 = *(int *)(v35 + 48);
          *(void *)&__dst[v36] = *(void *)&__src[v36];
          uint64_t v37 = *(void *)&__src[v36 + 8];
          *(void *)&__dst[v36 + 8] = v37;
          uint64_t v38 = *(int *)(v35 + 64);
          *(void *)&__dst[v38] = *(void *)&__src[v38];
          uint64_t v39 = *(void *)&__src[v38 + 8];
          *(void *)&__dst[v38 + 8] = v39;
          swift_bridgeObjectRetain(v37);
          swift_bridgeObjectRetain(v39);
          uint64_t v41 = 6;
LABEL_13:
          uint64_t v14 = v41;
          uint64_t v12 = __dst;
          uint64_t v13 = v5;
LABEL_14:
          swift_storeEnumTagMultiPayload(v12, v13, v14);
          swift_storeEnumTagMultiPayload(__dst, a3, 1);
          break;
      }
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

char *initializeWithTake for MLHandPoseClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
  {
    uint64_t v4 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
    switch(swift_getEnumCaseMultiPayload(__src, v4))
    {
      case 0u:
        uint64_t v16 = type metadata accessor for URL(0);
        uint64_t v17 = *(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 32);
        v17(__dst, __src, v16);
        uint64_t v5 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
        v17(&__dst[v5[12]], &__src[v5[12]], v16);
        *(_OWORD *)&__dst[v5[16]] = *(_OWORD *)&__src[v5[16]];
        *(_OWORD *)&__dst[v5[20]] = *(_OWORD *)&__src[v5[20]];
        uint64_t v6 = v4;
        uint64_t v7 = 0;
        goto LABEL_11;
      case 1u:
        uint64_t v8 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
        uint64_t v15 = 1;
        goto LABEL_10;
      case 2u:
        uint64_t v9 = type metadata accessor for URL(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
        uint64_t v15 = 2;
        goto LABEL_10;
      case 5u:
        uint64_t v10 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
        uint64_t v11 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        *(_OWORD *)&__dst[v11[12]] = *(_OWORD *)&__src[v11[12]];
        *(_OWORD *)&__dst[v11[16]] = *(_OWORD *)&__src[v11[16]];
        *(_OWORD *)&__dst[v11[20]] = *(_OWORD *)&__src[v11[20]];
        uint64_t v15 = 5;
        goto LABEL_10;
      case 6u:
        uint64_t v12 = type metadata accessor for DataFrame(0);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
        uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
        *(_OWORD *)&__dst[*(int *)(v13 + 48)] = *(_OWORD *)&__src[*(int *)(v13 + 48)];
        *(_OWORD *)&__dst[*(int *)(v13 + 64)] = *(_OWORD *)&__src[*(int *)(v13 + 64)];
        uint64_t v15 = 6;
LABEL_10:
        uint64_t v7 = v15;
        uint64_t v6 = v4;
LABEL_11:
        swift_storeEnumTagMultiPayload(__dst, v6, v7);
        break;
      default:
        memcpy(__dst, __src, *(void *)(*(void *)(v4 - 8) + 64));
        break;
    }
    swift_storeEnumTagMultiPayload(__dst, a3, 1);
  }
  else
  {
    memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
  }
  return __dst;
}

char *assignWithTake for MLHandPoseClassifier.ModelParameters.ValidationData(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLHandActionClassifier.ModelParameters.ValidationData((uint64_t)__dst, type metadata accessor for MLHandPoseClassifier.ModelParameters.ValidationData);
    if (swift_getEnumCaseMultiPayload(__src, a3) == 1)
    {
      uint64_t v4 = type metadata accessor for MLHandPoseClassifier.DataSource(0);
      switch(swift_getEnumCaseMultiPayload(__src, v4))
      {
        case 0u:
          uint64_t v16 = type metadata accessor for URL(0);
          uint64_t v17 = *(void (**)(char *, char *, uint64_t))(*(void *)(v16 - 8) + 32);
          v17(__dst, __src, v16);
          uint64_t v5 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, imageColumn: String, labelColumn: String));
          v17(&__dst[v5[12]], &__src[v5[12]], v16);
          *(_OWORD *)&__dst[v5[16]] = *(_OWORD *)&__src[v5[16]];
          *(_OWORD *)&__dst[v5[20]] = *(_OWORD *)&__src[v5[20]];
          uint64_t v6 = v4;
          uint64_t v7 = 0;
          goto LABEL_12;
        case 1u:
          uint64_t v8 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v8 - 8) + 32))(__dst, __src, v8);
          uint64_t v15 = 1;
          goto LABEL_11;
        case 2u:
          uint64_t v9 = type metadata accessor for URL(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, __src, v9);
          uint64_t v15 = 2;
          goto LABEL_11;
        case 5u:
          uint64_t v10 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v10 - 8) + 32))(__dst, __src, v10);
          uint64_t v11 = (int *)__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
          *(_OWORD *)&__dst[v11[12]] = *(_OWORD *)&__src[v11[12]];
          *(_OWORD *)&__dst[v11[16]] = *(_OWORD *)&__src[v11[16]];
          *(_OWORD *)&__dst[v11[20]] = *(_OWORD *)&__src[v11[20]];
          uint64_t v15 = 5;
          goto LABEL_11;
        case 6u:
          uint64_t v12 = type metadata accessor for DataFrame(0);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(__dst, __src, v12);
          uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, imageColumn: String, labelColumn: String));
          *(_OWORD *)&__dst[*(int *)(v13 + 48)] = *(_OWORD *)&__src[*(int *)(v13 + 48)];
          *(_OWORD *)&__dst[*(int *)(v13 + 64)] = *(_OWORD *)&__src[*(int *)(v13 + 64)];
          uint64_t v15 = 6;
LABEL_11:
          uint64_t v7 = v15;
          uint64_t v6 = v4;
LABEL_12:
          swift_storeEnumTagMultiPayload(__dst, v6, v7);
          break;
        default:
          memcpy(__dst, __src, *(void *)(*(void *)(v4 - 8) + 64));
          break;
      }
      swift_storeEnumTagMultiPayload(__dst, a3, 1);
    }
    else
    {
      memcpy(__dst, __src, *(void *)(*(void *)(a3 - 8) + 64));
    }
  }
  return __dst;
}

uint64_t type metadata completion function for MLHandPoseClassifier.ModelParameters.ValidationData(uint64_t a1)
{
  v5[0] = &unk_34B9C8;
  uint64_t result = type metadata accessor for MLHandPoseClassifier.DataSource(319);
  if (v4 <= 0x3F)
  {
    v5[1] = *(void *)(result - 8) + 64;
    swift_initEnumMetadataMultiPayload(a1, 256, 2, v5, v2, v3);
    return 0;
  }
  return result;
}

uint64_t MLTrainingSessionParameters.init(sessionDirectory:reportInterval:checkpointInterval:iterations:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v6 = a2;
  uint64_t v7 = v4;
  uint64_t v8 = (int *)type metadata accessor for MLTrainingSessionParameters(0);
  uint64_t v12 = v8[5];
  *(void *)(v7 + v12) = 5;
  uint64_t v13 = v8[6];
  *(void *)(v7 + v13) = 10;
  uint64_t v9 = v8[7];
  *(void *)(v7 + v9) = 1000;
  outlined init with copy of URL?(a1, v7);
  if (a3 < a2) {
    uint64_t v6 = a3;
  }
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, &demangling cache variable for type metadata for URL?);
  *(void *)(v7 + v12) = v6;
  *(void *)(v7 + v13) = a3;
  uint64_t result = a4;
  *(void *)(v7 + v9) = a4;
  return result;
}

uint64_t type metadata accessor for MLTrainingSessionParameters(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLTrainingSessionParameters;
  if (!type metadata singleton initialization cache for MLTrainingSessionParameters) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLTrainingSessionParameters);
  }
  return result;
}

uint64_t outlined init with copy of URL?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t MLTrainingSessionParameters.sessionDirectory.getter()
{
  return outlined init with copy of URL?(v1, v0);
}

uint64_t MLTrainingSessionParameters.reportInterval.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 20));
}

uint64_t MLTrainingSessionParameters.reportInterval.setter(uint64_t a1)
{
  uint64_t result = *(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 20);
  *(void *)(v1 + result) = a1;
  return result;
}

void (*MLTrainingSessionParameters.reportInterval.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLTrainingSessionParameters.checkpointInterval.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 24));
}

uint64_t MLTrainingSessionParameters.checkpointInterval.setter(uint64_t a1)
{
  uint64_t result = *(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 24);
  *(void *)(v1 + result) = a1;
  return result;
}

void (*MLTrainingSessionParameters.checkpointInterval.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLTrainingSessionParameters.iterations.getter()
{
  return *(void *)(v0 + *(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 28));
}

uint64_t MLTrainingSessionParameters.iterations.setter(uint64_t a1)
{
  uint64_t result = *(int *)(type metadata accessor for MLTrainingSessionParameters(0) + 28);
  *(void *)(v1 + result) = a1;
  return result;
}

void (*MLTrainingSessionParameters.iterations.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLTrainingSession.parameters.getter()
{
  return outlined init with copy of MLTrainingSessionParameters(direct field offset for MLTrainingSession.parameters + v1, v0, type metadata accessor for MLTrainingSessionParameters);
}

uint64_t MLTrainingSession.date.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = *(void *)(*(void *)v1 + 112) + v1;
  swift_beginAccess(v3, v6, 0, 0);
  uint64_t v4 = type metadata accessor for Date(0);
  return (*(uint64_t (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 16))(v2, v3, v4);
}

char MLTrainingSession.phase.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = *v1;
  uint64_t v4 = (uint64_t)v1 + *(void *)(*v1 + 112);
  swift_beginAccess(v4, v8, 0, 0);
  char result = *(unsigned char *)(*(int *)(type metadata accessor for MLTrainingSession.Metadata(0, *(void *)(v3 + 80), v5, v6)
                             + 28)
                    + v4);
  *uint64_t v2 = result;
  return result;
}

uint64_t type metadata accessor for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for MLTrainingSession.Metadata);
}

uint64_t key path setter for MLTrainingSession.phase : <A>MLTrainingSession<A>(char *a1)
{
  v3[0] = HIBYTE(v1);
  v3[0] = *a1;
  return MLTrainingSession.phase.setter(v3);
}

uint64_t MLTrainingSession.phase.setter(char *a1)
{
  uint64_t v2 = *v1;
  char v3 = *a1;
  uint64_t v4 = (uint64_t)v1 + *(void *)(*v1 + 112);
  swift_beginAccess(v4, v8, 1, 0);
  uint64_t result = *(int *)(type metadata accessor for MLTrainingSession.Metadata(0, *(void *)(v2 + 80), v5, v6) + 28);
  *(unsigned char *)(result + v4) = v3;
  return result;
}

uint64_t MLTrainingSession.iteration.getter()
{
  uint64_t v1 = *v0;
  uint64_t v2 = (uint64_t)v0 + *(void *)(*v0 + 112);
  swift_beginAccess(v2, v6, 0, 0);
  return *(void *)(*(int *)(type metadata accessor for MLTrainingSession.Metadata(0, *(void *)(v1 + 80), v3, v4)
                            + 32)
                   + v2);
}

uint64_t MLTrainingSession.iteration.setter(uint64_t a1)
{
  uint64_t v2 = *v1;
  uint64_t v3 = (uint64_t)v1 + *(void *)(*v1 + 112);
  swift_beginAccess(v3, v7, 1, 0);
  uint64_t result = *(int *)(type metadata accessor for MLTrainingSession.Metadata(0, *(void *)(v2 + 80), v4, v5) + 32);
  *(void *)(result + v3) = a1;
  return result;
}

uint64_t MLTrainingSession.checkpoints.getter()
{
  uint64_t v1 = *v0;
  uint64_t v2 = (uint64_t)v0 + *(void *)(*v0 + 112);
  swift_beginAccess(v2, v7, 0, 0);
  uint64_t v5 = *(void *)(*(int *)(type metadata accessor for MLTrainingSession.Metadata(0, *(void *)(v1 + 80), v3, v4) + 44)
                 + v2);
  swift_bridgeObjectRetain(v5);
  return v5;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> MLTrainingSession.save()()
{
  uint64_t v58 = v2;
  uint64_t v56 = type metadata accessor for MLTrainingSession.Metadata(0, *(void *)(*(void *)v3 + 80), v0, v1);
  uint64_t v60 = *(void *)(v56 - 8);
  int64_t v4 = *(void *)(v60 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v52 = v50;
  uint64_t v61 = type metadata accessor for CodingUserInfoKey(0);
  uint64_t v54 = *(void *)(v61 - 8);
  int64_t v7 = *(void *)(v54 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v53 = v50;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                              - 8)
                  + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  int64_t v13 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v16 = type metadata accessor for URL(0);
  uint64_t v57 = *(void *)(v16 - 8);
  int64_t v17 = *(void *)(v57 + 64);
  char v18 = alloca(v17);
  uint64_t v19 = alloca(v17);
  uint64_t v62 = v50;
  uint64_t v20 = alloca(v17);
  uint64_t v21 = alloca(v17);
  id v59 = v50;
  uint64_t v55 = v3;
  outlined init with copy of MLTrainingSessionParameters(v3 + direct field offset for MLTrainingSession.parameters, (uint64_t)v50, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?((uint64_t)v50, (uint64_t)v50);
  if (__swift_getEnumTagSinglePayload((uint64_t)v50, 1, v16) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v50, &demangling cache variable for type metadata for URL?);
    return;
  }
  uint64_t v22 = v59;
  (*(void (**)(unsigned char *, unsigned char *, uint64_t))(v57 + 32))(v59, v50, v16);
  URL.appendingPathComponent(_:)(0x696C702E6174656DLL, 0xEA00000000007473);
  uint64_t v23 = type metadata accessor for PropertyListEncoder(0);
  swift_allocObject(v23, *(unsigned int *)(v23 + 48), *(unsigned __int16 *)(v23 + 52));
  uint64_t v63 = PropertyListEncoder.init()();
  uint64_t v24 = v16;
  if (one-time initialization token for sessionDirectory != -1) {
    swift_once(&one-time initialization token for sessionDirectory, one-time initialization function for sessionDirectory);
  }
  uint64_t v25 = v61;
  uint64_t v26 = __swift_project_value_buffer(v61, (uint64_t)static CodingUserInfoKey.sessionDirectory);
  uint64_t v27 = (uint64_t)v53;
  (*(void (**)(unsigned char *, uint64_t, uint64_t))(v54 + 16))(v53, v26, v25);
  v51[3] = v24;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v51);
  uint64_t v61 = v24;
  (*(void (**)(void *, unsigned char *, uint64_t))(v57 + 16))(boxed_opaque_existential_1, v22, v24);
  uint64_t v29 = (void (*)(unsigned char *, void))dispatch thunk of PropertyListEncoder.userInfo.modify(v50);
  specialized Dictionary.subscript.setter((uint64_t)v51, v27);
  v29(v50, 0);
  uint64_t v30 = v55 + *(void *)(*(void *)v55 + 112);
  swift_beginAccess(v30, v51, 0, 0);
  uint64_t v31 = v52;
  uint64_t v32 = v30;
  uint64_t v33 = v56;
  uint64_t v34 = v60;
  (*(void (**)(unsigned char *, uint64_t, uint64_t))(v60 + 16))(v52, v32, v56);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for MLTrainingSession<A>.Metadata, v33);
  uint64_t v36 = v58;
  uint64_t v37 = dispatch thunk of PropertyListEncoder.encode<A>(_:)(v31, v33, WitnessTable);
  if (v36)
  {
    swift_release();
    (*(void (**)(unsigned char *, uint64_t))(v34 + 8))(v31, v33);
  }
  else
  {
    uint64_t v39 = v33;
    uint64_t v40 = v37;
    uint64_t v56 = v38;
    (*(void (**)(unsigned char *, uint64_t))(v34 + 8))(v31, v39);
    uint64_t v41 = v40;
    uint64_t v42 = v40;
    unint64_t v43 = v56;
    Data.write(to:options:)(v62, 0, v42, v56);
    uint64_t v60 = v41;
    uint64_t v47 = *(void *)(v55 + direct field offset for MLTrainingSession.delegate + 24);
    uint64_t v58 = 0;
    uint64_t v48 = *(void *)(v55 + direct field offset for MLTrainingSession.delegate + 32);
    __swift_project_boxed_opaque_existential_0Tm((void *)(v55 + direct field offset for MLTrainingSession.delegate), v47);
    uint64_t v49 = v58;
    (*(void (**)(unsigned char *, uint64_t))(*(void *)(v48 + 8) + 8))(v59, v47);
    if (!v49)
    {
      outlined consume of Data._Representation(v60, v43);
      swift_release();
      uint64_t v44 = *(void (**)(unsigned char *, uint64_t))(v57 + 8);
      uint64_t v45 = v62;
      goto LABEL_9;
    }
    outlined consume of Data._Representation(v60, v43);
    swift_release();
  }
  uint64_t v44 = *(void (**)(unsigned char *, uint64_t))(v57 + 8);
  uint64_t v45 = v62;
LABEL_9:
  uint64_t v46 = v61;
  v44(v45, v61);
  v44(v59, v46);
}

char MLTrainingSession.Metadata.CodingKeys.init(stringValue:)(uint64_t a1, unint64_t a2)
{
  if (a1 == 1702125924 && a2 == 0xE400000000000000)
  {
    unint64_t v2 = 0xE400000000000000;
LABEL_6:
    swift_bridgeObjectRelease(v2);
    return 0;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(1702125924, 0xE400000000000000, a1, a2, 0))
  {
    unint64_t v2 = a2;
    goto LABEL_6;
  }
  if (a1 == 0x6573616870 && a2 == 0xE500000000000000)
  {
    unint64_t v4 = 0xE500000000000000;
LABEL_12:
    swift_bridgeObjectRelease(v4);
    return 1;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0x6573616870, 0xE500000000000000, a1, a2, 0))
  {
    unint64_t v4 = a2;
    goto LABEL_12;
  }
  if (a1 == 0x6F69746172657469 && a2 == 0xE90000000000006ELL)
  {
    unint64_t v5 = 0xE90000000000006ELL;
LABEL_18:
    swift_bridgeObjectRelease(v5);
    return 2;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0x6F69746172657469, 0xE90000000000006ELL, a1, a2, 0))
  {
    unint64_t v5 = a2;
    goto LABEL_18;
  }
  if (a1 == 0x4C52556C65646F6DLL && a2 == 0xE800000000000000)
  {
    unint64_t v6 = 0xE800000000000000;
LABEL_24:
    swift_bridgeObjectRelease(v6);
    return 3;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0x4C52556C65646F6DLL, 0xE800000000000000, a1, a2, 0))
  {
    unint64_t v6 = a2;
    goto LABEL_24;
  }
  if (a1 == 0x7461447475706E69 && a2 == 0xEC0000004C525561)
  {
    unint64_t v7 = 0xEC0000004C525561;
LABEL_30:
    swift_bridgeObjectRelease(v7);
    return 4;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0x7461447475706E69, 0xEC0000004C525561, a1, a2, 0))
  {
    unint64_t v7 = a2;
    goto LABEL_30;
  }
  if (a1 == 0x696F706B63656863 && a2 == 0xEB0000000073746ELL)
  {
    swift_bridgeObjectRelease(0xEB0000000073746ELL);
    return 5;
  }
  else
  {
    char v8 = _stringCompareWithSmolCheck(_:_:expecting:)(0x696F706B63656863, 0xEB0000000073746ELL, a1, a2, 0);
    swift_bridgeObjectRelease(a2);
    return 6 - (v8 & 1);
  }
}

char MLTrainingSession.Metadata.CodingKeys.init(intValue:)()
{
  return 6;
}

uint64_t MLTrainingSession.Metadata.CodingKeys.stringValue.getter(char a1)
{
  switch(a1)
  {
    case 0:
      uint64_t result = 1702125924;
      break;
    case 1:
      uint64_t result = 0x6573616870;
      break;
    case 2:
      uint64_t result = 0x6F69746172657469;
      break;
    case 3:
      uint64_t result = 0x4C52556C65646F6DLL;
      break;
    case 4:
      uint64_t result = 0x7461447475706E69;
      break;
    case 5:
      uint64_t result = 0x696F706B63656863;
      break;
  }
  return result;
}

uint64_t MLTrainingSession.Metadata.encode(to:)(void *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  uint64_t v34 = v4;
  uint64_t v37 = v5;
  uint64_t v36 = (int *)a2;
  uint64_t v6 = type metadata accessor for MLTrainingSession.Metadata.CodingKeys(255, *(void *)(a2 + 16), a3, a4);
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for MLTrainingSession<A>.Metadata.CodingKeys, v6);
  uint64_t v38 = type metadata accessor for KeyedEncodingContainer(0, v6, WitnessTable);
  uint64_t v45 = *(void *)(v38 - 8);
  int64_t v7 = *(void *)(v45 + 64);
  char v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  uint64_t v35 = &v30;
  uint64_t v10 = a1[3];
  uint64_t v33 = a1[4];
  __swift_project_boxed_opaque_existential_0Tm(a1, v10);
  dispatch thunk of Encoder.container<A>(keyedBy:)(v6, v6, WitnessTable, v10, v33);
  char v39 = 0;
  uint64_t v11 = type metadata accessor for Date(0);
  uint64_t v12 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type Date and conformance Date, (uint64_t (*)(uint64_t))&type metadata accessor for Date, (uint64_t)&protocol conformance descriptor for Date);
  uint64_t v13 = v38;
  uint64_t v14 = v35;
  uint64_t v15 = v34;
  KeyedEncodingContainer.encode<A>(_:forKey:)(v37, &v39, v38, v11, v12);
  if (v15)
  {
    uint64_t v29 = v14;
  }
  else
  {
    char v40 = *(unsigned char *)(v37 + v36[7]);
    char v41 = 1;
    uint64_t v16 = lazy protocol witness table accessor for type MLPhase and conformance MLPhase();
    uint64_t v17 = v38;
    KeyedEncodingContainer.encode<A>(_:forKey:)(&v40, &v41, v38, &type metadata for MLPhase, v16);
    uint64_t v19 = *(void *)(v37 + v36[8]);
    char v42 = 2;
    KeyedEncodingContainer.encode(_:forKey:)(v19, &v42, v17);
    uint64_t v20 = v37 + v36[9];
    v46[0] = 3;
    uint64_t v34 = type metadata accessor for URL(0);
    uint64_t v21 = v20;
    uint64_t v22 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type URL and conformance URL, (uint64_t (*)(uint64_t))&type metadata accessor for URL, (uint64_t)&protocol conformance descriptor for URL);
    uint64_t v23 = v17;
    uint64_t v24 = v34;
    KeyedEncodingContainer.encodeIfPresent<A>(_:forKey:)(v21, v46, v23, v34, v22);
    uint64_t v25 = v37 + v36[10];
    char v43 = 4;
    KeyedEncodingContainer.encodeIfPresent<A>(_:forKey:)(v25, &v43, v38, v24, v22);
    uint64_t v31 = *(void *)(v37 + v36[11]);
    char v44 = 5;
    uint64_t v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLCheckpoint]);
    uint64_t v27 = lazy protocol witness table accessor for type [MLCheckpoint] and conformance <A> [A](&lazy protocol witness table cache variable for type [MLCheckpoint] and conformance <A> [A], &lazy protocol witness table cache variable for type MLCheckpoint and conformance MLCheckpoint, (uint64_t)&protocol conformance descriptor for MLCheckpoint, (uint64_t)&protocol conformance descriptor for <A> [A]);
    uint64_t v28 = v35;
    uint64_t v13 = v38;
    KeyedEncodingContainer.encode<A>(_:forKey:)(&v31, &v44, v38, v26, v27);
    uint64_t v29 = v28;
  }
  return (*(uint64_t (**)(uint64_t *, uint64_t))(v45 + 8))(v29, v13);
}

uint64_t MLTrainingSession.Metadata.init(from:)(void *a1, uint64_t a2)
{
  uint64_t v68 = v3;
  uint64_t v79 = a1;
  uint64_t v65 = v2;
  int64_t v4 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v62 = &v54;
  int64_t v7 = alloca(v4);
  char v8 = alloca(v4);
  id v59 = &v54;
  uint64_t v66 = type metadata accessor for Date(0);
  uint64_t v57 = *(void *)(v66 - 8);
  int64_t v9 = *(void *)(v57 + 64);
  uint64_t v10 = alloca(v9);
  uint64_t v11 = alloca(v9);
  id v67 = &v54;
  uint64_t v14 = type metadata accessor for MLTrainingSession.Metadata.CodingKeys(255, a2, v12, v13);
  uint64_t v56 = v14;
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for MLTrainingSession<A>.Metadata.CodingKeys, v14);
  uint64_t v78 = type metadata accessor for KeyedDecodingContainer(0, v14, WitnessTable);
  uint64_t v75 = *(void *)(v78 - 8);
  int64_t v15 = *(void *)(v75 + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  char v80 = &v54;
  uint64_t v20 = (int *)type metadata accessor for MLTrainingSession.Metadata(0, a2, v18, v19);
  uint64_t v77 = *((void *)v20 - 1);
  int64_t v21 = *(void *)(v77 + 64);
  uint64_t v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  Date.init()(0);
  uint64_t v58 = v20[7];
  *((unsigned char *)&v54 + v58) = 0;
  uint64_t v61 = v20[8];
  *(uint64_t *)((char *)&v54 + v61) = 0;
  uint64_t v24 = (char *)&v54 + v20[9];
  uint64_t v25 = type metadata accessor for URL(0);
  uint64_t v63 = v24;
  __swift_storeEnumTagSinglePayload((uint64_t)v24, 1, 1, v25);
  uint64_t v64 = (uint64_t)&v54 + v20[10];
  uint64_t v60 = v25;
  __swift_storeEnumTagSinglePayload(v64, 1, 1, v25);
  uint64_t v76 = v20;
  uint64_t v26 = v20[11];
  uint64_t v69 = &v54;
  *(uint64_t *)((char *)&v54 + v26) = (uint64_t)_swiftEmptyArrayStorage;
  uint64_t v27 = v26;
  uint64_t v28 = v79[3];
  uint64_t v29 = v79[4];
  __swift_project_boxed_opaque_existential_0Tm(v79, v28);
  uint64_t v30 = v68;
  dispatch thunk of Decoder.container<A>(keyedBy:)(v56, v56, WitnessTable, v28, v29);
  if (v30)
  {
    uint64_t v51 = v76;
    uint64_t v52 = v77;
    __swift_destroy_boxed_opaque_existential_1Tm(v79);
    uint64_t v53 = v69;
  }
  else
  {
    uint64_t v31 = v58;
    uint64_t v32 = v57;
    uint64_t v68 = v27;
    char v70 = 0;
    uint64_t v33 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type Date and conformance Date, (uint64_t (*)(uint64_t))&type metadata accessor for Date, (uint64_t)&protocol conformance descriptor for Date);
    KeyedDecodingContainer.decode<A>(_:forKey:)(v66, &v70, v78, v66, v33);
    (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v32 + 40))(v69, v67, v66);
    char v71 = 1;
    uint64_t v34 = lazy protocol witness table accessor for type MLPhase and conformance MLPhase();
    uint64_t v35 = v78;
    KeyedDecodingContainer.decode<A>(_:forKey:)(&type metadata for MLPhase, &v71, v78, &type metadata for MLPhase, v34);
    uint64_t v37 = v69;
    *((unsigned char *)v69 + v31) = v81;
    uint64_t v38 = v37;
    char v72 = 2;
    uint64_t v39 = KeyedDecodingContainer.decode(_:forKey:)(&v72, v35);
    *(uint64_t *)((char *)v38 + v61) = v39;
    v82[0] = 3;
    uint64_t v40 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type URL and conformance URL, (uint64_t (*)(uint64_t))&type metadata accessor for URL, (uint64_t)&protocol conformance descriptor for URL);
    uint64_t v41 = v35;
    uint64_t v42 = v40;
    uint64_t v43 = (uint64_t)v59;
    uint64_t v44 = v60;
    KeyedDecodingContainer.decodeIfPresent<A>(_:forKey:)(v60, v82, v41, v60, v40);
    outlined assign with take of URL?(v43, (uint64_t)v63);
    char v73 = 4;
    uint64_t v45 = (uint64_t)v62;
    KeyedDecodingContainer.decodeIfPresent<A>(_:forKey:)(v44, &v73, v78, v44, v42);
    outlined assign with take of URL?(v45, v64);
    uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLCheckpoint]);
    char v74 = 5;
    uint64_t v47 = lazy protocol witness table accessor for type [MLCheckpoint] and conformance <A> [A](&lazy protocol witness table cache variable for type [MLCheckpoint] and conformance <A> [A], &lazy protocol witness table cache variable for type MLCheckpoint and conformance MLCheckpoint, (uint64_t)&protocol conformance descriptor for MLCheckpoint, (uint64_t)&protocol conformance descriptor for <A> [A]);
    KeyedDecodingContainer.decode<A>(_:forKey:)(v46, &v74, v78, v46, v47);
    (*(void (**)(uint64_t *, uint64_t))(v75 + 8))(v80, v78);
    uint64_t v48 = v54;
    uint64_t v49 = v69;
    uint64_t v50 = v68;
    swift_bridgeObjectRelease(*(uint64_t *)((char *)v69 + v68));
    *(uint64_t *)((char *)v49 + v50) = v48;
    uint64_t v51 = v76;
    uint64_t v52 = v77;
    (*(void (**)(uint64_t, uint64_t *, int *))(v77 + 16))(v65, v49, v76);
    __swift_destroy_boxed_opaque_existential_1Tm(v79);
    uint64_t v53 = v49;
  }
  return (*(uint64_t (**)(uint64_t *, int *))(v52 + 8))(v53, v51);
}

BOOL protocol witness for static Equatable.== infix(_:_:) in conformance MLTrainingSession<A>.Metadata.CodingKeys(char *a1, char *a2)
{
  return static MLObjectDetector.DecodableAnnotation.Coordinates.CodingKeys.== infix(_:_:)(*a1, *a2);
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLTrainingSession<A>.Metadata.CodingKeys()
{
  return MLObjectDetector.DecodableAnnotation.Coordinates.CodingKeys.hashValue.getter(*v0);
}

void protocol witness for Hashable.hash(into:) in conformance MLTrainingSession<A>.Metadata.CodingKeys(uint64_t a1)
{
  MLObjectDetector.DecodableAnnotation.Coordinates.CodingKeys.hash(into:)(a1, *v1);
}

Swift::Int protocol witness for Hashable._rawHashValue(seed:) in conformance MLTrainingSession<A>.Metadata.CodingKeys(uint64_t a1)
{
  Hasher.init(_seed:)(a1);
  MLObjectDetector.DecodableAnnotation.Coordinates.CodingKeys.hash(into:)((uint64_t)v3, *v1);
  return Hasher._finalize()();
}

uint64_t protocol witness for CodingKey.stringValue.getter in conformance MLTrainingSession<A>.Metadata.CodingKeys()
{
  return MLTrainingSession.Metadata.CodingKeys.stringValue.getter(*v0);
}

char protocol witness for CodingKey.init(stringValue:) in conformance MLTrainingSession<A>.Metadata.CodingKeys(uint64_t a1, unint64_t a2)
{
  uint64_t v3 = v2;
  char result = MLTrainingSession.Metadata.CodingKeys.init(stringValue:)(a1, a2);
  *uint64_t v3 = result;
  return result;
}

uint64_t protocol witness for CodingKey.intValue.getter in conformance MLTrainingSession<A>.Metadata.CodingKeys()
{
  return Rectangle.CodingKeys.intValue.getter();
}

char protocol witness for CodingKey.init(intValue:) in conformance MLTrainingSession<A>.Metadata.CodingKeys()
{
  uint64_t v1 = v0;
  char result = MLTrainingSession.Metadata.CodingKeys.init(intValue:)();
  *uint64_t v1 = result;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLTrainingSession<A>.Metadata.CodingKeys(uint64_t a1)
{
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for MLTrainingSession<A>.Metadata.CodingKeys, a1);
  return CodingKey.description.getter(a1, WitnessTable);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLTrainingSession<A>.Metadata.CodingKeys(uint64_t a1)
{
  uint64_t WitnessTable = swift_getWitnessTable(&protocol conformance descriptor for MLTrainingSession<A>.Metadata.CodingKeys, a1);
  return CodingKey.debugDescription.getter(a1, WitnessTable);
}

uint64_t protocol witness for Decodable.init(from:) in conformance MLTrainingSession<A>.Metadata(void *a1, uint64_t a2)
{
  return MLTrainingSession.Metadata.init(from:)(a1, *(void *)(a2 + 16));
}

uint64_t protocol witness for Encodable.encode(to:) in conformance MLTrainingSession<A>.Metadata(void *a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return MLTrainingSession.Metadata.encode(to:)(a1, a2, a3, a4);
}

NSURL *MLTrainingSession.removeCheckpoints(_:)(uint64_t (*a1)(void *), uint64_t a2)
{
  uint64_t v68 = v2;
  int64_t v4 = v3;
  v55[1] = a2;
  uint64_t v56 = a1;
  int64_t v70 = *v3;
  int64_t v5 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                             - 8)
                 + 64);
  uint64_t v6 = alloca(v5);
  int64_t v7 = alloca(v5);
  char v8 = v55;
  int64_t v9 = alloca(v5);
  uint64_t v10 = alloca(v5);
  uint64_t v61 = v55;
  uint64_t v60 = type metadata accessor for MLCheckpoint(0);
  uint64_t v57 = *(void *)(v60 - 8);
  int64_t v11 = *(void *)(v57 + 64);
  uint64_t v12 = alloca(v11);
  uint64_t v13 = alloca(v11);
  uint64_t v63 = v55;
  uint64_t v14 = alloca(v11);
  int64_t v15 = alloca(v11);
  uint64_t v16 = v55;
  id v17 = objc_allocWithZone((Class)NSFileManager);
  id v64 = [v17 init];
  uint64_t v18 = *(void *)(*v4 + 112);
  id v67 = v4;
  uint64_t v19 = (char *)v4 + v18;
  swift_beginAccess(v19, v72, 1, 0);
  uint64_t v22 = type metadata accessor for MLTrainingSession.Metadata(0, *(void *)(v70 + 80), v20, v21);
  uint64_t v23 = v19;
  uint64_t v65 = v22;
  uint64_t v24 = *(int *)(v22 + 44);
  uint64_t v25 = *(void *)&v19[v24];
  uint64_t v58 = *(void *)(v25 + 16);
  uint64_t v62 = v19;
  if (v58)
  {
    uint64_t v69 = _swiftEmptyArrayStorage;
    unint64_t v26 = 0;
    uint64_t v27 = type metadata accessor for MLCheckpoint;
    id v59 = v55;
    uint64_t v66 = v55;
    do
    {
      uint64_t v28 = *(void *)&v23[*(int *)(v65 + 44)];
      if (v26 >= *(void *)(v28 + 16)) {
        BUG();
      }
      uint64_t v29 = (*(unsigned __int8 *)(v57 + 80) + 32) & ~*(unsigned __int8 *)(v57 + 80);
      v55[0] = *(void *)(v57 + 72);
      int64_t v70 = v26;
      outlined init with copy of MLTrainingSessionParameters(v29 + v26 * v55[0] + v28, (uint64_t)v16, v27);
      uint64_t v30 = v27;
      uint64_t v31 = (NSURL *)v56(v16);
      if (v31)
      {
        URL._bridgeToObjectiveC()(v31);
        uint64_t v33 = v32;
        id v71 = 0;
        unsigned __int8 v34 = [v64 removeItemAtURL:v32 error:&v71];

        id v35 = v71;
        if (v34)
        {
          v71;
        }
        else
        {
          id v41 = v71;
          uint64_t v42 = _convertNSErrorToError(_:)(v35);

          swift_willThrow(v41, "removeItemAtURL:error:", v43, v44, v45, v46);
          swift_errorRelease(v42);
          uint64_t v68 = 0;
        }
        char v8 = v66;
        uint64_t v27 = v30;
        int64_t v37 = v70;
      }
      else
      {
        outlined init with copy of MLTrainingSessionParameters((uint64_t)v16, (uint64_t)v63, v27);
        if (swift_isUniquelyReferenced_nonNull_native(v69)) {
          uint64_t v36 = v69;
        }
        else {
          uint64_t v36 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v69[2] + 1, 1, (uint64_t)v69);
        }
        int64_t v37 = v70;
        unint64_t v38 = v36[2];
        unint64_t v39 = v36[3];
        int64_t v40 = v38 + 1;
        if (v39 >> 1 <= v38)
        {
          int64_t v70 = v38 + 1;
          uint64_t v36 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v39 >= 2, v40, 1, (uint64_t)v36);
          int64_t v40 = v70;
        }
        void v36[2] = v40;
        uint64_t v69 = v36;
        outlined init with take of MLCheckpoint((uint64_t)v63, (uint64_t)v36 + v29 + v55[0] * v38);
        char v8 = v66;
      }
      unint64_t v26 = v37 + 1;
      uint64_t v16 = v59;
      outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v59, v27);
      uint64_t v23 = v62;
    }
    while (v58 != v26);
    uint64_t v24 = *(int *)(v65 + 44);
    uint64_t v25 = *(void *)&v62[v24];
    uint64_t v47 = v69;
  }
  else
  {
    uint64_t v47 = _swiftEmptyArrayStorage;
  }
  *(void *)&v23[v24] = v47;
  swift_bridgeObjectRetain((_BYTE)v47);
  swift_bridgeObjectRelease(v25);
  uint64_t v48 = (uint64_t)v61;
  specialized BidirectionalCollection.last.getter((uint64_t)v47);
  uint64_t v49 = v60;
  if (__swift_getEnumTagSinglePayload(v48, 1, v60) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v48, &demangling cache variable for type metadata for MLCheckpoint?);
    swift_bridgeObjectRelease((_BYTE)v47);
  }
  else
  {
    LOBYTE(v70) = *(unsigned char *)(v48 + *(int *)(v49 + 20));
    outlined destroy of MLActivityClassifier.ModelParameters(v48, type metadata accessor for MLCheckpoint);
    specialized BidirectionalCollection.last.getter((uint64_t)v47);
    swift_bridgeObjectRelease((_BYTE)v47);
    if (__swift_getEnumTagSinglePayload((uint64_t)v8, 1, v49) == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v8, &demangling cache variable for type metadata for MLCheckpoint?);
    }
    else
    {
      uint64_t v50 = (uint64_t)v8;
      uint64_t v51 = *(void *)((char *)v8 + *(int *)(v49 + 24));
      outlined destroy of MLActivityClassifier.ModelParameters(v50, type metadata accessor for MLCheckpoint);
      uint64_t v52 = v65;
      uint64_t v53 = v62;
      v62[*(int *)(v65 + 28)] = v70;
      *(void *)&v53[*(int *)(v52 + 32)] = v51;
    }
  }
  MLTrainingSession.save()();

  return __stack_chk_guard;
}

NSURL *MLTrainingSession.reuseExtractedFeatures(from:)(void *a1)
{
  uint64_t v108 = v1;
  uint64_t v107 = a1;
  uint64_t v3 = *v2;
  uint64_t v96 = type metadata accessor for Date(0);
  uint64_t v97 = *(void *)(v96 - 8);
  int64_t v4 = *(void *)(v97 + 64);
  int64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  id v98 = &v92;
  int64_t v7 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                             - 8)
                 + 64);
  char v8 = alloca(v7);
  int64_t v9 = alloca(v7);
  uint64_t v92 = (uint64_t)&v92;
  int64_t v10 = *(void *)(*(void *)(type metadata accessor for MLTrainingSessionParameters(0) - 8) + 64);
  int64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v95 = &v92;
  int64_t v13 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLCheckpoint?)
                              - 8)
                  + 64);
  uint64_t v14 = alloca(v13);
  int64_t v15 = alloca(v13);
  uint64_t v93 = &v92;
  uint64_t v106 = type metadata accessor for MLCheckpoint(0);
  uint64_t v102 = *(void *)(v106 - 8);
  int64_t v16 = *(void *)(v102 + 64);
  id v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  char v99 = &v92;
  uint64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v104 = &v92;
  uint64_t v21 = alloca(v16);
  uint64_t v22 = alloca(v16);
  uint64_t v23 = alloca(v16);
  uint64_t v24 = alloca(v16);
  uint64_t v105 = &v92;
  uint64_t v25 = v3[14];
  uint64_t v94 = v2;
  unint64_t v26 = (char *)v2 + v25;
  swift_beginAccess(v26, v112, 1, 0);
  uint64_t v29 = type metadata accessor for MLTrainingSession.Metadata(0, v3[10], v27, v28);
  if (*(void *)(*(void *)&v26[*(int *)(v29 + 44)] + 16))
  {
    uint64_t v30 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v30, 0, 0);
    *(void *)uint64_t v31 = 0xD000000000000047;
    id v35 = "reExtractor.swift";
LABEL_20:
    *(void *)(v31 + 8) = (unint64_t)v35 | 0x8000000000000000;
    *(_OWORD *)(v31 + 16) = 0;
    *(_OWORD *)(v31 + 32) = 0;
    *(unsigned char *)(v31 + 48) = 0;
    swift_willThrow(&type metadata for MLCreateError, v30, v31, v32, v33, v34);
    return __stack_chk_guard;
  }
  uint64_t v100 = v26;
  uint64_t v36 = (char *)v107 + *(void *)(*v107 + 112);
  uint64_t v37 = v29;
  swift_beginAccess(v36, v111, 0, 0);
  uint64_t v101 = v37;
  unint64_t v38 = *(void **)&v36[*(int *)(v37 + 44)];
  id v110 = v38;
  uint64_t v39 = v38[2];
  uint64_t v107 = v38;
  if (v39)
  {
    uint64_t v40 = v102;
    char v103 = (char *)v38 + ((*(unsigned __int8 *)(v102 + 80) + 32) & ~*(unsigned __int8 *)(v102 + 80));
    swift_bridgeObjectRetain((_BYTE)v38);
    id v41 = (int *)v106;
    while (2)
    {
      if (v39 > v107[2]) {
        BUG();
      }
      outlined init with copy of MLTrainingSessionParameters((uint64_t)&v103[--v39 * *(void *)(v40 + 72)], (uint64_t)&v92, type metadata accessor for MLCheckpoint);
      switch(*((unsigned char *)&v92 + v41[5]))
      {
        case 0:
          unint64_t v42 = 0xEB0000000064657ALL;
          uint64_t v43 = 0x696C616974696E69;
          goto LABEL_11;
        case 1:
          swift_bridgeObjectRelease(110);
          outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v92, type metadata accessor for MLCheckpoint);
          char v46 = 0;
          goto LABEL_17;
        case 2:
          unint64_t v42 = 0xE800000000000000;
          uint64_t v43 = 0x676E696E69617274;
          goto LABEL_11;
        case 3:
          unint64_t v42 = 0xEA0000000000676ELL;
          uint64_t v43 = 0x697461756C617665;
          goto LABEL_11;
        case 4:
          unint64_t v42 = 0xEB00000000676E69;
          uint64_t v43 = 0x636E657265666E69;
LABEL_11:
          char v44 = _stringCompareWithSmolCheck(_:_:expecting:)(v43, v42, 0x6974636172747865, 0xEA0000000000676ELL, 0);
          swift_bridgeObjectRelease(v42);
          outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v92, type metadata accessor for MLCheckpoint);
          if (v44)
          {
            char v46 = 0;
            goto LABEL_16;
          }
          id v41 = (int *)v106;
          uint64_t v40 = v102;
          uint64_t v45 = v108;
          if (v39) {
            continue;
          }
          char v46 = 1;
          uint64_t v39 = 0;
          break;
      }
      break;
    }
  }
  else
  {
    swift_bridgeObjectRetain((_BYTE)v38);
    char v46 = 1;
    uint64_t v39 = 0;
LABEL_16:
    id v41 = (int *)v106;
LABEL_17:
    uint64_t v45 = v108;
  }
  uint64_t v47 = alloca(24);
  uint64_t v48 = alloca(32);
  uint64_t v94 = &v110;
  uint64_t v49 = (uint64_t)v93;
  _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5Tm((uint64_t (*)(void))partial apply for specialized closure #1 in BidirectionalCollection.last(where:), (uint64_t)&v92, v39, v46, (uint64_t)v109, type metadata accessor for MLCheckpoint);
  swift_bridgeObjectRelease((_BYTE)v107);
  uint64_t v50 = v49;
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v49, 1, (uint64_t)v41);
  uint64_t v52 = v92;
  if (EnumTagSinglePayload == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v50, &demangling cache variable for type metadata for MLCheckpoint?);
    uint64_t v30 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v30, 0, 0);
    *(void *)uint64_t v31 = 0xD000000000000029;
    id v35 = "e create a new session.";
    goto LABEL_20;
  }
  char v103 = (char *)v45;
  uint64_t v54 = (uint64_t)v105;
  outlined init with take of MLCheckpoint(v50, (uint64_t)v105);
  uint64_t v55 = (uint64_t)v95;
  outlined init with copy of MLTrainingSessionParameters((uint64_t)v94 + direct field offset for MLTrainingSession.parameters, (uint64_t)v95, type metadata accessor for MLTrainingSessionParameters);
  outlined init with take of URL?(v55, v52);
  uint64_t v108 = type metadata accessor for URL(0);
  if (__swift_getEnumTagSinglePayload(v52, 1, v108) == 1) {
    BUG();
  }
  uint64_t v56 = v54;
  uint64_t v57 = *(void *)(v54 + v41[6]);
  uint64_t v107 = *(void **)(v56 + v41[8]);
  char v58 = (char)v107;
  uint64_t v59 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  uint64_t v60 = (void *)swift_allocObject(v59, 112, 7);
  v60[2] = 2;
  id v60[3] = 4;
  unsigned char v60[7] = &type metadata for String;
  v60[8] = lazy protocol witness table accessor for type String and conformance String();
  v60[4] = 0x6974636172747865;
  v60[5] = 0xEA0000000000676ELL;
  v60[12] = &type metadata for Int;
  v60[13] = &protocol witness table for Int;
  v60[9] = v57;
  swift_bridgeObjectRetain(v58);
  uint64_t v61 = String.init(format:_:)(0xD000000000000012, "ng a features checkpoint." + 0x8000000000000000, v60);
  uint64_t v63 = v62;
  uint64_t v64 = (uint64_t)v99;
  URL.appendingPathComponent(_:)(v61, v62);
  uint64_t v65 = v63;
  swift_bridgeObjectRelease(v63);
  uint64_t v66 = v106;
  *(unsigned char *)(v64 + *(int *)(v106 + 20)) = 1;
  uint64_t v67 = v66;
  *(void *)(v64 + *(int *)(v66 + 24)) = v57;
  uint64_t v68 = v98;
  Date.init()(v65);
  (*(void (**)(uint64_t))(*(void *)(v108 - 8) + 8))(v52);
  (*(void (**)(uint64_t, uint64_t *, uint64_t))(v97 + 32))(v64 + *(int *)(v67 + 28), v68, v96);
  *(void *)(v64 + *(int *)(v67 + 32)) = v107;
  outlined init with take of MLCheckpoint(v64, (uint64_t)v104);
  uint64_t v69 = objc_opt_self(NSFileManager);
  id v70 = [v69 defaultManager];
  id v71 = (NSURL *)v70;
  URL._bridgeToObjectiveC()(v71);
  char v73 = v72;
  URL._bridgeToObjectiveC()(v72);
  uint64_t v75 = v74;
  id v110 = 0;
  LOBYTE(v108) = [(NSURL *)v71 copyItemAtURL:v73 toURL:v74 error:&v110];

  id v76 = v110;
  if ((_BYTE)v108)
  {
    uint64_t v77 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<MLCheckpoint>);
    uint64_t v78 = *(unsigned __int8 *)(v102 + 80);
    uint64_t v79 = ((int)v78 + 32) & ~*(unsigned __int8 *)(v102 + 80);
    uint64_t v80 = swift_allocObject(v77, v79 + *(void *)(v102 + 72), v78 | 7);
    *(void *)(v80 + 16) = 1;
    *(void *)(v80 + 24) = 2;
    uint64_t v81 = (uint64_t)v104;
    outlined init with copy of MLTrainingSessionParameters((uint64_t)v104, v80 + v79, type metadata accessor for MLCheckpoint);
    v76;
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v105, type metadata accessor for MLCheckpoint);
    uint64_t v82 = v101;
    uint64_t v83 = *(int *)(v101 + 44);
    char v84 = v100;
    uint64_t v85 = *(void *)&v100[v83];
    *(void *)&v100[v83] = v80;
    swift_bridgeObjectRelease(v85);
    v84[*(int *)(v82 + 28)] = 1;
    uint64_t v86 = *(void *)(v81 + *(int *)(v106 + 24));
    outlined destroy of MLActivityClassifier.ModelParameters(v81, type metadata accessor for MLCheckpoint);
    *(void *)&v84[*(int *)(v82 + 32)] = v86;
  }
  else
  {
    id v87 = v110;
    _convertNSErrorToError(_:)(v76);

    swift_willThrow(v87, "copyItemAtURL:toURL:error:", v88, v89, v90, v91);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v104, type metadata accessor for MLCheckpoint);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v105, type metadata accessor for MLCheckpoint);
  }
  return __stack_chk_guard;
}

uint64_t *MLTrainingSession.deinit()
{
  uint64_t v1 = *v0;
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v0 + direct field offset for MLTrainingSession.parameters, type metadata accessor for MLTrainingSessionParameters);
  __swift_destroy_boxed_opaque_existential_1Tm((uint64_t *)((char *)v0
                                                         + direct field offset for MLTrainingSession.delegate));
  uint64_t v2 = (uint64_t)v0 + *(void *)(*v0 + 112);
  uint64_t v5 = type metadata accessor for MLTrainingSession.Metadata(0, *(void *)(v1 + 80), v3, v4);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v5 - 8) + 8))(v2, v5);
  return v0;
}

uint64_t MLTrainingSession.__deallocating_deinit()
{
  MLTrainingSession.deinit();
  return swift_deallocClassInstance(v0, *(unsigned int *)(*(void *)v0 + 48), *(unsigned __int16 *)(*(void *)v0 + 52));
}

uint64_t outlined init with take of MLCheckpoint(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = type metadata accessor for MLCheckpoint(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5(uint64_t (*a1)(void), uint64_t a2, uint64_t a3, char a4, uint64_t a5)
{
  return _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5Tm(a1, a2, a3, a4, a5, type metadata accessor for MLCheckpoint);
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_18CreateMLComponents5EventVTg5(uint64_t (*a1)(void), uint64_t a2, uint64_t a3, char a4, uint64_t a5)
{
  return _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5Tm(a1, a2, a3, a4, a5, (uint64_t (*)(void))&type metadata accessor for Event);
}

uint64_t _sSq3mapyqd_0_Sgqd_0_xqd__YKXEqd__YKs5ErrorRd__Ri_d_0_r0_lFxq0_q_Ri_zRi0_zRi__Ri0__Ri_0_Ri0_0_r1_lyxs5NeverOqd_0_Isgnrzr_xSgAb2ERsd__Ri_d_0_r_0_lIetMgnrzo_Tpq5Si_8CreateML12MLCheckpointVTg5Tm(uint64_t (*a1)(void), uint64_t a2, uint64_t a3, char a4, uint64_t a5, uint64_t (*a6)(void))
{
  uint64_t v8 = v6;
  if (a4)
  {
    uint64_t v11 = a6(0);
    uint64_t v12 = v8;
    uint64_t v13 = 1;
    return __swift_storeEnumTagSinglePayload(v12, v13, 1, v11);
  }
  uint64_t result = a1();
  if (!v7)
  {
    uint64_t v11 = a6(0);
    uint64_t v12 = v8;
    uint64_t v13 = 0;
    return __swift_storeEnumTagSinglePayload(v12, v13, 1, v11);
  }
  return result;
}

uint64_t specialized closure #1 in BidirectionalCollection.last(where:)(uint64_t *a1, uint64_t *a2)
{
  return specialized closure #1 in BidirectionalCollection.last(where:)(*a1, *a2);
}

{
  unsigned char v3[8];

  return specialized closure #1 in BidirectionalCollection.last(where:)(*a1, *a2, (uint64_t)v3);
}

char sub_1408CC()
{
  return MLTrainingSession.phase.getter();
}

uint64_t sub_1408E3(char *a1)
{
  return key path setter for MLTrainingSession.phase : <A>MLTrainingSession<A>(a1);
}

uint64_t sub_1408ED()
{
  return 8;
}

uint64_t sub_140907(uint64_t *a1, uint64_t *a2)
{
  uint64_t result = *a1;
  *a2 = *a1;
  return result;
}

uint64_t sub_140913()
{
  uint64_t v1 = v0;
  uint64_t result = MLTrainingSession.iteration.getter();
  *uint64_t v1 = result;
  return result;
}

uint64_t sub_14092D(uint64_t *a1)
{
  return MLTrainingSession.iteration.setter(*a1);
}

uint64_t sub_140947()
{
  return 8;
}

char *initializeBufferWithCopyOfBuffer for MLTrainingSessionParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v3 = __dst;
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v8 = *(void *)__src;
    *(void *)uint64_t v3 = *(void *)__src;
    uint64_t v3 = (char *)(v8 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    uint64_t v6 = type metadata accessor for URL(0);
    if (__swift_getEnumTagSinglePayload((uint64_t)__src, 1, v6))
    {
      uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
      memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
    }
    else
    {
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v6 - 8) + 16))(__dst, __src, v6);
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v6);
    }
    *(void *)&__dst[a3[5]] = *(void *)&__src[a3[5]];
    *(void *)&__dst[a3[6]] = *(void *)&__src[a3[6]];
    *(void *)&__dst[a3[7]] = *(void *)&__src[a3[7]];
  }
  return v3;
}

char *initializeWithCopy for MLTrainingSessionParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v4 = type metadata accessor for URL(0);
  if (__swift_getEnumTagSinglePayload((uint64_t)__src, 1, v4))
  {
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 16))(__dst, __src, v4);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v4);
  }
  *(void *)&__dst[a3[5]] = *(void *)&__src[a3[5]];
  *(void *)&__dst[a3[6]] = *(void *)&__src[a3[6]];
  *(void *)&__dst[a3[7]] = *(void *)&__src[a3[7]];
  return __dst;
}

char *assignWithCopy for MLTrainingSessionParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v3 = type metadata accessor for URL(0);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)__dst, 1, v3);
  int v5 = __swift_getEnumTagSinglePayload((uint64_t)__src, 1, v3);
  if (!EnumTagSinglePayload)
  {
    uint64_t v6 = *(void *)(v3 - 8);
    if (!v5)
    {
      (*(void (**)(char *, char *, uint64_t))(v6 + 24))(__dst, __src, v3);
      goto LABEL_7;
    }
    (*(void (**)(char *, uint64_t))(v6 + 8))(__dst, v3);
    goto LABEL_6;
  }
  if (v5)
  {
LABEL_6:
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
    goto LABEL_7;
  }
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v3 - 8) + 16))(__dst, __src, v3);
  __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v3);
LABEL_7:
  *(void *)&__dst[a3[5]] = *(void *)&__src[a3[5]];
  *(void *)&__dst[a3[6]] = *(void *)&__src[a3[6]];
  *(void *)&__dst[a3[7]] = *(void *)&__src[a3[7]];
  return __dst;
}

char *initializeWithTake for MLTrainingSessionParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v4 = type metadata accessor for URL(0);
  if (__swift_getEnumTagSinglePayload((uint64_t)__src, 1, v4))
  {
    uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(__dst, __src, *(void *)(*(void *)(v5 - 8) + 64));
  }
  else
  {
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v4 - 8) + 32))(__dst, __src, v4);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v4);
  }
  *(void *)&__dst[a3[5]] = *(void *)&__src[a3[5]];
  *(void *)&__dst[a3[6]] = *(void *)&__src[a3[6]];
  *(void *)&__dst[a3[7]] = *(void *)&__src[a3[7]];
  return __dst;
}

char *assignWithTake for MLTrainingSessionParameters(char *__dst, char *__src, int *a3)
{
  uint64_t v3 = type metadata accessor for URL(0);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)__dst, 1, v3);
  int v5 = __swift_getEnumTagSinglePayload((uint64_t)__src, 1, v3);
  if (!EnumTagSinglePayload)
  {
    uint64_t v6 = *(void *)(v3 - 8);
    if (!v5)
    {
      (*(void (**)(char *, char *, uint64_t))(v6 + 40))(__dst, __src, v3);
      goto LABEL_7;
    }
    (*(void (**)(char *, uint64_t))(v6 + 8))(__dst, v3);
    goto LABEL_6;
  }
  if (v5)
  {
LABEL_6:
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(__dst, __src, *(void *)(*(void *)(v7 - 8) + 64));
    goto LABEL_7;
  }
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v3 - 8) + 32))(__dst, __src, v3);
  __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v3);
LABEL_7:
  *(void *)&__dst[a3[5]] = *(void *)&__src[a3[5]];
  *(void *)&__dst[a3[6]] = *(void *)&__src[a3[6]];
  *(void *)&__dst[a3[7]] = *(void *)&__src[a3[7]];
  return __dst;
}

uint64_t getEnumTagSinglePayload for MLTrainingSessionParameters(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_140D5B);
}

uint64_t sub_140D5B(uint64_t a1, unsigned int a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  return __swift_getEnumTagSinglePayload(a1, a2, v2);
}

uint64_t storeEnumTagSinglePayload for MLTrainingSessionParameters(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_140D95);
}

uint64_t sub_140D95(uint64_t a1, unsigned int a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  return __swift_storeEnumTagSinglePayload(a1, a2, a2, v2);
}

uint64_t type metadata completion function for MLTrainingSessionParameters(uint64_t a1)
{
  uint64_t result = type metadata accessor for URL?(319);
  if (v2 <= 0x3F)
  {
    v3[0] = *(void *)(result - 8) + 64;
    v3[1] = (char *)&value witness table for Builtin.Int64 + 64;
    v3[2] = (char *)&value witness table for Builtin.Int64 + 64;
    void v3[3] = (char *)&value witness table for Builtin.Int64 + 64;
    swift_initStructMetadata(a1, 256, 4, v3, a1 + 16);
    return 0;
  }
  return result;
}

uint64_t type metadata accessor for URL?(uint64_t a1)
{
  uint64_t result = lazy cache variable for type metadata for URL?;
  if (!lazy cache variable for type metadata for URL?)
  {
    uint64_t v2 = type metadata accessor for URL(255);
    uint64_t result = type metadata accessor for Optional(a1, v2);
    if (!v3) {
      lazy cache variable for type metadata for URL? = result;
    }
  }
  return result;
}

uint64_t type metadata completion function for MLTrainingSession(uint64_t a1)
{
  uint64_t result = type metadata accessor for MLTrainingSessionParameters(319);
  if (v2 <= 0x3F)
  {
    v5[0] = *(void *)(result - 8) + 64;
    v5[1] = &unk_34BA68;
    _OWORD v5[2] = &unk_34BA80;
    uint64_t result = type metadata accessor for MLTrainingSession.Metadata(319, *(void *)(a1 + 80), v2, v3);
    if (v4 <= 0x3F)
    {
      void v5[3] = *(void *)(result - 8) + 64;
      uint64_t result = swift_initClassMetadata2(a1, 0, 4, v5, a1 + 88);
      if (!result) {
        return 0;
      }
    }
  }
  return result;
}

uint64_t type metadata accessor for MLTrainingSession(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for MLTrainingSession);
}

uint64_t method lookup function for MLTrainingSession(uint64_t a1, uint64_t a2)
{
  return swift_lookUpClassMethod(a1, a2, &nominal type descriptor for MLTrainingSession);
}

uint64_t type metadata completion function for MLTrainingSession.Metadata(uint64_t a1)
{
  uint64_t v1 = type metadata accessor for Date(319);
  uint64_t v2 = v1;
  if (v3 <= 0x3F)
  {
    v7[0] = *(void *)(v1 - 8) + 64;
    v7[1] = &unk_34BAC0;
    v7[2] = (char *)&value witness table for Builtin.Int64 + 64;
    uint64_t v4 = type metadata accessor for URL?(319);
    uint64_t v2 = v4;
    if (v5 <= 0x3F)
    {
      uint64_t v8 = *(void *)(v4 - 8) + 64;
      uint64_t v9 = v8;
      int64_t v10 = (char *)&value witness table for Builtin.BridgeObject + 64;
      uint64_t v2 = 0;
      swift_initStructMetadata(a1, 0, 6, v7, a1 + 24);
    }
  }
  return v2;
}

void *initializeBufferWithCopyOfBuffer for MLTrainingSession.Metadata(void *a1, void *a2, int *a3)
{
  unint64_t v3 = a1;
  int v4 = *(_DWORD *)(*((void *)a3 - 1) + 80);
  if ((v4 & 0x20000) != 0)
  {
    uint64_t v11 = *a2;
    *unint64_t v3 = *a2;
    unint64_t v3 = (void *)(v11 + ((v4 + 16) & ~v4));
    swift_retain();
  }
  else
  {
    uint64_t v6 = type metadata accessor for Date(0);
    (*(void (**)(void *, void *, uint64_t))(*(void *)(v6 - 8) + 16))(a1, a2, v6);
    *((unsigned char *)a1 + a3[7]) = *((unsigned char *)a2 + a3[7]);
    *(void *)((char *)a1 + a3[8]) = *(void *)((char *)a2 + a3[8]);
    uint64_t v7 = a3[9];
    __dst = (char *)a1 + v7;
    uint64_t v8 = (char *)a2 + v7;
    uint64_t v9 = type metadata accessor for URL(0);
    if (__swift_getEnumTagSinglePayload((uint64_t)v8, 1, v9))
    {
      uint64_t v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
      memcpy(__dst, v8, *(void *)(*(void *)(v10 - 8) + 64));
    }
    else
    {
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))(__dst, v8, v9);
      __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v9);
    }
    uint64_t v12 = a3[10];
    __dsta = (char *)a1 + v12;
    uint64_t v13 = (char *)a2 + v12;
    if (__swift_getEnumTagSinglePayload((uint64_t)v13, 1, v9))
    {
      uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
      memcpy(__dsta, v13, *(void *)(*(void *)(v14 - 8) + 64));
    }
    else
    {
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v9 - 8) + 16))(__dsta, v13, v9);
      __swift_storeEnumTagSinglePayload((uint64_t)__dsta, 0, 1, v9);
    }
    uint64_t v15 = a3[11];
    uint64_t v16 = *(void *)((char *)a2 + v15);
    *(void *)((char *)v3 + v15) = v16;
    swift_bridgeObjectRetain(v16);
  }
  return v3;
}

uint64_t destroy for MLTrainingSession.Metadata(uint64_t a1, int *a2)
{
  uint64_t v2 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a1, v2);
  uint64_t v3 = a1 + a2[9];
  uint64_t v4 = type metadata accessor for URL(0);
  if (!__swift_getEnumTagSinglePayload(v3, 1, v4)) {
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(v3, v4);
  }
  uint64_t v5 = a1 + a2[10];
  if (!__swift_getEnumTagSinglePayload(v5, 1, v4)) {
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(v5, v4);
  }
  return swift_bridgeObjectRelease(*(void *)(a1 + a2[11]));
}

uint64_t initializeWithCopy for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v5 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v5 - 8) + 16))(a1, a2, v5);
  *(unsigned char *)(a1 + a3[7]) = *(unsigned char *)(a2 + a3[7]);
  *(void *)(a1 + a3[8]) = *(void *)(a2 + a3[8]);
  uint64_t v6 = a3[9];
  __dst = (void *)(a1 + v6);
  uint64_t v7 = (const void *)(a2 + v6);
  uint64_t v8 = type metadata accessor for URL(0);
  if (__swift_getEnumTagSinglePayload((uint64_t)v7, 1, v8))
  {
    uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(__dst, v7, *(void *)(*(void *)(v9 - 8) + 64));
  }
  else
  {
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v8 - 8) + 16))(__dst, v7, v8);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v8);
  }
  __dsta = a3;
  uint64_t v10 = a3[10];
  uint64_t v11 = (void *)(a1 + v10);
  uint64_t v12 = (const void *)(a2 + v10);
  if (__swift_getEnumTagSinglePayload((uint64_t)v12, 1, v8))
  {
    uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v11, v12, *(void *)(*(void *)(v13 - 8) + 64));
  }
  else
  {
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v8 - 8) + 16))(v11, v12, v8);
    __swift_storeEnumTagSinglePayload((uint64_t)v11, 0, 1, v8);
  }
  uint64_t v14 = __dsta[11];
  uint64_t v15 = *(void *)(a2 + v14);
  *(void *)(a1 + v14) = v15;
  swift_bridgeObjectRetain(v15);
  return a1;
}

uint64_t assignWithCopy for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v4 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 24))(a1, a2, v4);
  *(unsigned char *)(a1 + a3[7]) = *(unsigned char *)(a2 + a3[7]);
  *(void *)(a1 + a3[8]) = *(void *)(a2 + a3[8]);
  uint64_t v25 = a3;
  uint64_t v5 = a3[9];
  uint64_t v6 = (void *)(v5 + a1);
  uint64_t v7 = (const void *)(a2 + v5);
  uint64_t v8 = type metadata accessor for URL(0);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v6, 1, v8);
  int v10 = __swift_getEnumTagSinglePayload((uint64_t)v7, 1, v8);
  if (EnumTagSinglePayload)
  {
    if (!v10)
    {
      (*(void (**)(void *, const void *, uint64_t))(*(void *)(v8 - 8) + 16))(v6, v7, v8);
      __swift_storeEnumTagSinglePayload((uint64_t)v6, 0, 1, v8);
      goto LABEL_7;
    }
    goto LABEL_6;
  }
  uint64_t v11 = *(void *)(v8 - 8);
  if (v10)
  {
    (*(void (**)(void *, uint64_t))(v11 + 8))(v6, v8);
LABEL_6:
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v6, v7, *(void *)(*(void *)(v12 - 8) + 64));
    goto LABEL_7;
  }
  (*(void (**)(void *, const void *, uint64_t))(v11 + 24))(v6, v7, v8);
LABEL_7:
  uint64_t v13 = v25[10];
  uint64_t v14 = (void *)(a1 + v13);
  uint64_t v15 = (const void *)(a2 + v13);
  int v16 = __swift_getEnumTagSinglePayload((uint64_t)v14, 1, v8);
  int v17 = __swift_getEnumTagSinglePayload((uint64_t)v15, 1, v8);
  if (!v16)
  {
    uint64_t v18 = *(void *)(v8 - 8);
    if (!v17)
    {
      (*(void (**)(void *, const void *, uint64_t))(v18 + 24))(v14, v15, v8);
      goto LABEL_13;
    }
    (*(void (**)(void *, uint64_t))(v18 + 8))(v14, v8);
    goto LABEL_12;
  }
  if (v17)
  {
LABEL_12:
    uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v14, v15, *(void *)(*(void *)(v19 - 8) + 64));
    goto LABEL_13;
  }
  (*(void (**)(void *, const void *, uint64_t))(*(void *)(v8 - 8) + 16))(v14, v15, v8);
  __swift_storeEnumTagSinglePayload((uint64_t)v14, 0, 1, v8);
LABEL_13:
  uint64_t v20 = v25[11];
  uint64_t v21 = *(void *)(a2 + v20);
  uint64_t v22 = *(void *)(a1 + v20);
  *(void *)(a1 + v20) = v21;
  swift_bridgeObjectRetain(v21);
  swift_bridgeObjectRelease(v22);
  return a1;
}

uint64_t initializeWithTake for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v4 = type metadata accessor for Date(0);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v4 - 8) + 32))(a1, a2, v4);
  *(unsigned char *)(a1 + a3[7]) = *(unsigned char *)(a2 + a3[7]);
  *(void *)(a1 + a3[8]) = *(void *)(a2 + a3[8]);
  uint64_t v5 = a3[9];
  __dst = (void *)(a1 + v5);
  uint64_t v6 = (const void *)(a2 + v5);
  uint64_t v7 = type metadata accessor for URL(0);
  if (__swift_getEnumTagSinglePayload((uint64_t)v6, 1, v7))
  {
    uint64_t v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(__dst, v6, *(void *)(*(void *)(v8 - 8) + 64));
  }
  else
  {
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v7 - 8) + 32))(__dst, v6, v7);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v7);
  }
  __dsta = a3;
  uint64_t v9 = a3[10];
  int v10 = (void *)(a1 + v9);
  uint64_t v11 = (const void *)(a2 + v9);
  if (__swift_getEnumTagSinglePayload((uint64_t)v11, 1, v7))
  {
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v10, v11, *(void *)(*(void *)(v12 - 8) + 64));
  }
  else
  {
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v7 - 8) + 32))(v10, v11, v7);
    __swift_storeEnumTagSinglePayload((uint64_t)v10, 0, 1, v7);
  }
  *(void *)(a1 + __dsta[11]) = *(void *)(a2 + __dsta[11]);
  return a1;
}

char *assignWithTake for MLTrainingSession.Metadata(char *a1, uint64_t a2, int *a3)
{
  uint64_t v5 = type metadata accessor for Date(0);
  (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v5 - 8) + 40))(a1, a2, v5);
  a1[a3[7]] = *(unsigned char *)(a2 + a3[7]);
  *(void *)&a1[a3[8]] = *(void *)(a2 + a3[8]);
  uint64_t v24 = a3;
  uint64_t v6 = a3[9];
  uint64_t v7 = (uint64_t)&a1[v6];
  uint64_t v8 = (const void *)(a2 + v6);
  uint64_t v9 = type metadata accessor for URL(0);
  __dst = (void *)v7;
  LODWORD(v7) = __swift_getEnumTagSinglePayload(v7, 1, v9);
  int EnumTagSinglePayload = __swift_getEnumTagSinglePayload((uint64_t)v8, 1, v9);
  if (v7)
  {
    if (EnumTagSinglePayload)
    {
      size_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                                  - 8)
                      + 64);
      uint64_t v12 = __dst;
LABEL_6:
      memcpy(v12, v8, v11);
      goto LABEL_9;
    }
    (*(void (**)(void *, const void *, uint64_t))(*(void *)(v9 - 8) + 32))(__dst, v8, v9);
    __swift_storeEnumTagSinglePayload((uint64_t)__dst, 0, 1, v9);
  }
  else
  {
    uint64_t v13 = *(void *)(v9 - 8);
    if (EnumTagSinglePayload)
    {
      (*(void (**)(void *, uint64_t))(v13 + 8))(__dst, v9);
      size_t v11 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?)
                                  - 8)
                      + 64);
      uint64_t v12 = __dst;
      goto LABEL_6;
    }
    (*(void (**)(void *, const void *, uint64_t))(v13 + 40))(__dst, v8, v9);
  }
LABEL_9:
  uint64_t v14 = v24[10];
  __dsta = a1;
  uint64_t v15 = &a1[v14];
  int v16 = (const void *)(a2 + v14);
  int v17 = __swift_getEnumTagSinglePayload((uint64_t)v15, 1, v9);
  int v18 = __swift_getEnumTagSinglePayload((uint64_t)v16, 1, v9);
  if (!v17)
  {
    uint64_t v19 = *(void *)(v9 - 8);
    if (!v18)
    {
      (*(void (**)(char *, const void *, uint64_t))(v19 + 40))(v15, v16, v9);
      goto LABEL_15;
    }
    (*(void (**)(char *, uint64_t))(v19 + 8))(v15, v9);
    goto LABEL_14;
  }
  if (v18)
  {
LABEL_14:
    uint64_t v20 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
    memcpy(v15, v16, *(void *)(*(void *)(v20 - 8) + 64));
    goto LABEL_15;
  }
  (*(void (**)(char *, const void *, uint64_t))(*(void *)(v9 - 8) + 32))(v15, v16, v9);
  __swift_storeEnumTagSinglePayload((uint64_t)v15, 0, 1, v9);
LABEL_15:
  uint64_t v21 = v24[11];
  uint64_t v22 = *(void *)&__dsta[v21];
  *(void *)&__dsta[v21] = *(void *)(a2 + v21);
  swift_bridgeObjectRelease(v22);
  return __dsta;
}

uint64_t getEnumTagSinglePayload for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_141815);
}

uint64_t sub_141815(uint64_t a1, unsigned int a2, uint64_t a3)
{
  uint64_t v4 = a1;
  uint64_t v5 = type metadata accessor for Date(0);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2) {
    return __swift_getEnumTagSinglePayload(v4, a2, v5);
  }
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2)
  {
    uint64_t v4 = *(int *)(a3 + 36) + a1;
    return __swift_getEnumTagSinglePayload(v4, a2, v5);
  }
  uint64_t result = 0;
  if ((*(void *)(a1 + *(int *)(a3 + 44)) & 0xFFFFFFFF00000001) == 0) {
    return (*(void *)(a1 + *(int *)(a3 + 44)) >> 1) + 1;
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLTrainingSession.Metadata(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_1418A8);
}

uint64_t sub_1418A8(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  uint64_t v6 = a1;
  uint64_t v7 = type metadata accessor for Date(0);
  if (*(_DWORD *)(*(void *)(v7 - 8) + 84) == a3) {
    return __swift_storeEnumTagSinglePayload(v6, a2, a2, v7);
  }
  uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  if (*(_DWORD *)(*(void *)(v7 - 8) + 84) == a3)
  {
    uint64_t v6 = *(int *)(a4 + 36) + a1;
    return __swift_storeEnumTagSinglePayload(v6, a2, a2, v7);
  }
  uint64_t result = *(int *)(a4 + 44);
  *(void *)(a1 + result) = 2 * (a2 - 1);
  return result;
}

uint64_t type metadata accessor for MLTrainingSession.Metadata.CodingKeys(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return __swift_instantiateGenericMetadata(a1, a2, a3, a4, (uint64_t)&nominal type descriptor for MLTrainingSession.Metadata.CodingKeys);
}

uint64_t outlined assign with take of URL?(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for URL?);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 40))(a2, a1, v2);
  return a2;
}

uint64_t lazy protocol witness table accessor for type [MLCheckpoint] and conformance <A> [A](uint64_t *a1, uint64_t *a2, uint64_t a3, uint64_t a4)
{
  uint64_t result = *a1;
  if (!*a1)
  {
    uint64_t v7 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [MLCheckpoint]);
    lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(a2, type metadata accessor for MLCheckpoint, a3);
    uint64_t result = swift_getWitnessTable(a4, v7);
    *a1 = result;
  }
  return result;
}

uint64_t type metadata instantiation function for MLTrainingSession.Metadata.CodingKeys(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_allocateGenericValueMetadata(a1, a2, a3, 8);
}

uint64_t base witness table accessor for Equatable in MLTrainingSession<A>.Metadata.CodingKeys(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for MLTrainingSession<A>.Metadata.CodingKeys, a1);
}

uint64_t base witness table accessor for CustomDebugStringConvertible in MLTrainingSession<A>.Metadata.CodingKeys(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for MLTrainingSession<A>.Metadata.CodingKeys, a1);
}

uint64_t base witness table accessor for CustomStringConvertible in MLTrainingSession<A>.Metadata.CodingKeys(uint64_t a1)
{
  return swift_getWitnessTable(&protocol conformance descriptor for MLTrainingSession<A>.Metadata.CodingKeys, a1);
}

uint64_t sub_141A1C(uint64_t *a1, uint64_t *a2)
{
  return sub_140907(a1, a2);
}

uint64_t MLTextClassifier.write(to:metadata:)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 64);
  v4[0] = *(_OWORD *)a2;
  v4[1] = *(_OWORD *)(a2 + 16);
  _OWORD v4[2] = *(_OWORD *)(a2 + 32);
  v4[3] = *(_OWORD *)(a2 + 48);
  uint64_t v5 = v2;
  return NLModel.write(to:defaultName:metadata:)(a1, 0x73616C4374786554, 0xEE00726569666973, v4);
}

uint64_t MLTextClassifier.write(toFile:metadata:)(Swift::String a1, uint64_t a2)
{
  uint64_t v2 = *(void *)(a2 + 64);
  v4[0] = *(_OWORD *)a2;
  v4[1] = *(_OWORD *)(a2 + 16);
  _OWORD v4[2] = *(_OWORD *)(a2 + 32);
  v4[3] = *(_OWORD *)(a2 + 48);
  uint64_t v5 = v2;
  return NLModel.write(toFile:defaultName:metadata:)(a1, 0x73616C4374786554, (void *)0xEE00726569666973, (uint64_t)v4);
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVySo7CIImageCSSGG_AJs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B59RtzlFAlMcfu_32ebed8ba5c9417264c39088de476e42ecAmLTf3nnnpk_nTf1cn_n(uint64_t a1)
{
  uint64_t v1 = *(void *)(a1 + 16);
  if (!v1) {
    return _swiftEmptyArrayStorage;
  }
  specialized ContiguousArray.reserveCapacity(_:)(v1);
  uint64_t v2 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>)
                 - 8);
  uint64_t v3 = ((*(unsigned __int8 *)(v2 + 80) + 32) & ~*(unsigned __int8 *)(v2 + 80)) + a1;
  uint64_t v7 = *(void *)(v2 + 72);
  do
  {
    uint64_t KeyPath = swift_getKeyPath(&unk_34BD58);
    swift_getAtKeyPath(v3, KeyPath);
    swift_release();
    specialized ContiguousArray._makeUniqueAndReserveCapacityIfNotUnique()(KeyPath);
    uint64_t v5 = _swiftEmptyArrayStorage[2];
    specialized ContiguousArray._reserveCapacityAssumingUniqueBuffer(oldCount:)(v5);
    specialized ContiguousArray._appendElementAssumeUniqueAndCapacity(_:newElement:)(v5);
    specialized ContiguousArray._endMutation()(v5);
    v3 += v7;
    --v1;
  }
  while (v1);
  return _swiftEmptyArrayStorage;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVySo7CIImageCSSGG_SSs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B63RtzlFSSAMcfu0_33_7eec49b2e7313abe927b434220475ef8AMSSTf3nnnpk_nTf1cn_n(uint64_t a1)
{
  int64_t v1 = *(void *)(a1 + 16);
  if (v1)
  {
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v1, 0);
    uint64_t v2 = *(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>)
                   - 8);
    uint64_t v3 = ((*(unsigned __int8 *)(v2 + 80) + 32) & ~*(unsigned __int8 *)(v2 + 80)) + a1;
    uint64_t v12 = *(void *)(v2 + 72);
    do
    {
      uint64_t KeyPath = swift_getKeyPath(&unk_34BD20);
      swift_getAtKeyPath(v3, KeyPath);
      swift_release();
      int64_t v11 = v1;
      if (!swift_isUniquelyReferenced_nonNull_native(_swiftEmptyArrayStorage)) {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, _swiftEmptyArrayStorage[2] + 1, 1);
      }
      unint64_t v5 = _swiftEmptyArrayStorage[2];
      unint64_t v6 = v5 + 1;
      if (_swiftEmptyArrayStorage[3] >> 1 <= v5)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v5 + 1, 1);
        unint64_t v6 = v5 + 1;
      }
      _swiftEmptyArrayStorage[2] = v6;
      uint64_t v7 = 2 * v5;
      _swiftEmptyArrayStorage[v7 + 4] = v9;
      _swiftEmptyArrayStorage[v7 + 5] = v10;
      v3 += v12;
      int64_t v1 = v11 - 1;
    }
    while (v11 != 1);
  }
  return _swiftEmptyArrayStorage;
}

uint64_t static MLImageClassifier._defaultSessionParameters.getter()
{
  uint64_t v1 = v0;
  if (one-time initialization token for _defaultSessionParameters != -1) {
    swift_once(&one-time initialization token for _defaultSessionParameters, one-time initialization function for _defaultSessionParameters);
  }
  uint64_t v2 = type metadata accessor for MLTrainingSessionParameters(0);
  uint64_t v3 = __swift_project_value_buffer(v2, (uint64_t)static MLImageClassifier._defaultSessionParameters);
  return outlined init with copy of MLTrainingSessionParameters(v3, v1, type metadata accessor for MLTrainingSessionParameters);
}

id MLImageClassifier.model.getter()
{
  return *v0;
}

void key path setter for MLImageClassifier.model : MLImageClassifier(id *a1)
{
  id v1 = *a1;
  MLImageClassifier.model.setter(v1);
}

void MLImageClassifier.model.setter(void *a1)
{
  *id v1 = a1;
}

void (*MLImageClassifier.model.modify(void **a1))(uint64_t a1, char a2)
{
  a1[1] = v1;
  uint64_t v3 = *v1;
  *a1 = *v1;
  v3;
  return MLImageClassifier.model.modify;
}

void MLImageClassifier.model.modify(uint64_t a1, char a2)
{
  id v2 = *(id *)a1;
  uint64_t v3 = *(id **)(a1 + 8);
  id v4 = *v3;
  if (a2)
  {
    id v5 = *(id *)a1;

    *uint64_t v3 = v5;
  }
  else
  {

    *uint64_t v3 = v2;
  }
}

uint64_t MLImageClassifier.modelParameters.getter()
{
  return outlined init with copy of MLImageClassifier.ModelParameters(v1 + 8, v0);
}

uint64_t MLImageClassifier.trainingMetrics.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLImageClassifier(0);
  return outlined init with copy of MLTrainingSessionParameters(v1 + *(int *)(v3 + 24), v2, type metadata accessor for MLClassifierMetrics);
}

uint64_t type metadata accessor for MLImageClassifier(uint64_t a1)
{
  uint64_t result = type metadata singleton initialization cache for MLImageClassifier;
  if (!type metadata singleton initialization cache for MLImageClassifier) {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLImageClassifier);
  }
  return result;
}

uint64_t MLImageClassifier.validationMetrics.getter()
{
  uint64_t v2 = v0;
  uint64_t v3 = type metadata accessor for MLImageClassifier(0);
  return outlined init with copy of MLTrainingSessionParameters(v1 + *(int *)(v3 + 28), v2, type metadata accessor for MLClassifierMetrics);
}

uint64_t MLImageClassifier.init(trainingData:parameters:)(uint64_t a1, uint64_t a2)
{
  uint64_t v27 = v3;
  uint64_t v26 = a2;
  uint64_t v4 = v2;
  uint64_t v5 = type metadata accessor for MLImageClassifier(0);
  int64_t v6 = *(void *)(*(void *)(v5 - 8) + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v22 = v21;
  uint64_t v25 = v4 + *(int *)(v5 + 24);
  MLClassifierMetrics.init()();
  uint64_t v9 = (uint64_t *)(v4 + *(int *)(v5 + 28));
  uint64_t v10 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v11 = swift_allocError(&type metadata for MLCreateError, v10, 0, 0);
  *(void *)uint64_t v12 = 0xD0000000000000C0;
  *(void *)(v12 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v12 + 16) = 0;
  *(_OWORD *)(v12 + 32) = 0;
  *(unsigned char *)(v12 + 48) = 0;
  *uint64_t v9 = v11;
  uint64_t v13 = type metadata accessor for MLClassifierMetrics.Contents(0);
  uint64_t v23 = v9;
  swift_storeEnumTagMultiPayload(v9, v13, 2);
  uint64_t v24 = a1;
  uint64_t v14 = v27;
  uint64_t v15 = static _ImageUtilities.getImageURLsAndLabels(from:)(a1);
  if (v14)
  {
    outlined destroy of MLImageClassifier.ModelParameters(v26);
    outlined destroy of MLActivityClassifier.ModelParameters(v24, type metadata accessor for MLImageClassifier.DataSource);
    outlined destroy of MLActivityClassifier.ModelParameters(v25, type metadata accessor for MLClassifierMetrics);
    return outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v23, type metadata accessor for MLClassifierMetrics);
  }
  else
  {
    uint64_t v16 = v15;
    uint64_t v27 = v4;
    uint64_t v17 = v26;
    outlined init with copy of MLImageClassifier.ModelParameters(v26, (uint64_t)v21);
    uint64_t v18 = swift_allocObject(&unk_399D58, 104, 7);
    *(void *)(v18 + 16) = v16;
    qmemcpy((void *)(v18 + 24), v21, 0x50uLL);
    uint64_t v19 = (uint64_t)v22;
    specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLImageClassifier.init(trainingData:parameters:), v18);
    swift_release();
    outlined destroy of MLImageClassifier.ModelParameters(v17);
    outlined destroy of MLActivityClassifier.ModelParameters(v24, type metadata accessor for MLImageClassifier.DataSource);
    outlined destroy of MLActivityClassifier.ModelParameters(v25, type metadata accessor for MLClassifierMetrics);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v23, type metadata accessor for MLClassifierMetrics);
    return outlined init with take of MLClassifierMetrics(v19, v27, type metadata accessor for MLImageClassifier);
  }
}

{
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  int64_t v6;
  void *v7;
  void *v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t result;
  unsigned char v18[80];
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  unsigned char *v23;

  uint64_t v20 = a2;
  uint64_t v19 = a1;
  uint64_t v4 = v2;
  uint64_t v5 = type metadata accessor for MLImageClassifier(0);
  int64_t v6 = *(void *)(*(void *)(v5 - 8) + 64);
  uint64_t v7 = alloca(v6);
  uint64_t v8 = alloca(v6);
  uint64_t v23 = v18;
  uint64_t v9 = v4 + *(int *)(v5 + 24);
  MLClassifierMetrics.init()();
  uint64_t v10 = *(int *)(v5 + 28);
  uint64_t v21 = v4 + v10;
  uint64_t v11 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v12 = swift_allocError(&type metadata for MLCreateError, v11, 0, 0);
  *(void *)uint64_t v13 = 0xD0000000000000C0;
  *(void *)(v13 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v13 + 16) = 0;
  *(_OWORD *)(v13 + 32) = 0;
  *(unsigned char *)(v13 + 48) = 0;
  uint64_t v22 = v4;
  *(void *)(v4 + v10) = v12;
  uint64_t v14 = type metadata accessor for MLClassifierMetrics.Contents(0);
  swift_storeEnumTagMultiPayload(v4 + v10, v14, 2);
  uint64_t v15 = v20;
  outlined init with copy of MLImageClassifier.ModelParameters(v20, (uint64_t)v18);
  uint64_t v16 = swift_allocObject(&unk_399D80, 104, 7);
  *(void *)(v16 + 16) = v19;
  qmemcpy((void *)(v16 + 24), v18, 0x50uLL);
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLImageClassifier.init(trainingData:parameters:), v16);
  outlined destroy of MLImageClassifier.ModelParameters(v15);
  swift_release();
  outlined destroy of MLActivityClassifier.ModelParameters(v9, type metadata accessor for MLClassifierMetrics);
  uint64_t result = outlined destroy of MLActivityClassifier.ModelParameters(v21, type metadata accessor for MLClassifierMetrics);
  if (!v3) {
    return outlined init with take of MLClassifierMetrics((uint64_t)v23, v22, type metadata accessor for MLImageClassifier);
  }
  return result;
}

uint64_t closure #1 in MLImageClassifier.init(trainingData:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v3[14] = a3;
  v3[13] = a2;
  v3[12] = a1;
  return swift_task_switch(closure #1 in MLImageClassifier.init(trainingData:parameters:), 0, 0);
}

{
  void *v3;

  v3[14] = a3;
  v3[13] = a2;
  v3[12] = a1;
  return swift_task_switch(closure #1 in MLImageClassifier.init(trainingData:parameters:), 0, 0);
}

uint64_t closure #1 in MLImageClassifier.init(trainingData:parameters:)()
{
  uint64_t v1 = v0[13];
  uint64_t v2 = v0[14];
  uint64_t v3 = specialized Sequence.flatMap<A>(_:)(v1);
  outlined init with copy of MLImageClassifier.ModelParameters(v2, (uint64_t)(v0 + 2));
  swift_bridgeObjectRetain(v1);
  uint64_t v4 = specialized Set.init<A>(_:)(v1);
  uint64_t v5 = (uint64_t **)swift_task_alloc(dword_3A911C);
  v0[15] = (uint64_t)v5;
  void *v5 = v0;
  v5[1] = (uint64_t *)closure #1 in MLImageClassifier.init(trainingData:parameters:);
  return MLImageClassifier.init(trainingData:parameters:classNames:)(v0[12], (uint64_t)v3, (uint64_t)(v0 + 2), v4);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v2 = *(void *)(*v1 + 120);
  uint64_t v3 = *v1;
  *(void *)(v3 + 128) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    return swift_task_switch(closure #1 in MLImageClassifier.init(trainingData:parameters:), 0, 0);
  }
  else {
    return (*(uint64_t (**)(void))(v3 + 8))();
  }
}

{
  uint64_t v0;

  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t *v0;
  uint64_t v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  uint64_t **v5;

  uint64_t v1 = v0[13];
  uint64_t v2 = v0[14];
  uint64_t v3 = specialized Sequence.flatMap<A>(_:)(v1);
  outlined init with copy of MLImageClassifier.ModelParameters(v2, (uint64_t)(v0 + 2));
  swift_bridgeObjectRetain(v1);
  uint64_t v4 = specialized Set.init<A>(_:)(v1);
  uint64_t v5 = (uint64_t **)swift_task_alloc(dword_3A911C);
  v0[15] = (uint64_t)v5;
  void *v5 = v0;
  v5[1] = (uint64_t *)closure #1 in MLImageClassifier.init(trainingData:parameters:);
  return MLImageClassifier.init(trainingData:parameters:classNames:)(v0[12], (uint64_t)v3, (uint64_t)(v0 + 2), v4);
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v2 = *(void *)(*v1 + 120);
  uint64_t v3 = *v1;
  *(void *)(v3 + 128) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    return swift_task_switch(closure #1 in MLImageClassifier.init(trainingData:parameters:), 0, 0);
  }
  else {
    return (*(uint64_t (**)(void))(v3 + 8))();
  }
}

{
  return closure #1 in MLImageClassifier.init(trainingData:parameters:)();
}

uint64_t MLImageClassifier.init(trainingData:parameters:classNames:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v4[28] = a4;
  v4[27] = a3;
  v4[26] = a2;
  v4[25] = a1;
  unint64_t v5 = (*(void *)(*(void *)(type metadata accessor for MLClassifierMetrics(0) - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[29] = swift_task_alloc(v5);
  v4[30] = swift_task_alloc(v5);
  unint64_t v6 = (*(void *)(*(void *)(type metadata accessor for MLImageClassifier.Model(0) - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[31] = swift_task_alloc(v6);
  v4[32] = swift_task_alloc(v6);
  uint64_t v7 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  v4[33] = v7;
  uint64_t v8 = *(void *)(v7 - 8);
  v4[34] = v8;
  uint64_t v9 = *(void *)(v8 + 64);
  v4[35] = v9;
  unint64_t v10 = (v9 + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[36] = swift_task_alloc(v10);
  v4[37] = swift_task_alloc(v10);
  unint64_t v11 = (*(void *)(*(void *)(type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0) - 8)
                   + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[38] = swift_task_alloc(v11);
  v4[39] = swift_task_alloc(v11);
  unint64_t v12 = (*(void *)(*(void *)(type metadata accessor for MLImageClassifier.FeatureExtractorType(0) - 8) + 64)
       + 15) & 0xFFFFFFFFFFFFFFF0;
  v4[40] = swift_task_alloc(v12);
  v4[41] = swift_task_alloc(v12);
  uint64_t v13 = type metadata accessor for MLImageClassifier.Classifier(0);
  v4[42] = swift_task_alloc((*(void *)(*(void *)(v13 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLImageClassifier.init(trainingData:parameters:classNames:), 0, 0);
}

uint64_t MLImageClassifier.init(trainingData:parameters:classNames:)()
{
  uint64_t v1 = *(void *)(v0 + 200);
  uint64_t v2 = *(void *)(v0 + 216);
  uint64_t v3 = type metadata accessor for MLImageClassifier(0);
  *(void *)(v0 + 344) = v3;
  *(_DWORD *)(v0 + 528) = *(_DWORD *)(v3 + 24);
  MLClassifierMetrics.init()();
  uint64_t v4 = *(int *)(v3 + 28);
  *(_DWORD *)(v0 + 532) = v4;
  uint64_t v5 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  uint64_t v6 = swift_allocError(&type metadata for MLCreateError, v5, 0, 0);
  *(void *)uint64_t v7 = 0xD0000000000000C0;
  *(void *)(v7 + 8) = "essor\n\nParameters\n" + 0x8000000000000000;
  *(_OWORD *)(v7 + 16) = 0;
  *(_OWORD *)(v7 + 32) = 0;
  *(unsigned char *)(v7 + 48) = 0;
  *(void *)(v1 + v4) = v6;
  uint64_t v8 = type metadata accessor for MLClassifierMetrics.Contents(0);
  swift_storeEnumTagMultiPayload(v1 + v4, v8, 2);
  uint64_t v9 = v1 + 8;
  outlined init with copy of MLImageClassifier.ModelParameters(v2, v9);
  MLImageClassifier.ModelParameters.validate()();
  if (v10)
  {
    uint64_t v11 = *(void *)(v0 + 224);
    uint64_t v12 = *(void *)(v0 + 208);
    outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v0 + 216));
    swift_bridgeObjectRelease(v11);
    swift_bridgeObjectRelease(v12);
    uint64_t v13 = *(void *)(v0 + 200);
    uint64_t v14 = v13 + *(int *)(v0 + 532);
    uint64_t v15 = v13 + *(int *)(v0 + 528);
    outlined destroy of MLImageClassifier.ModelParameters(v13 + 8);
    outlined destroy of MLActivityClassifier.ModelParameters(v15, type metadata accessor for MLClassifierMetrics);
    outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLClassifierMetrics);
    uint64_t v16 = *(void *)(v0 + 328);
    uint64_t v17 = *(void *)(v0 + 320);
    uint64_t v18 = *(void *)(v0 + 312);
    uint64_t v19 = *(void *)(v0 + 304);
    uint64_t v28 = *(void *)(v0 + 296);
    uint64_t v27 = *(void *)(v0 + 288);
    uint64_t v26 = *(void *)(v0 + 256);
    uint64_t v25 = *(void *)(v0 + 248);
    uint64_t v29 = *(void *)(v0 + 232);
    uint64_t v31 = *(void *)(v0 + 240);
    swift_task_dealloc(*(void *)(v0 + 336));
    swift_task_dealloc(v16);
    swift_task_dealloc(v17);
    swift_task_dealloc(v18);
    swift_task_dealloc(v19);
    swift_task_dealloc(v28);
    swift_task_dealloc(v27);
    swift_task_dealloc(v26);
    swift_task_dealloc(v25);
    swift_task_dealloc(v31);
    swift_task_dealloc(v29);
    return (*(uint64_t (**)(void))(v0 + 8))();
  }
  else
  {
    uint64_t v30 = *(void *)(v0 + 328);
    uint64_t v21 = *(void *)(v0 + 224);
    uint64_t v22 = *(void *)(v0 + 312);
    outlined init with copy of MLImageClassifier.ModelParameters(v9, v0 + 16);
    swift_bridgeObjectRetain(v21);
    MLImageClassifier.Classifier.init(labels:parameters:)(v21, (void *)(v0 + 16));
    MLImageClassifier.ModelParameters.algorithm.getter(v21);
    uint64_t v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType));
    *(void *)(v0 + 352) = v23;
    swift_bridgeObjectRelease(*(void *)(v22 + *(int *)(v23 + 48)));
    outlined init with take of MLClassifierMetrics(v22, v30, type metadata accessor for MLImageClassifier.FeatureExtractorType);
    uint64_t v24 = (void *)swift_task_alloc(dword_3AEB5C);
    *(void *)(v0 + 360) = v24;
    *uint64_t v24 = v0;
    v24[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
    return MLImageClassifier.FeatureExtractor.init(type:)(v0 + 96, *(void *)(v0 + 328));
  }
}

{
  uint64_t v0;
  uint64_t *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t (*v5)();

  uint64_t v3 = *(void *)(*v1 + 360);
  uint64_t v2 = *v1;
  *(void *)(*v1 + 368) = v0;
  swift_task_dealloc(v3);
  if (v0)
  {
    uint64_t v4 = *(void *)(v2 + 208);
    swift_bridgeObjectRelease(*(void *)(v2 + 224));
    swift_bridgeObjectRelease(v4);
    uint64_t v5 = MLImageClassifier.init(trainingData:parameters:classNames:);
  }
  else
  {
    uint64_t v5 = MLImageClassifier.init(trainingData:parameters:classNames:);
  }
  return swift_task_switch(v5, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v20;
  uint64_t (*v21)(uint64_t, uint64_t, uint64_t);
  void *v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;

  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 216) + 16, v0 + 168, &demangling cache variable for type metadata for Any?);
  if (!*(void *)(v0 + 192)) {
    BUG();
  }
  uint64_t v24 = *(void *)(v0 + 368);
  uint64_t v1 = *(void *)(v0 + 296);
  uint64_t v25 = *(void *)(v0 + 288);
  uint64_t v2 = *(void *)(v0 + 280);
  uint64_t v32 = *(void *)(v0 + 272);
  uint64_t v27 = *(void *)(v0 + 264);
  uint64_t v29 = *(void *)(v0 + 208);
  uint64_t v34 = *(void *)(v0 + 216);
  outlined init with take of Any((long long *)(v0 + 168), (_OWORD *)(v0 + 136));
  swift_dynamicCast(v1, v0 + 136, (char *)&type metadata for Any + 8, v27, 7);
  id v35 = *(void *)(v34 + 8);
  outlined init with copy of MLTrainingSessionParameters(v1, v25, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  uint64_t v3 = *(unsigned __int8 *)(v32 + 80);
  uint64_t v4 = ~*(unsigned __int8 *)(v32 + 80) & (v3 + 24);
  uint64_t v5 = swift_allocObject(&unk_399DB8, v4 + v2, v3 | 7);
  *(void *)(v5 + 16) = v29;
  outlined init with take of MLClassifierMetrics(v25, v5 + v4, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  specialized blockAwait<A>(_:)((uint64_t)&async function pointer to partial apply for closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:), v5);
  *(void *)(v0 + 376) = v6;
  *(void *)(v0 + 384) = v7;
  if (v24)
  {
    uint64_t v30 = *(void *)(v0 + 336);
    uint64_t v8 = *(void *)(v0 + 296);
    uint64_t v9 = *(void *)(v0 + 216);
    uint64_t v10 = *(void *)(v0 + 224);
    swift_release();
    swift_bridgeObjectRelease(v10);
    outlined destroy of MLImageClassifier.ModelParameters(v9);
    outlined destroy of MLActivityClassifier.ModelParameters(v8, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
    outlined destroy of MLImageClassifier.FeatureExtractor(v0 + 96);
    outlined destroy of MLActivityClassifier.ModelParameters(v30, type metadata accessor for MLImageClassifier.Classifier);
    uint64_t v11 = *(void *)(v0 + 200);
    uint64_t v12 = v11 + 8;
    uint64_t v13 = v11 + *(int *)(v0 + 532);
    uint64_t v14 = *(int *)(v0 + 528) + v11;
    outlined destroy of MLImageClassifier.ModelParameters(v12);
    outlined destroy of MLActivityClassifier.ModelParameters(v14, type metadata accessor for MLClassifierMetrics);
    outlined destroy of MLActivityClassifier.ModelParameters(v13, type metadata accessor for MLClassifierMetrics);
    uint64_t v15 = *(void *)(v0 + 328);
    uint64_t v16 = *(void *)(v0 + 320);
    uint64_t v17 = *(void *)(v0 + 312);
    uint64_t v18 = *(void *)(v0 + 304);
    uint64_t v23 = *(void *)(v0 + 296);
    uint64_t v28 = *(void *)(v0 + 288);
    uint64_t v36 = *(void *)(v0 + 256);
    uint64_t v26 = *(void *)(v0 + 248);
    uint64_t v31 = *(void *)(v0 + 232);
    uint64_t v33 = *(void *)(v0 + 240);
    swift_task_dealloc(*(void *)(v0 + 336));
    swift_task_dealloc(v15);
    swift_task_dealloc(v16);
    swift_task_dealloc(v17);
    swift_task_dealloc(v18);
    swift_task_dealloc(v23);
    swift_task_dealloc(v28);
    swift_task_dealloc(v36);
    swift_task_dealloc(v26);
    swift_task_dealloc(v33);
    swift_task_dealloc(v31);
    return (*(uint64_t (**)(void))(v0 + 8))();
  }
  else
  {
    uint64_t v20 = v6;
    swift_release();
    uint64_t v21 = (uint64_t (*)(uint64_t, uint64_t, uint64_t))((char *)&async function pointer to specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:)
                                                            + async function pointer to specialized static MLImageClassifier.applyAugmentations<A>(to:augmentationOptions:upsampleFactor:));
    uint64_t v22 = (void *)swift_task_alloc(dword_3AF4CC);
    *(void *)(v0 + 392) = v22;
    *uint64_t v22 = v0;
    v22[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
    return v21(v20, v35, 1);
  }
}

{
  void *v0;
  void *v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t (*v5)(void);
  void *v6;

  uint64_t v1 = (void *)v0[27];
  uint64_t v2 = v0[28];
  uint64_t v3 = *(void *)(v0[50] + 16);
  uint64_t v4 = *(void *)(v2 + 16);
  swift_bridgeObjectRelease(v2);
  static MLImageClassifier.reportAnalytics(trainingExampleCount:classCount:parameters:)(v3, v4, v1);
  uint64_t v5 = (uint64_t (*)(void))((char *)&async function pointer to specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:)
                                      + async function pointer to specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:));
  uint64_t v6 = (void *)swift_task_alloc(dword_3AF484);
  v0[52] = v6;
  const void *v6 = v0;
  v6[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
  return v5(v0[50]);
}

{
  void *v0;
  uint64_t v1;
  uint64_t (*v2)(void);
  void *v3;
  char *v5;
  void *v6;

  uint64_t v1 = *(void *)(v0[48] + 16);
  v0[55] = v1;
  if (v1)
  {
    uint64_t v2 = (uint64_t (*)(void))((char *)&async function pointer to specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:)
                                        + async function pointer to specialized MLImageClassifier.FeatureExtractor.extractFeatures<A>(from:));
    uint64_t v3 = (void *)swift_task_alloc(dword_3AF484);
    v0[58] = v3;
    *uint64_t v3 = v0;
    v3[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
    return v2(v0[48]);
  }
  else
  {
    uint64_t v5 = (char *)&async function pointer to specialized MLImageClassifier.Classifier.fitted<A>(to:eventHandler:)
       + async function pointer to specialized MLImageClassifier.Classifier.fitted<A>(to:eventHandler:);
    uint64_t v6 = (void *)swift_task_alloc(dword_3AF4B4);
    v0[56] = v6;
    const void *v6 = v0;
    v6[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
    return ((uint64_t (*)(void, void, void, void))v5)(v0[32], v0[53], 0, 0);
  }
}

{
  uint64_t v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t (*v5)();

  uint64_t v3 = *(void *)(*(void *)v1 + 448);
  uint64_t v2 = *(void **)v1;
  *(void *)(*(void *)v1 + 456) = v0;
  swift_task_dealloc(v3);
  if (v0)
  {
    uint64_t v4 = v2[48];
    swift_bridgeObjectRelease(v2[47]);
    swift_bridgeObjectRelease(v4);
    uint64_t v5 = MLImageClassifier.init(trainingData:parameters:classNames:);
  }
  else
  {
    swift_bridgeObjectRelease(v2[53]);
    uint64_t v5 = MLImageClassifier.init(trainingData:parameters:classNames:);
  }
  return swift_task_switch(v5, 0, 0);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  void *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v1 = v0[32];
  uint64_t v6 = v0[44];
  uint64_t v5 = v0[40];
  uint64_t v2 = v0[38];
  outlined init with take of MLClassifierMetrics(v1, v0[25] + *(int *)(v0[43] + 32), type metadata accessor for MLImageClassifier.Model);
  MLImageClassifier.ModelParameters.algorithm.getter(v1);
  swift_bridgeObjectRelease(*(void *)(v2 + *(int *)(v6 + 48)));
  outlined init with take of MLClassifierMetrics(v2, v5, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v3 = (void *)swift_task_alloc(dword_3A801C);
  v0[63] = v3;
  *uint64_t v3 = v0;
  v3[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
  return MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:)(v0[40]);
}

{
  uint64_t v0;
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t (*v5)();
  uint64_t v6;

  uint64_t v3 = *(void *)(*(void *)v1 + 488);
  uint64_t v2 = *(void **)v1;
  *(void *)(*(void *)v1 + 496) = v0;
  swift_task_dealloc(v3);
  if (v0)
  {
    uint64_t v4 = v2[48];
    swift_bridgeObjectRelease(v2[47]);
    swift_bridgeObjectRelease(v4);
    uint64_t v5 = MLImageClassifier.init(trainingData:parameters:classNames:);
  }
  else
  {
    uint64_t v6 = v2[53];
    swift_bridgeObjectRelease(v2[59]);
    swift_bridgeObjectRelease(v6);
    uint64_t v5 = MLImageClassifier.init(trainingData:parameters:classNames:);
  }
  return swift_task_switch(v5, 0, 0);
}

{
  void *v0;
  uint64_t v1;
  uint64_t v2;
  void *v3;
  uint64_t v5;
  uint64_t v6;

  uint64_t v1 = v0[31];
  uint64_t v6 = v0[44];
  uint64_t v5 = v0[40];
  uint64_t v2 = v0[38];
  outlined init with take of MLClassifierMetrics(v1, v0[25] + *(int *)(v0[43] + 32), type metadata accessor for MLImageClassifier.Model);
  MLImageClassifier.ModelParameters.algorithm.getter(v1);
  swift_bridgeObjectRelease(*(void *)(v2 + *(int *)(v6 + 48)));
  outlined init with take of MLClassifierMetrics(v2, v5, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v3 = (void *)swift_task_alloc(dword_3A801C);
  v0[63] = v3;
  *uint64_t v3 = v0;
  v3[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
  return MLImageClassifier.Model.exportAsCompiledMLModel(featureExtractorType:)(v0[40]);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t (*v15)(void);
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v32;
  uint64_t v33;
  uint64_t v34;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  uint64_t v41;
  uint64_t v42;
  uint64_t v43;
  uint64_t v44;
  uint64_t v45;
  uint64_t v46;

  id v41 = v0 + 96;
  uint64_t v1 = *(void *)(v0 + 520);
  char v44 = *(void *)(v0 + 512);
  uint64_t v2 = *(void *)(v0 + 376);
  uint64_t v3 = *(void **)(v0 + 200);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 320), type metadata accessor for MLImageClassifier.FeatureExtractorType);
  *uint64_t v3 = v1;
  specialized MLImageClassifier.evaluation<A>(on:)(v2);
  uint64_t v4 = *(void *)(v0 + 376);
  if (v44)
  {
    uint64_t v5 = *(void *)(v0 + 336);
    uint64_t v6 = *(void *)(v0 + 216);
    uint64_t v7 = *(void *)(v0 + 296);
    swift_bridgeObjectRelease(*(void *)(v0 + 384));
    outlined destroy of MLImageClassifier.ModelParameters(v6);
    outlined destroy of MLActivityClassifier.ModelParameters(v7, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
    outlined destroy of MLImageClassifier.FeatureExtractor(v41);
    outlined destroy of MLActivityClassifier.ModelParameters(v5, type metadata accessor for MLImageClassifier.Classifier);
    swift_bridgeObjectRelease(v4);

    uint64_t v8 = *(void *)(v0 + 200);
    uint64_t v9 = v8 + *(int *)(v0 + 532);
    uint64_t v10 = v8 + *(int *)(v0 + 528);
    outlined destroy of MLImageClassifier.ModelParameters(v8 + 8);
    outlined destroy of MLActivityClassifier.ModelParameters(v10, type metadata accessor for MLClassifierMetrics);
    outlined destroy of MLActivityClassifier.ModelParameters(v9, type metadata accessor for MLClassifierMetrics);
    outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 200) + *(int *)(*(void *)(v0 + 344) + 32), type metadata accessor for MLImageClassifier.Model);
    uint64_t v11 = *(void *)(v0 + 328);
    uint64_t v12 = *(void *)(v0 + 320);
    uint64_t v13 = *(void *)(v0 + 312);
    uint64_t v14 = *(void *)(v0 + 304);
    uint64_t v32 = *(void *)(v0 + 296);
    uint64_t v39 = *(void *)(v0 + 288);
    uint64_t v37 = *(void *)(v0 + 256);
    id v35 = *(void *)(v0 + 248);
    unint64_t v42 = *(void *)(v0 + 232);
    uint64_t v33 = *(void *)(v0 + 240);
    swift_task_dealloc(*(void *)(v0 + 336));
    swift_task_dealloc(v11);
    swift_task_dealloc(v12);
    swift_task_dealloc(v13);
    swift_task_dealloc(v14);
    swift_task_dealloc(v32);
    swift_task_dealloc(v39);
    swift_task_dealloc(v37);
    swift_task_dealloc(v35);
    swift_task_dealloc(v33);
    swift_task_dealloc(v42);
    uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
  }
  else
  {
    uint64_t v16 = *(void *)(v0 + 240);
    uint64_t v17 = *(void *)(v0 + 440);
    uint64_t v18 = *(void *)(v0 + 200) + *(int *)(v0 + 528);
    swift_bridgeObjectRelease(v4);
    outlined assign with take of MLClassifierMetrics(v16, v18);
    uint64_t v19 = *(void *)(v0 + 384);
    if (v17)
    {
      specialized MLImageClassifier.evaluation<A>(on:)(v19);
      uint64_t v20 = *(void *)(v0 + 384);
      uint64_t v24 = *(void *)(v0 + 336);
      uint64_t v25 = *(void *)(v0 + 296);
      uint64_t v45 = *(void *)(v0 + 232);
      uint64_t v26 = *(void *)(v0 + 200) + *(int *)(v0 + 532);
      outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v0 + 216));
      outlined destroy of MLActivityClassifier.ModelParameters(v25, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
      outlined destroy of MLImageClassifier.FeatureExtractor(v41);
      outlined destroy of MLActivityClassifier.ModelParameters(v24, type metadata accessor for MLImageClassifier.Classifier);
      swift_bridgeObjectRelease(v20);
      outlined assign with take of MLClassifierMetrics(v45, v26);
    }
    else
    {
      uint64_t v21 = *(void *)(v0 + 336);
      uint64_t v22 = *(void *)(v0 + 216);
      uint64_t v23 = *(void *)(v0 + 296);
      swift_bridgeObjectRelease(v19);
      outlined destroy of MLImageClassifier.ModelParameters(v22);
      outlined destroy of MLActivityClassifier.ModelParameters(v23, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
      outlined destroy of MLImageClassifier.FeatureExtractor(v41);
      outlined destroy of MLActivityClassifier.ModelParameters(v21, type metadata accessor for MLImageClassifier.Classifier);
    }
    uint64_t v27 = *(void *)(v0 + 328);
    uint64_t v28 = *(void *)(v0 + 320);
    uint64_t v29 = *(void *)(v0 + 312);
    uint64_t v30 = *(void *)(v0 + 304);
    uint64_t v40 = *(void *)(v0 + 296);
    unint64_t v38 = *(void *)(v0 + 288);
    uint64_t v36 = *(void *)(v0 + 256);
    uint64_t v34 = *(void *)(v0 + 248);
    char v46 = *(void *)(v0 + 232);
    uint64_t v43 = *(void *)(v0 + 240);
    swift_task_dealloc(*(void *)(v0 + 336));
    swift_task_dealloc(v27);
    swift_task_dealloc(v28);
    swift_task_dealloc(v29);
    swift_task_dealloc(v30);
    swift_task_dealloc(v40);
    swift_task_dealloc(v38);
    swift_task_dealloc(v36);
    swift_task_dealloc(v34);
    swift_task_dealloc(v43);
    swift_task_dealloc(v46);
    uint64_t v15 = *(uint64_t (**)(void))(v0 + 8);
  }
  return v15();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;

  uint64_t v1 = *(void *)(v0 + 336);
  outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v0 + 216));
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLImageClassifier.Classifier);
  uint64_t v2 = *(void *)(v0 + 200);
  uint64_t v3 = v2 + *(int *)(v0 + 532);
  uint64_t v4 = v2 + *(int *)(v0 + 528);
  outlined destroy of MLImageClassifier.ModelParameters(v2 + 8);
  outlined destroy of MLActivityClassifier.ModelParameters(v4, type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLClassifierMetrics);
  uint64_t v5 = *(void *)(v0 + 328);
  uint64_t v6 = *(void *)(v0 + 320);
  uint64_t v7 = *(void *)(v0 + 312);
  uint64_t v8 = *(void *)(v0 + 304);
  uint64_t v15 = *(void *)(v0 + 296);
  uint64_t v14 = *(void *)(v0 + 288);
  uint64_t v13 = *(void *)(v0 + 256);
  uint64_t v12 = *(void *)(v0 + 248);
  uint64_t v10 = *(void *)(v0 + 232);
  uint64_t v11 = *(void *)(v0 + 240);
  swift_task_dealloc(*(void *)(v0 + 336));
  swift_task_dealloc(v5);
  swift_task_dealloc(v6);
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;

  uint64_t v1 = *(void *)(v0 + 376);
  uint64_t v2 = *(void *)(v0 + 336);
  uint64_t v3 = *(void *)(v0 + 296);
  outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v0 + 216));
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined destroy of MLImageClassifier.FeatureExtractor(v0 + 96);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.Classifier);
  swift_bridgeObjectRelease(v1);
  uint64_t v4 = *(void *)(v0 + 200);
  uint64_t v5 = v4 + *(int *)(v0 + 532);
  uint64_t v6 = v4 + *(int *)(v0 + 528);
  outlined destroy of MLImageClassifier.ModelParameters(v4 + 8);
  outlined destroy of MLActivityClassifier.ModelParameters(v6, type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(v5, type metadata accessor for MLClassifierMetrics);
  uint64_t v7 = *(void *)(v0 + 328);
  uint64_t v8 = *(void *)(v0 + 320);
  uint64_t v9 = *(void *)(v0 + 312);
  uint64_t v10 = *(void *)(v0 + 304);
  uint64_t v17 = *(void *)(v0 + 296);
  uint64_t v16 = *(void *)(v0 + 288);
  uint64_t v15 = *(void *)(v0 + 256);
  uint64_t v14 = *(void *)(v0 + 248);
  uint64_t v12 = *(void *)(v0 + 232);
  uint64_t v13 = *(void *)(v0 + 240);
  swift_task_dealloc(*(void *)(v0 + 336));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v10);
  swift_task_dealloc(v17);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;

  uint64_t v1 = *(void *)(v0 + 400);
  uint64_t v2 = *(void *)(v0 + 336);
  uint64_t v3 = *(void *)(v0 + 296);
  outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v0 + 216));
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined destroy of MLImageClassifier.FeatureExtractor(v0 + 96);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.Classifier);
  swift_bridgeObjectRelease(v1);
  uint64_t v4 = *(void *)(v0 + 200);
  uint64_t v5 = v4 + *(int *)(v0 + 532);
  uint64_t v6 = v4 + *(int *)(v0 + 528);
  outlined destroy of MLImageClassifier.ModelParameters(v4 + 8);
  outlined destroy of MLActivityClassifier.ModelParameters(v6, type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(v5, type metadata accessor for MLClassifierMetrics);
  uint64_t v7 = *(void *)(v0 + 328);
  uint64_t v8 = *(void *)(v0 + 320);
  uint64_t v9 = *(void *)(v0 + 312);
  uint64_t v10 = *(void *)(v0 + 304);
  uint64_t v17 = *(void *)(v0 + 296);
  uint64_t v16 = *(void *)(v0 + 288);
  uint64_t v15 = *(void *)(v0 + 256);
  uint64_t v14 = *(void *)(v0 + 248);
  uint64_t v12 = *(void *)(v0 + 232);
  uint64_t v13 = *(void *)(v0 + 240);
  swift_task_dealloc(*(void *)(v0 + 336));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v10);
  swift_task_dealloc(v17);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;

  uint64_t v1 = *(void *)(v0 + 424);
  uint64_t v2 = *(void *)(v0 + 336);
  uint64_t v3 = *(void *)(v0 + 296);
  outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v0 + 216));
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined destroy of MLImageClassifier.FeatureExtractor(v0 + 96);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.Classifier);
  swift_bridgeObjectRelease(v1);
  uint64_t v4 = *(void *)(v0 + 200);
  uint64_t v5 = v4 + *(int *)(v0 + 532);
  uint64_t v6 = v4 + *(int *)(v0 + 528);
  outlined destroy of MLImageClassifier.ModelParameters(v4 + 8);
  outlined destroy of MLActivityClassifier.ModelParameters(v6, type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(v5, type metadata accessor for MLClassifierMetrics);
  uint64_t v7 = *(void *)(v0 + 328);
  uint64_t v8 = *(void *)(v0 + 320);
  uint64_t v9 = *(void *)(v0 + 312);
  uint64_t v10 = *(void *)(v0 + 304);
  uint64_t v17 = *(void *)(v0 + 296);
  uint64_t v16 = *(void *)(v0 + 288);
  uint64_t v15 = *(void *)(v0 + 256);
  uint64_t v14 = *(void *)(v0 + 248);
  uint64_t v12 = *(void *)(v0 + 232);
  uint64_t v13 = *(void *)(v0 + 240);
  swift_task_dealloc(*(void *)(v0 + 336));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v10);
  swift_task_dealloc(v17);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;

  uint64_t v1 = *(void *)(v0 + 384);
  uint64_t v2 = *(void *)(v0 + 336);
  uint64_t v3 = *(void *)(v0 + 296);
  outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v0 + 216));
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined destroy of MLImageClassifier.FeatureExtractor(v0 + 96);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.Classifier);
  swift_bridgeObjectRelease(v1);
  uint64_t v4 = *(void *)(v0 + 200);
  uint64_t v5 = v4 + *(int *)(v0 + 532);
  uint64_t v6 = v4 + *(int *)(v0 + 528);
  outlined destroy of MLImageClassifier.ModelParameters(v4 + 8);
  outlined destroy of MLActivityClassifier.ModelParameters(v6, type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(v5, type metadata accessor for MLClassifierMetrics);
  uint64_t v7 = *(void *)(v0 + 328);
  uint64_t v8 = *(void *)(v0 + 320);
  uint64_t v9 = *(void *)(v0 + 312);
  uint64_t v10 = *(void *)(v0 + 304);
  uint64_t v17 = *(void *)(v0 + 296);
  uint64_t v16 = *(void *)(v0 + 288);
  uint64_t v15 = *(void *)(v0 + 256);
  uint64_t v14 = *(void *)(v0 + 248);
  uint64_t v12 = *(void *)(v0 + 232);
  uint64_t v13 = *(void *)(v0 + 240);
  swift_task_dealloc(*(void *)(v0 + 336));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v10);
  swift_task_dealloc(v17);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;
  uint64_t v18;

  uint64_t v1 = *(void *)(v0 + 472);
  uint64_t v18 = *(void *)(v0 + 424);
  uint64_t v2 = *(void *)(v0 + 336);
  uint64_t v3 = *(void *)(v0 + 296);
  outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v0 + 216));
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined destroy of MLImageClassifier.FeatureExtractor(v0 + 96);
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.Classifier);
  swift_bridgeObjectRelease(v1);
  swift_bridgeObjectRelease(v18);
  uint64_t v4 = *(void *)(v0 + 200);
  uint64_t v5 = v4 + *(int *)(v0 + 532);
  uint64_t v6 = v4 + *(int *)(v0 + 528);
  outlined destroy of MLImageClassifier.ModelParameters(v4 + 8);
  outlined destroy of MLActivityClassifier.ModelParameters(v6, type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(v5, type metadata accessor for MLClassifierMetrics);
  uint64_t v7 = *(void *)(v0 + 328);
  uint64_t v8 = *(void *)(v0 + 320);
  uint64_t v9 = *(void *)(v0 + 312);
  uint64_t v10 = *(void *)(v0 + 304);
  uint64_t v17 = *(void *)(v0 + 296);
  uint64_t v16 = *(void *)(v0 + 288);
  uint64_t v15 = *(void *)(v0 + 256);
  uint64_t v14 = *(void *)(v0 + 248);
  uint64_t v12 = *(void *)(v0 + 232);
  uint64_t v13 = *(void *)(v0 + 240);
  swift_task_dealloc(*(void *)(v0 + 336));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v10);
  swift_task_dealloc(v17);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v17;

  uint64_t v1 = *(void *)(v0 + 336);
  uint64_t v2 = *(void *)(v0 + 320);
  uint64_t v3 = *(void *)(v0 + 296);
  outlined destroy of MLImageClassifier.ModelParameters(*(void *)(v0 + 216));
  outlined destroy of MLActivityClassifier.ModelParameters(v2, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined destroy of MLImageClassifier.FeatureExtractor(v0 + 96);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLImageClassifier.Classifier);
  uint64_t v4 = *(void *)(v0 + 200);
  uint64_t v5 = v4 + *(int *)(v0 + 532);
  uint64_t v6 = v4 + *(int *)(v0 + 528);
  outlined destroy of MLImageClassifier.ModelParameters(v4 + 8);
  outlined destroy of MLActivityClassifier.ModelParameters(v6, type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(v5, type metadata accessor for MLClassifierMetrics);
  outlined destroy of MLActivityClassifier.ModelParameters(*(void *)(v0 + 200) + *(int *)(*(void *)(v0 + 344) + 32), type metadata accessor for MLImageClassifier.Model);
  uint64_t v7 = *(void *)(v0 + 328);
  uint64_t v8 = *(void *)(v0 + 320);
  uint64_t v9 = *(void *)(v0 + 312);
  uint64_t v10 = *(void *)(v0 + 304);
  uint64_t v17 = *(void *)(v0 + 296);
  uint64_t v16 = *(void *)(v0 + 288);
  uint64_t v15 = *(void *)(v0 + 256);
  uint64_t v14 = *(void *)(v0 + 248);
  uint64_t v12 = *(void *)(v0 + 232);
  uint64_t v13 = *(void *)(v0 + 240);
  swift_task_dealloc(*(void *)(v0 + 336));
  swift_task_dealloc(v7);
  swift_task_dealloc(v8);
  swift_task_dealloc(v9);
  swift_task_dealloc(v10);
  swift_task_dealloc(v17);
  swift_task_dealloc(v16);
  swift_task_dealloc(v15);
  swift_task_dealloc(v14);
  swift_task_dealloc(v13);
  swift_task_dealloc(v12);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t MLImageClassifier.init(trainingData:parameters:classNames:)(uint64_t a1)
{
  uint64_t v4 = *(void *)(*(void *)v2 + 392);
  uint64_t v3 = *(void **)v2;
  v3[50] = a1;
  v3[51] = v1;
  swift_task_dealloc(v4);
  if (v1)
  {
    uint64_t v5 = v3[48];
    swift_bridgeObjectRelease(v3[28]);
    swift_bridgeObjectRelease(v5);
    uint64_t v6 = MLImageClassifier.init(trainingData:parameters:classNames:);
  }
  else
  {
    uint64_t v6 = MLImageClassifier.init(trainingData:parameters:classNames:);
  }
  return swift_task_switch(v6, 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t (*v6)();

  uint64_t v4 = *(void *)(*(void *)v2 + 416);
  uint64_t v3 = *(void **)v2;
  v3[53] = a1;
  v3[54] = v1;
  swift_task_dealloc(v4);
  if (v1)
  {
    uint64_t v5 = v3[48];
    swift_bridgeObjectRelease(v3[47]);
    swift_bridgeObjectRelease(v5);
    uint64_t v6 = MLImageClassifier.init(trainingData:parameters:classNames:);
  }
  else
  {
    swift_bridgeObjectRelease(v3[50]);
    uint64_t v6 = MLImageClassifier.init(trainingData:parameters:classNames:);
  }
  return swift_task_switch(v6, 0, 0);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v4;
  void *v5;
  uint64_t v6;
  char *v8;
  void *v9;

  uint64_t v4 = *(void *)(*(void *)v2 + 464);
  uint64_t v5 = *(void **)v2;
  v5[59] = a1;
  v5[60] = v1;
  swift_task_dealloc(v4);
  if (v1)
  {
    uint64_t v6 = v5[53];
    swift_bridgeObjectRelease(v5[47]);
    swift_bridgeObjectRelease(v6);
    return swift_task_switch(MLImageClassifier.init(trainingData:parameters:classNames:), 0, 0);
  }
  else
  {
    uint64_t v8 = (char *)&async function pointer to specialized MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:)
       + async function pointer to specialized MLImageClassifier.Classifier.fitted<A, B>(to:validateOn:eventHandler:);
    uint64_t v9 = (void *)swift_task_alloc(dword_3AF4A4);
    v5[61] = v9;
    *uint64_t v9 = v5;
    v9[1] = MLImageClassifier.init(trainingData:parameters:classNames:);
    return ((uint64_t (*)(void, void, uint64_t, void, void))v8)(v5[31], v5[53], a1, 0, 0);
  }
}

{
  uint64_t v1;
  uint64_t v2;
  void *v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t (*v7)();

  uint64_t v5 = *(void *)(*(void *)v2 + 504);
  uint64_t v4 = *(void **)v2;
  *(void *)(*(void *)v2 + 512) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    uint64_t v6 = v4[48];
    swift_bridgeObjectRelease(v4[47]);
    swift_bridgeObjectRelease(v6);
    uint64_t v7 = MLImageClassifier.init(trainingData:parameters:classNames:);
  }
  else
  {
    v4[65] = a1;
    uint64_t v7 = MLImageClassifier.init(trainingData:parameters:classNames:);
  }
  return swift_task_switch(v7, 0, 0);
}

uint64_t closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(void *)(v3 + 16) = a1;
  uint64_t v5 = (void *)swift_task_alloc(dword_3A9134);
  *(void *)(v3 + 24) = v5;
  void *v5 = v3;
  v5[1] = closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:);
  return static MLImageClassifier.collectImages(trainingData:validationData:)(a2, a3);
}

uint64_t closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:)(uint64_t a1, uint64_t a2)
{
  uint64_t v5 = *v3;
  uint64_t v6 = *(void *)(*v3 + 24);
  uint64_t v7 = *v3;
  swift_task_dealloc(v6);
  if (v2) {
    return (*(uint64_t (**)(void))(v7 + 8))();
  }
  *(void *)(v5 + 32) = a2;
  *(void *)(v5 + 40) = a1;
  return swift_task_switch(closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:), 0, 0);
}

uint64_t closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:)()
{
  *(__m128i *)*(void *)(v0 + 16) = _mm_shuffle_epi32(_mm_loadu_si128((const __m128i *)(v0 + 32)), 78);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t static MLImageClassifier.collectImages(trainingData:validationData:)(uint64_t a1, uint64_t a2)
{
  v2[3] = a2;
  v2[2] = a1;
  uint64_t v3 = type metadata accessor for MLImageClassifier.DataSource(0);
  v2[4] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v4 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  v2[5] = v4;
  v2[6] = swift_task_alloc((*(void *)(*(void *)(v4 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v5 = type metadata accessor for ImageReader(0);
  v2[7] = v5;
  uint64_t v6 = *(void *)(v5 - 8);
  v2[8] = v6;
  v2[9] = swift_task_alloc((*(void *)(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(static MLImageClassifier.collectImages(trainingData:validationData:), 0, 0);
}

uint64_t static MLImageClassifier.collectImages(trainingData:validationData:)()
{
  uint64_t v1 = v0[6];
  uint64_t v2 = v0[3];
  uint64_t v3 = v0[5];
  ImageReader.init()();
  outlined init with copy of MLTrainingSessionParameters(v2, v1, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  switch(swift_getEnumCaseMultiPayload(v1, v3))
  {
    case 0u:
      uint64_t v4 = v0[2];
      uint64_t v5 = v0[6];
      uint64_t v20 = *(void *)v5;
      uint64_t v6 = *(void *)(v5 + 8);
      __int16 v7 = *(unsigned __int8 *)(v5 + 16);
      unsigned __int8 v8 = *(unsigned char *)(v5 + 17);
      swift_bridgeObjectRetain(v4);
      uint64_t v9 = specialized Collection.randomSplit<A, B>(strategy:)(v20, v6, v7 | (unsigned __int16)(v8 << 8), v4);
      uint64_t v11 = v10;
      swift_bridgeObjectRelease(v4);
      break;
    case 1u:
      uint64_t v12 = v0[2];
      uint64_t v13 = v0[4];
      outlined init with take of MLClassifierMetrics(v0[6], v13, type metadata accessor for MLImageClassifier.DataSource);
      swift_bridgeObjectRetain(v12);
      uint64_t v14 = static _ImageUtilities.getImageURLsAndLabels(from:)(v13);
      LOBYTE(v12) = v14;
      uint64_t v16 = v0[4];
      uint64_t v9 = specialized Sequence.flatMap<A>(_:)(v14);
      swift_bridgeObjectRelease(v12);
      outlined destroy of MLActivityClassifier.ModelParameters(v16, type metadata accessor for MLImageClassifier.DataSource);
      goto LABEL_6;
    case 2u:
      uint64_t v15 = *(void *)v0[6];
      swift_bridgeObjectRetain(v0[2]);
      uint64_t v9 = specialized Sequence.flatMap<A>(_:)(v15);
      swift_bridgeObjectRelease(v15);
LABEL_6:
      uint64_t v11 = v0[2];
      break;
    case 3u:
      uint64_t v11 = v0[2];
      swift_bridgeObjectRetain(v11);
      uint64_t v9 = _swiftEmptyArrayStorage;
      break;
  }
  v0[11] = v11;
  v0[10] = v9;
  uint64_t v17 = (char *)&async function pointer to specialized Transformer.applied<A, B>(to:eventHandler:)
      + async function pointer to specialized Transformer.applied<A, B>(to:eventHandler:);
  uint64_t v18 = (void *)swift_task_alloc(dword_3AF47C);
  v0[12] = v18;
  *uint64_t v18 = v0;
  v18[1] = static MLImageClassifier.collectImages(trainingData:validationData:);
  return ((uint64_t (*)(uint64_t, void, void))v17)(v11, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v1 = *(void *)(v0 + 72);
  uint64_t v2 = *(void *)(v0 + 32);
  uint64_t v3 = *(void *)(v0 + 48);
  (*(void (**)(uint64_t, void))(*(void *)(v0 + 64) + 8))(v1, *(void *)(v0 + 56));
  swift_task_dealloc(v1);
  swift_task_dealloc(v3);
  swift_task_dealloc(v2);
  return (*(uint64_t (**)(void, void))(v0 + 8))(*(void *)(v0 + 104), *(void *)(v0 + 136));
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;

  (*(void (**)(void, void))(*(void *)(v0 + 64) + 8))(*(void *)(v0 + 72), *(void *)(v0 + 56));
  uint64_t v1 = *(void *)(v0 + 32);
  uint64_t v2 = *(void *)(v0 + 48);
  swift_task_dealloc(*(void *)(v0 + 72));
  swift_task_dealloc(v2);
  swift_task_dealloc(v1);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;

  uint64_t v1 = *(void *)(v0 + 80);
  (*(void (**)(void, void))(*(void *)(v0 + 64) + 8))(*(void *)(v0 + 72), *(void *)(v0 + 56));
  swift_bridgeObjectRelease(v1);
  uint64_t v2 = *(void *)(v0 + 32);
  uint64_t v3 = *(void *)(v0 + 48);
  swift_task_dealloc(*(void *)(v0 + 72));
  swift_task_dealloc(v3);
  swift_task_dealloc(v2);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

uint64_t static MLImageClassifier.collectImages(trainingData:validationData:)(uint64_t a1)
{
  uint64_t v3 = *(void *)(*(void *)v2 + 88);
  uint64_t v4 = *(void *)(*(void *)v2 + 96);
  uint64_t v5 = *(void **)v2;
  v5[13] = a1;
  v5[14] = v1;
  swift_task_dealloc(v4);
  swift_bridgeObjectRelease(v3);
  if (v1)
  {
    swift_bridgeObjectRelease(v5[10]);
    return swift_task_switch(static MLImageClassifier.collectImages(trainingData:validationData:), 0, 0);
  }
  else
  {
    __int16 v7 = (char *)&async function pointer to specialized Transformer.applied<A, B>(to:eventHandler:)
       + async function pointer to specialized Transformer.applied<A, B>(to:eventHandler:);
    unsigned __int8 v8 = (void *)swift_task_alloc(dword_3AF47C);
    v5[15] = v8;
    void *v8 = v5;
    v8[1] = static MLImageClassifier.collectImages(trainingData:validationData:);
    return ((uint64_t (*)(void, void, void))v7)(v5[10], 0, 0);
  }
}

{
  uint64_t v1;
  uint64_t v2;
  void *v4;
  uint64_t v5;
  uint64_t (*v6)();

  uint64_t v5 = *(void *)(*(void *)v2 + 120);
  uint64_t v4 = *(void **)v2;
  *(void *)(*(void *)v2 + 128) = v1;
  swift_task_dealloc(v5);
  if (v1)
  {
    swift_bridgeObjectRelease(v4[13]);
    uint64_t v6 = static MLImageClassifier.collectImages(trainingData:validationData:);
  }
  else
  {
    swift_bridgeObjectRelease(v4[10]);
    v4[17] = a1;
    uint64_t v6 = static MLImageClassifier.collectImages(trainingData:validationData:);
  }
  return swift_task_switch(v6, 0, 0);
}

char static MLImageClassifier.reportAnalytics(trainingExampleCount:classCount:parameters:)(int a1, int a2, void *a3)
{
  uint64_t v12 = v3;
  int64_t v5 = *(void *)(*(void *)(type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0) - 8)
                 + 64);
  uint64_t v6 = alloca(v5);
  __int16 v7 = alloca(v5);
  char result = AnalyticsReporter.init()();
  if ((result & 1) == 0)
  {
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_imageClassifier, (Swift::String)__PAIR128__((unint64_t)("ImageClassifier\n\nParameters\n" + 0x8000000000000000), 0xD000000000000010), (float)a1);
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_imageClassifier, (Swift::String)__PAIR128__((unint64_t)("Number of Images" + 0x8000000000000000), 0xD000000000000011), (float)a2);
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_imageClassifier, (Swift::String)__PAIR128__(0xEE00736E6F697461, 0x726574492078614DLL), (float)(int)*a3);
    AnalyticsReporter.reportDataMetrics(model:metricName:quantity:)(CreateML_ModelType_imageClassifier, (Swift::String)__PAIR128__((unint64_t)("Number of Classes" + 0x8000000000000000), 0xD000000000000014), a3[1]);
    MLImageClassifier.ModelParameters.algorithm.getter(12);
    uint64_t v9 = MLImageClassifier.ModelParameters.ModelAlgorithmType.description.getter(12);
    unint64_t v11 = v10;
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v12, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
    AnalyticsReporter.reportParameterSettings(model:parameterName:parameterValue:)(CreateML_ModelType_imageClassifier, (Swift::String)__PAIR128__(0xE90000000000006DLL, 0x687469726F676C41), (Swift::String)__PAIR128__(v11, v9));
    return swift_bridgeObjectRelease(v11);
  }
  return result;
}

uint64_t specialized MLImageClassifier.evaluation<A>(on:)(uint64_t a1)
{
  uint64_t v16 = v1;
  MLComponents16AnnotatedFeatureVySo7CIImageCSSGG_AJs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B59RtzlFAlMcfu_32ebed8ba5c9417264c39088de476e42ecAmLTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVySo7CIImageCSSGG_AJs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B59RtzlFAlMcfu_32ebed8ba5c9417264c39088de476e42ecAmLTf3nnnpk_nTf1cn_n(a1);
  char v4 = (char)MLComponents16AnnotatedFeatureVySo7CIImageCSSGG_AJs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B59RtzlFAlMcfu_32ebed8ba5c9417264c39088de476e42ecAmLTf3nnnpk_nTf1cn_n;
  int64_t v5 = MLImageClassifier.performRequests(_:)((uint64_t)MLComponents16AnnotatedFeatureVySo7CIImageCSSGG_AJs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B59RtzlFAlMcfu_32ebed8ba5c9417264c39088de476e42ecAmLTf3nnnpk_nTf1cn_n);
  uint64_t result = swift_bridgeObjectRelease(v4);
  if (!v2)
  {
    MLComponents16AnnotatedFeatureVySo7CIImageCSSGG_SSs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B63RtzlFSSAMcfu0_33_7eec49b2e7313abe927b434220475ef8AMSSTf3nnnpk_nTf1cn_n = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSay18CreateMLComponents16AnnotatedFeatureVySo7CIImageCSSGG_SSs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B63RtzlFSSAMcfu0_33_7eec49b2e7313abe927b434220475ef8AMSSTf3nnnpk_nTf1cn_n(a1);
    swift_bridgeObjectRetain((_BYTE)MLComponents16AnnotatedFeatureVySo7CIImageCSSGG_SSs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B63RtzlFSSAMcfu0_33_7eec49b2e7313abe927b434220475ef8AMSSTf3nnnpk_nTf1cn_n);
    uint64_t v8 = specialized Set.init<A>(_:)((uint64_t)MLComponents16AnnotatedFeatureVySo7CIImageCSSGG_SSs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B63RtzlFSSAMcfu0_33_7eec49b2e7313abe927b434220475ef8AMSSTf3nnnpk_nTf1cn_n);
    uint64_t v14 = v5;
    uint64_t v15 = MLComponents16AnnotatedFeatureVySo7CIImageCSSGG_SSs5NeverOTg503_s8d87ML17MLImageClassifierV10evaluation2onAA19MLClassifierMetricsVx_tKSlRz0A12MLComponents16fg5VySo7h5CSSG7B63RtzlFSSAMcfu0_33_7eec49b2e7313abe927b434220475ef8AMSSTf3nnnpk_nTf1cn_n;
    uint64_t v9 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
    uint64_t v10 = lazy protocol witness table accessor for type [String] and conformance [A]();
    uint64_t v11 = v16;
    ClassificationMetrics.init<A, B>(predicted:groundTruth:labels:)(&v14, &v15, v8, &type metadata for String, v9, v9, &protocol witness table for String, v10, v10);
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    swift_storeEnumTagMultiPayload(v11, v12, 0);
    uint64_t v13 = type metadata accessor for MLClassifierMetrics.Contents(0);
    return swift_storeEnumTagMultiPayload(v11, v13, 0);
  }
  return result;
}

uint64_t MLImageClassifier.init(delegate:)(uint64_t a1, uint64_t a2)
{
  v2[43] = a2;
  v2[42] = a1;
  uint64_t v3 = type metadata accessor for MLClassifierMetrics(0);
  v2[44] = v3;
  v2[45] = swift_task_alloc((*(void *)(*(void *)(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  unint64_t v4 = (*(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLClassifierMetrics?)
                              - 8)
                  + 64)
      + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[46] = swift_task_alloc(v4);
  v2[47] = swift_task_alloc(v4);
  uint64_t v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.Model?);
  v2[48] = swift_task_alloc((*(void *)(*(void *)(v5 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v6 = type metadata accessor for MLImageClassifier(0);
  v2[49] = v6;
  v2[50] = swift_task_alloc((*(void *)(*(void *)(v6 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v7 = type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType(0);
  v2[51] = v7;
  unint64_t v8 = (*(void *)(*(void *)(v7 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[52] = swift_task_alloc(v8);
  v2[53] = swift_task_alloc(v8);
  uint64_t v9 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  v2[54] = v9;
  unint64_t v10 = (*(void *)(*(void *)(v9 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v2[55] = swift_task_alloc(v10);
  v2[56] = swift_task_alloc(v10);
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  v2[57] = swift_task_alloc((*(void *)(*(void *)(v11 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  uint64_t v12 = type metadata accessor for MLImageClassifier.PersistentParameters(0);
  v2[58] = v12;
  v2[59] = swift_task_alloc((*(void *)(*(void *)(v12 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLImageClassifier.init(delegate:), 0, 0);
}

uint64_t MLImageClassifier.init(delegate:)()
{
  uint64_t v1 = *(void *)(v0 + 464);
  uint64_t v2 = *(void *)(v0 + 456);
  uint64_t v3 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingParameters + *(void *)(v0 + 344);
  swift_beginAccess(v3, v0 + 240, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v3, v2, &demangling cache variable for type metadata for MLImageClassifier.PersistentParameters?);
  if (__swift_getEnumTagSinglePayload(v2, 1, v1) == 1) {
    BUG();
  }
  uint64_t v18 = (void *)(v0 + 208);
  uint64_t v21 = (void *)(v0 + 176);
  uint64_t v4 = *(void *)(v0 + 472);
  uint64_t v5 = *(int **)(v0 + 464);
  uint64_t v6 = *(void *)(v0 + 448);
  uint64_t v23 = *(void *)(v0 + 440);
  uint64_t v22 = *(void *)(v0 + 432);
  uint64_t v26 = *(void *)(v0 + 424);
  uint64_t v20 = *(void *)(v0 + 416);
  uint64_t v19 = *(void *)(v0 + 408);
  uint64_t v17 = *(void *)(v0 + 344);
  uint64_t v16 = *(void *)(v0 + 384);
  outlined init with take of MLClassifierMetrics(*(void *)(v0 + 456), v4, type metadata accessor for MLImageClassifier.PersistentParameters);
  outlined init with copy of MLTrainingSessionParameters(v4 + v5[5], v6, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  uint64_t v24 = *(void *)(v4 + v5[8]);
  uint64_t v25 = *(void *)(v4 + v5[9]);
  uint64_t v7 = *(int *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (featureExtractor: MLImageClassifier.FeatureExtractorType, classifier: MLImageClassifier.ModelParameters.ClassifierType))
              + 48);
  outlined init with copy of MLTrainingSessionParameters(v4 + v5[6], v26, type metadata accessor for MLImageClassifier.FeatureExtractorType);
  uint64_t v8 = *(void *)(v4 + v5[7]);
  uint64_t v9 = v8;
  if (v8 == 2) {
    uint64_t v9 = 0;
  }
  *(void *)(v26 + v7) = v9;
  *(_OWORD *)(v0 + 80) = 0;
  *(_OWORD *)(v0 + 64) = 0;
  *(_OWORD *)(v0 + 48) = 0;
  *(_OWORD *)(v0 + 32) = 0;
  *(void *)(v0 + 16) = v24;
  *(void *)(v0 + 24) = v25;
  outlined init with copy of MLTrainingSessionParameters(v6, v23, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  *(void *)(v0 + 200) = v22;
  boxed_opaque_existential_1 = __swift_allocate_boxed_opaque_existential_1(v21);
  outlined init with take of MLClassifierMetrics(v23, (uint64_t)boxed_opaque_existential_1, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  outlined copy of MLImageClassifier.ModelParameters.ClassifierType?(v8);
  outlined assign with take of Any?((uint64_t)v21, v0 + 32);
  outlined init with copy of MLTrainingSessionParameters(v26, v20, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  *(void *)(v0 + 232) = v19;
  uint64_t v11 = __swift_allocate_boxed_opaque_existential_1(v18);
  outlined init with take of MLClassifierMetrics(v20, (uint64_t)v11, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  outlined assign with take of Any?((uint64_t)v18, v0 + 64);
  outlined destroy of MLActivityClassifier.ModelParameters(v26, type metadata accessor for MLImageClassifier.ModelParameters.ModelAlgorithmType);
  outlined destroy of MLActivityClassifier.ModelParameters(v6, type metadata accessor for MLImageClassifier.ModelParameters.ValidationData);
  uint64_t v12 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model + v17;
  swift_beginAccess(OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_model + v17, v0 + 264, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v12, v16, &demangling cache variable for type metadata for MLImageClassifier.Model?);
  uint64_t v13 = type metadata accessor for MLImageClassifier.Model(0);
  if (__swift_getEnumTagSinglePayload(v16, 1, v13) == 1) {
    BUG();
  }
  outlined init with copy of MLImageClassifier.ModelParameters(v0 + 16, v0 + 96);
  uint64_t v14 = (void *)swift_task_alloc(dword_3AEBBC);
  *(void *)(v0 + 480) = v14;
  *uint64_t v14 = v0;
  v14[1] = MLImageClassifier.init(delegate:);
  return MLImageClassifier.init(_:parameters:)(*(void *)(v0 + 400), *(void *)(v0 + 384), v0 + 96);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t (*v3)();

  uint64_t v2 = *(void *)(*(void *)v1 + 480);
  *(void *)(*(void *)v1 + 488) = v0;
  swift_task_dealloc(v2);
  if (v0) {
    uint64_t v3 = MLImageClassifier.init(delegate:);
  }
  else {
    uint64_t v3 = MLImageClassifier.init(delegate:);
  }
  return swift_task_switch(v3, 0, 0);
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v4;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  uint64_t v22;
  uint64_t v23;
  uint64_t v24;
  uint64_t v25;
  uint64_t v26;

  uint64_t v1 = *(void *)(v0 + 376);
  uint64_t v2 = *(void *)(v0 + 352);
  uint64_t v3 = *(void *)(v0 + 344);
  outlined init with take of MLClassifierMetrics(*(void *)(v0 + 400), *(void *)(v0 + 336), type metadata accessor for MLImageClassifier);
  uint64_t v4 = OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_trainingMetrics + v3;
  swift_beginAccess(v4, v0 + 288, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v4, v1, &demangling cache variable for type metadata for MLClassifierMetrics?);
  if (__swift_getEnumTagSinglePayload(v1, 1, v2) == 1) {
    BUG();
  }
  uint64_t v5 = *(void *)(v0 + 472);
  uint64_t v6 = *(void *)(v0 + 392);
  uint64_t v25 = *(void *)(v0 + 376);
  uint64_t v22 = *(void *)(v0 + 368);
  uint64_t v20 = *(void *)(v0 + 352);
  uint64_t v7 = *(void *)(v0 + 336);
  uint64_t v8 = *(void *)(v0 + 344);
  outlined destroy of MLImageClassifier.ModelParameters(v0 + 16);
  outlined destroy of MLActivityClassifier.ModelParameters(v5, type metadata accessor for MLImageClassifier.PersistentParameters);
  outlined assign with take of MLClassifierMetrics(v25, v7 + *(int *)(v6 + 24));
  uint64_t v9 = v8 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationMetrics;
  swift_beginAccess(v8 + OBJC_IVAR____TtC8CreateML38ImageClassifierTrainingSessionDelegate_validationMetrics, v0 + 312, 0, 0);
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v9, v22, &demangling cache variable for type metadata for MLClassifierMetrics?);
  swift_release();
  if (__swift_getEnumTagSinglePayload(v22, 1, v20) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(*(void *)(v0 + 368), &demangling cache variable for type metadata for MLClassifierMetrics?);
  }
  else
  {
    unint64_t v10 = *(void *)(v0 + 392);
    uint64_t v11 = *(void *)(v0 + 336);
    uint64_t v12 = *(void *)(v0 + 360);
    outlined init with take of MLClassifierMetrics(*(void *)(v0 + 368), v12, type metadata accessor for MLClassifierMetrics);
    outlined assign with take of MLClassifierMetrics(v12, v11 + *(int *)(v10 + 28));
  }
  uint64_t v13 = *(void *)(v0 + 456);
  uint64_t v14 = *(void *)(v0 + 448);
  uint64_t v15 = *(void *)(v0 + 440);
  uint64_t v16 = *(void *)(v0 + 424);
  uint64_t v19 = *(void *)(v0 + 416);
  uint64_t v18 = *(void *)(v0 + 400);
  uint64_t v26 = *(void *)(v0 + 384);
  uint64_t v24 = *(void *)(v0 + 376);
  uint64_t v21 = *(void *)(v0 + 360);
  uint64_t v23 = *(void *)(v0 + 368);
  swift_task_dealloc(*(void *)(v0 + 472));
  swift_task_dealloc(v13);
  swift_task_dealloc(v14);
  swift_task_dealloc(v15);
  swift_task_dealloc(v16);
  swift_task_dealloc(v19);
  swift_task_dealloc(v18);
  swift_task_dealloc(v26);
  swift_task_dealloc(v24);
  swift_task_dealloc(v23);
  swift_task_dealloc(v21);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

{
  uint64_t v0;
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  uint64_t v5;
  uint64_t v6;
  uint64_t v7;
  uint64_t v8;
  uint64_t v9;
  uint64_t v10;
  uint64_t v11;
  uint64_t v12;

  uint64_t v1 = *(void *)(v0 + 472);
  uint64_t v2 = *(void *)(v0 + 456);
  uint64_t v3 = *(void *)(v0 + 448);
  uint64_t v12 = *(void *)(v0 + 440);
  uint64_t v11 = *(void *)(v0 + 424);
  unint64_t v10 = *(void *)(v0 + 416);
  uint64_t v9 = *(void *)(v0 + 400);
  uint64_t v8 = *(void *)(v0 + 384);
  uint64_t v7 = *(void *)(v0 + 376);
  uint64_t v6 = *(void *)(v0 + 368);
  uint64_t v5 = *(void *)(v0 + 360);
  swift_release();
  outlined destroy of MLImageClassifier.ModelParameters(v0 + 16);
  outlined destroy of MLActivityClassifier.ModelParameters(v1, type metadata accessor for MLImageClassifier.PersistentParameters);
  swift_task_dealloc(v1);
  swift_task_dealloc(v2);
  swift_task_dealloc(v3);
  swift_task_dealloc(v12);
  swift_task_dealloc(v11);
  swift_task_dealloc(v10);
  swift_task_dealloc(v9);
  swift_task_dealloc(v8);
  swift_task_dealloc(v7);
  swift_task_dealloc(v6);
  swift_task_dealloc(v5);
  return (*(uint64_t (**)(void))(v0 + 8))();
}

void *MLImageClassifier.description.getter()
{
  return MLImageClassifier.debugDescription.getter();
}

void *MLImageClassifier.debugDescription.getter()
{
  uint64_t v1 = v0;
  v23._char object = (void *)type metadata accessor for MLClassifierMetrics.Contents(0);
  int64_t v2 = *(void *)(*((void *)v23._object - 1) + 64);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  v23._uint64_t countAndFlagsBits = MLImageClassifier.ModelParameters.description.getter();
  uint64_t v6 = v5;
  uint64_t v7 = type metadata accessor for MLImageClassifier(0);
  v20._uint64_t countAndFlagsBits = MLClassifierMetrics.description.getter();
  v20._char object = v8;
  uint64_t v9 = *(int *)(v7 + 28);
  unint64_t v10 = v6;
  outlined init with copy of MLTrainingSessionParameters(v1 + v9, (uint64_t)&v19, type metadata accessor for MLClassifierMetrics.Contents);
  LODWORD(v23._object) = swift_getEnumCaseMultiPayload(&v19, v23._object);
  outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)&v19, type metadata accessor for MLClassifierMetrics.Contents);
  v21._uint64_t countAndFlagsBits = MLClassifierMetrics.description.getter();
  uint64_t v12 = v11;
  v21._char object = (void *)0xD00000000000001CLL;
  uint64_t v22 = "odelType" + 0x8000000000000000;
  v13._uint64_t countAndFlagsBits = v23._countAndFlagsBits;
  v23._uint64_t countAndFlagsBits = (uint64_t)v10;
  v13._char object = v10;
  String.append(_:)(v13);
  v19._uint64_t countAndFlagsBits = 0xD00000000000001ELL;
  v19._char object = "ActivityClassifier\n\nParameters\n" + 0x8000000000000000;
  char object = (char)v20._object;
  String.append(_:)(v20);
  LOBYTE(v1) = v19._object;
  String.append(_:)(v19);
  swift_bridgeObjectRelease(v1);
  if (LODWORD(v23._object) > 1)
  {
    char v17 = object;
  }
  else
  {
    v19._uint64_t countAndFlagsBits = 0xD000000000000020;
    v19._char object = "\nPerformance on Training Data\n" + 0x8000000000000000;
    v15._uint64_t countAndFlagsBits = v21._countAndFlagsBits;
    v15._char object = v12;
    String.append(_:)(v15);
    char v16 = (char)v19._object;
    String.append(_:)(v19);
    swift_bridgeObjectRelease(object);
    char v17 = (char)v12;
    LOBYTE(v12) = v16;
  }
  swift_bridgeObjectRelease(v17);
  swift_bridgeObjectRelease((_BYTE)v12);
  swift_bridgeObjectRelease(v23._countAndFlagsBits);
  return v21._object;
}

void *protocol witness for CustomStringConvertible.description.getter in conformance MLImageClassifier()
{
  return MLImageClassifier.description.getter();
}

void *protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLImageClassifier()
{
  return MLImageClassifier.debugDescription.getter();
}

NSAttributedString MLImageClassifier.playgroundDescription.getter()
{
  uint64_t v1 = v0;
  uint64_t v2 = type metadata accessor for NSAttributedString();
  v3._uint64_t countAndFlagsBits = (uint64_t)MLImageClassifier.debugDescription.getter();
  v3._char object = v4;
  result.super.Class isa = NSAttributedString.__allocating_init(string:)(v3).super.isa;
  v1[3].super.Class isa = (Class)v2;
  v1->super.Class isa = result.super.isa;
  return result;
}

NSAttributedString protocol witness for CustomPlaygroundDisplayConvertible.playgroundDescription.getter in conformance MLImageClassifier()
{
  return MLImageClassifier.playgroundDescription.getter();
}

void *key path getter for AnnotatedFeature.feature : AnnotatedFeature<CIImage, String>()
{
  uint64_t v4 = v0;
  uint64_t v1 = v0;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>);
  AnnotatedFeature.feature.getter(v2);
  NSAttributedString result = v4;
  *uint64_t v1 = v4;
  return result;
}

uint64_t key path setter for AnnotatedFeature.feature : AnnotatedFeature<CIImage, String>(id *a1)
{
  v3[0] = *a1;
  v3[0];
  uint64_t v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>);
  return AnnotatedFeature.feature.setter(v3, v1);
}

uint64_t key path getter for AnnotatedFeature.annotation : AnnotatedFeature<CIImage, String>()
{
  uint64_t v1 = v0;
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>);
  uint64_t result = AnnotatedFeature.annotation.getter(v2);
  *uint64_t v1 = v4;
  return result;
}

uint64_t key path setter for AnnotatedFeature.annotation : AnnotatedFeature<CIImage, String>(uint64_t *a1)
{
  uint64_t v1 = *a1;
  uint64_t v2 = a1[1];
  v5[0] = v1;
  v5[1] = v2;
  swift_bridgeObjectRetain(v2);
  uint64_t v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<CIImage, String>);
  return AnnotatedFeature.annotation.setter(v5, v3);
}

uint64_t sub_145926()
{
  return objectdestroyTm_2();
}

uint64_t partial apply for closure #1 in MLImageClassifier.init(trainingData:parameters:)(uint64_t a1)
{
  uint64_t v3 = *(void *)(v1 + 16);
  long long v4 = (void *)swift_task_alloc(dword_3A9044);
  *(void *)(v2 + 16) = v4;
  void *v4 = v2;
  v4[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLImageClassifier.init(trainingData:parameters:)(a1, v3, v1 + 24);
}

{
  uint64_t v1;
  uint64_t v2;
  uint64_t v3;
  void *v4;

  uint64_t v3 = *(void *)(v1 + 16);
  long long v4 = (void *)swift_task_alloc(dword_3A9054);
  *(void *)(v2 + 16) = v4;
  void *v4 = v2;
  v4[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLImageClassifier.init(trainingData:parameters:)(a1, v3, v1 + 24);
}

uint64_t sub_145994()
{
  return objectdestroyTm_2();
}

uint64_t objectdestroyTm_2()
{
  swift_bridgeObjectRelease(v0[2]);
  if (v0[8]) {
    __swift_destroy_boxed_opaque_existential_1Tm(v0 + 5);
  }
  if (v0[12]) {
    __swift_destroy_boxed_opaque_existential_1Tm(v0 + 9);
  }
  return swift_deallocObject(v0, 104, 7);
}

id sub_145A4B()
{
  uint64_t v1 = v0;
  id result = MLImageClassifier.model.getter();
  *uint64_t v1 = result;
  return result;
}

void sub_145A65(id *a1)
{
}

char *initializeBufferWithCopyOfBuffer for MLImageClassifier(char *a1, char **a2, uint64_t a3)
{
  int v4 = *(_DWORD *)(*(void *)(a3 - 8) + 80);
  uint64_t v5 = *a2;
  *(void *)a1 = *a2;
  if ((v4 & 0x20000) != 0)
  {
    a1 = &v5[(v4 + 16) & ~v4];
    swift_retain();
    return a1;
  }
  *(_OWORD *)(a1 + 8) = *(_OWORD *)(a2 + 1);
  uint64_t v7 = a2[6];
  v5;
  if (v7)
  {
    *((void *)a1 + 6) = v7;
    (**((void (***)(uint64_t, uint64_t, char *))v7 - 1))((uint64_t)(a1 + 24), (uint64_t)(a2 + 3), v7);
  }
  else
  {
    long long v8 = *(_OWORD *)(a2 + 3);
    *(_OWORD *)(a1 + 40) = *(_OWORD *)(a2 + 5);
    *(_OWORD *)(a1 + 24) = v8;
  }
  uint64_t v9 = a1 + 56;
  unint64_t v10 = (long long *)(a2 + 7);
  uint64_t v11 = a2[10];
  if (v11)
  {
    *((void *)a1 + 10) = v11;
    (**((void (***)(_OWORD *, long long *))v11 - 1))(v9, v10);
  }
  else
  {
    long long v12 = *v10;
    *(_OWORD *)(a1 + 72) = *(_OWORD *)(a2 + 9);
    *uint64_t v9 = v12;
  }
  uint64_t v13 = *(int *)(a3 + 24);
  uint64_t v14 = &a1[v13];
  Swift::String v15 = (char **)((char *)a2 + v13);
  uint64_t v16 = type metadata accessor for MLClassifierMetrics.Contents(0);
  unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v15, v16);
  unsigned int v67 = EnumCaseMultiPayload;
  if (EnumCaseMultiPayload == 2)
  {
    uint64_t v26 = *v15;
    swift_errorRetain(v26);
    *(void *)uint64_t v14 = v26;
    Swift::String v23 = v14;
LABEL_16:
    uint64_t v25 = a3;
    goto LABEL_17;
  }
  if (EnumCaseMultiPayload != 1)
  {
    uint64_t v65 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v27 = swift_getEnumCaseMultiPayload(v15, v65);
    BOOL v70 = v27 == 1;
    uint64_t v28 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v27 == 1) {
      uint64_t v28 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v29 = __swift_instantiateConcreteTypeFromMangledName(v28);
    uint64_t v30 = v15;
    Swift::String v23 = v14;
    (*(void (**)(char *, void *, uint64_t))(*(void *)(v29 - 8) + 16))(v14, v30, v29);
    swift_storeEnumTagMultiPayload(v14, v65, v70);
    goto LABEL_16;
  }
  *(void *)uint64_t v14 = *v15;
  char v58 = v14;
  uint64_t v61 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
  uint64_t v69 = v16;
  uint64_t v18 = *(int *)(v61 + 20);
  uint64_t v57 = &v14[v18];
  uint64_t v19 = type metadata accessor for DataFrame(0);
  uint64_t v64 = *(void (**)(char *, char *, uint64_t))(*(void *)(v19 - 8) + 16);
  Swift::String v20 = (char *)v15 + v18;
  uint64_t v16 = v69;
  v64(v57, v20, v19);
  uint64_t v21 = *(int *)(v61 + 24);
  uint64_t v22 = (char *)v15 + v21;
  Swift::String v23 = v58;
  uint64_t v24 = v19;
  uint64_t v25 = a3;
  v64(&v58[v21], v22, v24);
LABEL_17:
  swift_storeEnumTagMultiPayload(v23, v16, v67);
  uint64_t v31 = *(int *)(v25 + 28);
  uint64_t v68 = &a1[v31];
  uint64_t v32 = (char **)((char *)a2 + v31);
  unsigned int v33 = swift_getEnumCaseMultiPayload(v32, v16);
  unsigned int v66 = v33;
  if (v33 == 2)
  {
    uint64_t v42 = *v32;
    swift_errorRetain(v42);
    *(void *)uint64_t v68 = v42;
    uint64_t v40 = v68;
  }
  else if (v33 == 1)
  {
    *(void *)uint64_t v68 = *v32;
    uint64_t v62 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v34 = *(int *)(v62 + 20);
    uint64_t v59 = &v68[v34];
    uint64_t v71 = v16;
    uint64_t v35 = type metadata accessor for DataFrame(0);
    uint64_t v36 = (char *)v32 + v34;
    uint64_t v37 = *(void (**)(char *, char *, uint64_t))(*(void *)(v35 - 8) + 16);
    v37(v59, v36, v35);
    uint64_t v38 = *(int *)(v62 + 24);
    uint64_t v39 = (char *)v32 + v38;
    uint64_t v40 = v68;
    uint64_t v41 = v35;
    uint64_t v16 = v71;
    v37(&v68[v38], v39, v41);
    uint64_t v25 = a3;
  }
  else
  {
    uint64_t v72 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v43 = swift_getEnumCaseMultiPayload(v32, v72);
    BOOL v63 = v43 == 1;
    char v44 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v43 == 1) {
      char v44 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(v44);
    char v46 = v32;
    uint64_t v40 = v68;
    (*(void (**)(char *, void *, uint64_t))(*(void *)(v45 - 8) + 16))(v68, v46, v45);
    swift_storeEnumTagMultiPayload(v68, v72, v63);
  }
  swift_storeEnumTagMultiPayload(v40, v16, v66);
  uint64_t v47 = *(int *)(v25 + 32);
  uint64_t v48 = &a1[v47];
  uint64_t v49 = (uint64_t)a2 + v47;
  uint64_t v50 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  if (swift_getEnumCaseMultiPayload(v49, v50) == 1)
  {
    uint64_t v51 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
    (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v51 - 8) + 16))(v48, v49, v51);
    uint64_t v52 = 1;
    uint64_t v53 = v48;
    uint64_t v54 = v50;
  }
  else
  {
    uint64_t v55 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
    (*(void (**)(char *, uint64_t, uint64_t))(*(void *)(v55 - 8) + 16))(v48, v49, v55);
    uint64_t v53 = v48;
    uint64_t v54 = v50;
    uint64_t v52 = 0;
  }
  swift_storeEnumTagMultiPayload(v53, v54, v52);
  return a1;
}

uint64_t destroy for MLImageClassifier(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = a2;

  if (*(void *)(a1 + 48)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 24));
  }
  if (*(void *)(a1 + 80)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 56));
  }
  int v4 = (char *)(a1 + *(int *)(a2 + 24));
  uint64_t v5 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v4, v5);
  switch(EnumCaseMultiPayload)
  {
    case 2:
      swift_errorRelease(*(void *)v4);
      break;
    case 1:
      uint64_t v29 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v9 = &v4[*(int *)(v29 + 20)];
      uint64_t v10 = type metadata accessor for DataFrame(0);
      uint64_t v27 = v5;
      uint64_t v11 = *(void (**)(char *, uint64_t))(*(void *)(v10 - 8) + 8);
      long long v12 = v9;
      uint64_t v2 = a2;
      v11(v12, v10);
      v11(&v4[*(int *)(v29 + 24)], v10);
      uint64_t v5 = v27;
      break;
    case 0:
      uint64_t v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload(v4, v7) == 1) {
        long long v8 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        long long v8 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(v8);
      (*(void (**)(char *, uint64_t))(*(void *)(v13 - 8) + 8))(v4, v13);
      break;
  }
  uint64_t v14 = (char *)(a1 + *(int *)(v2 + 28));
  int v15 = swift_getEnumCaseMultiPayload(v14, v5);
  switch(v15)
  {
    case 2:
      swift_errorRelease(*(void *)v14);
      break;
    case 1:
      uint64_t v30 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v18 = &v14[*(int *)(v30 + 20)];
      uint64_t v19 = type metadata accessor for DataFrame(0);
      uint64_t v28 = v2;
      Swift::String v20 = *(void (**)(char *, uint64_t))(*(void *)(v19 - 8) + 8);
      v20(v18, v19);
      v20(&v14[*(int *)(v30 + 24)], v19);
      uint64_t v2 = v28;
      break;
    case 0:
      uint64_t v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      if (swift_getEnumCaseMultiPayload(v14, v16) == 1) {
        char v17 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      else {
        char v17 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      }
      uint64_t v21 = __swift_instantiateConcreteTypeFromMangledName(v17);
      (*(void (**)(char *, uint64_t))(*(void *)(v21 - 8) + 8))(v14, v21);
      break;
  }
  uint64_t v22 = *(int *)(v2 + 32) + a1;
  uint64_t v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  uint64_t v24 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (swift_getEnumCaseMultiPayload(v22, v23) == 1) {
    uint64_t v24 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v25 = __swift_instantiateConcreteTypeFromMangledName(v24);
  return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v25 - 8) + 8))(v22, v25);
}

uint64_t initializeWithCopy for MLImageClassifier(uint64_t a1, uint64_t a2, int *a3)
{
  uint64_t v5 = *(void **)a2;
  *(void *)a1 = *(void *)a2;
  *(_OWORD *)(a1 + 8) = *(_OWORD *)(a2 + 8);
  uint64_t v6 = *(void *)(a2 + 48);
  v5;
  if (v6)
  {
    *(void *)(a1 + 48) = v6;
    (**(void (***)(uint64_t, uint64_t, uint64_t))(v6 - 8))(a1 + 24, a2 + 24, v6);
  }
  else
  {
    long long v7 = *(_OWORD *)(a2 + 24);
    *(_OWORD *)(a1 + 40) = *(_OWORD *)(a2 + 40);
    *(_OWORD *)(a1 + 24) = v7;
  }
  long long v8 = (_OWORD *)(a1 + 56);
  uint64_t v9 = (long long *)(a2 + 56);
  uint64_t v10 = *(void *)(a2 + 80);
  if (v10)
  {
    *(void *)(a1 + 80) = v10;
    (**(void (***)(_OWORD *, long long *))(v10 - 8))(v8, v9);
  }
  else
  {
    long long v11 = *v9;
    *(_OWORD *)(a1 + 72) = *(_OWORD *)(a2 + 72);
    _OWORD *v8 = v11;
  }
  uint64_t v12 = a3[6];
  uint64_t v13 = (char *)(a1 + v12);
  uint64_t v14 = (char *)(a2 + v12);
  uint64_t v49 = type metadata accessor for MLClassifierMetrics.Contents(0);
  unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v14, v49);
  uint64_t v51 = a1;
  if (EnumCaseMultiPayload == 2)
  {
    uint64_t v21 = *(void *)v14;
    swift_errorRetain(*(void *)v14);
    *(void *)uint64_t v13 = v21;
    a1 = v51;
  }
  else if (EnumCaseMultiPayload == 1)
  {
    *(void *)uint64_t v13 = *(void *)v14;
    uint64_t v52 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v16 = *(int *)(v52 + 20);
    uint64_t v48 = &v13[v16];
    uint64_t v17 = type metadata accessor for DataFrame(0);
    uint64_t v56 = v13;
    uint64_t v18 = *(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 16);
    uint64_t v19 = &v14[v16];
    unsigned int EnumCaseMultiPayload = 1;
    v18(v48, v19, v17);
    uint64_t v20 = v17;
    a1 = v51;
    v18(&v56[*(int *)(v52 + 24)], &v14[*(int *)(v52 + 24)], v20);
    uint64_t v13 = v56;
  }
  else
  {
    uint64_t v57 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v22 = swift_getEnumCaseMultiPayload(v14, v57);
    BOOL v54 = v22 == 1;
    uint64_t v23 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v22 == 1) {
      uint64_t v23 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(v23);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v24 - 8) + 16))(v13, v14, v24);
    swift_storeEnumTagMultiPayload(v13, v57, v54);
  }
  swift_storeEnumTagMultiPayload(v13, v49, EnumCaseMultiPayload);
  uint64_t v25 = a3[7];
  uint64_t v26 = (char *)(a1 + v25);
  uint64_t v27 = (char *)(a2 + v25);
  unsigned int v28 = swift_getEnumCaseMultiPayload(v27, v49);
  if (v28 == 2)
  {
    uint64_t v34 = *(void *)v27;
    swift_errorRetain(*(void *)v27);
    *(void *)uint64_t v26 = v34;
  }
  else if (v28 == 1)
  {
    *(void *)uint64_t v26 = *(void *)v27;
    uint64_t v55 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v29 = *(int *)(v55 + 20);
    uint64_t v53 = &v26[v29];
    uint64_t v30 = type metadata accessor for DataFrame(0);
    uint64_t v31 = &v27[v29];
    uint64_t v32 = *(void (**)(char *, char *, uint64_t))(*(void *)(v30 - 8) + 16);
    v32(v53, v31, v30);
    uint64_t v33 = v30;
    unsigned int v28 = 1;
    v32(&v26[*(int *)(v55 + 24)], &v27[*(int *)(v55 + 24)], v33);
  }
  else
  {
    uint64_t v58 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v35 = swift_getEnumCaseMultiPayload(v27, v58);
    BOOL v36 = v35 == 1;
    uint64_t v37 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v35 == 1) {
      uint64_t v37 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v38 = __swift_instantiateConcreteTypeFromMangledName(v37);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v38 - 8) + 16))(v26, v27, v38);
    swift_storeEnumTagMultiPayload(v26, v58, v36);
  }
  swift_storeEnumTagMultiPayload(v26, v49, v28);
  uint64_t v39 = a3[8];
  uint64_t v40 = v39 + v51;
  uint64_t v41 = v39 + a2;
  uint64_t v42 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int v43 = swift_getEnumCaseMultiPayload(v41, v42);
  BOOL v44 = v43 == 1;
  uint64_t v45 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (v43 == 1) {
    uint64_t v45 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v46 = __swift_instantiateConcreteTypeFromMangledName(v45);
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v46 - 8) + 16))(v40, v41, v46);
  swift_storeEnumTagMultiPayload(v40, v42, v44);
  return v51;
}

uint64_t assignWithCopy for MLImageClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = *(void **)a2;
  long long v7 = *(void **)a1;
  *(void *)a1 = *(void *)a2;
  v6;

  *(void *)(a1 + 8) = *(void *)(a2 + 8);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  uint64_t v8 = *(void *)(a2 + 48);
  if (*(void *)(a1 + 48))
  {
    if (v8)
    {
      __swift_assign_boxed_opaque_existential_0((uint64_t *)(a1 + 24), (uint64_t *)(a2 + 24));
      goto LABEL_8;
    }
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 24));
  }
  else if (v8)
  {
    *(void *)(a1 + 48) = v8;
    (**(void (***)(uint64_t, uint64_t))(v8 - 8))(a1 + 24, a2 + 24);
    goto LABEL_8;
  }
  long long v9 = *(_OWORD *)(a2 + 24);
  *(_OWORD *)(a1 + 40) = *(_OWORD *)(a2 + 40);
  *(_OWORD *)(a1 + 24) = v9;
LABEL_8:
  uint64_t v10 = *(void *)(a2 + 80);
  if (*(void *)(a1 + 80))
  {
    if (v10)
    {
      __swift_assign_boxed_opaque_existential_0((uint64_t *)(a1 + 56), (uint64_t *)(a2 + 56));
      goto LABEL_15;
    }
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 56));
  }
  else if (v10)
  {
    *(void *)(a1 + 80) = v10;
    (**(void (***)(uint64_t, uint64_t))(v10 - 8))(a1 + 56, a2 + 56);
    goto LABEL_15;
  }
  long long v11 = *(_OWORD *)(a2 + 56);
  *(_OWORD *)(a1 + 72) = *(_OWORD *)(a2 + 72);
  *(_OWORD *)(a1 + 56) = v11;
LABEL_15:
  if (a1 != a2)
  {
    uint64_t v44 = a3;
    uint64_t v12 = *(int *)(a3 + 24);
    uint64_t v13 = (char *)(a1 + v12);
    uint64_t v14 = (char *)(a2 + v12);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v13, type metadata accessor for MLClassifierMetrics.Contents);
    uint64_t v15 = type metadata accessor for MLClassifierMetrics.Contents(0);
    unsigned int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v14, v15);
    uint64_t v49 = v15;
    if (EnumCaseMultiPayload == 2)
    {
      uint64_t v19 = *(void *)v14;
      swift_errorRetain(*(void *)v14);
      uint64_t v20 = 2;
      *(void *)uint64_t v13 = v19;
      uint64_t v15 = v49;
    }
    else
    {
      unsigned int v58 = EnumCaseMultiPayload;
      if (EnumCaseMultiPayload == 1)
      {
        *(void *)uint64_t v13 = *(void *)v14;
        uint64_t v50 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
        uint64_t v17 = *(int *)(v50 + 20);
        uint64_t v45 = &v13[v17];
        uint64_t v47 = type metadata accessor for DataFrame(0);
        BOOL v54 = *(void (**)(char *, char *, uint64_t))(*(void *)(v47 - 8) + 16);
        uint64_t v18 = &v14[v17];
        uint64_t v15 = v49;
        v54(v45, v18, v47);
        v54(&v13[*(int *)(v50 + 24)], &v14[*(int *)(v50 + 24)], v47);
      }
      else
      {
        uint64_t v55 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
        int v21 = swift_getEnumCaseMultiPayload(v14, v55);
        BOOL v51 = v21 == 1;
        int v22 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
        if (v21 == 1) {
          int v22 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
        }
        uint64_t v23 = __swift_instantiateConcreteTypeFromMangledName(v22);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v23 - 8) + 16))(v13, v14, v23);
        swift_storeEnumTagMultiPayload(v13, v55, v51);
      }
      uint64_t v20 = v58;
    }
    swift_storeEnumTagMultiPayload(v13, v15, v20);
    uint64_t v24 = *(int *)(v44 + 28);
    uint64_t v25 = (char *)(a1 + v24);
    uint64_t v26 = (char *)(a2 + v24);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v25, type metadata accessor for MLClassifierMetrics.Contents);
    unsigned int v27 = swift_getEnumCaseMultiPayload(v26, v15);
    if (v27 == 2)
    {
      uint64_t v30 = *(void *)v26;
      swift_errorRetain(*(void *)v26);
      uint64_t v31 = 2;
      *(void *)uint64_t v25 = v30;
      uint64_t v15 = v49;
    }
    else
    {
      unsigned int v59 = v27;
      if (v27 == 1)
      {
        *(void *)uint64_t v25 = *(void *)v26;
        uint64_t v52 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
        uint64_t v28 = *(int *)(v52 + 20);
        uint64_t v46 = &v25[v28];
        uint64_t v48 = type metadata accessor for DataFrame(0);
        uint64_t v56 = *(void (**)(char *, char *, uint64_t))(*(void *)(v48 - 8) + 16);
        uint64_t v29 = &v26[v28];
        uint64_t v15 = v49;
        v56(v46, v29, v48);
        v56(&v25[*(int *)(v52 + 24)], &v26[*(int *)(v52 + 24)], v48);
      }
      else
      {
        uint64_t v57 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
        int v32 = swift_getEnumCaseMultiPayload(v26, v57);
        BOOL v53 = v32 == 1;
        uint64_t v33 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
        if (v32 == 1) {
          uint64_t v33 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
        }
        uint64_t v34 = __swift_instantiateConcreteTypeFromMangledName(v33);
        (*(void (**)(char *, char *, uint64_t))(*(void *)(v34 - 8) + 16))(v25, v26, v34);
        swift_storeEnumTagMultiPayload(v25, v57, v53);
      }
      uint64_t v31 = v59;
    }
    swift_storeEnumTagMultiPayload(v25, v15, v31);
    uint64_t v35 = *(int *)(v44 + 32);
    uint64_t v36 = a1 + v35;
    uint64_t v37 = v35 + a2;
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1 + v35, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    uint64_t v38 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
    int v39 = swift_getEnumCaseMultiPayload(v37, v38);
    BOOL v40 = v39 == 1;
    uint64_t v41 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
    if (v39 == 1) {
      uint64_t v41 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
    }
    uint64_t v42 = __swift_instantiateConcreteTypeFromMangledName(v41);
    (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v42 - 8) + 16))(v36, v37, v42);
    swift_storeEnumTagMultiPayload(v36, v38, v40);
  }
  return a1;
}

void __swift_assign_boxed_opaque_existential_0(uint64_t *a1, uint64_t *a2)
{
  if (a1 != a2)
  {
    uint64_t v3 = a1[3];
    uint64_t v4 = a2[3];
    if (v3 == v4)
    {
      uint64_t v8 = *(void *)(v3 - 8);
      if ((*(unsigned char *)(v8 + 82) & 2) != 0)
      {
        uint64_t v10 = *a1;
        uint64_t v11 = *a2;
        swift_retain(*a2);
        swift_release(v10);
        *a1 = v11;
      }
      else
      {
        (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v8 + 24))(a1, a2, a1[3]);
      }
    }
    else
    {
      a1[3] = v4;
      uint64_t v5 = *(void *)(v3 - 8);
      uint64_t v6 = *(void *)(v4 - 8);
      int v7 = *(_DWORD *)(v6 + 80);
      if ((*(unsigned char *)(v5 + 82) & 2) != 0)
      {
        uint64_t v9 = *a1;
        if ((v7 & 0x20000) != 0)
        {
          uint64_t v13 = *a2;
          *a1 = *a2;
          swift_retain(v13);
        }
        else
        {
          (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v6 + 16))(a1, a2, v4);
        }
        swift_release(v9);
      }
      else
      {
        uint64_t v16 = *(void *)(v4 - 8);
        uint64_t v15 = v5;
        (*(void (**)(unsigned char *, uint64_t *, uint64_t))(v5 + 32))(v14, a1, v3);
        if ((v7 & 0x20000) != 0)
        {
          uint64_t v12 = *a2;
          *a1 = *a2;
          swift_retain(v12);
        }
        else
        {
          (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v16 + 16))(a1, a2, v4);
        }
        (*(void (**)(unsigned char *, uint64_t))(v15 + 8))(v14, v3);
      }
    }
  }
}

void *initializeWithTake for MLImageClassifier(void *a1, void *a2, int *a3)
{
  *a1 = *a2;
  qmemcpy(a1 + 1, a2 + 1, 0x50uLL);
  uint64_t v4 = a3[6];
  uint64_t v5 = (char *)a1 + v4;
  uint64_t v6 = (char *)a2 + v4;
  uint64_t v7 = type metadata accessor for MLClassifierMetrics.Contents(0);
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v6, v7);
  uint64_t v50 = v7;
  if (EnumCaseMultiPayload == 1)
  {
    *(void *)uint64_t v5 = *(void *)v6;
    uint64_t v52 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v17 = *(int *)(v52 + 20);
    uint64_t v48 = &v5[v17];
    uint64_t v18 = type metadata accessor for DataFrame(0);
    uint64_t v45 = v5;
    uint64_t v19 = *(void (**)(char *, char *, uint64_t))(*(void *)(v18 - 8) + 32);
    v19(v48, &v6[v17], v18);
    uint64_t v20 = v18;
    uint64_t v7 = v50;
    v19(&v45[*(int *)(v52 + 24)], &v6[*(int *)(v52 + 24)], v20);
    uint64_t v16 = 1;
    uint64_t v14 = v45;
    uint64_t v15 = v50;
LABEL_7:
    swift_storeEnumTagMultiPayload(v14, v15, v16);
    goto LABEL_9;
  }
  if (!EnumCaseMultiPayload)
  {
    uint64_t v51 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v9 = swift_getEnumCaseMultiPayload(v6, v51);
    BOOL v10 = v9 == 1;
    uint64_t v11 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v9 == 1) {
      uint64_t v11 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v12 = __swift_instantiateConcreteTypeFromMangledName(v11);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v12 - 8) + 32))(v5, v6, v12);
    BOOL v13 = v10;
    uint64_t v7 = v50;
    swift_storeEnumTagMultiPayload(v5, v51, v13);
    uint64_t v14 = v5;
    uint64_t v15 = v50;
    uint64_t v16 = 0;
    goto LABEL_7;
  }
  memcpy(v5, v6, *(void *)(*(void *)(v7 - 8) + 64));
LABEL_9:
  uint64_t v21 = a3[7];
  int v22 = (char *)a1 + v21;
  uint64_t v23 = (char *)a2 + v21;
  int v24 = swift_getEnumCaseMultiPayload(v23, v7);
  if (v24 == 1)
  {
    *(void *)int v22 = *(void *)v23;
    uint64_t v54 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
    uint64_t v32 = *(int *)(v54 + 20);
    uint64_t v49 = &v22[v32];
    uint64_t v33 = type metadata accessor for DataFrame(0);
    uint64_t v34 = &v23[v32];
    uint64_t v35 = *(void (**)(char *, char *, uint64_t))(*(void *)(v33 - 8) + 32);
    v35(v49, v34, v33);
    v35(&v22[*(int *)(v54 + 24)], &v23[*(int *)(v54 + 24)], v33);
    uint64_t v31 = 1;
    uint64_t v29 = v22;
    uint64_t v30 = v50;
LABEL_15:
    swift_storeEnumTagMultiPayload(v29, v30, v31);
    goto LABEL_17;
  }
  if (!v24)
  {
    uint64_t v53 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
    int v25 = swift_getEnumCaseMultiPayload(v23, v53);
    BOOL v26 = v25 == 1;
    unsigned int v27 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
    if (v25 == 1) {
      unsigned int v27 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
    }
    uint64_t v28 = __swift_instantiateConcreteTypeFromMangledName(v27);
    (*(void (**)(char *, char *, uint64_t))(*(void *)(v28 - 8) + 32))(v22, v23, v28);
    swift_storeEnumTagMultiPayload(v22, v53, v26);
    uint64_t v29 = v22;
    uint64_t v30 = v50;
    uint64_t v31 = 0;
    goto LABEL_15;
  }
  memcpy(v22, v23, *(void *)(*(void *)(v7 - 8) + 64));
LABEL_17:
  uint64_t v36 = a3[8];
  uint64_t v37 = (char *)a1 + v36;
  uint64_t v38 = (char *)a2 + v36;
  uint64_t v39 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
  int v40 = swift_getEnumCaseMultiPayload(v38, v39);
  BOOL v41 = v40 == 1;
  uint64_t v42 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
  if (v40 == 1) {
    uint64_t v42 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
  }
  uint64_t v43 = __swift_instantiateConcreteTypeFromMangledName(v42);
  (*(void (**)(char *, char *, uint64_t))(*(void *)(v43 - 8) + 32))(v37, v38, v43);
  swift_storeEnumTagMultiPayload(v37, v39, v41);
  return a1;
}

uint64_t assignWithTake for MLImageClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v6 = *(void **)a1;
  *(void *)a1 = *(void *)a2;

  *(_OWORD *)(a1 + 8) = *(_OWORD *)(a2 + 8);
  if (*(void *)(a1 + 48)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 24));
  }
  long long v7 = *(_OWORD *)(a2 + 24);
  *(_OWORD *)(a1 + 40) = *(_OWORD *)(a2 + 40);
  *(_OWORD *)(a1 + 24) = v7;
  if (*(void *)(a1 + 80)) {
    __swift_destroy_boxed_opaque_existential_1Tm((void *)(a1 + 56));
  }
  long long v8 = *(_OWORD *)(a2 + 56);
  *(_OWORD *)(a1 + 72) = *(_OWORD *)(a2 + 72);
  *(_OWORD *)(a1 + 56) = v8;
  if (a1 != a2)
  {
    uint64_t v48 = a3;
    uint64_t v9 = *(int *)(a3 + 24);
    BOOL v10 = (char *)(a1 + v9);
    uint64_t v11 = (char *)(a2 + v9);
    outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v10, type metadata accessor for MLClassifierMetrics.Contents);
    uint64_t v12 = type metadata accessor for MLClassifierMetrics.Contents(0);
    int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v11, v12);
    uint64_t v53 = v12;
    if (EnumCaseMultiPayload == 1)
    {
      *(void *)BOOL v10 = *(void *)v11;
      uint64_t v49 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
      uint64_t v22 = *(int *)(v49 + 20);
      uint64_t v51 = &v10[v22];
      uint64_t v47 = type metadata accessor for DataFrame(0);
      uint64_t v55 = *(void (**)(char *, char *, uint64_t))(*(void *)(v47 - 8) + 32);
      uint64_t v23 = &v11[v22];
      uint64_t v12 = v53;
      v55(v51, v23, v47);
      v55(&v10[*(int *)(v49 + 24)], &v11[*(int *)(v49 + 24)], v47);
      uint64_t v21 = 1;
      uint64_t v19 = v10;
      uint64_t v20 = v53;
    }
    else
    {
      if (EnumCaseMultiPayload)
      {
        memcpy(v10, v11, *(void *)(*(void *)(v12 - 8) + 64));
LABEL_14:
        uint64_t v24 = *(int *)(v48 + 28);
        int v25 = (char *)(a1 + v24);
        BOOL v26 = (char *)(a2 + v24);
        outlined destroy of MLActivityClassifier.ModelParameters((uint64_t)v25, type metadata accessor for MLClassifierMetrics.Contents);
        int v27 = swift_getEnumCaseMultiPayload(v26, v12);
        if (v27 == 1)
        {
          *(void *)int v25 = *(void *)v26;
          uint64_t v57 = type metadata accessor for MLClassifierMetrics.Precomputed(0);
          uint64_t v35 = *(int *)(v57 + 20);
          uint64_t v50 = &v25[v35];
          uint64_t v52 = type metadata accessor for DataFrame(0);
          uint64_t v36 = &v26[v35];
          uint64_t v37 = *(void (**)(char *, char *, uint64_t))(*(void *)(v52 - 8) + 32);
          v37(v50, v36, v52);
          v37(&v25[*(int *)(v57 + 24)], &v26[*(int *)(v57 + 24)], v52);
          uint64_t v34 = 1;
          uint64_t v32 = v25;
          uint64_t v33 = v53;
        }
        else
        {
          if (v27)
          {
            memcpy(v25, v26, *(void *)(*(void *)(v12 - 8) + 64));
            goto LABEL_22;
          }
          uint64_t v56 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
          int v28 = swift_getEnumCaseMultiPayload(v26, v56);
          BOOL v29 = v28 == 1;
          uint64_t v30 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
          if (v28 == 1) {
            uint64_t v30 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
          }
          uint64_t v31 = __swift_instantiateConcreteTypeFromMangledName(v30);
          (*(void (**)(char *, char *, uint64_t))(*(void *)(v31 - 8) + 32))(v25, v26, v31);
          swift_storeEnumTagMultiPayload(v25, v56, v29);
          uint64_t v32 = v25;
          uint64_t v33 = v53;
          uint64_t v34 = 0;
        }
        swift_storeEnumTagMultiPayload(v32, v33, v34);
LABEL_22:
        uint64_t v38 = *(int *)(v48 + 32);
        uint64_t v39 = a1 + v38;
        uint64_t v40 = v38 + a2;
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1 + v38, &demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
        uint64_t v41 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>);
        int v42 = swift_getEnumCaseMultiPayload(v40, v41);
        BOOL v43 = v42 == 1;
        uint64_t v44 = &demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>;
        if (v42 == 1) {
          uint64_t v44 = &demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>;
        }
        uint64_t v45 = __swift_instantiateConcreteTypeFromMangledName(v44);
        (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v45 - 8) + 32))(v39, v40, v45);
        swift_storeEnumTagMultiPayload(v39, v41, v43);
        return a1;
      }
      uint64_t v54 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<ClassificationMetrics<String>, ClassificationMetrics<Int>>);
      int v14 = swift_getEnumCaseMultiPayload(v11, v54);
      BOOL v15 = v14 == 1;
      uint64_t v16 = &demangling cache variable for type metadata for ClassificationMetrics<String>;
      if (v14 == 1) {
        uint64_t v16 = &demangling cache variable for type metadata for ClassificationMetrics<Int>;
      }
      uint64_t v17 = __swift_instantiateConcreteTypeFromMangledName(v16);
      (*(void (**)(char *, char *, uint64_t))(*(void *)(v17 - 8) + 32))(v10, v11, v17);
      BOOL v18 = v15;
      uint64_t v12 = v53;
      swift_storeEnumTagMultiPayload(v10, v54, v18);
      uint64_t v19 = v10;
      uint64_t v20 = v53;
      uint64_t v21 = 0;
    }
    swift_storeEnumTagMultiPayload(v19, v20, v21);
    goto LABEL_14;
  }
  return a1;
}

uint64_t getEnumTagSinglePayload for MLImageClassifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  return swift_getEnumTagSinglePayloadGeneric(a1, a2, a3, sub_146EAC);
}

uint64_t sub_146EAC(void *a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    uint64_t result = 0;
    if ((*a1 & 0xFFFFFFFF00000001) == 0) {
      return (*a1 >> 1) + 1;
    }
  }
  else
  {
    uint64_t v5 = type metadata accessor for MLClassifierMetrics(0);
    if (*(_DWORD *)(*(void *)(v5 - 8) + 84) == a2)
    {
      uint64_t v6 = *(int *)(a3 + 24);
    }
    else
    {
      uint64_t v5 = type metadata accessor for MLImageClassifier.Model(0);
      uint64_t v6 = *(int *)(a3 + 32);
    }
    return __swift_getEnumTagSinglePayload((uint64_t)a1 + v6, a2, v5);
  }
  return result;
}

uint64_t storeEnumTagSinglePayload for MLImageClassifier(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  return swift_storeEnumTagSinglePayloadGeneric(a1, a2, a3, a4, sub_146F49);
}

void sub_146F49(void *a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 0x7FFFFFFF)
  {
    *a1 = 2 * (a2 - 1);
  }
  else
  {
    uint64_t v6 = type metadata accessor for MLClassifierMetrics(0);
    if (*(_DWORD *)(*(void *)(v6 - 8) + 84) == a3)
    {
      uint64_t v7 = *(int *)(a4 + 24);
    }
    else
    {
      uint64_t v6 = type metadata accessor for MLImageClassifier.Model(0);
      uint64_t v7 = *(int *)(a4 + 32);
    }
    __swift_storeEnumTagSinglePayload((uint64_t)a1 + v7, a2, a2, v6);
  }
}

uint64_t type metadata completion function for MLImageClassifier(uint64_t a1)
{
  v4[0] = (char *)&value witness table for Builtin.UnknownObject + 64;
  v4[1] = "P";
  uint64_t result = type metadata accessor for MLClassifierMetrics.Contents(319);
  if (v2 <= 0x3F)
  {
    uint64_t v5 = *(void *)(result - 8) + 64;
    uint64_t v6 = v5;
    uint64_t result = type metadata accessor for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(319);
    if (v3 <= 0x3F)
    {
      uint64_t v7 = *(void *)(result - 8) + 64;
      swift_initStructMetadata(a1, 256, 5, v4, a1 + 16);
      return 0;
    }
  }
  return result;
}

uint64_t type metadata accessor for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>(uint64_t a1)
{
  uint64_t result = lazy cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>;
  if (!lazy cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>>)
  {
    uint64_t v2 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for LogisticRegressionClassifierModel<Float, String>);
    uint64_t v3 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for FullyConnectedNetworkClassifierModel<Float, String>);
    uint64_t result = type metadata accessor for Either(a1, v2, v3, v4);
    if (!v5) {
      lazy cache variable for type metadata for Either<LogisticRegressionClassifierModel<Float, String>, FullyConnectedNetworkClassifierModel<Float, String>> = result;
    }
  }
  return result;
}

uint64_t outlined copy of MLImageClassifier.ModelParameters.ClassifierType?(uint64_t a1)
{
  if (a1 != 2) {
    return swift_bridgeObjectRetain(a1);
  }
  return result;
}

uint64_t sub_1470C6()
{
  uint64_t v1 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  uint64_t v2 = *(void *)(v1 - 8);
  uint64_t v3 = *(unsigned __int8 *)(v2 + 80);
  uint64_t v4 = ~*(unsigned __int8 *)(v2 + 80) & (v3 + 24);
  uint64_t v10 = *(void *)(v2 + 64);
  swift_bridgeObjectRelease(*(void *)(v0 + 16));
  int EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v4 + v0, v1);
  if (EnumCaseMultiPayload == 2) {
    goto LABEL_6;
  }
  if (EnumCaseMultiPayload != 1) {
    return swift_deallocObject(v0, v10 + v4, v3 | 7);
  }
  uint64_t v6 = type metadata accessor for MLImageClassifier.DataSource(0);
  unsigned int v7 = swift_getEnumCaseMultiPayload(v4 + v0, v6);
  if (v7 == 2)
  {
LABEL_6:
    swift_bridgeObjectRelease(*(void *)(v4 + v0));
    return swift_deallocObject(v0, v10 + v4, v3 | 7);
  }
  if (v7 <= 1)
  {
    uint64_t v8 = type metadata accessor for URL(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v8 - 8) + 8))(v4 + v0, v8);
  }
  return swift_deallocObject(v0, v10 + v4, v3 | 7);
}

uint64_t partial apply for closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:)(uint64_t a1)
{
  uint64_t v3 = type metadata accessor for MLImageClassifier.ModelParameters.ValidationData(0);
  uint64_t v4 = *(void *)(v1 + 16);
  uint64_t v5 = v1
     + (~*(unsigned __int8 *)(*(void *)(v3 - 8) + 80) & (*(unsigned __int8 *)(*(void *)(v3 - 8)
                                                                                              + 80)
                                                           + 24));
  uint64_t v6 = (void *)swift_task_alloc(dword_3A9124);
  *(void *)(v2 + 16) = v6;
  void *v6 = v2;
  v6[1] = partial apply for closure #1 in MLActivityClassifier.init(trainingData:featureColumns:labelColumn:recordingFileColumn:parameters:);
  return closure #1 in MLImageClassifier.init(trainingData:parameters:classNames:)(a1, v4, v5);
}

uint64_t outlined destroy of MLImageClassifier.FeatureExtractor(uint64_t a1)
{
  return a1;
}

uint64_t sub_14725B()
{
  return key path getter for AnnotatedFeature.annotation : AnnotatedFeature<CIImage, String>();
}

uint64_t sub_147265(uint64_t *a1)
{
  return key path setter for AnnotatedFeature.annotation : AnnotatedFeature<CIImage, String>(a1);
}

void *sub_14726F()
{
  return key path getter for AnnotatedFeature.feature : AnnotatedFeature<CIImage, String>();
}

uint64_t sub_147279(id *a1)
{
  return key path setter for AnnotatedFeature.feature : AnnotatedFeature<CIImage, String>(a1);
}

uint64_t MLActionClassifier.VideoAugmentationOptions.rawValue.getter()
{
  return *(void *)v0;
}

void *MLActionClassifier.VideoAugmentationOptions.init(rawValue:)(uint64_t a1)
{
  *uint64_t result = a1;
  return result;
}

void *static MLActionClassifier.VideoAugmentationOptions.horizontalFlip.getter()
{
  *uint64_t result = 1;
  return result;
}

uint64_t base witness table accessor for RawRepresentable in MLActionClassifier.VideoAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions();
}

uint64_t lazy protocol witness table accessor for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions()
{
  uint64_t result = lazy protocol witness table cache variable for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLActionClassifier.VideoAugmentationOptions, &type metadata for MLActionClassifier.VideoAugmentationOptions);
    lazy protocol witness table cache variable for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLActionClassifier.VideoAugmentationOptions, &type metadata for MLActionClassifier.VideoAugmentationOptions);
    lazy protocol witness table cache variable for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLActionClassifier.VideoAugmentationOptions, &type metadata for MLActionClassifier.VideoAugmentationOptions);
    lazy protocol witness table cache variable for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions;
  if (!lazy protocol witness table cache variable for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLActionClassifier.VideoAugmentationOptions, &type metadata for MLActionClassifier.VideoAugmentationOptions);
    lazy protocol witness table cache variable for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions = result;
  }
  return result;
}

uint64_t base witness table accessor for SetAlgebra in MLActionClassifier.VideoAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions();
}

void *protocol witness for OptionSet.init(rawValue:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
  return MLActionClassifier.VideoAugmentationOptions.init(rawValue:)(*a1);
}

uint64_t protocol witness for Decodable.init(from:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = lazy protocol witness table accessor for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions();
  return RawRepresentable<>.init(from:)(a1, a2, a3, v3);
}

uint64_t protocol witness for Encodable.encode(to:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = lazy protocol witness table accessor for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions();
  return RawRepresentable<>.encode(to:)(a1, a2, a3, v4);
}

uint64_t base witness table accessor for Equatable in MLActionClassifier.VideoAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions();
}

uint64_t base witness table accessor for ExpressibleByArrayLiteral in MLActionClassifier.VideoAugmentationOptions()
{
  return lazy protocol witness table accessor for type MLActionClassifier.VideoAugmentationOptions and conformance MLActionClassifier.VideoAugmentationOptions();
}

void *protocol witness for SetAlgebra.init() in conformance MLActionClassifier.VideoAugmentationOptions()
{
  return specialized OptionSet<>.init()();
}

BOOL protocol witness for SetAlgebra.contains(_:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet<>.contains(_:)(*a1, *v1);
}

uint64_t *protocol witness for SetAlgebra.union(_:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet.union(_:)(*a1, *v1);
}

uint64_t *protocol witness for SetAlgebra.intersection(_:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet.intersection(_:)(*a1, *v1);
}

uint64_t *protocol witness for SetAlgebra.symmetricDifference(_:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
  return specialized OptionSet.symmetricDifference(_:)(*a1, *v1);
}

BOOL protocol witness for SetAlgebra.insert(_:) in conformance MLActionClassifier.VideoAugmentationOptions(void *a1, uint64_t *a2)
{
  return specialized OptionSet<>.insert(_:)(a1, *a2);
}

void protocol witness for SetAlgebra.formUnion(_:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
}

void protocol witness for SetAlgebra.formIntersection(_:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
}

void protocol witness for SetAlgebra.formSymmetricDifference(_:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
}

uint64_t *protocol witness for SetAlgebra.subtracting(_:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
  return specialized SetAlgebra.subtracting(_:)(*a1, *v1);
}

BOOL protocol witness for SetAlgebra.isSubset(of:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
  return specialized SetAlgebra.isSubset(of:)(*a1, *v1);
}

BOOL protocol witness for SetAlgebra.isDisjoint(with:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
  return specialized SetAlgebra.isDisjoint(with:)(*a1, *v1);
}

void protocol witness for SetAlgebra.subtract(_:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
}

void *protocol witness for RawRepresentable.init(rawValue:) in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t *a1)
{
  uint64_t v2 = v1;
  uint64_t result = MLActionClassifier.VideoAugmentationOptions.init(rawValue:)(*a1);
  *(unsigned char *)(v2 + 8) = 0;
  return result;
}

uint64_t protocol witness for RawRepresentable.rawValue.getter in conformance MLActionClassifier.VideoAugmentationOptions(uint64_t a1)
{
  uint64_t v2 = v1;
  uint64_t result = MLActionClassifier.VideoAugmentationOptions.rawValue.getter(a1);
  *uint64_t v2 = result;
  return result;
}

ValueMetadata *type metadata accessor for MLActionClassifier.VideoAugmentationOptions()
{
  return &type metadata for MLActionClassifier.VideoAugmentationOptions;
}

uint64_t specialized Dictionary.subscript.setter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (*(void *)(a1 + 24))
  {
    outlined init with take of Any((long long *)a1, v5);
    specialized Dictionary._Variant.setValue(_:forKey:)(v5, a2, a3);
  }
  else
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, &demangling cache variable for type metadata for Any?);
    specialized Dictionary._Variant.removeValue(forKey:)(a2, a3);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v5, &demangling cache variable for type metadata for Any?);
  }
  return swift_bridgeObjectRelease(a3);
}

{
  return specialized Dictionary.subscript.setter(a1, a2, a3, &demangling cache variable for type metadata for JSONType?, (uint64_t (*)(void))&type metadata accessor for JSONType, (void (*)(uint64_t *, uint64_t, uint64_t))specialized Dictionary._Variant.setValue(_:forKey:), &demangling cache variable for type metadata for _NativeDictionary<String, JSONType>);
}

{
  return specialized Dictionary.subscript.setter(a1, a2, a3, &demangling cache variable for type metadata for CSVType?, (uint64_t (*)(void))&type metadata accessor for CSVType, (void (*)(uint64_t *, uint64_t, uint64_t))specialized Dictionary._Variant.setValue(_:forKey:), &demangling cache variable for type metadata for _NativeDictionary<String, CSVType>);
}

{
  return specialized Dictionary.subscript.setter(a1, a2, a3, &demangling cache variable for type metadata for MetricsKey?, (uint64_t (*)(void))&type metadata accessor for MetricsKey, (void (*)(uint64_t *, uint64_t, uint64_t))specialized Dictionary._Variant.setValue(_:forKey:), &demangling cache variable for type metadata for _NativeDictionary<String, MetricsKey>);
}

{
  return specialized Dictionary.subscript.setter(a1, a2, a3, &demangling cache variable for type metadata for Tensor?, (uint64_t (*)(void))&type metadata accessor for Tensor, (void (*)(uint64_t *, uint64_t, uint64_t))specialized Dictionary._Variant.setValue(_:forKey:), &demangling cache variable for type metadata for _NativeDictionary<String, Tensor>);
}

{
  return specialized Dictionary.subscript.setter(a1, a2, a3, &demangling cache variable for type metadata for MLProgram.Block?, (uint64_t (*)(void))&type metadata accessor for MLProgram.Block, (void (*)(uint64_t *, uint64_t, uint64_t))specialized Dictionary._Variant.setValue(_:forKey:), &demangling cache variable for type metadata for _NativeDictionary<String, MLProgram.Block>);
}

uint64_t specialized Dictionary.subscript.setter(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t *a4, uint64_t (*a5)(void), void (*a6)(uint64_t *, uint64_t, uint64_t), uint64_t *a7)
{
  uint64_t v23 = a6;
  uint64_t v27 = v7;
  uint64_t v26 = a3;
  uint64_t v28 = a2;
  int64_t v10 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(a4) - 8) + 64);
  uint64_t v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  int v25 = &v22;
  uint64_t v24 = a5;
  uint64_t v13 = a5(0);
  uint64_t v14 = *(void *)(v13 - 8);
  int64_t v15 = *(void *)(v14 + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  if (__swift_getEnumTagSinglePayload(a1, 1, v13) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, a4);
    uint64_t v18 = (uint64_t)v25;
    uint64_t v19 = v26;
    specialized Dictionary._Variant.removeValue(forKey:)(v28, v26, a7, v24);
    swift_bridgeObjectRelease(v19);
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, a4);
  }
  else
  {
    (*(void (**)(uint64_t *, uint64_t, uint64_t))(v14 + 32))(&v22, a1, v13);
    uint64_t v21 = v26;
    v23(&v22, v28, v26);
    return swift_bridgeObjectRelease(v21);
  }
}

uint64_t specialized Dictionary.subscript.setter(uint64_t a1, uint64_t a2)
{
  if (*(void *)(a1 + 24))
  {
    outlined init with take of Any((long long *)a1, v5);
    specialized Dictionary._Variant.setValue(_:forKey:)(v5, a2);
    uint64_t v2 = type metadata accessor for CodingUserInfoKey(0);
    return (*(uint64_t (**)(uint64_t, uint64_t))(*(void *)(v2 - 8) + 8))(a2, v2);
  }
  else
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, &demangling cache variable for type metadata for Any?);
    specialized Dictionary._Variant.removeValue(forKey:)(a2);
    uint64_t v4 = type metadata accessor for CodingUserInfoKey(0);
    (*(void (**)(uint64_t, uint64_t))(*(void *)(v4 - 8) + 8))(a2, v4);
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v5, &demangling cache variable for type metadata for Any?);
  }
}

{
  long long v3[3];

  if (*(void *)(a1 + 24))
  {
    outlined init with take of Any((long long *)a1, v3);
    specialized Dictionary._Variant.setValue(_:forKey:)(v3, a2);
    return outlined destroy of AnyHashable(a2);
  }
  else
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, &demangling cache variable for type metadata for Any?);
    specialized Dictionary._Variant.removeValue(forKey:)(a2);
    outlined destroy of AnyHashable(a2);
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v3, &demangling cache variable for type metadata for Any?);
  }
}

uint64_t specialized Dictionary.subscript.setter(uint64_t a1, char a2)
{
  if (*(void *)(a1 + 24))
  {
    outlined init with take of Any((long long *)a1, v3);
    return specialized Dictionary._Variant.setValue(_:forKey:)(v3, a2);
  }
  else
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(a1, &demangling cache variable for type metadata for Any?);
    specialized Dictionary._Variant.removeValue(forKey:)(a2);
    return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)v3, &demangling cache variable for type metadata for Any?);
  }
}

void *specialized _dictionaryUpCast<A, B, C, D>(_:)(uint64_t a1)
{
  uint64_t v65 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: MetricsKey, value: Sendable));
  int64_t v1 = *(void *)(*(void *)(v65 - 8) + 64);
  uint64_t v2 = alloca(v1);
  uint64_t v3 = alloca(v1);
  unsigned int v66 = &v61;
  uint64_t v67 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MetricsKey, Sendable));
  int64_t v4 = *(void *)(*(void *)(v67 - 8) + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v68 = &v61;
  uint64_t v81 = type metadata accessor for MetricsKey(0);
  uint64_t v69 = *(void *)(v81 - 8);
  int64_t v7 = *(void *)(v69 + 64);
  uint64_t v8 = alloca(v7);
  uint64_t v9 = alloca(v7);
  int64_t v10 = alloca(v7);
  uint64_t v11 = alloca(v7);
  uint64_t v71 = &v61;
  uint64_t v72 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: MetricsKey, value: Double));
  int64_t v12 = *(void *)(*(void *)(v72 - 8) + 64);
  uint64_t v13 = alloca(v12);
  uint64_t v14 = alloca(v12);
  char v73 = &v61;
  int64_t v15 = alloca(v12);
  uint64_t v16 = alloca(v12);
  char v74 = &v61;
  uint64_t v80 = a1;
  uint64_t v17 = *(void *)(a1 + 16);
  if (v17)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _DictionaryStorage<MetricsKey, Sendable>);
    uint64_t v18 = (void *)static _DictionaryStorage.allocate(capacity:)(v17);
  }
  else
  {
    uint64_t v18 = _swiftEmptyDictionarySingleton;
  }
  uint64_t v19 = -1 << *(unsigned char *)(v80 + 32);
  uint64_t v83 = v80 + 64;
  uint64_t v20 = ~(-1 << -(char)v19);
  if (-v19 >= 64) {
    uint64_t v20 = -1;
  }
  unint64_t v21 = *(void *)(v80 + 64) & v20;
  uint64_t v76 = v19;
  int64_t v82 = (unint64_t)(63 - v19) >> 6;
  swift_bridgeObjectRetain(v80);
  swift_retain();
  int64_t v22 = 0;
  BOOL v70 = &v61;
  uint64_t v75 = v18;
  while (1)
  {
    if (v21)
    {
      _BitScanForward64(&v23, v21);
      uint64_t v79 = (v21 - 1) & v21;
      unint64_t v24 = v23 | (v22 << 6);
      int64_t v78 = v22;
      goto LABEL_20;
    }
    int64_t v25 = v22 + 1;
    if (__OFADD__(1, v22)) {
      BUG();
    }
    if (v25 >= v82) {
      break;
    }
    unint64_t i = *(void *)(v83 + 8 * v25);
    if (i)
    {
      int64_t v27 = v22 + 1;
    }
    else
    {
      int64_t v27 = v22 + 2;
      if (v22 + 2 >= v82) {
        break;
      }
      unint64_t i = *(void *)(v83 + 8 * v25 + 8);
      if (!i)
      {
        int64_t v27 = v22 + 3;
        if (v22 + 3 >= v82) {
          break;
        }
        unint64_t i = *(void *)(v83 + 8 * v25 + 16);
        if (!i)
        {
          int64_t v27 = v22 + 4;
          if (v22 + 4 >= v82) {
            break;
          }
          unint64_t i = *(void *)(v83 + 8 * v25 + 24);
          if (!i)
          {
            int64_t v27 = v22 + 5;
            if (v22 + 5 >= v82) {
              break;
            }
            for (unint64_t i = *(void *)(v83 + 8 * v25 + 32); !i; unint64_t i = *(void *)(v83 + 8 * v27))
            {
              if (__OFADD__(1, v27++)) {
                BUG();
              }
              if (v27 >= v82) {
                goto LABEL_38;
              }
            }
          }
        }
      }
    }
    _BitScanForward64(&v28, i);
    uint64_t v79 = i & (i - 1);
    int64_t v78 = v27;
    unint64_t v24 = v28 + (v27 << 6);
LABEL_20:
    uint64_t v29 = v69;
    uint64_t v64 = *(void *)(v69 + 72);
    uint64_t v30 = v80;
    uint64_t v31 = v74;
    (*(void (**)(uint64_t *, unint64_t, uint64_t))(v69 + 16))(v74, *(void *)(v80 + 48) + v24 * v64, v81);
    uint64_t v32 = *(void *)(*(void *)(v30 + 56) + 8 * v24);
    uint64_t v33 = v72;
    *(uint64_t *)((char *)v31 + *(int *)(v72 + 48)) = v32;
    uint64_t v34 = (uint64_t)v31;
    uint64_t v35 = (uint64_t)v73;
    outlined init with take of (key: MetricsKey, value: Double)(v34, (uint64_t)v73);
    uint64_t v36 = *(int *)(v33 + 48);
    uint64_t v37 = v66;
    uint64_t v38 = (long long *)((char *)v66 + *(int *)(v65 + 48));
    uint64_t v77 = *(void (**)(uint64_t *, uint64_t, uint64_t))(v29 + 32);
    v77(v66, v35, v81);
    *(void *)&v63[0] = *(void *)(v35 + v36);
    uint64_t v39 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    swift_dynamicCast(v38, v63, &type metadata for Double, v39, 7);
    uint64_t v40 = v68;
    uint64_t v41 = (long long *)((char *)v68 + *(int *)(v67 + 48));
    int v42 = v37;
    uint64_t v43 = v81;
    uint64_t v44 = (void (*)(uint64_t *, uint64_t *, uint64_t))v77;
    v77(v68, (uint64_t)v42, v81);
    outlined init with take of Any(v38, v41);
    uint64_t v45 = v71;
    v44(v71, v40, v43);
    outlined init with take of Any(v41, v63);
    uint64_t v46 = v70;
    v44(v70, v45, v43);
    outlined init with take of Any(v63, v62);
    uint64_t v18 = v75;
    uint64_t v47 = v75[5];
    uint64_t v48 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, (uint64_t (*)(uint64_t))&type metadata accessor for MetricsKey, (uint64_t)&protocol conformance descriptor for MetricsKey);
    unint64_t v49 = dispatch thunk of Hashable._rawHashValue(seed:)(v47, v81, v48) & ~(-1 << *((unsigned char *)v18 + 32));
    unint64_t v50 = v49 >> 6;
    unint64_t v51 = ~v18[(v49 >> 6) + 8] >> v49 << v49;
    if (v51)
    {
      _BitScanForward64(&v51, v51);
      unint64_t v52 = v51 | v49 & 0xFFFFFFFFFFFFFFC0;
    }
    else
    {
      unint64_t v53 = (unint64_t)(63 - (-1 << *((unsigned char *)v18 + 32))) >> 6;
      char v54 = 0;
      do
      {
        unint64_t v55 = v50 + 1;
        if (v50 + 1 == v53 && (v54 & 1) != 0) {
          BUG();
        }
        unint64_t v50 = 0;
        if (v55 != v53) {
          unint64_t v50 = v55;
        }
        v54 |= v55 == v53;
        uint64_t v56 = v18[v50 + 8];
      }
      while (v56 == -1);
      unint64_t v57 = ~v56;
      uint64_t v58 = 64;
      if (v57) {
        _BitScanForward64((unint64_t *)&v58, v57);
      }
      unint64_t v52 = v58 + (v50 << 6);
    }
    v18[(v52 >> 6) + 8] |= 1 << v52;
    v77((uint64_t *)(v18[6] + v52 * v64), (uint64_t)v46, v81);
    outlined init with take of Any(v62, (_OWORD *)(v18[7] + 32 * v52));
    ++v18[2];
    int64_t v22 = v78;
    unint64_t v21 = v79;
  }
LABEL_38:
  swift_release();
  outlined consume of [String : [Int]].Iterator._Variant(v80);
  return v18;
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  int64_t v6;
  unint64_t v7;
  unint64_t v8;
  int64_t v9;
  unint64_t i;
  int64_t v11;
  unint64_t v12;
  uint64_t v13;
  char v14;
  unint64_t v15;
  char v16;
  unint64_t v17;
  unint64_t v18;
  unint64_t v19;
  unint64_t v20;
  unint64_t v21;
  char v22;
  unint64_t v23;
  uint64_t v24;
  unint64_t v25;
  uint64_t v26;
  char v29[8];
  long long v30[4];
  long long v31[2];
  long long v32[2];
  char *v33;
  char *v34;
  char *v35;
  char *v36;
  char *v37;
  char *v38;
  uint64_t v39;
  int64_t v40;
  uint64_t v41;
  int64_t v42;
  uint64_t v43;

  uint64_t v41 = a1;
  int64_t v1 = *(void *)(a1 + 16);
  if (v1)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _DictionaryStorage<MLProgress.Metric, Any>);
    uint64_t v2 = (void *)static _DictionaryStorage.allocate(capacity:)(v1);
  }
  else
  {
    uint64_t v2 = _swiftEmptyDictionarySingleton;
  }
  uint64_t v3 = -1 << *(unsigned char *)(v41 + 32);
  uint64_t v43 = v41 + 64;
  int64_t v4 = ~(-1 << -(char)v3);
  if (-v3 >= 64) {
    int64_t v4 = -1;
  }
  uint64_t v5 = *(void *)(v41 + 64) & v4;
  uint64_t v39 = v3;
  int v42 = (unint64_t)(63 - v3) >> 6;
  swift_bridgeObjectRetain(v41);
  swift_retain();
  uint64_t v6 = 0;
  uint64_t v33 = (char *)&type metadata for Any + 8;
  uint64_t v34 = "accuracy" + 0x8000000000000000;
  uint64_t v35 = "validationAccuracy" + 0x8000000000000000;
  uint64_t v36 = "stylizedImageURL" + 0x8000000000000000;
  uint64_t v37 = "rror" + 0x8000000000000000;
  uint64_t v38 = "validationRootMeanSquaredError" + 0x8000000000000000;
  while (1)
  {
    if (v5)
    {
      _BitScanForward64(&v7, v5);
      v5 &= v5 - 1;
      uint64_t v8 = v7 | (v6 << 6);
      uint64_t v40 = v6;
      goto LABEL_20;
    }
    uint64_t v9 = v6 + 1;
    if (__OFADD__(1, v6)) {
      BUG();
    }
    if (v9 >= v42) {
      break;
    }
    unint64_t i = *(void *)(v43 + 8 * v9);
    if (i)
    {
      uint64_t v11 = v6 + 1;
    }
    else
    {
      uint64_t v11 = v6 + 2;
      if (v6 + 2 >= v42) {
        break;
      }
      unint64_t i = *(void *)(v43 + 8 * v9 + 8);
      if (!i)
      {
        uint64_t v11 = v6 + 3;
        if (v6 + 3 >= v42) {
          break;
        }
        unint64_t i = *(void *)(v43 + 8 * v9 + 16);
        if (!i)
        {
          uint64_t v11 = v6 + 4;
          if (v6 + 4 >= v42) {
            break;
          }
          unint64_t i = *(void *)(v43 + 8 * v9 + 24);
          if (!i)
          {
            uint64_t v11 = v6 + 5;
            if (v6 + 5 >= v42) {
              break;
            }
            for (unint64_t i = *(void *)(v43 + 8 * v9 + 32); !i; unint64_t i = *(void *)(v43 + 8 * v11))
            {
              if (__OFADD__(1, v11++)) {
                BUG();
              }
              if (v11 >= v42) {
                goto LABEL_50;
              }
            }
          }
        }
      }
    }
    _BitScanForward64(&v12, i);
    uint64_t v5 = i & (i - 1);
    uint64_t v40 = v11;
    uint64_t v8 = v12 + (v11 << 6);
LABEL_20:
    uint64_t v13 = *(void *)(*(void *)(v41 + 56) + 8 * v8);
    LOBYTE(v32[0]) = *(unsigned char *)(*(void *)(v41 + 48) + v8);
    *(void *)&v31[0] = v13;
    swift_dynamicCast((char *)v32 + 8, v31, &type metadata for Double, v33, 7);
    uint64_t v14 = v32[0];
    outlined init with take of Any((long long *)((char *)v32 + 8), v30);
    outlined init with take of Any(v30, v32);
    outlined init with take of Any(v32, v31);
    Hasher.init(_seed:)(v2[5]);
    switch(v14)
    {
      case 0:
        int64_t v15 = 1936945004;
        uint64_t v16 = 0;
        break;
      case 1:
        int64_t v15 = 0x4C746E65746E6F63;
        uint64_t v16 = 111;
        break;
      case 2:
        int64_t v15 = 0x736F4C656C797473;
        uint64_t v16 = 115;
        break;
      case 3:
        int64_t v15 = 0x7963617275636361;
        uint64_t v16 = 0;
        break;
      case 4:
        int64_t v15 = 0x69746164696C6176;
        uint64_t v16 = 111;
        break;
      case 5:
        int64_t v15 = 0xD000000000000012;
        uint64_t v16 = (char)v34;
        break;
      case 6:
        int64_t v15 = 0xD000000000000010;
        uint64_t v16 = (char)v35;
        break;
      case 7:
        int64_t v15 = 0xD000000000000014;
        uint64_t v16 = (char)v36;
        break;
      case 8:
        int64_t v15 = 0x456D756D6978616DLL;
        uint64_t v16 = 114;
        break;
      case 9:
        int64_t v15 = 0xD00000000000001ELL;
        uint64_t v16 = (char)v37;
        break;
      case 10:
        int64_t v15 = 0xD000000000000016;
        uint64_t v16 = (char)v38;
        break;
    }
    String.hash(into:)(v29, v15);
    swift_bridgeObjectRelease(v16);
    uint64_t v17 = Hasher._finalize()() & ~(-1 << *((unsigned char *)v2 + 32));
    uint64_t v18 = v17 >> 6;
    uint64_t v19 = ~v2[(v17 >> 6) + 8] >> v17 << v17;
    if (v19)
    {
      _BitScanForward64(&v19, v19);
      uint64_t v20 = v19 | v17 & 0xFFFFFFFFFFFFFFC0;
    }
    else
    {
      unint64_t v21 = (unint64_t)(63 - (-1 << *((unsigned char *)v2 + 32))) >> 6;
      int64_t v22 = 0;
      do
      {
        unint64_t v23 = v18 + 1;
        if (v18 + 1 == v21 && (v22 & 1) != 0) {
          BUG();
        }
        uint64_t v18 = 0;
        if (v23 != v21) {
          uint64_t v18 = v23;
        }
        v22 |= v23 == v21;
        unint64_t v24 = v2[v18 + 8];
      }
      while (v24 == -1);
      int64_t v25 = ~v24;
      uint64_t v26 = 64;
      if (v25) {
        _BitScanForward64((unint64_t *)&v26, v25);
      }
      uint64_t v20 = v26 + (v18 << 6);
    }
    v2[(v20 >> 6) + 8] |= 1 << v20;
    *(unsigned char *)(v2[6] + v20) = v14;
    outlined init with take of Any(v31, (_OWORD *)(v2[7] + 32 * v20));
    ++v2[2];
    uint64_t v6 = v40;
  }
LABEL_50:
  swift_release();
  outlined consume of [String : [Int]].Iterator._Variant(v41);
  return v2;
}

{
  uint64_t v1;
  void *v2;
  uint64_t v3;
  uint64_t v4;
  unint64_t v5;
  int64_t i;
  unint64_t v7;
  unint64_t v8;
  int64_t v9;
  unint64_t j;
  int64_t v11;
  unint64_t v12;
  uint64_t v13;
  uint64_t v14;
  uint64_t v15;
  unint64_t v16;
  unint64_t v17;
  unint64_t v18;
  unint64_t v19;
  unint64_t v20;
  char v21;
  unint64_t v22;
  uint64_t v23;
  unint64_t v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  long long v28;
  long long v31[2];
  long long v32;
  long long v33;
  uint64_t v34;
  long long v35[2];
  uint64_t v36;
  uint64_t v37;
  _OWORD v38[2];
  uint64_t v39;
  uint64_t v40;
  long long v41[2];
  long long v42;
  long long v43;
  uint64_t v44;
  long long v45[2];
  uint64_t v46;
  int64_t v47;
  uint64_t v48;
  int64_t v49;
  uint64_t v50;

  uint64_t v48 = a1;
  int64_t v1 = *(void *)(a1 + 16);
  if (v1)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _DictionaryStorage<AnyHashable, Any>);
    uint64_t v2 = (void *)static _DictionaryStorage.allocate(capacity:)(v1);
  }
  else
  {
    uint64_t v2 = _swiftEmptyDictionarySingleton;
  }
  uint64_t v3 = -1 << *(unsigned char *)(v48 + 32);
  unint64_t v50 = v48 + 64;
  int64_t v4 = ~(-1 << -(char)v3);
  if (-v3 >= 64) {
    int64_t v4 = -1;
  }
  uint64_t v5 = *(void *)(v48 + 64) & v4;
  uint64_t v46 = v3;
  unint64_t v49 = (unint64_t)(63 - v3) >> 6;
  swift_bridgeObjectRetain(v48);
  swift_retain();
  for (unint64_t i = 0; ; unint64_t i = v47)
  {
    if (v5)
    {
      _BitScanForward64(&v7, v5);
      v5 &= v5 - 1;
      uint64_t v8 = v7 | (i << 6);
      uint64_t v47 = i;
      goto LABEL_20;
    }
    uint64_t v9 = i + 1;
    if (__OFADD__(1, i)) {
      BUG();
    }
    if (v9 >= v49) {
      break;
    }
    char j = *(void *)(v50 + 8 * v9);
    if (j)
    {
      uint64_t v11 = i + 1;
    }
    else
    {
      uint64_t v11 = i + 2;
      if (i + 2 >= v49) {
        break;
      }
      char j = *(void *)(v50 + 8 * v9 + 8);
      if (!j)
      {
        uint64_t v11 = i + 3;
        if (i + 3 >= v49) {
          break;
        }
        char j = *(void *)(v50 + 8 * v9 + 16);
        if (!j)
        {
          uint64_t v11 = i + 4;
          if (i + 4 >= v49) {
            break;
          }
          char j = *(void *)(v50 + 8 * v9 + 24);
          if (!j)
          {
            uint64_t v11 = i + 5;
            if (i + 5 >= v49) {
              break;
            }
            for (char j = *(void *)(v50 + 8 * v9 + 32); !j; char j = *(void *)(v50 + 8 * v11))
            {
              if (__OFADD__(1, v11++)) {
                BUG();
              }
              if (v11 >= v49) {
                goto LABEL_38;
              }
            }
          }
        }
      }
    }
    _BitScanForward64(&v12, j);
    uint64_t v5 = j & (j - 1);
    uint64_t v47 = v11;
    uint64_t v8 = v12 + (v11 << 6);
LABEL_20:
    uint64_t v13 = *(void *)(v48 + 48);
    uint64_t v14 = *(void *)(v13 + 16 * v8);
    int64_t v15 = *(void *)(v13 + 16 * v8 + 8);
    outlined init with copy of Any(*(void *)(v48 + 56) + 32 * v8, (uint64_t)v38);
    uint64_t v36 = v14;
    uint64_t v37 = v15;
    v41[1] = v38[1];
    v41[0] = v38[0];
    uint64_t v39 = v14;
    uint64_t v40 = v15;
    *(void *)&v31[0] = v14;
    *((void *)&v31[0] + 1) = v15;
    swift_bridgeObjectRetain(v15);
    swift_dynamicCast(&v42, v31, &type metadata for String, &type metadata for AnyHashable, 7);
    outlined init with take of Any(v41, v45);
    uint64_t v32 = v42;
    uint64_t v33 = v43;
    uint64_t v34 = v44;
    outlined init with take of Any(v45, v35);
    uint64_t v44 = v34;
    uint64_t v43 = v33;
    int v42 = v32;
    outlined init with take of Any(v35, v31);
    outlined init with take of Any(v31, &v32);
    uint64_t v16 = AnyHashable._rawHashValue(seed:)(v2[5]) & ~(-1 << *((unsigned char *)v2 + 32));
    uint64_t v17 = v16 >> 6;
    uint64_t v18 = ~v2[(v16 >> 6) + 8] >> v16 << v16;
    if (v18)
    {
      _BitScanForward64(&v18, v18);
      uint64_t v19 = v18 | v16 & 0xFFFFFFFFFFFFFFC0;
    }
    else
    {
      uint64_t v20 = (unint64_t)(63 - (-1 << *((unsigned char *)v2 + 32))) >> 6;
      unint64_t v21 = 0;
      do
      {
        int64_t v22 = v17 + 1;
        if (v17 + 1 == v20 && (v21 & 1) != 0) {
          BUG();
        }
        uint64_t v17 = 0;
        if (v22 != v20) {
          uint64_t v17 = v22;
        }
        v21 |= v22 == v20;
        unint64_t v23 = v2[v17 + 8];
      }
      while (v23 == -1);
      unint64_t v24 = ~v23;
      int64_t v25 = 64;
      if (v24) {
        _BitScanForward64((unint64_t *)&v25, v24);
      }
      uint64_t v19 = v25 + (v17 << 6);
    }
    v2[(v19 >> 6) + 8] |= 1 << v19;
    uint64_t v26 = v2[6];
    int64_t v27 = 40 * v19;
    *(void *)(v26 + v27 + 32) = v44;
    unint64_t v28 = v42;
    *(_OWORD *)(v26 + v27 + 16) = v43;
    *(_OWORD *)(v26 + v27) = v28;
    outlined init with take of Any(&v32, (_OWORD *)(v2[7] + 32 * v19));
    ++v2[2];
  }
LABEL_38:
  swift_release();
  outlined consume of [String : [Int]].Iterator._Variant(v48);
  return v2;
}

{
  uint64_t v1;
  uint64_t v2;
  void *v3;
  uint64_t v4;
  uint64_t v5;
  unint64_t v6;
  int64_t v7;
  unint64_t v8;
  unint64_t v9;
  int64_t v10;
  unint64_t i;
  int64_t v12;
  unint64_t v13;
  uint64_t v14;
  uint64_t v15;
  uint64_t v16;
  char v17;
  uint64_t v18;
  uint64_t v19;
  uint64_t v20;
  uint64_t v21;
  unint64_t v22;
  unint64_t v23;
  char v24;
  uint64_t v25;
  uint64_t v26;
  uint64_t v27;
  uint64_t v28;
  uint64_t v29;
  uint64_t v30;
  uint64_t v31;
  BOOL v32;
  uint64_t v33;
  uint64_t v35;
  uint64_t v36;
  uint64_t v37;
  uint64_t v38;
  uint64_t v39;
  uint64_t v40;
  int64_t v41;
  uint64_t v42;
  int64_t v43;
  uint64_t v44;

  int64_t v1 = a1;
  uint64_t v2 = *(void *)(a1 + 16);
  if (v2)
  {
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _DictionaryStorage<String, [NSNumber]>);
    uint64_t v3 = (void *)static _DictionaryStorage.allocate(capacity:)(v2);
  }
  else
  {
    uint64_t v3 = _swiftEmptyDictionarySingleton;
  }
  int64_t v4 = -1 << *(unsigned char *)(a1 + 32);
  uint64_t v5 = ~(-1 << -(char)v4);
  if (-v4 >= 64) {
    uint64_t v5 = -1;
  }
  uint64_t v6 = *(void *)(a1 + 64) & v5;
  uint64_t v44 = a1 + 64;
  uint64_t v39 = v4;
  uint64_t v43 = (unint64_t)(63 - v4) >> 6;
  swift_bridgeObjectRetain(a1);
  int64_t v7 = 0;
  uint64_t v38 = a1;
  while (1)
  {
    if (v6)
    {
      _BitScanForward64(&v8, v6);
      int v42 = (v6 - 1) & v6;
      uint64_t v9 = v8 | (v7 << 6);
      uint64_t v41 = v7;
      goto LABEL_20;
    }
    int64_t v10 = v7 + 1;
    if (__OFADD__(1, v7)) {
      BUG();
    }
    if (v10 >= v43) {
      break;
    }
    unint64_t i = *(void *)(v44 + 8 * v10);
    if (i)
    {
      int64_t v12 = v7 + 1;
    }
    else
    {
      int64_t v12 = v7 + 2;
      if (v7 + 2 >= v43) {
        break;
      }
      unint64_t i = *(void *)(v44 + 8 * v10 + 8);
      if (!i)
      {
        int64_t v12 = v7 + 3;
        if (v7 + 3 >= v43) {
          break;
        }
        unint64_t i = *(void *)(v44 + 8 * v10 + 16);
        if (!i)
        {
          int64_t v12 = v7 + 4;
          if (v7 + 4 >= v43) {
            break;
          }
          unint64_t i = *(void *)(v44 + 8 * v10 + 24);
          if (!i)
          {
            int64_t v12 = v7 + 5;
            if (v7 + 5 >= v43) {
              break;
            }
            for (unint64_t i = *(void *)(v44 + 8 * v10 + 32); !i; unint64_t i = *(void *)(v44 + 8 * v12))
            {
              uint64_t v32 = __OFADD__(1, v12++);
              if (v32) {
                BUG();
              }
              if (v12 >= v43) {
                goto LABEL_32;
              }
            }
          }
        }
      }
    }
    _BitScanForward64(&v13, i);
    int v42 = i & (i - 1);
    uint64_t v41 = v12;
    uint64_t v9 = v13 + (v12 << 6);
LABEL_20:
    uint64_t v14 = *(void *)(v1 + 48);
    int64_t v15 = *(void *)(v14 + 16 * v9);
    uint64_t v16 = *(void *)(v14 + 16 * v9 + 8);
    uint64_t v36 = *(void *)(*(void *)(v1 + 56) + 8 * v9);
    uint64_t v17 = v36;
    swift_bridgeObjectRetain(v16);
    swift_bridgeObjectRetain(v17);
    uint64_t v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [Double]);
    uint64_t v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [NSNumber]);
    uint64_t v20 = v18;
    unint64_t v21 = v15;
    swift_dynamicCast(&v35, &v36, v20, v19, 7);
    uint64_t v40 = v35;
    int64_t v22 = specialized __RawDictionaryStorage.find<A>(_:)(v15, v16);
    unint64_t v23 = v22;
    if (v24)
    {
      int64_t v25 = v3[6];
      uint64_t v37 = v21;
      uint64_t v26 = 16 * v22;
      swift_bridgeObjectRelease(*(void *)(v25 + 16 * v22 + 8));
      *(void *)(v25 + 16 * v23) = v37;
      *(void *)(v25 + v26 + 8) = v16;
      int64_t v27 = v3[7];
      swift_bridgeObjectRelease(*(void *)(v27 + 8 * v23));
      *(void *)(v27 + 8 * v23) = v40;
      int64_t v1 = v38;
    }
    else
    {
      unint64_t v28 = v40;
      if (v3[2] >= v3[3]) {
        BUG();
      }
      v3[(v22 >> 6) + 8] |= 1 << v22;
      uint64_t v29 = v3[6];
      uint64_t v30 = 16 * v23;
      *(void *)(v29 + v30) = v21;
      *(void *)(v29 + v30 + 8) = v16;
      *(void *)(v3[7] + 8 * v23) = v28;
      uint64_t v31 = v3[2];
      uint64_t v32 = __OFADD__(1, v31);
      uint64_t v33 = v31 + 1;
      if (v32) {
        BUG();
      }
      v3[2] = v33;
    }
    int64_t v7 = v41;
    uint64_t v6 = v42;
  }
LABEL_32:
  outlined consume of [String : [Int]].Iterator._Variant(v1);
  return v3;
}

double MLProgress.elapsedTime.getter()
{
  return *(double *)v0;
}

void MLProgress.elapsedTime.setter(double a1)
{
  *int64_t v1 = a1;
}

void (*MLProgress.elapsedTime.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

unsigned char *MLProgress.phase.getter()
{
  *uint64_t result = *(unsigned char *)(v1 + 8);
  return result;
}

char MLProgress.phase.setter(char *a1)
{
  char result = *a1;
  *(unsigned char *)(v1 + 8) = *a1;
  return result;
}

void (*MLProgress.phase.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLProgress.itemCount.getter()
{
  return *(void *)(v0 + 16);
}

void MLProgress.itemCount.setter(uint64_t a1)
{
  *(void *)(v1 + 16) = a1;
}

void (*MLProgress.itemCount.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLProgress.totalItemCount.getter()
{
  return *(void *)(v0 + 24);
}

void MLProgress.totalItemCount.setter(uint64_t a1, char a2)
{
  *(void *)(v2 + 24) = a1;
  *(unsigned char *)(v2 + 32) = a2 & 1;
}

void (*MLProgress.totalItemCount.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLProgress.metrics.getter()
{
  return swift_bridgeObjectRetain(*(void *)(v0 + 40));
}

uint64_t MLProgress.metrics.setter(uint64_t a1)
{
  uint64_t result = swift_bridgeObjectRelease(*(void *)(v1 + 40));
  *(void *)(v1 + 40) = a1;
  return result;
}

void (*MLProgress.metrics.modify())()
{
  return MLBoostedTreeRegressor.ModelParameters.maxDepth.modify;
}

uint64_t MLProgress.init(phase:)(char *a1)
{
  uint64_t v2 = v1;
  char v3 = *a1;
  uint64_t v4 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t result = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v4);
  *(void *)uint64_t v2 = 0;
  *(unsigned char *)(v2 + 8) = v3;
  *(_OWORD *)(v2 + 16) = 0;
  *(unsigned char *)(v2 + 32) = 1;
  *(void *)(v2 + 40) = result;
  return result;
}

uint64_t MLProgress.init(progress:)(id a1)
{
  uint64_t v54 = v1;
  char v67 = 1;
  uint64_t v2 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  char v3 = (void *)Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v2);
  id v65 = a1;
  id v4 = [a1 userInfo];
  id v5 = v4;
  uint64_t v59 = type metadata accessor for NSProgressUserInfoKey(0);
  uint64_t v64 = (char *)&type metadata for Any + 8;
  uint64_t v60 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type NSProgressUserInfoKey and conformance NSProgressUserInfoKey, type metadata accessor for NSProgressUserInfoKey, (uint64_t)&protocol conformance descriptor for NSProgressUserInfoKey);
  uint64_t v6 = static Dictionary._unconditionallyBridgeFromObjectiveC(_:)(v5, v59, (char *)&type metadata for Any + 8, v60);

  if (one-time initialization token for elapsedTimeKey != -1) {
    swift_once(&one-time initialization token for elapsedTimeKey, one-time initialization function for elapsedTimeKey);
  }
  id v7 = static MLProgress.elapsedTimeKey;
  specialized Dictionary.subscript.getter((uint64_t)v7, v6);

  swift_bridgeObjectRelease(v6);
  if (!*((void *)&v62 + 1)) {
    goto LABEL_18;
  }
  uint64_t v8 = v64;
  if (!swift_dynamicCast(v56, &v61, v64, &type metadata for Double, 6)) {
    goto LABEL_19;
  }
  uint64_t v50 = *(void *)&v56[0];
  id v9 = [v65 userInfo];
  id v10 = v9;
  uint64_t v11 = static Dictionary._unconditionallyBridgeFromObjectiveC(_:)(v10, v59, v8, v60);

  if (one-time initialization token for phaseKey != -1) {
    swift_once(&one-time initialization token for phaseKey, one-time initialization function for phaseKey);
  }
  id v12 = static MLProgress.phaseKey;
  specialized Dictionary.subscript.getter((uint64_t)v12, v11);

  swift_bridgeObjectRelease(v11);
  if (!*((void *)&v62 + 1)) {
    goto LABEL_18;
  }
  uint64_t v13 = v64;
  if (!swift_dynamicCast(v56, &v61, v64, &type metadata for MLPhase, 6))
  {
LABEL_19:

    goto LABEL_20;
  }
  uint64_t v51 = LOBYTE(v56[0]);
  id v14 = [v65 userInfo];
  id v15 = v14;
  uint64_t v16 = static Dictionary._unconditionallyBridgeFromObjectiveC(_:)(v15, v59, v13, v60);

  if (one-time initialization token for itemCountKey != -1) {
    swift_once(&one-time initialization token for itemCountKey, one-time initialization function for itemCountKey);
  }
  id v17 = static MLProgress.itemCountKey;
  specialized Dictionary.subscript.getter((uint64_t)v17, v16);

  swift_bridgeObjectRelease(v16);
  if (!*((void *)&v62 + 1))
  {
LABEL_18:

    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v61, &demangling cache variable for type metadata for Any?);
LABEL_20:
    swift_bridgeObjectRelease((_BYTE)v3);
    uint64_t result = v54;
    *(_OWORD *)(v54 + 32) = 0;
    *(_OWORD *)(v54 + 16) = 0;
    *(_OWORD *)uint64_t v54 = 0;
    return result;
  }
  uint64_t v18 = v64;
  if (!swift_dynamicCast(v56, &v61, v64, &type metadata for Int, 6)) {
    goto LABEL_19;
  }
  uint64_t v52 = *(void *)&v56[0];
  id v19 = [v65 userInfo];
  id v20 = v19;
  uint64_t v21 = static Dictionary._unconditionallyBridgeFromObjectiveC(_:)(v20, v59, v18, v60);

  if (one-time initialization token for totalItemCountKey != -1) {
    swift_once(&one-time initialization token for totalItemCountKey, one-time initialization function for totalItemCountKey);
  }
  id v22 = static MLProgress.totalItemCountKey;
  specialized Dictionary.subscript.getter((uint64_t)v22, v21);

  swift_bridgeObjectRelease(v21);
  if (*((void *)&v62 + 1))
  {
    char v23 = swift_dynamicCast(v56, &v61, v64, &type metadata for Int, 6);
    if (v23) {
      uint64_t v24 = *(void *)&v56[0];
    }
    else {
      uint64_t v24 = 0;
    }
    char v26 = v23 ^ 1;
  }
  else
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v61, &demangling cache variable for type metadata for Any?);
    char v26 = 1;
    uint64_t v24 = 0;
  }
  char v67 = v26;
  uint64_t v53 = v24;
  for (uint64_t i = 0; i != 11; ++i)
  {
    int v28 = *((unsigned __int8 *)&outlined read-only object #0 of static MLProgress.Metric.allCases.getter + i + 32);
    if (v28 != 6 || (_UNKNOWN *)type metadata accessor for URL(0) == &type metadata for Double)
    {
      unint64_t v55 = v3;
      id v29 = [v65 userInfo];
      id v30 = v29;
      uint64_t v31 = static Dictionary._unconditionallyBridgeFromObjectiveC(_:)(v30, v59, v64, v60);

      switch(v28)
      {
        case 0:
          uint64_t v32 = &static MLProgress.lossKey;
          if (one-time initialization token for lossKey != -1)
          {
            swift_once(&one-time initialization token for lossKey, one-time initialization function for lossKey);
            uint64_t v32 = &static MLProgress.lossKey;
          }
          break;
        case 1:
          uint64_t v32 = &static MLProgress.contentLossKey;
          if (one-time initialization token for contentLossKey != -1)
          {
            swift_once(&one-time initialization token for contentLossKey, one-time initialization function for contentLossKey);
            uint64_t v32 = &static MLProgress.contentLossKey;
          }
          break;
        case 2:
          uint64_t v32 = &static MLProgress.styleLossKey;
          if (one-time initialization token for styleLossKey != -1)
          {
            swift_once(&one-time initialization token for styleLossKey, one-time initialization function for styleLossKey);
            uint64_t v32 = &static MLProgress.styleLossKey;
          }
          break;
        case 3:
          uint64_t v32 = &static MLProgress.accuracyKey;
          if (one-time initialization token for accuracyKey != -1)
          {
            swift_once(&one-time initialization token for accuracyKey, one-time initialization function for accuracyKey);
            uint64_t v32 = &static MLProgress.accuracyKey;
          }
          break;
        case 4:
          uint64_t v32 = &static MLProgress.validationLossKey;
          if (one-time initialization token for validationLossKey != -1)
          {
            swift_once(&one-time initialization token for validationLossKey, one-time initialization function for validationLossKey);
            uint64_t v32 = &static MLProgress.validationLossKey;
          }
          break;
        case 5:
          uint64_t v32 = &static MLProgress.validationAccuracyKey;
          if (one-time initialization token for validationAccuracyKey != -1)
          {
            swift_once(&one-time initialization token for validationAccuracyKey, one-time initialization function for validationAccuracyKey);
            uint64_t v32 = &static MLProgress.validationAccuracyKey;
          }
          break;
        case 6:
          uint64_t v32 = &static MLProgress.stylizedImageKey;
          if (one-time initialization token for stylizedImageKey != -1)
          {
            swift_once(&one-time initialization token for stylizedImageKey, one-time initialization function for stylizedImageKey);
            uint64_t v32 = &static MLProgress.stylizedImageKey;
          }
          break;
        case 7:
          uint64_t v32 = &static MLProgress.rootMeanSquaredErrorKey;
          if (one-time initialization token for rootMeanSquaredErrorKey != -1)
          {
            swift_once(&one-time initialization token for rootMeanSquaredErrorKey, one-time initialization function for rootMeanSquaredErrorKey);
            uint64_t v32 = &static MLProgress.rootMeanSquaredErrorKey;
          }
          break;
        case 8:
          uint64_t v32 = &static MLProgress.maximumErrorKey;
          if (one-time initialization token for maximumErrorKey != -1)
          {
            swift_once(&one-time initialization token for maximumErrorKey, one-time initialization function for maximumErrorKey);
            uint64_t v32 = &static MLProgress.maximumErrorKey;
          }
          break;
        case 9:
          uint64_t v32 = &static MLProgress.validationRootMeanSquaredErrorKey;
          if (one-time initialization token for validationRootMeanSquaredErrorKey != -1)
          {
            swift_once(&one-time initialization token for validationRootMeanSquaredErrorKey, one-time initialization function for validationRootMeanSquaredErrorKey);
            uint64_t v32 = &static MLProgress.validationRootMeanSquaredErrorKey;
          }
          break;
        case 10:
          uint64_t v32 = &static MLProgress.validationMaximumErrorKey;
          if (one-time initialization token for validationMaximumErrorKey != -1)
          {
            swift_once(&one-time initialization token for validationMaximumErrorKey, one-time initialization function for validationMaximumErrorKey);
            uint64_t v32 = &static MLProgress.validationMaximumErrorKey;
          }
          break;
      }
      id v33 = (id)*v32;
      uint64_t v34 = v33;
      if (*(void *)(v31 + 16) && (unint64_t v35 = specialized __RawDictionaryStorage.find<A>(_:)((uint64_t)v33), (v36 & 1) != 0))
      {
        outlined init with copy of Any(*(void *)(v31 + 56) + 32 * v35, (uint64_t)&v61);
      }
      else
      {
        long long v62 = 0;
        long long v61 = 0;
      }

      swift_bridgeObjectRelease(v31);
      if (*((void *)&v62 + 1))
      {
        int v63 = v28;
        char v3 = v55;
        if (swift_dynamicCast(v56, &v61, v64, &type metadata for Double, 6))
        {
          *((void *)&v62 + 1) = &type metadata for Double;
          *(void *)&long long v61 = *(void *)&v56[0];
          outlined init with take of Any(&v61, v56);
          char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v55);
          uint64_t v58 = v55;
          int v57 = v63;
          unint64_t v38 = specialized __RawDictionaryStorage.find<A>(_:)(v63);
          char v66 = v39;
          BOOL v40 = (v39 & 1) == 0;
          BOOL v41 = __OFADD__(v55[2], v40);
          Swift::Int v42 = v55[2] + v40;
          if (v41) {
            BUG();
          }
          __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<MLProgress.Metric, Any>);
          Swift::Bool v43 = _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v42);
          char v44 = v63;
          char v45 = v66;
          if (v43)
          {
            unint64_t v38 = specialized __RawDictionaryStorage.find<A>(_:)(v57);
            if ((v45 & 1) != (v46 & 1))
            {
              KEY_TYPE_OF_DICTIONARY_VIOLATES_HASHABLE_REQUIREMENTS(_:)(&type metadata for MLProgress.Metric);
              BUG();
            }
          }
          char v3 = v58;
          if (v45)
          {
            uint64_t v47 = (void *)(v58[7] + 32 * v38);
            __swift_destroy_boxed_opaque_existential_1Tm(v47);
            outlined init with take of Any(v56, v47);
          }
          else
          {
            v58[(v38 >> 6) + 8] |= 1 << v38;
            *(unsigned char *)(v3[6] + v38) = v44;
            outlined init with take of Any(v56, (_OWORD *)(v3[7] + 32 * v38));
            uint64_t v48 = v3[2];
            BOOL v41 = __OFADD__(1, v48);
            uint64_t v49 = v48 + 1;
            if (v41) {
              BUG();
            }
            v3[2] = v49;
          }
          swift_bridgeObjectRelease(0);
        }
      }
      else
      {
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>((uint64_t)&v61, &demangling cache variable for type metadata for Any?);
        char v3 = v55;
      }
    }
  }
  swift_bridgeObjectRelease(&outlined read-only object #0 of static MLProgress.Metric.allCases.getter);

  uint64_t result = v67 & 1;
  *(void *)uint64_t v54 = v50;
  *(void *)(v54 + 8) = v51;
  *(void *)(v54 + 16) = v52;
  *(void *)(v54 + 24) = v53;
  *(void *)(v54 + 32) = result;
  *(void *)(v54 + 40) = v3;
  return result;
}

_UNKNOWN **static MLProgress.Metric.allCases.getter()
{
  return &outlined read-only object #0 of static MLProgress.Metric.allCases.getter;
}

CreateML::MLProgress::Metric_optional __swiftcall MLProgress.Metric.init(rawValue:)(Swift::String rawValue)
{
  uint64_t v2 = v1;
  unint64_t v3 = _findStringSwitchCase(cases:string:)((Swift::OpaquePointer)&outlined read-only object #0 of MLProgress.Metric.init(rawValue:), rawValue);
  swift_bridgeObjectRelease(rawValue._object);
  result.value = CreateML_MLProgress_Metric_unknownDefault;
  if (v3 < 0xB) {
    result.value = (char)v3;
  }
  v2->value = result.value;
  return result;
}

unint64_t MLProgress.Metric.rawValue.getter()
{
  switch(*v0)
  {
    case 0:
      unint64_t result = 1936945004;
      break;
    case 1:
      unint64_t result = 0x4C746E65746E6F63;
      break;
    case 2:
      unint64_t result = 0x736F4C656C797473;
      break;
    case 3:
      unint64_t result = 0x7963617275636361;
      break;
    case 4:
      unint64_t result = 0x69746164696C6176;
      break;
    case 5:
      unint64_t result = 0xD000000000000012;
      break;
    case 6:
      unint64_t result = 0xD000000000000010;
      break;
    case 7:
      unint64_t result = 0xD000000000000014;
      break;
    case 8:
      unint64_t result = 0x456D756D6978616DLL;
      break;
    case 9:
      unint64_t result = 0xD00000000000001ELL;
      break;
    case 0xA:
      unint64_t result = 0xD000000000000016;
      break;
  }
  return result;
}

uint64_t protocol witness for static Equatable.== infix(_:_:) in conformance MLProgress.Metric(unsigned __int8 *a1, char *a2)
{
  return specialized == infix<A>(_:_:)(*a1, *a2);
}

CreateML::MLProgress::Metric_optional protocol witness for RawRepresentable.init(rawValue:) in conformance MLProgress.Metric(Swift::String *a1)
{
  return MLProgress.Metric.init(rawValue:)(*a1);
}

unint64_t protocol witness for RawRepresentable.rawValue.getter in conformance MLProgress.Metric()
{
  uint64_t v1 = v0;
  unint64_t result = MLProgress.Metric.rawValue.getter();
  *uint64_t v1 = result;
  v1[1] = v3;
  return result;
}

uint64_t protocol witness for Decodable.init(from:) in conformance MLProgress.Metric(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v3 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  return RawRepresentable<>.init(from:)(a1, a2, a3, v3);
}

uint64_t protocol witness for Encodable.encode(to:) in conformance MLProgress.Metric(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v4 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  return RawRepresentable<>.encode(to:)(a1, a2, a3, v4);
}

CreateML::MLProgress::CodingKeys_optional __swiftcall MLProgress.CodingKeys.init(stringValue:)(Swift::String stringValue)
{
  if (stringValue._countAndFlagsBits == 0x5464657370616C65 && stringValue._object == (void *)0xEB00000000656D69)
  {
    char object = (void *)0xEB00000000656D69;
LABEL_6:
    swift_bridgeObjectRelease(object);
    return 0;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0x5464657370616C65, 0xEB00000000656D69, stringValue._countAndFlagsBits, stringValue._object, 0))
  {
    char object = stringValue._object;
    goto LABEL_6;
  }
  if (stringValue._countAndFlagsBits == 0x6573616870 && stringValue._object == (void *)0xE500000000000000)
  {
    uint64_t v3 = (void *)0xE500000000000000;
LABEL_12:
    swift_bridgeObjectRelease(v3);
    return (CreateML::MLProgress::CodingKeys_optional)1;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0x6573616870, 0xE500000000000000, stringValue._countAndFlagsBits, stringValue._object, 0))
  {
    uint64_t v3 = stringValue._object;
    goto LABEL_12;
  }
  if (stringValue._countAndFlagsBits == 0x6F72506573616870 && stringValue._object == (void *)0xED00007373657267)
  {
    uint64_t v4 = (void *)0xED00007373657267;
LABEL_18:
    swift_bridgeObjectRelease(v4);
    return (CreateML::MLProgress::CodingKeys_optional)2;
  }
  if (_stringCompareWithSmolCheck(_:_:expecting:)(0x6F72506573616870, 0xED00007373657267, stringValue._countAndFlagsBits, stringValue._object, 0))
  {
    uint64_t v4 = stringValue._object;
    goto LABEL_18;
  }
  if (stringValue._countAndFlagsBits == 0x7363697274656DLL && stringValue._object == (void *)0xE700000000000000)
  {
    swift_bridgeObjectRelease(0xE700000000000000);
    return (CreateML::MLProgress::CodingKeys_optional)3;
  }
  else
  {
    char v5 = _stringCompareWithSmolCheck(_:_:expecting:)(0x7363697274656DLL, 0xE700000000000000, stringValue._countAndFlagsBits, stringValue._object, 0);
    swift_bridgeObjectRelease(stringValue._object);
    return (CreateML::MLProgress::CodingKeys_optional)(4 - (v5 & 1));
  }
}

uint64_t MLProgress.CodingKeys.stringValue.getter(char a1)
{
  switch(a1)
  {
    case 0:
      uint64_t result = 0x5464657370616C65;
      break;
    case 1:
      uint64_t result = 0x6573616870;
      break;
    case 2:
      uint64_t result = 0x6F72506573616870;
      break;
    case 3:
      uint64_t result = 0x7363697274656DLL;
      break;
  }
  return result;
}

Swift::Int protocol witness for Hashable.hashValue.getter in conformance MLProgress.Metric()
{
  return specialized RawRepresentable<>.hashValue.getter(*v0);
}

uint64_t protocol witness for Hashable.hash(into:) in conformance MLProgress.Metric(uint64_t a1)
{
  return specialized RawRepresentable<>.hash(into:)(a1, *v1);
}

Swift::Int protocol witness for Hashable._rawHashValue(seed:) in conformance MLProgress.Metric(uint64_t a1)
{
  return specialized RawRepresentable<>._rawHashValue(seed:)(a1, *v1);
}

void *protocol witness for static CaseIterable.allCases.getter in conformance MLProgress.Metric()
{
  *uint64_t result = &outlined read-only object #0 of static MLProgress.Metric.allCases.getter;
  return result;
}

uint64_t protocol witness for CodingKey.stringValue.getter in conformance MLProgress.CodingKeys()
{
  return MLProgress.CodingKeys.stringValue.getter(*v0);
}

CreateML::MLProgress::CodingKeys_optional protocol witness for CodingKey.init(stringValue:) in conformance MLProgress.CodingKeys(Swift::String a1)
{
  uint64_t v2 = v1;
  result.value = MLProgress.CodingKeys.init(stringValue:)(a1).value;
  v2->value = result.value;
  return result;
}

unsigned char *protocol witness for CodingKey.init(intValue:) in conformance MLProgress.CodingKeys()
{
  *CreateML::MLProgress::CodingKeys_optional result = 4;
  return result;
}

uint64_t protocol witness for CustomStringConvertible.description.getter in conformance MLProgress.CodingKeys(uint64_t a1)
{
  uint64_t v1 = lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys();
  return CodingKey.description.getter(a1, v1);
}

uint64_t protocol witness for CustomDebugStringConvertible.debugDescription.getter in conformance MLProgress.CodingKeys(uint64_t a1)
{
  uint64_t v1 = lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys();
  return CodingKey.debugDescription.getter(a1, v1);
}

uint64_t MLProgress.init(from:)(void *a1, double a2)
{
  double v22 = v3;
  uint64_t v21 = v2;
  uint64_t v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedDecodingContainer<MLProgress.CodingKeys>);
  uint64_t v25 = *(void *)(v24 - 8);
  int64_t v4 = *(void *)(v25 + 64);
  char v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v7 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
  uint64_t v26 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v7);
  uint64_t v8 = a1[3];
  uint64_t v23 = a1[4];
  __swift_project_boxed_opaque_existential_0Tm(a1, v8);
  uint64_t v9 = lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys();
  id v29 = &v20;
  char v10 = v26;
  dispatch thunk of Decoder.container<A>(keyedBy:)(&type metadata for MLProgress.CodingKeys, &type metadata for MLProgress.CodingKeys, v9, v8, v23);
  if (v3 == 0.0)
  {
    char v27 = 0;
    KeyedDecodingContainer.decode(_:forKey:)(&v27, v24);
    double v22 = a2;
    char v28 = 1;
    uint64_t v11 = lazy protocol witness table accessor for type MLPhase and conformance MLPhase();
    uint64_t v12 = v24;
    KeyedDecodingContainer.decode<A>(_:forKey:)(&type metadata for MLPhase, &v28, v24, &type metadata for MLPhase, v11);
    LOBYTE(v23) = v30;
    uint64_t v14 = v12;
    uint64_t v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLProgress.Metric : Double]);
    v31[0] = 3;
    uint64_t v16 = lazy protocol witness table accessor for type [MLProgress.Metric : Double] and conformance <> [A : B](&lazy protocol witness table cache variable for type [MLProgress.Metric : Double] and conformance <> [A : B], (void (*)(void))lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric, (uint64_t)&protocol witness table for Double, (uint64_t)&protocol conformance descriptor for <> [A : B]);
    KeyedDecodingContainer.decode<A>(_:forKey:)(v15, v31, v14, v15, v16);
    LOBYTE(v15) = v20;
    id v17 = specialized _dictionaryUpCast<A, B, C, D>(_:)(v20);
    swift_bridgeObjectRelease(v15);
    (*(void (**)(uint64_t *, uint64_t))(v25 + 8))(v29, v24);
    swift_bridgeObjectRetain((_BYTE)v17);
    swift_bridgeObjectRelease(v26);
    uint64_t v18 = v21;
    *uint64_t v21 = v22;
    *((unsigned char *)v18 + 8) = v23;
    *((_OWORD *)v18 + 1) = 0;
    *((unsigned char *)v18 + 32) = 1;
    *((void *)v18 + 5) = v17;
    __swift_destroy_boxed_opaque_existential_1Tm(a1);
    char v19 = (char)v17;
  }
  else
  {
    __swift_destroy_boxed_opaque_existential_1Tm(a1);
    char v19 = v10;
  }
  return swift_bridgeObjectRelease(v19);
}

uint64_t MLProgress.encode(to:)(void *a1)
{
  char v19 = v1;
  uint64_t v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for KeyedEncodingContainer<MLProgress.CodingKeys>);
  uint64_t v18 = *(void *)(v14 - 8);
  int64_t v3 = *(void *)(v18 + 64);
  int64_t v4 = alloca(v3);
  char v5 = alloca(v3);
  double v15 = *(double *)v2;
  char v24 = *(unsigned char *)(v2 + 8);
  uint64_t v17 = *(void *)(v2 + 40);
  uint64_t v6 = a1[3];
  uint64_t v16 = a1[4];
  __swift_project_boxed_opaque_existential_0Tm(a1, v6);
  uint64_t v7 = lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys();
  uint64_t v8 = v14;
  dispatch thunk of Encoder.container<A>(keyedBy:)(&type metadata for MLProgress.CodingKeys, &type metadata for MLProgress.CodingKeys, v7, v6, v16);
  char v20 = 0;
  KeyedEncodingContainer.encode(_:forKey:)(&v20, v14, v15);
  if (v1) {
    return (*(uint64_t (**)(void **, uint64_t))(v18 + 8))(&v13, v14);
  }
  char v21 = v24;
  char v22 = 1;
  uint64_t v10 = lazy protocol witness table accessor for type MLPhase and conformance MLPhase();
  KeyedEncodingContainer.encode<A>(_:forKey:)(&v21, &v22, v14, &type metadata for MLPhase, v10);
  char v19 = specialized Dictionary.compactMapValues<A>(_:)(v17);
  uint64_t v13 = v19;
  char v23 = 3;
  uint64_t v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [MLProgress.Metric : Double]);
  uint64_t v12 = lazy protocol witness table accessor for type [MLProgress.Metric : Double] and conformance <> [A : B](&lazy protocol witness table cache variable for type [MLProgress.Metric : Double] and conformance <> [A : B], (void (*)(void))lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric, (uint64_t)&protocol witness table for Double, (uint64_t)&protocol conformance descriptor for <> [A : B]);
  KeyedEncodingContainer.encode<A>(_:forKey:)(&v13, &v23, v8, v11, v12);
  (*(void (**)(void **, uint64_t))(v18 + 8))(&v13, v8);
  return swift_bridgeObjectRelease((_BYTE)v19);
}

uint64_t protocol witness for Decodable.init(from:) in conformance MLProgress(void *a1, double a2)
{
  return MLProgress.init(from:)(a1, a2);
}

uint64_t protocol witness for Encodable.encode(to:) in conformance MLProgress(void *a1)
{
  return MLProgress.encode(to:)(a1);
}

NSString one-time initialization function for elapsedTimeKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.elapsedTimeKey = result;
  return result;
}

id static MLProgress.elapsedTimeKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for elapsedTimeKey, &static MLProgress.elapsedTimeKey, (uint64_t)one-time initialization function for elapsedTimeKey);
}

NSString one-time initialization function for phaseKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.phaseKey = result;
  return result;
}

id static MLProgress.phaseKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for phaseKey, &static MLProgress.phaseKey, (uint64_t)one-time initialization function for phaseKey);
}

NSString one-time initialization function for itemCountKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.itemCountKey = result;
  return result;
}

id static MLProgress.itemCountKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for itemCountKey, &static MLProgress.itemCountKey, (uint64_t)one-time initialization function for itemCountKey);
}

NSString one-time initialization function for totalItemCountKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.totalItemCountKey = result;
  return result;
}

id static MLProgress.totalItemCountKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for totalItemCountKey, &static MLProgress.totalItemCountKey, (uint64_t)one-time initialization function for totalItemCountKey);
}

NSString one-time initialization function for lossKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.lossKey = (uint64_t)result;
  return result;
}

id static MLProgress.lossKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for lossKey, (id *)&static MLProgress.lossKey, (uint64_t)one-time initialization function for lossKey);
}

NSString one-time initialization function for contentLossKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.contentLossKey = (uint64_t)result;
  return result;
}

id static MLProgress.contentLossKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for contentLossKey, (id *)&static MLProgress.contentLossKey, (uint64_t)one-time initialization function for contentLossKey);
}

NSString one-time initialization function for styleLossKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.styleLossKey = (uint64_t)result;
  return result;
}

id static MLProgress.styleLossKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for styleLossKey, (id *)&static MLProgress.styleLossKey, (uint64_t)one-time initialization function for styleLossKey);
}

NSString one-time initialization function for accuracyKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.accuracyKey = (uint64_t)result;
  return result;
}

id static MLProgress.accuracyKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for accuracyKey, (id *)&static MLProgress.accuracyKey, (uint64_t)one-time initialization function for accuracyKey);
}

NSString one-time initialization function for validationLossKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.validationLossKey = (uint64_t)result;
  return result;
}

id static MLProgress.validationLossKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for validationLossKey, (id *)&static MLProgress.validationLossKey, (uint64_t)one-time initialization function for validationLossKey);
}

NSString one-time initialization function for validationAccuracyKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.validationAccuracyKey = (uint64_t)result;
  return result;
}

id static MLProgress.validationAccuracyKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for validationAccuracyKey, (id *)&static MLProgress.validationAccuracyKey, (uint64_t)one-time initialization function for validationAccuracyKey);
}

NSString one-time initialization function for stylizedImageKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.stylizedImageKey = (uint64_t)result;
  return result;
}

id static MLProgress.stylizedImageKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for stylizedImageKey, (id *)&static MLProgress.stylizedImageKey, (uint64_t)one-time initialization function for stylizedImageKey);
}

NSString one-time initialization function for rootMeanSquaredErrorKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.rootMeanSquaredErrorKey = (uint64_t)result;
  return result;
}

id static MLProgress.rootMeanSquaredErrorKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for rootMeanSquaredErrorKey, (id *)&static MLProgress.rootMeanSquaredErrorKey, (uint64_t)one-time initialization function for rootMeanSquaredErrorKey);
}

NSString one-time initialization function for maximumErrorKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.maximumErrorKey = (uint64_t)result;
  return result;
}

id static MLProgress.maximumErrorKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for maximumErrorKey, (id *)&static MLProgress.maximumErrorKey, (uint64_t)one-time initialization function for maximumErrorKey);
}

NSString one-time initialization function for validationRootMeanSquaredErrorKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.validationRootMeanSquaredErrorKey = (uint64_t)result;
  return result;
}

id static MLProgress.validationRootMeanSquaredErrorKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for validationRootMeanSquaredErrorKey, (id *)&static MLProgress.validationRootMeanSquaredErrorKey, (uint64_t)one-time initialization function for validationRootMeanSquaredErrorKey);
}

NSString one-time initialization function for validationMaximumErrorKey()
{
  NSString result = String._bridgeToObjectiveC()();
  static MLProgress.validationMaximumErrorKey = (uint64_t)result;
  return result;
}

id static MLProgress.validationMaximumErrorKey.getter()
{
  return static MLProgress.elapsedTimeKey.getter(&one-time initialization token for validationMaximumErrorKey, (id *)&static MLProgress.validationMaximumErrorKey, (uint64_t)one-time initialization function for validationMaximumErrorKey);
}

id static MLProgress.elapsedTimeKey.getter(void *a1, id *a2, uint64_t a3)
{
  if (*a1 != -1) {
    swift_once(a1, a3);
  }
  return *a2;
}

uint64_t specialized Dictionary._Variant.removeValue(forKey:)(uint64_t a1, uint64_t a2)
{
  int64_t v4 = v3;
  char v5 = v2;
  uint64_t v6 = *v3;
  swift_bridgeObjectRetain(v6);
  unint64_t v7 = specialized __RawDictionaryStorage.find<A>(_:)(a1, a2);
  char v9 = v8;
  uint64_t result = swift_bridgeObjectRelease(v6);
  if (v9)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(*v4);
    uint64_t v15 = *v4;
    uint64_t v12 = *v4;
    void *v4 = 0x8000000000000000;
    Swift::Int v13 = *(void *)(v12 + 24);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<String, Any>);
    _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v13);
    swift_bridgeObjectRelease(*(void *)(*(void *)(v15 + 48) + 16 * v7 + 8));
    outlined init with take of Any((long long *)(*(void *)(v15 + 56) + 32 * v7), v5);
    _NativeDictionary._delete(at:)(v7, v15, &type metadata for String, (char *)&type metadata for Any + 8, &protocol witness table for String);
    uint64_t v14 = *v4;
    void *v4 = v15;
    return swift_bridgeObjectRelease(v14);
  }
  else
  {
    v5[1] = 0;
    _OWORD *v5 = 0;
  }
  return result;
}

{
  return specialized Dictionary._Variant.removeValue(forKey:)(a1, a2, &demangling cache variable for type metadata for _NativeDictionary<String, Tensor>, (uint64_t (*)(void))&type metadata accessor for Tensor);
}

uint64_t specialized Dictionary._Variant.removeValue(forKey:)(uint64_t a1, uint64_t a2, uint64_t *a3, uint64_t (*a4)(void))
{
  uint64_t v6 = v5;
  uint64_t v7 = v4;
  uint64_t v8 = *v5;
  swift_bridgeObjectRetain(v8);
  unint64_t v9 = specialized __RawDictionaryStorage.find<A>(_:)(a1, a2);
  char v11 = v10;
  swift_bridgeObjectRelease(v8);
  if (v11)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(*v6);
    uint64_t v20 = *v6;
    uint64_t v13 = *v6;
    void *v6 = 0x8000000000000000;
    uint64_t v22 = v7;
    Swift::Int v14 = *(void *)(v13 + 24);
    __swift_instantiateConcreteTypeFromMangledName(a3);
    _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v14);
    swift_bridgeObjectRelease(*(void *)(*(void *)(v20 + 48) + 16 * v9 + 8));
    uint64_t v15 = *(void *)(v20 + 56);
    uint64_t v16 = a4(0);
    (*(void (**)(uint64_t, unint64_t, uint64_t))(*(void *)(v16 - 8) + 32))(v22, v15 + v9 * *(void *)(*(void *)(v16 - 8) + 72), v16);
    _NativeDictionary._delete(at:)(v9, v20, &type metadata for String, v16, &protocol witness table for String);
    uint64_t v17 = *v6;
    void *v6 = v20;
    swift_bridgeObjectRelease(v17);
    return __swift_storeEnumTagSinglePayload(v22, 0, 1, v16);
  }
  else
  {
    uint64_t v19 = a4(0);
    return __swift_storeEnumTagSinglePayload(v7, 1, 1, v19);
  }
}

uint64_t specialized Dictionary._Variant.removeValue(forKey:)(uint64_t a1)
{
  int64_t v3 = v2;
  uint64_t v4 = v1;
  uint64_t v5 = *v2;
  swift_bridgeObjectRetain(v5);
  unint64_t v6 = specialized __RawDictionaryStorage.find<A>(_:)(a1);
  char v8 = v7;
  uint64_t result = swift_bridgeObjectRelease(v5);
  if (v8)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(*v3);
    uint64_t v16 = *v3;
    uint64_t v11 = *v3;
    *int64_t v3 = 0x8000000000000000;
    uint64_t v17 = v4;
    Swift::Int v12 = *(void *)(v11 + 24);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<CodingUserInfoKey, Any>);
    _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v12);
    uint64_t v13 = *(void *)(v16 + 48);
    uint64_t v14 = type metadata accessor for CodingUserInfoKey(0);
    (*(void (**)(unint64_t, uint64_t))(*(void *)(v14 - 8) + 8))(v13 + v6 * *(void *)(*(void *)(v14 - 8) + 72), v14);
    outlined init with take of Any((long long *)(*(void *)(v16 + 56) + 32 * v6), v17);
    _NativeDictionary._delete(at:)(v6, v16, v14, (char *)&type metadata for Any + 8, &protocol witness table for CodingUserInfoKey);
    uint64_t v15 = *v3;
    *int64_t v3 = v16;
    return swift_bridgeObjectRelease(v15);
  }
  else
  {
    v4[1] = 0;
    _OWORD *v4 = 0;
  }
  return result;
}

{
  _OWORD *v1;
  void *v2;
  void *v3;
  _OWORD *v4;
  uint64_t v5;
  unint64_t v6;
  char v7;
  char v8;
  uint64_t result;
  char isUniquelyReferenced_nonNull_native;
  uint64_t v11;
  Swift::Int v12;
  uint64_t v13;
  uint64_t v14;

  int64_t v3 = v2;
  uint64_t v4 = v1;
  uint64_t v5 = *v2;
  swift_bridgeObjectRetain(v5);
  unint64_t v6 = specialized __RawDictionaryStorage.find<A>(_:)(a1);
  char v8 = v7;
  uint64_t result = swift_bridgeObjectRelease(v5);
  if (v8)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(*v3);
    uint64_t v14 = *v3;
    uint64_t v11 = *v3;
    *int64_t v3 = 0x8000000000000000;
    Swift::Int v12 = *(void *)(v11 + 24);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<AnyHashable, Any>);
    _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v12);
    outlined destroy of AnyHashable(*(void *)(v14 + 48) + 40 * v6);
    outlined init with take of Any((long long *)(*(void *)(v14 + 56) + 32 * v6), v4);
    _NativeDictionary._delete(at:)(v6, v14, &type metadata for AnyHashable, (char *)&type metadata for Any + 8, &protocol witness table for AnyHashable);
    uint64_t v13 = *v3;
    *int64_t v3 = v14;
    return swift_bridgeObjectRelease(v13);
  }
  else
  {
    v4[1] = 0;
    _OWORD *v4 = 0;
  }
  return result;
}

uint64_t specialized Dictionary._Variant.removeValue(forKey:)(char a1)
{
  int64_t v3 = v2;
  uint64_t v4 = v1;
  uint64_t v5 = *v2;
  swift_bridgeObjectRetain(v5);
  unint64_t v6 = specialized __RawDictionaryStorage.find<A>(_:)(a1);
  char v8 = v7;
  uint64_t result = swift_bridgeObjectRelease(v5);
  if (v8)
  {
    char isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(*v3);
    uint64_t v15 = *v3;
    uint64_t v11 = *v3;
    *int64_t v3 = 0x8000000000000000;
    unint64_t v16 = v6;
    Swift::Int v12 = *(void *)(v11 + 24);
    __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _NativeDictionary<MLProgress.Metric, Any>);
    _NativeDictionary.ensureUnique(isUnique:capacity:)(isUniquelyReferenced_nonNull_native, v12);
    outlined init with take of Any((long long *)(*(void *)(v15 + 56) + 32 * v16), v4);
    uint64_t v13 = lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
    _NativeDictionary._delete(at:)(v16, v15, &type metadata for MLProgress.Metric, (char *)&type metadata for Any + 8, v13);
    uint64_t v14 = *v3;
    *int64_t v3 = v15;
    return swift_bridgeObjectRelease(v14);
  }
  else
  {
    v4[1] = 0;
    _OWORD *v4 = 0;
  }
  return result;
}

uint64_t lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys()
{
  uint64_t result = lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys;
  if (!lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLProgress.CodingKeys, &type metadata for MLProgress.CodingKeys);
    lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys;
  if (!lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLProgress.CodingKeys, &type metadata for MLProgress.CodingKeys);
    lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys;
  if (!lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLProgress.CodingKeys, &type metadata for MLProgress.CodingKeys);
    lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys = result;
  }
  return result;
}

{
  uint64_t result;

  uint64_t result = lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys;
  if (!lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys)
  {
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for MLProgress.CodingKeys, &type metadata for MLProgress.CodingKeys);
    lazy protocol witness table cache variable for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys = result;
  }
  return result;
}

uint64_t base witness table accessor for Equatable in MLProgress.Metric()
{
  return lazy protocol witness table accessor for type MLProgress.Metric and conformance MLProgress.Metric();
}

uint64_t associated type witness table accessor for CaseIterable.AllCases : Collection in MLProgress.Metric()
{
  return lazy protocol witness table accessor for type [MLProgress.Metric] and conformance [A]();
}

uint64_t lazy protocol witness table accessor for type [MLProgress.Metric] and conformance [A]()
{
  uint64_t result = lazy protocol witness table cache variable for type [MLProgress.Metric] and conformance [A];
  if (!lazy protocol witness table cache variable for type [MLProgress.Metric] and conformance [A])
  {
    uint64_t v1 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for [MLProgress.Metric]);
    uint64_t result = swift_getWitnessTable(&protocol conformance descriptor for [A], v1);
    lazy protocol witness table cache variable for type [MLProgress.Metric] and conformance [A] = result;
  }
  return result;
}

uint64_t destroy for MLProgress(uint64_t a1)
{
  return swift_bridgeObjectRelease(*(void *)(a1 + 40));
}

uint64_t initializeWithCopy for MLProgress(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  *(unsigned char *)(a1 + 8) = *(unsigned char *)(a2 + 8);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  *(unsigned char *)(a1 + 32) = *(unsigned char *)(a2 + 32);
  uint64_t v3 = *(void *)(a2 + 40);
  *(void *)(a1 + 40) = v3;
  swift_bridgeObjectRetain(v3);
  return a1;
}

uint64_t assignWithCopy for MLProgress(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  *(unsigned char *)(a1 + 8) = *(unsigned char *)(a2 + 8);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  *(unsigned char *)(a1 + 32) = *(unsigned char *)(a2 + 32);
  uint64_t v3 = *(void *)(a2 + 40);
  uint64_t v4 = *(void *)(a1 + 40);
  *(void *)(a1 + 40) = v3;
  swift_bridgeObjectRetain(v3);
  swift_bridgeObjectRelease(v4);
  return a1;
}

uint64_t assignWithTake for MLProgress(uint64_t a1, uint64_t a2)
{
  *(void *)a1 = *(void *)a2;
  *(unsigned char *)(a1 + 8) = *(unsigned char *)(a2 + 8);
  *(void *)(a1 + 16) = *(void *)(a2 + 16);
  *(void *)(a1 + 24) = *(void *)(a2 + 24);
  *(unsigned char *)(a1 + 32) = *(unsigned char *)(a2 + 32);
  uint64_t v3 = *(void *)(a1 + 40);
  *(void *)(a1 + 40) = *(void *)(a2 + 40);
  swift_bridgeObjectRelease(v3);
  return a1;
}

uint64_t getEnumTagSinglePayload for MLProgress(uint64_t a1, int a2)
{
  if (a2)
  {
    if (a2 < 0 && *(unsigned char *)(a1 + 48)) {
      int v2 = *(_DWORD *)a1 + 0x7FFFFFFF;
    }
    else {
      int v2 = (*(void *)(a1 + 40) & 0xFFFFFFFF00000001) != 0 ? -1 : *(void *)(a1 + 40) >> 1;
    }
  }
  else
  {
    int v2 = -1;
  }
  return (v2 + 1);
}

void storeEnumTagSinglePayload for MLProgress(uint64_t a1, int a2, int a3)
{
  if (a2 < 0)
  {
    *(void *)(a1 + 40) = 0;
    *(_OWORD *)(a1 + 24) = 0;
    *(_OWORD *)(a1 + 8) = 0;
    *(void *)a1 = a2 + 0x80000000;
    if (a3 < 0) {
      *(unsigned char *)(a1 + 48) = 1;
    }
  }
  else
  {
    if (a3 < 0) {
      *(unsigned char *)(a1 + 48) = 0;
    }
    if (a2) {
      *(void *)(a1 + 40) = 2 * (a2 - 1);
    }
  }
}

ValueMetadata *type metadata accessor for MLProgress()
{
  return &type metadata for MLProgress;
}

uint64_t getEnumTagSinglePayload for MLProgress.Metric(unsigned __int8 *a1, unsigned int a2)
{
  if (a2)
  {
    if (a2 < 0xF6) {
      goto LABEL_13;
    }
    unsigned int v2 = a2 + 10;
    int v3 = 1;
    if (v2 >= 0xFF00) {
      int v3 = 2 * (v2 >= 0xFFFF00) + 2;
    }
    if (v3 == 4) {
      int v4 = *(_DWORD *)(a1 + 1);
    }
    else {
      int v4 = v3 == 2 ? *(unsigned __int16 *)(a1 + 1) : a1[1];
    }
    if (v4)
    {
      int v5 = *a1 + (v4 << 8) - 11;
    }
    else
    {
LABEL_13:
      unsigned int v6 = *a1;
      int v7 = v6 - 11;
      BOOL v8 = v6 < 0xB;
      int v5 = -1;
      if (!v8) {
        int v5 = v7;
      }
    }
  }
  else
  {
    int v5 = -1;
  }
  return (v5 + 1);
}

uint64_t storeEnumTagSinglePayload for MLProgress.Metric(unsigned char *a1, unsigned int a2, unsigned int a3)
{
  LODWORD(result) = 0;
  if (a3 >= 0xF6)
  {
    unsigned int v4 = a3 + 10;
    LODWORD(result) = 1;
    if (v4 >= 0xFF00) {
      LODWORD(result) = 2 * (v4 >= 0xFFFF00) + 2;
    }
  }
  if (a2 > 0xF5)
  {
    unsigned int v5 = a2 - 246;
    int v6 = (v5 >> 8) + 1;
    *a1 = v5;
    uint64_t result = result;
    switch((int)result)
    {
      case 0:
        return result;
      case 1:
        a1[1] = v6;
        break;
      case 2:
        *(_WORD *)(a1 + 1) = v6;
        break;
      case 3:
LABEL_16:
        BUG();
      case 4:
        *(_DWORD *)(a1 + 1) = v6;
        break;
    }
  }
  else
  {
    uint64_t result = result;
    switch((int)result)
    {
      case 0:
        goto LABEL_11;
      case 1:
        a1[1] = 0;
        goto LABEL_11;
      case 2:
        *(_WORD *)(a1 + 1) = 0;
        goto LABEL_11;
      case 3:
        goto LABEL_16;
      case 4:
        *(_DWORD *)(a1 + 1) = 0;
LABEL_11:
        if (a2) {
          *a1 = a2 + 10;
        }
        break;
      case 5:
        JUMPOUT(0x14B0C0);
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for MLProgress.Metric()
{
  return &type metadata for MLProgress.Metric;
}

uint64_t storeEnumTagSinglePayload for MLProgress.CodingKeys(unsigned char *a1, unsigned int a2, unsigned int a3)
{
  LODWORD(result) = 0;
  if (a3 >= 0xFD)
  {
    unsigned int v4 = a3 + 3;
    LODWORD(result) = 1;
    if (v4 >= 0xFF00) {
      LODWORD(result) = 2 * (v4 >= 0xFFFF00) + 2;
    }
  }
  if (a2 > 0xFC)
  {
    unsigned int v5 = a2 - 253;
    int v6 = (v5 >> 8) + 1;
    *a1 = v5;
    uint64_t result = result;
    switch((int)result)
    {
      case 0:
        return result;
      case 1:
        a1[1] = v6;
        break;
      case 2:
        *(_WORD *)(a1 + 1) = v6;
        break;
      case 3:
LABEL_16:
        BUG();
      case 4:
        *(_DWORD *)(a1 + 1) = v6;
        break;
    }
  }
  else
  {
    uint64_t result = result;
    switch((int)result)
    {
      case 0:
        goto LABEL_11;
      case 1:
        a1[1] = 0;
        goto LABEL_11;
      case 2:
        *(_WORD *)(a1 + 1) = 0;
        goto LABEL_11;
      case 3:
        goto LABEL_16;
      case 4:
        *(_DWORD *)(a1 + 1) = 0;
LABEL_11:
        if (a2) {
          *a1 = a2 + 3;
        }
        break;
      case 5:
        JUMPOUT(0x14B198);
    }
  }
  return result;
}

ValueMetadata *type metadata accessor for MLProgress.CodingKeys()
{
  return &type metadata for MLProgress.CodingKeys;
}

uint64_t base witness table accessor for Equatable in MLProgress.CodingKeys()
{
  return lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys();
}

uint64_t base witness table accessor for CustomDebugStringConvertible in MLProgress.CodingKeys()
{
  return lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys();
}

uint64_t base witness table accessor for CustomStringConvertible in MLProgress.CodingKeys()
{
  return lazy protocol witness table accessor for type MLProgress.CodingKeys and conformance MLProgress.CodingKeys();
}

uint64_t outlined init with take of (key: MetricsKey, value: Double)(uint64_t a1, uint64_t a2)
{
  uint64_t v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (key: MetricsKey, value: Double));
  (*(void (**)(uint64_t, uint64_t, uint64_t))(*(void *)(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

void destructiveInjectEnumTag for MLProgress.Metric(unsigned char *a1, char a2)
{
}

uint64_t getEnumTag for MLProgress.Metric(unsigned __int8 *a1)
{
  return getEnumTag for Rectangle.CodingKeys(a1);
}

uint64_t static MLHandPoseClassifier.__Defaults.batchSize.getter()
{
  return 32;
}

uint64_t static MLHandPoseClassifier.__Defaults.maximumIterations.getter()
{
  return 80;
}

uint64_t static MLHandPoseClassifier.__Defaults.sessionIdColumnName.getter()
{
  return 0x5F6E6F6973736573;
}

uint64_t static MLHandPoseClassifier.__Defaults.featureColumnName.getter()
{
  return 0x746E696F7079656BLL;
}

uint64_t static MLHandPoseClassifier.__Defaults.labelColumnName.getter()
{
  return 0x6C6562616CLL;
}

uint64_t static MLHandPoseClassifier.__Defaults.imageColumnName.getter()
{
  return 0x7461506567616D69;
}

ValueMetadata *type metadata accessor for MLHandPoseClassifier.__Defaults()
{
  return &type metadata for MLHandPoseClassifier.__Defaults;
}

void *_sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySo8NSNumberCG_Sis5NeverOTg5074_s8CreateML24MLFewShotSoundClassifierV5write2toy10Foundation3URLV_tKFSiSo8D54Ccfu_33_5bdac5b40c7411f20a64c1277f8fd44fAJSiTf3nnnpk_nTf1cn_n(uint64_t a1)
{
  if ((a1 & 0x4000000000000001) != 0)
  {
    uint64_t v10 = a1 & 0xFFFFFFFFFFFFF8;
    if (a1) {
      uint64_t v10 = a1;
    }
    swift_bridgeObjectRetain(a1);
    uint64_t v1 = _CocoaArrayWrapper.endIndex.getter(v10);
    swift_bridgeObjectRelease(a1);
  }
  else
  {
    uint64_t v1 = *(void *)((char *)&dword_10 + (a1 & 0xFFFFFFFFFFFFF8));
  }
  if (v1)
  {
    int64_t v2 = 0;
    if (v1 > 0) {
      int64_t v2 = v1;
    }
    uint64_t v12 = v1;
    specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v2, 0);
    uint64_t v3 = v1;
    if (v1 < 0) {
      BUG();
    }
    uint64_t v4 = 0;
    do
    {
      if (v3 == v4) {
        BUG();
      }
      if ((a1 & 0xC000000000000003) != 0) {
        id v5 = (id)specialized _ArrayBuffer._getElementSlowPath(_:)(v4, a1);
      }
      else {
        id v5 = *(id *)(a1 + 8 * v4 + 32);
      }
      int v6 = v5;
      id v11 = [v5 integerValue];

      unint64_t v7 = _swiftEmptyArrayStorage[2];
      unint64_t v8 = v7 + 1;
      if (_swiftEmptyArrayStorage[3] >> 1 <= v7)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(_swiftEmptyArrayStorage[3] >= 2uLL, v7 + 1, 1);
        unint64_t v8 = v7 + 1;
      }
      ++v4;
      _swiftEmptyArrayStorage[2] = v8;
      _swiftEmptyArrayStorage[v7 + 4] = v11;
      uint64_t v3 = v12;
    }
    while (v12 != v4);
  }
  return _swiftEmptyArrayStorage;
}

uint64_t *MLFewShotSoundClassifier.TemporalClassifier.makeConvBlock(name:input:output:layer:)(long long a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6)
{
  uint64_t v59 = a5;
  uint64_t v60 = a4;
  uint64_t v73 = a2;
  *(void *)&long long v72 = a1;
  int64_t v7 = *(void *)(*(void *)(type metadata accessor for NeuralNetwork.Border(0) - 8) + 64);
  unint64_t v8 = alloca(v7);
  unint64_t v9 = alloca(v7);
  int64_t v78 = &v59;
  int64_t v10 = *(void *)(*(void *)(type metadata accessor for NeuralNetwork.Layer.PadParameters.Kind(0) - 8) + 64);
  id v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v75 = &v59;
  uint64_t v62 = type metadata accessor for MLFewShotSoundClassifier.CausalConv1D(0);
  int64_t v13 = *(void *)(*(void *)(v62 - 8) + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v68 = &v59;
  uint64_t v67 = type metadata accessor for NeuralNetwork.Layer.Kind(0);
  uint64_t v77 = *(void *)(v67 - 8);
  int64_t v16 = *(void *)(v77 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v69 = &v59;
  uint64_t v71 = type metadata accessor for NeuralNetwork.Layer(0);
  uint64_t v76 = *(void (**)(char *, uint64_t *, uint64_t))(v71 - 8);
  int64_t v19 = *((void *)v76 + 8);
  uint64_t v20 = alloca(v19);
  char v21 = alloca(v19);
  long long v61 = &v59;
  uint64_t v22 = alloca(v19);
  char v23 = alloca(v19);
  int v63 = &v59;
  char v24 = alloca(v19);
  uint64_t v25 = alloca(v19);
  id v65 = &v59;
  long long v70 = a1;
  *((void *)&v72 + 1) = *((void *)&a1 + 1);
  swift_bridgeObjectRetain(BYTE8(a1));
  v26._char object = (void *)0xE400000000000000;
  v26._uint64_t countAndFlagsBits = 1684107359;
  String.append(_:)(v26);
  long long v74 = v70;
  uint64_t v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  char v28 = (void *)swift_allocObject(v27, 48, 7);
  void v28[2] = 1;
  v28[3] = 2;
  v28[4] = v73;
  v28[5] = a3;
  uint64_t v73 = v27;
  uint64_t v29 = swift_allocObject(v27, 48, 7);
  *(void *)(v29 + 16) = 1;
  *(void *)(v29 + 24) = 2;
  uint64_t v30 = v29;
  uint64_t v66 = v29;
  long long v70 = v72;
  swift_bridgeObjectRetain(BYTE8(v72));
  swift_bridgeObjectRetain(a3);
  v26._uint64_t countAndFlagsBits = 0x74756F5F6461705FLL;
  v26._char object = (void *)0xE800000000000000;
  String.append(_:)(v26);
  *(_OWORD *)(v30 + 32) = v70;
  uint64_t v31 = v68;
  outlined init with copy of MLTrainingSessionParameters(a6, (uint64_t)v68, type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
  uint64_t v32 = v75;
  static NeuralNetwork.Layer.PadParameters.Kind.constant(value:)(0.0);
  id v33 = v78;
  NeuralNetwork.Border.init(leadingHeight:trailingHeight:leadingWidth:trailingWidth:)(0, 0, *v31, 0);
  uint64_t v34 = v69;
  NeuralNetwork.Layer.PadParameters.init(kind:amount:)(v32, v33);
  outlined destroy of MLFewShotSoundClassifier.TemporalClassifier((uint64_t)v31, type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
  uint64_t v64 = *(void (**)(uint64_t *, void, uint64_t))(v77 + 104);
  v64(v34, enum case for NeuralNetwork.Layer.Kind.pad(_:), v67);
  unint64_t v35 = v65;
  NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)(v74, *((void *)&v74 + 1), v28, v66, v34);
  char v36 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, 1, 1, (uint64_t)_swiftEmptyArrayStorage);
  unint64_t v37 = v36[2];
  if ((unint64_t)v36[3] >> 1 <= v37) {
    char v36 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)((unint64_t)v36[3] >= 2, v37 + 1, 1, (uint64_t)v36);
  }
  int64_t v78 = v36;
  void v36[2] = v37 + 1;
  uint64_t v75 = (uint64_t *)((*((unsigned __int8 *)v76 + 80) + 32) & ~*((unsigned __int8 *)v76 + 80));
  unint64_t v38 = (void (*)(char *, uint64_t *, uint64_t))*((void *)v76 + 4);
  uint64_t v77 = *((void *)v76 + 9);
  uint64_t v76 = v38;
  v38((char *)v36 + (void)v75 + v77 * v37, v35, v71);
  uint64_t v39 = v72;
  long long v70 = v72;
  uint64_t v40 = *((void *)&v72 + 1);
  swift_bridgeObjectRetain(BYTE8(v72));
  v41._uint64_t countAndFlagsBits = 0x6431766E6F635FLL;
  v41._char object = (void *)0xE700000000000000;
  String.append(_:)(v41);
  long long v74 = v70;
  uint64_t v42 = v73;
  uint64_t v43 = swift_allocObject(v73, 48, 7);
  *(void *)(v43 + 16) = 1;
  *(void *)(v43 + 24) = 2;
  *(void *)&long long v70 = v39;
  *((void *)&v70 + 1) = v40;
  swift_bridgeObjectRetain(v40);
  v41._uint64_t countAndFlagsBits = 0x74756F5F6461705FLL;
  v41._char object = (void *)0xE800000000000000;
  String.append(_:)(v41);
  *(_OWORD *)(v43 + 32) = v70;
  uint64_t v44 = swift_allocObject(v42, 48, 7);
  *(void *)(v44 + 16) = 1;
  *(void *)(v44 + 24) = 2;
  *(void *)&long long v70 = v39;
  *((void *)&v70 + 1) = v40;
  swift_bridgeObjectRetain(v40);
  v41._uint64_t countAndFlagsBits = 0x756F5F766E6F635FLL;
  v41._char object = (void *)0xE900000000000074;
  String.append(_:)(v41);
  *(_OWORD *)(v44 + 32) = v70;
  uint64_t v45 = (uint64_t)v68;
  outlined init with copy of MLTrainingSessionParameters(a6, (uint64_t)v68, type metadata accessor for MLFewShotSoundClassifier.CausalConv1D);
  char v46 = v69;
  NeuralNetwork.Layer.ConvolutionParameters.init(from:)(v45);
  v64(v46, enum case for NeuralNetwork.Layer.Kind.convolution(_:), v67);
  uint64_t v47 = v63;
  uint64_t v48 = v46;
  uint64_t v49 = v78;
  NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)(v74, *((void *)&v74 + 1), v43, v44, v48);
  unint64_t v50 = v49[2];
  if ((unint64_t)v49[3] >> 1 <= v50) {
    uint64_t v49 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)((unint64_t)v49[3] >= 2, v50 + 1, 1, (uint64_t)v49);
  }
  int64_t v78 = v49;
  v49[2] = v50 + 1;
  v76((char *)v75 + (void)v49 + v77 * v50, v47, v71);
  uint64_t v51 = v72;
  long long v70 = v72;
  uint64_t v52 = *((void *)&v72 + 1);
  swift_bridgeObjectRetain(BYTE8(v72));
  v53._uint64_t countAndFlagsBits = 0x746176697463615FLL;
  v53._char object = (void *)0xEB000000006E6F69;
  String.append(_:)(v53);
  long long v54 = v70;
  *(void *)&long long v70 = v51;
  *((void *)&v70 + 1) = v52;
  swift_bridgeObjectRetain(v52);
  v53._uint64_t countAndFlagsBits = 0x756F5F766E6F635FLL;
  v53._char object = (void *)0xE900000000000074;
  String.append(_:)(v53);
  LOBYTE(v51) = BYTE8(v70);
  unint64_t v55 = v61;
  static NeuralNetwork.Layer.leakyRelu(name:inputName:outputName:negativeSlope:)(v54, *((void *)&v54 + 1), v70, *((void *)&v70 + 1), v60, v59, *(float *)(a6 + *(int *)(v62 + 24)));
  swift_bridgeObjectRelease(BYTE8(v54));
  LOBYTE(v53._countAndFlagsBits) = v51;
  uint64_t v56 = v78;
  swift_bridgeObjectRelease(v53._countAndFlagsBits);
  unint64_t v57 = v56[2];
  if ((unint64_t)v56[3] >> 1 <= v57) {
    uint64_t v56 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)((unint64_t)v56[3] >= 2, v57 + 1, 1, (uint64_t)v56);
  }
  long long v56[2] = v57 + 1;
  v76((char *)v75 + (void)v56 + v77 * v57, v55, v71);
  return v56;
}

void *MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:)(uint64_t a1)
{
  uint64_t v84 = v1;
  uint64_t v105 = v2;
  uint64_t v108 = a1;
  uint64_t v3 = (void *)type metadata accessor for Dense(0);
  uint64_t v85 = *(v3 - 1);
  int64_t v4 = *(void *)(v85 + 64);
  id v5 = alloca(v4);
  int v6 = alloca(v4);
  uint64_t v93 = &v80;
  uint64_t v86 = type metadata accessor for NeuralNetwork.Layer.SliceParameters.Axis(0);
  uint64_t v87 = *(void *)(v86 - 8);
  int64_t v7 = *(void *)(v87 + 64);
  unint64_t v8 = alloca(v7);
  unint64_t v9 = alloca(v7);
  uint64_t v88 = &v80;
  uint64_t v81 = type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D(0);
  int64_t v10 = *(void *)(*(void *)(v81 - 8) + 64);
  id v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  int64_t v82 = &v80;
  uint64_t v102 = type metadata accessor for NeuralNetwork.Layer.Kind(0);
  uint64_t v83 = *(void *)(v102 - 8);
  int64_t v13 = *(void *)(v83 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v101 = &v80;
  uint64_t v107 = type metadata accessor for NeuralNetwork.Layer(0);
  char v109 = *(void **)(v107 - 8);
  int64_t v16 = v109[8];
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  int64_t v19 = alloca(v16);
  uint64_t v20 = alloca(v16);
  uint64_t v94 = &v80;
  char v21 = alloca(v16);
  uint64_t v22 = alloca(v16);
  uint64_t v95 = &v80;
  char v23 = alloca(v16);
  char v24 = alloca(v16);
  uint64_t v96 = &v80;
  uint64_t v25 = alloca(v16);
  Swift::String v26 = alloca(v16);
  uint64_t v97 = &v80;
  uint64_t v27 = alloca(v16);
  char v28 = alloca(v16);
  char v103 = &v80;
  uint64_t v29 = alloca(v16);
  uint64_t v30 = alloca(v16);
  uint64_t v91 = &v80;
  uint64_t v31 = alloca(v16);
  uint64_t v32 = alloca(v16);
  uint64_t v92 = &v80;
  id v33 = alloca(v16);
  uint64_t v34 = alloca(v16);
  uint64_t v104 = &v80;
  unint64_t v35 = alloca(v16);
  char v36 = alloca(v16);
  uint64_t v37 = specialized BidirectionalCollection.last.getter(v108);
  if (v38)
  {
    uint64_t v74 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v74, 0, 0);
    *(void *)uint64_t v75 = 0xD00000000000002CLL;
    *(void *)(v75 + 8) = "framewiseEmbedding" + 0x8000000000000000;
    *(_OWORD *)(v75 + 16) = 0;
    *(_OWORD *)(v75 + 32) = 0;
    *(unsigned char *)(v75 + 48) = 2;
    swift_willThrow(&type metadata for MLCreateError, v74, v75, v76, v77, v78);
  }
  else
  {
    uint64_t v98 = v37;
    char v99 = v3;
    uint64_t v100 = &v80;
    uint64_t v89 = &v80;
    unint64_t v90 = 0xD00000000000001ALL;
    static NeuralNetwork.Layer.expandDimensions(name:inputName:outputName:axes:)(0x646E61707865, 0xE600000000000000, 0xD000000000000012, "fixedLengthEmbedding" + 0x8000000000000000, 0xD00000000000001ALL, "ing shape must not be empty." + 0x8000000000000000, &outlined read-only object #0 of MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:));
    uint64_t v39 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, 1, 1, (uint64_t)_swiftEmptyArrayStorage);
    unint64_t v40 = v39[2];
    unint64_t v41 = v39[3];
    if (v41 >> 1 <= v40) {
      uint64_t v39 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v41 >= 2, v40 + 1, 1, (uint64_t)v39);
    }
    v39[2] = v40 + 1;
    uint64_t v108 = (*((unsigned __int8 *)v109 + 80) + 32) & ~*((unsigned __int8 *)v109 + 80);
    uint64_t v42 = (void *)v109[4];
    uint64_t v106 = v109[9];
    char v109 = v42;
    ((void (*)(char *, void *, uint64_t))v42)((char *)v39 + v108 + v106 * v40, v89, v107);
    static NeuralNetwork.Layer.transpose(name:inputName:outputName:axes:)(0x736F70736E617274, 0xE900000000000065, v90, "ing shape must not be empty." + 0x8000000000000000, 0xD00000000000001CLL, "validationMaximumError" + 0x8000000000000000, &outlined read-only object #1 of MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:));
    unint64_t v43 = v39[2];
    if (v39[3] >> 1 <= v43) {
      uint64_t v39 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v39[3] >= 2uLL, v43 + 1, 1, (uint64_t)v39);
    }
    v39[2] = v43 + 1;
    ((void (*)(char *, void *, uint64_t))v109)((char *)v39 + v108 + v106 * v43, v104, v107);
    uint64_t v44 = (uint64_t)v82;
    outlined init with copy of MLTrainingSessionParameters(v105, (uint64_t)v82, type metadata accessor for MLFewShotSoundClassifier.LeakyConv2D);
    uint64_t v45 = v101;
    NeuralNetwork.Layer.ConvolutionParameters.init(from:)(v44);
    uint64_t v104 = *(void **)(v83 + 104);
    ((void (*)(void *, void, uint64_t))v104)(v45, enum case for NeuralNetwork.Layer.Kind.convolution(_:), v102);
    NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)(0xD000000000000010, "expandedFramewiseEmbedding" + 0x8000000000000000, &outlined read-only object #2 of MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:), &outlined read-only object #3 of MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:), v45);
    unint64_t v46 = v39[2];
    if (v39[3] >> 1 <= v46) {
      uint64_t v39 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v39[3] >= 2uLL, v46 + 1, 1, (uint64_t)v39);
    }
    v39[2] = v46 + 1;
    ((void (*)(char *, void *, uint64_t))v109)((char *)v39 + v108 + v106 * v46, v92, v107);
    static NeuralNetwork.Layer.leakyRelu(name:inputName:outputName:negativeSlope:)(0xD000000000000019, "featureReduction" + 0x8000000000000000, 0x64656375646572, 0xE700000000000000, 0xD000000000000010, "featureReductionLeakyRelu" + 0x8000000000000000, *(float *)(v105 + *(int *)(v81 + 20)));
    unint64_t v47 = v39[2];
    if (v39[3] >> 1 <= v47) {
      uint64_t v39 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v39[3] >= 2uLL, v47 + 1, 1, (uint64_t)v39);
    }
    v39[2] = v47 + 1;
    ((void (*)(char *, void *, uint64_t))v109)((char *)v39 + v108 + v106 * v47, v91, v107);
    static NeuralNetwork.Layer.transpose(name:inputName:outputName:axes:)(0x736F70736E617274, 0xE900000000000065, 0xD000000000000010, "featureReductionLeakyRelu" + 0x8000000000000000, 0x6E69646465626D65, 0xE900000000000067, &outlined read-only object #4 of MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:));
    unint64_t v48 = v39[2];
    if (v39[3] >> 1 <= v48) {
      uint64_t v39 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v39[3] >= 2uLL, v48 + 1, 1, (uint64_t)v39);
    }
    v39[2] = v48 + 1;
    ((void (*)(char *, void *, uint64_t))v109)((char *)v39 + v108 + v106 * v48, v103, v107);
    uint64_t v80 = v39;
    uint64_t v49 = (int *)type metadata accessor for MLFewShotSoundClassifier.ConvolutionalNetwork(0);
    uint64_t v50 = v105;
    *(void *)&long long v51 = 12643;
    *((void *)&v51 + 1) = 0xE200000000000000;
    uint64_t v52 = MLFewShotSoundClassifier.TemporalClassifier.makeConvBlock(name:input:output:layer:)(v51, 0x6E69646465626D65, 0xE900000000000067, 12643, 0xE200000000000000, v105 + v49[5]);
    specialized Array.append<A>(contentsOf:)((uint64_t)v52);
    *(void *)&long long v51 = 12899;
    *((void *)&v51 + 1) = 0xE200000000000000;
    Swift::String v53 = MLFewShotSoundClassifier.TemporalClassifier.makeConvBlock(name:input:output:layer:)(v51, 12643, 0xE200000000000000, 12899, 0xE200000000000000, v50 + v49[6]);
    specialized Array.append<A>(contentsOf:)((uint64_t)v53);
    *(void *)&long long v51 = 13155;
    *((void *)&v51 + 1) = 0xE200000000000000;
    long long v54 = MLFewShotSoundClassifier.TemporalClassifier.makeConvBlock(name:input:output:layer:)(v51, 12899, 0xE200000000000000, 13155, 0xE200000000000000, v50 + v49[7]);
    specialized Array.append<A>(contentsOf:)((uint64_t)v54);
    *(void *)&long long v51 = 13411;
    *((void *)&v51 + 1) = 0xE200000000000000;
    unint64_t v55 = MLFewShotSoundClassifier.TemporalClassifier.makeConvBlock(name:input:output:layer:)(v51, 13155, 0xE200000000000000, 13411, 0xE200000000000000, v50 + v49[8]);
    specialized Array.append<A>(contentsOf:)((uint64_t)v55);
    uint64_t v56 = v98 - 1;
    if (__OFSUB__(v98, 1)) {
      BUG();
    }
    unint64_t v57 = v88;
    uint64_t v58 = v86;
    uint64_t v59 = v87;
    (*(void (**)(void *, void, uint64_t))(v87 + 104))(v88, enum case for NeuralNetwork.Layer.SliceParameters.Axis.width(_:), v86);
    static NeuralNetwork.Layer.slice(name:inputName:outputName:startIndex:endIndex:stride:axis:)(0x6563696C73, 0xE500000000000000, 13411, 0xE200000000000000, 0x646563696C73, 0xE600000000000000, v56, v98, 1, v57);
    (*(void (**)(void *, uint64_t))(v59 + 8))(v57, v58);
    uint64_t v3 = v80;
    if (!swift_isUniquelyReferenced_nonNull_native(v80)) {
      uint64_t v3 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v3[2] + 1, 1, (uint64_t)v3);
    }
    unint64_t v60 = v3[2];
    if (v3[3] >> 1 <= v60) {
      uint64_t v3 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v3[3] >= 2uLL, v60 + 1, 1, (uint64_t)v3);
    }
    v3[2] = v60 + 1;
    ((void (*)(char *, void *, uint64_t))v109)((char *)v3 + v108 + v106 * v60, v97, v107);
    uint64_t v61 = *(int *)(type metadata accessor for MLFewShotSoundClassifier.TemporalClassifier(0) + 20) + v105;
    uint64_t v62 = *(void **)(v85 + 16);
    uint64_t v63 = (uint64_t)v93;
    uint64_t v105 = v61;
    char v103 = v62;
    ((void (*)(void *, uint64_t, void *))v62)(v93, v61, v99);
    uint64_t v64 = v101;
    NeuralNetwork.Layer.InnerProductParameters.init(from:)(v63);
    unsigned int v65 = enum case for NeuralNetwork.Layer.Kind.innerProduct(_:);
    ((void (*)(void *, void, uint64_t))v104)(v64, enum case for NeuralNetwork.Layer.Kind.innerProduct(_:), v102);
    NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)(12644, 0xE200000000000000, &outlined read-only object #5 of MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:), &outlined read-only object #6 of MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:), v64);
    unint64_t v66 = v3[2];
    if (v3[3] >> 1 <= v66) {
      uint64_t v3 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v3[3] >= 2uLL, v66 + 1, 1, (uint64_t)v3);
    }
    v3[2] = v66 + 1;
    ((void (*)(char *, void *, uint64_t))v109)((char *)v3 + v108 + v106 * v66, v96, v107);
    static NeuralNetwork.Layer.relu(name:inputName:outputName:)(0x756C65725F3164, 0xE700000000000000, 12644, 0xE200000000000000, 0x756C65725F3164, 0xE700000000000000);
    unint64_t v67 = v3[2];
    if (v3[3] >> 1 <= v67) {
      uint64_t v3 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v3[3] >= 2uLL, v67 + 1, 1, (uint64_t)v3);
    }
    v3[2] = v67 + 1;
    ((void (*)(char *, void *, uint64_t))v109)((char *)v3 + v108 + v106 * v67, v95, v107);
    uint64_t v68 = type metadata accessor for MLFewShotSoundClassifier.MLP(0);
    uint64_t v69 = (uint64_t)v93;
    ((void (*)(void *, uint64_t, void *))v103)(v93, *(int *)(v68 + 20) + v105, v99);
    long long v70 = v101;
    NeuralNetwork.Layer.InnerProductParameters.init(from:)(v69);
    ((void (*)(void *, void, uint64_t))v104)(v70, v65, v102);
    NeuralNetwork.Layer.init(name:inputNames:outputNames:kind:)(12900, 0xE200000000000000, &outlined read-only object #7 of MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:), &outlined read-only object #8 of MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:), v70);
    unint64_t v71 = v3[2];
    if (v3[3] >> 1 <= v71) {
      uint64_t v3 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v3[3] >= 2uLL, v71 + 1, 1, (uint64_t)v3);
    }
    long long v72 = v100;
    v3[2] = v71 + 1;
    ((void (*)(char *, void *, uint64_t))v109)((char *)v3 + v108 + v106 * v71, v94, v107);
    static NeuralNetwork.Layer.softmax(name:inputName:outputName:)(0x78616D74666F73, 0xE700000000000000, 12900, 0xE200000000000000, 0x62614C7373616C63, 0xEF73626F72506C65);
    unint64_t v73 = v3[2];
    if (v3[3] >> 1 <= v73) {
      uint64_t v3 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v3[3] >= 2uLL, v73 + 1, 1, (uint64_t)v3);
    }
    v3[2] = v73 + 1;
    ((void (*)(char *, void *, uint64_t))v109)((char *)v3 + v108 + v106 * v73, v72, v107);
  }
  return v3;
}

uint64_t MLFewShotSoundClassifier.TemporalClassifier.branchClassifier(input:classLabels:framewiseEmbeddingShape:exemplar:)(uint64_t a1, uint64_t a2, uint64_t a3, char *a4)
{
  uint64_t v116 = v5;
  uint64_t v107 = v6;
  uint64_t v114 = a4;
  uint64_t v112 = a3;
  uint64_t v98 = a2;
  uint64_t v111 = v4;
  uint64_t v82 = type metadata accessor for ModelKind(0);
  uint64_t v83 = *(void *)(v82 - 8);
  int64_t v7 = *(void *)(v83 + 64);
  unint64_t v8 = alloca(v7);
  unint64_t v9 = alloca(v7);
  uint64_t v84 = &v81;
  uint64_t v86 = type metadata accessor for NeuralNetworkClassifier.ClassLabels(0);
  uint64_t v87 = *(void *)(v86 - 8);
  int64_t v10 = *(void *)(v87 + 64);
  id v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v88 = &v81;
  uint64_t v90 = type metadata accessor for NeuralNetwork.ArrayShapeMapping(0);
  uint64_t v91 = *(void *)(v90 - 8);
  int64_t v13 = *(void *)(v91 + 64);
  uint64_t v14 = alloca(v13);
  uint64_t v15 = alloca(v13);
  uint64_t v92 = &v81;
  uint64_t v99 = type metadata accessor for NeuralNetworkClassifier(0);
  uint64_t v85 = *(void *)(v99 - 8);
  int64_t v16 = *(void *)(v85 + 64);
  uint64_t v17 = alloca(v16);
  uint64_t v18 = alloca(v16);
  uint64_t v89 = &v81;
  uint64_t v106 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType(0);
  uint64_t v95 = *(void *)(v106 - 8);
  int64_t v19 = *(void *)(v95 + 64);
  uint64_t v20 = alloca(v19);
  char v21 = alloca(v19);
  char v103 = &v81;
  uint64_t v93 = type metadata accessor for FeatureType(0);
  uint64_t v94 = *(void *)(v93 - 8);
  int64_t v22 = *(void *)(v94 + 64);
  char v23 = alloca(v22);
  char v24 = alloca(v22);
  uint64_t v105 = &v81;
  int64_t v25 = *(void *)(*(void *)(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NeuralNetwork?)
                              - 8)
                  + 64);
  Swift::String v26 = alloca(v25);
  uint64_t v27 = alloca(v25);
  uint64_t v108 = &v81;
  uint64_t v113 = type metadata accessor for NeuralNetwork.Layer(0);
  uint64_t v28 = *(void *)(v113 - 8);
  int64_t v29 = *(void *)(v28 + 64);
  uint64_t v30 = alloca(v29);
  uint64_t v31 = alloca(v29);
  long long v115 = &v81;
  uint64_t v100 = type metadata accessor for NeuralNetwork(0);
  uint64_t v101 = *(void *)(v100 - 8);
  int64_t v32 = *(void *)(v101 + 64);
  id v33 = alloca(v32);
  uint64_t v34 = alloca(v32);
  uint64_t v102 = &v81;
  unint64_t v35 = alloca(v32);
  char v36 = alloca(v32);
  uint64_t v114 = MLFewShotSoundClassifier.TemporalClassifier.cosineSimilarity(input:exemplar:)(a1, (uint64_t)v114);
  uint64_t v37 = v116;
  char v38 = MLFewShotSoundClassifier.TemporalClassifier.largeMarginClassifierLayers(framewiseEmbeddingShape:)(v112);
  if (v37) {
    return swift_bridgeObjectRelease((_BYTE)v114);
  }
  uint64_t v109 = a1;
  uint64_t v107 = 0;
  uint64_t v104 = &v81;
  NeuralNetwork.init(layers:preprocessors:)(v38, _swiftEmptyArrayStorage);
  uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<NeuralNetwork.Layer>);
  uint64_t v41 = *(void *)(v28 + 72);
  uint64_t v116 = v28;
  uint64_t v42 = *(unsigned __int8 *)(v28 + 80);
  uint64_t v43 = ((int)v42 + 32) & ~*(unsigned __int8 *)(v28 + 80);
  uint64_t v44 = swift_allocObject(v40, v43 + 2 * v41, v42 | 7);
  *(void *)(v44 + 16) = 2;
  *(void *)(v44 + 24) = 4;
  static NeuralNetwork.Layer.constant(name:outputName:shape:values:)(0x746E6174736E6F63, 0xED000073626F7250, 0x746E6174736E6F63, 0xED000073626F7250, &outlined read-only object #0 of MLFewShotSoundClassifier.TemporalClassifier.branchClassifier(input:classLabels:framewiseEmbeddingShape:exemplar:), &outlined read-only object #1 of MLFewShotSoundClassifier.TemporalClassifier.branchClassifier(input:classLabels:framewiseEmbeddingShape:exemplar:));
  uint64_t v110 = v41;
  static NeuralNetwork.Layer.squeezeAll(name:inputName:outputName:)(0x657A6565757173, 0xE700000000000000, 0x746E6174736E6F63, 0xED000073626F7250, 0x62614C7373616C63, 0xEF73626F72506C65);
  uint64_t v45 = v102;
  NeuralNetwork.init(layers:preprocessors:)(v44, _swiftEmptyArrayStorage);
  uint64_t v46 = (uint64_t)v108;
  uint64_t v47 = v100;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v101 + 16))(v108, v45, v100);
  __swift_storeEnumTagSinglePayload(v46, 0, 1, v47);
  static NeuralNetwork.Layer.branch(name:inputName:ifBranch:elseBranch:)(0x68636E617262, 0xE600000000000000, 0x6C616E676973, 0xE600000000000000, v104, v46);
  outlined destroy of NeuralNetwork?(v46);
  unint64_t v48 = v114;
  BOOL v49 = swift_isUniquelyReferenced_nonNull_native(v114) == 0;
  uint64_t v50 = v48;
  if (v49) {
    uint64_t v50 = (char *)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *((void *)v48 + 2) + 1, 1, (uint64_t)v48);
  }
  unint64_t v51 = *((void *)v50 + 2);
  uint64_t v52 = v50;
  unint64_t v53 = *((void *)v50 + 3);
  uint64_t v54 = v113;
  uint64_t v55 = v116;
  if (v53 >> 1 <= v51)
  {
    uint64_t v80 = (char *)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v53 >= 2, v51 + 1, 1, (uint64_t)v52);
    uint64_t v55 = v116;
    uint64_t v54 = v113;
    uint64_t v52 = v80;
  }
  uint64_t v114 = v52;
  *((void *)v52 + 2) = v51 + 1;
  (*(void (**)(char *, uint64_t *, uint64_t))(v55 + 32))(&v52[v43 + v110 * v51], v115, v54);
  Model.init()();
  Model.specificationVersion.setter(4);
  uint64_t v56 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  uint64_t v113 = v56;
  long long v115 = (uint64_t *)type metadata accessor for FeatureDescription(0);
  uint64_t v57 = *(v115 - 1);
  uint64_t v116 = *(void *)(v57 + 72);
  uint64_t v58 = *(unsigned __int8 *)(v57 + 80);
  uint64_t v59 = (((int)v58 + 32) & ~*(unsigned __int8 *)(v57 + 80)) + 2 * v116;
  uint64_t v60 = ((int)v58 + 32) & ~*(unsigned __int8 *)(v57 + 80);
  uint64_t v96 = v60;
  uint64_t v110 = v59;
  uint64_t v108 = (uint64_t *)(v58 | 7);
  uint64_t v61 = swift_allocObject(v56, v59, v58 | 7);
  *(void *)(v61 + 16) = 2;
  *(void *)(v61 + 24) = 4;
  uint64_t v62 = v61 + v60;
  uint64_t v63 = v61;
  (*(void (**)(uint64_t, uint64_t, uint64_t *))(v57 + 16))(v62, v109, v115);
  LODWORD(v109) = enum case for FeatureType.ShapedArrayParameters.DataType.float32(_:);
  uint64_t v64 = v95;
  uint64_t v97 = *(void (**)(uint64_t *, void, uint64_t))(v95 + 104);
  unsigned int v65 = v103;
  v97(v103, enum case for FeatureType.ShapedArrayParameters.DataType.float32(_:), v106);
  static FeatureType.shapedArray(dataType:shape:optional:)(v65, v112, 0);
  long long v115 = *(uint64_t **)(v64 + 8);
  unint64_t v66 = v65;
  uint64_t v67 = v106;
  ((void (*)(uint64_t *, uint64_t))v115)(v66, v106);
  FeatureDescription.init(name:type:description:)(0xD000000000000012, "fixedLengthEmbedding" + 0x8000000000000000, v105, 0, 0xE000000000000000);
  Model.inputs.setter(v63);
  uint64_t v68 = swift_allocObject(v113, v110, v108);
  uint64_t v112 = v68;
  *(void *)(v68 + 16) = 2;
  *(void *)(v68 + 24) = 4;
  uint64_t v69 = v103;
  v97(v103, v109, v67);
  uint64_t v70 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  unint64_t v71 = (void *)swift_allocObject(v70, 56, 7);
  LOBYTE(v67) = (_BYTE)v71;
  v71[2] = 3;
  v71[3] = 6;
  v71[4] = 1;
  v71[5] = 1;
  v71[6] = *(void *)(v98 + 16);
  long long v72 = v105;
  static FeatureType.shapedArray(dataType:shape:optional:)(v69, v71, 0);
  swift_bridgeObjectRelease(v67);
  ((void (*)(uint64_t *, uint64_t))v115)(v69, v106);
  FeatureDescription.init(name:type:description:)(0x62614C7373616C63, 0xEF73626F72506C65, v72, 0, 0xE000000000000000);
  FeatureType.StringParameters.init(optional:)(0);
  (*(void (**)(uint64_t *, void, uint64_t))(v94 + 104))(v72, enum case for FeatureType.string(_:), v93);
  FeatureDescription.init(name:type:description:)(0x62614C7373616C63, 0xEA00000000006C65, v72, 0, 0xE000000000000000);
  Model.outputs.setter(v112);
  Model.predictedFeatureName.setter(0x62614C7373616C63, 0xEA00000000006C65);
  Model.predictedProbabilitiesName.setter(0x62614C7373616C63, 0xEF73626F72506C65);
  unint64_t v73 = v89;
  NeuralNetworkClassifier.init(layers:preprocessors:)(v114, _swiftEmptyArrayStorage);
  uint64_t v74 = v92;
  (*(void (**)(uint64_t *, void, uint64_t))(v91 + 104))(v92, enum case for NeuralNetwork.ArrayShapeMapping.exactArrayMapping(_:), v90);
  NeuralNetworkClassifier.arrayInputShapeMapping.setter(v74);
  NeuralNetworkClassifier.labelProbabilityLayerName.setter(0x62614C7373616C63, 0xEF73626F72506C65);
  uint64_t v75 = v88;
  LOBYTE(v67) = v98;
  *uint64_t v88 = v98;
  (*(void (**)(uint64_t *, void, uint64_t))(v87 + 104))(v75, enum case for NeuralNetworkClassifier.ClassLabels.string(_:), v86);
  swift_bridgeObjectRetain(v67);
  NeuralNetworkClassifier.classLabels.setter(v75);
  uint64_t v76 = v84;
  uint64_t v77 = v85;
  (*(void (**)(uint64_t *, uint64_t *, uint64_t))(v85 + 16))(v84, v73, v99);
  (*(void (**)(uint64_t *, void, uint64_t))(v83 + 104))(v76, enum case for ModelKind.neuralNetworkClassifier(_:), v82);
  Model.kind.setter(v76);
  (*(void (**)(uint64_t *, uint64_t))(v77 + 8))(v73, v99);
  uint64_t v78 = *(void (**)(uint64_t *, uint64_t))(v101 + 8);
  uint64_t v79 = v100;
  v78(v102, v100);
  return ((uint64_t (*)(uint64_t *, uint64_t))v78)(v104, v79);
}

char *MLFewShotSoundClassifier.TemporalClassifier.cosineSimilarity(input:exemplar:)(uint64_t a1, uint64_t a2)
{
  uint64_t v32 = a2;
  uint64_t v37 = type metadata accessor for NeuralNetwork.Layer(0);
  char v38 = *(void (**)(char *, uint64_t *, uint64_t))(v37 - 8);
  int64_t v2 = *((void *)v38 + 8);
  uint64_t v3 = alloca(v2);
  uint64_t v4 = alloca(v2);
  uint64_t v30 = (uint64_t *)&v30;
  uint64_t v5 = alloca(v2);
  uint64_t v6 = alloca(v2);
  uint64_t v34 = (uint64_t *)&v30;
  int64_t v7 = alloca(v2);
  unint64_t v8 = alloca(v2);
  uint64_t v31 = (uint64_t *)&v30;
  unint64_t v9 = alloca(v2);
  int64_t v10 = alloca(v2);
  unint64_t v35 = (uint64_t *)&v30;
  id v11 = alloca(v2);
  uint64_t v12 = alloca(v2);
  uint64_t v13 = FeatureDescription.name.getter();
  char v15 = v14;
  id v33 = (uint64_t *)&v30;
  static NeuralNetwork.Layer.expandDimensions(name:inputName:outputName:axes:)(0x6E49646E61707865, 0xEB00000000747570, v13, v14, 0x6E49646E61707865, 0xEB00000000747570, &outlined read-only object #0 of MLFewShotSoundClassifier.TemporalClassifier.cosineSimilarity(input:exemplar:));
  swift_bridgeObjectRelease(v15);
  int64_t v16 = (char *)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, 1, 1, (uint64_t)_swiftEmptyArrayStorage);
  unint64_t v17 = *((void *)v16 + 2);
  unint64_t v18 = *((void *)v16 + 3);
  if (v18 >> 1 <= v17) {
    int64_t v16 = (char *)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v18 >= 2, v17 + 1, 1, (uint64_t)v16);
  }
  *((void *)v16 + 2) = v17 + 1;
  uint64_t v19 = (*((unsigned __int8 *)v38 + 80) + 32) & ~*((unsigned __int8 *)v38 + 80);
  uint64_t v20 = (void (*)(char *, uint64_t *, uint64_t))*((void *)v38 + 4);
  uint64_t v36 = *((void *)v38 + 9);
  char v38 = v20;
  v20(&v16[v36 * v17 + v19], v33, v37);
  static NeuralNetwork.Layer.constant(name:outputName:shape:values:)(0x72616C706D657865, 0xE800000000000000, 0x72616C706D657865, 0xE800000000000000, &outlined read-only object #1 of MLFewShotSoundClassifier.TemporalClassifier.cosineSimilarity(input:exemplar:), v32);
  unint64_t v21 = *((void *)v16 + 2);
  int64_t v22 = v21 + 1;
  if (*((void *)v16 + 3) >> 1 <= v21) {
    int64_t v16 = (char *)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v16 + 3) >= 2uLL, v22, 1, (uint64_t)v16);
  }
  *((void *)v16 + 2) = v22;
  v38(&v16[v36 * v21 + v19], v35, v37);
  char v23 = v31;
  static NeuralNetwork.Layer.constant(name:outputName:shape:values:)(0x6854656E69736F63, 0xEF646C6F68736572, 0x6854656E69736F63, 0xEF646C6F68736572, &outlined read-only object #2 of MLFewShotSoundClassifier.TemporalClassifier.cosineSimilarity(input:exemplar:), &outlined read-only object #3 of MLFewShotSoundClassifier.TemporalClassifier.cosineSimilarity(input:exemplar:));
  unint64_t v24 = *((void *)v16 + 2);
  int64_t v25 = v24 + 1;
  if (*((void *)v16 + 3) >> 1 <= v24) {
    int64_t v16 = (char *)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v16 + 3) >= 2uLL, v25, 1, (uint64_t)v16);
  }
  *((void *)v16 + 2) = v25;
  v38(&v16[v36 * v24 + v19], v23, v37);
  static NeuralNetwork.Layer.cosineSimilarity(name:inputNames:outputName:)(0xD000000000000010, "activatedReduced" + 0x8000000000000000, 0x72616C706D657865, 0xE800000000000000, 0x6E49646E61707865, 0xEB00000000747570, 0xD000000000000010, "activatedReduced" + 0x8000000000000000);
  unint64_t v26 = *((void *)v16 + 2);
  if (*((void *)v16 + 3) >> 1 <= v26) {
    int64_t v16 = (char *)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v16 + 3) >= 2uLL, v26 + 1, 1, (uint64_t)v16);
  }
  *((void *)v16 + 2) = v26 + 1;
  v38(&v16[v36 * v26 + v19], v34, v37);
  uint64_t v27 = v30;
  static NeuralNetwork.Layer.broadcastableSubtract(name:inputNames:outputName:)(0x7463617274627573, 0xE800000000000000, 0xD000000000000010, "activatedReduced" + 0x8000000000000000, 0x6854656E69736F63, 0xEF646C6F68736572, 0x6C616E676973, 0xE600000000000000);
  unint64_t v28 = *((void *)v16 + 2);
  if (*((void *)v16 + 3) >> 1 <= v28) {
    int64_t v16 = (char *)specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*((void *)v16 + 3) >= 2uLL, v28 + 1, 1, (uint64_t)v16);
  }
  *((void *)v16 + 2) = v28 + 1;
  v38(&v16[v19 + v36 * v28], v27, v37);
  return v16;
}

uint64_t MLFewShotSoundClassifier.TemporalClassifier.soundPrintKCustomModel(input:fixedOutput:framewiseEmbeddingShape:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  uint64_t v32 = a3;
  uint64_t v33 = a2;
  uint64_t v36 = a1;
  uint64_t v42 = v3;
  uint64_t v29 = type metadata accessor for ModelKind(0);
  uint64_t v30 = *(void *)(v29 - 8);
  int64_t v4 = *(void *)(v30 + 64);
  uint64_t v5 = alloca(v4);
  uint64_t v6 = alloca(v4);
  uint64_t v31 = &v28;
  uint64_t v34 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType(0);
  uint64_t v35 = *(void *)(v34 - 8);
  int64_t v7 = *(void *)(v35 + 64);
  unint64_t v8 = alloca(v7);
  unint64_t v9 = alloca(v7);
  uint64_t v37 = &v28;
  int64_t v10 = *(void *)(*(void *)(type metadata accessor for FeatureType(0) - 8) + 64);
  id v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  uint64_t v41 = &v28;
  Model.init()();
  Model.specificationVersion.setter(4);
  uint64_t v13 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  uint64_t v39 = v13;
  uint64_t v14 = type metadata accessor for FeatureDescription(0);
  uint64_t v15 = *(void *)(v14 - 8);
  uint64_t v40 = v14;
  uint64_t v38 = *(void *)(v15 + 72);
  uint64_t v16 = *(unsigned __int8 *)(v15 + 80);
  uint64_t v17 = ((int)v16 + 32) & ~*(unsigned __int8 *)(v15 + 80);
  v16 |= 7uLL;
  uint64_t v18 = swift_allocObject(v13, v17 + v38, v16);
  *(void *)(v18 + 16) = 1;
  *(void *)(v18 + 24) = 2;
  uint64_t v19 = *(void (**)(uint64_t, uint64_t, uint64_t))(v15 + 16);
  v19(v18 + v17, v36, v14);
  Model.inputs.setter(v18);
  uint64_t v20 = swift_allocObject(v39, v17 + 2 * v38, v16);
  *(void *)(v20 + 16) = 2;
  *(void *)(v20 + 24) = 4;
  v19(v20 + v17, v33, v40);
  unint64_t v21 = v37;
  uint64_t v22 = v34;
  uint64_t v23 = v35;
  (*(void (**)(uint64_t *, void, uint64_t))(v35 + 104))(v37, enum case for FeatureType.ShapedArrayParameters.DataType.float32(_:), v34);
  static FeatureType.shapedArray(dataType:shape:optional:)(v21, v32, 0);
  (*(void (**)(uint64_t *, uint64_t))(v23 + 8))(v21, v22);
  FeatureDescription.init(name:type:description:)(0xD000000000000012, "fixedLengthEmbedding" + 0x8000000000000000, v41, 0, 0xE000000000000000);
  Model.outputs.setter(v20);
  uint64_t v24 = type metadata accessor for CustomModelConfiguration.ParameterValue(0);
  uint64_t v25 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, v24, &protocol witness table for String);
  unint64_t v26 = v31;
  CustomModelConfiguration.init(className:parameters:)(0xD000000000000029, "cosineSimilarity" + 0x8000000000000000, v25);
  (*(void (**)(uint64_t *, void, uint64_t))(v30 + 104))(v26, enum case for ModelKind.custom(_:), v29);
  return Model.kind.setter(v26);
}

uint64_t MLFewShotSoundClassifier.TemporalClassifier.pipeline(classLabels:inferenceWindowSize:framewiseEmbeddingShape:exemplar:)(uint64_t a1, uint64_t a2, uint64_t a3, char *a4)
{
  uint64_t v54 = v5;
  uint64_t v57 = v6;
  uint64_t v55 = a4;
  uint64_t v58 = a3;
  uint64_t v56 = a1;
  uint64_t v64 = v4;
  uint64_t v62 = type metadata accessor for ModelKind(0);
  uint64_t v61 = *(void *)(v62 - 8);
  int64_t v7 = *(void *)(v61 + 64);
  unint64_t v8 = alloca(v7);
  unint64_t v9 = alloca(v7);
  uint64_t v63 = &v54;
  uint64_t v67 = type metadata accessor for Model(0);
  uint64_t v68 = *(void *)(v67 - 8);
  int64_t v10 = *(void *)(v68 + 64);
  id v11 = alloca(v10);
  uint64_t v12 = alloca(v10);
  long long v72 = &v54;
  uint64_t v13 = alloca(v10);
  uint64_t v14 = alloca(v10);
  unint64_t v71 = &v54;
  uint64_t v59 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType(0);
  uint64_t v75 = *(void *)(v59 - 8);
  int64_t v15 = *(void *)(v75 + 64);
  uint64_t v16 = alloca(v15);
  uint64_t v17 = alloca(v15);
  int64_t v18 = *(void *)(*(void *)(type metadata accessor for FeatureType(0) - 8) + 64);
  uint64_t v19 = alloca(v18);
  uint64_t v20 = alloca(v18);
  unint64_t v73 = &v54;
  uint64_t v69 = type metadata accessor for FeatureDescription(0);
  uint64_t v70 = *(void *)(v69 - 8);
  int64_t v21 = *(void *)(v70 + 64);
  uint64_t v22 = alloca(v21);
  uint64_t v23 = alloca(v21);
  unint64_t v66 = &v54;
  uint64_t v24 = alloca(v21);
  uint64_t v25 = alloca(v21);
  uint64_t v74 = &v54;
  uint64_t v26 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  uint64_t v27 = (void *)swift_allocObject(v26, 56, 7);
  void v27[2] = 3;
  v27[3] = 6;
  v27[4] = 1;
  v27[5] = 1;
  v27[6] = a2;
  unsigned int v65 = enum case for FeatureType.ShapedArrayParameters.DataType.float32(_:);
  uint64_t v60 = *(void (**)(void **, void, uint64_t))(v75 + 104);
  uint64_t v28 = v59;
  v60(&v54, enum case for FeatureType.ShapedArrayParameters.DataType.float32(_:), v59);
  static FeatureType.shapedArray(dataType:shape:optional:)(&v54, v27, 0);
  swift_bridgeObjectRelease((_BYTE)v27);
  uint64_t v75 = *(void *)(v75 + 8);
  ((void (*)(void **, uint64_t))v75)(&v54, v28);
  uint64_t v29 = v73;
  FeatureDescription.init(name:type:description:)(0x6F696475615F6474, 0xE800000000000000, v73, 0, 0xE000000000000000);
  uint64_t v30 = (uint64_t)v66;
  v60(&v54, v65, v28);
  static FeatureType.shapedArray(dataType:shape:optional:)(&v54, &outlined read-only object #0 of MLFewShotSoundClassifier.TemporalClassifier.pipeline(classLabels:inferenceWindowSize:framewiseEmbeddingShape:exemplar:), 0);
  ((void (*)(void **, uint64_t))v75)(&v54, v28);
  FeatureDescription.init(name:type:description:)(0xD000000000000014, "lid temporal dimension." + 0x8000000000000000, v29, 0, 0xE000000000000000);
  uint64_t v31 = v58;
  MLFewShotSoundClassifier.TemporalClassifier.soundPrintKCustomModel(input:fixedOutput:framewiseEmbeddingShape:)((uint64_t)v74, v30, v58);
  uint64_t v32 = v54;
  MLFewShotSoundClassifier.TemporalClassifier.branchClassifier(input:classLabels:framewiseEmbeddingShape:exemplar:)(v30, v56, v31, v55);
  unint64_t v73 = v32;
  if (v32)
  {
    (*(void (**)(void *, uint64_t))(v68 + 8))(v71, v67);
  }
  else
  {
    Model.init()();
    Model.specificationVersion.setter(4);
    uint64_t v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
    uint64_t v34 = v70;
    uint64_t v35 = *(unsigned __int8 *)(v70 + 80);
    uint64_t v36 = ((int)v35 + 32) & ~*(unsigned __int8 *)(v70 + 80);
    uint64_t v37 = swift_allocObject(v33, v36 + *(void *)(v70 + 72), v35 | 7);
    *(void *)(v37 + 16) = 1;
    *(void *)(v37 + 24) = 2;
    uint64_t v38 = (uint64_t)v74;
    (*(void (**)(uint64_t, void *, uint64_t))(v34 + 16))(v37 + v36, v74, v69);
    Model.inputs.setter(v37);
    uint64_t v39 = Model.outputs.getter(v37, v38);
    Model.outputs.setter(v39);
    Model.predictedFeatureName.setter(0x62614C7373616C63, 0xEA00000000006C65);
    Model.predictedProbabilitiesName.setter(0x62614C7373616C63, 0xEF73626F72506C65);
    uint64_t v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Model>);
    uint64_t v75 = *(void *)(v68 + 72);
    uint64_t v41 = *(unsigned __int8 *)(v68 + 80);
    uint64_t v42 = v68;
    uint64_t v43 = ((int)v41 + 32) & ~*(unsigned __int8 *)(v68 + 80);
    uint64_t v44 = swift_allocObject(v40, v43 + 2 * v75, v41 | 7);
    *(void *)(v44 + 16) = 2;
    *(void *)(v44 + 24) = 4;
    uint64_t v45 = v44 + v43;
    uint64_t v46 = *(void (**)(uint64_t, void *, uint64_t))(v42 + 16);
    uint64_t v47 = v67;
    v46(v45, v71, v67);
    v46(v75 + v45, v72, v47);
    unint64_t v48 = v63;
    PipelineConfiguration.init(models:names:)(v44, _swiftEmptyArrayStorage);
    (*(void (**)(void *, void, uint64_t))(v61 + 104))(v48, enum case for ModelKind.pipeline(_:), v62);
    Model.kind.setter(v48);
    BOOL v49 = *(void (**)(void *, uint64_t))(v68 + 8);
    uint64_t v50 = v67;
    v49(v72, v67);
    v49(v71, v50);
  }
  unint64_t v51 = *(void (**)(void *, uint64_t))(v70 + 8);
  uint64_t v52 = v69;
  v51(v66, v69);
  return ((uint64_t (*)(void *, uint64_t))v51)(v74, v52);
}